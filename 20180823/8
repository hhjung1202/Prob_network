Files already downloaded and verified
USE 1 GPUs!
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3258) |  Loss2: (0.0000) | Acc: (10.00%) (14/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.3144) |  Loss2: (0.0000) | Acc: (9.00%) (133/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.3055) |  Loss2: (0.0000) | Acc: (9.00%) (267/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.2987) |  Loss2: (0.0000) | Acc: (10.00%) (431/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (2.2903) |  Loss2: (0.0000) | Acc: (12.00%) (641/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (2.2832) |  Loss2: (0.0000) | Acc: (13.00%) (849/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (2.2747) |  Loss2: (0.0000) | Acc: (14.00%) (1118/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (2.2666) |  Loss2: (0.0000) | Acc: (15.00%) (1388/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (2.2580) |  Loss2: (0.0000) | Acc: (16.00%) (1686/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (2.2480) |  Loss2: (0.0000) | Acc: (16.00%) (1962/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (2.2383) |  Loss2: (0.0000) | Acc: (17.00%) (2281/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (2.2284) |  Loss2: (0.0000) | Acc: (18.00%) (2592/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (2.2185) |  Loss2: (0.0000) | Acc: (18.00%) (2927/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (2.2101) |  Loss2: (0.0000) | Acc: (19.00%) (3230/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (2.2011) |  Loss2: (0.0000) | Acc: (19.00%) (3553/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (2.1926) |  Loss2: (0.0000) | Acc: (20.00%) (3875/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (2.1820) |  Loss2: (0.0000) | Acc: (20.00%) (4231/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (2.1742) |  Loss2: (0.0000) | Acc: (20.00%) (4578/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (2.1659) |  Loss2: (0.0000) | Acc: (21.00%) (4906/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (2.1568) |  Loss2: (0.0000) | Acc: (21.00%) (5273/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (2.1478) |  Loss2: (0.0000) | Acc: (21.00%) (5639/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (2.1399) |  Loss2: (0.0000) | Acc: (22.00%) (6007/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (2.1330) |  Loss2: (0.0000) | Acc: (22.00%) (6390/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (2.1256) |  Loss2: (0.0000) | Acc: (22.00%) (6767/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (2.1179) |  Loss2: (0.0000) | Acc: (23.00%) (7180/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (2.1104) |  Loss2: (0.0000) | Acc: (23.00%) (7577/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (2.1035) |  Loss2: (0.0000) | Acc: (23.00%) (7970/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (2.0976) |  Loss2: (0.0000) | Acc: (24.00%) (8362/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (2.0912) |  Loss2: (0.0000) | Acc: (24.00%) (8748/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (2.0852) |  Loss2: (0.0000) | Acc: (24.00%) (9126/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (2.0795) |  Loss2: (0.0000) | Acc: (24.00%) (9513/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (2.0741) |  Loss2: (0.0000) | Acc: (24.00%) (9894/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (2.0678) |  Loss2: (0.0000) | Acc: (25.00%) (10323/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (2.0614) |  Loss2: (0.0000) | Acc: (25.00%) (10735/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (2.0552) |  Loss2: (0.0000) | Acc: (25.00%) (11154/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (2.0496) |  Loss2: (0.0000) | Acc: (25.00%) (11576/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (2.0436) |  Loss2: (0.0000) | Acc: (25.00%) (12006/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (2.0379) |  Loss2: (0.0000) | Acc: (26.00%) (12413/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (2.0339) |  Loss2: (0.0000) | Acc: (26.00%) (12801/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (2.0285) |  Loss2: (0.0000) | Acc: (26.00%) (13200/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_000.pth.tar'
# TEST : Loss: (1.7791) | Acc: (34.00%) (3487/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.6131, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(765.5832, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(768.1483, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1533.0088, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(513.0873, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2171.2161, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4342.3057, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1438.9307, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6134.8774, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12269.7314, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4085.2729, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17368.8613, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.8688) |  Loss2: (0.0000) | Acc: (27.00%) (35/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.8264) |  Loss2: (0.0000) | Acc: (31.00%) (445/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.8291) |  Loss2: (0.0000) | Acc: (32.00%) (881/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8208) |  Loss2: (0.0000) | Acc: (33.00%) (1338/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8194) |  Loss2: (0.0000) | Acc: (33.00%) (1761/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.8103) |  Loss2: (0.0000) | Acc: (33.00%) (2218/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.8010) |  Loss2: (0.0000) | Acc: (34.00%) (2679/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.7957) |  Loss2: (0.0000) | Acc: (34.00%) (3144/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.7914) |  Loss2: (0.0000) | Acc: (34.00%) (3608/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.7860) |  Loss2: (0.0000) | Acc: (34.00%) (4056/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.7841) |  Loss2: (0.0000) | Acc: (34.00%) (4479/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.7805) |  Loss2: (0.0000) | Acc: (34.00%) (4932/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.7768) |  Loss2: (0.0000) | Acc: (34.00%) (5378/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.7738) |  Loss2: (0.0000) | Acc: (34.00%) (5845/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7700) |  Loss2: (0.0000) | Acc: (35.00%) (6318/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7657) |  Loss2: (0.0000) | Acc: (35.00%) (6805/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7639) |  Loss2: (0.0000) | Acc: (35.00%) (7262/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7610) |  Loss2: (0.0000) | Acc: (35.00%) (7756/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7588) |  Loss2: (0.0000) | Acc: (35.00%) (8224/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7554) |  Loss2: (0.0000) | Acc: (35.00%) (8708/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7524) |  Loss2: (0.0000) | Acc: (35.00%) (9189/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7494) |  Loss2: (0.0000) | Acc: (35.00%) (9658/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7477) |  Loss2: (0.0000) | Acc: (35.00%) (10132/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7440) |  Loss2: (0.0000) | Acc: (36.00%) (10647/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7412) |  Loss2: (0.0000) | Acc: (36.00%) (11124/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7386) |  Loss2: (0.0000) | Acc: (36.00%) (11601/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7365) |  Loss2: (0.0000) | Acc: (36.00%) (12075/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7348) |  Loss2: (0.0000) | Acc: (36.00%) (12553/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7327) |  Loss2: (0.0000) | Acc: (36.00%) (13042/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7289) |  Loss2: (0.0000) | Acc: (36.00%) (13548/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7260) |  Loss2: (0.0000) | Acc: (36.00%) (14053/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7228) |  Loss2: (0.0000) | Acc: (36.00%) (14562/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7193) |  Loss2: (0.0000) | Acc: (36.00%) (15086/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7168) |  Loss2: (0.0000) | Acc: (36.00%) (15574/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7145) |  Loss2: (0.0000) | Acc: (36.00%) (16109/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.7124) |  Loss2: (0.0000) | Acc: (36.00%) (16614/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.7091) |  Loss2: (0.0000) | Acc: (37.00%) (17128/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.7072) |  Loss2: (0.0000) | Acc: (37.00%) (17633/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.7055) |  Loss2: (0.0000) | Acc: (37.00%) (18137/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.7032) |  Loss2: (0.0000) | Acc: (37.00%) (18646/50000)
# TEST : Loss: (1.5856) | Acc: (40.00%) (4036/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 2 | Batch_idx: 0 |  Loss: (1.6181) |  Loss2: (0.0000) | Acc: (45.00%) (58/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.6101) |  Loss2: (0.0000) | Acc: (41.00%) (581/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.5972) |  Loss2: (0.0000) | Acc: (41.00%) (1106/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.5841) |  Loss2: (0.0000) | Acc: (41.00%) (1666/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.5863) |  Loss2: (0.0000) | Acc: (41.00%) (2203/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.5851) |  Loss2: (0.0000) | Acc: (41.00%) (2739/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.5860) |  Loss2: (0.0000) | Acc: (41.00%) (3267/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.5853) |  Loss2: (0.0000) | Acc: (41.00%) (3768/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.5813) |  Loss2: (0.0000) | Acc: (41.00%) (4322/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.5802) |  Loss2: (0.0000) | Acc: (41.00%) (4858/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.5734) |  Loss2: (0.0000) | Acc: (42.00%) (5455/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.5743) |  Loss2: (0.0000) | Acc: (42.00%) (5991/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5711) |  Loss2: (0.0000) | Acc: (42.00%) (6555/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5707) |  Loss2: (0.0000) | Acc: (42.00%) (7105/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5688) |  Loss2: (0.0000) | Acc: (42.00%) (7665/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5688) |  Loss2: (0.0000) | Acc: (42.00%) (8239/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5650) |  Loss2: (0.0000) | Acc: (42.00%) (8818/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5655) |  Loss2: (0.0000) | Acc: (42.00%) (9340/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5635) |  Loss2: (0.0000) | Acc: (42.00%) (9908/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5604) |  Loss2: (0.0000) | Acc: (42.00%) (10495/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5580) |  Loss2: (0.0000) | Acc: (43.00%) (11074/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5550) |  Loss2: (0.0000) | Acc: (43.00%) (11652/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5527) |  Loss2: (0.0000) | Acc: (43.00%) (12199/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5487) |  Loss2: (0.0000) | Acc: (43.00%) (12804/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5477) |  Loss2: (0.0000) | Acc: (43.00%) (13360/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5459) |  Loss2: (0.0000) | Acc: (43.00%) (13924/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5432) |  Loss2: (0.0000) | Acc: (43.00%) (14505/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5398) |  Loss2: (0.0000) | Acc: (43.00%) (15108/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5382) |  Loss2: (0.0000) | Acc: (43.00%) (15702/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5351) |  Loss2: (0.0000) | Acc: (43.00%) (16287/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5340) |  Loss2: (0.0000) | Acc: (43.00%) (16858/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5333) |  Loss2: (0.0000) | Acc: (43.00%) (17426/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5320) |  Loss2: (0.0000) | Acc: (43.00%) (17996/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5297) |  Loss2: (0.0000) | Acc: (43.00%) (18574/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.5275) |  Loss2: (0.0000) | Acc: (43.00%) (19162/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.5256) |  Loss2: (0.0000) | Acc: (43.00%) (19758/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.5233) |  Loss2: (0.0000) | Acc: (44.00%) (20378/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.5216) |  Loss2: (0.0000) | Acc: (44.00%) (20975/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.5203) |  Loss2: (0.0000) | Acc: (44.00%) (21558/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.5187) |  Loss2: (0.0000) | Acc: (44.00%) (22138/50000)
# TEST : Loss: (1.4278) | Acc: (48.00%) (4807/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 3 | Batch_idx: 0 |  Loss: (1.4223) |  Loss2: (0.0000) | Acc: (53.00%) (69/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4201) |  Loss2: (0.0000) | Acc: (48.00%) (677/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.4311) |  Loss2: (0.0000) | Acc: (47.00%) (1289/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.4331) |  Loss2: (0.0000) | Acc: (48.00%) (1912/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.4256) |  Loss2: (0.0000) | Acc: (48.00%) (2548/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.4303) |  Loss2: (0.0000) | Acc: (48.00%) (3177/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4263) |  Loss2: (0.0000) | Acc: (48.00%) (3802/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4212) |  Loss2: (0.0000) | Acc: (48.00%) (4435/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4124) |  Loss2: (0.0000) | Acc: (49.00%) (5086/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4095) |  Loss2: (0.0000) | Acc: (49.00%) (5732/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.4076) |  Loss2: (0.0000) | Acc: (49.00%) (6378/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.4047) |  Loss2: (0.0000) | Acc: (49.00%) (7044/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.4027) |  Loss2: (0.0000) | Acc: (49.00%) (7687/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.3985) |  Loss2: (0.0000) | Acc: (49.00%) (8345/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.3946) |  Loss2: (0.0000) | Acc: (49.00%) (9016/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.3942) |  Loss2: (0.0000) | Acc: (50.00%) (9672/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.3952) |  Loss2: (0.0000) | Acc: (49.00%) (10289/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.3942) |  Loss2: (0.0000) | Acc: (50.00%) (10947/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.3933) |  Loss2: (0.0000) | Acc: (49.00%) (11567/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.3906) |  Loss2: (0.0000) | Acc: (50.00%) (12238/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.3893) |  Loss2: (0.0000) | Acc: (50.00%) (12898/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.3883) |  Loss2: (0.0000) | Acc: (50.00%) (13552/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.3880) |  Loss2: (0.0000) | Acc: (50.00%) (14207/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.3875) |  Loss2: (0.0000) | Acc: (50.00%) (14854/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.3858) |  Loss2: (0.0000) | Acc: (50.00%) (15492/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.3848) |  Loss2: (0.0000) | Acc: (50.00%) (16156/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.3835) |  Loss2: (0.0000) | Acc: (50.00%) (16829/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.3799) |  Loss2: (0.0000) | Acc: (50.00%) (17529/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.3771) |  Loss2: (0.0000) | Acc: (50.00%) (18215/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.3753) |  Loss2: (0.0000) | Acc: (50.00%) (18868/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.3742) |  Loss2: (0.0000) | Acc: (50.00%) (19518/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.3719) |  Loss2: (0.0000) | Acc: (50.00%) (20233/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.3696) |  Loss2: (0.0000) | Acc: (50.00%) (20914/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.3674) |  Loss2: (0.0000) | Acc: (51.00%) (21611/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.3667) |  Loss2: (0.0000) | Acc: (51.00%) (22274/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.3655) |  Loss2: (0.0000) | Acc: (51.00%) (22955/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.3625) |  Loss2: (0.0000) | Acc: (51.00%) (23652/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.3609) |  Loss2: (0.0000) | Acc: (51.00%) (24319/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.3592) |  Loss2: (0.0000) | Acc: (51.00%) (25023/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.3584) |  Loss2: (0.0000) | Acc: (51.00%) (25674/50000)
# TEST : Loss: (1.3280) | Acc: (51.00%) (5191/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 4 | Batch_idx: 0 |  Loss: (1.3109) |  Loss2: (0.0000) | Acc: (50.00%) (64/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.2880) |  Loss2: (0.0000) | Acc: (53.00%) (748/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.2804) |  Loss2: (0.0000) | Acc: (53.00%) (1447/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.2772) |  Loss2: (0.0000) | Acc: (54.00%) (2162/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.2721) |  Loss2: (0.0000) | Acc: (54.00%) (2858/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.2821) |  Loss2: (0.0000) | Acc: (54.00%) (3532/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.2791) |  Loss2: (0.0000) | Acc: (54.00%) (4235/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.2746) |  Loss2: (0.0000) | Acc: (54.00%) (4969/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.2732) |  Loss2: (0.0000) | Acc: (54.00%) (5656/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.2743) |  Loss2: (0.0000) | Acc: (54.00%) (6389/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.2704) |  Loss2: (0.0000) | Acc: (55.00%) (7117/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.2701) |  Loss2: (0.0000) | Acc: (55.00%) (7833/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.2690) |  Loss2: (0.0000) | Acc: (55.00%) (8529/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.2699) |  Loss2: (0.0000) | Acc: (55.00%) (9224/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.2664) |  Loss2: (0.0000) | Acc: (55.00%) (9950/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.2660) |  Loss2: (0.0000) | Acc: (55.00%) (10673/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.2649) |  Loss2: (0.0000) | Acc: (55.00%) (11379/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.2611) |  Loss2: (0.0000) | Acc: (55.00%) (12128/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.2598) |  Loss2: (0.0000) | Acc: (55.00%) (12853/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.2582) |  Loss2: (0.0000) | Acc: (55.00%) (13552/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.2571) |  Loss2: (0.0000) | Acc: (55.00%) (14271/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.2555) |  Loss2: (0.0000) | Acc: (55.00%) (14993/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.2542) |  Loss2: (0.0000) | Acc: (55.00%) (15710/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.2513) |  Loss2: (0.0000) | Acc: (55.00%) (16459/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.2492) |  Loss2: (0.0000) | Acc: (55.00%) (17195/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.2479) |  Loss2: (0.0000) | Acc: (55.00%) (17932/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.2469) |  Loss2: (0.0000) | Acc: (55.00%) (18655/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.2455) |  Loss2: (0.0000) | Acc: (55.00%) (19370/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.2449) |  Loss2: (0.0000) | Acc: (55.00%) (20075/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.2442) |  Loss2: (0.0000) | Acc: (55.00%) (20801/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.2424) |  Loss2: (0.0000) | Acc: (55.00%) (21534/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.2408) |  Loss2: (0.0000) | Acc: (55.00%) (22267/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.2387) |  Loss2: (0.0000) | Acc: (56.00%) (23011/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.2364) |  Loss2: (0.0000) | Acc: (56.00%) (23760/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.2344) |  Loss2: (0.0000) | Acc: (56.00%) (24509/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.2329) |  Loss2: (0.0000) | Acc: (56.00%) (25238/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.2309) |  Loss2: (0.0000) | Acc: (56.00%) (25983/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.2286) |  Loss2: (0.0000) | Acc: (56.00%) (26738/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.2279) |  Loss2: (0.0000) | Acc: (56.00%) (27462/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.2270) |  Loss2: (0.0000) | Acc: (56.00%) (28187/50000)
# TEST : Loss: (1.1766) | Acc: (56.00%) (5633/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 5 | Batch_idx: 0 |  Loss: (1.1658) |  Loss2: (0.0000) | Acc: (57.00%) (74/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.2453) |  Loss2: (0.0000) | Acc: (54.00%) (768/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.2630) |  Loss2: (0.0000) | Acc: (53.00%) (1439/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.2795) |  Loss2: (0.0000) | Acc: (53.00%) (2112/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.2868) |  Loss2: (0.0000) | Acc: (52.00%) (2774/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.2913) |  Loss2: (0.0000) | Acc: (53.00%) (3471/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.2906) |  Loss2: (0.0000) | Acc: (53.00%) (4155/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.2934) |  Loss2: (0.0000) | Acc: (53.00%) (4818/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.2955) |  Loss2: (0.0000) | Acc: (53.00%) (5498/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.2949) |  Loss2: (0.0000) | Acc: (53.00%) (6178/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.2946) |  Loss2: (0.0000) | Acc: (53.00%) (6869/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.2907) |  Loss2: (0.0000) | Acc: (53.00%) (7562/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.2860) |  Loss2: (0.0000) | Acc: (53.00%) (8271/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.2837) |  Loss2: (0.0000) | Acc: (53.00%) (8967/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.2847) |  Loss2: (0.0000) | Acc: (53.00%) (9634/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.2826) |  Loss2: (0.0000) | Acc: (53.00%) (10342/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.2815) |  Loss2: (0.0000) | Acc: (53.00%) (11026/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.2820) |  Loss2: (0.0000) | Acc: (53.00%) (11700/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.2798) |  Loss2: (0.0000) | Acc: (53.00%) (12391/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.2760) |  Loss2: (0.0000) | Acc: (53.00%) (13111/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.2735) |  Loss2: (0.0000) | Acc: (53.00%) (13829/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.2704) |  Loss2: (0.0000) | Acc: (53.00%) (14541/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.2696) |  Loss2: (0.0000) | Acc: (53.00%) (15245/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.2668) |  Loss2: (0.0000) | Acc: (53.00%) (15955/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.2662) |  Loss2: (0.0000) | Acc: (54.00%) (16665/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.2657) |  Loss2: (0.0000) | Acc: (54.00%) (17358/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.2623) |  Loss2: (0.0000) | Acc: (54.00%) (18101/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.2605) |  Loss2: (0.0000) | Acc: (54.00%) (18809/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.2586) |  Loss2: (0.0000) | Acc: (54.00%) (19526/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.2568) |  Loss2: (0.0000) | Acc: (54.00%) (20259/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.2543) |  Loss2: (0.0000) | Acc: (54.00%) (20999/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.2530) |  Loss2: (0.0000) | Acc: (54.00%) (21711/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.2524) |  Loss2: (0.0000) | Acc: (54.00%) (22442/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.2510) |  Loss2: (0.0000) | Acc: (54.00%) (23182/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.2497) |  Loss2: (0.0000) | Acc: (54.00%) (23905/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.2488) |  Loss2: (0.0000) | Acc: (54.00%) (24626/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.2477) |  Loss2: (0.0000) | Acc: (54.00%) (25343/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.2467) |  Loss2: (0.0000) | Acc: (54.00%) (26075/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.2447) |  Loss2: (0.0000) | Acc: (54.00%) (26814/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.2433) |  Loss2: (0.0000) | Acc: (55.00%) (27504/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_005.pth.tar'
# TEST : Loss: (1.1854) | Acc: (57.00%) (5731/10000)
percent tensor([0.5031, 0.5033, 0.5053, 0.5025, 0.5048, 0.5030, 0.5036, 0.5039, 0.5022,
        0.5044, 0.5025, 0.5053, 0.5029, 0.5016, 0.5033, 0.5026],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.4968, 0.4967, 0.4975, 0.4967, 0.4983, 0.4970, 0.4967, 0.4968,
        0.4971, 0.4968, 0.4971, 0.4978, 0.4964, 0.4982, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5012, 0.5029, 0.5058, 0.5028, 0.5056, 0.5029, 0.5032, 0.5036, 0.5018,
        0.5028, 0.5022, 0.5055, 0.5014, 0.5020, 0.5015, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.5059, 0.5069, 0.5072, 0.5053, 0.5078, 0.5037, 0.5084, 0.5073, 0.5068,
        0.5076, 0.5075, 0.5086, 0.5066, 0.5052, 0.5071, 0.5056],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5059, 0.5152, 0.5137, 0.5136, 0.5044, 0.5090, 0.5161, 0.5070,
        0.5082, 0.5063, 0.5126, 0.5058, 0.5037, 0.5067, 0.5068],
       device='cuda:0') torch.Size([16])
percent tensor([0.5002, 0.4997, 0.5054, 0.5054, 0.5052, 0.4993, 0.5023, 0.5059, 0.5000,
        0.5015, 0.4985, 0.5032, 0.4985, 0.4993, 0.4996, 0.5008],
       device='cuda:0') torch.Size([16])
percent tensor([0.5074, 0.5069, 0.5202, 0.5218, 0.5199, 0.5103, 0.5119, 0.5322, 0.5066,
        0.5081, 0.5060, 0.5087, 0.5064, 0.5063, 0.5091, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5304, 0.5241, 0.5678, 0.5799, 0.5666, 0.5430, 0.5327, 0.5925, 0.5403,
        0.5394, 0.5307, 0.5363, 0.5366, 0.5347, 0.5396, 0.5647],
       device='cuda:0') torch.Size([16])
Epoch: 6 | Batch_idx: 0 |  Loss: (1.1487) |  Loss2: (0.0000) | Acc: (59.00%) (76/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.1656) |  Loss2: (0.0000) | Acc: (58.00%) (829/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.1951) |  Loss2: (0.0000) | Acc: (58.00%) (1562/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.2082) |  Loss2: (0.0000) | Acc: (57.00%) (2287/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.2114) |  Loss2: (0.0000) | Acc: (56.00%) (2990/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.2001) |  Loss2: (0.0000) | Acc: (57.00%) (3738/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.1963) |  Loss2: (0.0000) | Acc: (57.00%) (4471/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.1933) |  Loss2: (0.0000) | Acc: (57.00%) (5220/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.1905) |  Loss2: (0.0000) | Acc: (57.00%) (5976/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.1895) |  Loss2: (0.0000) | Acc: (57.00%) (6719/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.1910) |  Loss2: (0.0000) | Acc: (57.00%) (7457/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.1896) |  Loss2: (0.0000) | Acc: (57.00%) (8193/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.1898) |  Loss2: (0.0000) | Acc: (57.00%) (8932/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.1904) |  Loss2: (0.0000) | Acc: (57.00%) (9651/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.1918) |  Loss2: (0.0000) | Acc: (57.00%) (10378/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.1898) |  Loss2: (0.0000) | Acc: (57.00%) (11100/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.1899) |  Loss2: (0.0000) | Acc: (57.00%) (11844/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.1910) |  Loss2: (0.0000) | Acc: (57.00%) (12568/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.1893) |  Loss2: (0.0000) | Acc: (57.00%) (13317/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.1865) |  Loss2: (0.0000) | Acc: (57.00%) (14083/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.1858) |  Loss2: (0.0000) | Acc: (57.00%) (14822/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.1854) |  Loss2: (0.0000) | Acc: (57.00%) (15554/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.1826) |  Loss2: (0.0000) | Acc: (57.00%) (16328/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.1834) |  Loss2: (0.0000) | Acc: (57.00%) (17049/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.1835) |  Loss2: (0.0000) | Acc: (57.00%) (17775/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.1837) |  Loss2: (0.0000) | Acc: (57.00%) (18506/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.1828) |  Loss2: (0.0000) | Acc: (57.00%) (19243/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.1827) |  Loss2: (0.0000) | Acc: (57.00%) (19984/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.1830) |  Loss2: (0.0000) | Acc: (57.00%) (20704/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.1820) |  Loss2: (0.0000) | Acc: (57.00%) (21456/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.1799) |  Loss2: (0.0000) | Acc: (57.00%) (22218/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.1811) |  Loss2: (0.0000) | Acc: (57.00%) (22930/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.1823) |  Loss2: (0.0000) | Acc: (57.00%) (23631/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.1816) |  Loss2: (0.0000) | Acc: (57.00%) (24365/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.1813) |  Loss2: (0.0000) | Acc: (57.00%) (25117/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.1816) |  Loss2: (0.0000) | Acc: (57.00%) (25864/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.1813) |  Loss2: (0.0000) | Acc: (57.00%) (26606/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.1813) |  Loss2: (0.0000) | Acc: (57.00%) (27329/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.1804) |  Loss2: (0.0000) | Acc: (57.00%) (28064/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.1801) |  Loss2: (0.0000) | Acc: (57.00%) (28766/50000)
# TEST : Loss: (1.1645) | Acc: (57.00%) (5769/10000)
percent tensor([0.5046, 0.5052, 0.5076, 0.5040, 0.5069, 0.5046, 0.5055, 0.5061, 0.5036,
        0.5064, 0.5040, 0.5077, 0.5046, 0.5029, 0.5051, 0.5040],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.4958, 0.4959, 0.4969, 0.4958, 0.4976, 0.4962, 0.4959, 0.4958,
        0.4964, 0.4958, 0.4963, 0.4972, 0.4953, 0.4976, 0.4971],
       device='cuda:0') torch.Size([16])
percent tensor([0.5038, 0.5070, 0.5126, 0.5063, 0.5122, 0.5074, 0.5077, 0.5081, 0.5046,
        0.5071, 0.5053, 0.5120, 0.5041, 0.5049, 0.5045, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5112, 0.5131, 0.5136, 0.5104, 0.5148, 0.5072, 0.5160, 0.5142, 0.5130,
        0.5143, 0.5141, 0.5163, 0.5124, 0.5100, 0.5132, 0.5108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5130, 0.5129, 0.5313, 0.5282, 0.5281, 0.5098, 0.5194, 0.5336, 0.5147,
        0.5176, 0.5134, 0.5267, 0.5122, 0.5082, 0.5144, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.5008, 0.5000, 0.5063, 0.5064, 0.5064, 0.4997, 0.5032, 0.5066, 0.4996,
        0.5023, 0.4980, 0.5039, 0.4976, 0.4993, 0.4993, 0.5015],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.5173, 0.5353, 0.5374, 0.5346, 0.5253, 0.5247, 0.5568, 0.5163,
        0.5200, 0.5157, 0.5173, 0.5175, 0.5175, 0.5183, 0.5346],
       device='cuda:0') torch.Size([16])
percent tensor([0.6240, 0.5974, 0.6968, 0.7236, 0.6967, 0.6700, 0.6295, 0.7641, 0.6385,
        0.6481, 0.6100, 0.6316, 0.6278, 0.6353, 0.6308, 0.7355],
       device='cuda:0') torch.Size([16])
Epoch: 7 | Batch_idx: 0 |  Loss: (1.0837) |  Loss2: (0.0000) | Acc: (58.00%) (75/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.1734) |  Loss2: (0.0000) | Acc: (56.00%) (796/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.1480) |  Loss2: (0.0000) | Acc: (58.00%) (1560/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.1447) |  Loss2: (0.0000) | Acc: (57.00%) (2298/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.1498) |  Loss2: (0.0000) | Acc: (57.00%) (3013/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.1475) |  Loss2: (0.0000) | Acc: (58.00%) (3799/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.1486) |  Loss2: (0.0000) | Acc: (57.00%) (4528/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.1521) |  Loss2: (0.0000) | Acc: (57.00%) (5266/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.1515) |  Loss2: (0.0000) | Acc: (58.00%) (6014/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.1475) |  Loss2: (0.0000) | Acc: (58.00%) (6785/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (1.1509) |  Loss2: (0.0000) | Acc: (58.00%) (7528/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (1.1514) |  Loss2: (0.0000) | Acc: (58.00%) (8267/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (1.1501) |  Loss2: (0.0000) | Acc: (58.00%) (9018/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (1.1524) |  Loss2: (0.0000) | Acc: (58.00%) (9762/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (1.1531) |  Loss2: (0.0000) | Acc: (58.00%) (10492/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (1.1533) |  Loss2: (0.0000) | Acc: (58.00%) (11229/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (1.1542) |  Loss2: (0.0000) | Acc: (58.00%) (11967/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (1.1541) |  Loss2: (0.0000) | Acc: (58.00%) (12696/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (1.1533) |  Loss2: (0.0000) | Acc: (58.00%) (13458/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (1.1535) |  Loss2: (0.0000) | Acc: (58.00%) (14182/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (1.1525) |  Loss2: (0.0000) | Acc: (58.00%) (14946/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (1.1534) |  Loss2: (0.0000) | Acc: (58.00%) (15673/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (1.1534) |  Loss2: (0.0000) | Acc: (58.00%) (16427/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (1.1547) |  Loss2: (0.0000) | Acc: (58.00%) (17165/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (1.1555) |  Loss2: (0.0000) | Acc: (58.00%) (17895/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (1.1559) |  Loss2: (0.0000) | Acc: (58.00%) (18650/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (1.1564) |  Loss2: (0.0000) | Acc: (58.00%) (19380/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (1.1574) |  Loss2: (0.0000) | Acc: (57.00%) (20117/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (1.1575) |  Loss2: (0.0000) | Acc: (58.00%) (20870/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (1.1564) |  Loss2: (0.0000) | Acc: (58.00%) (21640/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (1.1550) |  Loss2: (0.0000) | Acc: (58.00%) (22423/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (1.1551) |  Loss2: (0.0000) | Acc: (58.00%) (23184/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (1.1561) |  Loss2: (0.0000) | Acc: (58.00%) (23924/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (1.1564) |  Loss2: (0.0000) | Acc: (58.00%) (24655/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (1.1574) |  Loss2: (0.0000) | Acc: (58.00%) (25386/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (1.1567) |  Loss2: (0.0000) | Acc: (58.00%) (26156/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (1.1569) |  Loss2: (0.0000) | Acc: (58.00%) (26893/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (1.1559) |  Loss2: (0.0000) | Acc: (58.00%) (27655/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (1.1570) |  Loss2: (0.0000) | Acc: (58.00%) (28379/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (1.1570) |  Loss2: (0.0000) | Acc: (58.00%) (29098/50000)
# TEST : Loss: (1.1519) | Acc: (58.00%) (5821/10000)
percent tensor([0.5067, 0.5079, 0.5106, 0.5061, 0.5097, 0.5068, 0.5082, 0.5090, 0.5059,
        0.5092, 0.5062, 0.5109, 0.5069, 0.5050, 0.5076, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.4981, 0.4956, 0.4958, 0.4969, 0.4956, 0.4974, 0.4961, 0.4958, 0.4956,
        0.4964, 0.4954, 0.4961, 0.4971, 0.4949, 0.4975, 0.4969],
       device='cuda:0') torch.Size([16])
percent tensor([0.5069, 0.5121, 0.5193, 0.5101, 0.5200, 0.5132, 0.5139, 0.5133, 0.5085,
        0.5122, 0.5096, 0.5195, 0.5075, 0.5085, 0.5093, 0.5075],
       device='cuda:0') torch.Size([16])
percent tensor([0.5168, 0.5195, 0.5205, 0.5162, 0.5223, 0.5116, 0.5237, 0.5217, 0.5195,
        0.5212, 0.5207, 0.5242, 0.5183, 0.5153, 0.5197, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5186, 0.5183, 0.5460, 0.5413, 0.5418, 0.5142, 0.5283, 0.5494, 0.5215,
        0.5258, 0.5188, 0.5394, 0.5169, 0.5121, 0.5205, 0.5213],
       device='cuda:0') torch.Size([16])
percent tensor([0.5004, 0.4993, 0.5060, 0.5059, 0.5061, 0.4987, 0.5031, 0.5056, 0.4984,
        0.5022, 0.4966, 0.5033, 0.4961, 0.4983, 0.4977, 0.5011],
       device='cuda:0') torch.Size([16])
percent tensor([0.5255, 0.5227, 0.5363, 0.5391, 0.5352, 0.5307, 0.5289, 0.5570, 0.5204,
        0.5272, 0.5207, 0.5200, 0.5227, 0.5241, 0.5202, 0.5410],
       device='cuda:0') torch.Size([16])
percent tensor([0.7099, 0.6645, 0.7724, 0.8070, 0.7800, 0.7678, 0.7115, 0.8543, 0.7122,
        0.7413, 0.6760, 0.7118, 0.6998, 0.7243, 0.7028, 0.8502],
       device='cuda:0') torch.Size([16])
Epoch: 8 | Batch_idx: 0 |  Loss: (1.2221) |  Loss2: (0.0000) | Acc: (56.00%) (72/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (1.1110) |  Loss2: (0.0000) | Acc: (59.00%) (844/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (1.1342) |  Loss2: (0.0000) | Acc: (59.00%) (1595/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (1.1284) |  Loss2: (0.0000) | Acc: (59.00%) (2358/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (1.1384) |  Loss2: (0.0000) | Acc: (58.00%) (3090/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (1.1351) |  Loss2: (0.0000) | Acc: (59.00%) (3863/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (1.1355) |  Loss2: (0.0000) | Acc: (59.00%) (4635/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (1.1328) |  Loss2: (0.0000) | Acc: (59.00%) (5405/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (1.1333) |  Loss2: (0.0000) | Acc: (59.00%) (6160/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (1.1368) |  Loss2: (0.0000) | Acc: (59.00%) (6896/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (1.1409) |  Loss2: (0.0000) | Acc: (58.00%) (7624/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (1.1440) |  Loss2: (0.0000) | Acc: (58.00%) (8350/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (1.1432) |  Loss2: (0.0000) | Acc: (58.00%) (9094/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (1.1425) |  Loss2: (0.0000) | Acc: (58.00%) (9840/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (1.1445) |  Loss2: (0.0000) | Acc: (58.00%) (10547/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (1.1411) |  Loss2: (0.0000) | Acc: (58.00%) (11334/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (1.1421) |  Loss2: (0.0000) | Acc: (58.00%) (12107/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (1.1403) |  Loss2: (0.0000) | Acc: (58.00%) (12868/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (1.1406) |  Loss2: (0.0000) | Acc: (58.00%) (13608/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (1.1424) |  Loss2: (0.0000) | Acc: (58.00%) (14357/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (1.1424) |  Loss2: (0.0000) | Acc: (58.00%) (15103/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (1.1431) |  Loss2: (0.0000) | Acc: (58.00%) (15853/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (1.1422) |  Loss2: (0.0000) | Acc: (58.00%) (16607/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (1.1416) |  Loss2: (0.0000) | Acc: (58.00%) (17361/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (1.1451) |  Loss2: (0.0000) | Acc: (58.00%) (18048/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (1.1455) |  Loss2: (0.0000) | Acc: (58.00%) (18791/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (1.1450) |  Loss2: (0.0000) | Acc: (58.00%) (19552/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (1.1439) |  Loss2: (0.0000) | Acc: (58.00%) (20316/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (1.1445) |  Loss2: (0.0000) | Acc: (58.00%) (21064/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (1.1442) |  Loss2: (0.0000) | Acc: (58.00%) (21823/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (1.1446) |  Loss2: (0.0000) | Acc: (58.00%) (22550/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (1.1441) |  Loss2: (0.0000) | Acc: (58.00%) (23298/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (1.1450) |  Loss2: (0.0000) | Acc: (58.00%) (24054/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (1.1440) |  Loss2: (0.0000) | Acc: (58.00%) (24827/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (1.1439) |  Loss2: (0.0000) | Acc: (58.00%) (25560/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (1.1442) |  Loss2: (0.0000) | Acc: (58.00%) (26290/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (1.1452) |  Loss2: (0.0000) | Acc: (58.00%) (27037/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (1.1447) |  Loss2: (0.0000) | Acc: (58.00%) (27810/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (1.1448) |  Loss2: (0.0000) | Acc: (58.00%) (28553/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (1.1454) |  Loss2: (0.0000) | Acc: (58.00%) (29292/50000)
# TEST : Loss: (1.1436) | Acc: (58.00%) (5844/10000)
percent tensor([0.5099, 0.5119, 0.5150, 0.5090, 0.5140, 0.5099, 0.5122, 0.5132, 0.5092,
        0.5135, 0.5096, 0.5156, 0.5103, 0.5080, 0.5113, 0.5089],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.4958, 0.4957, 0.4971, 0.4954, 0.4973, 0.4961, 0.4958, 0.4957,
        0.4965, 0.4955, 0.4961, 0.4973, 0.4950, 0.4976, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5103, 0.5177, 0.5262, 0.5145, 0.5285, 0.5193, 0.5205, 0.5202, 0.5136,
        0.5179, 0.5146, 0.5271, 0.5113, 0.5126, 0.5149, 0.5120],
       device='cuda:0') torch.Size([16])
percent tensor([0.5218, 0.5252, 0.5268, 0.5217, 0.5293, 0.5159, 0.5308, 0.5288, 0.5255,
        0.5275, 0.5266, 0.5317, 0.5235, 0.5201, 0.5256, 0.5221],
       device='cuda:0') torch.Size([16])
percent tensor([0.5241, 0.5239, 0.5629, 0.5553, 0.5578, 0.5184, 0.5383, 0.5671, 0.5290,
        0.5347, 0.5245, 0.5548, 0.5215, 0.5157, 0.5268, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.4998, 0.4986, 0.5069, 0.5063, 0.5071, 0.4975, 0.5035, 0.5060, 0.4973,
        0.5022, 0.4953, 0.5033, 0.4941, 0.4972, 0.4963, 0.5005],
       device='cuda:0') torch.Size([16])
percent tensor([0.5277, 0.5243, 0.5351, 0.5378, 0.5337, 0.5313, 0.5293, 0.5522, 0.5214,
        0.5299, 0.5227, 0.5206, 0.5237, 0.5268, 0.5192, 0.5395],
       device='cuda:0') torch.Size([16])
percent tensor([0.7528, 0.6971, 0.8170, 0.8492, 0.8272, 0.8164, 0.7509, 0.8949, 0.7458,
        0.7835, 0.7121, 0.7538, 0.7310, 0.7669, 0.7417, 0.8880],
       device='cuda:0') torch.Size([16])
Epoch: 9 | Batch_idx: 0 |  Loss: (1.0924) |  Loss2: (0.0000) | Acc: (64.00%) (83/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (1.1177) |  Loss2: (0.0000) | Acc: (59.00%) (831/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (1.1255) |  Loss2: (0.0000) | Acc: (58.00%) (1580/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (1.1320) |  Loss2: (0.0000) | Acc: (58.00%) (2331/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (1.1399) |  Loss2: (0.0000) | Acc: (58.00%) (3082/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (1.1440) |  Loss2: (0.0000) | Acc: (58.00%) (3822/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (1.1418) |  Loss2: (0.0000) | Acc: (58.00%) (4579/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (1.1370) |  Loss2: (0.0000) | Acc: (58.00%) (5338/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (1.1383) |  Loss2: (0.0000) | Acc: (58.00%) (6098/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (1.1360) |  Loss2: (0.0000) | Acc: (58.00%) (6859/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (1.1390) |  Loss2: (0.0000) | Acc: (58.00%) (7601/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (1.1411) |  Loss2: (0.0000) | Acc: (58.00%) (8333/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (1.1415) |  Loss2: (0.0000) | Acc: (58.00%) (9098/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (1.1426) |  Loss2: (0.0000) | Acc: (58.00%) (9835/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (1.1449) |  Loss2: (0.0000) | Acc: (58.00%) (10563/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (1.1425) |  Loss2: (0.0000) | Acc: (58.00%) (11337/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (1.1419) |  Loss2: (0.0000) | Acc: (58.00%) (12094/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (1.1429) |  Loss2: (0.0000) | Acc: (58.00%) (12852/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (1.1393) |  Loss2: (0.0000) | Acc: (58.00%) (13612/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (1.1353) |  Loss2: (0.0000) | Acc: (58.00%) (14371/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (1.1353) |  Loss2: (0.0000) | Acc: (58.00%) (15122/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (1.1366) |  Loss2: (0.0000) | Acc: (58.00%) (15882/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (1.1383) |  Loss2: (0.0000) | Acc: (58.00%) (16613/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (1.1390) |  Loss2: (0.0000) | Acc: (58.00%) (17358/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (1.1376) |  Loss2: (0.0000) | Acc: (58.00%) (18117/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (1.1377) |  Loss2: (0.0000) | Acc: (58.00%) (18869/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (1.1371) |  Loss2: (0.0000) | Acc: (58.00%) (19620/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (1.1378) |  Loss2: (0.0000) | Acc: (58.00%) (20356/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (1.1380) |  Loss2: (0.0000) | Acc: (58.00%) (21112/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (1.1382) |  Loss2: (0.0000) | Acc: (58.00%) (21857/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (1.1401) |  Loss2: (0.0000) | Acc: (58.00%) (22570/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (1.1386) |  Loss2: (0.0000) | Acc: (58.00%) (23345/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (1.1394) |  Loss2: (0.0000) | Acc: (58.00%) (24091/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (1.1388) |  Loss2: (0.0000) | Acc: (58.00%) (24858/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (1.1380) |  Loss2: (0.0000) | Acc: (58.00%) (25619/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (1.1377) |  Loss2: (0.0000) | Acc: (58.00%) (26382/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (1.1373) |  Loss2: (0.0000) | Acc: (58.00%) (27148/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (1.1382) |  Loss2: (0.0000) | Acc: (58.00%) (27900/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (1.1372) |  Loss2: (0.0000) | Acc: (58.00%) (28692/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (1.1372) |  Loss2: (0.0000) | Acc: (58.00%) (29398/50000)
# TEST : Loss: (1.1390) | Acc: (58.00%) (5865/10000)
percent tensor([0.5131, 0.5158, 0.5188, 0.5117, 0.5179, 0.5130, 0.5162, 0.5170, 0.5128,
        0.5173, 0.5132, 0.5197, 0.5137, 0.5113, 0.5150, 0.5118],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4965, 0.4960, 0.4975, 0.4957, 0.4975, 0.4965, 0.4961, 0.4963,
        0.4970, 0.4961, 0.4964, 0.4979, 0.4955, 0.4979, 0.4974],
       device='cuda:0') torch.Size([16])
percent tensor([0.5126, 0.5214, 0.5301, 0.5180, 0.5335, 0.5231, 0.5245, 0.5246, 0.5167,
        0.5215, 0.5178, 0.5317, 0.5137, 0.5154, 0.5189, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.5277, 0.5315, 0.5334, 0.5279, 0.5366, 0.5212, 0.5381, 0.5365, 0.5320,
        0.5340, 0.5332, 0.5394, 0.5294, 0.5257, 0.5320, 0.5283],
       device='cuda:0') torch.Size([16])
percent tensor([0.5276, 0.5274, 0.5730, 0.5644, 0.5672, 0.5217, 0.5439, 0.5780, 0.5340,
        0.5401, 0.5281, 0.5641, 0.5244, 0.5186, 0.5302, 0.5321],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.4974, 0.5058, 0.5055, 0.5064, 0.4967, 0.5028, 0.5041, 0.4959,
        0.5014, 0.4936, 0.5023, 0.4918, 0.4961, 0.4945, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5298, 0.5260, 0.5308, 0.5343, 0.5292, 0.5323, 0.5283, 0.5421, 0.5226,
        0.5323, 0.5247, 0.5206, 0.5251, 0.5301, 0.5178, 0.5368],
       device='cuda:0') torch.Size([16])
percent tensor([0.7890, 0.7301, 0.8474, 0.8759, 0.8596, 0.8532, 0.7852, 0.9206, 0.7813,
        0.8226, 0.7471, 0.7929, 0.7624, 0.8077, 0.7744, 0.9114],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 10 | Batch_idx: 0 |  Loss: (1.0893) |  Loss2: (0.0000) | Acc: (61.00%) (79/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (1.1277) |  Loss2: (0.0000) | Acc: (58.00%) (826/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (1.1153) |  Loss2: (0.0000) | Acc: (58.00%) (1579/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (1.1218) |  Loss2: (0.0000) | Acc: (59.00%) (2349/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (1.1289) |  Loss2: (0.0000) | Acc: (58.00%) (3095/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (1.1326) |  Loss2: (0.0000) | Acc: (58.00%) (3826/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (1.1326) |  Loss2: (0.0000) | Acc: (58.00%) (4582/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (1.1304) |  Loss2: (0.0000) | Acc: (59.00%) (5363/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (1.1314) |  Loss2: (0.0000) | Acc: (58.00%) (6111/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (1.1330) |  Loss2: (0.0000) | Acc: (58.00%) (6859/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (1.1291) |  Loss2: (0.0000) | Acc: (58.00%) (7612/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (1.1244) |  Loss2: (0.0000) | Acc: (59.00%) (8383/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (1.1242) |  Loss2: (0.0000) | Acc: (58.00%) (9134/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (1.1214) |  Loss2: (0.0000) | Acc: (59.00%) (9910/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (1.1199) |  Loss2: (0.0000) | Acc: (59.00%) (10689/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (1.1209) |  Loss2: (0.0000) | Acc: (59.00%) (11441/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (1.1222) |  Loss2: (0.0000) | Acc: (59.00%) (12182/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (1.1237) |  Loss2: (0.0000) | Acc: (59.00%) (12929/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (1.1249) |  Loss2: (0.0000) | Acc: (58.00%) (13669/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (1.1243) |  Loss2: (0.0000) | Acc: (59.00%) (14426/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (1.1225) |  Loss2: (0.0000) | Acc: (59.00%) (15228/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (1.1226) |  Loss2: (0.0000) | Acc: (59.00%) (16001/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (1.1209) |  Loss2: (0.0000) | Acc: (59.00%) (16798/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (1.1190) |  Loss2: (0.0000) | Acc: (59.00%) (17569/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (1.1174) |  Loss2: (0.0000) | Acc: (59.00%) (18344/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (1.1163) |  Loss2: (0.0000) | Acc: (59.00%) (19119/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (1.1153) |  Loss2: (0.0000) | Acc: (59.00%) (19899/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (1.1119) |  Loss2: (0.0000) | Acc: (59.00%) (20708/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (1.1099) |  Loss2: (0.0000) | Acc: (59.00%) (21520/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (1.1102) |  Loss2: (0.0000) | Acc: (59.00%) (22278/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (1.1090) |  Loss2: (0.0000) | Acc: (59.00%) (23073/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (1.1087) |  Loss2: (0.0000) | Acc: (59.00%) (23848/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (1.1090) |  Loss2: (0.0000) | Acc: (59.00%) (24616/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (1.1074) |  Loss2: (0.0000) | Acc: (59.00%) (25416/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (1.1061) |  Loss2: (0.0000) | Acc: (60.00%) (26208/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (1.1056) |  Loss2: (0.0000) | Acc: (60.00%) (26978/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (1.1045) |  Loss2: (0.0000) | Acc: (60.00%) (27761/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (1.1026) |  Loss2: (0.0000) | Acc: (60.00%) (28565/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (1.1006) |  Loss2: (0.0000) | Acc: (60.00%) (29364/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (1.0995) |  Loss2: (0.0000) | Acc: (60.00%) (30112/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_010.pth.tar'
# TEST : Loss: (1.1012) | Acc: (60.00%) (6077/10000)
percent tensor([0.5131, 0.5158, 0.5155, 0.5103, 0.5164, 0.5143, 0.5161, 0.5149, 0.5122,
        0.5159, 0.5130, 0.5173, 0.5139, 0.5112, 0.5152, 0.5118],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4971, 0.4959, 0.4965, 0.4956, 0.4970, 0.4968, 0.4963, 0.4960,
        0.4969, 0.4971, 0.4961, 0.4980, 0.4964, 0.4979, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5209, 0.5331, 0.5223, 0.5357, 0.5209, 0.5232, 0.5276, 0.5162,
        0.5189, 0.5161, 0.5287, 0.5128, 0.5151, 0.5189, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5294, 0.5315, 0.5352, 0.5298, 0.5360, 0.5207, 0.5368, 0.5360, 0.5322,
        0.5337, 0.5332, 0.5409, 0.5299, 0.5270, 0.5320, 0.5285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5341, 0.5280, 0.5844, 0.5717, 0.5749, 0.5253, 0.5438, 0.5783, 0.5366,
        0.5427, 0.5288, 0.5706, 0.5279, 0.5212, 0.5350, 0.5312],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.4949, 0.5079, 0.5063, 0.5081, 0.4954, 0.5017, 0.5040, 0.4965,
        0.5005, 0.4931, 0.5043, 0.4909, 0.4957, 0.4941, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.5274, 0.5269, 0.5316, 0.5324, 0.5368, 0.5307, 0.5279, 0.5376, 0.5258,
        0.5308, 0.5279, 0.5251, 0.5259, 0.5266, 0.5200, 0.5295],
       device='cuda:0') torch.Size([16])
percent tensor([0.7939, 0.7365, 0.8701, 0.8470, 0.8856, 0.8476, 0.7966, 0.9044, 0.7736,
        0.8252, 0.7761, 0.8402, 0.7610, 0.7773, 0.8145, 0.8662],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.7534, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(772.6391, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(771.4395, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.6177, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(511.3165, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2166.1475, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4325.4062, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1433.3063, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6105.1494, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12215.0693, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4068.5647, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17282.8008, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 11 | Batch_idx: 0 |  Loss: (1.1581) |  Loss2: (0.0000) | Acc: (53.00%) (68/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (1.0898) |  Loss2: (0.0000) | Acc: (58.00%) (829/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (1.0781) |  Loss2: (0.0000) | Acc: (60.00%) (1621/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (1.0552) |  Loss2: (0.0000) | Acc: (61.00%) (2448/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (1.0525) |  Loss2: (0.0000) | Acc: (61.00%) (3244/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (1.0450) |  Loss2: (0.0000) | Acc: (62.00%) (4057/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (1.0428) |  Loss2: (0.0000) | Acc: (61.00%) (4829/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (1.0398) |  Loss2: (0.0000) | Acc: (61.00%) (5629/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (1.0367) |  Loss2: (0.0000) | Acc: (61.00%) (6425/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (1.0318) |  Loss2: (0.0000) | Acc: (62.00%) (7259/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (1.0294) |  Loss2: (0.0000) | Acc: (62.00%) (8082/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (1.0266) |  Loss2: (0.0000) | Acc: (62.00%) (8917/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (1.0318) |  Loss2: (0.0000) | Acc: (62.00%) (9695/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (1.0333) |  Loss2: (0.0000) | Acc: (62.00%) (10500/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (1.0296) |  Loss2: (0.0000) | Acc: (62.00%) (11336/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (1.0267) |  Loss2: (0.0000) | Acc: (62.00%) (12163/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (1.0271) |  Loss2: (0.0000) | Acc: (62.00%) (12962/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (1.0258) |  Loss2: (0.0000) | Acc: (62.00%) (13784/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (1.0243) |  Loss2: (0.0000) | Acc: (63.00%) (14597/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (1.0237) |  Loss2: (0.0000) | Acc: (63.00%) (15419/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (1.0235) |  Loss2: (0.0000) | Acc: (63.00%) (16229/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (1.0220) |  Loss2: (0.0000) | Acc: (63.00%) (17073/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (1.0221) |  Loss2: (0.0000) | Acc: (63.00%) (17880/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (1.0198) |  Loss2: (0.0000) | Acc: (63.00%) (18737/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (1.0187) |  Loss2: (0.0000) | Acc: (63.00%) (19566/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (1.0185) |  Loss2: (0.0000) | Acc: (63.00%) (20404/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (1.0182) |  Loss2: (0.0000) | Acc: (63.00%) (21245/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (1.0177) |  Loss2: (0.0000) | Acc: (63.00%) (22057/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (1.0153) |  Loss2: (0.0000) | Acc: (63.00%) (22898/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (1.0156) |  Loss2: (0.0000) | Acc: (63.00%) (23694/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (1.0149) |  Loss2: (0.0000) | Acc: (63.00%) (24523/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (1.0139) |  Loss2: (0.0000) | Acc: (63.00%) (25332/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (1.0130) |  Loss2: (0.0000) | Acc: (63.00%) (26154/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (1.0125) |  Loss2: (0.0000) | Acc: (63.00%) (26974/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (1.0121) |  Loss2: (0.0000) | Acc: (63.00%) (27821/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (1.0113) |  Loss2: (0.0000) | Acc: (63.00%) (28641/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (1.0103) |  Loss2: (0.0000) | Acc: (63.00%) (29478/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (1.0086) |  Loss2: (0.0000) | Acc: (63.00%) (30322/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (1.0075) |  Loss2: (0.0000) | Acc: (63.00%) (31183/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (1.0073) |  Loss2: (0.0000) | Acc: (63.00%) (31978/50000)
# TEST : Loss: (1.0701) | Acc: (61.00%) (6186/10000)
percent tensor([0.5139, 0.5161, 0.5171, 0.5105, 0.5166, 0.5142, 0.5166, 0.5157, 0.5129,
        0.5166, 0.5140, 0.5181, 0.5147, 0.5117, 0.5156, 0.5126],
       device='cuda:0') torch.Size([16])
percent tensor([0.4985, 0.4967, 0.4964, 0.4967, 0.4961, 0.4977, 0.4965, 0.4964, 0.4965,
        0.4966, 0.4968, 0.4964, 0.4981, 0.4956, 0.4976, 0.4980],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5215, 0.5253, 0.5214, 0.5273, 0.5188, 0.5208, 0.5241, 0.5137,
        0.5181, 0.5166, 0.5235, 0.5131, 0.5168, 0.5185, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5293, 0.5326, 0.5342, 0.5291, 0.5353, 0.5211, 0.5371, 0.5350, 0.5316,
        0.5340, 0.5335, 0.5397, 0.5306, 0.5272, 0.5326, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5356, 0.5281, 0.5779, 0.5677, 0.5662, 0.5300, 0.5426, 0.5724, 0.5374,
        0.5409, 0.5313, 0.5740, 0.5314, 0.5222, 0.5382, 0.5360],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.4960, 0.5093, 0.5070, 0.5062, 0.4986, 0.5020, 0.5043, 0.4966,
        0.5010, 0.4937, 0.5074, 0.4886, 0.4967, 0.4965, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5272, 0.5294, 0.5291, 0.5309, 0.5349, 0.5270, 0.5304, 0.5384, 0.5245,
        0.5328, 0.5268, 0.5337, 0.5231, 0.5314, 0.5238, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.7944, 0.7571, 0.8470, 0.8451, 0.8565, 0.8157, 0.8173, 0.9090, 0.7780,
        0.8206, 0.7929, 0.8674, 0.7488, 0.8154, 0.8425, 0.8786],
       device='cuda:0') torch.Size([16])
Epoch: 12 | Batch_idx: 0 |  Loss: (0.9670) |  Loss2: (0.0000) | Acc: (64.00%) (83/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.9864) |  Loss2: (0.0000) | Acc: (64.00%) (907/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.9950) |  Loss2: (0.0000) | Acc: (64.00%) (1730/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.9613) |  Loss2: (0.0000) | Acc: (65.00%) (2615/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.9612) |  Loss2: (0.0000) | Acc: (65.00%) (3462/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.9628) |  Loss2: (0.0000) | Acc: (66.00%) (4315/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.9575) |  Loss2: (0.0000) | Acc: (66.00%) (5180/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.9558) |  Loss2: (0.0000) | Acc: (66.00%) (6041/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.9565) |  Loss2: (0.0000) | Acc: (66.00%) (6897/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.9586) |  Loss2: (0.0000) | Acc: (66.00%) (7739/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.9514) |  Loss2: (0.0000) | Acc: (66.00%) (8617/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.9510) |  Loss2: (0.0000) | Acc: (66.00%) (9472/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.9538) |  Loss2: (0.0000) | Acc: (66.00%) (10296/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.9510) |  Loss2: (0.0000) | Acc: (66.00%) (11174/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.9504) |  Loss2: (0.0000) | Acc: (66.00%) (12018/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.9514) |  Loss2: (0.0000) | Acc: (66.00%) (12855/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.9514) |  Loss2: (0.0000) | Acc: (66.00%) (13723/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.9497) |  Loss2: (0.0000) | Acc: (66.00%) (14574/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.9489) |  Loss2: (0.0000) | Acc: (66.00%) (15436/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.9473) |  Loss2: (0.0000) | Acc: (66.00%) (16306/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.9437) |  Loss2: (0.0000) | Acc: (66.00%) (17198/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.9436) |  Loss2: (0.0000) | Acc: (66.00%) (18037/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.9427) |  Loss2: (0.0000) | Acc: (66.00%) (18898/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.9429) |  Loss2: (0.0000) | Acc: (66.00%) (19731/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.9417) |  Loss2: (0.0000) | Acc: (66.00%) (20598/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.9416) |  Loss2: (0.0000) | Acc: (66.00%) (21449/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.9404) |  Loss2: (0.0000) | Acc: (66.00%) (22313/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.9420) |  Loss2: (0.0000) | Acc: (66.00%) (23138/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.9423) |  Loss2: (0.0000) | Acc: (66.00%) (23999/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.9408) |  Loss2: (0.0000) | Acc: (66.00%) (24846/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.9408) |  Loss2: (0.0000) | Acc: (66.00%) (25683/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.9412) |  Loss2: (0.0000) | Acc: (66.00%) (26526/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.9406) |  Loss2: (0.0000) | Acc: (66.00%) (27372/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.9417) |  Loss2: (0.0000) | Acc: (66.00%) (28202/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.9410) |  Loss2: (0.0000) | Acc: (66.00%) (29079/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.9396) |  Loss2: (0.0000) | Acc: (66.00%) (29939/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.9384) |  Loss2: (0.0000) | Acc: (66.00%) (30795/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.9368) |  Loss2: (0.0000) | Acc: (66.00%) (31678/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.9356) |  Loss2: (0.0000) | Acc: (66.00%) (32549/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.9349) |  Loss2: (0.0000) | Acc: (66.00%) (33368/50000)
# TEST : Loss: (1.0482) | Acc: (63.00%) (6359/10000)
percent tensor([0.5140, 0.5162, 0.5150, 0.5103, 0.5155, 0.5149, 0.5161, 0.5152, 0.5125,
        0.5162, 0.5141, 0.5164, 0.5148, 0.5116, 0.5158, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.4968, 0.4962, 0.4966, 0.4958, 0.4981, 0.4966, 0.4962, 0.4967,
        0.4967, 0.4974, 0.4963, 0.4981, 0.4964, 0.4976, 0.4982],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5223, 0.5286, 0.5222, 0.5306, 0.5201, 0.5213, 0.5262, 0.5161,
        0.5196, 0.5176, 0.5245, 0.5144, 0.5184, 0.5201, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5291, 0.5313, 0.5338, 0.5291, 0.5349, 0.5211, 0.5364, 0.5340, 0.5320,
        0.5332, 0.5327, 0.5385, 0.5296, 0.5284, 0.5309, 0.5281],
       device='cuda:0') torch.Size([16])
percent tensor([0.5353, 0.5279, 0.5780, 0.5653, 0.5693, 0.5316, 0.5402, 0.5707, 0.5387,
        0.5407, 0.5296, 0.5670, 0.5294, 0.5228, 0.5371, 0.5333],
       device='cuda:0') torch.Size([16])
percent tensor([0.5002, 0.4927, 0.5059, 0.5050, 0.5043, 0.4990, 0.4993, 0.5017, 0.4962,
        0.4994, 0.4925, 0.5047, 0.4883, 0.4939, 0.4941, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5311, 0.5283, 0.5326, 0.5305, 0.5385, 0.5310, 0.5306, 0.5387, 0.5272,
        0.5325, 0.5270, 0.5293, 0.5241, 0.5292, 0.5236, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.8348, 0.7605, 0.8652, 0.8486, 0.8751, 0.8415, 0.8117, 0.8978, 0.7862,
        0.8303, 0.7915, 0.8472, 0.7493, 0.8038, 0.8410, 0.8815],
       device='cuda:0') torch.Size([16])
Epoch: 13 | Batch_idx: 0 |  Loss: (0.9317) |  Loss2: (0.0000) | Acc: (62.00%) (80/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.9348) |  Loss2: (0.0000) | Acc: (66.00%) (937/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.9200) |  Loss2: (0.0000) | Acc: (67.00%) (1801/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.9011) |  Loss2: (0.0000) | Acc: (68.00%) (2703/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.9109) |  Loss2: (0.0000) | Acc: (67.00%) (3558/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.9060) |  Loss2: (0.0000) | Acc: (67.00%) (4439/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.9030) |  Loss2: (0.0000) | Acc: (68.00%) (5327/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.9008) |  Loss2: (0.0000) | Acc: (68.00%) (6205/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.8981) |  Loss2: (0.0000) | Acc: (68.00%) (7085/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.8948) |  Loss2: (0.0000) | Acc: (68.00%) (7964/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.8912) |  Loss2: (0.0000) | Acc: (68.00%) (8847/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.8967) |  Loss2: (0.0000) | Acc: (68.00%) (9681/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.8929) |  Loss2: (0.0000) | Acc: (68.00%) (10572/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.8945) |  Loss2: (0.0000) | Acc: (68.00%) (11408/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.8916) |  Loss2: (0.0000) | Acc: (68.00%) (12302/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.8916) |  Loss2: (0.0000) | Acc: (68.00%) (13170/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.8919) |  Loss2: (0.0000) | Acc: (68.00%) (14031/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.8934) |  Loss2: (0.0000) | Acc: (68.00%) (14888/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.8923) |  Loss2: (0.0000) | Acc: (68.00%) (15766/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.8910) |  Loss2: (0.0000) | Acc: (68.00%) (16639/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.8922) |  Loss2: (0.0000) | Acc: (67.00%) (17490/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.8898) |  Loss2: (0.0000) | Acc: (68.00%) (18397/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.8882) |  Loss2: (0.0000) | Acc: (68.00%) (19278/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.8880) |  Loss2: (0.0000) | Acc: (68.00%) (20157/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.8881) |  Loss2: (0.0000) | Acc: (68.00%) (21040/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.8869) |  Loss2: (0.0000) | Acc: (68.00%) (21927/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.8876) |  Loss2: (0.0000) | Acc: (68.00%) (22797/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.8883) |  Loss2: (0.0000) | Acc: (68.00%) (23682/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.8878) |  Loss2: (0.0000) | Acc: (68.00%) (24578/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.8858) |  Loss2: (0.0000) | Acc: (68.00%) (25468/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.8856) |  Loss2: (0.0000) | Acc: (68.00%) (26334/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.8866) |  Loss2: (0.0000) | Acc: (68.00%) (27209/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.8857) |  Loss2: (0.0000) | Acc: (68.00%) (28090/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.8835) |  Loss2: (0.0000) | Acc: (68.00%) (29008/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.8819) |  Loss2: (0.0000) | Acc: (68.00%) (29928/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.8800) |  Loss2: (0.0000) | Acc: (68.00%) (30839/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.8805) |  Loss2: (0.0000) | Acc: (68.00%) (31716/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.8793) |  Loss2: (0.0000) | Acc: (68.00%) (32611/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.8794) |  Loss2: (0.0000) | Acc: (68.00%) (33478/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.8784) |  Loss2: (0.0000) | Acc: (68.00%) (34352/50000)
# TEST : Loss: (1.0888) | Acc: (63.00%) (6353/10000)
percent tensor([0.5137, 0.5162, 0.5140, 0.5103, 0.5153, 0.5145, 0.5161, 0.5143, 0.5128,
        0.5159, 0.5139, 0.5158, 0.5148, 0.5118, 0.5156, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.4965, 0.4971, 0.4974, 0.4963, 0.4986, 0.4963, 0.4967, 0.4962,
        0.4966, 0.4966, 0.4967, 0.4978, 0.4961, 0.4975, 0.4983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5115, 0.5215, 0.5258, 0.5216, 0.5285, 0.5186, 0.5202, 0.5257, 0.5151,
        0.5197, 0.5171, 0.5212, 0.5145, 0.5183, 0.5186, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.5316, 0.5329, 0.5290, 0.5354, 0.5214, 0.5367, 0.5338, 0.5313,
        0.5331, 0.5324, 0.5382, 0.5291, 0.5291, 0.5309, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5354, 0.5300, 0.5689, 0.5656, 0.5653, 0.5338, 0.5398, 0.5717, 0.5388,
        0.5422, 0.5309, 0.5612, 0.5320, 0.5243, 0.5393, 0.5357],
       device='cuda:0') torch.Size([16])
percent tensor([0.4991, 0.4931, 0.5044, 0.5054, 0.5032, 0.4996, 0.4981, 0.5023, 0.4960,
        0.4989, 0.4931, 0.5015, 0.4892, 0.4924, 0.4950, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5294, 0.5336, 0.5305, 0.5297, 0.5427, 0.5282, 0.5316, 0.5413, 0.5272,
        0.5378, 0.5321, 0.5290, 0.5268, 0.5279, 0.5214, 0.5279],
       device='cuda:0') torch.Size([16])
percent tensor([0.7956, 0.8195, 0.8724, 0.8495, 0.9103, 0.8058, 0.8098, 0.8996, 0.8043,
        0.8608, 0.8245, 0.8406, 0.7775, 0.7952, 0.8106, 0.8586],
       device='cuda:0') torch.Size([16])
Epoch: 14 | Batch_idx: 0 |  Loss: (0.9020) |  Loss2: (0.0000) | Acc: (67.00%) (86/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.8344) |  Loss2: (0.0000) | Acc: (70.00%) (997/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.8528) |  Loss2: (0.0000) | Acc: (69.00%) (1872/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.8505) |  Loss2: (0.0000) | Acc: (69.00%) (2760/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.8535) |  Loss2: (0.0000) | Acc: (69.00%) (3647/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.8589) |  Loss2: (0.0000) | Acc: (69.00%) (4530/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.8569) |  Loss2: (0.0000) | Acc: (69.00%) (5425/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.8550) |  Loss2: (0.0000) | Acc: (69.00%) (6325/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.8464) |  Loss2: (0.0000) | Acc: (70.00%) (7266/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.8462) |  Loss2: (0.0000) | Acc: (70.00%) (8169/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.8413) |  Loss2: (0.0000) | Acc: (70.00%) (9101/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.8439) |  Loss2: (0.0000) | Acc: (70.00%) (9980/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.8441) |  Loss2: (0.0000) | Acc: (70.00%) (10891/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.8432) |  Loss2: (0.0000) | Acc: (70.00%) (11796/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.8376) |  Loss2: (0.0000) | Acc: (70.00%) (12742/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.8356) |  Loss2: (0.0000) | Acc: (70.00%) (13650/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.8351) |  Loss2: (0.0000) | Acc: (70.00%) (14552/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.8380) |  Loss2: (0.0000) | Acc: (70.00%) (15433/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.8361) |  Loss2: (0.0000) | Acc: (70.00%) (16344/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.8357) |  Loss2: (0.0000) | Acc: (70.00%) (17244/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.8359) |  Loss2: (0.0000) | Acc: (70.00%) (18142/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.8351) |  Loss2: (0.0000) | Acc: (70.00%) (19060/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.8347) |  Loss2: (0.0000) | Acc: (70.00%) (19965/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.8340) |  Loss2: (0.0000) | Acc: (70.00%) (20882/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.8344) |  Loss2: (0.0000) | Acc: (70.00%) (21775/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.8334) |  Loss2: (0.0000) | Acc: (70.00%) (22692/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.8326) |  Loss2: (0.0000) | Acc: (70.00%) (23606/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.8326) |  Loss2: (0.0000) | Acc: (70.00%) (24504/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.8325) |  Loss2: (0.0000) | Acc: (70.00%) (25428/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.8338) |  Loss2: (0.0000) | Acc: (70.00%) (26319/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.8334) |  Loss2: (0.0000) | Acc: (70.00%) (27235/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.8330) |  Loss2: (0.0000) | Acc: (70.00%) (28147/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.8322) |  Loss2: (0.0000) | Acc: (70.00%) (29052/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.8325) |  Loss2: (0.0000) | Acc: (70.00%) (29932/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.8325) |  Loss2: (0.0000) | Acc: (70.00%) (30830/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.8316) |  Loss2: (0.0000) | Acc: (70.00%) (31745/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.8311) |  Loss2: (0.0000) | Acc: (70.00%) (32652/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.8299) |  Loss2: (0.0000) | Acc: (70.00%) (33575/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.8293) |  Loss2: (0.0000) | Acc: (70.00%) (34477/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.8286) |  Loss2: (0.0000) | Acc: (70.00%) (35368/50000)
# TEST : Loss: (0.8514) | Acc: (70.00%) (7003/10000)
percent tensor([0.5135, 0.5158, 0.5136, 0.5102, 0.5149, 0.5140, 0.5160, 0.5144, 0.5123,
        0.5157, 0.5134, 0.5158, 0.5146, 0.5116, 0.5152, 0.5128],
       device='cuda:0') torch.Size([16])
percent tensor([0.4985, 0.4967, 0.4977, 0.4972, 0.4968, 0.4984, 0.4967, 0.4969, 0.4964,
        0.4967, 0.4968, 0.4972, 0.4978, 0.4962, 0.4975, 0.4983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5128, 0.5218, 0.5226, 0.5198, 0.5270, 0.5198, 0.5205, 0.5241, 0.5146,
        0.5199, 0.5179, 0.5177, 0.5158, 0.5161, 0.5200, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.5271, 0.5309, 0.5282, 0.5269, 0.5308, 0.5195, 0.5342, 0.5325, 0.5301,
        0.5311, 0.5309, 0.5334, 0.5278, 0.5295, 0.5301, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.5276, 0.5558, 0.5569, 0.5496, 0.5281, 0.5330, 0.5640, 0.5338,
        0.5375, 0.5280, 0.5497, 0.5314, 0.5235, 0.5343, 0.5320],
       device='cuda:0') torch.Size([16])
percent tensor([0.4998, 0.4926, 0.5011, 0.5041, 0.5007, 0.4991, 0.4975, 0.5011, 0.4958,
        0.4971, 0.4936, 0.4974, 0.4890, 0.4944, 0.4952, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.5370, 0.5326, 0.5260, 0.5249, 0.5305, 0.5326, 0.5301, 0.5359, 0.5230,
        0.5306, 0.5305, 0.5227, 0.5245, 0.5310, 0.5217, 0.5322],
       device='cuda:0') torch.Size([16])
percent tensor([0.8713, 0.7897, 0.8407, 0.7911, 0.8397, 0.8447, 0.8311, 0.8701, 0.7536,
        0.7947, 0.8010, 0.8071, 0.7681, 0.8069, 0.7907, 0.8767],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 15 | Batch_idx: 0 |  Loss: (0.7346) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.8679) |  Loss2: (0.0000) | Acc: (69.00%) (984/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.8736) |  Loss2: (0.0000) | Acc: (69.00%) (1872/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.8877) |  Loss2: (0.0000) | Acc: (68.00%) (2719/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.9106) |  Loss2: (0.0000) | Acc: (67.00%) (3543/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.9102) |  Loss2: (0.0000) | Acc: (67.00%) (4398/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.9220) |  Loss2: (0.0000) | Acc: (66.00%) (5217/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.9220) |  Loss2: (0.0000) | Acc: (66.00%) (6070/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.9230) |  Loss2: (0.0000) | Acc: (66.00%) (6920/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.9210) |  Loss2: (0.0000) | Acc: (66.00%) (7788/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.9228) |  Loss2: (0.0000) | Acc: (66.00%) (8643/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.9220) |  Loss2: (0.0000) | Acc: (66.00%) (9506/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.9217) |  Loss2: (0.0000) | Acc: (66.00%) (10365/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.9166) |  Loss2: (0.0000) | Acc: (67.00%) (11247/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.9164) |  Loss2: (0.0000) | Acc: (67.00%) (12096/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.9137) |  Loss2: (0.0000) | Acc: (67.00%) (12976/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.9114) |  Loss2: (0.0000) | Acc: (67.00%) (13853/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.9099) |  Loss2: (0.0000) | Acc: (67.00%) (14733/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.9114) |  Loss2: (0.0000) | Acc: (67.00%) (15578/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.9100) |  Loss2: (0.0000) | Acc: (67.00%) (16465/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.9091) |  Loss2: (0.0000) | Acc: (67.00%) (17348/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.9075) |  Loss2: (0.0000) | Acc: (67.00%) (18212/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.9067) |  Loss2: (0.0000) | Acc: (67.00%) (19073/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.9043) |  Loss2: (0.0000) | Acc: (67.00%) (19956/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.9016) |  Loss2: (0.0000) | Acc: (67.00%) (20842/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.9017) |  Loss2: (0.0000) | Acc: (67.00%) (21704/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.8992) |  Loss2: (0.0000) | Acc: (67.00%) (22614/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.8974) |  Loss2: (0.0000) | Acc: (67.00%) (23504/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.8954) |  Loss2: (0.0000) | Acc: (67.00%) (24398/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.8952) |  Loss2: (0.0000) | Acc: (67.00%) (25304/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.8958) |  Loss2: (0.0000) | Acc: (67.00%) (26169/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.8937) |  Loss2: (0.0000) | Acc: (67.00%) (27068/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.8902) |  Loss2: (0.0000) | Acc: (68.00%) (28010/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.8879) |  Loss2: (0.0000) | Acc: (68.00%) (28921/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.8867) |  Loss2: (0.0000) | Acc: (68.00%) (29817/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.8867) |  Loss2: (0.0000) | Acc: (68.00%) (30676/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.8857) |  Loss2: (0.0000) | Acc: (68.00%) (31557/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.8852) |  Loss2: (0.0000) | Acc: (68.00%) (32433/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.8848) |  Loss2: (0.0000) | Acc: (68.00%) (33298/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.8835) |  Loss2: (0.0000) | Acc: (68.00%) (34179/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_015.pth.tar'
# TEST : Loss: (0.8677) | Acc: (69.00%) (6928/10000)
percent tensor([0.5198, 0.5237, 0.5219, 0.5155, 0.5239, 0.5209, 0.5247, 0.5218, 0.5178,
        0.5243, 0.5196, 0.5254, 0.5213, 0.5167, 0.5228, 0.5193],
       device='cuda:0') torch.Size([16])
percent tensor([0.4974, 0.4951, 0.4961, 0.4952, 0.4951, 0.4971, 0.4953, 0.4942, 0.4940,
        0.4948, 0.4954, 0.4961, 0.4965, 0.4937, 0.4967, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.5159, 0.5231, 0.5207, 0.5262, 0.5141, 0.5156, 0.5261, 0.5106,
        0.5152, 0.5113, 0.5173, 0.5093, 0.5109, 0.5134, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.5394, 0.5450, 0.5374, 0.5359, 0.5389, 0.5295, 0.5476, 0.5440, 0.5407,
        0.5443, 0.5458, 0.5470, 0.5407, 0.5417, 0.5453, 0.5385],
       device='cuda:0') torch.Size([16])
percent tensor([0.5607, 0.5464, 0.5905, 0.5900, 0.5711, 0.5526, 0.5556, 0.5963, 0.5592,
        0.5588, 0.5498, 0.5809, 0.5577, 0.5392, 0.5615, 0.5579],
       device='cuda:0') torch.Size([16])
percent tensor([0.5010, 0.4901, 0.4984, 0.5018, 0.4967, 0.5040, 0.4962, 0.4979, 0.4971,
        0.4937, 0.4940, 0.4962, 0.4891, 0.4942, 0.4961, 0.5004],
       device='cuda:0') torch.Size([16])
percent tensor([0.5396, 0.5227, 0.5159, 0.5174, 0.5129, 0.5519, 0.5224, 0.5152, 0.5206,
        0.5247, 0.5311, 0.5228, 0.5256, 0.5341, 0.5194, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.9314, 0.8863, 0.9269, 0.8887, 0.9190, 0.9241, 0.9092, 0.9431, 0.8649,
        0.8891, 0.8999, 0.9218, 0.8779, 0.8726, 0.8780, 0.9391],
       device='cuda:0') torch.Size([16])
Epoch: 16 | Batch_idx: 0 |  Loss: (0.8617) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.8907) |  Loss2: (0.0000) | Acc: (67.00%) (950/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.8488) |  Loss2: (0.0000) | Acc: (69.00%) (1855/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.8461) |  Loss2: (0.0000) | Acc: (69.00%) (2752/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.8435) |  Loss2: (0.0000) | Acc: (69.00%) (3658/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.8461) |  Loss2: (0.0000) | Acc: (69.00%) (4555/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.8447) |  Loss2: (0.0000) | Acc: (69.00%) (5452/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.8447) |  Loss2: (0.0000) | Acc: (69.00%) (6344/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.8426) |  Loss2: (0.0000) | Acc: (69.00%) (7240/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.8475) |  Loss2: (0.0000) | Acc: (69.00%) (8115/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.8428) |  Loss2: (0.0000) | Acc: (69.00%) (9041/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.8434) |  Loss2: (0.0000) | Acc: (70.00%) (9948/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.8410) |  Loss2: (0.0000) | Acc: (70.00%) (10867/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.8391) |  Loss2: (0.0000) | Acc: (70.00%) (11779/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.8389) |  Loss2: (0.0000) | Acc: (70.00%) (12700/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.8383) |  Loss2: (0.0000) | Acc: (70.00%) (13595/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.8372) |  Loss2: (0.0000) | Acc: (70.00%) (14507/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.8373) |  Loss2: (0.0000) | Acc: (70.00%) (15401/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.8361) |  Loss2: (0.0000) | Acc: (70.00%) (16329/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.8366) |  Loss2: (0.0000) | Acc: (70.00%) (17198/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.8378) |  Loss2: (0.0000) | Acc: (70.00%) (18087/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.8374) |  Loss2: (0.0000) | Acc: (70.00%) (18969/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.8395) |  Loss2: (0.0000) | Acc: (70.00%) (19837/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.8393) |  Loss2: (0.0000) | Acc: (70.00%) (20733/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.8392) |  Loss2: (0.0000) | Acc: (70.00%) (21625/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.8390) |  Loss2: (0.0000) | Acc: (70.00%) (22517/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.8376) |  Loss2: (0.0000) | Acc: (70.00%) (23432/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.8352) |  Loss2: (0.0000) | Acc: (70.00%) (24357/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.8360) |  Loss2: (0.0000) | Acc: (70.00%) (25245/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.8350) |  Loss2: (0.0000) | Acc: (70.00%) (26167/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.8364) |  Loss2: (0.0000) | Acc: (70.00%) (27041/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.8349) |  Loss2: (0.0000) | Acc: (70.00%) (27960/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.8342) |  Loss2: (0.0000) | Acc: (70.00%) (28869/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.8338) |  Loss2: (0.0000) | Acc: (70.00%) (29779/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.8328) |  Loss2: (0.0000) | Acc: (70.00%) (30707/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.8323) |  Loss2: (0.0000) | Acc: (70.00%) (31608/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.8324) |  Loss2: (0.0000) | Acc: (70.00%) (32517/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.8310) |  Loss2: (0.0000) | Acc: (70.00%) (33439/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.8306) |  Loss2: (0.0000) | Acc: (70.00%) (34340/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.8321) |  Loss2: (0.0000) | Acc: (70.00%) (35181/50000)
# TEST : Loss: (0.8384) | Acc: (70.00%) (7019/10000)
percent tensor([0.5195, 0.5242, 0.5217, 0.5150, 0.5237, 0.5208, 0.5251, 0.5217, 0.5175,
        0.5245, 0.5197, 0.5254, 0.5210, 0.5172, 0.5230, 0.5193],
       device='cuda:0') torch.Size([16])
percent tensor([0.4978, 0.4955, 0.4961, 0.4949, 0.4952, 0.4973, 0.4956, 0.4941, 0.4939,
        0.4950, 0.4957, 0.4964, 0.4968, 0.4936, 0.4971, 0.4969],
       device='cuda:0') torch.Size([16])
percent tensor([0.5077, 0.5177, 0.5263, 0.5226, 0.5292, 0.5144, 0.5174, 0.5292, 0.5116,
        0.5178, 0.5123, 0.5204, 0.5099, 0.5116, 0.5142, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5404, 0.5462, 0.5375, 0.5346, 0.5381, 0.5290, 0.5487, 0.5424, 0.5415,
        0.5454, 0.5476, 0.5484, 0.5425, 0.5429, 0.5461, 0.5383],
       device='cuda:0') torch.Size([16])
percent tensor([0.5747, 0.5528, 0.6119, 0.6072, 0.5859, 0.5665, 0.5669, 0.6137, 0.5729,
        0.5666, 0.5596, 0.5993, 0.5685, 0.5456, 0.5748, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.4892, 0.4985, 0.5026, 0.4971, 0.5077, 0.4972, 0.4987, 0.4981,
        0.4923, 0.4941, 0.4979, 0.4880, 0.4951, 0.4980, 0.5020],
       device='cuda:0') torch.Size([16])
percent tensor([0.5429, 0.5153, 0.5076, 0.5120, 0.5012, 0.5680, 0.5166, 0.4964, 0.5203,
        0.5209, 0.5328, 0.5232, 0.5274, 0.5394, 0.5163, 0.5265],
       device='cuda:0') torch.Size([16])
percent tensor([0.9559, 0.9228, 0.9551, 0.9252, 0.9462, 0.9554, 0.9429, 0.9681, 0.9088,
        0.9247, 0.9339, 0.9541, 0.9175, 0.9136, 0.9163, 0.9647],
       device='cuda:0') torch.Size([16])
Epoch: 17 | Batch_idx: 0 |  Loss: (0.8363) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.7915) |  Loss2: (0.0000) | Acc: (72.00%) (1015/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.8006) |  Loss2: (0.0000) | Acc: (71.00%) (1932/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.8053) |  Loss2: (0.0000) | Acc: (71.00%) (2832/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.7984) |  Loss2: (0.0000) | Acc: (71.00%) (3773/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.7984) |  Loss2: (0.0000) | Acc: (71.00%) (4700/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.7930) |  Loss2: (0.0000) | Acc: (72.00%) (5654/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.7920) |  Loss2: (0.0000) | Acc: (72.00%) (6581/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.7898) |  Loss2: (0.0000) | Acc: (72.00%) (7486/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.7869) |  Loss2: (0.0000) | Acc: (72.00%) (8419/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.7882) |  Loss2: (0.0000) | Acc: (72.00%) (9338/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.7882) |  Loss2: (0.0000) | Acc: (72.00%) (10259/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.7909) |  Loss2: (0.0000) | Acc: (72.00%) (11155/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.7887) |  Loss2: (0.0000) | Acc: (72.00%) (12089/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.7931) |  Loss2: (0.0000) | Acc: (71.00%) (12983/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.7947) |  Loss2: (0.0000) | Acc: (71.00%) (13888/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.7963) |  Loss2: (0.0000) | Acc: (71.00%) (14780/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.7992) |  Loss2: (0.0000) | Acc: (71.00%) (15669/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.8014) |  Loss2: (0.0000) | Acc: (71.00%) (16574/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.8013) |  Loss2: (0.0000) | Acc: (71.00%) (17496/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.8024) |  Loss2: (0.0000) | Acc: (71.00%) (18397/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.8008) |  Loss2: (0.0000) | Acc: (71.00%) (19318/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.8026) |  Loss2: (0.0000) | Acc: (71.00%) (20222/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.8021) |  Loss2: (0.0000) | Acc: (71.00%) (21153/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.8048) |  Loss2: (0.0000) | Acc: (71.00%) (22046/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.8067) |  Loss2: (0.0000) | Acc: (71.00%) (22942/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.8070) |  Loss2: (0.0000) | Acc: (71.00%) (23834/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.8074) |  Loss2: (0.0000) | Acc: (71.00%) (24746/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.8072) |  Loss2: (0.0000) | Acc: (71.00%) (25636/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.8070) |  Loss2: (0.0000) | Acc: (71.00%) (26534/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.8062) |  Loss2: (0.0000) | Acc: (71.00%) (27439/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.8071) |  Loss2: (0.0000) | Acc: (71.00%) (28358/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.8075) |  Loss2: (0.0000) | Acc: (71.00%) (29288/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.8073) |  Loss2: (0.0000) | Acc: (71.00%) (30216/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.8073) |  Loss2: (0.0000) | Acc: (71.00%) (31128/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.8090) |  Loss2: (0.0000) | Acc: (71.00%) (32014/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.8087) |  Loss2: (0.0000) | Acc: (71.00%) (32935/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.8089) |  Loss2: (0.0000) | Acc: (71.00%) (33873/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.8104) |  Loss2: (0.0000) | Acc: (71.00%) (34753/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.8097) |  Loss2: (0.0000) | Acc: (71.00%) (35626/50000)
# TEST : Loss: (0.8260) | Acc: (70.00%) (7085/10000)
percent tensor([0.5181, 0.5232, 0.5200, 0.5136, 0.5219, 0.5194, 0.5239, 0.5203, 0.5163,
        0.5233, 0.5185, 0.5239, 0.5197, 0.5165, 0.5218, 0.5181],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.4964, 0.4969, 0.4955, 0.4960, 0.4981, 0.4966, 0.4949, 0.4945,
        0.4959, 0.4965, 0.4972, 0.4975, 0.4942, 0.4979, 0.4977],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5190, 0.5243, 0.5203, 0.5281, 0.5127, 0.5175, 0.5277, 0.5110,
        0.5184, 0.5127, 0.5198, 0.5091, 0.5122, 0.5136, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.5389, 0.5450, 0.5355, 0.5320, 0.5353, 0.5270, 0.5472, 0.5387, 0.5404,
        0.5442, 0.5467, 0.5473, 0.5419, 0.5419, 0.5447, 0.5362],
       device='cuda:0') torch.Size([16])
percent tensor([0.5763, 0.5499, 0.6189, 0.6122, 0.5900, 0.5686, 0.5685, 0.6188, 0.5770,
        0.5649, 0.5595, 0.6054, 0.5684, 0.5452, 0.5756, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.5032, 0.4897, 0.5007, 0.5053, 0.4997, 0.5112, 0.4993, 0.5022, 0.5003,
        0.4924, 0.4952, 0.5008, 0.4880, 0.4968, 0.5008, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5454, 0.5113, 0.5004, 0.5075, 0.4925, 0.5769, 0.5129, 0.4807, 0.5217,
        0.5197, 0.5351, 0.5248, 0.5293, 0.5443, 0.5133, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.9696, 0.9422, 0.9680, 0.9427, 0.9614, 0.9691, 0.9586, 0.9794, 0.9315,
        0.9442, 0.9501, 0.9671, 0.9375, 0.9351, 0.9377, 0.9761],
       device='cuda:0') torch.Size([16])
Epoch: 18 | Batch_idx: 0 |  Loss: (1.0927) |  Loss2: (0.0000) | Acc: (63.00%) (81/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.8348) |  Loss2: (0.0000) | Acc: (70.00%) (989/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.8241) |  Loss2: (0.0000) | Acc: (70.00%) (1900/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.8152) |  Loss2: (0.0000) | Acc: (70.00%) (2817/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.8113) |  Loss2: (0.0000) | Acc: (71.00%) (3734/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.8030) |  Loss2: (0.0000) | Acc: (71.00%) (4671/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.8027) |  Loss2: (0.0000) | Acc: (71.00%) (5566/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.8073) |  Loss2: (0.0000) | Acc: (71.00%) (6459/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.8128) |  Loss2: (0.0000) | Acc: (70.00%) (7347/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.8043) |  Loss2: (0.0000) | Acc: (71.00%) (8285/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.8031) |  Loss2: (0.0000) | Acc: (71.00%) (9199/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.7989) |  Loss2: (0.0000) | Acc: (71.00%) (10144/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.8001) |  Loss2: (0.0000) | Acc: (71.00%) (11063/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.8013) |  Loss2: (0.0000) | Acc: (71.00%) (11974/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.7992) |  Loss2: (0.0000) | Acc: (71.00%) (12894/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.8005) |  Loss2: (0.0000) | Acc: (71.00%) (13810/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.8037) |  Loss2: (0.0000) | Acc: (71.00%) (14693/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.8029) |  Loss2: (0.0000) | Acc: (71.00%) (15619/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.8053) |  Loss2: (0.0000) | Acc: (71.00%) (16510/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.8045) |  Loss2: (0.0000) | Acc: (71.00%) (17416/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.8035) |  Loss2: (0.0000) | Acc: (71.00%) (18343/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.8014) |  Loss2: (0.0000) | Acc: (71.00%) (19278/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.7995) |  Loss2: (0.0000) | Acc: (71.00%) (20205/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.8005) |  Loss2: (0.0000) | Acc: (71.00%) (21114/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.8008) |  Loss2: (0.0000) | Acc: (71.00%) (22015/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.8006) |  Loss2: (0.0000) | Acc: (71.00%) (22941/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.8007) |  Loss2: (0.0000) | Acc: (71.00%) (23866/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.7999) |  Loss2: (0.0000) | Acc: (71.00%) (24800/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.7986) |  Loss2: (0.0000) | Acc: (71.00%) (25736/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.7998) |  Loss2: (0.0000) | Acc: (71.00%) (26628/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.7996) |  Loss2: (0.0000) | Acc: (71.00%) (27546/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.7995) |  Loss2: (0.0000) | Acc: (71.00%) (28458/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.7994) |  Loss2: (0.0000) | Acc: (71.00%) (29364/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.7995) |  Loss2: (0.0000) | Acc: (71.00%) (30270/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.7987) |  Loss2: (0.0000) | Acc: (71.00%) (31198/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.7990) |  Loss2: (0.0000) | Acc: (71.00%) (32101/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.7992) |  Loss2: (0.0000) | Acc: (71.00%) (33019/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.7998) |  Loss2: (0.0000) | Acc: (71.00%) (33930/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.7998) |  Loss2: (0.0000) | Acc: (71.00%) (34859/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.7995) |  Loss2: (0.0000) | Acc: (71.00%) (35743/50000)
# TEST : Loss: (0.8180) | Acc: (71.00%) (7133/10000)
percent tensor([0.5177, 0.5231, 0.5191, 0.5128, 0.5211, 0.5190, 0.5235, 0.5196, 0.5160,
        0.5228, 0.5183, 0.5231, 0.5193, 0.5166, 0.5214, 0.5177],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.4970, 0.4973, 0.4958, 0.4964, 0.4985, 0.4973, 0.4955, 0.4950,
        0.4965, 0.4971, 0.4979, 0.4981, 0.4947, 0.4985, 0.4982],
       device='cuda:0') torch.Size([16])
percent tensor([0.5055, 0.5209, 0.5251, 0.5197, 0.5292, 0.5116, 0.5189, 0.5285, 0.5114,
        0.5202, 0.5135, 0.5218, 0.5092, 0.5131, 0.5135, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.5408, 0.5473, 0.5362, 0.5320, 0.5356, 0.5277, 0.5493, 0.5386, 0.5427,
        0.5465, 0.5497, 0.5495, 0.5445, 0.5444, 0.5465, 0.5372],
       device='cuda:0') torch.Size([16])
percent tensor([0.5815, 0.5519, 0.6264, 0.6176, 0.5946, 0.5723, 0.5737, 0.6240, 0.5831,
        0.5685, 0.5646, 0.6138, 0.5726, 0.5487, 0.5807, 0.5732],
       device='cuda:0') torch.Size([16])
percent tensor([0.5053, 0.4914, 0.5030, 0.5076, 0.5021, 0.5143, 0.5022, 0.5055, 0.5033,
        0.4936, 0.4975, 0.5043, 0.4893, 0.4994, 0.5044, 0.5068],
       device='cuda:0') torch.Size([16])
percent tensor([0.5447, 0.5068, 0.4916, 0.5004, 0.4826, 0.5828, 0.5083, 0.4631, 0.5227,
        0.5174, 0.5363, 0.5239, 0.5305, 0.5475, 0.5091, 0.5176],
       device='cuda:0') torch.Size([16])
percent tensor([0.9754, 0.9540, 0.9775, 0.9556, 0.9714, 0.9765, 0.9670, 0.9861, 0.9466,
        0.9563, 0.9617, 0.9763, 0.9507, 0.9463, 0.9504, 0.9809],
       device='cuda:0') torch.Size([16])
Epoch: 19 | Batch_idx: 0 |  Loss: (0.8999) |  Loss2: (0.0000) | Acc: (67.00%) (86/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.7875) |  Loss2: (0.0000) | Acc: (72.00%) (1018/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.7884) |  Loss2: (0.0000) | Acc: (72.00%) (1941/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.7874) |  Loss2: (0.0000) | Acc: (72.00%) (2875/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.7950) |  Loss2: (0.0000) | Acc: (72.00%) (3788/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.7867) |  Loss2: (0.0000) | Acc: (72.00%) (4726/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.7880) |  Loss2: (0.0000) | Acc: (72.00%) (5655/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.7904) |  Loss2: (0.0000) | Acc: (72.00%) (6576/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.7839) |  Loss2: (0.0000) | Acc: (72.00%) (7526/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.7863) |  Loss2: (0.0000) | Acc: (72.00%) (8455/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.7820) |  Loss2: (0.0000) | Acc: (72.00%) (9399/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.7778) |  Loss2: (0.0000) | Acc: (72.00%) (10360/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.7804) |  Loss2: (0.0000) | Acc: (72.00%) (11262/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.7795) |  Loss2: (0.0000) | Acc: (72.00%) (12195/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.7832) |  Loss2: (0.0000) | Acc: (72.00%) (13088/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.7843) |  Loss2: (0.0000) | Acc: (72.00%) (14009/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.7844) |  Loss2: (0.0000) | Acc: (72.00%) (14927/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.7849) |  Loss2: (0.0000) | Acc: (72.00%) (15831/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.7865) |  Loss2: (0.0000) | Acc: (72.00%) (16741/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.7866) |  Loss2: (0.0000) | Acc: (72.00%) (17667/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.7859) |  Loss2: (0.0000) | Acc: (72.00%) (18591/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.7854) |  Loss2: (0.0000) | Acc: (72.00%) (19511/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.7840) |  Loss2: (0.0000) | Acc: (72.00%) (20462/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.7841) |  Loss2: (0.0000) | Acc: (72.00%) (21390/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.7865) |  Loss2: (0.0000) | Acc: (72.00%) (22268/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.7860) |  Loss2: (0.0000) | Acc: (72.00%) (23199/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.7851) |  Loss2: (0.0000) | Acc: (72.00%) (24136/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.7868) |  Loss2: (0.0000) | Acc: (72.00%) (25041/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.7853) |  Loss2: (0.0000) | Acc: (72.00%) (25971/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.7842) |  Loss2: (0.0000) | Acc: (72.00%) (26913/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.7842) |  Loss2: (0.0000) | Acc: (72.00%) (27830/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.7841) |  Loss2: (0.0000) | Acc: (72.00%) (28749/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.7850) |  Loss2: (0.0000) | Acc: (72.00%) (29666/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.7863) |  Loss2: (0.0000) | Acc: (72.00%) (30550/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.7864) |  Loss2: (0.0000) | Acc: (72.00%) (31456/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.7872) |  Loss2: (0.0000) | Acc: (72.00%) (32359/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.7874) |  Loss2: (0.0000) | Acc: (71.00%) (33265/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.7882) |  Loss2: (0.0000) | Acc: (71.00%) (34164/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.7888) |  Loss2: (0.0000) | Acc: (71.00%) (35066/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.7882) |  Loss2: (0.0000) | Acc: (71.00%) (35981/50000)
# TEST : Loss: (0.8138) | Acc: (71.00%) (7136/10000)
percent tensor([0.5171, 0.5229, 0.5183, 0.5123, 0.5203, 0.5183, 0.5231, 0.5190, 0.5154,
        0.5224, 0.5179, 0.5224, 0.5188, 0.5166, 0.5210, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.4993, 0.4977, 0.4980, 0.4964, 0.4971, 0.4991, 0.4980, 0.4963, 0.4955,
        0.4971, 0.4977, 0.4986, 0.4987, 0.4952, 0.4991, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.5210, 0.5227, 0.5169, 0.5272, 0.5092, 0.5181, 0.5260, 0.5101,
        0.5201, 0.5129, 0.5205, 0.5081, 0.5130, 0.5120, 0.5079],
       device='cuda:0') torch.Size([16])
percent tensor([0.5440, 0.5511, 0.5387, 0.5340, 0.5377, 0.5301, 0.5531, 0.5406, 0.5461,
        0.5503, 0.5538, 0.5537, 0.5483, 0.5483, 0.5505, 0.5400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5806, 0.5483, 0.6273, 0.6180, 0.5946, 0.5718, 0.5727, 0.6234, 0.5848,
        0.5661, 0.5638, 0.6158, 0.5709, 0.5477, 0.5786, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.5070, 0.4927, 0.5064, 0.5112, 0.5057, 0.5174, 0.5050, 0.5103, 0.5064,
        0.4949, 0.4993, 0.5081, 0.4902, 0.5014, 0.5080, 0.5093],
       device='cuda:0') torch.Size([16])
percent tensor([0.5494, 0.5086, 0.4899, 0.4994, 0.4794, 0.5915, 0.5098, 0.4570, 0.5284,
        0.5203, 0.5425, 0.5298, 0.5363, 0.5556, 0.5113, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.9811, 0.9640, 0.9833, 0.9645, 0.9781, 0.9816, 0.9747, 0.9903, 0.9582,
        0.9659, 0.9703, 0.9825, 0.9610, 0.9566, 0.9629, 0.9855],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 20 | Batch_idx: 0 |  Loss: (0.6837) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.8253) |  Loss2: (0.0000) | Acc: (71.00%) (1000/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.8044) |  Loss2: (0.0000) | Acc: (71.00%) (1910/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.8240) |  Loss2: (0.0000) | Acc: (70.00%) (2805/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.8151) |  Loss2: (0.0000) | Acc: (70.00%) (3718/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.8082) |  Loss2: (0.0000) | Acc: (71.00%) (4651/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.8000) |  Loss2: (0.0000) | Acc: (71.00%) (5585/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.8038) |  Loss2: (0.0000) | Acc: (71.00%) (6496/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.8001) |  Loss2: (0.0000) | Acc: (71.00%) (7428/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.7982) |  Loss2: (0.0000) | Acc: (71.00%) (8342/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.7976) |  Loss2: (0.0000) | Acc: (71.00%) (9261/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.7957) |  Loss2: (0.0000) | Acc: (71.00%) (10176/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.7956) |  Loss2: (0.0000) | Acc: (71.00%) (11103/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.7963) |  Loss2: (0.0000) | Acc: (71.00%) (12019/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.7935) |  Loss2: (0.0000) | Acc: (71.00%) (12948/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.7934) |  Loss2: (0.0000) | Acc: (71.00%) (13872/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.7980) |  Loss2: (0.0000) | Acc: (71.00%) (14770/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.7948) |  Loss2: (0.0000) | Acc: (71.00%) (15722/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.7940) |  Loss2: (0.0000) | Acc: (71.00%) (16635/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.7939) |  Loss2: (0.0000) | Acc: (71.00%) (17555/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.7917) |  Loss2: (0.0000) | Acc: (71.00%) (18504/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.7920) |  Loss2: (0.0000) | Acc: (71.00%) (19418/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.7917) |  Loss2: (0.0000) | Acc: (71.00%) (20333/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.7924) |  Loss2: (0.0000) | Acc: (71.00%) (21242/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.7931) |  Loss2: (0.0000) | Acc: (71.00%) (22163/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.7940) |  Loss2: (0.0000) | Acc: (71.00%) (23056/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.7944) |  Loss2: (0.0000) | Acc: (71.00%) (23985/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.7920) |  Loss2: (0.0000) | Acc: (71.00%) (24924/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.7920) |  Loss2: (0.0000) | Acc: (71.00%) (25847/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.7906) |  Loss2: (0.0000) | Acc: (71.00%) (26800/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.7882) |  Loss2: (0.0000) | Acc: (72.00%) (27757/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.7869) |  Loss2: (0.0000) | Acc: (72.00%) (28696/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.7874) |  Loss2: (0.0000) | Acc: (72.00%) (29615/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.7882) |  Loss2: (0.0000) | Acc: (72.00%) (30530/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.7873) |  Loss2: (0.0000) | Acc: (72.00%) (31455/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.7875) |  Loss2: (0.0000) | Acc: (72.00%) (32378/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.7858) |  Loss2: (0.0000) | Acc: (72.00%) (33324/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.7869) |  Loss2: (0.0000) | Acc: (72.00%) (34236/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.7864) |  Loss2: (0.0000) | Acc: (72.00%) (35173/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.7861) |  Loss2: (0.0000) | Acc: (72.00%) (36058/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_020.pth.tar'
# TEST : Loss: (0.8129) | Acc: (71.00%) (7174/10000)
percent tensor([0.5168, 0.5220, 0.5185, 0.5120, 0.5194, 0.5175, 0.5220, 0.5190, 0.5160,
        0.5211, 0.5183, 0.5212, 0.5188, 0.5159, 0.5202, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.4991, 0.4972, 0.4974, 0.4963, 0.4961, 0.4988, 0.4973, 0.4964, 0.4948,
        0.4967, 0.4970, 0.4980, 0.4981, 0.4947, 0.4990, 0.4983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5047, 0.5208, 0.5284, 0.5171, 0.5323, 0.5106, 0.5206, 0.5249, 0.5146,
        0.5193, 0.5139, 0.5252, 0.5095, 0.5130, 0.5136, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5438, 0.5473, 0.5439, 0.5383, 0.5429, 0.5314, 0.5527, 0.5407, 0.5451,
        0.5494, 0.5505, 0.5550, 0.5458, 0.5446, 0.5460, 0.5391],
       device='cuda:0') torch.Size([16])
percent tensor([0.5797, 0.5454, 0.6395, 0.6298, 0.6147, 0.5665, 0.5792, 0.6287, 0.5940,
        0.5653, 0.5652, 0.6285, 0.5707, 0.5535, 0.5708, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.4925, 0.5142, 0.5155, 0.5117, 0.5179, 0.5070, 0.5143, 0.5039,
        0.4956, 0.4991, 0.5132, 0.4900, 0.5002, 0.5091, 0.5103],
       device='cuda:0') torch.Size([16])
percent tensor([0.5366, 0.5088, 0.4949, 0.5048, 0.4787, 0.5774, 0.5023, 0.4588, 0.5217,
        0.5133, 0.5330, 0.5122, 0.5352, 0.5552, 0.5013, 0.5116],
       device='cuda:0') torch.Size([16])
percent tensor([0.9806, 0.9591, 0.9808, 0.9772, 0.9775, 0.9796, 0.9736, 0.9930, 0.9597,
        0.9632, 0.9660, 0.9758, 0.9578, 0.9548, 0.9735, 0.9841],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(171.5052, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(782.8129, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(778.5638, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.4556, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(509.6865, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2170.7129, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4314.4414, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1428.0433, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6088.0376, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12165.6104, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4052.5000, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17203.3984, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 21 | Batch_idx: 0 |  Loss: (0.7416) |  Loss2: (0.0000) | Acc: (71.00%) (92/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.7663) |  Loss2: (0.0000) | Acc: (73.00%) (1028/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.7395) |  Loss2: (0.0000) | Acc: (74.00%) (1991/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.7463) |  Loss2: (0.0000) | Acc: (73.00%) (2932/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.7475) |  Loss2: (0.0000) | Acc: (73.00%) (3873/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.7446) |  Loss2: (0.0000) | Acc: (74.00%) (4837/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.7396) |  Loss2: (0.0000) | Acc: (74.00%) (5793/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.7353) |  Loss2: (0.0000) | Acc: (74.00%) (6742/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.7388) |  Loss2: (0.0000) | Acc: (74.00%) (7683/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.7422) |  Loss2: (0.0000) | Acc: (73.00%) (8608/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.7415) |  Loss2: (0.0000) | Acc: (74.00%) (9573/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.7399) |  Loss2: (0.0000) | Acc: (73.00%) (10510/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.7404) |  Loss2: (0.0000) | Acc: (73.00%) (11445/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.7390) |  Loss2: (0.0000) | Acc: (73.00%) (12403/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.7400) |  Loss2: (0.0000) | Acc: (73.00%) (13340/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.7399) |  Loss2: (0.0000) | Acc: (73.00%) (14289/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.7421) |  Loss2: (0.0000) | Acc: (73.00%) (15221/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.7449) |  Loss2: (0.0000) | Acc: (73.00%) (16152/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.7470) |  Loss2: (0.0000) | Acc: (73.00%) (17079/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.7471) |  Loss2: (0.0000) | Acc: (73.00%) (18033/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.7496) |  Loss2: (0.0000) | Acc: (73.00%) (18937/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.7482) |  Loss2: (0.0000) | Acc: (73.00%) (19894/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.7506) |  Loss2: (0.0000) | Acc: (73.00%) (20815/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.7480) |  Loss2: (0.0000) | Acc: (73.00%) (21785/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.7503) |  Loss2: (0.0000) | Acc: (73.00%) (22705/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.7502) |  Loss2: (0.0000) | Acc: (73.00%) (23657/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.7498) |  Loss2: (0.0000) | Acc: (73.00%) (24596/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.7499) |  Loss2: (0.0000) | Acc: (73.00%) (25549/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.7503) |  Loss2: (0.0000) | Acc: (73.00%) (26485/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.7481) |  Loss2: (0.0000) | Acc: (73.00%) (27455/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.7473) |  Loss2: (0.0000) | Acc: (73.00%) (28417/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.7468) |  Loss2: (0.0000) | Acc: (73.00%) (29364/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.7453) |  Loss2: (0.0000) | Acc: (73.00%) (30338/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.7454) |  Loss2: (0.0000) | Acc: (73.00%) (31274/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.7458) |  Loss2: (0.0000) | Acc: (73.00%) (32216/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.7450) |  Loss2: (0.0000) | Acc: (73.00%) (33180/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.7433) |  Loss2: (0.0000) | Acc: (73.00%) (34145/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.7428) |  Loss2: (0.0000) | Acc: (73.00%) (35102/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.7418) |  Loss2: (0.0000) | Acc: (73.00%) (36069/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.7416) |  Loss2: (0.0000) | Acc: (73.00%) (36982/50000)
# TEST : Loss: (0.7741) | Acc: (73.00%) (7372/10000)
percent tensor([0.5166, 0.5221, 0.5175, 0.5127, 0.5186, 0.5169, 0.5219, 0.5186, 0.5155,
        0.5211, 0.5181, 0.5211, 0.5188, 0.5161, 0.5201, 0.5168],
       device='cuda:0') torch.Size([16])
percent tensor([0.4992, 0.4974, 0.4982, 0.4966, 0.4971, 0.4990, 0.4978, 0.4971, 0.4964,
        0.4970, 0.4978, 0.4984, 0.4989, 0.4959, 0.4989, 0.4988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.5219, 0.5222, 0.5147, 0.5276, 0.5104, 0.5185, 0.5209, 0.5117,
        0.5199, 0.5153, 0.5194, 0.5111, 0.5121, 0.5138, 0.5102],
       device='cuda:0') torch.Size([16])
percent tensor([0.5440, 0.5477, 0.5417, 0.5396, 0.5417, 0.5314, 0.5515, 0.5418, 0.5465,
        0.5497, 0.5511, 0.5543, 0.5488, 0.5473, 0.5458, 0.5400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5767, 0.5489, 0.6276, 0.6187, 0.6000, 0.5614, 0.5777, 0.6250, 0.5925,
        0.5671, 0.5606, 0.6222, 0.5739, 0.5550, 0.5706, 0.5662],
       device='cuda:0') torch.Size([16])
percent tensor([0.5046, 0.4914, 0.5115, 0.5121, 0.5068, 0.5175, 0.5053, 0.5102, 0.5039,
        0.4942, 0.4947, 0.5099, 0.4874, 0.5007, 0.5070, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.5326, 0.5040, 0.5076, 0.5134, 0.4791, 0.5774, 0.4974, 0.4610, 0.5201,
        0.5152, 0.5346, 0.5156, 0.5270, 0.5538, 0.5057, 0.5034],
       device='cuda:0') torch.Size([16])
percent tensor([0.9781, 0.9542, 0.9907, 0.9839, 0.9833, 0.9742, 0.9720, 0.9944, 0.9653,
        0.9695, 0.9652, 0.9901, 0.9628, 0.9593, 0.9713, 0.9820],
       device='cuda:0') torch.Size([16])
Epoch: 22 | Batch_idx: 0 |  Loss: (0.8006) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.7173) |  Loss2: (0.0000) | Acc: (75.00%) (1057/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.6958) |  Loss2: (0.0000) | Acc: (76.00%) (2053/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.6906) |  Loss2: (0.0000) | Acc: (76.00%) (3045/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.6845) |  Loss2: (0.0000) | Acc: (76.00%) (4038/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.6794) |  Loss2: (0.0000) | Acc: (77.00%) (5034/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.6813) |  Loss2: (0.0000) | Acc: (76.00%) (6006/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.6814) |  Loss2: (0.0000) | Acc: (76.00%) (6989/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.6849) |  Loss2: (0.0000) | Acc: (76.00%) (7946/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.6926) |  Loss2: (0.0000) | Acc: (76.00%) (8893/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.6955) |  Loss2: (0.0000) | Acc: (76.00%) (9855/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.6976) |  Loss2: (0.0000) | Acc: (76.00%) (10806/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.6940) |  Loss2: (0.0000) | Acc: (75.00%) (11768/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.6927) |  Loss2: (0.0000) | Acc: (75.00%) (12741/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.6949) |  Loss2: (0.0000) | Acc: (75.00%) (13708/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.6964) |  Loss2: (0.0000) | Acc: (75.00%) (14666/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.6998) |  Loss2: (0.0000) | Acc: (75.00%) (15599/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.7008) |  Loss2: (0.0000) | Acc: (75.00%) (16573/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.7032) |  Loss2: (0.0000) | Acc: (75.00%) (17516/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.7021) |  Loss2: (0.0000) | Acc: (75.00%) (18492/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.6995) |  Loss2: (0.0000) | Acc: (75.00%) (19488/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.7004) |  Loss2: (0.0000) | Acc: (75.00%) (20444/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.7004) |  Loss2: (0.0000) | Acc: (75.00%) (21408/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.7008) |  Loss2: (0.0000) | Acc: (75.00%) (22356/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.7004) |  Loss2: (0.0000) | Acc: (75.00%) (23324/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.7014) |  Loss2: (0.0000) | Acc: (75.00%) (24263/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.7000) |  Loss2: (0.0000) | Acc: (75.00%) (25242/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.6997) |  Loss2: (0.0000) | Acc: (75.00%) (26211/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.6985) |  Loss2: (0.0000) | Acc: (75.00%) (27207/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.6986) |  Loss2: (0.0000) | Acc: (75.00%) (28168/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.6986) |  Loss2: (0.0000) | Acc: (75.00%) (29142/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.6988) |  Loss2: (0.0000) | Acc: (75.00%) (30096/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.6979) |  Loss2: (0.0000) | Acc: (75.00%) (31078/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.6966) |  Loss2: (0.0000) | Acc: (75.00%) (32065/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.6961) |  Loss2: (0.0000) | Acc: (75.00%) (33035/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.6959) |  Loss2: (0.0000) | Acc: (75.00%) (33996/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.6955) |  Loss2: (0.0000) | Acc: (75.00%) (34968/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.6945) |  Loss2: (0.0000) | Acc: (75.00%) (35955/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.6947) |  Loss2: (0.0000) | Acc: (75.00%) (36907/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.6948) |  Loss2: (0.0000) | Acc: (75.00%) (37837/50000)
# TEST : Loss: (0.7694) | Acc: (73.00%) (7331/10000)
percent tensor([0.5168, 0.5224, 0.5170, 0.5129, 0.5183, 0.5168, 0.5220, 0.5189, 0.5154,
        0.5208, 0.5183, 0.5205, 0.5190, 0.5165, 0.5203, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.4992, 0.4977, 0.4966, 0.4967, 0.4960, 0.4993, 0.4976, 0.4966, 0.4957,
        0.4964, 0.4975, 0.4980, 0.4985, 0.4963, 0.4988, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.5047, 0.5214, 0.5254, 0.5151, 0.5287, 0.5108, 0.5183, 0.5216, 0.5123,
        0.5198, 0.5153, 0.5212, 0.5109, 0.5134, 0.5142, 0.5102],
       device='cuda:0') torch.Size([16])
percent tensor([0.5422, 0.5471, 0.5401, 0.5404, 0.5413, 0.5313, 0.5522, 0.5438, 0.5455,
        0.5472, 0.5492, 0.5527, 0.5443, 0.5491, 0.5463, 0.5399],
       device='cuda:0') torch.Size([16])
percent tensor([0.5792, 0.5478, 0.6227, 0.6187, 0.5985, 0.5647, 0.5741, 0.6203, 0.5930,
        0.5616, 0.5596, 0.6134, 0.5707, 0.5494, 0.5704, 0.5673],
       device='cuda:0') torch.Size([16])
percent tensor([0.5047, 0.4911, 0.5079, 0.5121, 0.5068, 0.5153, 0.5045, 0.5067, 0.5023,
        0.4946, 0.4952, 0.5090, 0.4905, 0.4980, 0.5063, 0.5084],
       device='cuda:0') torch.Size([16])
percent tensor([0.5301, 0.5051, 0.5045, 0.5129, 0.4872, 0.5713, 0.5037, 0.4626, 0.5234,
        0.5134, 0.5343, 0.5156, 0.5311, 0.5524, 0.5040, 0.5084],
       device='cuda:0') torch.Size([16])
percent tensor([0.9794, 0.9662, 0.9848, 0.9840, 0.9774, 0.9741, 0.9751, 0.9929, 0.9696,
        0.9727, 0.9706, 0.9808, 0.9698, 0.9649, 0.9775, 0.9832],
       device='cuda:0') torch.Size([16])
Epoch: 23 | Batch_idx: 0 |  Loss: (0.7209) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.6894) |  Loss2: (0.0000) | Acc: (75.00%) (1056/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.6700) |  Loss2: (0.0000) | Acc: (76.00%) (2047/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.6844) |  Loss2: (0.0000) | Acc: (75.00%) (3008/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.6829) |  Loss2: (0.0000) | Acc: (75.00%) (3980/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.6787) |  Loss2: (0.0000) | Acc: (75.00%) (4955/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.6795) |  Loss2: (0.0000) | Acc: (75.00%) (5927/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.6788) |  Loss2: (0.0000) | Acc: (75.00%) (6901/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.6822) |  Loss2: (0.0000) | Acc: (75.00%) (7856/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.6799) |  Loss2: (0.0000) | Acc: (75.00%) (8837/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.6798) |  Loss2: (0.0000) | Acc: (75.00%) (9813/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.6812) |  Loss2: (0.0000) | Acc: (76.00%) (10800/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.6810) |  Loss2: (0.0000) | Acc: (76.00%) (11776/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.6813) |  Loss2: (0.0000) | Acc: (75.00%) (12728/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.6812) |  Loss2: (0.0000) | Acc: (75.00%) (13701/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.6815) |  Loss2: (0.0000) | Acc: (75.00%) (14680/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.6817) |  Loss2: (0.0000) | Acc: (75.00%) (15652/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.6773) |  Loss2: (0.0000) | Acc: (76.00%) (16668/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.6754) |  Loss2: (0.0000) | Acc: (76.00%) (17676/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.6712) |  Loss2: (0.0000) | Acc: (76.00%) (18674/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.6709) |  Loss2: (0.0000) | Acc: (76.00%) (19665/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.6711) |  Loss2: (0.0000) | Acc: (76.00%) (20637/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.6689) |  Loss2: (0.0000) | Acc: (76.00%) (21640/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.6702) |  Loss2: (0.0000) | Acc: (76.00%) (22601/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.6690) |  Loss2: (0.0000) | Acc: (76.00%) (23592/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.6685) |  Loss2: (0.0000) | Acc: (76.00%) (24571/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.6676) |  Loss2: (0.0000) | Acc: (76.00%) (25548/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.6660) |  Loss2: (0.0000) | Acc: (76.00%) (26548/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.6668) |  Loss2: (0.0000) | Acc: (76.00%) (27540/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.6675) |  Loss2: (0.0000) | Acc: (76.00%) (28511/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.6659) |  Loss2: (0.0000) | Acc: (76.00%) (29518/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.6646) |  Loss2: (0.0000) | Acc: (76.00%) (30536/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.6643) |  Loss2: (0.0000) | Acc: (76.00%) (31518/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.6647) |  Loss2: (0.0000) | Acc: (76.00%) (32492/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.6641) |  Loss2: (0.0000) | Acc: (76.00%) (33469/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.6653) |  Loss2: (0.0000) | Acc: (76.00%) (34440/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.6646) |  Loss2: (0.0000) | Acc: (76.00%) (35448/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.6655) |  Loss2: (0.0000) | Acc: (76.00%) (36434/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.6632) |  Loss2: (0.0000) | Acc: (76.00%) (37463/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.6622) |  Loss2: (0.0000) | Acc: (76.00%) (38418/50000)
# TEST : Loss: (0.7205) | Acc: (74.00%) (7471/10000)
percent tensor([0.5169, 0.5219, 0.5181, 0.5135, 0.5193, 0.5173, 0.5218, 0.5196, 0.5151,
        0.5209, 0.5180, 0.5214, 0.5190, 0.5152, 0.5203, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.4991, 0.4975, 0.4978, 0.4967, 0.4970, 0.4992, 0.4978, 0.4968, 0.4956,
        0.4967, 0.4977, 0.4985, 0.4988, 0.4957, 0.4989, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.5215, 0.5212, 0.5156, 0.5267, 0.5100, 0.5185, 0.5215, 0.5137,
        0.5194, 0.5145, 0.5168, 0.5101, 0.5147, 0.5134, 0.5115],
       device='cuda:0') torch.Size([16])
percent tensor([0.5451, 0.5470, 0.5435, 0.5403, 0.5430, 0.5304, 0.5528, 0.5438, 0.5469,
        0.5491, 0.5517, 0.5549, 0.5480, 0.5476, 0.5449, 0.5386],
       device='cuda:0') torch.Size([16])
percent tensor([0.5762, 0.5490, 0.6123, 0.6146, 0.5882, 0.5649, 0.5744, 0.6123, 0.5908,
        0.5608, 0.5631, 0.6067, 0.5733, 0.5543, 0.5707, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5026, 0.4902, 0.5085, 0.5115, 0.5087, 0.5156, 0.5065, 0.5086, 0.5021,
        0.4930, 0.4957, 0.5092, 0.4894, 0.4990, 0.5047, 0.5081],
       device='cuda:0') torch.Size([16])
percent tensor([0.5294, 0.5054, 0.4952, 0.5157, 0.4948, 0.5706, 0.5120, 0.4733, 0.5280,
        0.5080, 0.5372, 0.5269, 0.5322, 0.5559, 0.5047, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.9730, 0.9650, 0.9773, 0.9791, 0.9694, 0.9681, 0.9820, 0.9906, 0.9648,
        0.9702, 0.9742, 0.9785, 0.9705, 0.9759, 0.9731, 0.9841],
       device='cuda:0') torch.Size([16])
Epoch: 24 | Batch_idx: 0 |  Loss: (0.5440) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.6370) |  Loss2: (0.0000) | Acc: (78.00%) (1106/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.6397) |  Loss2: (0.0000) | Acc: (78.00%) (2101/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.6359) |  Loss2: (0.0000) | Acc: (78.00%) (3100/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.6328) |  Loss2: (0.0000) | Acc: (78.00%) (4114/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.6279) |  Loss2: (0.0000) | Acc: (78.00%) (5134/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.6339) |  Loss2: (0.0000) | Acc: (78.00%) (6114/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.6290) |  Loss2: (0.0000) | Acc: (78.00%) (7130/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.6308) |  Loss2: (0.0000) | Acc: (78.00%) (8125/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.6312) |  Loss2: (0.0000) | Acc: (78.00%) (9126/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.6315) |  Loss2: (0.0000) | Acc: (78.00%) (10107/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.6314) |  Loss2: (0.0000) | Acc: (78.00%) (11115/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.6348) |  Loss2: (0.0000) | Acc: (78.00%) (12091/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.6341) |  Loss2: (0.0000) | Acc: (78.00%) (13089/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.6329) |  Loss2: (0.0000) | Acc: (78.00%) (14092/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.6281) |  Loss2: (0.0000) | Acc: (78.00%) (15125/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.6274) |  Loss2: (0.0000) | Acc: (78.00%) (16144/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.6288) |  Loss2: (0.0000) | Acc: (78.00%) (17124/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.6263) |  Loss2: (0.0000) | Acc: (78.00%) (18148/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.6259) |  Loss2: (0.0000) | Acc: (78.00%) (19152/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.6269) |  Loss2: (0.0000) | Acc: (78.00%) (20134/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.6285) |  Loss2: (0.0000) | Acc: (78.00%) (21122/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.6288) |  Loss2: (0.0000) | Acc: (78.00%) (22128/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.6295) |  Loss2: (0.0000) | Acc: (78.00%) (23113/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.6299) |  Loss2: (0.0000) | Acc: (78.00%) (24099/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.6294) |  Loss2: (0.0000) | Acc: (78.00%) (25108/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (78.00%) (26122/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.6268) |  Loss2: (0.0000) | Acc: (78.00%) (27148/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.6262) |  Loss2: (0.0000) | Acc: (78.00%) (28162/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.6255) |  Loss2: (0.0000) | Acc: (78.00%) (29168/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.6259) |  Loss2: (0.0000) | Acc: (78.00%) (30158/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.6259) |  Loss2: (0.0000) | Acc: (78.00%) (31151/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.6253) |  Loss2: (0.0000) | Acc: (78.00%) (32166/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (33180/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.6237) |  Loss2: (0.0000) | Acc: (78.00%) (34190/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.6241) |  Loss2: (0.0000) | Acc: (78.00%) (35199/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.6238) |  Loss2: (0.0000) | Acc: (78.00%) (36204/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.6234) |  Loss2: (0.0000) | Acc: (78.00%) (37232/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.6239) |  Loss2: (0.0000) | Acc: (78.00%) (38224/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.6230) |  Loss2: (0.0000) | Acc: (78.00%) (39223/50000)
# TEST : Loss: (0.7110) | Acc: (75.00%) (7595/10000)
percent tensor([0.5173, 0.5216, 0.5174, 0.5136, 0.5183, 0.5171, 0.5215, 0.5196, 0.5159,
        0.5206, 0.5186, 0.5205, 0.5194, 0.5153, 0.5204, 0.5174],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.4975, 0.4982, 0.4968, 0.4972, 0.4995, 0.4978, 0.4970, 0.4964,
        0.4968, 0.4981, 0.4984, 0.4993, 0.4954, 0.4988, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5051, 0.5202, 0.5224, 0.5170, 0.5296, 0.5121, 0.5174, 0.5240, 0.5120,
        0.5179, 0.5145, 0.5199, 0.5117, 0.5104, 0.5154, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5469, 0.5475, 0.5430, 0.5389, 0.5441, 0.5306, 0.5530, 0.5439, 0.5499,
        0.5492, 0.5538, 0.5541, 0.5497, 0.5495, 0.5456, 0.5392],
       device='cuda:0') torch.Size([16])
percent tensor([0.5825, 0.5551, 0.6142, 0.6155, 0.5962, 0.5600, 0.5795, 0.6102, 0.5978,
        0.5649, 0.5708, 0.6086, 0.5786, 0.5654, 0.5691, 0.5668],
       device='cuda:0') torch.Size([16])
percent tensor([0.5059, 0.4908, 0.5125, 0.5125, 0.5123, 0.5177, 0.5072, 0.5107, 0.5017,
        0.4937, 0.4943, 0.5114, 0.4882, 0.4987, 0.5070, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5373, 0.5056, 0.5061, 0.5140, 0.5004, 0.5811, 0.5061, 0.4727, 0.5283,
        0.5119, 0.5376, 0.5315, 0.5271, 0.5580, 0.5143, 0.5209],
       device='cuda:0') torch.Size([16])
percent tensor([0.9780, 0.9589, 0.9854, 0.9798, 0.9868, 0.9694, 0.9825, 0.9898, 0.9724,
        0.9726, 0.9736, 0.9858, 0.9616, 0.9760, 0.9728, 0.9771],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 25 | Batch_idx: 0 |  Loss: (0.5851) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.6275) |  Loss2: (0.0000) | Acc: (78.00%) (1101/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.6974) |  Loss2: (0.0000) | Acc: (76.00%) (2055/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.7289) |  Loss2: (0.0000) | Acc: (75.00%) (2979/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.7312) |  Loss2: (0.0000) | Acc: (75.00%) (3941/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.7294) |  Loss2: (0.0000) | Acc: (74.00%) (4883/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.7336) |  Loss2: (0.0000) | Acc: (74.00%) (5822/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.7345) |  Loss2: (0.0000) | Acc: (74.00%) (6793/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.7304) |  Loss2: (0.0000) | Acc: (75.00%) (7778/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.7305) |  Loss2: (0.0000) | Acc: (74.00%) (8734/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.7324) |  Loss2: (0.0000) | Acc: (74.00%) (9691/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.7291) |  Loss2: (0.0000) | Acc: (75.00%) (10665/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.7303) |  Loss2: (0.0000) | Acc: (75.00%) (11620/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.7283) |  Loss2: (0.0000) | Acc: (75.00%) (12604/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.7275) |  Loss2: (0.0000) | Acc: (75.00%) (13581/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.7263) |  Loss2: (0.0000) | Acc: (75.00%) (14525/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.7231) |  Loss2: (0.0000) | Acc: (75.00%) (15503/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.7220) |  Loss2: (0.0000) | Acc: (75.00%) (16463/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.7187) |  Loss2: (0.0000) | Acc: (75.00%) (17453/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.7158) |  Loss2: (0.0000) | Acc: (75.00%) (18445/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.7112) |  Loss2: (0.0000) | Acc: (75.00%) (19444/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.7086) |  Loss2: (0.0000) | Acc: (75.00%) (20438/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.7086) |  Loss2: (0.0000) | Acc: (75.00%) (21403/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.7055) |  Loss2: (0.0000) | Acc: (75.00%) (22400/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.7030) |  Loss2: (0.0000) | Acc: (75.00%) (23380/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.7004) |  Loss2: (0.0000) | Acc: (75.00%) (24370/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.7014) |  Loss2: (0.0000) | Acc: (75.00%) (25319/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.6998) |  Loss2: (0.0000) | Acc: (75.00%) (26312/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.6980) |  Loss2: (0.0000) | Acc: (75.00%) (27306/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.6956) |  Loss2: (0.0000) | Acc: (76.00%) (28316/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.6935) |  Loss2: (0.0000) | Acc: (76.00%) (29321/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.6919) |  Loss2: (0.0000) | Acc: (76.00%) (30317/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.6922) |  Loss2: (0.0000) | Acc: (76.00%) (31284/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.6905) |  Loss2: (0.0000) | Acc: (76.00%) (32277/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.6888) |  Loss2: (0.0000) | Acc: (76.00%) (33280/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.6886) |  Loss2: (0.0000) | Acc: (76.00%) (34272/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.6879) |  Loss2: (0.0000) | Acc: (76.00%) (35259/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.6868) |  Loss2: (0.0000) | Acc: (76.00%) (36270/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.6855) |  Loss2: (0.0000) | Acc: (76.00%) (37255/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.6849) |  Loss2: (0.0000) | Acc: (76.00%) (38214/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_025.pth.tar'
# TEST : Loss: (0.6760) | Acc: (76.00%) (7635/10000)
percent tensor([0.5125, 0.5159, 0.5132, 0.5105, 0.5139, 0.5127, 0.5159, 0.5151, 0.5115,
        0.5148, 0.5134, 0.5152, 0.5135, 0.5116, 0.5153, 0.5128],
       device='cuda:0') torch.Size([16])
percent tensor([0.4985, 0.4972, 0.4965, 0.4957, 0.4958, 0.4986, 0.4974, 0.4962, 0.4952,
        0.4956, 0.4968, 0.4978, 0.4976, 0.4956, 0.4991, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.5068, 0.5252, 0.5300, 0.5208, 0.5392, 0.5157, 0.5240, 0.5305, 0.5181,
        0.5251, 0.5186, 0.5277, 0.5150, 0.5139, 0.5191, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.5344, 0.5341, 0.5366, 0.5324, 0.5380, 0.5213, 0.5412, 0.5361, 0.5392,
        0.5362, 0.5391, 0.5435, 0.5340, 0.5364, 0.5327, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.5864, 0.5422, 0.6386, 0.6419, 0.6145, 0.5802, 0.5767, 0.6281, 0.6101,
        0.5639, 0.5667, 0.6148, 0.5692, 0.5660, 0.5666, 0.5733],
       device='cuda:0') torch.Size([16])
percent tensor([0.5241, 0.5122, 0.5323, 0.5319, 0.5332, 0.5319, 0.5299, 0.5346, 0.5230,
        0.5157, 0.5151, 0.5339, 0.5117, 0.5196, 0.5280, 0.5271],
       device='cuda:0') torch.Size([16])
percent tensor([0.5236, 0.4988, 0.5119, 0.5179, 0.5119, 0.5635, 0.5095, 0.4791, 0.5147,
        0.5096, 0.5226, 0.5279, 0.5055, 0.5410, 0.5075, 0.5089],
       device='cuda:0') torch.Size([16])
percent tensor([0.9785, 0.9676, 0.9859, 0.9802, 0.9877, 0.9657, 0.9833, 0.9913, 0.9761,
        0.9771, 0.9795, 0.9836, 0.9607, 0.9785, 0.9790, 0.9814],
       device='cuda:0') torch.Size([16])
Epoch: 26 | Batch_idx: 0 |  Loss: (0.7507) |  Loss2: (0.0000) | Acc: (72.00%) (93/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.6539) |  Loss2: (0.0000) | Acc: (76.00%) (1082/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.6516) |  Loss2: (0.0000) | Acc: (76.00%) (2062/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.6601) |  Loss2: (0.0000) | Acc: (76.00%) (3041/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.6539) |  Loss2: (0.0000) | Acc: (77.00%) (4048/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.6481) |  Loss2: (0.0000) | Acc: (77.00%) (5061/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.6561) |  Loss2: (0.0000) | Acc: (77.00%) (6035/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.6562) |  Loss2: (0.0000) | Acc: (77.00%) (7036/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.6541) |  Loss2: (0.0000) | Acc: (77.00%) (8026/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.6547) |  Loss2: (0.0000) | Acc: (77.00%) (9004/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.6566) |  Loss2: (0.0000) | Acc: (77.00%) (9978/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.6553) |  Loss2: (0.0000) | Acc: (77.00%) (10958/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.6518) |  Loss2: (0.0000) | Acc: (77.00%) (11946/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.6520) |  Loss2: (0.0000) | Acc: (77.00%) (12942/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.6513) |  Loss2: (0.0000) | Acc: (77.00%) (13924/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.6461) |  Loss2: (0.0000) | Acc: (77.00%) (14964/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.6442) |  Loss2: (0.0000) | Acc: (77.00%) (15960/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.6433) |  Loss2: (0.0000) | Acc: (77.00%) (16979/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.6421) |  Loss2: (0.0000) | Acc: (77.00%) (17979/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.6417) |  Loss2: (0.0000) | Acc: (77.00%) (18968/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.6425) |  Loss2: (0.0000) | Acc: (77.00%) (19948/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.6435) |  Loss2: (0.0000) | Acc: (77.00%) (20925/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.6429) |  Loss2: (0.0000) | Acc: (77.00%) (21913/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.6432) |  Loss2: (0.0000) | Acc: (77.00%) (22917/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.6430) |  Loss2: (0.0000) | Acc: (77.00%) (23920/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.6417) |  Loss2: (0.0000) | Acc: (77.00%) (24923/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.6391) |  Loss2: (0.0000) | Acc: (77.00%) (25950/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.6385) |  Loss2: (0.0000) | Acc: (77.00%) (26963/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.6369) |  Loss2: (0.0000) | Acc: (77.00%) (27980/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.6381) |  Loss2: (0.0000) | Acc: (77.00%) (28954/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.6365) |  Loss2: (0.0000) | Acc: (77.00%) (29967/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.6359) |  Loss2: (0.0000) | Acc: (77.00%) (30975/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.6366) |  Loss2: (0.0000) | Acc: (77.00%) (31961/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.6359) |  Loss2: (0.0000) | Acc: (77.00%) (32992/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.6360) |  Loss2: (0.0000) | Acc: (77.00%) (33985/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.6358) |  Loss2: (0.0000) | Acc: (77.00%) (34997/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.6351) |  Loss2: (0.0000) | Acc: (77.00%) (36008/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.6337) |  Loss2: (0.0000) | Acc: (77.00%) (37033/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.6340) |  Loss2: (0.0000) | Acc: (77.00%) (38016/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.6337) |  Loss2: (0.0000) | Acc: (77.00%) (38989/50000)
# TEST : Loss: (0.6483) | Acc: (77.00%) (7728/10000)
percent tensor([0.5142, 0.5168, 0.5158, 0.5124, 0.5166, 0.5145, 0.5174, 0.5174, 0.5131,
        0.5164, 0.5146, 0.5175, 0.5151, 0.5117, 0.5168, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.4980, 0.4966, 0.4961, 0.4951, 0.4954, 0.4981, 0.4969, 0.4956, 0.4944,
        0.4951, 0.4962, 0.4974, 0.4971, 0.4944, 0.4990, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.5082, 0.5293, 0.5311, 0.5227, 0.5411, 0.5189, 0.5267, 0.5322, 0.5204,
        0.5286, 0.5222, 0.5293, 0.5175, 0.5182, 0.5228, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5373, 0.5357, 0.5416, 0.5371, 0.5437, 0.5236, 0.5443, 0.5410, 0.5428,
        0.5390, 0.5415, 0.5477, 0.5355, 0.5381, 0.5353, 0.5301],
       device='cuda:0') torch.Size([16])
percent tensor([0.5959, 0.5374, 0.6526, 0.6612, 0.6245, 0.5983, 0.5743, 0.6331, 0.6250,
        0.5664, 0.5730, 0.6197, 0.5710, 0.5779, 0.5635, 0.5813],
       device='cuda:0') torch.Size([16])
percent tensor([0.5482, 0.5359, 0.5559, 0.5559, 0.5574, 0.5525, 0.5547, 0.5621, 0.5479,
        0.5404, 0.5407, 0.5604, 0.5367, 0.5453, 0.5522, 0.5499],
       device='cuda:0') torch.Size([16])
percent tensor([0.5296, 0.5047, 0.5199, 0.5244, 0.5208, 0.5727, 0.5163, 0.4888, 0.5208,
        0.5176, 0.5279, 0.5326, 0.5052, 0.5517, 0.5138, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.9850, 0.9773, 0.9903, 0.9858, 0.9917, 0.9733, 0.9883, 0.9946, 0.9818,
        0.9846, 0.9861, 0.9874, 0.9714, 0.9855, 0.9853, 0.9870],
       device='cuda:0') torch.Size([16])
Epoch: 27 | Batch_idx: 0 |  Loss: (0.5537) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.6072) |  Loss2: (0.0000) | Acc: (78.00%) (1111/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.6293) |  Loss2: (0.0000) | Acc: (78.00%) (2102/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.6198) |  Loss2: (0.0000) | Acc: (78.00%) (3112/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.6225) |  Loss2: (0.0000) | Acc: (78.00%) (4119/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.6232) |  Loss2: (0.0000) | Acc: (78.00%) (5127/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.6159) |  Loss2: (0.0000) | Acc: (78.00%) (6143/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.6197) |  Loss2: (0.0000) | Acc: (78.00%) (7128/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.6134) |  Loss2: (0.0000) | Acc: (78.00%) (8155/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.6156) |  Loss2: (0.0000) | Acc: (78.00%) (9164/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.6172) |  Loss2: (0.0000) | Acc: (78.00%) (10174/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.6206) |  Loss2: (0.0000) | Acc: (78.00%) (11168/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.6184) |  Loss2: (0.0000) | Acc: (78.00%) (12185/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.6201) |  Loss2: (0.0000) | Acc: (78.00%) (13187/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.6198) |  Loss2: (0.0000) | Acc: (78.00%) (14200/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.6187) |  Loss2: (0.0000) | Acc: (78.00%) (15215/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.6206) |  Loss2: (0.0000) | Acc: (78.00%) (16217/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.6196) |  Loss2: (0.0000) | Acc: (78.00%) (17225/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.6187) |  Loss2: (0.0000) | Acc: (78.00%) (18246/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.6191) |  Loss2: (0.0000) | Acc: (78.00%) (19245/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.6194) |  Loss2: (0.0000) | Acc: (78.00%) (20262/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.6210) |  Loss2: (0.0000) | Acc: (78.00%) (21237/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.6205) |  Loss2: (0.0000) | Acc: (78.00%) (22240/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.6199) |  Loss2: (0.0000) | Acc: (78.00%) (23246/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.6182) |  Loss2: (0.0000) | Acc: (78.00%) (24277/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.6177) |  Loss2: (0.0000) | Acc: (78.00%) (25283/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.6196) |  Loss2: (0.0000) | Acc: (78.00%) (26249/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.6189) |  Loss2: (0.0000) | Acc: (78.00%) (27260/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.6188) |  Loss2: (0.0000) | Acc: (78.00%) (28259/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.6191) |  Loss2: (0.0000) | Acc: (78.00%) (29267/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.6182) |  Loss2: (0.0000) | Acc: (78.00%) (30282/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.6170) |  Loss2: (0.0000) | Acc: (78.00%) (31309/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.6145) |  Loss2: (0.0000) | Acc: (78.00%) (32349/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.6139) |  Loss2: (0.0000) | Acc: (78.00%) (33351/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.6132) |  Loss2: (0.0000) | Acc: (78.00%) (34374/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.6131) |  Loss2: (0.0000) | Acc: (78.00%) (35385/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.6126) |  Loss2: (0.0000) | Acc: (78.00%) (36410/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.6131) |  Loss2: (0.0000) | Acc: (78.00%) (37408/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.6133) |  Loss2: (0.0000) | Acc: (78.00%) (38403/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.6135) |  Loss2: (0.0000) | Acc: (78.00%) (39370/50000)
# TEST : Loss: (0.6342) | Acc: (77.00%) (7787/10000)
percent tensor([0.5159, 0.5179, 0.5180, 0.5141, 0.5191, 0.5163, 0.5190, 0.5195, 0.5147,
        0.5180, 0.5159, 0.5196, 0.5167, 0.5120, 0.5184, 0.5156],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.4968, 0.4964, 0.4950, 0.4956, 0.4980, 0.4971, 0.4959, 0.4945,
        0.4952, 0.4963, 0.4976, 0.4973, 0.4942, 0.4991, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.5304, 0.5312, 0.5241, 0.5414, 0.5217, 0.5269, 0.5326, 0.5206,
        0.5296, 0.5236, 0.5294, 0.5186, 0.5194, 0.5249, 0.5190],
       device='cuda:0') torch.Size([16])
percent tensor([0.5401, 0.5379, 0.5456, 0.5412, 0.5483, 0.5257, 0.5477, 0.5453, 0.5464,
        0.5420, 0.5444, 0.5517, 0.5375, 0.5407, 0.5382, 0.5325],
       device='cuda:0') torch.Size([16])
percent tensor([0.5927, 0.5301, 0.6511, 0.6629, 0.6222, 0.5995, 0.5663, 0.6245, 0.6289,
        0.5636, 0.5724, 0.6150, 0.5647, 0.5831, 0.5535, 0.5761],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.5518, 0.5731, 0.5732, 0.5747, 0.5682, 0.5726, 0.5804, 0.5660,
        0.5576, 0.5586, 0.5795, 0.5539, 0.5649, 0.5688, 0.5662],
       device='cuda:0') torch.Size([16])
percent tensor([0.5347, 0.5061, 0.5278, 0.5318, 0.5305, 0.5848, 0.5215, 0.4951, 0.5241,
        0.5219, 0.5303, 0.5373, 0.5020, 0.5611, 0.5177, 0.5239],
       device='cuda:0') torch.Size([16])
percent tensor([0.9907, 0.9845, 0.9936, 0.9900, 0.9943, 0.9802, 0.9923, 0.9965, 0.9876,
        0.9901, 0.9909, 0.9915, 0.9800, 0.9909, 0.9897, 0.9913],
       device='cuda:0') torch.Size([16])
Epoch: 28 | Batch_idx: 0 |  Loss: (0.5771) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.5951) |  Loss2: (0.0000) | Acc: (78.00%) (1108/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.5910) |  Loss2: (0.0000) | Acc: (79.00%) (2124/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.6056) |  Loss2: (0.0000) | Acc: (78.00%) (3113/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.6134) |  Loss2: (0.0000) | Acc: (78.00%) (4117/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.6131) |  Loss2: (0.0000) | Acc: (78.00%) (5127/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.6070) |  Loss2: (0.0000) | Acc: (78.00%) (6137/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.5956) |  Loss2: (0.0000) | Acc: (79.00%) (7194/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.5947) |  Loss2: (0.0000) | Acc: (79.00%) (8213/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.5961) |  Loss2: (0.0000) | Acc: (79.00%) (9220/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.6006) |  Loss2: (0.0000) | Acc: (79.00%) (10219/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.6010) |  Loss2: (0.0000) | Acc: (79.00%) (11229/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.6013) |  Loss2: (0.0000) | Acc: (79.00%) (12244/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.6006) |  Loss2: (0.0000) | Acc: (79.00%) (13265/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.6008) |  Loss2: (0.0000) | Acc: (79.00%) (14278/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.5994) |  Loss2: (0.0000) | Acc: (79.00%) (15297/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.5997) |  Loss2: (0.0000) | Acc: (79.00%) (16296/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.6004) |  Loss2: (0.0000) | Acc: (79.00%) (17307/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.6005) |  Loss2: (0.0000) | Acc: (79.00%) (18319/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.6006) |  Loss2: (0.0000) | Acc: (79.00%) (19335/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.6012) |  Loss2: (0.0000) | Acc: (79.00%) (20342/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.6016) |  Loss2: (0.0000) | Acc: (78.00%) (21331/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.6030) |  Loss2: (0.0000) | Acc: (78.00%) (22327/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.6040) |  Loss2: (0.0000) | Acc: (78.00%) (23326/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.6064) |  Loss2: (0.0000) | Acc: (78.00%) (24315/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.6047) |  Loss2: (0.0000) | Acc: (78.00%) (25341/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.6067) |  Loss2: (0.0000) | Acc: (78.00%) (26314/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.6066) |  Loss2: (0.0000) | Acc: (78.00%) (27317/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.6079) |  Loss2: (0.0000) | Acc: (78.00%) (28300/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.6081) |  Loss2: (0.0000) | Acc: (78.00%) (29304/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.6086) |  Loss2: (0.0000) | Acc: (78.00%) (30318/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.6079) |  Loss2: (0.0000) | Acc: (78.00%) (31339/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.6072) |  Loss2: (0.0000) | Acc: (78.00%) (32363/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.6064) |  Loss2: (0.0000) | Acc: (78.00%) (33384/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.6061) |  Loss2: (0.0000) | Acc: (78.00%) (34393/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.6059) |  Loss2: (0.0000) | Acc: (78.00%) (35399/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.6051) |  Loss2: (0.0000) | Acc: (78.00%) (36424/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.6058) |  Loss2: (0.0000) | Acc: (78.00%) (37416/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.6057) |  Loss2: (0.0000) | Acc: (78.00%) (38423/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.6045) |  Loss2: (0.0000) | Acc: (78.00%) (39400/50000)
# TEST : Loss: (0.6288) | Acc: (78.00%) (7813/10000)
percent tensor([0.5180, 0.5196, 0.5207, 0.5161, 0.5219, 0.5183, 0.5211, 0.5220, 0.5167,
        0.5201, 0.5178, 0.5223, 0.5188, 0.5129, 0.5204, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.4969, 0.4965, 0.4950, 0.4957, 0.4980, 0.4973, 0.4960, 0.4945,
        0.4953, 0.4963, 0.4979, 0.4974, 0.4940, 0.4992, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.5295, 0.5313, 0.5249, 0.5415, 0.5235, 0.5258, 0.5322, 0.5202,
        0.5288, 0.5231, 0.5287, 0.5179, 0.5188, 0.5250, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5443, 0.5419, 0.5505, 0.5464, 0.5537, 0.5288, 0.5527, 0.5507, 0.5513,
        0.5467, 0.5491, 0.5570, 0.5413, 0.5451, 0.5425, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.5934, 0.5279, 0.6500, 0.6652, 0.6199, 0.6012, 0.5626, 0.6183, 0.6351,
        0.5639, 0.5764, 0.6124, 0.5641, 0.5909, 0.5486, 0.5738],
       device='cuda:0') torch.Size([16])
percent tensor([0.5804, 0.5647, 0.5873, 0.5881, 0.5893, 0.5814, 0.5876, 0.5950, 0.5813,
        0.5717, 0.5735, 0.5953, 0.5679, 0.5812, 0.5821, 0.5798],
       device='cuda:0') torch.Size([16])
percent tensor([0.5476, 0.5124, 0.5417, 0.5448, 0.5455, 0.6039, 0.5318, 0.5047, 0.5340,
        0.5315, 0.5399, 0.5479, 0.5054, 0.5773, 0.5262, 0.5355],
       device='cuda:0') torch.Size([16])
percent tensor([0.9935, 0.9887, 0.9955, 0.9926, 0.9960, 0.9847, 0.9947, 0.9976, 0.9908,
        0.9931, 0.9934, 0.9937, 0.9849, 0.9935, 0.9924, 0.9938],
       device='cuda:0') torch.Size([16])
Epoch: 29 | Batch_idx: 0 |  Loss: (0.5417) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.5929) |  Loss2: (0.0000) | Acc: (79.00%) (1125/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.5837) |  Loss2: (0.0000) | Acc: (79.00%) (2143/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.5852) |  Loss2: (0.0000) | Acc: (79.00%) (3171/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.5840) |  Loss2: (0.0000) | Acc: (79.00%) (4188/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.5905) |  Loss2: (0.0000) | Acc: (79.00%) (5180/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.5869) |  Loss2: (0.0000) | Acc: (79.00%) (6211/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.5828) |  Loss2: (0.0000) | Acc: (79.00%) (7247/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.5826) |  Loss2: (0.0000) | Acc: (79.00%) (8282/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.5838) |  Loss2: (0.0000) | Acc: (79.00%) (9280/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.5899) |  Loss2: (0.0000) | Acc: (79.00%) (10254/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.5888) |  Loss2: (0.0000) | Acc: (79.00%) (11276/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.5879) |  Loss2: (0.0000) | Acc: (79.00%) (12287/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.5877) |  Loss2: (0.0000) | Acc: (79.00%) (13316/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.5867) |  Loss2: (0.0000) | Acc: (79.00%) (14340/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.5850) |  Loss2: (0.0000) | Acc: (79.00%) (15383/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.5895) |  Loss2: (0.0000) | Acc: (79.00%) (16379/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.5925) |  Loss2: (0.0000) | Acc: (79.00%) (17380/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.5957) |  Loss2: (0.0000) | Acc: (79.00%) (18357/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.5947) |  Loss2: (0.0000) | Acc: (79.00%) (19394/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.5969) |  Loss2: (0.0000) | Acc: (79.00%) (20379/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.5940) |  Loss2: (0.0000) | Acc: (79.00%) (21424/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.5951) |  Loss2: (0.0000) | Acc: (79.00%) (22428/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.5976) |  Loss2: (0.0000) | Acc: (79.00%) (23429/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.5998) |  Loss2: (0.0000) | Acc: (79.00%) (24424/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.5987) |  Loss2: (0.0000) | Acc: (79.00%) (25452/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.5982) |  Loss2: (0.0000) | Acc: (79.00%) (26489/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.5977) |  Loss2: (0.0000) | Acc: (79.00%) (27513/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.5982) |  Loss2: (0.0000) | Acc: (79.00%) (28519/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.5984) |  Loss2: (0.0000) | Acc: (79.00%) (29538/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.5979) |  Loss2: (0.0000) | Acc: (79.00%) (30552/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.5968) |  Loss2: (0.0000) | Acc: (79.00%) (31573/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.5967) |  Loss2: (0.0000) | Acc: (79.00%) (32600/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.5963) |  Loss2: (0.0000) | Acc: (79.00%) (33613/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.5964) |  Loss2: (0.0000) | Acc: (79.00%) (34625/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.5969) |  Loss2: (0.0000) | Acc: (79.00%) (35637/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.5966) |  Loss2: (0.0000) | Acc: (79.00%) (36668/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.5962) |  Loss2: (0.0000) | Acc: (79.00%) (37699/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.5964) |  Loss2: (0.0000) | Acc: (79.00%) (38711/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.5962) |  Loss2: (0.0000) | Acc: (79.00%) (39677/50000)
# TEST : Loss: (0.6212) | Acc: (78.00%) (7862/10000)
percent tensor([0.5214, 0.5228, 0.5246, 0.5190, 0.5262, 0.5214, 0.5248, 0.5260, 0.5201,
        0.5237, 0.5210, 0.5263, 0.5224, 0.5150, 0.5238, 0.5206],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.4971, 0.4965, 0.4949, 0.4957, 0.4980, 0.4974, 0.4961, 0.4946,
        0.4953, 0.4964, 0.4980, 0.4976, 0.4940, 0.4993, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.5106, 0.5312, 0.5355, 0.5294, 0.5455, 0.5277, 0.5275, 0.5352, 0.5222,
        0.5308, 0.5250, 0.5318, 0.5194, 0.5207, 0.5280, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.5470, 0.5445, 0.5536, 0.5497, 0.5571, 0.5306, 0.5557, 0.5537, 0.5545,
        0.5497, 0.5523, 0.5604, 0.5438, 0.5480, 0.5452, 0.5388],
       device='cuda:0') torch.Size([16])
percent tensor([0.5987, 0.5332, 0.6506, 0.6680, 0.6199, 0.6048, 0.5646, 0.6150, 0.6428,
        0.5684, 0.5856, 0.6142, 0.5699, 0.6018, 0.5502, 0.5769],
       device='cuda:0') torch.Size([16])
percent tensor([0.5882, 0.5717, 0.5950, 0.5958, 0.5968, 0.5886, 0.5955, 0.6016, 0.5900,
        0.5794, 0.5819, 0.6039, 0.5754, 0.5907, 0.5892, 0.5869],
       device='cuda:0') torch.Size([16])
percent tensor([0.5548, 0.5168, 0.5450, 0.5471, 0.5493, 0.6160, 0.5356, 0.5018, 0.5392,
        0.5378, 0.5466, 0.5499, 0.5070, 0.5889, 0.5277, 0.5409],
       device='cuda:0') torch.Size([16])
percent tensor([0.9955, 0.9914, 0.9967, 0.9947, 0.9971, 0.9888, 0.9962, 0.9983, 0.9931,
        0.9949, 0.9953, 0.9953, 0.9884, 0.9954, 0.9946, 0.9956],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 30 | Batch_idx: 0 |  Loss: (0.6396) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.6013) |  Loss2: (0.0000) | Acc: (79.00%) (1114/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.6298) |  Loss2: (0.0000) | Acc: (77.00%) (2093/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.6317) |  Loss2: (0.0000) | Acc: (77.00%) (3085/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.6143) |  Loss2: (0.0000) | Acc: (78.00%) (4128/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.6154) |  Loss2: (0.0000) | Acc: (78.00%) (5132/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.6148) |  Loss2: (0.0000) | Acc: (78.00%) (6121/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.6125) |  Loss2: (0.0000) | Acc: (78.00%) (7137/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.6111) |  Loss2: (0.0000) | Acc: (78.00%) (8167/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.6107) |  Loss2: (0.0000) | Acc: (78.00%) (9173/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.6148) |  Loss2: (0.0000) | Acc: (78.00%) (10164/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.6180) |  Loss2: (0.0000) | Acc: (78.00%) (11148/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.6093) |  Loss2: (0.0000) | Acc: (78.00%) (12202/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.6097) |  Loss2: (0.0000) | Acc: (78.00%) (13193/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.6103) |  Loss2: (0.0000) | Acc: (78.00%) (14192/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.6097) |  Loss2: (0.0000) | Acc: (78.00%) (15189/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.6084) |  Loss2: (0.0000) | Acc: (78.00%) (16203/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.6098) |  Loss2: (0.0000) | Acc: (78.00%) (17189/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.6103) |  Loss2: (0.0000) | Acc: (78.00%) (18190/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.6078) |  Loss2: (0.0000) | Acc: (78.00%) (19221/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.6055) |  Loss2: (0.0000) | Acc: (78.00%) (20249/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.6043) |  Loss2: (0.0000) | Acc: (78.00%) (21264/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.6026) |  Loss2: (0.0000) | Acc: (78.00%) (22291/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.6038) |  Loss2: (0.0000) | Acc: (78.00%) (23288/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.6026) |  Loss2: (0.0000) | Acc: (78.00%) (24305/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.6033) |  Loss2: (0.0000) | Acc: (78.00%) (25329/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.6032) |  Loss2: (0.0000) | Acc: (78.00%) (26343/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.6043) |  Loss2: (0.0000) | Acc: (78.00%) (27335/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.6042) |  Loss2: (0.0000) | Acc: (78.00%) (28341/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.6052) |  Loss2: (0.0000) | Acc: (78.00%) (29343/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.6053) |  Loss2: (0.0000) | Acc: (78.00%) (30352/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.6054) |  Loss2: (0.0000) | Acc: (78.00%) (31355/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.6057) |  Loss2: (0.0000) | Acc: (78.00%) (32353/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.6049) |  Loss2: (0.0000) | Acc: (78.00%) (33373/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.6046) |  Loss2: (0.0000) | Acc: (78.00%) (34392/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.6052) |  Loss2: (0.0000) | Acc: (78.00%) (35395/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.6056) |  Loss2: (0.0000) | Acc: (78.00%) (36399/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.6048) |  Loss2: (0.0000) | Acc: (78.00%) (37438/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.6033) |  Loss2: (0.0000) | Acc: (78.00%) (38469/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.6034) |  Loss2: (0.0000) | Acc: (78.00%) (39452/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_030.pth.tar'
# TEST : Loss: (0.6610) | Acc: (76.00%) (7676/10000)
percent tensor([0.5208, 0.5233, 0.5229, 0.5182, 0.5254, 0.5211, 0.5255, 0.5250, 0.5200,
        0.5237, 0.5207, 0.5261, 0.5227, 0.5169, 0.5236, 0.5200],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.4972, 0.4975, 0.4957, 0.4963, 0.4981, 0.4975, 0.4967, 0.4949,
        0.4960, 0.4964, 0.4995, 0.4984, 0.4938, 0.4997, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5141, 0.5299, 0.5327, 0.5281, 0.5435, 0.5298, 0.5263, 0.5334, 0.5216,
        0.5290, 0.5279, 0.5271, 0.5222, 0.5203, 0.5284, 0.5244],
       device='cuda:0') torch.Size([16])
percent tensor([0.5473, 0.5479, 0.5508, 0.5462, 0.5533, 0.5313, 0.5577, 0.5544, 0.5538,
        0.5516, 0.5551, 0.5582, 0.5447, 0.5523, 0.5481, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.6004, 0.5391, 0.6456, 0.6655, 0.6127, 0.5967, 0.5692, 0.6178, 0.6343,
        0.5729, 0.5931, 0.6132, 0.5682, 0.5967, 0.5588, 0.5753],
       device='cuda:0') torch.Size([16])
percent tensor([0.5897, 0.5760, 0.5941, 0.5929, 0.5915, 0.5845, 0.5961, 0.5991, 0.5925,
        0.5862, 0.5882, 0.6097, 0.5825, 0.5920, 0.5910, 0.5864],
       device='cuda:0') torch.Size([16])
percent tensor([0.5467, 0.5221, 0.5455, 0.5421, 0.5464, 0.6084, 0.5352, 0.5070, 0.5378,
        0.5399, 0.5469, 0.5446, 0.5037, 0.5897, 0.5299, 0.5440],
       device='cuda:0') torch.Size([16])
percent tensor([0.9957, 0.9912, 0.9972, 0.9944, 0.9942, 0.9917, 0.9953, 0.9979, 0.9941,
        0.9951, 0.9962, 0.9971, 0.9914, 0.9946, 0.9957, 0.9952],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(173.4601, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(790.4446, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(785.2360, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.4688, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(508.1368, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2178.1792, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4308.6919, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1423.0562, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6082.7910, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12119.5127, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4036.7351, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17128.1172, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 31 | Batch_idx: 0 |  Loss: (0.5077) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.5566) |  Loss2: (0.0000) | Acc: (80.00%) (1135/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.5670) |  Loss2: (0.0000) | Acc: (80.00%) (2163/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.5601) |  Loss2: (0.0000) | Acc: (80.00%) (3205/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.5699) |  Loss2: (0.0000) | Acc: (80.00%) (4214/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.5771) |  Loss2: (0.0000) | Acc: (79.00%) (5216/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.5725) |  Loss2: (0.0000) | Acc: (80.00%) (6253/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.5785) |  Loss2: (0.0000) | Acc: (80.00%) (7271/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.5788) |  Loss2: (0.0000) | Acc: (80.00%) (8303/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.5758) |  Loss2: (0.0000) | Acc: (80.00%) (9349/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.5733) |  Loss2: (0.0000) | Acc: (80.00%) (10377/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.5757) |  Loss2: (0.0000) | Acc: (80.00%) (11394/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.5722) |  Loss2: (0.0000) | Acc: (80.00%) (12418/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.5714) |  Loss2: (0.0000) | Acc: (80.00%) (13445/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.5732) |  Loss2: (0.0000) | Acc: (80.00%) (14462/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.5729) |  Loss2: (0.0000) | Acc: (80.00%) (15499/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.5715) |  Loss2: (0.0000) | Acc: (80.00%) (16535/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.5720) |  Loss2: (0.0000) | Acc: (80.00%) (17559/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.5716) |  Loss2: (0.0000) | Acc: (80.00%) (18567/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.5690) |  Loss2: (0.0000) | Acc: (80.00%) (19608/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.5669) |  Loss2: (0.0000) | Acc: (80.00%) (20653/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.5672) |  Loss2: (0.0000) | Acc: (80.00%) (21692/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.5656) |  Loss2: (0.0000) | Acc: (80.00%) (22738/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.5668) |  Loss2: (0.0000) | Acc: (80.00%) (23762/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.5685) |  Loss2: (0.0000) | Acc: (80.00%) (24767/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.5675) |  Loss2: (0.0000) | Acc: (80.00%) (25801/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.5666) |  Loss2: (0.0000) | Acc: (80.00%) (26853/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.5656) |  Loss2: (0.0000) | Acc: (80.00%) (27914/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.5670) |  Loss2: (0.0000) | Acc: (80.00%) (28944/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.5667) |  Loss2: (0.0000) | Acc: (80.00%) (29985/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.5656) |  Loss2: (0.0000) | Acc: (80.00%) (31021/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.5642) |  Loss2: (0.0000) | Acc: (80.00%) (32071/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.5651) |  Loss2: (0.0000) | Acc: (80.00%) (33093/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.5664) |  Loss2: (0.0000) | Acc: (80.00%) (34104/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.5670) |  Loss2: (0.0000) | Acc: (80.00%) (35134/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.5682) |  Loss2: (0.0000) | Acc: (80.00%) (36129/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (37187/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.5680) |  Loss2: (0.0000) | Acc: (80.00%) (38194/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.5677) |  Loss2: (0.0000) | Acc: (80.00%) (39235/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.5682) |  Loss2: (0.0000) | Acc: (80.00%) (40209/50000)
# TEST : Loss: (0.6958) | Acc: (76.00%) (7682/10000)
percent tensor([0.5224, 0.5225, 0.5256, 0.5192, 0.5273, 0.5219, 0.5252, 0.5256, 0.5207,
        0.5234, 0.5214, 0.5273, 0.5234, 0.5138, 0.5242, 0.5206],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.4974, 0.4976, 0.4960, 0.4963, 0.4983, 0.4973, 0.4970, 0.4944,
        0.4961, 0.4964, 0.4990, 0.4984, 0.4929, 0.4997, 0.4977],
       device='cuda:0') torch.Size([16])
percent tensor([0.5121, 0.5329, 0.5271, 0.5270, 0.5395, 0.5298, 0.5284, 0.5296, 0.5238,
        0.5302, 0.5282, 0.5269, 0.5209, 0.5272, 0.5285, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.5460, 0.5433, 0.5498, 0.5477, 0.5521, 0.5346, 0.5527, 0.5511, 0.5503,
        0.5477, 0.5521, 0.5556, 0.5416, 0.5489, 0.5456, 0.5395],
       device='cuda:0') torch.Size([16])
percent tensor([0.5997, 0.5384, 0.6357, 0.6578, 0.6051, 0.6061, 0.5712, 0.6136, 0.6335,
        0.5701, 0.5911, 0.6097, 0.5644, 0.6112, 0.5616, 0.5784],
       device='cuda:0') torch.Size([16])
percent tensor([0.5859, 0.5710, 0.5909, 0.5923, 0.5916, 0.5863, 0.5903, 0.5912, 0.5892,
        0.5799, 0.5836, 0.6001, 0.5771, 0.5909, 0.5882, 0.5841],
       device='cuda:0') torch.Size([16])
percent tensor([0.5461, 0.5118, 0.5506, 0.5412, 0.5451, 0.6136, 0.5326, 0.4969, 0.5423,
        0.5236, 0.5449, 0.5305, 0.5003, 0.5915, 0.5120, 0.5442],
       device='cuda:0') torch.Size([16])
percent tensor([0.9948, 0.9912, 0.9976, 0.9946, 0.9942, 0.9897, 0.9947, 0.9980, 0.9892,
        0.9937, 0.9925, 0.9951, 0.9862, 0.9937, 0.9943, 0.9954],
       device='cuda:0') torch.Size([16])
Epoch: 32 | Batch_idx: 0 |  Loss: (0.5342) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.5131) |  Loss2: (0.0000) | Acc: (82.00%) (1160/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.5320) |  Loss2: (0.0000) | Acc: (82.00%) (2209/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5265) |  Loss2: (0.0000) | Acc: (82.00%) (3275/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5245) |  Loss2: (0.0000) | Acc: (82.00%) (4326/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.5354) |  Loss2: (0.0000) | Acc: (81.00%) (5349/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.5424) |  Loss2: (0.0000) | Acc: (81.00%) (6373/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.5351) |  Loss2: (0.0000) | Acc: (81.00%) (7436/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.5343) |  Loss2: (0.0000) | Acc: (81.00%) (8489/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.5372) |  Loss2: (0.0000) | Acc: (81.00%) (9517/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.5373) |  Loss2: (0.0000) | Acc: (81.00%) (10550/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.5347) |  Loss2: (0.0000) | Acc: (81.00%) (11594/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.5375) |  Loss2: (0.0000) | Acc: (81.00%) (12636/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.5406) |  Loss2: (0.0000) | Acc: (81.00%) (13663/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.5425) |  Loss2: (0.0000) | Acc: (81.00%) (14701/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.5406) |  Loss2: (0.0000) | Acc: (81.00%) (15747/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.5394) |  Loss2: (0.0000) | Acc: (81.00%) (16793/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.5414) |  Loss2: (0.0000) | Acc: (81.00%) (17811/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.5420) |  Loss2: (0.0000) | Acc: (81.00%) (18845/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.5428) |  Loss2: (0.0000) | Acc: (81.00%) (19880/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.5420) |  Loss2: (0.0000) | Acc: (81.00%) (20939/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.5418) |  Loss2: (0.0000) | Acc: (81.00%) (21954/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.5402) |  Loss2: (0.0000) | Acc: (81.00%) (23009/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.5394) |  Loss2: (0.0000) | Acc: (81.00%) (24042/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.5390) |  Loss2: (0.0000) | Acc: (81.00%) (25083/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.5401) |  Loss2: (0.0000) | Acc: (81.00%) (26114/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.5391) |  Loss2: (0.0000) | Acc: (81.00%) (27176/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.5379) |  Loss2: (0.0000) | Acc: (81.00%) (28233/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.5374) |  Loss2: (0.0000) | Acc: (81.00%) (29273/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.5382) |  Loss2: (0.0000) | Acc: (81.00%) (30309/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.5386) |  Loss2: (0.0000) | Acc: (81.00%) (31346/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.5380) |  Loss2: (0.0000) | Acc: (81.00%) (32395/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.5383) |  Loss2: (0.0000) | Acc: (81.00%) (33451/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.5387) |  Loss2: (0.0000) | Acc: (81.00%) (34500/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.5397) |  Loss2: (0.0000) | Acc: (81.00%) (35523/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.5406) |  Loss2: (0.0000) | Acc: (81.00%) (36549/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.5405) |  Loss2: (0.0000) | Acc: (81.00%) (37581/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.5405) |  Loss2: (0.0000) | Acc: (81.00%) (38616/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.5419) |  Loss2: (0.0000) | Acc: (81.00%) (39630/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.5414) |  Loss2: (0.0000) | Acc: (81.00%) (40644/50000)
# TEST : Loss: (0.6767) | Acc: (77.00%) (7727/10000)
percent tensor([0.5223, 0.5239, 0.5244, 0.5191, 0.5271, 0.5223, 0.5263, 0.5258, 0.5209,
        0.5243, 0.5223, 0.5269, 0.5240, 0.5156, 0.5249, 0.5209],
       device='cuda:0') torch.Size([16])
percent tensor([0.4989, 0.4979, 0.4976, 0.4960, 0.4966, 0.4988, 0.4976, 0.4972, 0.4947,
        0.4962, 0.4964, 0.4993, 0.4989, 0.4931, 0.4999, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5309, 0.5321, 0.5300, 0.5436, 0.5290, 0.5266, 0.5315, 0.5219,
        0.5305, 0.5275, 0.5309, 0.5213, 0.5220, 0.5284, 0.5239],
       device='cuda:0') torch.Size([16])
percent tensor([0.5480, 0.5474, 0.5518, 0.5502, 0.5532, 0.5340, 0.5565, 0.5536, 0.5531,
        0.5514, 0.5560, 0.5569, 0.5451, 0.5515, 0.5477, 0.5411],
       device='cuda:0') torch.Size([16])
percent tensor([0.6000, 0.5405, 0.6411, 0.6604, 0.6174, 0.6052, 0.5728, 0.6028, 0.6390,
        0.5737, 0.5993, 0.6098, 0.5700, 0.6131, 0.5607, 0.5749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5861, 0.5747, 0.5878, 0.5920, 0.5867, 0.5885, 0.5938, 0.5912, 0.5898,
        0.5819, 0.5831, 0.6031, 0.5802, 0.5932, 0.5883, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.5476, 0.5130, 0.5317, 0.5339, 0.5292, 0.6105, 0.5243, 0.4976, 0.5367,
        0.5305, 0.5488, 0.5368, 0.5044, 0.5920, 0.5208, 0.5394],
       device='cuda:0') torch.Size([16])
percent tensor([0.9974, 0.9947, 0.9978, 0.9971, 0.9960, 0.9884, 0.9982, 0.9986, 0.9922,
        0.9972, 0.9956, 0.9973, 0.9915, 0.9970, 0.9952, 0.9966],
       device='cuda:0') torch.Size([16])
Epoch: 33 | Batch_idx: 0 |  Loss: (0.5110) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.4879) |  Loss2: (0.0000) | Acc: (82.00%) (1165/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (82.00%) (2225/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5057) |  Loss2: (0.0000) | Acc: (81.00%) (3253/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5010) |  Loss2: (0.0000) | Acc: (82.00%) (4320/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5106) |  Loss2: (0.0000) | Acc: (82.00%) (5362/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5124) |  Loss2: (0.0000) | Acc: (82.00%) (6420/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5103) |  Loss2: (0.0000) | Acc: (82.00%) (7490/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5111) |  Loss2: (0.0000) | Acc: (82.00%) (8558/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5136) |  Loss2: (0.0000) | Acc: (82.00%) (9616/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5125) |  Loss2: (0.0000) | Acc: (82.00%) (10675/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5123) |  Loss2: (0.0000) | Acc: (82.00%) (11730/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5122) |  Loss2: (0.0000) | Acc: (82.00%) (12781/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5160) |  Loss2: (0.0000) | Acc: (82.00%) (13814/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5177) |  Loss2: (0.0000) | Acc: (82.00%) (14861/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5172) |  Loss2: (0.0000) | Acc: (82.00%) (15924/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5176) |  Loss2: (0.0000) | Acc: (82.00%) (16973/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5181) |  Loss2: (0.0000) | Acc: (82.00%) (18006/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5177) |  Loss2: (0.0000) | Acc: (82.00%) (19055/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5182) |  Loss2: (0.0000) | Acc: (82.00%) (20099/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5170) |  Loss2: (0.0000) | Acc: (82.00%) (21156/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5167) |  Loss2: (0.0000) | Acc: (82.00%) (22209/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5172) |  Loss2: (0.0000) | Acc: (82.00%) (23257/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5166) |  Loss2: (0.0000) | Acc: (82.00%) (24311/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5182) |  Loss2: (0.0000) | Acc: (82.00%) (25337/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5175) |  Loss2: (0.0000) | Acc: (82.00%) (26392/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5156) |  Loss2: (0.0000) | Acc: (82.00%) (27454/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5150) |  Loss2: (0.0000) | Acc: (82.00%) (28509/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5152) |  Loss2: (0.0000) | Acc: (82.00%) (29567/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (82.00%) (30611/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5149) |  Loss2: (0.0000) | Acc: (82.00%) (31664/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (32713/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5154) |  Loss2: (0.0000) | Acc: (82.00%) (33774/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5149) |  Loss2: (0.0000) | Acc: (82.00%) (34841/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5140) |  Loss2: (0.0000) | Acc: (82.00%) (35915/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5127) |  Loss2: (0.0000) | Acc: (82.00%) (36985/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5139) |  Loss2: (0.0000) | Acc: (82.00%) (38034/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5150) |  Loss2: (0.0000) | Acc: (82.00%) (39057/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5152) |  Loss2: (0.0000) | Acc: (82.00%) (40108/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5148) |  Loss2: (0.0000) | Acc: (82.00%) (41143/50000)
# TEST : Loss: (0.6631) | Acc: (77.00%) (7780/10000)
percent tensor([0.5220, 0.5238, 0.5241, 0.5194, 0.5266, 0.5217, 0.5260, 0.5263, 0.5210,
        0.5240, 0.5221, 0.5263, 0.5235, 0.5162, 0.5244, 0.5208],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.4976, 0.4977, 0.4954, 0.4964, 0.4978, 0.4975, 0.4970, 0.4951,
        0.4959, 0.4964, 0.4992, 0.4982, 0.4938, 0.4994, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.5129, 0.5303, 0.5274, 0.5286, 0.5408, 0.5282, 0.5245, 0.5289, 0.5206,
        0.5281, 0.5267, 0.5246, 0.5206, 0.5207, 0.5272, 0.5243],
       device='cuda:0') torch.Size([16])
percent tensor([0.5498, 0.5474, 0.5485, 0.5476, 0.5522, 0.5353, 0.5555, 0.5560, 0.5536,
        0.5498, 0.5577, 0.5536, 0.5469, 0.5522, 0.5486, 0.5425],
       device='cuda:0') torch.Size([16])
percent tensor([0.6044, 0.5455, 0.6259, 0.6569, 0.6107, 0.6000, 0.5703, 0.6178, 0.6371,
        0.5775, 0.5940, 0.6027, 0.5763, 0.6186, 0.5630, 0.5801],
       device='cuda:0') torch.Size([16])
percent tensor([0.5883, 0.5753, 0.5891, 0.5902, 0.5898, 0.5870, 0.5927, 0.5929, 0.5894,
        0.5800, 0.5820, 0.6025, 0.5793, 0.5945, 0.5871, 0.5845],
       device='cuda:0') torch.Size([16])
percent tensor([0.5367, 0.5099, 0.5366, 0.5348, 0.5364, 0.6032, 0.5243, 0.4935, 0.5380,
        0.5220, 0.5403, 0.5280, 0.4951, 0.5910, 0.5123, 0.5252],
       device='cuda:0') torch.Size([16])
percent tensor([0.9959, 0.9914, 0.9953, 0.9940, 0.9931, 0.9891, 0.9948, 0.9972, 0.9932,
        0.9954, 0.9934, 0.9958, 0.9908, 0.9940, 0.9920, 0.9958],
       device='cuda:0') torch.Size([16])
Epoch: 34 | Batch_idx: 0 |  Loss: (0.4614) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.4762) |  Loss2: (0.0000) | Acc: (83.00%) (1173/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (2228/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.4841) |  Loss2: (0.0000) | Acc: (83.00%) (3305/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.4833) |  Loss2: (0.0000) | Acc: (83.00%) (4377/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.4855) |  Loss2: (0.0000) | Acc: (83.00%) (5431/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.4868) |  Loss2: (0.0000) | Acc: (83.00%) (6488/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.4929) |  Loss2: (0.0000) | Acc: (82.00%) (7517/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.4939) |  Loss2: (0.0000) | Acc: (82.00%) (8575/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.4941) |  Loss2: (0.0000) | Acc: (82.00%) (9632/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.4949) |  Loss2: (0.0000) | Acc: (82.00%) (10686/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (82.00%) (11753/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.4970) |  Loss2: (0.0000) | Acc: (82.00%) (12789/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.4971) |  Loss2: (0.0000) | Acc: (82.00%) (13865/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.4980) |  Loss2: (0.0000) | Acc: (82.00%) (14932/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.4985) |  Loss2: (0.0000) | Acc: (82.00%) (15985/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.5010) |  Loss2: (0.0000) | Acc: (82.00%) (17023/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (18089/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.5008) |  Loss2: (0.0000) | Acc: (82.00%) (19139/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.5001) |  Loss2: (0.0000) | Acc: (82.00%) (20195/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.4989) |  Loss2: (0.0000) | Acc: (82.00%) (21262/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.4975) |  Loss2: (0.0000) | Acc: (82.00%) (22323/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (23348/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.5010) |  Loss2: (0.0000) | Acc: (82.00%) (24403/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.5005) |  Loss2: (0.0000) | Acc: (82.00%) (25478/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (26547/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.4981) |  Loss2: (0.0000) | Acc: (82.00%) (27621/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (28663/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.5001) |  Loss2: (0.0000) | Acc: (82.00%) (29712/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.4999) |  Loss2: (0.0000) | Acc: (82.00%) (30774/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.5003) |  Loss2: (0.0000) | Acc: (82.00%) (31826/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.5017) |  Loss2: (0.0000) | Acc: (82.00%) (32872/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.5011) |  Loss2: (0.0000) | Acc: (82.00%) (33952/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.5009) |  Loss2: (0.0000) | Acc: (82.00%) (35001/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (36081/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.5003) |  Loss2: (0.0000) | Acc: (82.00%) (37131/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.5006) |  Loss2: (0.0000) | Acc: (82.00%) (38175/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.4994) |  Loss2: (0.0000) | Acc: (82.00%) (39255/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.4986) |  Loss2: (0.0000) | Acc: (82.00%) (40331/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.4999) |  Loss2: (0.0000) | Acc: (82.00%) (41326/50000)
# TEST : Loss: (0.5917) | Acc: (80.00%) (8009/10000)
percent tensor([0.5217, 0.5239, 0.5247, 0.5193, 0.5270, 0.5214, 0.5262, 0.5265, 0.5212,
        0.5239, 0.5219, 0.5271, 0.5237, 0.5167, 0.5242, 0.5210],
       device='cuda:0') torch.Size([16])
percent tensor([0.4981, 0.4970, 0.4978, 0.4960, 0.4962, 0.4971, 0.4971, 0.4971, 0.4951,
        0.4956, 0.4963, 0.4992, 0.4984, 0.4933, 0.4992, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.5154, 0.5332, 0.5327, 0.5266, 0.5450, 0.5317, 0.5290, 0.5311, 0.5237,
        0.5314, 0.5295, 0.5302, 0.5228, 0.5210, 0.5306, 0.5261],
       device='cuda:0') torch.Size([16])
percent tensor([0.5490, 0.5471, 0.5529, 0.5497, 0.5538, 0.5354, 0.5568, 0.5541, 0.5529,
        0.5509, 0.5560, 0.5561, 0.5452, 0.5521, 0.5481, 0.5415],
       device='cuda:0') torch.Size([16])
percent tensor([0.6013, 0.5399, 0.6330, 0.6608, 0.6151, 0.6073, 0.5741, 0.6070, 0.6329,
        0.5687, 0.5897, 0.6054, 0.5678, 0.6085, 0.5618, 0.5771],
       device='cuda:0') torch.Size([16])
percent tensor([0.5847, 0.5760, 0.5906, 0.5936, 0.5900, 0.5817, 0.5945, 0.5925, 0.5884,
        0.5811, 0.5809, 0.6034, 0.5774, 0.5922, 0.5883, 0.5829],
       device='cuda:0') torch.Size([16])
percent tensor([0.5393, 0.5201, 0.5413, 0.5310, 0.5420, 0.5963, 0.5249, 0.4867, 0.5332,
        0.5288, 0.5447, 0.5389, 0.4988, 0.5856, 0.5120, 0.5247],
       device='cuda:0') torch.Size([16])
percent tensor([0.9927, 0.9907, 0.9967, 0.9959, 0.9960, 0.9883, 0.9955, 0.9986, 0.9938,
        0.9953, 0.9937, 0.9970, 0.9891, 0.9947, 0.9942, 0.9947],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 35 | Batch_idx: 0 |  Loss: (0.6429) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.5594) |  Loss2: (0.0000) | Acc: (82.00%) (1156/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.5871) |  Loss2: (0.0000) | Acc: (80.00%) (2161/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.6015) |  Loss2: (0.0000) | Acc: (79.00%) (3160/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.6024) |  Loss2: (0.0000) | Acc: (79.00%) (4177/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.6071) |  Loss2: (0.0000) | Acc: (79.00%) (5178/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.6000) |  Loss2: (0.0000) | Acc: (79.00%) (6205/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.5978) |  Loss2: (0.0000) | Acc: (79.00%) (7232/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.5974) |  Loss2: (0.0000) | Acc: (79.00%) (8241/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.6070) |  Loss2: (0.0000) | Acc: (79.00%) (9217/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.6045) |  Loss2: (0.0000) | Acc: (79.00%) (10237/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.6033) |  Loss2: (0.0000) | Acc: (79.00%) (11255/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.6004) |  Loss2: (0.0000) | Acc: (79.00%) (12280/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.5966) |  Loss2: (0.0000) | Acc: (79.00%) (13309/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.5946) |  Loss2: (0.0000) | Acc: (79.00%) (14327/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.5927) |  Loss2: (0.0000) | Acc: (79.00%) (15355/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.5915) |  Loss2: (0.0000) | Acc: (79.00%) (16387/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.5910) |  Loss2: (0.0000) | Acc: (79.00%) (17413/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.5902) |  Loss2: (0.0000) | Acc: (79.00%) (18442/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.5895) |  Loss2: (0.0000) | Acc: (79.00%) (19450/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.5881) |  Loss2: (0.0000) | Acc: (79.00%) (20481/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.5853) |  Loss2: (0.0000) | Acc: (79.00%) (21521/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.5830) |  Loss2: (0.0000) | Acc: (79.00%) (22555/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.5817) |  Loss2: (0.0000) | Acc: (79.00%) (23588/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.5818) |  Loss2: (0.0000) | Acc: (79.00%) (24606/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.5805) |  Loss2: (0.0000) | Acc: (79.00%) (25625/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.5796) |  Loss2: (0.0000) | Acc: (79.00%) (26641/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.5792) |  Loss2: (0.0000) | Acc: (79.00%) (27659/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.5783) |  Loss2: (0.0000) | Acc: (79.00%) (28683/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.5756) |  Loss2: (0.0000) | Acc: (79.00%) (29746/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.5738) |  Loss2: (0.0000) | Acc: (79.00%) (30788/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.5734) |  Loss2: (0.0000) | Acc: (79.00%) (31820/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.5730) |  Loss2: (0.0000) | Acc: (79.00%) (32851/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.5739) |  Loss2: (0.0000) | Acc: (79.00%) (33866/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.5735) |  Loss2: (0.0000) | Acc: (79.00%) (34878/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.5730) |  Loss2: (0.0000) | Acc: (79.00%) (35917/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.5706) |  Loss2: (0.0000) | Acc: (80.00%) (36985/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.5696) |  Loss2: (0.0000) | Acc: (80.00%) (38018/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.5691) |  Loss2: (0.0000) | Acc: (80.00%) (39051/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.5691) |  Loss2: (0.0000) | Acc: (80.00%) (40036/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_035.pth.tar'
# TEST : Loss: (0.6061) | Acc: (79.00%) (7977/10000)
percent tensor([0.5159, 0.5168, 0.5186, 0.5145, 0.5206, 0.5170, 0.5189, 0.5193, 0.5158,
        0.5166, 0.5157, 0.5194, 0.5169, 0.5119, 0.5180, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.4958, 0.4981, 0.4958, 0.4961, 0.4980, 0.4960, 0.4964, 0.4955,
        0.4953, 0.4965, 0.4980, 0.4981, 0.4932, 0.4987, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.5044, 0.5191, 0.5119, 0.5088, 0.5217, 0.5172, 0.5134, 0.5108, 0.5088,
        0.5153, 0.5143, 0.5138, 0.5133, 0.5071, 0.5174, 0.5116],
       device='cuda:0') torch.Size([16])
percent tensor([0.5402, 0.5394, 0.5388, 0.5389, 0.5405, 0.5283, 0.5459, 0.5404, 0.5432,
        0.5409, 0.5484, 0.5429, 0.5373, 0.5459, 0.5387, 0.5336],
       device='cuda:0') torch.Size([16])
percent tensor([0.5888, 0.5316, 0.5980, 0.6370, 0.5773, 0.6055, 0.5456, 0.5440, 0.6302,
        0.5569, 0.5977, 0.5842, 0.5699, 0.6241, 0.5351, 0.5582],
       device='cuda:0') torch.Size([16])
percent tensor([0.5774, 0.5678, 0.5928, 0.5914, 0.5872, 0.5689, 0.5844, 0.5975, 0.5827,
        0.5739, 0.5718, 0.6013, 0.5685, 0.5795, 0.5830, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.5503, 0.5144, 0.5527, 0.5479, 0.5471, 0.6027, 0.5182, 0.4854, 0.5334,
        0.5199, 0.5481, 0.5477, 0.4983, 0.5926, 0.5070, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.9966, 0.9914, 0.9981, 0.9969, 0.9969, 0.9916, 0.9950, 0.9988, 0.9944,
        0.9952, 0.9948, 0.9970, 0.9900, 0.9955, 0.9939, 0.9955],
       device='cuda:0') torch.Size([16])
Epoch: 36 | Batch_idx: 0 |  Loss: (0.5277) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.5169) |  Loss2: (0.0000) | Acc: (81.00%) (1143/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.5281) |  Loss2: (0.0000) | Acc: (81.00%) (2186/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.5201) |  Loss2: (0.0000) | Acc: (81.00%) (3242/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.5226) |  Loss2: (0.0000) | Acc: (81.00%) (4283/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.5237) |  Loss2: (0.0000) | Acc: (81.00%) (5323/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.5171) |  Loss2: (0.0000) | Acc: (81.00%) (6392/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.5154) |  Loss2: (0.0000) | Acc: (82.00%) (7457/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.5165) |  Loss2: (0.0000) | Acc: (82.00%) (8507/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.5181) |  Loss2: (0.0000) | Acc: (81.00%) (9536/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.5221) |  Loss2: (0.0000) | Acc: (81.00%) (10565/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.5245) |  Loss2: (0.0000) | Acc: (81.00%) (11589/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.5235) |  Loss2: (0.0000) | Acc: (81.00%) (12642/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.5248) |  Loss2: (0.0000) | Acc: (81.00%) (13669/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.5268) |  Loss2: (0.0000) | Acc: (81.00%) (14701/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.5285) |  Loss2: (0.0000) | Acc: (81.00%) (15736/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.5275) |  Loss2: (0.0000) | Acc: (81.00%) (16790/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.5242) |  Loss2: (0.0000) | Acc: (81.00%) (17870/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.5230) |  Loss2: (0.0000) | Acc: (81.00%) (18909/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.5228) |  Loss2: (0.0000) | Acc: (81.00%) (19962/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.5212) |  Loss2: (0.0000) | Acc: (81.00%) (21024/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.5208) |  Loss2: (0.0000) | Acc: (81.00%) (22084/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.5203) |  Loss2: (0.0000) | Acc: (81.00%) (23136/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.5197) |  Loss2: (0.0000) | Acc: (81.00%) (24196/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.5191) |  Loss2: (0.0000) | Acc: (81.00%) (25257/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.5189) |  Loss2: (0.0000) | Acc: (81.00%) (26300/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.5181) |  Loss2: (0.0000) | Acc: (81.00%) (27360/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.5175) |  Loss2: (0.0000) | Acc: (81.00%) (28424/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.5169) |  Loss2: (0.0000) | Acc: (81.00%) (29473/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.5143) |  Loss2: (0.0000) | Acc: (82.00%) (30564/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.5143) |  Loss2: (0.0000) | Acc: (82.00%) (31607/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.5138) |  Loss2: (0.0000) | Acc: (82.00%) (32670/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.5131) |  Loss2: (0.0000) | Acc: (82.00%) (33715/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.5148) |  Loss2: (0.0000) | Acc: (81.00%) (34741/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.5143) |  Loss2: (0.0000) | Acc: (82.00%) (35806/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.5147) |  Loss2: (0.0000) | Acc: (82.00%) (36867/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.5148) |  Loss2: (0.0000) | Acc: (82.00%) (37935/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.5148) |  Loss2: (0.0000) | Acc: (82.00%) (38990/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (40025/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5145) |  Loss2: (0.0000) | Acc: (82.00%) (41047/50000)
# TEST : Loss: (0.5677) | Acc: (81.00%) (8104/10000)
percent tensor([0.5147, 0.5149, 0.5166, 0.5134, 0.5188, 0.5162, 0.5169, 0.5175, 0.5149,
        0.5145, 0.5145, 0.5169, 0.5154, 0.5110, 0.5166, 0.5138],
       device='cuda:0') torch.Size([16])
percent tensor([0.4989, 0.4965, 0.4980, 0.4963, 0.4967, 0.4991, 0.4968, 0.4972, 0.4970,
        0.4961, 0.4977, 0.4981, 0.4990, 0.4948, 0.4989, 0.4982],
       device='cuda:0') torch.Size([16])
percent tensor([0.5060, 0.5220, 0.5105, 0.5091, 0.5215, 0.5188, 0.5153, 0.5097, 0.5095,
        0.5169, 0.5163, 0.5146, 0.5168, 0.5071, 0.5200, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5459, 0.5459, 0.5428, 0.5441, 0.5453, 0.5338, 0.5521, 0.5452, 0.5486,
        0.5468, 0.5554, 0.5475, 0.5430, 0.5538, 0.5449, 0.5395],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5296, 0.5911, 0.6385, 0.5673, 0.6113, 0.5385, 0.5264, 0.6375,
        0.5556, 0.6072, 0.5839, 0.5726, 0.6443, 0.5255, 0.5528],
       device='cuda:0') torch.Size([16])
percent tensor([0.5757, 0.5660, 0.5944, 0.5941, 0.5898, 0.5644, 0.5846, 0.6014, 0.5825,
        0.5724, 0.5693, 0.6029, 0.5655, 0.5778, 0.5839, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.5777, 0.5301, 0.5688, 0.5601, 0.5520, 0.6230, 0.5305, 0.4813, 0.5532,
        0.5368, 0.5748, 0.5719, 0.5188, 0.6243, 0.5197, 0.5422],
       device='cuda:0') torch.Size([16])
percent tensor([0.9974, 0.9930, 0.9985, 0.9976, 0.9975, 0.9931, 0.9959, 0.9990, 0.9953,
        0.9961, 0.9957, 0.9973, 0.9914, 0.9962, 0.9952, 0.9964],
       device='cuda:0') torch.Size([16])
Epoch: 37 | Batch_idx: 0 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.5387) |  Loss2: (0.0000) | Acc: (81.00%) (1152/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.5162) |  Loss2: (0.0000) | Acc: (82.00%) (2211/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.5029) |  Loss2: (0.0000) | Acc: (82.00%) (3273/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.5056) |  Loss2: (0.0000) | Acc: (82.00%) (4319/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.4997) |  Loss2: (0.0000) | Acc: (82.00%) (5372/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.5017) |  Loss2: (0.0000) | Acc: (82.00%) (6424/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.5003) |  Loss2: (0.0000) | Acc: (82.00%) (7488/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.5080) |  Loss2: (0.0000) | Acc: (82.00%) (8516/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.5075) |  Loss2: (0.0000) | Acc: (82.00%) (9576/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.5045) |  Loss2: (0.0000) | Acc: (82.00%) (10650/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.5027) |  Loss2: (0.0000) | Acc: (82.00%) (11715/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.5005) |  Loss2: (0.0000) | Acc: (82.00%) (12786/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.4975) |  Loss2: (0.0000) | Acc: (82.00%) (13844/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.4972) |  Loss2: (0.0000) | Acc: (82.00%) (14917/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.4991) |  Loss2: (0.0000) | Acc: (82.00%) (15951/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (82.00%) (17025/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.4962) |  Loss2: (0.0000) | Acc: (82.00%) (18095/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.4946) |  Loss2: (0.0000) | Acc: (82.00%) (19156/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.4949) |  Loss2: (0.0000) | Acc: (82.00%) (20214/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.4927) |  Loss2: (0.0000) | Acc: (82.00%) (21307/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.4932) |  Loss2: (0.0000) | Acc: (82.00%) (22353/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.4931) |  Loss2: (0.0000) | Acc: (82.00%) (23417/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.4924) |  Loss2: (0.0000) | Acc: (82.00%) (24487/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.4933) |  Loss2: (0.0000) | Acc: (82.00%) (25538/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.4923) |  Loss2: (0.0000) | Acc: (82.00%) (26603/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.4941) |  Loss2: (0.0000) | Acc: (82.00%) (27656/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.4934) |  Loss2: (0.0000) | Acc: (82.00%) (28716/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.4929) |  Loss2: (0.0000) | Acc: (82.00%) (29785/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.4916) |  Loss2: (0.0000) | Acc: (82.00%) (30876/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.4922) |  Loss2: (0.0000) | Acc: (82.00%) (31920/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.4927) |  Loss2: (0.0000) | Acc: (82.00%) (32968/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.4939) |  Loss2: (0.0000) | Acc: (82.00%) (34021/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.4940) |  Loss2: (0.0000) | Acc: (82.00%) (35073/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.4934) |  Loss2: (0.0000) | Acc: (82.00%) (36154/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.4924) |  Loss2: (0.0000) | Acc: (82.00%) (37235/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.4930) |  Loss2: (0.0000) | Acc: (82.00%) (38286/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.4932) |  Loss2: (0.0000) | Acc: (82.00%) (39335/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.4934) |  Loss2: (0.0000) | Acc: (82.00%) (40398/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.4936) |  Loss2: (0.0000) | Acc: (82.00%) (41414/50000)
# TEST : Loss: (0.5483) | Acc: (81.00%) (8139/10000)
percent tensor([0.5156, 0.5154, 0.5171, 0.5142, 0.5197, 0.5174, 0.5175, 0.5181, 0.5160,
        0.5147, 0.5153, 0.5169, 0.5162, 0.5117, 0.5175, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.4972, 0.4982, 0.4968, 0.4972, 0.4998, 0.4974, 0.4978, 0.4981,
        0.4967, 0.4986, 0.4983, 0.4996, 0.4960, 0.4991, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.5072, 0.5248, 0.5105, 0.5091, 0.5222, 0.5203, 0.5171, 0.5097, 0.5102,
        0.5187, 0.5183, 0.5159, 0.5198, 0.5073, 0.5226, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.5524, 0.5525, 0.5485, 0.5500, 0.5514, 0.5395, 0.5592, 0.5517, 0.5550,
        0.5533, 0.5625, 0.5537, 0.5492, 0.5614, 0.5516, 0.5456],
       device='cuda:0') torch.Size([16])
percent tensor([0.5855, 0.5271, 0.5894, 0.6410, 0.5635, 0.6179, 0.5355, 0.5185, 0.6426,
        0.5532, 0.6112, 0.5857, 0.5740, 0.6556, 0.5215, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5843, 0.5750, 0.6059, 0.6061, 0.6016, 0.5697, 0.5954, 0.6154, 0.5928,
        0.5818, 0.5777, 0.6152, 0.5740, 0.5862, 0.5951, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.6000, 0.5484, 0.5797, 0.5671, 0.5577, 0.6364, 0.5442, 0.4825, 0.5716,
        0.5562, 0.5964, 0.5922, 0.5397, 0.6453, 0.5347, 0.5545],
       device='cuda:0') torch.Size([16])
percent tensor([0.9979, 0.9947, 0.9989, 0.9981, 0.9981, 0.9941, 0.9968, 0.9992, 0.9965,
        0.9971, 0.9969, 0.9978, 0.9932, 0.9970, 0.9963, 0.9970],
       device='cuda:0') torch.Size([16])
Epoch: 38 | Batch_idx: 0 |  Loss: (0.4109) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.4738) |  Loss2: (0.0000) | Acc: (83.00%) (1173/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.4941) |  Loss2: (0.0000) | Acc: (82.00%) (2224/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.4753) |  Loss2: (0.0000) | Acc: (83.00%) (3322/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (83.00%) (4370/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.4857) |  Loss2: (0.0000) | Acc: (83.00%) (5420/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.4914) |  Loss2: (0.0000) | Acc: (82.00%) (6458/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.4956) |  Loss2: (0.0000) | Acc: (82.00%) (7515/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.4942) |  Loss2: (0.0000) | Acc: (82.00%) (8588/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.4939) |  Loss2: (0.0000) | Acc: (82.00%) (9647/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.4903) |  Loss2: (0.0000) | Acc: (82.00%) (10727/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.4901) |  Loss2: (0.0000) | Acc: (82.00%) (11780/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (12864/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.4887) |  Loss2: (0.0000) | Acc: (83.00%) (13922/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.4939) |  Loss2: (0.0000) | Acc: (82.00%) (14951/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.4922) |  Loss2: (0.0000) | Acc: (82.00%) (16037/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.4890) |  Loss2: (0.0000) | Acc: (83.00%) (17117/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.4892) |  Loss2: (0.0000) | Acc: (83.00%) (18189/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.4922) |  Loss2: (0.0000) | Acc: (82.00%) (19229/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.4908) |  Loss2: (0.0000) | Acc: (83.00%) (20304/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.4895) |  Loss2: (0.0000) | Acc: (83.00%) (21384/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.4881) |  Loss2: (0.0000) | Acc: (83.00%) (22465/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (23537/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (24594/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.4879) |  Loss2: (0.0000) | Acc: (83.00%) (25644/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (26712/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.4877) |  Loss2: (0.0000) | Acc: (83.00%) (27777/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.4884) |  Loss2: (0.0000) | Acc: (83.00%) (28824/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.4879) |  Loss2: (0.0000) | Acc: (83.00%) (29899/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.4886) |  Loss2: (0.0000) | Acc: (83.00%) (30947/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.4881) |  Loss2: (0.0000) | Acc: (83.00%) (32013/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.4873) |  Loss2: (0.0000) | Acc: (83.00%) (33089/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.4864) |  Loss2: (0.0000) | Acc: (83.00%) (34177/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.4870) |  Loss2: (0.0000) | Acc: (83.00%) (35233/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (36308/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.4876) |  Loss2: (0.0000) | Acc: (83.00%) (37363/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.4879) |  Loss2: (0.0000) | Acc: (83.00%) (38433/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.4872) |  Loss2: (0.0000) | Acc: (83.00%) (39511/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.4877) |  Loss2: (0.0000) | Acc: (83.00%) (40575/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.4885) |  Loss2: (0.0000) | Acc: (83.00%) (41588/50000)
# TEST : Loss: (0.5412) | Acc: (81.00%) (8174/10000)
percent tensor([0.5158, 0.5151, 0.5166, 0.5141, 0.5195, 0.5178, 0.5172, 0.5178, 0.5162,
        0.5142, 0.5155, 0.5162, 0.5163, 0.5116, 0.5175, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.4999, 0.4979, 0.4985, 0.4973, 0.4978, 0.5005, 0.4982, 0.4985, 0.4990,
        0.4973, 0.4994, 0.4988, 0.5004, 0.4969, 0.4996, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.5094, 0.5276, 0.5122, 0.5106, 0.5251, 0.5233, 0.5198, 0.5112, 0.5123,
        0.5209, 0.5209, 0.5190, 0.5232, 0.5083, 0.5259, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.5554, 0.5560, 0.5506, 0.5519, 0.5540, 0.5418, 0.5628, 0.5542, 0.5580,
        0.5566, 0.5659, 0.5563, 0.5524, 0.5653, 0.5548, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.5926, 0.5320, 0.5969, 0.6498, 0.5685, 0.6264, 0.5419, 0.5198, 0.6527,
        0.5582, 0.6204, 0.5993, 0.5838, 0.6676, 0.5285, 0.5523],
       device='cuda:0') torch.Size([16])
percent tensor([0.5894, 0.5805, 0.6137, 0.6142, 0.6100, 0.5723, 0.6028, 0.6251, 0.5993,
        0.5878, 0.5819, 0.6239, 0.5786, 0.5913, 0.6026, 0.5854],
       device='cuda:0') torch.Size([16])
percent tensor([0.6036, 0.5503, 0.5865, 0.5728, 0.5621, 0.6390, 0.5468, 0.4824, 0.5755,
        0.5579, 0.5973, 0.6000, 0.5406, 0.6498, 0.5370, 0.5562],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9957, 0.9990, 0.9983, 0.9983, 0.9948, 0.9975, 0.9993, 0.9972,
        0.9977, 0.9974, 0.9982, 0.9947, 0.9976, 0.9970, 0.9976],
       device='cuda:0') torch.Size([16])
Epoch: 39 | Batch_idx: 0 |  Loss: (0.5278) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.5000) |  Loss2: (0.0000) | Acc: (82.00%) (1162/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.5021) |  Loss2: (0.0000) | Acc: (82.00%) (2218/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.5010) |  Loss2: (0.0000) | Acc: (82.00%) (3267/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.4955) |  Loss2: (0.0000) | Acc: (82.00%) (4337/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.4979) |  Loss2: (0.0000) | Acc: (82.00%) (5378/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.4941) |  Loss2: (0.0000) | Acc: (82.00%) (6451/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.4974) |  Loss2: (0.0000) | Acc: (82.00%) (7495/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.4931) |  Loss2: (0.0000) | Acc: (82.00%) (8582/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.4920) |  Loss2: (0.0000) | Acc: (82.00%) (9653/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.4914) |  Loss2: (0.0000) | Acc: (82.00%) (10707/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.4890) |  Loss2: (0.0000) | Acc: (82.00%) (11776/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.4895) |  Loss2: (0.0000) | Acc: (82.00%) (12834/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.4899) |  Loss2: (0.0000) | Acc: (82.00%) (13900/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.4891) |  Loss2: (0.0000) | Acc: (82.00%) (14968/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.4883) |  Loss2: (0.0000) | Acc: (83.00%) (16048/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.4880) |  Loss2: (0.0000) | Acc: (83.00%) (17118/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.4897) |  Loss2: (0.0000) | Acc: (83.00%) (18168/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.4909) |  Loss2: (0.0000) | Acc: (82.00%) (19226/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.4920) |  Loss2: (0.0000) | Acc: (82.00%) (20287/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.4906) |  Loss2: (0.0000) | Acc: (83.00%) (21358/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.4875) |  Loss2: (0.0000) | Acc: (83.00%) (22456/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.4868) |  Loss2: (0.0000) | Acc: (83.00%) (23530/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.4866) |  Loss2: (0.0000) | Acc: (83.00%) (24596/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.4853) |  Loss2: (0.0000) | Acc: (83.00%) (25669/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.4860) |  Loss2: (0.0000) | Acc: (83.00%) (26712/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.4857) |  Loss2: (0.0000) | Acc: (83.00%) (27790/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.4854) |  Loss2: (0.0000) | Acc: (83.00%) (28874/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.4861) |  Loss2: (0.0000) | Acc: (83.00%) (29932/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.4860) |  Loss2: (0.0000) | Acc: (83.00%) (30990/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.4856) |  Loss2: (0.0000) | Acc: (83.00%) (32062/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.4850) |  Loss2: (0.0000) | Acc: (83.00%) (33137/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.4847) |  Loss2: (0.0000) | Acc: (83.00%) (34211/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.4835) |  Loss2: (0.0000) | Acc: (83.00%) (35304/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (83.00%) (36361/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.4831) |  Loss2: (0.0000) | Acc: (83.00%) (37450/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.4829) |  Loss2: (0.0000) | Acc: (83.00%) (38520/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (39617/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.4821) |  Loss2: (0.0000) | Acc: (83.00%) (40697/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.4817) |  Loss2: (0.0000) | Acc: (83.00%) (41720/50000)
# TEST : Loss: (0.5349) | Acc: (81.00%) (8176/10000)
percent tensor([0.5171, 0.5161, 0.5175, 0.5150, 0.5208, 0.5190, 0.5183, 0.5189, 0.5177,
        0.5151, 0.5168, 0.5171, 0.5177, 0.5125, 0.5187, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5002, 0.4983, 0.4987, 0.4976, 0.4981, 0.5009, 0.4986, 0.4990, 0.4996,
        0.4977, 0.5000, 0.4991, 0.5009, 0.4975, 0.4999, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5106, 0.5301, 0.5121, 0.5116, 0.5268, 0.5255, 0.5218, 0.5119, 0.5134,
        0.5225, 0.5225, 0.5200, 0.5253, 0.5097, 0.5285, 0.5180],
       device='cuda:0') torch.Size([16])
percent tensor([0.5586, 0.5597, 0.5528, 0.5544, 0.5567, 0.5441, 0.5666, 0.5568, 0.5609,
        0.5601, 0.5697, 0.5590, 0.5555, 0.5694, 0.5583, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.5941, 0.5347, 0.5974, 0.6521, 0.5692, 0.6292, 0.5445, 0.5199, 0.6536,
        0.5577, 0.6220, 0.6035, 0.5846, 0.6715, 0.5315, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.5905, 0.5825, 0.6166, 0.6174, 0.6138, 0.5724, 0.6058, 0.6288, 0.6022,
        0.5898, 0.5830, 0.6277, 0.5796, 0.5937, 0.6057, 0.5863],
       device='cuda:0') torch.Size([16])
percent tensor([0.6068, 0.5544, 0.5835, 0.5688, 0.5561, 0.6393, 0.5468, 0.4717, 0.5801,
        0.5604, 0.6024, 0.6044, 0.5458, 0.6560, 0.5370, 0.5548],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9964, 0.9992, 0.9986, 0.9986, 0.9957, 0.9979, 0.9994, 0.9977,
        0.9982, 0.9979, 0.9985, 0.9956, 0.9980, 0.9975, 0.9980],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 40 | Batch_idx: 0 |  Loss: (0.5769) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.4672) |  Loss2: (0.0000) | Acc: (83.00%) (1174/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.4764) |  Loss2: (0.0000) | Acc: (82.00%) (2226/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.4988) |  Loss2: (0.0000) | Acc: (82.00%) (3269/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.4876) |  Loss2: (0.0000) | Acc: (82.00%) (4352/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.4890) |  Loss2: (0.0000) | Acc: (82.00%) (5404/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.4897) |  Loss2: (0.0000) | Acc: (82.00%) (6458/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.4870) |  Loss2: (0.0000) | Acc: (82.00%) (7539/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.4888) |  Loss2: (0.0000) | Acc: (83.00%) (8610/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.4901) |  Loss2: (0.0000) | Acc: (82.00%) (9653/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.4895) |  Loss2: (0.0000) | Acc: (82.00%) (10724/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.4883) |  Loss2: (0.0000) | Acc: (83.00%) (11793/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (82.00%) (12852/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.4895) |  Loss2: (0.0000) | Acc: (82.00%) (13907/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.4881) |  Loss2: (0.0000) | Acc: (82.00%) (14974/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.4895) |  Loss2: (0.0000) | Acc: (82.00%) (16019/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.4885) |  Loss2: (0.0000) | Acc: (82.00%) (17085/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.4905) |  Loss2: (0.0000) | Acc: (82.00%) (18145/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.4906) |  Loss2: (0.0000) | Acc: (82.00%) (19215/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.4911) |  Loss2: (0.0000) | Acc: (82.00%) (20286/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.4903) |  Loss2: (0.0000) | Acc: (83.00%) (21365/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.4880) |  Loss2: (0.0000) | Acc: (83.00%) (22451/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.4897) |  Loss2: (0.0000) | Acc: (83.00%) (23494/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.4887) |  Loss2: (0.0000) | Acc: (83.00%) (24568/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.4872) |  Loss2: (0.0000) | Acc: (83.00%) (25635/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.4877) |  Loss2: (0.0000) | Acc: (83.00%) (26693/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.4877) |  Loss2: (0.0000) | Acc: (83.00%) (27759/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.4878) |  Loss2: (0.0000) | Acc: (83.00%) (28831/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.4878) |  Loss2: (0.0000) | Acc: (83.00%) (29906/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.4870) |  Loss2: (0.0000) | Acc: (83.00%) (30973/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.4856) |  Loss2: (0.0000) | Acc: (83.00%) (32067/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.4848) |  Loss2: (0.0000) | Acc: (83.00%) (33145/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (83.00%) (34228/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (83.00%) (35305/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (83.00%) (36379/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.4838) |  Loss2: (0.0000) | Acc: (83.00%) (37442/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.4833) |  Loss2: (0.0000) | Acc: (83.00%) (38517/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.4845) |  Loss2: (0.0000) | Acc: (83.00%) (39554/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.4854) |  Loss2: (0.0000) | Acc: (83.00%) (40596/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.4862) |  Loss2: (0.0000) | Acc: (83.00%) (41612/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_040.pth.tar'
# TEST : Loss: (0.5625) | Acc: (80.00%) (8039/10000)
percent tensor([0.5177, 0.5153, 0.5172, 0.5158, 0.5206, 0.5197, 0.5173, 0.5188, 0.5166,
        0.5145, 0.5167, 0.5163, 0.5176, 0.5101, 0.5188, 0.5154],
       device='cuda:0') torch.Size([16])
percent tensor([0.5002, 0.4981, 0.4980, 0.4974, 0.4973, 0.5014, 0.4981, 0.4984, 0.4992,
        0.4972, 0.4997, 0.4988, 0.5005, 0.4974, 0.4999, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5289, 0.5132, 0.5134, 0.5293, 0.5202, 0.5220, 0.5155, 0.5132,
        0.5215, 0.5213, 0.5209, 0.5240, 0.5132, 0.5249, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.5601, 0.5592, 0.5537, 0.5569, 0.5605, 0.5480, 0.5666, 0.5601, 0.5598,
        0.5604, 0.5712, 0.5599, 0.5560, 0.5658, 0.5600, 0.5545],
       device='cuda:0') torch.Size([16])
percent tensor([0.5788, 0.5341, 0.5963, 0.6487, 0.5694, 0.6157, 0.5469, 0.5295, 0.6438,
        0.5542, 0.6194, 0.6051, 0.5724, 0.6565, 0.5295, 0.5478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5898, 0.5811, 0.6212, 0.6219, 0.6241, 0.5825, 0.6074, 0.6287, 0.6033,
        0.5917, 0.5786, 0.6295, 0.5788, 0.5922, 0.6012, 0.5893],
       device='cuda:0') torch.Size([16])
percent tensor([0.6006, 0.5298, 0.5911, 0.5668, 0.5802, 0.6459, 0.5484, 0.4960, 0.5821,
        0.5522, 0.6039, 0.6046, 0.5411, 0.6528, 0.5296, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9974, 0.9991, 0.9983, 0.9978, 0.9960, 0.9985, 0.9993, 0.9980,
        0.9989, 0.9987, 0.9992, 0.9965, 0.9984, 0.9971, 0.9984],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.0956, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(796.0579, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(790.7094, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.0308, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(506.4567, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2184.8533, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4303.8892, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1417.9453, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6085.9028, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12076.4336, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4021.1465, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17056.0488, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 41 | Batch_idx: 0 |  Loss: (0.5073) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.5021) |  Loss2: (0.0000) | Acc: (81.00%) (1143/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.4721) |  Loss2: (0.0000) | Acc: (82.00%) (2221/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.4672) |  Loss2: (0.0000) | Acc: (83.00%) (3305/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.4661) |  Loss2: (0.0000) | Acc: (83.00%) (4372/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.4684) |  Loss2: (0.0000) | Acc: (83.00%) (5424/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.4667) |  Loss2: (0.0000) | Acc: (83.00%) (6500/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.4657) |  Loss2: (0.0000) | Acc: (83.00%) (7585/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.4593) |  Loss2: (0.0000) | Acc: (83.00%) (8691/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.4649) |  Loss2: (0.0000) | Acc: (83.00%) (9750/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.4647) |  Loss2: (0.0000) | Acc: (83.00%) (10836/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.4659) |  Loss2: (0.0000) | Acc: (83.00%) (11900/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.4654) |  Loss2: (0.0000) | Acc: (83.00%) (12971/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.4626) |  Loss2: (0.0000) | Acc: (83.00%) (14064/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.4627) |  Loss2: (0.0000) | Acc: (83.00%) (15148/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.4652) |  Loss2: (0.0000) | Acc: (83.00%) (16213/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.4646) |  Loss2: (0.0000) | Acc: (83.00%) (17295/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (83.00%) (18366/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.4637) |  Loss2: (0.0000) | Acc: (83.00%) (19453/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.4632) |  Loss2: (0.0000) | Acc: (83.00%) (20525/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.4639) |  Loss2: (0.0000) | Acc: (83.00%) (21595/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.4653) |  Loss2: (0.0000) | Acc: (83.00%) (22651/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.4664) |  Loss2: (0.0000) | Acc: (83.00%) (23717/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.4675) |  Loss2: (0.0000) | Acc: (83.00%) (24771/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.4678) |  Loss2: (0.0000) | Acc: (83.00%) (25838/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.4681) |  Loss2: (0.0000) | Acc: (83.00%) (26899/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.4694) |  Loss2: (0.0000) | Acc: (83.00%) (27949/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.4689) |  Loss2: (0.0000) | Acc: (83.00%) (29041/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.4677) |  Loss2: (0.0000) | Acc: (83.00%) (30127/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.4674) |  Loss2: (0.0000) | Acc: (83.00%) (31208/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.4664) |  Loss2: (0.0000) | Acc: (83.00%) (32291/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.4656) |  Loss2: (0.0000) | Acc: (83.00%) (33371/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (83.00%) (34451/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (83.00%) (35538/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.4641) |  Loss2: (0.0000) | Acc: (83.00%) (36634/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.4640) |  Loss2: (0.0000) | Acc: (83.00%) (37715/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.4642) |  Loss2: (0.0000) | Acc: (83.00%) (38790/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.4639) |  Loss2: (0.0000) | Acc: (83.00%) (39862/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.4648) |  Loss2: (0.0000) | Acc: (83.00%) (40923/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (83.00%) (41962/50000)
# TEST : Loss: (0.5280) | Acc: (82.00%) (8219/10000)
percent tensor([0.5176, 0.5160, 0.5173, 0.5159, 0.5211, 0.5199, 0.5185, 0.5189, 0.5173,
        0.5153, 0.5173, 0.5163, 0.5179, 0.5122, 0.5191, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.5004, 0.4984, 0.4984, 0.4977, 0.4978, 0.5015, 0.4984, 0.4985, 0.4994,
        0.4976, 0.4999, 0.4992, 0.5008, 0.4978, 0.5004, 0.5004],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.5270, 0.5157, 0.5171, 0.5323, 0.5258, 0.5210, 0.5182, 0.5136,
        0.5215, 0.5213, 0.5198, 0.5242, 0.5099, 0.5272, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.5589, 0.5579, 0.5514, 0.5546, 0.5559, 0.5476, 0.5639, 0.5559, 0.5582,
        0.5588, 0.5697, 0.5563, 0.5535, 0.5682, 0.5586, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.5376, 0.6040, 0.6494, 0.5814, 0.6329, 0.5465, 0.5266, 0.6556,
        0.5602, 0.6281, 0.6124, 0.5773, 0.6590, 0.5344, 0.5559],
       device='cuda:0') torch.Size([16])
percent tensor([0.5931, 0.5838, 0.6138, 0.6152, 0.6133, 0.5794, 0.6049, 0.6266, 0.6080,
        0.5906, 0.5838, 0.6274, 0.5832, 0.5951, 0.6064, 0.5877],
       device='cuda:0') torch.Size([16])
percent tensor([0.5914, 0.5445, 0.5775, 0.5627, 0.5583, 0.6384, 0.5507, 0.4945, 0.5849,
        0.5581, 0.6018, 0.5942, 0.5489, 0.6485, 0.5287, 0.5671],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9968, 0.9993, 0.9978, 0.9979, 0.9959, 0.9981, 0.9994, 0.9971,
        0.9982, 0.9978, 0.9985, 0.9944, 0.9979, 0.9977, 0.9985],
       device='cuda:0') torch.Size([16])
Epoch: 42 | Batch_idx: 0 |  Loss: (0.4476) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4239) |  Loss2: (0.0000) | Acc: (84.00%) (1191/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.4408) |  Loss2: (0.0000) | Acc: (84.00%) (2258/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.4277) |  Loss2: (0.0000) | Acc: (84.00%) (3350/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.4330) |  Loss2: (0.0000) | Acc: (84.00%) (4423/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.4322) |  Loss2: (0.0000) | Acc: (84.00%) (5518/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.4337) |  Loss2: (0.0000) | Acc: (84.00%) (6603/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.4414) |  Loss2: (0.0000) | Acc: (84.00%) (7662/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.4348) |  Loss2: (0.0000) | Acc: (84.00%) (8778/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.4335) |  Loss2: (0.0000) | Acc: (84.00%) (9875/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.4311) |  Loss2: (0.0000) | Acc: (84.00%) (10974/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4315) |  Loss2: (0.0000) | Acc: (84.00%) (12047/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4339) |  Loss2: (0.0000) | Acc: (84.00%) (13128/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4345) |  Loss2: (0.0000) | Acc: (84.00%) (14219/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4361) |  Loss2: (0.0000) | Acc: (84.00%) (15306/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4393) |  Loss2: (0.0000) | Acc: (84.00%) (16360/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (84.00%) (17458/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4404) |  Loss2: (0.0000) | Acc: (84.00%) (18527/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4420) |  Loss2: (0.0000) | Acc: (84.00%) (19590/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.4443) |  Loss2: (0.0000) | Acc: (84.00%) (20661/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.4448) |  Loss2: (0.0000) | Acc: (84.00%) (21748/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.4466) |  Loss2: (0.0000) | Acc: (84.00%) (22816/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.4472) |  Loss2: (0.0000) | Acc: (84.00%) (23897/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.4480) |  Loss2: (0.0000) | Acc: (84.00%) (24971/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (26053/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.4472) |  Loss2: (0.0000) | Acc: (84.00%) (27147/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.4466) |  Loss2: (0.0000) | Acc: (84.00%) (28238/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4470) |  Loss2: (0.0000) | Acc: (84.00%) (29316/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (30383/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4466) |  Loss2: (0.0000) | Acc: (84.00%) (31479/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (32543/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4471) |  Loss2: (0.0000) | Acc: (84.00%) (33645/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4475) |  Loss2: (0.0000) | Acc: (84.00%) (34707/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (35796/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4490) |  Loss2: (0.0000) | Acc: (84.00%) (36858/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4494) |  Loss2: (0.0000) | Acc: (84.00%) (37944/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4494) |  Loss2: (0.0000) | Acc: (84.00%) (39011/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4499) |  Loss2: (0.0000) | Acc: (84.00%) (40091/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4486) |  Loss2: (0.0000) | Acc: (84.00%) (41209/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (42270/50000)
# TEST : Loss: (0.5669) | Acc: (81.00%) (8164/10000)
percent tensor([0.5174, 0.5161, 0.5177, 0.5161, 0.5210, 0.5187, 0.5185, 0.5190, 0.5171,
        0.5156, 0.5172, 0.5171, 0.5178, 0.5116, 0.5189, 0.5158],
       device='cuda:0') torch.Size([16])
percent tensor([0.4999, 0.4980, 0.4977, 0.4972, 0.4969, 0.5009, 0.4979, 0.4986, 0.4991,
        0.4968, 0.4993, 0.4986, 0.5002, 0.4977, 0.5000, 0.4999],
       device='cuda:0') torch.Size([16])
percent tensor([0.5096, 0.5304, 0.5126, 0.5128, 0.5264, 0.5201, 0.5228, 0.5146, 0.5140,
        0.5234, 0.5213, 0.5173, 0.5238, 0.5150, 0.5256, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.5603, 0.5539, 0.5555, 0.5585, 0.5488, 0.5661, 0.5590, 0.5608,
        0.5607, 0.5730, 0.5593, 0.5583, 0.5675, 0.5613, 0.5539],
       device='cuda:0') torch.Size([16])
percent tensor([0.5769, 0.5264, 0.6006, 0.6444, 0.5690, 0.6243, 0.5432, 0.5277, 0.6477,
        0.5533, 0.6124, 0.5977, 0.5677, 0.6556, 0.5282, 0.5495],
       device='cuda:0') torch.Size([16])
percent tensor([0.5895, 0.5784, 0.6098, 0.6139, 0.6111, 0.5766, 0.6023, 0.6241, 0.6006,
        0.5883, 0.5782, 0.6233, 0.5788, 0.5900, 0.6000, 0.5862],
       device='cuda:0') torch.Size([16])
percent tensor([0.5946, 0.5005, 0.5874, 0.5557, 0.5449, 0.6493, 0.5381, 0.4771, 0.5750,
        0.5262, 0.5872, 0.5756, 0.5271, 0.6312, 0.5122, 0.5489],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9970, 0.9991, 0.9981, 0.9986, 0.9966, 0.9987, 0.9994, 0.9975,
        0.9987, 0.9990, 0.9989, 0.9963, 0.9989, 0.9982, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 43 | Batch_idx: 0 |  Loss: (0.4191) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4324) |  Loss2: (0.0000) | Acc: (84.00%) (1193/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4328) |  Loss2: (0.0000) | Acc: (84.00%) (2276/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4224) |  Loss2: (0.0000) | Acc: (85.00%) (3374/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4322) |  Loss2: (0.0000) | Acc: (84.00%) (4448/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4252) |  Loss2: (0.0000) | Acc: (84.00%) (5545/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (85.00%) (6649/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4185) |  Loss2: (0.0000) | Acc: (85.00%) (7745/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4178) |  Loss2: (0.0000) | Acc: (85.00%) (8836/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4185) |  Loss2: (0.0000) | Acc: (85.00%) (9930/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4158) |  Loss2: (0.0000) | Acc: (85.00%) (11027/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4187) |  Loss2: (0.0000) | Acc: (85.00%) (12105/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (13206/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4195) |  Loss2: (0.0000) | Acc: (85.00%) (14306/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4178) |  Loss2: (0.0000) | Acc: (85.00%) (15420/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (16502/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (17595/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4230) |  Loss2: (0.0000) | Acc: (85.00%) (18666/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4244) |  Loss2: (0.0000) | Acc: (85.00%) (19762/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4262) |  Loss2: (0.0000) | Acc: (85.00%) (20836/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4264) |  Loss2: (0.0000) | Acc: (85.00%) (21923/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4265) |  Loss2: (0.0000) | Acc: (85.00%) (23013/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4262) |  Loss2: (0.0000) | Acc: (85.00%) (24108/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4244) |  Loss2: (0.0000) | Acc: (85.00%) (25226/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4262) |  Loss2: (0.0000) | Acc: (85.00%) (26300/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4267) |  Loss2: (0.0000) | Acc: (85.00%) (27385/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (85.00%) (28464/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4269) |  Loss2: (0.0000) | Acc: (85.00%) (29581/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4281) |  Loss2: (0.0000) | Acc: (85.00%) (30662/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4282) |  Loss2: (0.0000) | Acc: (85.00%) (31752/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4283) |  Loss2: (0.0000) | Acc: (85.00%) (32822/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (85.00%) (33934/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4279) |  Loss2: (0.0000) | Acc: (85.00%) (35012/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4284) |  Loss2: (0.0000) | Acc: (85.00%) (36105/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4280) |  Loss2: (0.0000) | Acc: (85.00%) (37207/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4275) |  Loss2: (0.0000) | Acc: (85.00%) (38308/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4283) |  Loss2: (0.0000) | Acc: (85.00%) (39393/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4280) |  Loss2: (0.0000) | Acc: (85.00%) (40491/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4296) |  Loss2: (0.0000) | Acc: (85.00%) (41563/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4299) |  Loss2: (0.0000) | Acc: (85.00%) (42604/50000)
# TEST : Loss: (0.6061) | Acc: (79.00%) (7974/10000)
percent tensor([0.5181, 0.5166, 0.5166, 0.5160, 0.5203, 0.5198, 0.5187, 0.5187, 0.5185,
        0.5153, 0.5182, 0.5161, 0.5187, 0.5134, 0.5194, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.5002, 0.4987, 0.4977, 0.4975, 0.4973, 0.5015, 0.4985, 0.4987, 0.4991,
        0.4974, 0.4997, 0.4983, 0.5005, 0.4981, 0.5004, 0.5005],
       device='cuda:0') torch.Size([16])
percent tensor([0.5102, 0.5265, 0.5148, 0.5124, 0.5295, 0.5234, 0.5211, 0.5149, 0.5135,
        0.5218, 0.5205, 0.5201, 0.5236, 0.5110, 0.5255, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5594, 0.5586, 0.5537, 0.5554, 0.5579, 0.5482, 0.5649, 0.5583, 0.5585,
        0.5604, 0.5686, 0.5596, 0.5544, 0.5675, 0.5603, 0.5524],
       device='cuda:0') torch.Size([16])
percent tensor([0.5655, 0.5169, 0.5868, 0.6271, 0.5687, 0.6168, 0.5339, 0.5259, 0.6322,
        0.5383, 0.6081, 0.5827, 0.5540, 0.6470, 0.5270, 0.5372],
       device='cuda:0') torch.Size([16])
percent tensor([0.5967, 0.5834, 0.6141, 0.6149, 0.6139, 0.5855, 0.6080, 0.6275, 0.6148,
        0.5947, 0.5871, 0.6320, 0.5874, 0.5970, 0.6072, 0.5927],
       device='cuda:0') torch.Size([16])
percent tensor([0.5991, 0.5627, 0.5899, 0.5675, 0.5556, 0.6419, 0.5644, 0.4939, 0.5916,
        0.5645, 0.6097, 0.5772, 0.5559, 0.6505, 0.5426, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.9983, 0.9964, 0.9995, 0.9989, 0.9980, 0.9961, 0.9971, 0.9995, 0.9981,
        0.9990, 0.9972, 0.9993, 0.9951, 0.9979, 0.9981, 0.9984],
       device='cuda:0') torch.Size([16])
Epoch: 44 | Batch_idx: 0 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.4436) |  Loss2: (0.0000) | Acc: (84.00%) (1189/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.4277) |  Loss2: (0.0000) | Acc: (84.00%) (2282/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.4198) |  Loss2: (0.0000) | Acc: (85.00%) (3383/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.4176) |  Loss2: (0.0000) | Acc: (85.00%) (4484/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.4277) |  Loss2: (0.0000) | Acc: (85.00%) (5574/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.4268) |  Loss2: (0.0000) | Acc: (85.00%) (6668/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.4250) |  Loss2: (0.0000) | Acc: (85.00%) (7780/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.4285) |  Loss2: (0.0000) | Acc: (85.00%) (8852/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.4274) |  Loss2: (0.0000) | Acc: (85.00%) (9945/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.4256) |  Loss2: (0.0000) | Acc: (85.00%) (11054/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.4272) |  Loss2: (0.0000) | Acc: (85.00%) (12138/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (13219/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.4263) |  Loss2: (0.0000) | Acc: (85.00%) (14319/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.4267) |  Loss2: (0.0000) | Acc: (85.00%) (15410/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.4288) |  Loss2: (0.0000) | Acc: (85.00%) (16480/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.4288) |  Loss2: (0.0000) | Acc: (85.00%) (17566/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.4269) |  Loss2: (0.0000) | Acc: (85.00%) (18665/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (19751/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.4262) |  Loss2: (0.0000) | Acc: (85.00%) (20837/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.4253) |  Loss2: (0.0000) | Acc: (85.00%) (21930/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.4246) |  Loss2: (0.0000) | Acc: (85.00%) (23025/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.4238) |  Loss2: (0.0000) | Acc: (85.00%) (24130/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.4218) |  Loss2: (0.0000) | Acc: (85.00%) (25232/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (26330/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.4210) |  Loss2: (0.0000) | Acc: (85.00%) (27427/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.4198) |  Loss2: (0.0000) | Acc: (85.00%) (28529/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (29611/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.4209) |  Loss2: (0.0000) | Acc: (85.00%) (30706/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (31802/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.4207) |  Loss2: (0.0000) | Acc: (85.00%) (32906/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (85.00%) (33997/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (35110/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (36219/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.4206) |  Loss2: (0.0000) | Acc: (85.00%) (37309/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.4216) |  Loss2: (0.0000) | Acc: (85.00%) (38385/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (39488/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.4216) |  Loss2: (0.0000) | Acc: (85.00%) (40588/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (41707/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.4209) |  Loss2: (0.0000) | Acc: (85.00%) (42760/50000)
# TEST : Loss: (0.4955) | Acc: (83.00%) (8328/10000)
percent tensor([0.5177, 0.5167, 0.5175, 0.5165, 0.5209, 0.5194, 0.5190, 0.5196, 0.5176,
        0.5157, 0.5177, 0.5167, 0.5181, 0.5128, 0.5193, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5002, 0.4987, 0.4979, 0.4980, 0.4970, 0.5013, 0.4984, 0.4991, 0.4990,
        0.4975, 0.4993, 0.4986, 0.5005, 0.4981, 0.5002, 0.5004],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5278, 0.5112, 0.5124, 0.5270, 0.5225, 0.5206, 0.5133, 0.5135,
        0.5213, 0.5214, 0.5171, 0.5246, 0.5144, 0.5253, 0.5154],
       device='cuda:0') torch.Size([16])
percent tensor([0.5583, 0.5563, 0.5560, 0.5556, 0.5595, 0.5508, 0.5638, 0.5561, 0.5582,
        0.5580, 0.5670, 0.5585, 0.5521, 0.5652, 0.5586, 0.5517],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.5223, 0.5955, 0.6331, 0.5766, 0.6236, 0.5330, 0.5183, 0.6229,
        0.5367, 0.5969, 0.5891, 0.5400, 0.6433, 0.5298, 0.5356],
       device='cuda:0') torch.Size([16])
percent tensor([0.5906, 0.5776, 0.6123, 0.6120, 0.6128, 0.5828, 0.6010, 0.6216, 0.6048,
        0.5898, 0.5787, 0.6291, 0.5809, 0.5895, 0.6033, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.5930, 0.5255, 0.5753, 0.5813, 0.5571, 0.6500, 0.5547, 0.4875, 0.5618,
        0.5356, 0.5814, 0.5686, 0.5274, 0.6385, 0.5340, 0.5772],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9965, 0.9989, 0.9985, 0.9981, 0.9948, 0.9982, 0.9994, 0.9976,
        0.9987, 0.9978, 0.9989, 0.9940, 0.9985, 0.9976, 0.9986],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 45 | Batch_idx: 0 |  Loss: (0.3550) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (84.00%) (1192/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4377) |  Loss2: (0.0000) | Acc: (84.00%) (2276/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4407) |  Loss2: (0.0000) | Acc: (84.00%) (3344/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.4413) |  Loss2: (0.0000) | Acc: (84.00%) (4427/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.4550) |  Loss2: (0.0000) | Acc: (83.00%) (5456/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.4496) |  Loss2: (0.0000) | Acc: (83.00%) (6540/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (83.00%) (7615/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.4545) |  Loss2: (0.0000) | Acc: (83.00%) (8703/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.4557) |  Loss2: (0.0000) | Acc: (84.00%) (9792/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.4561) |  Loss2: (0.0000) | Acc: (84.00%) (10883/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.4549) |  Loss2: (0.0000) | Acc: (84.00%) (11960/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.4569) |  Loss2: (0.0000) | Acc: (84.00%) (13025/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.4565) |  Loss2: (0.0000) | Acc: (84.00%) (14109/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.4555) |  Loss2: (0.0000) | Acc: (84.00%) (15181/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.4562) |  Loss2: (0.0000) | Acc: (84.00%) (16243/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.4538) |  Loss2: (0.0000) | Acc: (84.00%) (17328/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.4519) |  Loss2: (0.0000) | Acc: (84.00%) (18424/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.4526) |  Loss2: (0.0000) | Acc: (84.00%) (19500/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.4519) |  Loss2: (0.0000) | Acc: (84.00%) (20597/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.4515) |  Loss2: (0.0000) | Acc: (84.00%) (21680/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.4512) |  Loss2: (0.0000) | Acc: (84.00%) (22759/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.4496) |  Loss2: (0.0000) | Acc: (84.00%) (23851/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.4480) |  Loss2: (0.0000) | Acc: (84.00%) (24952/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.4475) |  Loss2: (0.0000) | Acc: (84.00%) (26043/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.4480) |  Loss2: (0.0000) | Acc: (84.00%) (27104/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.4476) |  Loss2: (0.0000) | Acc: (84.00%) (28199/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.4462) |  Loss2: (0.0000) | Acc: (84.00%) (29301/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.4447) |  Loss2: (0.0000) | Acc: (84.00%) (30405/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4441) |  Loss2: (0.0000) | Acc: (84.00%) (31500/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4439) |  Loss2: (0.0000) | Acc: (84.00%) (32581/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4438) |  Loss2: (0.0000) | Acc: (84.00%) (33655/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4437) |  Loss2: (0.0000) | Acc: (84.00%) (34727/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4427) |  Loss2: (0.0000) | Acc: (84.00%) (35818/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4419) |  Loss2: (0.0000) | Acc: (84.00%) (36910/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4413) |  Loss2: (0.0000) | Acc: (84.00%) (38016/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4411) |  Loss2: (0.0000) | Acc: (84.00%) (39105/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4408) |  Loss2: (0.0000) | Acc: (84.00%) (40192/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4401) |  Loss2: (0.0000) | Acc: (84.00%) (41276/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4395) |  Loss2: (0.0000) | Acc: (84.00%) (42324/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_045.pth.tar'
# TEST : Loss: (0.4954) | Acc: (83.00%) (8316/10000)
percent tensor([0.5215, 0.5213, 0.5201, 0.5200, 0.5238, 0.5229, 0.5230, 0.5235, 0.5215,
        0.5195, 0.5222, 0.5194, 0.5223, 0.5165, 0.5236, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.4980, 0.4959, 0.4952, 0.4956, 0.4942, 0.5002, 0.4954, 0.4963, 0.4964,
        0.4945, 0.4966, 0.4954, 0.4977, 0.4963, 0.4979, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.5056, 0.5262, 0.5260, 0.5198, 0.5468, 0.5206, 0.5277, 0.5297, 0.5178,
        0.5201, 0.5175, 0.5274, 0.5202, 0.5137, 0.5252, 0.5112],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.5509, 0.5498, 0.5512, 0.5526, 0.5452, 0.5579, 0.5500, 0.5524,
        0.5542, 0.5617, 0.5544, 0.5485, 0.5592, 0.5528, 0.5477],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5191, 0.6388, 0.6838, 0.6103, 0.6618, 0.5412, 0.5517, 0.6310,
        0.5500, 0.5983, 0.6133, 0.5428, 0.6450, 0.5346, 0.5606],
       device='cuda:0') torch.Size([16])
percent tensor([0.5754, 0.5664, 0.5857, 0.5888, 0.5855, 0.5643, 0.5850, 0.5915, 0.5896,
        0.5771, 0.5686, 0.6089, 0.5741, 0.5765, 0.5858, 0.5712],
       device='cuda:0') torch.Size([16])
percent tensor([0.6337, 0.5785, 0.6128, 0.6196, 0.5916, 0.6790, 0.6007, 0.5226, 0.6033,
        0.5870, 0.6238, 0.6141, 0.5703, 0.6774, 0.5646, 0.6053],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9965, 0.9989, 0.9985, 0.9987, 0.9942, 0.9986, 0.9995, 0.9978,
        0.9987, 0.9975, 0.9991, 0.9952, 0.9982, 0.9978, 0.9985],
       device='cuda:0') torch.Size([16])
Epoch: 46 | Batch_idx: 0 |  Loss: (0.4778) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.4368) |  Loss2: (0.0000) | Acc: (84.00%) (1196/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.4449) |  Loss2: (0.0000) | Acc: (84.00%) (2278/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.4428) |  Loss2: (0.0000) | Acc: (84.00%) (3357/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4397) |  Loss2: (0.0000) | Acc: (84.00%) (4449/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4369) |  Loss2: (0.0000) | Acc: (84.00%) (5534/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4366) |  Loss2: (0.0000) | Acc: (84.00%) (6636/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4370) |  Loss2: (0.0000) | Acc: (84.00%) (7715/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4356) |  Loss2: (0.0000) | Acc: (84.00%) (8804/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4319) |  Loss2: (0.0000) | Acc: (85.00%) (9914/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4282) |  Loss2: (0.0000) | Acc: (85.00%) (11013/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (12125/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4298) |  Loss2: (0.0000) | Acc: (85.00%) (13192/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4289) |  Loss2: (0.0000) | Acc: (85.00%) (14274/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (15365/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4256) |  Loss2: (0.0000) | Acc: (85.00%) (16488/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (17621/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4240) |  Loss2: (0.0000) | Acc: (85.00%) (18687/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4240) |  Loss2: (0.0000) | Acc: (85.00%) (19794/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4219) |  Loss2: (0.0000) | Acc: (85.00%) (20904/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4219) |  Loss2: (0.0000) | Acc: (85.00%) (22000/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4219) |  Loss2: (0.0000) | Acc: (85.00%) (23100/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (24198/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (25293/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4228) |  Loss2: (0.0000) | Acc: (85.00%) (26373/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4209) |  Loss2: (0.0000) | Acc: (85.00%) (27493/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4209) |  Loss2: (0.0000) | Acc: (85.00%) (28581/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (29685/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4184) |  Loss2: (0.0000) | Acc: (85.00%) (30795/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4181) |  Loss2: (0.0000) | Acc: (85.00%) (31890/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4179) |  Loss2: (0.0000) | Acc: (85.00%) (32999/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4174) |  Loss2: (0.0000) | Acc: (85.00%) (34104/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4164) |  Loss2: (0.0000) | Acc: (85.00%) (35221/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4169) |  Loss2: (0.0000) | Acc: (85.00%) (36318/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4163) |  Loss2: (0.0000) | Acc: (85.00%) (37415/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4155) |  Loss2: (0.0000) | Acc: (85.00%) (38542/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4161) |  Loss2: (0.0000) | Acc: (85.00%) (39645/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4150) |  Loss2: (0.0000) | Acc: (85.00%) (40749/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4156) |  Loss2: (0.0000) | Acc: (85.00%) (41827/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4155) |  Loss2: (0.0000) | Acc: (85.00%) (42871/50000)
# TEST : Loss: (0.4776) | Acc: (83.00%) (8363/10000)
percent tensor([0.5244, 0.5241, 0.5227, 0.5227, 0.5266, 0.5263, 0.5257, 0.5261, 0.5238,
        0.5221, 0.5251, 0.5217, 0.5250, 0.5187, 0.5268, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.4970, 0.4949, 0.4946, 0.4951, 0.4936, 0.5002, 0.4943, 0.4954, 0.4955,
        0.4936, 0.4956, 0.4944, 0.4966, 0.4955, 0.4971, 0.4971],
       device='cuda:0') torch.Size([16])
percent tensor([0.5025, 0.5228, 0.5252, 0.5169, 0.5487, 0.5159, 0.5272, 0.5312, 0.5157,
        0.5166, 0.5124, 0.5264, 0.5161, 0.5095, 0.5222, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.5568, 0.5543, 0.5510, 0.5528, 0.5543, 0.5462, 0.5612, 0.5520, 0.5549,
        0.5577, 0.5649, 0.5569, 0.5514, 0.5628, 0.5557, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.5782, 0.5135, 0.6373, 0.6856, 0.6142, 0.6555, 0.5359, 0.5572, 0.6249,
        0.5475, 0.5911, 0.6081, 0.5325, 0.6401, 0.5280, 0.5540],
       device='cuda:0') torch.Size([16])
percent tensor([0.5807, 0.5731, 0.5877, 0.5914, 0.5870, 0.5687, 0.5906, 0.5919, 0.5944,
        0.5833, 0.5755, 0.6132, 0.5805, 0.5845, 0.5893, 0.5757],
       device='cuda:0') torch.Size([16])
percent tensor([0.6448, 0.5810, 0.6335, 0.6354, 0.6132, 0.6933, 0.6122, 0.5393, 0.6094,
        0.5890, 0.6277, 0.6212, 0.5713, 0.6835, 0.5675, 0.6166],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9968, 0.9988, 0.9986, 0.9987, 0.9952, 0.9988, 0.9995, 0.9981,
        0.9989, 0.9978, 0.9991, 0.9956, 0.9985, 0.9979, 0.9986],
       device='cuda:0') torch.Size([16])
Epoch: 47 | Batch_idx: 0 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.4174) |  Loss2: (0.0000) | Acc: (85.00%) (1203/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.3986) |  Loss2: (0.0000) | Acc: (86.00%) (2326/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (3436/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4020) |  Loss2: (0.0000) | Acc: (86.00%) (4526/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (86.00%) (5618/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (6703/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4146) |  Loss2: (0.0000) | Acc: (85.00%) (7784/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4169) |  Loss2: (0.0000) | Acc: (85.00%) (8880/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4157) |  Loss2: (0.0000) | Acc: (85.00%) (9971/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4129) |  Loss2: (0.0000) | Acc: (85.00%) (11071/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4087) |  Loss2: (0.0000) | Acc: (85.00%) (12190/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (85.00%) (13295/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4042) |  Loss2: (0.0000) | Acc: (85.00%) (14400/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4061) |  Loss2: (0.0000) | Acc: (85.00%) (15495/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (85.00%) (16590/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4040) |  Loss2: (0.0000) | Acc: (85.00%) (17696/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (85.00%) (18801/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4050) |  Loss2: (0.0000) | Acc: (85.00%) (19895/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4051) |  Loss2: (0.0000) | Acc: (85.00%) (20992/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4050) |  Loss2: (0.0000) | Acc: (85.00%) (22100/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4043) |  Loss2: (0.0000) | Acc: (85.00%) (23200/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4031) |  Loss2: (0.0000) | Acc: (85.00%) (24314/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4033) |  Loss2: (0.0000) | Acc: (85.00%) (25416/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4031) |  Loss2: (0.0000) | Acc: (85.00%) (26522/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (85.00%) (27625/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (86.00%) (28731/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4022) |  Loss2: (0.0000) | Acc: (86.00%) (29845/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (86.00%) (30943/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (86.00%) (32058/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4040) |  Loss2: (0.0000) | Acc: (86.00%) (33147/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4038) |  Loss2: (0.0000) | Acc: (86.00%) (34247/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4034) |  Loss2: (0.0000) | Acc: (86.00%) (35364/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (36461/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4042) |  Loss2: (0.0000) | Acc: (86.00%) (37561/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (86.00%) (38666/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4042) |  Loss2: (0.0000) | Acc: (86.00%) (39776/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4035) |  Loss2: (0.0000) | Acc: (86.00%) (40884/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4024) |  Loss2: (0.0000) | Acc: (86.00%) (42016/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4023) |  Loss2: (0.0000) | Acc: (86.00%) (43074/50000)
# TEST : Loss: (0.4706) | Acc: (83.00%) (8389/10000)
percent tensor([0.5246, 0.5241, 0.5227, 0.5231, 0.5267, 0.5270, 0.5256, 0.5260, 0.5237,
        0.5220, 0.5253, 0.5216, 0.5249, 0.5188, 0.5271, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.4966, 0.4945, 0.4943, 0.4947, 0.4932, 0.5002, 0.4939, 0.4950, 0.4950,
        0.4931, 0.4952, 0.4939, 0.4961, 0.4953, 0.4967, 0.4968],
       device='cuda:0') torch.Size([16])
percent tensor([0.5016, 0.5204, 0.5277, 0.5185, 0.5525, 0.5155, 0.5276, 0.5346, 0.5154,
        0.5149, 0.5097, 0.5280, 0.5133, 0.5079, 0.5214, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5598, 0.5588, 0.5528, 0.5550, 0.5565, 0.5485, 0.5652, 0.5542, 0.5582,
        0.5617, 0.5692, 0.5600, 0.5554, 0.5670, 0.5594, 0.5535],
       device='cuda:0') torch.Size([16])
percent tensor([0.5724, 0.5141, 0.6321, 0.6822, 0.6118, 0.6507, 0.5337, 0.5545, 0.6214,
        0.5473, 0.5888, 0.6040, 0.5294, 0.6397, 0.5254, 0.5505],
       device='cuda:0') torch.Size([16])
percent tensor([0.5892, 0.5825, 0.5937, 0.5974, 0.5922, 0.5761, 0.5994, 0.5960, 0.6039,
        0.5927, 0.5860, 0.6223, 0.5907, 0.5960, 0.5967, 0.5830],
       device='cuda:0') torch.Size([16])
percent tensor([0.6423, 0.5715, 0.6356, 0.6344, 0.6131, 0.6982, 0.6061, 0.5325, 0.6054,
        0.5798, 0.6227, 0.6111, 0.5629, 0.6809, 0.5526, 0.6134],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9972, 0.9990, 0.9988, 0.9990, 0.9954, 0.9989, 0.9996, 0.9983,
        0.9990, 0.9980, 0.9992, 0.9959, 0.9986, 0.9982, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 48 | Batch_idx: 0 |  Loss: (0.3876) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.3987) |  Loss2: (0.0000) | Acc: (85.00%) (1207/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.4037) |  Loss2: (0.0000) | Acc: (85.00%) (2300/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.4053) |  Loss2: (0.0000) | Acc: (85.00%) (3393/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.3989) |  Loss2: (0.0000) | Acc: (85.00%) (4497/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.3913) |  Loss2: (0.0000) | Acc: (86.00%) (5627/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.3897) |  Loss2: (0.0000) | Acc: (86.00%) (6748/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (7844/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (8956/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.3894) |  Loss2: (0.0000) | Acc: (86.00%) (10074/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.3891) |  Loss2: (0.0000) | Acc: (86.00%) (11192/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (12277/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (13395/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.3946) |  Loss2: (0.0000) | Acc: (86.00%) (14500/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.3942) |  Loss2: (0.0000) | Acc: (86.00%) (15611/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.3965) |  Loss2: (0.0000) | Acc: (86.00%) (16708/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.3980) |  Loss2: (0.0000) | Acc: (86.00%) (17796/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.3978) |  Loss2: (0.0000) | Acc: (86.00%) (18900/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.3968) |  Loss2: (0.0000) | Acc: (86.00%) (20012/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.3965) |  Loss2: (0.0000) | Acc: (86.00%) (21118/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.3971) |  Loss2: (0.0000) | Acc: (86.00%) (22208/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.3978) |  Loss2: (0.0000) | Acc: (86.00%) (23304/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.3986) |  Loss2: (0.0000) | Acc: (86.00%) (24383/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.3982) |  Loss2: (0.0000) | Acc: (86.00%) (25492/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.3982) |  Loss2: (0.0000) | Acc: (86.00%) (26611/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.3975) |  Loss2: (0.0000) | Acc: (86.00%) (27733/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.3965) |  Loss2: (0.0000) | Acc: (86.00%) (28851/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.3971) |  Loss2: (0.0000) | Acc: (86.00%) (29953/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.3958) |  Loss2: (0.0000) | Acc: (86.00%) (31090/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.3957) |  Loss2: (0.0000) | Acc: (86.00%) (32202/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.3958) |  Loss2: (0.0000) | Acc: (86.00%) (33303/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.3954) |  Loss2: (0.0000) | Acc: (86.00%) (34426/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.3963) |  Loss2: (0.0000) | Acc: (86.00%) (35533/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.3956) |  Loss2: (0.0000) | Acc: (86.00%) (36661/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.3958) |  Loss2: (0.0000) | Acc: (86.00%) (37770/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.3956) |  Loss2: (0.0000) | Acc: (86.00%) (38875/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.3955) |  Loss2: (0.0000) | Acc: (86.00%) (39972/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.3949) |  Loss2: (0.0000) | Acc: (86.00%) (41082/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.3952) |  Loss2: (0.0000) | Acc: (86.00%) (42180/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.3945) |  Loss2: (0.0000) | Acc: (86.00%) (43270/50000)
# TEST : Loss: (0.4659) | Acc: (83.00%) (8397/10000)
percent tensor([0.5241, 0.5233, 0.5225, 0.5229, 0.5263, 0.5271, 0.5248, 0.5253, 0.5229,
        0.5213, 0.5247, 0.5209, 0.5240, 0.5181, 0.5267, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.4943, 0.4941, 0.4946, 0.4930, 0.5003, 0.4936, 0.4948, 0.4948,
        0.4928, 0.4950, 0.4936, 0.4959, 0.4951, 0.4965, 0.4966],
       device='cuda:0') torch.Size([16])
percent tensor([0.5003, 0.5200, 0.5280, 0.5176, 0.5533, 0.5133, 0.5289, 0.5365, 0.5156,
        0.5142, 0.5085, 0.5288, 0.5123, 0.5077, 0.5201, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5608, 0.5527, 0.5557, 0.5569, 0.5491, 0.5668, 0.5545, 0.5594,
        0.5634, 0.5714, 0.5609, 0.5569, 0.5692, 0.5609, 0.5548],
       device='cuda:0') torch.Size([16])
percent tensor([0.5700, 0.5167, 0.6302, 0.6809, 0.6122, 0.6477, 0.5345, 0.5552, 0.6214,
        0.5500, 0.5906, 0.6033, 0.5293, 0.6422, 0.5255, 0.5496],
       device='cuda:0') torch.Size([16])
percent tensor([0.5977, 0.5917, 0.6009, 0.6049, 0.5991, 0.5837, 0.6084, 0.6019, 0.6134,
        0.6020, 0.5962, 0.6318, 0.6003, 0.6067, 0.6043, 0.5904],
       device='cuda:0') torch.Size([16])
percent tensor([0.6403, 0.5663, 0.6402, 0.6353, 0.6176, 0.7021, 0.6032, 0.5305, 0.6043,
        0.5749, 0.6207, 0.6089, 0.5590, 0.6805, 0.5431, 0.6096],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9974, 0.9991, 0.9989, 0.9991, 0.9959, 0.9990, 0.9996, 0.9985,
        0.9991, 0.9983, 0.9992, 0.9963, 0.9987, 0.9983, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 49 | Batch_idx: 0 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.3523) |  Loss2: (0.0000) | Acc: (88.00%) (1240/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.3821) |  Loss2: (0.0000) | Acc: (87.00%) (2344/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.3826) |  Loss2: (0.0000) | Acc: (87.00%) (3467/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.3805) |  Loss2: (0.0000) | Acc: (87.00%) (4581/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.3851) |  Loss2: (0.0000) | Acc: (87.00%) (5687/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.3872) |  Loss2: (0.0000) | Acc: (87.00%) (6796/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.3838) |  Loss2: (0.0000) | Acc: (87.00%) (7915/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (87.00%) (9037/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (87.00%) (10154/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (87.00%) (11285/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (87.00%) (12402/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (87.00%) (13513/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.3838) |  Loss2: (0.0000) | Acc: (87.00%) (14613/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (87.00%) (15704/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.3853) |  Loss2: (0.0000) | Acc: (86.00%) (16811/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (87.00%) (17955/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (87.00%) (19064/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (87.00%) (20173/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (21258/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.3856) |  Loss2: (0.0000) | Acc: (86.00%) (22347/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.3851) |  Loss2: (0.0000) | Acc: (86.00%) (23469/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.3848) |  Loss2: (0.0000) | Acc: (86.00%) (24573/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (25682/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.3843) |  Loss2: (0.0000) | Acc: (86.00%) (26798/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.3842) |  Loss2: (0.0000) | Acc: (86.00%) (27912/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.3862) |  Loss2: (0.0000) | Acc: (86.00%) (28988/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.3858) |  Loss2: (0.0000) | Acc: (86.00%) (30107/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.3870) |  Loss2: (0.0000) | Acc: (86.00%) (31206/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.3858) |  Loss2: (0.0000) | Acc: (86.00%) (32329/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.3856) |  Loss2: (0.0000) | Acc: (86.00%) (33451/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.3861) |  Loss2: (0.0000) | Acc: (86.00%) (34567/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.3860) |  Loss2: (0.0000) | Acc: (86.00%) (35677/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.3858) |  Loss2: (0.0000) | Acc: (86.00%) (36786/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.3864) |  Loss2: (0.0000) | Acc: (86.00%) (37879/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.3867) |  Loss2: (0.0000) | Acc: (86.00%) (38983/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.3874) |  Loss2: (0.0000) | Acc: (86.00%) (40070/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.3869) |  Loss2: (0.0000) | Acc: (86.00%) (41191/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.3865) |  Loss2: (0.0000) | Acc: (86.00%) (42305/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (43368/50000)
# TEST : Loss: (0.4634) | Acc: (84.00%) (8409/10000)
percent tensor([0.5241, 0.5231, 0.5226, 0.5231, 0.5264, 0.5277, 0.5245, 0.5251, 0.5227,
        0.5211, 0.5247, 0.5206, 0.5239, 0.5180, 0.5270, 0.5234],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.4950, 0.4946, 0.4952, 0.4937, 0.5006, 0.4943, 0.4954, 0.4954,
        0.4935, 0.4956, 0.4942, 0.4964, 0.4959, 0.4971, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.4985, 0.5178, 0.5264, 0.5157, 0.5517, 0.5111, 0.5277, 0.5356, 0.5140,
        0.5117, 0.5062, 0.5272, 0.5098, 0.5067, 0.5178, 0.5011],
       device='cuda:0') torch.Size([16])
percent tensor([0.5638, 0.5646, 0.5548, 0.5583, 0.5591, 0.5514, 0.5704, 0.5572, 0.5626,
        0.5670, 0.5752, 0.5642, 0.5607, 0.5727, 0.5645, 0.5579],
       device='cuda:0') torch.Size([16])
percent tensor([0.5692, 0.5180, 0.6306, 0.6818, 0.6126, 0.6472, 0.5352, 0.5576, 0.6222,
        0.5509, 0.5917, 0.6048, 0.5305, 0.6447, 0.5265, 0.5503],
       device='cuda:0') torch.Size([16])
percent tensor([0.6024, 0.5972, 0.6043, 0.6081, 0.6015, 0.5878, 0.6134, 0.6029, 0.6191,
        0.6074, 0.6031, 0.6374, 0.6066, 0.6139, 0.6081, 0.5938],
       device='cuda:0') torch.Size([16])
percent tensor([0.6356, 0.5614, 0.6411, 0.6338, 0.6193, 0.7024, 0.6004, 0.5319, 0.5975,
        0.5687, 0.6152, 0.6016, 0.5506, 0.6744, 0.5358, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9978, 0.9992, 0.9991, 0.9993, 0.9964, 0.9991, 0.9997, 0.9987,
        0.9993, 0.9985, 0.9994, 0.9967, 0.9989, 0.9986, 0.9990],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 50 | Batch_idx: 0 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.3884) |  Loss2: (0.0000) | Acc: (86.00%) (1223/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.3805) |  Loss2: (0.0000) | Acc: (86.00%) (2334/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.3838) |  Loss2: (0.0000) | Acc: (86.00%) (3443/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.3969) |  Loss2: (0.0000) | Acc: (86.00%) (4530/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.3983) |  Loss2: (0.0000) | Acc: (86.00%) (5645/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (6755/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.3970) |  Loss2: (0.0000) | Acc: (86.00%) (7864/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.4011) |  Loss2: (0.0000) | Acc: (86.00%) (8959/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.4017) |  Loss2: (0.0000) | Acc: (86.00%) (10051/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.4042) |  Loss2: (0.0000) | Acc: (86.00%) (11127/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (85.00%) (12210/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.4061) |  Loss2: (0.0000) | Acc: (85.00%) (13308/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.4053) |  Loss2: (0.0000) | Acc: (85.00%) (14413/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.4038) |  Loss2: (0.0000) | Acc: (86.00%) (15524/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (85.00%) (16608/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (85.00%) (17721/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (18806/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (85.00%) (19922/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.4047) |  Loss2: (0.0000) | Acc: (86.00%) (21030/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (85.00%) (22118/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (23212/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (24319/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (85.00%) (25408/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (85.00%) (26493/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.4103) |  Loss2: (0.0000) | Acc: (85.00%) (27579/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.4108) |  Loss2: (0.0000) | Acc: (85.00%) (28668/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4110) |  Loss2: (0.0000) | Acc: (85.00%) (29756/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4103) |  Loss2: (0.0000) | Acc: (85.00%) (30857/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (31937/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4111) |  Loss2: (0.0000) | Acc: (85.00%) (33039/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4118) |  Loss2: (0.0000) | Acc: (85.00%) (34125/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4128) |  Loss2: (0.0000) | Acc: (85.00%) (35213/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4125) |  Loss2: (0.0000) | Acc: (85.00%) (36306/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (37425/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.4116) |  Loss2: (0.0000) | Acc: (85.00%) (38526/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4115) |  Loss2: (0.0000) | Acc: (85.00%) (39642/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4119) |  Loss2: (0.0000) | Acc: (85.00%) (40737/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (41835/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4112) |  Loss2: (0.0000) | Acc: (85.00%) (42894/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_050.pth.tar'
# TEST : Loss: (0.5171) | Acc: (82.00%) (8275/10000)
percent tensor([0.5247, 0.5230, 0.5228, 0.5229, 0.5279, 0.5286, 0.5248, 0.5249, 0.5233,
        0.5211, 0.5249, 0.5215, 0.5241, 0.5181, 0.5271, 0.5234],
       device='cuda:0') torch.Size([16])
percent tensor([0.4975, 0.4949, 0.4954, 0.4959, 0.4947, 0.5007, 0.4943, 0.4956, 0.4959,
        0.4939, 0.4963, 0.4950, 0.4970, 0.4953, 0.4974, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.5166, 0.5243, 0.5138, 0.5555, 0.5102, 0.5269, 0.5348, 0.5181,
        0.5117, 0.5068, 0.5275, 0.5088, 0.5055, 0.5177, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5615, 0.5660, 0.5548, 0.5550, 0.5579, 0.5483, 0.5700, 0.5552, 0.5604,
        0.5676, 0.5746, 0.5627, 0.5600, 0.5722, 0.5634, 0.5565],
       device='cuda:0') torch.Size([16])
percent tensor([0.5720, 0.5229, 0.6212, 0.6722, 0.6058, 0.6348, 0.5485, 0.5483, 0.6465,
        0.5529, 0.6038, 0.5992, 0.5363, 0.6752, 0.5239, 0.5625],
       device='cuda:0') torch.Size([16])
percent tensor([0.6017, 0.5965, 0.6083, 0.6067, 0.6086, 0.5888, 0.6155, 0.6050, 0.6187,
        0.6054, 0.6008, 0.6359, 0.6033, 0.6181, 0.6067, 0.5968],
       device='cuda:0') torch.Size([16])
percent tensor([0.6192, 0.5369, 0.6258, 0.6005, 0.6282, 0.6919, 0.6024, 0.5255, 0.6065,
        0.5415, 0.6234, 0.5847, 0.5351, 0.6655, 0.5197, 0.6145],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9980, 0.9993, 0.9990, 0.9992, 0.9974, 0.9990, 0.9996, 0.9989,
        0.9995, 0.9989, 0.9995, 0.9967, 0.9987, 0.9988, 0.9988],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(176.5536, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(800.6052, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(795.6917, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.9133, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(504.7851, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2192.3174, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4299.5205, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1412.7994, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6092.4644, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12035.3555, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4005.5679, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16986.0586, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 51 | Batch_idx: 0 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.4034) |  Loss2: (0.0000) | Acc: (86.00%) (1218/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.4007) |  Loss2: (0.0000) | Acc: (86.00%) (2317/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.3939) |  Loss2: (0.0000) | Acc: (86.00%) (3431/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.4095) |  Loss2: (0.0000) | Acc: (85.00%) (4506/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (85.00%) (5607/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.4043) |  Loss2: (0.0000) | Acc: (86.00%) (6723/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.4037) |  Loss2: (0.0000) | Acc: (86.00%) (7823/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (86.00%) (8921/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (86.00%) (10032/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.4007) |  Loss2: (0.0000) | Acc: (86.00%) (11156/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.4027) |  Loss2: (0.0000) | Acc: (86.00%) (12249/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (86.00%) (13345/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.4014) |  Loss2: (0.0000) | Acc: (86.00%) (14437/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.4018) |  Loss2: (0.0000) | Acc: (86.00%) (15547/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.4010) |  Loss2: (0.0000) | Acc: (86.00%) (16652/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.4016) |  Loss2: (0.0000) | Acc: (86.00%) (17742/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.4008) |  Loss2: (0.0000) | Acc: (86.00%) (18852/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.4007) |  Loss2: (0.0000) | Acc: (86.00%) (19956/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.3989) |  Loss2: (0.0000) | Acc: (86.00%) (21084/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.4007) |  Loss2: (0.0000) | Acc: (86.00%) (22176/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.3990) |  Loss2: (0.0000) | Acc: (86.00%) (23299/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.3979) |  Loss2: (0.0000) | Acc: (86.00%) (24397/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.3974) |  Loss2: (0.0000) | Acc: (86.00%) (25506/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.3963) |  Loss2: (0.0000) | Acc: (86.00%) (26627/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.3955) |  Loss2: (0.0000) | Acc: (86.00%) (27748/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.3944) |  Loss2: (0.0000) | Acc: (86.00%) (28861/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.3945) |  Loss2: (0.0000) | Acc: (86.00%) (29967/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.3948) |  Loss2: (0.0000) | Acc: (86.00%) (31072/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.3948) |  Loss2: (0.0000) | Acc: (86.00%) (32180/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.3936) |  Loss2: (0.0000) | Acc: (86.00%) (33305/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.3925) |  Loss2: (0.0000) | Acc: (86.00%) (34420/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (35536/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.3909) |  Loss2: (0.0000) | Acc: (86.00%) (36642/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.3913) |  Loss2: (0.0000) | Acc: (86.00%) (37748/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.3917) |  Loss2: (0.0000) | Acc: (86.00%) (38850/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.3916) |  Loss2: (0.0000) | Acc: (86.00%) (39957/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.3921) |  Loss2: (0.0000) | Acc: (86.00%) (41055/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.3924) |  Loss2: (0.0000) | Acc: (86.00%) (42153/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.3931) |  Loss2: (0.0000) | Acc: (86.00%) (43204/50000)
# TEST : Loss: (0.5722) | Acc: (81.00%) (8108/10000)
percent tensor([0.5241, 0.5225, 0.5240, 0.5235, 0.5289, 0.5290, 0.5247, 0.5251, 0.5220,
        0.5213, 0.5237, 0.5220, 0.5234, 0.5166, 0.5271, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.4974, 0.4946, 0.4946, 0.4951, 0.4942, 0.5008, 0.4941, 0.4952, 0.4963,
        0.4932, 0.4962, 0.4943, 0.4967, 0.4960, 0.4971, 0.4974],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5168, 0.5258, 0.5147, 0.5524, 0.5121, 0.5270, 0.5280, 0.5160,
        0.5109, 0.5081, 0.5255, 0.5089, 0.5061, 0.5181, 0.5019],
       device='cuda:0') torch.Size([16])
percent tensor([0.5661, 0.5682, 0.5554, 0.5572, 0.5593, 0.5509, 0.5723, 0.5585, 0.5676,
        0.5700, 0.5798, 0.5637, 0.5650, 0.5755, 0.5670, 0.5582],
       device='cuda:0') torch.Size([16])
percent tensor([0.5713, 0.5360, 0.6145, 0.6544, 0.6018, 0.6265, 0.5520, 0.5489, 0.6490,
        0.5634, 0.6167, 0.5974, 0.5531, 0.6758, 0.5277, 0.5585],
       device='cuda:0') torch.Size([16])
percent tensor([0.6042, 0.6029, 0.6067, 0.6093, 0.6025, 0.5877, 0.6199, 0.6082, 0.6228,
        0.6083, 0.6043, 0.6361, 0.6108, 0.6145, 0.6100, 0.5985],
       device='cuda:0') torch.Size([16])
percent tensor([0.6331, 0.5647, 0.6718, 0.6330, 0.6583, 0.6923, 0.6123, 0.5560, 0.6105,
        0.5756, 0.6274, 0.6183, 0.5453, 0.6678, 0.5524, 0.6108],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9986, 0.9996, 0.9992, 0.9992, 0.9978, 0.9990, 0.9995, 0.9995,
        0.9996, 0.9992, 0.9996, 0.9981, 0.9993, 0.9986, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 52 | Batch_idx: 0 |  Loss: (0.3373) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (87.00%) (1228/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.3668) |  Loss2: (0.0000) | Acc: (87.00%) (2350/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.3677) |  Loss2: (0.0000) | Acc: (87.00%) (3461/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (4596/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (5702/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3694) |  Loss2: (0.0000) | Acc: (87.00%) (6812/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3686) |  Loss2: (0.0000) | Acc: (87.00%) (7935/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3680) |  Loss2: (0.0000) | Acc: (87.00%) (9052/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3717) |  Loss2: (0.0000) | Acc: (87.00%) (10153/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3708) |  Loss2: (0.0000) | Acc: (87.00%) (11273/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (12398/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (87.00%) (13506/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (14614/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3718) |  Loss2: (0.0000) | Acc: (87.00%) (15734/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (16855/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (87.00%) (17985/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (87.00%) (19112/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (20205/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3731) |  Loss2: (0.0000) | Acc: (87.00%) (21319/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (87.00%) (22404/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (87.00%) (23525/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3758) |  Loss2: (0.0000) | Acc: (87.00%) (24629/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3762) |  Loss2: (0.0000) | Acc: (87.00%) (25742/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3765) |  Loss2: (0.0000) | Acc: (87.00%) (26854/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3775) |  Loss2: (0.0000) | Acc: (86.00%) (27950/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (29061/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3777) |  Loss2: (0.0000) | Acc: (86.00%) (30178/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (86.00%) (31284/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (86.00%) (32359/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3806) |  Loss2: (0.0000) | Acc: (86.00%) (33470/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (86.00%) (34590/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3812) |  Loss2: (0.0000) | Acc: (86.00%) (35696/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (36804/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3826) |  Loss2: (0.0000) | Acc: (86.00%) (37890/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (86.00%) (38994/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3836) |  Loss2: (0.0000) | Acc: (86.00%) (40089/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3843) |  Loss2: (0.0000) | Acc: (86.00%) (41187/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3856) |  Loss2: (0.0000) | Acc: (86.00%) (42286/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3853) |  Loss2: (0.0000) | Acc: (86.00%) (43361/50000)
# TEST : Loss: (0.4816) | Acc: (84.00%) (8402/10000)
percent tensor([0.5247, 0.5221, 0.5240, 0.5228, 0.5287, 0.5293, 0.5245, 0.5250, 0.5222,
        0.5210, 0.5243, 0.5221, 0.5238, 0.5160, 0.5273, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.4980, 0.4947, 0.4953, 0.4960, 0.4945, 0.5010, 0.4942, 0.4955, 0.4962,
        0.4937, 0.4963, 0.4948, 0.4969, 0.4956, 0.4974, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5005, 0.5173, 0.5259, 0.5238, 0.5535, 0.5140, 0.5268, 0.5356, 0.5147,
        0.5117, 0.5066, 0.5275, 0.5092, 0.5056, 0.5204, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5642, 0.5512, 0.5550, 0.5562, 0.5461, 0.5691, 0.5564, 0.5605,
        0.5656, 0.5751, 0.5604, 0.5594, 0.5715, 0.5631, 0.5551],
       device='cuda:0') torch.Size([16])
percent tensor([0.5696, 0.5213, 0.6110, 0.6716, 0.6038, 0.6249, 0.5514, 0.5544, 0.6392,
        0.5528, 0.6028, 0.5944, 0.5313, 0.6656, 0.5248, 0.5603],
       device='cuda:0') torch.Size([16])
percent tensor([0.5974, 0.5944, 0.6107, 0.6013, 0.6038, 0.5879, 0.6091, 0.6018, 0.6138,
        0.6008, 0.5975, 0.6352, 0.6010, 0.6122, 0.6030, 0.5911],
       device='cuda:0') torch.Size([16])
percent tensor([0.6320, 0.5606, 0.6595, 0.6264, 0.6424, 0.7036, 0.6068, 0.5335, 0.6242,
        0.5563, 0.6185, 0.5909, 0.5643, 0.6793, 0.5442, 0.6090],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9978, 0.9997, 0.9990, 0.9985, 0.9976, 0.9988, 0.9996, 0.9989,
        0.9992, 0.9988, 0.9996, 0.9968, 0.9990, 0.9991, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 53 | Batch_idx: 0 |  Loss: (0.3465) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.3425) |  Loss2: (0.0000) | Acc: (88.00%) (1246/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.3473) |  Loss2: (0.0000) | Acc: (88.00%) (2366/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.3417) |  Loss2: (0.0000) | Acc: (88.00%) (3505/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (4604/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (5732/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (6847/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (7968/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (9080/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.3658) |  Loss2: (0.0000) | Acc: (87.00%) (10187/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (87.00%) (11304/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (12422/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.3659) |  Loss2: (0.0000) | Acc: (87.00%) (13528/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.3658) |  Loss2: (0.0000) | Acc: (87.00%) (14645/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (15764/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (16872/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (87.00%) (17995/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.3697) |  Loss2: (0.0000) | Acc: (87.00%) (19095/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.3711) |  Loss2: (0.0000) | Acc: (87.00%) (20211/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.3711) |  Loss2: (0.0000) | Acc: (87.00%) (21336/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (87.00%) (22450/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.3695) |  Loss2: (0.0000) | Acc: (87.00%) (23572/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (87.00%) (24691/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.3708) |  Loss2: (0.0000) | Acc: (87.00%) (25790/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.3717) |  Loss2: (0.0000) | Acc: (87.00%) (26900/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (28011/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (87.00%) (29136/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (30248/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.3731) |  Loss2: (0.0000) | Acc: (87.00%) (31364/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.3730) |  Loss2: (0.0000) | Acc: (87.00%) (32471/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (33578/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (34702/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.3735) |  Loss2: (0.0000) | Acc: (87.00%) (35797/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (36933/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.3727) |  Loss2: (0.0000) | Acc: (87.00%) (38049/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (39156/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (40271/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (87.00%) (41404/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (42517/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (43584/50000)
# TEST : Loss: (0.5254) | Acc: (82.00%) (8257/10000)
percent tensor([0.5247, 0.5218, 0.5244, 0.5237, 0.5289, 0.5291, 0.5241, 0.5255, 0.5219,
        0.5210, 0.5236, 0.5224, 0.5238, 0.5154, 0.5271, 0.5233],
       device='cuda:0') torch.Size([16])
percent tensor([0.4976, 0.4947, 0.4954, 0.4959, 0.4949, 0.5010, 0.4943, 0.4956, 0.4962,
        0.4936, 0.4961, 0.4947, 0.4967, 0.4953, 0.4974, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5002, 0.5166, 0.5211, 0.5190, 0.5499, 0.5131, 0.5244, 0.5351, 0.5155,
        0.5104, 0.5067, 0.5242, 0.5098, 0.5065, 0.5193, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5644, 0.5669, 0.5520, 0.5551, 0.5561, 0.5480, 0.5706, 0.5567, 0.5604,
        0.5694, 0.5763, 0.5623, 0.5619, 0.5731, 0.5647, 0.5570],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.5246, 0.6072, 0.6685, 0.6028, 0.6368, 0.5421, 0.5559, 0.6317,
        0.5530, 0.6014, 0.6007, 0.5406, 0.6599, 0.5295, 0.5574],
       device='cuda:0') torch.Size([16])
percent tensor([0.5968, 0.5953, 0.6055, 0.6006, 0.5982, 0.5858, 0.6099, 0.5984, 0.6103,
        0.6025, 0.5983, 0.6306, 0.6043, 0.6112, 0.6030, 0.5938],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.5748, 0.6428, 0.6203, 0.6324, 0.6934, 0.5803, 0.5221, 0.6294,
        0.5564, 0.6214, 0.5792, 0.5710, 0.6767, 0.5411, 0.6058],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9976, 0.9993, 0.9985, 0.9980, 0.9977, 0.9989, 0.9993, 0.9982,
        0.9992, 0.9989, 0.9993, 0.9974, 0.9992, 0.9988, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 54 | Batch_idx: 0 |  Loss: (0.4315) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (2352/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (87.00%) (3490/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3593) |  Loss2: (0.0000) | Acc: (87.00%) (4602/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (5736/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.3660) |  Loss2: (0.0000) | Acc: (87.00%) (6834/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (7955/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (9076/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (10198/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (11307/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (12429/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (13556/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (87.00%) (14671/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.3613) |  Loss2: (0.0000) | Acc: (87.00%) (15791/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.3611) |  Loss2: (0.0000) | Acc: (87.00%) (16906/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (18047/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.3604) |  Loss2: (0.0000) | Acc: (87.00%) (19156/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.3616) |  Loss2: (0.0000) | Acc: (87.00%) (20268/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (87.00%) (21376/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.3614) |  Loss2: (0.0000) | Acc: (87.00%) (22519/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (23620/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (24760/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (25877/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.3640) |  Loss2: (0.0000) | Acc: (87.00%) (27006/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.3637) |  Loss2: (0.0000) | Acc: (87.00%) (28130/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (29235/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.3640) |  Loss2: (0.0000) | Acc: (87.00%) (30348/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (31469/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (32605/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (33722/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (87.00%) (34835/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.3622) |  Loss2: (0.0000) | Acc: (87.00%) (35967/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (37107/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.3603) |  Loss2: (0.0000) | Acc: (87.00%) (38229/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.3602) |  Loss2: (0.0000) | Acc: (87.00%) (39348/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (40465/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (41566/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.3617) |  Loss2: (0.0000) | Acc: (87.00%) (42684/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.3605) |  Loss2: (0.0000) | Acc: (87.00%) (43780/50000)
# TEST : Loss: (0.5199) | Acc: (83.00%) (8317/10000)
percent tensor([0.5245, 0.5223, 0.5243, 0.5232, 0.5288, 0.5290, 0.5248, 0.5252, 0.5225,
        0.5209, 0.5240, 0.5221, 0.5238, 0.5162, 0.5273, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.4978, 0.4952, 0.4951, 0.4959, 0.4943, 0.5009, 0.4945, 0.4957, 0.4962,
        0.4938, 0.4963, 0.4949, 0.4969, 0.4963, 0.4974, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5010, 0.5190, 0.5254, 0.5134, 0.5525, 0.5129, 0.5276, 0.5300, 0.5180,
        0.5124, 0.5078, 0.5252, 0.5108, 0.5071, 0.5198, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5634, 0.5666, 0.5562, 0.5592, 0.5590, 0.5490, 0.5702, 0.5595, 0.5604,
        0.5686, 0.5757, 0.5637, 0.5619, 0.5727, 0.5656, 0.5583],
       device='cuda:0') torch.Size([16])
percent tensor([0.5708, 0.5234, 0.6135, 0.6527, 0.5951, 0.6370, 0.5481, 0.5483, 0.6357,
        0.5530, 0.6152, 0.5939, 0.5459, 0.6620, 0.5251, 0.5524],
       device='cuda:0') torch.Size([16])
percent tensor([0.5985, 0.5976, 0.6077, 0.6103, 0.6044, 0.5895, 0.6138, 0.6015, 0.6142,
        0.6039, 0.6025, 0.6343, 0.6056, 0.6163, 0.6055, 0.5966],
       device='cuda:0') torch.Size([16])
percent tensor([0.6214, 0.5569, 0.6632, 0.6254, 0.6373, 0.6996, 0.6027, 0.5408, 0.6248,
        0.5596, 0.6359, 0.5982, 0.5684, 0.6845, 0.5423, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9979, 0.9994, 0.9989, 0.9982, 0.9981, 0.9988, 0.9995, 0.9985,
        0.9991, 0.9995, 0.9990, 0.9982, 0.9988, 0.9987, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 55 | Batch_idx: 0 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.3852) |  Loss2: (0.0000) | Acc: (87.00%) (2342/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.4008) |  Loss2: (0.0000) | Acc: (86.00%) (3430/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.4175) |  Loss2: (0.0000) | Acc: (85.00%) (4497/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.4156) |  Loss2: (0.0000) | Acc: (85.00%) (5598/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.4196) |  Loss2: (0.0000) | Acc: (85.00%) (6680/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.4238) |  Loss2: (0.0000) | Acc: (85.00%) (7769/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (8845/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (85.00%) (9932/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.4331) |  Loss2: (0.0000) | Acc: (85.00%) (11006/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.4316) |  Loss2: (0.0000) | Acc: (85.00%) (12102/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.4314) |  Loss2: (0.0000) | Acc: (85.00%) (13198/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.4300) |  Loss2: (0.0000) | Acc: (85.00%) (14297/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.4298) |  Loss2: (0.0000) | Acc: (85.00%) (15386/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (85.00%) (16479/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.4299) |  Loss2: (0.0000) | Acc: (85.00%) (17568/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.4278) |  Loss2: (0.0000) | Acc: (85.00%) (18666/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.4284) |  Loss2: (0.0000) | Acc: (85.00%) (19748/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.4248) |  Loss2: (0.0000) | Acc: (85.00%) (20871/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.4257) |  Loss2: (0.0000) | Acc: (85.00%) (21961/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.4259) |  Loss2: (0.0000) | Acc: (85.00%) (23067/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.4241) |  Loss2: (0.0000) | Acc: (85.00%) (24179/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.4232) |  Loss2: (0.0000) | Acc: (85.00%) (25281/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (26375/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (27462/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.4229) |  Loss2: (0.0000) | Acc: (85.00%) (28543/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.4226) |  Loss2: (0.0000) | Acc: (85.00%) (29623/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.4220) |  Loss2: (0.0000) | Acc: (85.00%) (30718/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.4216) |  Loss2: (0.0000) | Acc: (85.00%) (31820/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.4206) |  Loss2: (0.0000) | Acc: (85.00%) (32928/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (34012/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (35088/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.4200) |  Loss2: (0.0000) | Acc: (85.00%) (36194/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (37301/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.4192) |  Loss2: (0.0000) | Acc: (85.00%) (38397/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.4190) |  Loss2: (0.0000) | Acc: (85.00%) (39492/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.4182) |  Loss2: (0.0000) | Acc: (85.00%) (40605/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.4169) |  Loss2: (0.0000) | Acc: (85.00%) (41727/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.4154) |  Loss2: (0.0000) | Acc: (85.00%) (42804/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_055.pth.tar'
# TEST : Loss: (0.4942) | Acc: (83.00%) (8341/10000)
percent tensor([0.5253, 0.5237, 0.5270, 0.5238, 0.5303, 0.5298, 0.5265, 0.5273, 0.5235,
        0.5223, 0.5250, 0.5239, 0.5244, 0.5177, 0.5282, 0.5241],
       device='cuda:0') torch.Size([16])
percent tensor([0.4964, 0.4931, 0.4937, 0.4948, 0.4925, 0.5005, 0.4926, 0.4940, 0.4944,
        0.4920, 0.4943, 0.4926, 0.4951, 0.4943, 0.4960, 0.4965],
       device='cuda:0') torch.Size([16])
percent tensor([0.5004, 0.5178, 0.5193, 0.5058, 0.5370, 0.5129, 0.5195, 0.5161, 0.5091,
        0.5101, 0.5086, 0.5187, 0.5112, 0.5025, 0.5177, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.5532, 0.5597, 0.5431, 0.5483, 0.5483, 0.5419, 0.5602, 0.5479, 0.5522,
        0.5591, 0.5666, 0.5518, 0.5546, 0.5663, 0.5569, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5837, 0.5145, 0.6431, 0.6842, 0.6127, 0.6788, 0.5484, 0.5482, 0.6516,
        0.5502, 0.6243, 0.6069, 0.5418, 0.6943, 0.5164, 0.5721],
       device='cuda:0') torch.Size([16])
percent tensor([0.5899, 0.5858, 0.6010, 0.6029, 0.5954, 0.5769, 0.6002, 0.5928, 0.6051,
        0.5921, 0.5928, 0.6259, 0.5977, 0.6032, 0.5960, 0.5855],
       device='cuda:0') torch.Size([16])
percent tensor([0.6234, 0.5328, 0.6888, 0.6511, 0.6769, 0.7247, 0.5939, 0.5353, 0.6010,
        0.5368, 0.6299, 0.6155, 0.5530, 0.6865, 0.5156, 0.5882],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9981, 0.9992, 0.9982, 0.9981, 0.9979, 0.9986, 0.9995, 0.9984,
        0.9988, 0.9993, 0.9988, 0.9980, 0.9989, 0.9986, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 56 | Batch_idx: 0 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.3620) |  Loss2: (0.0000) | Acc: (88.00%) (1240/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (87.00%) (2350/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (87.00%) (3463/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.3897) |  Loss2: (0.0000) | Acc: (86.00%) (4555/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.3865) |  Loss2: (0.0000) | Acc: (86.00%) (5673/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.3837) |  Loss2: (0.0000) | Acc: (87.00%) (6794/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (87.00%) (7919/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.3796) |  Loss2: (0.0000) | Acc: (87.00%) (9031/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (87.00%) (10157/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.3797) |  Loss2: (0.0000) | Acc: (87.00%) (11265/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.3769) |  Loss2: (0.0000) | Acc: (87.00%) (12388/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (87.00%) (13484/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.3796) |  Loss2: (0.0000) | Acc: (87.00%) (14616/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.3789) |  Loss2: (0.0000) | Acc: (87.00%) (15731/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (87.00%) (16831/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (87.00%) (17957/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (87.00%) (19061/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.3808) |  Loss2: (0.0000) | Acc: (87.00%) (20159/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.3793) |  Loss2: (0.0000) | Acc: (87.00%) (21292/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (87.00%) (22386/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (86.00%) (23496/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.3812) |  Loss2: (0.0000) | Acc: (86.00%) (24601/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.3807) |  Loss2: (0.0000) | Acc: (87.00%) (25725/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (87.00%) (26862/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (87.00%) (27992/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (87.00%) (29109/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.3771) |  Loss2: (0.0000) | Acc: (87.00%) (30229/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (87.00%) (31348/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.3784) |  Loss2: (0.0000) | Acc: (87.00%) (32450/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (87.00%) (33545/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (87.00%) (34651/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.3807) |  Loss2: (0.0000) | Acc: (87.00%) (35760/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.3808) |  Loss2: (0.0000) | Acc: (87.00%) (36874/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (87.00%) (37979/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.3817) |  Loss2: (0.0000) | Acc: (87.00%) (39093/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (87.00%) (40215/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (87.00%) (41358/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (87.00%) (42475/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.3801) |  Loss2: (0.0000) | Acc: (87.00%) (43535/50000)
# TEST : Loss: (0.4722) | Acc: (84.00%) (8404/10000)
percent tensor([0.5263, 0.5250, 0.5283, 0.5248, 0.5316, 0.5308, 0.5280, 0.5287, 0.5246,
        0.5236, 0.5260, 0.5252, 0.5254, 0.5187, 0.5294, 0.5252],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.4938, 0.4941, 0.4952, 0.4931, 0.5006, 0.4933, 0.4947, 0.4948,
        0.4927, 0.4948, 0.4934, 0.4956, 0.4946, 0.4966, 0.4969],
       device='cuda:0') torch.Size([16])
percent tensor([0.5013, 0.5187, 0.5143, 0.5037, 0.5311, 0.5136, 0.5184, 0.5101, 0.5072,
        0.5102, 0.5100, 0.5149, 0.5124, 0.5023, 0.5190, 0.5037],
       device='cuda:0') torch.Size([16])
percent tensor([0.5611, 0.5688, 0.5491, 0.5548, 0.5548, 0.5484, 0.5685, 0.5543, 0.5591,
        0.5678, 0.5756, 0.5592, 0.5636, 0.5744, 0.5658, 0.5582],
       device='cuda:0') torch.Size([16])
percent tensor([0.5804, 0.5101, 0.6435, 0.6926, 0.6139, 0.6916, 0.5450, 0.5418, 0.6515,
        0.5458, 0.6256, 0.6039, 0.5312, 0.7064, 0.5135, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.6022, 0.5980, 0.6142, 0.6161, 0.6073, 0.5843, 0.6136, 0.6086, 0.6160,
        0.6053, 0.6058, 0.6423, 0.6112, 0.6148, 0.6097, 0.5970],
       device='cuda:0') torch.Size([16])
percent tensor([0.6269, 0.5238, 0.7033, 0.6665, 0.6889, 0.7331, 0.5893, 0.5414, 0.6031,
        0.5299, 0.6301, 0.6195, 0.5487, 0.6898, 0.5096, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9982, 0.9993, 0.9984, 0.9983, 0.9982, 0.9987, 0.9996, 0.9985,
        0.9989, 0.9993, 0.9989, 0.9981, 0.9990, 0.9987, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 57 | Batch_idx: 0 |  Loss: (0.3390) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.3743) |  Loss2: (0.0000) | Acc: (86.00%) (1221/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (86.00%) (2330/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (86.00%) (3434/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.3713) |  Loss2: (0.0000) | Acc: (86.00%) (4565/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.3760) |  Loss2: (0.0000) | Acc: (86.00%) (5672/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (86.00%) (6783/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.3730) |  Loss2: (0.0000) | Acc: (86.00%) (7906/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.3670) |  Loss2: (0.0000) | Acc: (87.00%) (9039/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (10186/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.3635) |  Loss2: (0.0000) | Acc: (87.00%) (11314/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (12418/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (13545/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.3627) |  Loss2: (0.0000) | Acc: (87.00%) (14697/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (15802/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (16933/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (18051/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.3683) |  Loss2: (0.0000) | Acc: (87.00%) (19144/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.3684) |  Loss2: (0.0000) | Acc: (87.00%) (20264/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.3687) |  Loss2: (0.0000) | Acc: (87.00%) (21374/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.3680) |  Loss2: (0.0000) | Acc: (87.00%) (22497/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.3652) |  Loss2: (0.0000) | Acc: (87.00%) (23641/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (24756/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (25869/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.3665) |  Loss2: (0.0000) | Acc: (87.00%) (26975/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (28088/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (87.00%) (29185/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.3688) |  Loss2: (0.0000) | Acc: (87.00%) (30300/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.3688) |  Loss2: (0.0000) | Acc: (87.00%) (31419/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.3695) |  Loss2: (0.0000) | Acc: (87.00%) (32517/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.3700) |  Loss2: (0.0000) | Acc: (87.00%) (33629/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (87.00%) (34737/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.3709) |  Loss2: (0.0000) | Acc: (87.00%) (35836/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (87.00%) (36948/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (38050/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (39168/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.3720) |  Loss2: (0.0000) | Acc: (87.00%) (40287/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (87.00%) (41403/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (42521/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.3730) |  Loss2: (0.0000) | Acc: (87.00%) (43584/50000)
# TEST : Loss: (0.4631) | Acc: (84.00%) (8433/10000)
percent tensor([0.5265, 0.5253, 0.5285, 0.5250, 0.5320, 0.5313, 0.5282, 0.5291, 0.5248,
        0.5239, 0.5263, 0.5254, 0.5255, 0.5189, 0.5298, 0.5256],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.4937, 0.4939, 0.4951, 0.4928, 0.5007, 0.4931, 0.4946, 0.4945,
        0.4925, 0.4946, 0.4932, 0.4954, 0.4944, 0.4966, 0.4968],
       device='cuda:0') torch.Size([16])
percent tensor([0.5064, 0.5256, 0.5155, 0.5070, 0.5336, 0.5200, 0.5234, 0.5110, 0.5117,
        0.5158, 0.5177, 0.5186, 0.5190, 0.5073, 0.5268, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5705, 0.5792, 0.5560, 0.5624, 0.5625, 0.5568, 0.5783, 0.5621, 0.5677,
        0.5775, 0.5862, 0.5677, 0.5738, 0.5842, 0.5765, 0.5675],
       device='cuda:0') torch.Size([16])
percent tensor([0.5801, 0.5119, 0.6442, 0.6993, 0.6163, 0.6993, 0.5472, 0.5402, 0.6531,
        0.5477, 0.6276, 0.6060, 0.5320, 0.7148, 0.5155, 0.5758],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.5967, 0.6146, 0.6151, 0.6065, 0.5795, 0.6129, 0.6093, 0.6143,
        0.6046, 0.6051, 0.6437, 0.6108, 0.6131, 0.6097, 0.5944],
       device='cuda:0') torch.Size([16])
percent tensor([0.6234, 0.5168, 0.7030, 0.6670, 0.6912, 0.7318, 0.5824, 0.5398, 0.5967,
        0.5250, 0.6235, 0.6147, 0.5393, 0.6833, 0.5037, 0.5803],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9985, 0.9994, 0.9985, 0.9985, 0.9984, 0.9988, 0.9996, 0.9987,
        0.9991, 0.9994, 0.9991, 0.9982, 0.9990, 0.9989, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 58 | Batch_idx: 0 |  Loss: (0.3903) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (1231/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3593) |  Loss2: (0.0000) | Acc: (86.00%) (2331/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3680) |  Loss2: (0.0000) | Acc: (86.00%) (3428/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3675) |  Loss2: (0.0000) | Acc: (86.00%) (4547/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (5685/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3597) |  Loss2: (0.0000) | Acc: (87.00%) (6799/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (86.00%) (7897/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (86.00%) (9006/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3659) |  Loss2: (0.0000) | Acc: (86.00%) (10131/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3695) |  Loss2: (0.0000) | Acc: (86.00%) (11231/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (86.00%) (12359/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3695) |  Loss2: (0.0000) | Acc: (86.00%) (13468/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (14595/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3694) |  Loss2: (0.0000) | Acc: (87.00%) (15722/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (87.00%) (16854/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3675) |  Loss2: (0.0000) | Acc: (87.00%) (17983/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (19104/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (20222/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3692) |  Loss2: (0.0000) | Acc: (87.00%) (21323/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (22453/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (23586/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (24704/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (25835/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (26961/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (28075/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (29193/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3633) |  Loss2: (0.0000) | Acc: (87.00%) (30333/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (31453/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3628) |  Loss2: (0.0000) | Acc: (87.00%) (32590/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (33692/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (34795/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3641) |  Loss2: (0.0000) | Acc: (87.00%) (35920/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (37032/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (38171/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3635) |  Loss2: (0.0000) | Acc: (87.00%) (39274/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (40407/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3633) |  Loss2: (0.0000) | Acc: (87.00%) (41518/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3633) |  Loss2: (0.0000) | Acc: (87.00%) (42639/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (87.00%) (43723/50000)
# TEST : Loss: (0.4535) | Acc: (84.00%) (8457/10000)
percent tensor([0.5259, 0.5250, 0.5281, 0.5247, 0.5316, 0.5308, 0.5278, 0.5288, 0.5242,
        0.5235, 0.5257, 0.5249, 0.5249, 0.5186, 0.5293, 0.5252],
       device='cuda:0') torch.Size([16])
percent tensor([0.4969, 0.4939, 0.4941, 0.4953, 0.4930, 0.5007, 0.4934, 0.4949, 0.4946,
        0.4928, 0.4947, 0.4935, 0.4956, 0.4943, 0.4968, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5090, 0.5273, 0.5162, 0.5092, 0.5354, 0.5241, 0.5253, 0.5113, 0.5137,
        0.5172, 0.5203, 0.5195, 0.5210, 0.5087, 0.5308, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5740, 0.5830, 0.5588, 0.5652, 0.5655, 0.5597, 0.5817, 0.5646, 0.5709,
        0.5813, 0.5900, 0.5708, 0.5781, 0.5876, 0.5802, 0.5707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5616, 0.5049, 0.6285, 0.6863, 0.6021, 0.6867, 0.5321, 0.5284, 0.6353,
        0.5368, 0.6122, 0.5902, 0.5189, 0.7008, 0.5085, 0.5579],
       device='cuda:0') torch.Size([16])
percent tensor([0.6055, 0.6019, 0.6199, 0.6197, 0.6106, 0.5815, 0.6181, 0.6160, 0.6189,
        0.6105, 0.6097, 0.6504, 0.6166, 0.6168, 0.6157, 0.5983],
       device='cuda:0') torch.Size([16])
percent tensor([0.6313, 0.5251, 0.7079, 0.6715, 0.6969, 0.7384, 0.5894, 0.5478, 0.6048,
        0.5298, 0.6321, 0.6193, 0.5460, 0.6890, 0.5082, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9985, 0.9994, 0.9987, 0.9985, 0.9984, 0.9988, 0.9996, 0.9987,
        0.9992, 0.9994, 0.9992, 0.9983, 0.9991, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 59 | Batch_idx: 0 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3409) |  Loss2: (0.0000) | Acc: (88.00%) (1249/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (2364/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (88.00%) (3494/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3472) |  Loss2: (0.0000) | Acc: (88.00%) (4627/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (5737/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3619) |  Loss2: (0.0000) | Acc: (87.00%) (6852/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (87.00%) (7973/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3581) |  Loss2: (0.0000) | Acc: (87.00%) (9109/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3593) |  Loss2: (0.0000) | Acc: (87.00%) (10229/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (11351/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3604) |  Loss2: (0.0000) | Acc: (87.00%) (12478/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3605) |  Loss2: (0.0000) | Acc: (87.00%) (13594/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3613) |  Loss2: (0.0000) | Acc: (87.00%) (14707/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (15822/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3617) |  Loss2: (0.0000) | Acc: (87.00%) (16942/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3614) |  Loss2: (0.0000) | Acc: (87.00%) (18084/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (19208/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3599) |  Loss2: (0.0000) | Acc: (87.00%) (20335/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3604) |  Loss2: (0.0000) | Acc: (87.00%) (21456/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (22598/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (23724/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (24850/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (25992/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (27116/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (28236/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (29359/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (30468/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (31593/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (32723/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (33845/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (34986/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (36107/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3554) |  Loss2: (0.0000) | Acc: (87.00%) (37256/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3551) |  Loss2: (0.0000) | Acc: (87.00%) (38389/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (39492/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (40625/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (41756/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (42874/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (43945/50000)
# TEST : Loss: (0.4528) | Acc: (84.00%) (8458/10000)
percent tensor([0.5258, 0.5251, 0.5281, 0.5247, 0.5316, 0.5308, 0.5279, 0.5289, 0.5241,
        0.5236, 0.5257, 0.5250, 0.5248, 0.5188, 0.5294, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.4970, 0.4942, 0.4943, 0.4955, 0.4932, 0.5008, 0.4937, 0.4952, 0.4947,
        0.4929, 0.4948, 0.4938, 0.4958, 0.4943, 0.4971, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.5085, 0.5248, 0.5162, 0.5093, 0.5346, 0.5257, 0.5236, 0.5102, 0.5124,
        0.5152, 0.5186, 0.5183, 0.5189, 0.5067, 0.5305, 0.5104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5725, 0.5817, 0.5565, 0.5631, 0.5630, 0.5583, 0.5800, 0.5614, 0.5694,
        0.5799, 0.5889, 0.5687, 0.5772, 0.5864, 0.5785, 0.5692],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5106, 0.6333, 0.6944, 0.6058, 0.6898, 0.5375, 0.5308, 0.6428,
        0.5441, 0.6218, 0.6012, 0.5274, 0.7071, 0.5152, 0.5632],
       device='cuda:0') torch.Size([16])
percent tensor([0.6090, 0.6054, 0.6247, 0.6246, 0.6147, 0.5818, 0.6228, 0.6214, 0.6229,
        0.6152, 0.6138, 0.6572, 0.6211, 0.6199, 0.6204, 0.6010],
       device='cuda:0') torch.Size([16])
percent tensor([0.6427, 0.5423, 0.7168, 0.6802, 0.7073, 0.7415, 0.6003, 0.5625, 0.6198,
        0.5441, 0.6453, 0.6321, 0.5610, 0.7008, 0.5199, 0.5937],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9987, 0.9995, 0.9988, 0.9986, 0.9986, 0.9990, 0.9997, 0.9989,
        0.9993, 0.9995, 0.9993, 0.9985, 0.9992, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.3441) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.3457) |  Loss2: (0.0000) | Acc: (87.00%) (1228/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (2345/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (86.00%) (3446/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3680) |  Loss2: (0.0000) | Acc: (87.00%) (4571/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (5696/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (6805/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3621) |  Loss2: (0.0000) | Acc: (87.00%) (7939/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (9066/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3652) |  Loss2: (0.0000) | Acc: (87.00%) (10170/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (11292/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3617) |  Loss2: (0.0000) | Acc: (87.00%) (12426/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (87.00%) (13549/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (14694/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (15817/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (16914/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (18015/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (19123/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (20248/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (21369/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (22513/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3582) |  Loss2: (0.0000) | Acc: (87.00%) (23646/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (24772/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (25896/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (26982/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (28101/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (29238/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (30375/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (31486/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (32612/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (33721/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (34839/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (35965/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (37090/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (38212/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (39332/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (40456/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (41577/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (42709/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (43787/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_060.pth.tar'
# TEST : Loss: (0.4673) | Acc: (84.00%) (8404/10000)
percent tensor([0.5259, 0.5243, 0.5270, 0.5247, 0.5318, 0.5314, 0.5269, 0.5280, 0.5240,
        0.5228, 0.5256, 0.5243, 0.5247, 0.5177, 0.5293, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.4972, 0.4944, 0.4945, 0.4948, 0.4938, 0.5009, 0.4940, 0.4948, 0.4950,
        0.4927, 0.4949, 0.4943, 0.4961, 0.4948, 0.4969, 0.4971],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.5236, 0.5142, 0.5081, 0.5377, 0.5272, 0.5226, 0.5108, 0.5141,
        0.5139, 0.5188, 0.5162, 0.5198, 0.5047, 0.5314, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.5718, 0.5829, 0.5561, 0.5612, 0.5581, 0.5545, 0.5830, 0.5623, 0.5696,
        0.5823, 0.5922, 0.5691, 0.5746, 0.5890, 0.5774, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.5406, 0.5069, 0.6164, 0.6754, 0.5972, 0.6779, 0.5315, 0.5322, 0.6030,
        0.5406, 0.5853, 0.5969, 0.5125, 0.6723, 0.5131, 0.5527],
       device='cuda:0') torch.Size([16])
percent tensor([0.6112, 0.6109, 0.6225, 0.6264, 0.6181, 0.5865, 0.6335, 0.6264, 0.6361,
        0.6224, 0.6179, 0.6622, 0.6244, 0.6217, 0.6223, 0.6033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6194, 0.5834, 0.6992, 0.6565, 0.6853, 0.7163, 0.5737, 0.5626, 0.6173,
        0.5772, 0.6433, 0.6261, 0.5655, 0.6693, 0.5258, 0.6045],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9987, 0.9997, 0.9996, 0.9994, 0.9977, 0.9989, 0.9996, 0.9994,
        0.9996, 0.9993, 0.9995, 0.9985, 0.9992, 0.9990, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(177.6777, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(804.7017, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(800.5461, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1525.8804, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(503.2258, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2199.4348, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4295.8379, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1407.7518, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6100.2832, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11996.3691, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3990.1619, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16916.9160, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 61 | Batch_idx: 0 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (1250/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (89.00%) (2393/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3273) |  Loss2: (0.0000) | Acc: (88.00%) (3529/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3304) |  Loss2: (0.0000) | Acc: (88.00%) (4656/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3291) |  Loss2: (0.0000) | Acc: (88.00%) (5797/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3304) |  Loss2: (0.0000) | Acc: (88.00%) (6943/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3267) |  Loss2: (0.0000) | Acc: (89.00%) (8092/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (9218/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (10351/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3312) |  Loss2: (0.0000) | Acc: (88.00%) (11485/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3298) |  Loss2: (0.0000) | Acc: (88.00%) (12629/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (13767/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3315) |  Loss2: (0.0000) | Acc: (88.00%) (14900/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (16039/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3303) |  Loss2: (0.0000) | Acc: (88.00%) (17177/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (18296/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3323) |  Loss2: (0.0000) | Acc: (88.00%) (19422/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (20568/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (21691/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (22799/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (23934/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (25072/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (26197/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (27328/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3372) |  Loss2: (0.0000) | Acc: (88.00%) (28453/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (88.00%) (29578/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (30715/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3379) |  Loss2: (0.0000) | Acc: (88.00%) (31850/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (88.00%) (32961/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (34093/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3410) |  Loss2: (0.0000) | Acc: (88.00%) (35189/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3402) |  Loss2: (0.0000) | Acc: (88.00%) (36334/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3414) |  Loss2: (0.0000) | Acc: (88.00%) (37448/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3424) |  Loss2: (0.0000) | Acc: (88.00%) (38570/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3430) |  Loss2: (0.0000) | Acc: (88.00%) (39693/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3435) |  Loss2: (0.0000) | Acc: (88.00%) (40811/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3439) |  Loss2: (0.0000) | Acc: (88.00%) (41929/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (43052/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3436) |  Loss2: (0.0000) | Acc: (88.00%) (44147/50000)
# TEST : Loss: (0.5662) | Acc: (81.00%) (8109/10000)
percent tensor([0.5256, 0.5246, 0.5243, 0.5247, 0.5301, 0.5311, 0.5263, 0.5272, 0.5229,
        0.5225, 0.5252, 0.5228, 0.5244, 0.5185, 0.5293, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.4970, 0.4937, 0.4945, 0.4951, 0.4941, 0.5005, 0.4934, 0.4950, 0.4950,
        0.4926, 0.4948, 0.4946, 0.4960, 0.4939, 0.4968, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5068, 0.5219, 0.5108, 0.5107, 0.5409, 0.5249, 0.5241, 0.5130, 0.5134,
        0.5150, 0.5174, 0.5199, 0.5171, 0.5068, 0.5299, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5793, 0.5854, 0.5596, 0.5618, 0.5608, 0.5591, 0.5842, 0.5598, 0.5717,
        0.5840, 0.5965, 0.5713, 0.5810, 0.5861, 0.5819, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5451, 0.5161, 0.6018, 0.6813, 0.5895, 0.6784, 0.5326, 0.5360, 0.6275,
        0.5383, 0.5990, 0.5823, 0.5179, 0.6961, 0.5185, 0.5666],
       device='cuda:0') torch.Size([16])
percent tensor([0.6094, 0.6102, 0.6278, 0.6246, 0.6234, 0.5858, 0.6329, 0.6313, 0.6310,
        0.6228, 0.6120, 0.6635, 0.6215, 0.6240, 0.6245, 0.6012],
       device='cuda:0') torch.Size([16])
percent tensor([0.6313, 0.5726, 0.7129, 0.6573, 0.6937, 0.7357, 0.6041, 0.5868, 0.6426,
        0.5644, 0.6445, 0.6172, 0.5515, 0.6858, 0.5359, 0.6154],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9998, 0.9995, 0.9994, 0.9986, 0.9992, 0.9997, 0.9995,
        0.9998, 0.9997, 0.9997, 0.9988, 0.9992, 0.9989, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 62 | Batch_idx: 0 |  Loss: (0.4495) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3176) |  Loss2: (0.0000) | Acc: (90.00%) (1270/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (89.00%) (2411/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (89.00%) (3552/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3293) |  Loss2: (0.0000) | Acc: (89.00%) (4680/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3238) |  Loss2: (0.0000) | Acc: (89.00%) (5816/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3275) |  Loss2: (0.0000) | Acc: (88.00%) (6941/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3239) |  Loss2: (0.0000) | Acc: (89.00%) (8092/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (9206/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (10342/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3337) |  Loss2: (0.0000) | Acc: (88.00%) (11459/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (12594/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (13726/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (14830/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3352) |  Loss2: (0.0000) | Acc: (88.00%) (15964/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3379) |  Loss2: (0.0000) | Acc: (88.00%) (17089/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (18241/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (19367/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (20491/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3360) |  Loss2: (0.0000) | Acc: (88.00%) (21632/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (88.00%) (22760/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (23884/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3392) |  Loss2: (0.0000) | Acc: (88.00%) (24999/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3403) |  Loss2: (0.0000) | Acc: (88.00%) (26117/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3403) |  Loss2: (0.0000) | Acc: (88.00%) (27241/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3396) |  Loss2: (0.0000) | Acc: (88.00%) (28380/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3389) |  Loss2: (0.0000) | Acc: (88.00%) (29524/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3388) |  Loss2: (0.0000) | Acc: (88.00%) (30664/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (88.00%) (31800/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (88.00%) (32942/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3383) |  Loss2: (0.0000) | Acc: (88.00%) (34066/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (35195/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3379) |  Loss2: (0.0000) | Acc: (88.00%) (36339/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (37464/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (38593/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3374) |  Loss2: (0.0000) | Acc: (88.00%) (39730/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3372) |  Loss2: (0.0000) | Acc: (88.00%) (40860/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3363) |  Loss2: (0.0000) | Acc: (88.00%) (41991/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3352) |  Loss2: (0.0000) | Acc: (88.00%) (43149/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (44228/50000)
# TEST : Loss: (0.4706) | Acc: (84.00%) (8424/10000)
percent tensor([0.5266, 0.5243, 0.5265, 0.5259, 0.5322, 0.5324, 0.5268, 0.5279, 0.5243,
        0.5229, 0.5256, 0.5250, 0.5251, 0.5180, 0.5297, 0.5258],
       device='cuda:0') torch.Size([16])
percent tensor([0.4970, 0.4942, 0.4941, 0.4949, 0.4937, 0.5009, 0.4934, 0.4946, 0.4947,
        0.4925, 0.4950, 0.4943, 0.4957, 0.4941, 0.4971, 0.4971],
       device='cuda:0') torch.Size([16])
percent tensor([0.5081, 0.5217, 0.5127, 0.5116, 0.5411, 0.5268, 0.5215, 0.5126, 0.5166,
        0.5128, 0.5169, 0.5167, 0.5186, 0.5060, 0.5306, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5748, 0.5807, 0.5603, 0.5637, 0.5595, 0.5582, 0.5801, 0.5621, 0.5683,
        0.5790, 0.5901, 0.5694, 0.5752, 0.5823, 0.5777, 0.5687],
       device='cuda:0') torch.Size([16])
percent tensor([0.5418, 0.5133, 0.6316, 0.6967, 0.6200, 0.6729, 0.5461, 0.5465, 0.6366,
        0.5448, 0.5923, 0.6103, 0.5266, 0.6959, 0.5180, 0.5578],
       device='cuda:0') torch.Size([16])
percent tensor([0.6045, 0.6038, 0.6160, 0.6160, 0.6166, 0.5860, 0.6259, 0.6206, 0.6227,
        0.6082, 0.6060, 0.6538, 0.6191, 0.6228, 0.6158, 0.6008],
       device='cuda:0') torch.Size([16])
percent tensor([0.6068, 0.5016, 0.6951, 0.6645, 0.6953, 0.7337, 0.5656, 0.5592, 0.6227,
        0.5267, 0.5956, 0.6109, 0.5381, 0.6737, 0.5246, 0.5739],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9982, 0.9995, 0.9985, 0.9985, 0.9979, 0.9990, 0.9996, 0.9988,
        0.9993, 0.9992, 0.9995, 0.9977, 0.9985, 0.9986, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 63 | Batch_idx: 0 |  Loss: (0.4833) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3579) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3463) |  Loss2: (0.0000) | Acc: (88.00%) (2366/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (3512/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (4641/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.3254) |  Loss2: (0.0000) | Acc: (88.00%) (5788/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (88.00%) (6923/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (8062/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.3191) |  Loss2: (0.0000) | Acc: (88.00%) (9207/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (88.00%) (10341/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (88.00%) (11486/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (12629/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.3181) |  Loss2: (0.0000) | Acc: (88.00%) (13776/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (14906/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (88.00%) (16037/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.3205) |  Loss2: (0.0000) | Acc: (88.00%) (17170/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (18295/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.3223) |  Loss2: (0.0000) | Acc: (88.00%) (19431/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.3240) |  Loss2: (0.0000) | Acc: (88.00%) (20556/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.3240) |  Loss2: (0.0000) | Acc: (88.00%) (21698/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (22846/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (23971/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (25060/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (26191/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.3268) |  Loss2: (0.0000) | Acc: (88.00%) (27311/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (28421/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (29569/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (30700/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (31833/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.3259) |  Loss2: (0.0000) | Acc: (88.00%) (32990/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.3252) |  Loss2: (0.0000) | Acc: (88.00%) (34136/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (88.00%) (35275/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3246) |  Loss2: (0.0000) | Acc: (88.00%) (36409/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3247) |  Loss2: (0.0000) | Acc: (88.00%) (37542/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (88.00%) (38673/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (88.00%) (39784/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3273) |  Loss2: (0.0000) | Acc: (88.00%) (40894/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (42027/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (43161/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3288) |  Loss2: (0.0000) | Acc: (88.00%) (44231/50000)
# TEST : Loss: (0.4949) | Acc: (83.00%) (8366/10000)
percent tensor([0.5259, 0.5242, 0.5258, 0.5248, 0.5311, 0.5314, 0.5269, 0.5275, 0.5240,
        0.5226, 0.5255, 0.5240, 0.5248, 0.5187, 0.5290, 0.5251],
       device='cuda:0') torch.Size([16])
percent tensor([0.4971, 0.4944, 0.4949, 0.4955, 0.4940, 0.5010, 0.4940, 0.4951, 0.4952,
        0.4929, 0.4949, 0.4947, 0.4959, 0.4945, 0.4972, 0.4971],
       device='cuda:0') torch.Size([16])
percent tensor([0.5081, 0.5223, 0.5183, 0.5154, 0.5443, 0.5261, 0.5232, 0.5172, 0.5184,
        0.5144, 0.5167, 0.5207, 0.5190, 0.5054, 0.5305, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5728, 0.5800, 0.5532, 0.5583, 0.5562, 0.5575, 0.5796, 0.5592, 0.5660,
        0.5785, 0.5896, 0.5668, 0.5762, 0.5830, 0.5774, 0.5678],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.5147, 0.6106, 0.6738, 0.6149, 0.6594, 0.5364, 0.5307, 0.6330,
        0.5432, 0.5872, 0.5981, 0.5305, 0.6884, 0.5148, 0.5642],
       device='cuda:0') torch.Size([16])
percent tensor([0.6073, 0.6087, 0.6216, 0.6196, 0.6101, 0.5850, 0.6267, 0.6216, 0.6269,
        0.6115, 0.6120, 0.6563, 0.6232, 0.6169, 0.6215, 0.5998],
       device='cuda:0') torch.Size([16])
percent tensor([0.6327, 0.5706, 0.7103, 0.6737, 0.7007, 0.7279, 0.5954, 0.5857, 0.6411,
        0.5509, 0.6254, 0.6177, 0.5679, 0.6912, 0.5472, 0.6100],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9990, 0.9997, 0.9995, 0.9989, 0.9985, 0.9995, 0.9997, 0.9991,
        0.9997, 0.9994, 0.9998, 0.9984, 0.9992, 0.9988, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 64 | Batch_idx: 0 |  Loss: (0.2929) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (1262/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (2405/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3088) |  Loss2: (0.0000) | Acc: (89.00%) (3546/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (89.00%) (4671/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (89.00%) (5812/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (6950/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (88.00%) (8083/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (9224/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (10375/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3166) |  Loss2: (0.0000) | Acc: (88.00%) (11501/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (88.00%) (12622/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (88.00%) (13764/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (88.00%) (14902/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3218) |  Loss2: (0.0000) | Acc: (88.00%) (16020/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3177) |  Loss2: (0.0000) | Acc: (88.00%) (17188/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (89.00%) (18346/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (89.00%) (19494/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (20641/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (21783/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (22926/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (24064/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (25212/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (26360/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (27492/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3132) |  Loss2: (0.0000) | Acc: (89.00%) (28656/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (29786/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (30911/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (32075/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3134) |  Loss2: (0.0000) | Acc: (89.00%) (33219/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (34354/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3149) |  Loss2: (0.0000) | Acc: (89.00%) (35494/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (89.00%) (36615/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3170) |  Loss2: (0.0000) | Acc: (89.00%) (37749/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (89.00%) (38886/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (89.00%) (40039/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (41195/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (42346/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (89.00%) (43484/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (89.00%) (44583/50000)
# TEST : Loss: (0.4905) | Acc: (84.00%) (8443/10000)
percent tensor([0.5255, 0.5248, 0.5250, 0.5250, 0.5305, 0.5312, 0.5270, 0.5273, 0.5241,
        0.5230, 0.5258, 0.5234, 0.5248, 0.5197, 0.5292, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.4972, 0.4941, 0.4950, 0.4953, 0.4942, 0.5007, 0.4936, 0.4949, 0.4950,
        0.4929, 0.4950, 0.4948, 0.4961, 0.4939, 0.4969, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5084, 0.5219, 0.5169, 0.5137, 0.5447, 0.5248, 0.5259, 0.5197, 0.5244,
        0.5163, 0.5188, 0.5217, 0.5210, 0.5077, 0.5299, 0.5118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5743, 0.5813, 0.5574, 0.5597, 0.5603, 0.5590, 0.5802, 0.5590, 0.5671,
        0.5806, 0.5889, 0.5704, 0.5764, 0.5819, 0.5769, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.5354, 0.5183, 0.5991, 0.6644, 0.5914, 0.6644, 0.5433, 0.5319, 0.6400,
        0.5397, 0.5955, 0.5890, 0.5235, 0.7030, 0.5150, 0.5608],
       device='cuda:0') torch.Size([16])
percent tensor([0.6061, 0.6033, 0.6255, 0.6205, 0.6156, 0.5834, 0.6274, 0.6236, 0.6270,
        0.6116, 0.6086, 0.6567, 0.6170, 0.6200, 0.6166, 0.6005],
       device='cuda:0') torch.Size([16])
percent tensor([0.6276, 0.5553, 0.7004, 0.6561, 0.6755, 0.7259, 0.6000, 0.5729, 0.6423,
        0.5378, 0.6275, 0.6054, 0.5575, 0.6808, 0.5361, 0.5942],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9987, 0.9998, 0.9997, 0.9993, 0.9985, 0.9994, 0.9999, 0.9987,
        0.9998, 0.9993, 0.9998, 0.9976, 0.9990, 0.9991, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 65 | Batch_idx: 0 |  Loss: (0.2977) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (89.00%) (1256/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (2371/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3539) |  Loss2: (0.0000) | Acc: (87.00%) (3482/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3611) |  Loss2: (0.0000) | Acc: (87.00%) (4583/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3637) |  Loss2: (0.0000) | Acc: (87.00%) (5690/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (6805/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (7932/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (9036/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3579) |  Loss2: (0.0000) | Acc: (87.00%) (10189/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (11306/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (12421/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (13544/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (14658/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3593) |  Loss2: (0.0000) | Acc: (87.00%) (15773/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3604) |  Loss2: (0.0000) | Acc: (87.00%) (16880/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3605) |  Loss2: (0.0000) | Acc: (87.00%) (18011/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3582) |  Loss2: (0.0000) | Acc: (87.00%) (19148/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (20268/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (21402/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (22523/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (23642/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (24763/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (25883/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3545) |  Loss2: (0.0000) | Acc: (87.00%) (27012/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (28165/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3525) |  Loss2: (0.0000) | Acc: (87.00%) (29286/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (87.00%) (30390/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3537) |  Loss2: (0.0000) | Acc: (87.00%) (31520/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (87.00%) (32637/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (33763/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3528) |  Loss2: (0.0000) | Acc: (87.00%) (34881/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (36006/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3521) |  Loss2: (0.0000) | Acc: (87.00%) (37134/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3504) |  Loss2: (0.0000) | Acc: (87.00%) (38281/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (39404/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (87.00%) (40547/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (41665/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (42793/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (87.00%) (43865/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_065.pth.tar'
# TEST : Loss: (0.4521) | Acc: (85.00%) (8525/10000)
percent tensor([0.5233, 0.5227, 0.5239, 0.5233, 0.5289, 0.5291, 0.5250, 0.5252, 0.5221,
        0.5212, 0.5237, 0.5217, 0.5224, 0.5181, 0.5270, 0.5234],
       device='cuda:0') torch.Size([16])
percent tensor([0.4998, 0.4982, 0.4980, 0.4986, 0.4979, 0.5016, 0.4979, 0.4989, 0.4987,
        0.4972, 0.4986, 0.4981, 0.4993, 0.4978, 0.4997, 0.5001],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.5351, 0.5346, 0.5309, 0.5652, 0.5434, 0.5411, 0.5376, 0.5381,
        0.5308, 0.5325, 0.5403, 0.5335, 0.5208, 0.5487, 0.5279],
       device='cuda:0') torch.Size([16])
percent tensor([0.5904, 0.5963, 0.5706, 0.5732, 0.5749, 0.5736, 0.5954, 0.5742, 0.5822,
        0.5945, 0.6047, 0.5837, 0.5918, 0.5960, 0.5936, 0.5840],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5274, 0.5947, 0.6718, 0.5910, 0.6664, 0.5441, 0.5244, 0.6430,
        0.5453, 0.6027, 0.5894, 0.5328, 0.7016, 0.5207, 0.5721],
       device='cuda:0') torch.Size([16])
percent tensor([0.5945, 0.5882, 0.6239, 0.6218, 0.6184, 0.5852, 0.6165, 0.6239, 0.6140,
        0.5928, 0.5869, 0.6405, 0.5924, 0.6080, 0.6080, 0.5963],
       device='cuda:0') torch.Size([16])
percent tensor([0.6238, 0.5447, 0.7201, 0.6915, 0.7012, 0.7374, 0.6063, 0.5915, 0.6352,
        0.5356, 0.6082, 0.6065, 0.5407, 0.6706, 0.5294, 0.6101],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9986, 0.9996, 0.9994, 0.9992, 0.9993, 0.9994, 0.9998, 0.9987,
        0.9998, 0.9993, 0.9995, 0.9979, 0.9990, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 66 | Batch_idx: 0 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (89.00%) (1259/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3298) |  Loss2: (0.0000) | Acc: (88.00%) (2375/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3272) |  Loss2: (0.0000) | Acc: (88.00%) (3508/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3329) |  Loss2: (0.0000) | Acc: (88.00%) (4636/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3271) |  Loss2: (0.0000) | Acc: (88.00%) (5779/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3267) |  Loss2: (0.0000) | Acc: (88.00%) (6911/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3238) |  Loss2: (0.0000) | Acc: (88.00%) (8049/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3256) |  Loss2: (0.0000) | Acc: (88.00%) (9177/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (88.00%) (10316/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3260) |  Loss2: (0.0000) | Acc: (88.00%) (11443/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3267) |  Loss2: (0.0000) | Acc: (88.00%) (12579/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3260) |  Loss2: (0.0000) | Acc: (88.00%) (13723/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (14848/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3259) |  Loss2: (0.0000) | Acc: (88.00%) (15983/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (88.00%) (17135/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3258) |  Loss2: (0.0000) | Acc: (88.00%) (18264/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3245) |  Loss2: (0.0000) | Acc: (88.00%) (19406/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (20542/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (21673/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (88.00%) (22804/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3246) |  Loss2: (0.0000) | Acc: (88.00%) (23940/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (25072/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3239) |  Loss2: (0.0000) | Acc: (88.00%) (26219/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (27348/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3246) |  Loss2: (0.0000) | Acc: (88.00%) (28479/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3242) |  Loss2: (0.0000) | Acc: (88.00%) (29629/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (88.00%) (30761/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (31931/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (33080/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (34212/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (35346/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (36490/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (37612/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (38740/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (88.00%) (39888/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (41025/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (42163/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (43294/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3224) |  Loss2: (0.0000) | Acc: (88.00%) (44411/50000)
# TEST : Loss: (0.4350) | Acc: (85.00%) (8562/10000)
percent tensor([0.5244, 0.5239, 0.5251, 0.5244, 0.5303, 0.5305, 0.5263, 0.5264, 0.5234,
        0.5223, 0.5248, 0.5228, 0.5234, 0.5193, 0.5282, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.5007, 0.4997, 0.4989, 0.4996, 0.4990, 0.5019, 0.4993, 0.5001, 0.5001,
        0.4988, 0.5000, 0.4992, 0.5004, 0.4993, 0.5008, 0.5011],
       device='cuda:0') torch.Size([16])
percent tensor([0.5254, 0.5375, 0.5365, 0.5346, 0.5663, 0.5466, 0.5420, 0.5397, 0.5387,
        0.5330, 0.5341, 0.5427, 0.5361, 0.5230, 0.5520, 0.5313],
       device='cuda:0') torch.Size([16])
percent tensor([0.6033, 0.6083, 0.5812, 0.5850, 0.5857, 0.5852, 0.6077, 0.5854, 0.5931,
        0.6065, 0.6173, 0.5953, 0.6040, 0.6074, 0.6068, 0.5966],
       device='cuda:0') torch.Size([16])
percent tensor([0.5356, 0.5267, 0.5933, 0.6707, 0.5882, 0.6624, 0.5404, 0.5188, 0.6401,
        0.5439, 0.6015, 0.5882, 0.5316, 0.6969, 0.5174, 0.5717],
       device='cuda:0') torch.Size([16])
percent tensor([0.5957, 0.5845, 0.6308, 0.6283, 0.6271, 0.5969, 0.6190, 0.6297, 0.6144,
        0.5890, 0.5818, 0.6396, 0.5849, 0.6071, 0.6113, 0.6017],
       device='cuda:0') torch.Size([16])
percent tensor([0.6384, 0.5585, 0.7250, 0.6925, 0.7042, 0.7518, 0.6181, 0.6032, 0.6499,
        0.5495, 0.6224, 0.6076, 0.5514, 0.6860, 0.5381, 0.6278],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9987, 0.9996, 0.9994, 0.9993, 0.9993, 0.9994, 0.9998, 0.9988,
        0.9998, 0.9995, 0.9995, 0.9980, 0.9992, 0.9988, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 67 | Batch_idx: 0 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (1245/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (2376/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (3501/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3275) |  Loss2: (0.0000) | Acc: (88.00%) (4648/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.3273) |  Loss2: (0.0000) | Acc: (88.00%) (5779/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.3291) |  Loss2: (0.0000) | Acc: (88.00%) (6909/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3238) |  Loss2: (0.0000) | Acc: (88.00%) (8049/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (9181/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3283) |  Loss2: (0.0000) | Acc: (88.00%) (10302/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (11409/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3310) |  Loss2: (0.0000) | Acc: (88.00%) (12541/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (13687/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3305) |  Loss2: (0.0000) | Acc: (88.00%) (14827/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3295) |  Loss2: (0.0000) | Acc: (88.00%) (15967/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (17101/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (18245/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (88.00%) (19395/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (20552/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (21690/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (88.00%) (22832/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3223) |  Loss2: (0.0000) | Acc: (88.00%) (23978/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (25134/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3201) |  Loss2: (0.0000) | Acc: (88.00%) (26291/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3191) |  Loss2: (0.0000) | Acc: (88.00%) (27436/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3189) |  Loss2: (0.0000) | Acc: (88.00%) (28566/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3176) |  Loss2: (0.0000) | Acc: (88.00%) (29724/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (88.00%) (30853/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3165) |  Loss2: (0.0000) | Acc: (89.00%) (32012/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3165) |  Loss2: (0.0000) | Acc: (88.00%) (33143/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3174) |  Loss2: (0.0000) | Acc: (88.00%) (34267/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3167) |  Loss2: (0.0000) | Acc: (88.00%) (35408/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3161) |  Loss2: (0.0000) | Acc: (88.00%) (36544/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (88.00%) (37682/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (88.00%) (38827/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (39958/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (41095/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (88.00%) (42238/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (88.00%) (43392/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (88.00%) (44488/50000)
# TEST : Loss: (0.4207) | Acc: (86.00%) (8608/10000)
percent tensor([0.5259, 0.5255, 0.5270, 0.5260, 0.5324, 0.5323, 0.5282, 0.5283, 0.5251,
        0.5238, 0.5265, 0.5244, 0.5251, 0.5208, 0.5300, 0.5261],
       device='cuda:0') torch.Size([16])
percent tensor([0.5012, 0.5006, 0.4995, 0.5002, 0.4997, 0.5022, 0.5002, 0.5009, 0.5009,
        0.4998, 0.5008, 0.5000, 0.5012, 0.5002, 0.5016, 0.5017],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.5399, 0.5432, 0.5404, 0.5736, 0.5512, 0.5456, 0.5464, 0.5427,
        0.5357, 0.5363, 0.5474, 0.5384, 0.5255, 0.5563, 0.5348],
       device='cuda:0') torch.Size([16])
percent tensor([0.6059, 0.6106, 0.5826, 0.5869, 0.5873, 0.5875, 0.6097, 0.5871, 0.5947,
        0.6085, 0.6196, 0.5971, 0.6064, 0.6093, 0.6094, 0.5988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5386, 0.5298, 0.5992, 0.6745, 0.5953, 0.6627, 0.5429, 0.5200, 0.6418,
        0.5473, 0.6021, 0.5907, 0.5339, 0.6968, 0.5206, 0.5748],
       device='cuda:0') torch.Size([16])
percent tensor([0.5984, 0.5838, 0.6379, 0.6353, 0.6364, 0.6078, 0.6231, 0.6364, 0.6170,
        0.5874, 0.5794, 0.6410, 0.5813, 0.6085, 0.6158, 0.6071],
       device='cuda:0') torch.Size([16])
percent tensor([0.6380, 0.5589, 0.7216, 0.6878, 0.7033, 0.7529, 0.6203, 0.6031, 0.6520,
        0.5528, 0.6192, 0.6034, 0.5499, 0.6873, 0.5381, 0.6328],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9987, 0.9996, 0.9994, 0.9993, 0.9993, 0.9994, 0.9998, 0.9988,
        0.9998, 0.9994, 0.9995, 0.9979, 0.9992, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 68 | Batch_idx: 0 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (87.00%) (1237/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.3193) |  Loss2: (0.0000) | Acc: (88.00%) (2383/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (3524/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (4683/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.3100) |  Loss2: (0.0000) | Acc: (89.00%) (5827/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.3123) |  Loss2: (0.0000) | Acc: (89.00%) (6966/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (8110/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (9238/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (10395/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (11524/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (12651/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (13806/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.3096) |  Loss2: (0.0000) | Acc: (89.00%) (14943/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.3098) |  Loss2: (0.0000) | Acc: (89.00%) (16089/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (17229/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.3088) |  Loss2: (0.0000) | Acc: (89.00%) (18391/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (19542/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (20664/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (21810/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (22969/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.3078) |  Loss2: (0.0000) | Acc: (89.00%) (24108/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (25246/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (26373/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.3092) |  Loss2: (0.0000) | Acc: (89.00%) (27509/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (28650/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (29803/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (30943/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (32092/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3082) |  Loss2: (0.0000) | Acc: (89.00%) (33237/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (34379/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3079) |  Loss2: (0.0000) | Acc: (89.00%) (35540/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (36682/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (37817/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (38955/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (40105/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3079) |  Loss2: (0.0000) | Acc: (89.00%) (41262/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (42409/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (43554/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (44628/50000)
# TEST : Loss: (0.4174) | Acc: (86.00%) (8627/10000)
percent tensor([0.5280, 0.5275, 0.5292, 0.5282, 0.5350, 0.5349, 0.5304, 0.5305, 0.5272,
        0.5258, 0.5287, 0.5265, 0.5271, 0.5225, 0.5324, 0.5282],
       device='cuda:0') torch.Size([16])
percent tensor([0.5016, 0.5012, 0.4997, 0.5006, 0.5000, 0.5025, 0.5008, 0.5013, 0.5014,
        0.5003, 0.5013, 0.5004, 0.5016, 0.5008, 0.5020, 0.5021],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.5353, 0.5405, 0.5370, 0.5702, 0.5477, 0.5406, 0.5435, 0.5391,
        0.5303, 0.5312, 0.5437, 0.5343, 0.5210, 0.5515, 0.5302],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.6096, 0.5808, 0.5854, 0.5853, 0.5862, 0.6084, 0.5847, 0.5930,
        0.6075, 0.6183, 0.5951, 0.6052, 0.6080, 0.6082, 0.5975],
       device='cuda:0') torch.Size([16])
percent tensor([0.5384, 0.5321, 0.6002, 0.6744, 0.5944, 0.6588, 0.5415, 0.5202, 0.6423,
        0.5480, 0.6016, 0.5914, 0.5354, 0.6969, 0.5210, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.5973, 0.5794, 0.6409, 0.6385, 0.6404, 0.6144, 0.6227, 0.6386, 0.6170,
        0.5825, 0.5744, 0.6393, 0.5753, 0.6056, 0.6160, 0.6083],
       device='cuda:0') torch.Size([16])
percent tensor([0.6353, 0.5546, 0.7175, 0.6832, 0.6962, 0.7535, 0.6171, 0.5971, 0.6524,
        0.5508, 0.6182, 0.5968, 0.5461, 0.6865, 0.5329, 0.6329],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9987, 0.9997, 0.9994, 0.9993, 0.9993, 0.9994, 0.9998, 0.9988,
        0.9998, 0.9994, 0.9995, 0.9979, 0.9992, 0.9989, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 69 | Batch_idx: 0 |  Loss: (0.3878) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (1278/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (90.00%) (2430/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (3562/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.3079) |  Loss2: (0.0000) | Acc: (89.00%) (4703/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (5843/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (6997/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (8148/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (9298/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (10438/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (11568/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (12726/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (13873/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (15022/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (16152/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (17298/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (18469/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.2989) |  Loss2: (0.0000) | Acc: (89.00%) (19625/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (89.00%) (20785/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.2983) |  Loss2: (0.0000) | Acc: (89.00%) (21937/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.2997) |  Loss2: (0.0000) | Acc: (89.00%) (23076/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (89.00%) (24222/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3006) |  Loss2: (0.0000) | Acc: (89.00%) (25359/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (26488/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3010) |  Loss2: (0.0000) | Acc: (89.00%) (27649/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (28799/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3004) |  Loss2: (0.0000) | Acc: (89.00%) (29959/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3001) |  Loss2: (0.0000) | Acc: (89.00%) (31106/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.2987) |  Loss2: (0.0000) | Acc: (89.00%) (32272/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.2991) |  Loss2: (0.0000) | Acc: (89.00%) (33401/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.2997) |  Loss2: (0.0000) | Acc: (89.00%) (34544/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (35693/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (36843/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3012) |  Loss2: (0.0000) | Acc: (89.00%) (37987/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3011) |  Loss2: (0.0000) | Acc: (89.00%) (39132/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (40264/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (41403/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3030) |  Loss2: (0.0000) | Acc: (89.00%) (42546/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (43687/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (44779/50000)
# TEST : Loss: (0.4151) | Acc: (86.00%) (8636/10000)
percent tensor([0.5277, 0.5269, 0.5290, 0.5278, 0.5347, 0.5348, 0.5299, 0.5299, 0.5268,
        0.5252, 0.5281, 0.5260, 0.5266, 0.5220, 0.5319, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.5017, 0.5000, 0.5009, 0.5004, 0.5027, 0.5013, 0.5017, 0.5018,
        0.5008, 0.5018, 0.5008, 0.5020, 0.5013, 0.5025, 0.5024],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5323, 0.5388, 0.5353, 0.5679, 0.5474, 0.5372, 0.5400, 0.5367,
        0.5273, 0.5287, 0.5414, 0.5322, 0.5187, 0.5495, 0.5283],
       device='cuda:0') torch.Size([16])
percent tensor([0.6067, 0.6116, 0.5822, 0.5871, 0.5867, 0.5882, 0.6104, 0.5863, 0.5947,
        0.6093, 0.6203, 0.5967, 0.6073, 0.6097, 0.6105, 0.5994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.5338, 0.6062, 0.6800, 0.5982, 0.6621, 0.5458, 0.5205, 0.6470,
        0.5511, 0.6061, 0.5982, 0.5374, 0.7010, 0.5221, 0.5796],
       device='cuda:0') torch.Size([16])
percent tensor([0.6004, 0.5805, 0.6452, 0.6429, 0.6452, 0.6215, 0.6256, 0.6418, 0.6199,
        0.5827, 0.5757, 0.6418, 0.5755, 0.6081, 0.6192, 0.6131],
       device='cuda:0') torch.Size([16])
percent tensor([0.6415, 0.5591, 0.7203, 0.6847, 0.6986, 0.7584, 0.6178, 0.5946, 0.6583,
        0.5554, 0.6259, 0.5961, 0.5523, 0.6963, 0.5302, 0.6384],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9997, 0.9994, 0.9993, 0.9993, 0.9995, 0.9998, 0.9989,
        0.9998, 0.9995, 0.9995, 0.9980, 0.9993, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 70 | Batch_idx: 0 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (91.00%) (1287/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (2444/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (89.00%) (3570/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (4688/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (5829/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.3088) |  Loss2: (0.0000) | Acc: (89.00%) (6975/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (8091/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (88.00%) (9227/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (10367/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (11510/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.3127) |  Loss2: (0.0000) | Acc: (88.00%) (12645/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (13798/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (14942/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (16092/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (17233/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (18364/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (19513/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (20654/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.3132) |  Loss2: (0.0000) | Acc: (89.00%) (21795/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (22933/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.3134) |  Loss2: (0.0000) | Acc: (89.00%) (24070/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (25203/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.3134) |  Loss2: (0.0000) | Acc: (89.00%) (26350/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (27480/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (28596/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (88.00%) (29728/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (89.00%) (30876/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (32013/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (33170/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (34324/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (35469/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (36618/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3132) |  Loss2: (0.0000) | Acc: (89.00%) (37758/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (38902/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (40032/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (41182/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (42320/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (43460/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (44564/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_070.pth.tar'
# TEST : Loss: (0.4439) | Acc: (85.00%) (8525/10000)
percent tensor([0.5283, 0.5257, 0.5289, 0.5281, 0.5348, 0.5341, 0.5289, 0.5306, 0.5265,
        0.5245, 0.5273, 0.5262, 0.5269, 0.5199, 0.5315, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5023, 0.5018, 0.5003, 0.5014, 0.5006, 0.5031, 0.5013, 0.5017, 0.5019,
        0.5008, 0.5017, 0.5010, 0.5021, 0.5015, 0.5028, 0.5027],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.5329, 0.5374, 0.5375, 0.5701, 0.5541, 0.5377, 0.5365, 0.5385,
        0.5250, 0.5317, 0.5408, 0.5342, 0.5222, 0.5525, 0.5290],
       device='cuda:0') torch.Size([16])
percent tensor([0.6081, 0.6137, 0.5820, 0.5843, 0.5845, 0.5889, 0.6127, 0.5865, 0.6001,
        0.6120, 0.6262, 0.5988, 0.6116, 0.6137, 0.6128, 0.6000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5484, 0.5320, 0.6140, 0.6868, 0.6004, 0.6596, 0.5468, 0.5243, 0.6310,
        0.5635, 0.6020, 0.6167, 0.5459, 0.6877, 0.5227, 0.5939],
       device='cuda:0') torch.Size([16])
percent tensor([0.6029, 0.5847, 0.6371, 0.6383, 0.6424, 0.6278, 0.6239, 0.6362, 0.6136,
        0.5793, 0.5787, 0.6357, 0.5791, 0.6063, 0.6219, 0.6173],
       device='cuda:0') torch.Size([16])
percent tensor([0.6393, 0.5775, 0.6901, 0.6468, 0.7038, 0.7582, 0.6117, 0.5752, 0.6467,
        0.5598, 0.6411, 0.6004, 0.5603, 0.7046, 0.5514, 0.6533],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9985, 0.9997, 0.9991, 0.9995, 0.9988, 0.9991, 0.9996, 0.9994,
        0.9993, 0.9995, 0.9995, 0.9983, 0.9989, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.8004, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(808.0442, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(805.0436, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.5957, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.4143, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2207.0347, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4292.6592, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1402.6697, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6109.4102, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11958.6650, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3974.6228, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16848.5098, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 71 | Batch_idx: 0 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (91.00%) (1292/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (90.00%) (2429/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (3571/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.3036) |  Loss2: (0.0000) | Acc: (89.00%) (4720/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (90.00%) (5880/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.3006) |  Loss2: (0.0000) | Acc: (90.00%) (7031/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (8175/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.3045) |  Loss2: (0.0000) | Acc: (89.00%) (9322/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (10465/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.3030) |  Loss2: (0.0000) | Acc: (89.00%) (11609/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (12758/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (13910/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (15067/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.2988) |  Loss2: (0.0000) | Acc: (89.00%) (16226/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (17363/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (89.00%) (18504/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (19644/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.3030) |  Loss2: (0.0000) | Acc: (89.00%) (20781/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (21928/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.3014) |  Loss2: (0.0000) | Acc: (89.00%) (23088/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.3010) |  Loss2: (0.0000) | Acc: (89.00%) (24237/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.3006) |  Loss2: (0.0000) | Acc: (89.00%) (25389/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.3010) |  Loss2: (0.0000) | Acc: (89.00%) (26530/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (27684/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (28834/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.3008) |  Loss2: (0.0000) | Acc: (89.00%) (29971/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (31135/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (32272/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (33422/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (34555/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (35701/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.3031) |  Loss2: (0.0000) | Acc: (89.00%) (36829/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (37972/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (39114/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (40244/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (41388/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (42545/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (43692/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (44801/50000)
# TEST : Loss: (0.4457) | Acc: (85.00%) (8512/10000)
percent tensor([0.5287, 0.5265, 0.5299, 0.5280, 0.5361, 0.5346, 0.5304, 0.5305, 0.5280,
        0.5254, 0.5283, 0.5278, 0.5274, 0.5216, 0.5317, 0.5279],
       device='cuda:0') torch.Size([16])
percent tensor([0.5020, 0.5017, 0.5000, 0.5006, 0.5004, 0.5028, 0.5013, 0.5018, 0.5018,
        0.5006, 0.5016, 0.5009, 0.5019, 0.5017, 0.5026, 0.5025],
       device='cuda:0') torch.Size([16])
percent tensor([0.5243, 0.5367, 0.5341, 0.5297, 0.5661, 0.5514, 0.5396, 0.5333, 0.5397,
        0.5280, 0.5332, 0.5381, 0.5373, 0.5223, 0.5512, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.6083, 0.6112, 0.5840, 0.5883, 0.5842, 0.5885, 0.6126, 0.5871, 0.5964,
        0.6113, 0.6250, 0.5993, 0.6090, 0.6106, 0.6109, 0.6003],
       device='cuda:0') torch.Size([16])
percent tensor([0.5439, 0.5339, 0.6229, 0.6855, 0.6111, 0.6558, 0.5536, 0.5299, 0.6436,
        0.5594, 0.6105, 0.6018, 0.5383, 0.6981, 0.5225, 0.5805],
       device='cuda:0') torch.Size([16])
percent tensor([0.6076, 0.5846, 0.6453, 0.6512, 0.6511, 0.6255, 0.6325, 0.6453, 0.6212,
        0.5906, 0.5798, 0.6407, 0.5905, 0.6096, 0.6221, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.6545, 0.5952, 0.7276, 0.6907, 0.7125, 0.7573, 0.6368, 0.5919, 0.6713,
        0.5772, 0.6497, 0.6107, 0.5903, 0.6965, 0.5541, 0.6361],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9987, 0.9999, 0.9998, 0.9996, 0.9993, 0.9994, 0.9997, 0.9993,
        0.9996, 0.9993, 0.9997, 0.9983, 0.9991, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 72 | Batch_idx: 0 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (88.00%) (1247/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (88.00%) (2392/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.2986) |  Loss2: (0.0000) | Acc: (89.00%) (3541/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.2975) |  Loss2: (0.0000) | Acc: (89.00%) (4690/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.2996) |  Loss2: (0.0000) | Acc: (89.00%) (5831/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (6972/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (89.00%) (8134/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (89.00%) (9281/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (89.00%) (10444/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.2947) |  Loss2: (0.0000) | Acc: (89.00%) (11593/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.2947) |  Loss2: (0.0000) | Acc: (89.00%) (12738/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (89.00%) (13910/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.2902) |  Loss2: (0.0000) | Acc: (89.00%) (15063/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.2894) |  Loss2: (0.0000) | Acc: (89.00%) (16217/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (17376/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.2892) |  Loss2: (0.0000) | Acc: (89.00%) (18531/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.2899) |  Loss2: (0.0000) | Acc: (89.00%) (19676/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (20823/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (89.00%) (21978/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.2890) |  Loss2: (0.0000) | Acc: (89.00%) (23143/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.2888) |  Loss2: (0.0000) | Acc: (90.00%) (24309/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.2897) |  Loss2: (0.0000) | Acc: (89.00%) (25450/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.2909) |  Loss2: (0.0000) | Acc: (89.00%) (26587/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (27744/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.2907) |  Loss2: (0.0000) | Acc: (89.00%) (28890/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.2911) |  Loss2: (0.0000) | Acc: (89.00%) (30022/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (89.00%) (31190/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.2905) |  Loss2: (0.0000) | Acc: (89.00%) (32335/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (89.00%) (33476/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.2917) |  Loss2: (0.0000) | Acc: (89.00%) (34631/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (35779/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (89.00%) (36909/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (89.00%) (38068/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (39200/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (40345/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.2932) |  Loss2: (0.0000) | Acc: (89.00%) (41506/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (42653/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (43801/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (44903/50000)
# TEST : Loss: (0.4483) | Acc: (85.00%) (8503/10000)
percent tensor([0.5280, 0.5263, 0.5299, 0.5277, 0.5355, 0.5344, 0.5298, 0.5305, 0.5269,
        0.5250, 0.5277, 0.5266, 0.5266, 0.5210, 0.5314, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5020, 0.5015, 0.5004, 0.5009, 0.5007, 0.5026, 0.5013, 0.5019, 0.5017,
        0.5007, 0.5015, 0.5011, 0.5018, 0.5013, 0.5022, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5233, 0.5342, 0.5356, 0.5306, 0.5646, 0.5493, 0.5377, 0.5307, 0.5343,
        0.5274, 0.5292, 0.5392, 0.5337, 0.5210, 0.5482, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.6048, 0.6143, 0.5822, 0.5859, 0.5839, 0.5882, 0.6136, 0.5889, 0.5961,
        0.6102, 0.6242, 0.5988, 0.6075, 0.6146, 0.6129, 0.5976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5335, 0.5264, 0.6248, 0.6762, 0.6183, 0.6520, 0.5396, 0.5286, 0.6493,
        0.5480, 0.5974, 0.6058, 0.5360, 0.6894, 0.5151, 0.5662],
       device='cuda:0') torch.Size([16])
percent tensor([0.6087, 0.5867, 0.6446, 0.6476, 0.6503, 0.6251, 0.6283, 0.6467, 0.6256,
        0.5895, 0.5854, 0.6421, 0.5913, 0.6104, 0.6221, 0.6161],
       device='cuda:0') torch.Size([16])
percent tensor([0.6259, 0.5696, 0.6844, 0.6520, 0.7024, 0.7643, 0.5912, 0.5682, 0.6435,
        0.5574, 0.6405, 0.5844, 0.5619, 0.6743, 0.5023, 0.6079],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9993, 0.9998, 0.9997, 0.9996, 0.9988, 0.9994, 0.9997, 0.9996,
        0.9997, 0.9997, 0.9997, 0.9987, 0.9996, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 73 | Batch_idx: 0 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (91.00%) (1285/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (91.00%) (2458/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (3608/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (4763/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (5916/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (7073/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (8246/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (9396/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (10562/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (11689/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.2767) |  Loss2: (0.0000) | Acc: (90.00%) (12839/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (14000/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (15156/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.2789) |  Loss2: (0.0000) | Acc: (90.00%) (16309/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (17452/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (18605/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (19762/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (20911/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (22063/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (23206/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (24349/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (90.00%) (25514/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (26665/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.2859) |  Loss2: (0.0000) | Acc: (90.00%) (27806/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (28941/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.2872) |  Loss2: (0.0000) | Acc: (90.00%) (30088/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (90.00%) (31226/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.2881) |  Loss2: (0.0000) | Acc: (90.00%) (32378/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (90.00%) (33531/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (90.00%) (34694/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (35863/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (37024/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (38174/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (39331/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (40475/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.2876) |  Loss2: (0.0000) | Acc: (90.00%) (41607/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.2870) |  Loss2: (0.0000) | Acc: (90.00%) (42772/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.2876) |  Loss2: (0.0000) | Acc: (90.00%) (43914/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.2881) |  Loss2: (0.0000) | Acc: (90.00%) (45010/50000)
# TEST : Loss: (0.4587) | Acc: (85.00%) (8528/10000)
percent tensor([0.5287, 0.5266, 0.5304, 0.5288, 0.5361, 0.5357, 0.5300, 0.5310, 0.5272,
        0.5250, 0.5281, 0.5270, 0.5269, 0.5211, 0.5322, 0.5285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5021, 0.5017, 0.5003, 0.5011, 0.5008, 0.5031, 0.5015, 0.5018, 0.5019,
        0.5007, 0.5016, 0.5012, 0.5019, 0.5013, 0.5027, 0.5024],
       device='cuda:0') torch.Size([16])
percent tensor([0.5267, 0.5346, 0.5334, 0.5389, 0.5653, 0.5545, 0.5379, 0.5361, 0.5353,
        0.5260, 0.5312, 0.5393, 0.5349, 0.5194, 0.5528, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.6082, 0.6110, 0.5857, 0.5882, 0.5888, 0.5897, 0.6125, 0.5867, 0.5963,
        0.6108, 0.6229, 0.6004, 0.6066, 0.6118, 0.6125, 0.5980],
       device='cuda:0') torch.Size([16])
percent tensor([0.5473, 0.5387, 0.6165, 0.6828, 0.6105, 0.6600, 0.5615, 0.5371, 0.6442,
        0.5570, 0.6118, 0.6023, 0.5394, 0.6957, 0.5314, 0.5866],
       device='cuda:0') torch.Size([16])
percent tensor([0.6108, 0.5943, 0.6427, 0.6425, 0.6491, 0.6316, 0.6368, 0.6444, 0.6302,
        0.5897, 0.5890, 0.6454, 0.5881, 0.6182, 0.6270, 0.6190],
       device='cuda:0') torch.Size([16])
percent tensor([0.6477, 0.6104, 0.6836, 0.6517, 0.6967, 0.7802, 0.6422, 0.5767, 0.6408,
        0.5702, 0.6416, 0.5692, 0.5622, 0.6796, 0.5347, 0.6527],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9991, 0.9998, 0.9996, 0.9996, 0.9991, 0.9995, 0.9997, 0.9995,
        0.9996, 0.9997, 0.9997, 0.9989, 0.9992, 0.9986, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 74 | Batch_idx: 0 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (1270/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (2423/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (3589/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (4753/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (5916/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (7057/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (8206/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (9357/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (10522/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (11675/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (12839/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (13995/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (15160/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (16322/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (17482/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (18644/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (19797/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (20942/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (22100/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (23257/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (24416/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2752) |  Loss2: (0.0000) | Acc: (90.00%) (25553/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (26678/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2789) |  Loss2: (0.0000) | Acc: (90.00%) (27818/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (28961/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (30128/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (31279/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (32454/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2776) |  Loss2: (0.0000) | Acc: (90.00%) (33606/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (34755/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (35913/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (37075/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (38230/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (39381/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (40521/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (41666/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (42819/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2794) |  Loss2: (0.0000) | Acc: (90.00%) (43973/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (45083/50000)
# TEST : Loss: (0.4571) | Acc: (85.00%) (8552/10000)
percent tensor([0.5286, 0.5256, 0.5292, 0.5284, 0.5360, 0.5350, 0.5290, 0.5306, 0.5265,
        0.5244, 0.5272, 0.5265, 0.5265, 0.5196, 0.5316, 0.5277],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.5015, 0.5003, 0.5010, 0.5007, 0.5033, 0.5013, 0.5016, 0.5017,
        0.5007, 0.5017, 0.5011, 0.5020, 0.5005, 0.5026, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5264, 0.5329, 0.5258, 0.5331, 0.5641, 0.5509, 0.5361, 0.5300, 0.5353,
        0.5253, 0.5319, 0.5359, 0.5347, 0.5214, 0.5524, 0.5263],
       device='cuda:0') torch.Size([16])
percent tensor([0.6068, 0.6101, 0.5880, 0.5866, 0.5866, 0.5862, 0.6106, 0.5868, 0.5972,
        0.6097, 0.6224, 0.6024, 0.6064, 0.6084, 0.6104, 0.5971],
       device='cuda:0') torch.Size([16])
percent tensor([0.5561, 0.5366, 0.6411, 0.6909, 0.6190, 0.6645, 0.5518, 0.5335, 0.6507,
        0.5588, 0.6147, 0.6199, 0.5507, 0.6867, 0.5363, 0.5903],
       device='cuda:0') torch.Size([16])
percent tensor([0.6100, 0.5956, 0.6410, 0.6383, 0.6474, 0.6276, 0.6303, 0.6414, 0.6233,
        0.5927, 0.5852, 0.6417, 0.5939, 0.6232, 0.6291, 0.6220],
       device='cuda:0') torch.Size([16])
percent tensor([0.6615, 0.6167, 0.7109, 0.6633, 0.7098, 0.7679, 0.6552, 0.5881, 0.6803,
        0.6120, 0.6532, 0.6106, 0.6023, 0.7229, 0.5610, 0.6595],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9991, 0.9998, 0.9992, 0.9994, 0.9992, 0.9993, 0.9996, 0.9994,
        0.9997, 0.9996, 0.9996, 0.9987, 0.9991, 0.9987, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 75 | Batch_idx: 0 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (2429/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (89.00%) (3569/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.2925) |  Loss2: (0.0000) | Acc: (89.00%) (4713/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.3073) |  Loss2: (0.0000) | Acc: (89.00%) (5818/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (6959/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (88.00%) (8066/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (88.00%) (9196/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (10307/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.3262) |  Loss2: (0.0000) | Acc: (88.00%) (11441/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.3279) |  Loss2: (0.0000) | Acc: (88.00%) (12565/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (13679/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.3310) |  Loss2: (0.0000) | Acc: (88.00%) (14815/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.3309) |  Loss2: (0.0000) | Acc: (88.00%) (15945/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (17081/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.3311) |  Loss2: (0.0000) | Acc: (88.00%) (18215/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.3330) |  Loss2: (0.0000) | Acc: (88.00%) (19331/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.3350) |  Loss2: (0.0000) | Acc: (88.00%) (20447/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (21579/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.3343) |  Loss2: (0.0000) | Acc: (88.00%) (22721/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (23876/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.3319) |  Loss2: (0.0000) | Acc: (88.00%) (25012/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (26155/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.3289) |  Loss2: (0.0000) | Acc: (88.00%) (27298/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (28416/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (29547/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.3293) |  Loss2: (0.0000) | Acc: (88.00%) (30691/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (31809/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (88.00%) (32960/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.3286) |  Loss2: (0.0000) | Acc: (88.00%) (34109/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (35265/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.3266) |  Loss2: (0.0000) | Acc: (88.00%) (36411/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.3258) |  Loss2: (0.0000) | Acc: (88.00%) (37562/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.3258) |  Loss2: (0.0000) | Acc: (88.00%) (38703/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (39820/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (40970/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (42108/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (43233/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (88.00%) (44330/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_075.pth.tar'
# TEST : Loss: (0.4560) | Acc: (84.00%) (8460/10000)
percent tensor([0.5431, 0.5401, 0.5455, 0.5413, 0.5542, 0.5497, 0.5449, 0.5463, 0.5418,
        0.5386, 0.5414, 0.5433, 0.5412, 0.5315, 0.5467, 0.5414],
       device='cuda:0') torch.Size([16])
percent tensor([0.5020, 0.5009, 0.5003, 0.5009, 0.5007, 0.5032, 0.5010, 0.5012, 0.5016,
        0.5003, 0.5014, 0.5009, 0.5017, 0.5002, 0.5022, 0.5020],
       device='cuda:0') torch.Size([16])
percent tensor([0.5185, 0.5198, 0.5190, 0.5273, 0.5539, 0.5473, 0.5228, 0.5218, 0.5230,
        0.5114, 0.5169, 0.5257, 0.5230, 0.5143, 0.5421, 0.5187],
       device='cuda:0') torch.Size([16])
percent tensor([0.5786, 0.5811, 0.5656, 0.5649, 0.5630, 0.5631, 0.5825, 0.5625, 0.5712,
        0.5814, 0.5906, 0.5733, 0.5756, 0.5816, 0.5824, 0.5710],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.5336, 0.6655, 0.7157, 0.6449, 0.6854, 0.5471, 0.5443, 0.6358,
        0.5482, 0.5982, 0.6224, 0.5340, 0.6768, 0.5407, 0.5963],
       device='cuda:0') torch.Size([16])
percent tensor([0.6229, 0.6047, 0.6545, 0.6458, 0.6688, 0.6388, 0.6433, 0.6582, 0.6415,
        0.5992, 0.5932, 0.6590, 0.6042, 0.6330, 0.6414, 0.6293],
       device='cuda:0') torch.Size([16])
percent tensor([0.4855, 0.4366, 0.5681, 0.5290, 0.5902, 0.6743, 0.4832, 0.4397, 0.5015,
        0.4373, 0.4798, 0.4684, 0.4434, 0.5544, 0.4263, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9990, 0.9996, 0.9989, 0.9995, 0.9992, 0.9992, 0.9996, 0.9993,
        0.9996, 0.9995, 0.9994, 0.9985, 0.9987, 0.9986, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 76 | Batch_idx: 0 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (1244/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.3215) |  Loss2: (0.0000) | Acc: (88.00%) (2380/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (3508/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (88.00%) (4643/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (88.00%) (5783/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (88.00%) (6915/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.3199) |  Loss2: (0.0000) | Acc: (88.00%) (8035/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (88.00%) (9186/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (88.00%) (10358/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.3100) |  Loss2: (0.0000) | Acc: (89.00%) (11519/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.3069) |  Loss2: (0.0000) | Acc: (89.00%) (12671/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.3099) |  Loss2: (0.0000) | Acc: (89.00%) (13803/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (14950/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (16089/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (17239/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (18400/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (19532/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (20673/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.3093) |  Loss2: (0.0000) | Acc: (89.00%) (21817/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.3078) |  Loss2: (0.0000) | Acc: (89.00%) (22972/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (24129/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (25278/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.3062) |  Loss2: (0.0000) | Acc: (89.00%) (26419/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (27571/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (28717/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (29885/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (31028/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (32164/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (33293/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.3036) |  Loss2: (0.0000) | Acc: (89.00%) (34434/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (35591/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (36726/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (37861/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (39004/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (40131/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (41285/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.3031) |  Loss2: (0.0000) | Acc: (89.00%) (42442/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (43592/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (44705/50000)
# TEST : Loss: (0.4377) | Acc: (85.00%) (8514/10000)
percent tensor([0.5448, 0.5419, 0.5477, 0.5429, 0.5563, 0.5510, 0.5469, 0.5484, 0.5436,
        0.5407, 0.5431, 0.5455, 0.5429, 0.5331, 0.5482, 0.5430],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.5011, 0.5003, 0.5011, 0.5008, 0.5035, 0.5012, 0.5014, 0.5018,
        0.5005, 0.5016, 0.5011, 0.5019, 0.5005, 0.5024, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5162, 0.5148, 0.5203, 0.5269, 0.5549, 0.5484, 0.5200, 0.5239, 0.5214,
        0.5067, 0.5125, 0.5247, 0.5185, 0.5128, 0.5397, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.5820, 0.5840, 0.5689, 0.5675, 0.5664, 0.5660, 0.5868, 0.5668, 0.5749,
        0.5839, 0.5934, 0.5770, 0.5780, 0.5855, 0.5862, 0.5739],
       device='cuda:0') torch.Size([16])
percent tensor([0.5634, 0.5457, 0.6634, 0.7134, 0.6445, 0.6911, 0.5556, 0.5430, 0.6397,
        0.5554, 0.6043, 0.6193, 0.5451, 0.6826, 0.5503, 0.6061],
       device='cuda:0') torch.Size([16])
percent tensor([0.6148, 0.5954, 0.6492, 0.6422, 0.6628, 0.6347, 0.6345, 0.6527, 0.6317,
        0.5885, 0.5833, 0.6497, 0.5932, 0.6217, 0.6331, 0.6208],
       device='cuda:0') torch.Size([16])
percent tensor([0.4815, 0.4368, 0.5896, 0.5519, 0.6161, 0.6924, 0.4898, 0.4604, 0.5033,
        0.4395, 0.4762, 0.4753, 0.4383, 0.5442, 0.4298, 0.5264],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9990, 0.9996, 0.9990, 0.9995, 0.9992, 0.9992, 0.9997, 0.9993,
        0.9996, 0.9995, 0.9994, 0.9985, 0.9987, 0.9988, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 77 | Batch_idx: 0 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (89.00%) (1265/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (89.00%) (2401/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (3535/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (4697/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.2973) |  Loss2: (0.0000) | Acc: (89.00%) (5830/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.2934) |  Loss2: (0.0000) | Acc: (89.00%) (6995/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (89.00%) (8121/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.2991) |  Loss2: (0.0000) | Acc: (89.00%) (9267/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.2969) |  Loss2: (0.0000) | Acc: (89.00%) (10426/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.2975) |  Loss2: (0.0000) | Acc: (89.00%) (11570/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.2974) |  Loss2: (0.0000) | Acc: (89.00%) (12705/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.2997) |  Loss2: (0.0000) | Acc: (89.00%) (13841/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.2978) |  Loss2: (0.0000) | Acc: (89.00%) (14997/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.2973) |  Loss2: (0.0000) | Acc: (89.00%) (16146/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.2951) |  Loss2: (0.0000) | Acc: (89.00%) (17312/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (18459/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (19626/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (20781/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (89.00%) (21952/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.2920) |  Loss2: (0.0000) | Acc: (89.00%) (23113/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.2919) |  Loss2: (0.0000) | Acc: (89.00%) (24269/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.2920) |  Loss2: (0.0000) | Acc: (89.00%) (25417/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.2918) |  Loss2: (0.0000) | Acc: (89.00%) (26568/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.2910) |  Loss2: (0.0000) | Acc: (89.00%) (27727/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (89.00%) (28889/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.2890) |  Loss2: (0.0000) | Acc: (89.00%) (30049/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (89.00%) (31210/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (32354/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.2887) |  Loss2: (0.0000) | Acc: (89.00%) (33506/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (34668/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (35825/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.2885) |  Loss2: (0.0000) | Acc: (89.00%) (36973/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.2876) |  Loss2: (0.0000) | Acc: (90.00%) (38135/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (39293/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.2877) |  Loss2: (0.0000) | Acc: (90.00%) (40442/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (41610/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.2870) |  Loss2: (0.0000) | Acc: (90.00%) (42772/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.2872) |  Loss2: (0.0000) | Acc: (90.00%) (43917/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (45017/50000)
# TEST : Loss: (0.4309) | Acc: (85.00%) (8550/10000)
percent tensor([0.5432, 0.5401, 0.5466, 0.5414, 0.5547, 0.5492, 0.5454, 0.5470, 0.5422,
        0.5393, 0.5413, 0.5441, 0.5413, 0.5320, 0.5462, 0.5413],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.5012, 0.5004, 0.5013, 0.5008, 0.5036, 0.5013, 0.5015, 0.5019,
        0.5006, 0.5018, 0.5011, 0.5020, 0.5007, 0.5026, 0.5024],
       device='cuda:0') torch.Size([16])
percent tensor([0.5155, 0.5130, 0.5217, 0.5272, 0.5568, 0.5504, 0.5196, 0.5248, 0.5219,
        0.5054, 0.5108, 0.5259, 0.5172, 0.5127, 0.5393, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.5898, 0.5746, 0.5724, 0.5723, 0.5707, 0.5938, 0.5737, 0.5814,
        0.5896, 0.5995, 0.5836, 0.5834, 0.5924, 0.5925, 0.5792],
       device='cuda:0') torch.Size([16])
percent tensor([0.5667, 0.5456, 0.6653, 0.7157, 0.6471, 0.6943, 0.5572, 0.5465, 0.6452,
        0.5568, 0.6068, 0.6215, 0.5465, 0.6867, 0.5525, 0.6094],
       device='cuda:0') torch.Size([16])
percent tensor([0.6199, 0.5989, 0.6565, 0.6486, 0.6690, 0.6410, 0.6388, 0.6591, 0.6353,
        0.5912, 0.5863, 0.6547, 0.5962, 0.6242, 0.6379, 0.6246],
       device='cuda:0') torch.Size([16])
percent tensor([0.5066, 0.4558, 0.6195, 0.5809, 0.6409, 0.7235, 0.5160, 0.4781, 0.5293,
        0.4578, 0.5034, 0.4950, 0.4581, 0.5641, 0.4449, 0.5548],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9997, 0.9991, 0.9995, 0.9992, 0.9993, 0.9997, 0.9994,
        0.9997, 0.9996, 0.9994, 0.9987, 0.9987, 0.9988, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 78 | Batch_idx: 0 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (91.00%) (2449/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2766) |  Loss2: (0.0000) | Acc: (90.00%) (3595/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (4762/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (91.00%) (5941/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (7085/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (8209/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (9358/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (10521/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (11666/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (90.00%) (12806/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (13969/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (15139/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (16309/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.2808) |  Loss2: (0.0000) | Acc: (90.00%) (17483/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (90.00%) (18628/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (19774/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (20917/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (22075/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (23224/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.2846) |  Loss2: (0.0000) | Acc: (90.00%) (24370/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (90.00%) (25513/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (26663/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.2855) |  Loss2: (0.0000) | Acc: (90.00%) (27824/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (28990/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (30144/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.2846) |  Loss2: (0.0000) | Acc: (90.00%) (31300/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (32462/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (33612/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (34774/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (35911/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (37067/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (38232/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (39400/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (40568/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (41717/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (42871/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (44021/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (90.00%) (45152/50000)
# TEST : Loss: (0.4197) | Acc: (85.00%) (8586/10000)
percent tensor([0.5436, 0.5408, 0.5473, 0.5421, 0.5553, 0.5493, 0.5461, 0.5478, 0.5428,
        0.5401, 0.5418, 0.5448, 0.5418, 0.5329, 0.5466, 0.5419],
       device='cuda:0') torch.Size([16])
percent tensor([0.5027, 0.5016, 0.5007, 0.5017, 0.5011, 0.5040, 0.5017, 0.5019, 0.5023,
        0.5010, 0.5021, 0.5015, 0.5024, 0.5011, 0.5029, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.5161, 0.5143, 0.5236, 0.5273, 0.5586, 0.5503, 0.5217, 0.5277, 0.5250,
        0.5071, 0.5121, 0.5285, 0.5190, 0.5152, 0.5400, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5935, 0.5945, 0.5804, 0.5775, 0.5782, 0.5754, 0.6000, 0.5800, 0.5872,
        0.5945, 0.6048, 0.5896, 0.5878, 0.5985, 0.5984, 0.5840],
       device='cuda:0') torch.Size([16])
percent tensor([0.5624, 0.5442, 0.6586, 0.7080, 0.6430, 0.6869, 0.5553, 0.5442, 0.6405,
        0.5527, 0.6015, 0.6141, 0.5425, 0.6809, 0.5510, 0.6023],
       device='cuda:0') torch.Size([16])
percent tensor([0.6251, 0.6029, 0.6636, 0.6565, 0.6757, 0.6487, 0.6449, 0.6658, 0.6397,
        0.5944, 0.5905, 0.6604, 0.5985, 0.6296, 0.6432, 0.6295],
       device='cuda:0') torch.Size([16])
percent tensor([0.5242, 0.4716, 0.6395, 0.6045, 0.6616, 0.7386, 0.5371, 0.5033, 0.5449,
        0.4750, 0.5199, 0.5131, 0.4695, 0.5706, 0.4626, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9991, 0.9997, 0.9992, 0.9996, 0.9990, 0.9994, 0.9997, 0.9994,
        0.9997, 0.9996, 0.9995, 0.9986, 0.9988, 0.9988, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 79 | Batch_idx: 0 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (1278/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (91.00%) (2447/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (3605/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (4763/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (91.00%) (5941/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (7085/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (8252/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (9404/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (10554/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (11726/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (12883/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (14048/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (15209/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (16382/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (17533/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (18698/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (19848/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (21014/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (22161/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2747) |  Loss2: (0.0000) | Acc: (90.00%) (23321/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (24491/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (25662/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (26833/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (27988/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2767) |  Loss2: (0.0000) | Acc: (90.00%) (29118/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (30279/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (31460/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (32626/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (33783/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (34926/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (36093/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (37270/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (38428/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (39585/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (40754/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (41912/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (43093/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (44251/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (45357/50000)
# TEST : Loss: (0.4175) | Acc: (86.00%) (8615/10000)
percent tensor([0.5438, 0.5412, 0.5477, 0.5423, 0.5556, 0.5492, 0.5465, 0.5481, 0.5432,
        0.5406, 0.5422, 0.5452, 0.5422, 0.5334, 0.5467, 0.5421],
       device='cuda:0') torch.Size([16])
percent tensor([0.5026, 0.5013, 0.5004, 0.5014, 0.5008, 0.5039, 0.5014, 0.5015, 0.5021,
        0.5007, 0.5019, 0.5012, 0.5022, 0.5010, 0.5027, 0.5026],
       device='cuda:0') torch.Size([16])
percent tensor([0.5161, 0.5158, 0.5238, 0.5270, 0.5599, 0.5504, 0.5231, 0.5287, 0.5271,
        0.5082, 0.5131, 0.5302, 0.5205, 0.5168, 0.5407, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5943, 0.5945, 0.5819, 0.5786, 0.5798, 0.5762, 0.6012, 0.5819, 0.5884,
        0.5944, 0.6048, 0.5906, 0.5874, 0.5998, 0.5993, 0.5843],
       device='cuda:0') torch.Size([16])
percent tensor([0.5582, 0.5414, 0.6507, 0.6990, 0.6362, 0.6791, 0.5524, 0.5395, 0.6365,
        0.5505, 0.6005, 0.6084, 0.5387, 0.6792, 0.5476, 0.5954],
       device='cuda:0') torch.Size([16])
percent tensor([0.6185, 0.5947, 0.6589, 0.6528, 0.6701, 0.6450, 0.6376, 0.6595, 0.6325,
        0.5857, 0.5831, 0.6537, 0.5893, 0.6225, 0.6355, 0.6218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.4739, 0.6441, 0.6144, 0.6668, 0.7489, 0.5397, 0.5048, 0.5472,
        0.4790, 0.5232, 0.5171, 0.4720, 0.5704, 0.4659, 0.5872],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9992, 0.9998, 0.9993, 0.9996, 0.9991, 0.9994, 0.9998, 0.9994,
        0.9997, 0.9996, 0.9995, 0.9987, 0.9989, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 80 | Batch_idx: 0 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (1278/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (2429/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (3584/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (4748/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (5924/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (7083/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (8258/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (9432/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2610) |  Loss2: (0.0000) | Acc: (91.00%) (10601/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (91.00%) (11773/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (12924/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (14070/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (15209/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (16360/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (17512/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (18667/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (19833/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (20992/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2711) |  Loss2: (0.0000) | Acc: (90.00%) (22144/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (23308/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (24477/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (25632/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (26785/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (27943/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (29089/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (30245/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (31404/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (32551/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (33702/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (34856/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (36022/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (37165/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (38309/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (39467/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (40609/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (41765/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (42921/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (44081/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (45191/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_080.pth.tar'
# TEST : Loss: (0.5107) | Acc: (83.00%) (8347/10000)
percent tensor([0.5432, 0.5416, 0.5465, 0.5425, 0.5530, 0.5468, 0.5465, 0.5485, 0.5431,
        0.5413, 0.5426, 0.5432, 0.5429, 0.5344, 0.5459, 0.5423],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.5013, 0.4998, 0.5009, 0.5001, 0.5034, 0.5011, 0.5013, 0.5019,
        0.5003, 0.5016, 0.5005, 0.5018, 0.5015, 0.5026, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5154, 0.5177, 0.5400, 0.5273, 0.5683, 0.5493, 0.5276, 0.5396, 0.5339,
        0.5100, 0.5151, 0.5355, 0.5208, 0.5142, 0.5394, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.5958, 0.5776, 0.5788, 0.5793, 0.5758, 0.6010, 0.5827, 0.5862,
        0.5929, 0.6076, 0.5849, 0.5884, 0.6033, 0.5991, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.5602, 0.5453, 0.6280, 0.6830, 0.6250, 0.6719, 0.5532, 0.5407, 0.6322,
        0.5478, 0.6121, 0.5937, 0.5508, 0.6820, 0.5453, 0.5946],
       device='cuda:0') torch.Size([16])
percent tensor([0.6264, 0.6000, 0.6759, 0.6649, 0.6755, 0.6460, 0.6488, 0.6675, 0.6364,
        0.5958, 0.5973, 0.6670, 0.5951, 0.6220, 0.6382, 0.6305],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.5100, 0.6702, 0.6136, 0.6703, 0.7441, 0.5427, 0.5221, 0.5741,
        0.5248, 0.5632, 0.5230, 0.4847, 0.5501, 0.4913, 0.5998],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9998, 0.9997, 0.9994, 0.9989, 0.9995, 0.9998, 0.9996,
        0.9998, 0.9997, 0.9999, 0.9989, 0.9997, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.5974, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(811.2915, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(808.8826, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1523.4094, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(499.5145, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2214.8945, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4290.1240, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1397.6487, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6119.3076, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11921.5127, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3959.2683, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16780.4375, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 81 | Batch_idx: 0 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (90.00%) (1277/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (2456/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (3622/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (4807/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (5974/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (7131/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (91.00%) (8286/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2601) |  Loss2: (0.0000) | Acc: (91.00%) (9452/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (91.00%) (10610/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (91.00%) (11778/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (91.00%) (12946/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2606) |  Loss2: (0.0000) | Acc: (91.00%) (14123/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (91.00%) (15292/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (91.00%) (16458/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2607) |  Loss2: (0.0000) | Acc: (91.00%) (17617/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (91.00%) (18774/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (91.00%) (19944/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (91.00%) (21103/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (91.00%) (22257/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (23411/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (24574/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (25741/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (90.00%) (26903/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (28063/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (29231/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (30384/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (31548/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2668) |  Loss2: (0.0000) | Acc: (90.00%) (32696/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (33862/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2673) |  Loss2: (0.0000) | Acc: (90.00%) (35017/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (36182/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (37340/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2668) |  Loss2: (0.0000) | Acc: (90.00%) (38506/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (39652/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (40812/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (41958/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (43106/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (44261/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (45381/50000)
# TEST : Loss: (0.4428) | Acc: (85.00%) (8540/10000)
percent tensor([0.5435, 0.5407, 0.5460, 0.5424, 0.5527, 0.5490, 0.5461, 0.5466, 0.5413,
        0.5403, 0.5422, 0.5433, 0.5420, 0.5337, 0.5462, 0.5421],
       device='cuda:0') torch.Size([16])
percent tensor([0.5028, 0.5017, 0.5003, 0.5012, 0.5003, 0.5038, 0.5014, 0.5015, 0.5020,
        0.5009, 0.5021, 0.5011, 0.5022, 0.5015, 0.5029, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.5152, 0.5178, 0.5357, 0.5230, 0.5630, 0.5484, 0.5262, 0.5312, 0.5285,
        0.5095, 0.5138, 0.5347, 0.5204, 0.5137, 0.5373, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5944, 0.5965, 0.5749, 0.5794, 0.5775, 0.5788, 0.6004, 0.5821, 0.5883,
        0.5941, 0.6067, 0.5828, 0.5909, 0.6014, 0.5988, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5424, 0.6469, 0.6978, 0.6462, 0.6814, 0.5579, 0.5515, 0.6474,
        0.5555, 0.6042, 0.6075, 0.5546, 0.6845, 0.5432, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.6109, 0.5881, 0.6643, 0.6550, 0.6654, 0.6414, 0.6292, 0.6594, 0.6314,
        0.5848, 0.5834, 0.6549, 0.5885, 0.6091, 0.6268, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.5315, 0.4870, 0.6681, 0.6088, 0.6412, 0.7224, 0.5359, 0.5077, 0.5516,
        0.5011, 0.5445, 0.5348, 0.4862, 0.5670, 0.4629, 0.5451],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9993, 0.9997, 0.9994, 0.9996, 0.9986, 0.9995, 0.9997, 0.9997,
        0.9997, 0.9997, 0.9995, 0.9991, 0.9995, 0.9990, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 82 | Batch_idx: 0 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (1272/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (2460/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (3616/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (4785/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (5959/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (7121/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (8286/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (9453/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (10620/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (11786/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (12933/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2596) |  Loss2: (0.0000) | Acc: (90.00%) (14083/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2609) |  Loss2: (0.0000) | Acc: (90.00%) (15241/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (16386/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2668) |  Loss2: (0.0000) | Acc: (90.00%) (17533/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (18707/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (19877/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (21040/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (90.00%) (22227/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (23380/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (24526/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (25697/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (26854/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (28016/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (29175/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (30334/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (31498/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (32680/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (33835/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (35011/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (90.00%) (36177/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (90.00%) (37339/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2627) |  Loss2: (0.0000) | Acc: (90.00%) (38494/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (90.00%) (39655/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2617) |  Loss2: (0.0000) | Acc: (90.00%) (40831/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (90.00%) (41992/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2620) |  Loss2: (0.0000) | Acc: (90.00%) (43133/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (90.00%) (44279/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (90.00%) (45405/50000)
# TEST : Loss: (0.4579) | Acc: (85.00%) (8505/10000)
percent tensor([0.5426, 0.5420, 0.5461, 0.5421, 0.5525, 0.5470, 0.5470, 0.5475, 0.5420,
        0.5412, 0.5426, 0.5433, 0.5419, 0.5353, 0.5461, 0.5418],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.5015, 0.4999, 0.5014, 0.5001, 0.5034, 0.5013, 0.5017, 0.5017,
        0.5006, 0.5019, 0.5007, 0.5020, 0.5015, 0.5029, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.5140, 0.5192, 0.5320, 0.5241, 0.5607, 0.5514, 0.5300, 0.5307, 0.5274,
        0.5101, 0.5145, 0.5291, 0.5192, 0.5177, 0.5370, 0.5180],
       device='cuda:0') torch.Size([16])
percent tensor([0.5972, 0.5958, 0.5813, 0.5800, 0.5826, 0.5788, 0.6019, 0.5831, 0.5889,
        0.5939, 0.6080, 0.5876, 0.5906, 0.6001, 0.5996, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.5566, 0.5350, 0.6194, 0.6904, 0.6181, 0.6538, 0.5518, 0.5406, 0.6521,
        0.5475, 0.6058, 0.5813, 0.5428, 0.6955, 0.5345, 0.5695],
       device='cuda:0') torch.Size([16])
percent tensor([0.6173, 0.5915, 0.6624, 0.6551, 0.6673, 0.6427, 0.6378, 0.6609, 0.6355,
        0.5893, 0.5936, 0.6441, 0.5811, 0.6181, 0.6306, 0.6154],
       device='cuda:0') torch.Size([16])
percent tensor([0.5351, 0.4942, 0.6740, 0.6038, 0.6682, 0.7249, 0.5667, 0.5023, 0.5904,
        0.5071, 0.5601, 0.4807, 0.4770, 0.5837, 0.4894, 0.5616],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9998, 0.9996, 0.9995, 0.9991, 0.9995, 0.9998, 0.9996,
        0.9997, 0.9998, 0.9995, 0.9991, 0.9994, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 83 | Batch_idx: 0 |  Loss: (0.2951) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (1304/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (92.00%) (2476/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (3644/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (92.00%) (4831/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (92.00%) (6009/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (7178/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (8343/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (9519/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (10694/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (11854/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (13012/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (14170/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (15347/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (16522/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (17695/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (18861/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (20039/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (21203/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (91.00%) (22367/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (23526/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (24700/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (91.00%) (25849/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (27036/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (28195/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (29357/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (91.00%) (30515/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (31700/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (32872/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (34035/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2566) |  Loss2: (0.0000) | Acc: (91.00%) (35182/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (36347/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2572) |  Loss2: (0.0000) | Acc: (91.00%) (37496/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (38681/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (39862/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (41024/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (42188/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (43350/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2575) |  Loss2: (0.0000) | Acc: (91.00%) (44498/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2573) |  Loss2: (0.0000) | Acc: (91.00%) (45645/50000)
# TEST : Loss: (0.4201) | Acc: (86.00%) (8615/10000)
percent tensor([0.5429, 0.5414, 0.5454, 0.5433, 0.5528, 0.5478, 0.5462, 0.5467, 0.5410,
        0.5402, 0.5412, 0.5434, 0.5412, 0.5351, 0.5460, 0.5419],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.5012, 0.4995, 0.5010, 0.4996, 0.5034, 0.5008, 0.5014, 0.5012,
        0.5003, 0.5016, 0.5002, 0.5017, 0.5011, 0.5026, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5170, 0.5169, 0.5297, 0.5245, 0.5664, 0.5531, 0.5285, 0.5318, 0.5303,
        0.5091, 0.5139, 0.5317, 0.5189, 0.5173, 0.5377, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5919, 0.5963, 0.5776, 0.5782, 0.5793, 0.5774, 0.6010, 0.5810, 0.5861,
        0.5925, 0.6073, 0.5856, 0.5883, 0.5997, 0.5982, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5600, 0.5481, 0.6434, 0.6904, 0.6339, 0.6634, 0.5624, 0.5443, 0.6661,
        0.5642, 0.6264, 0.6008, 0.5505, 0.7062, 0.5466, 0.5941],
       device='cuda:0') torch.Size([16])
percent tensor([0.6129, 0.5919, 0.6645, 0.6664, 0.6709, 0.6433, 0.6416, 0.6551, 0.6274,
        0.5852, 0.5848, 0.6569, 0.5807, 0.6274, 0.6349, 0.6194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5565, 0.4914, 0.6796, 0.6360, 0.6713, 0.7275, 0.5660, 0.4967, 0.5863,
        0.5170, 0.5484, 0.4909, 0.4854, 0.5938, 0.4952, 0.5787],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9991, 0.9998, 0.9998, 0.9993, 0.9987, 0.9996, 0.9998, 0.9993,
        0.9995, 0.9995, 0.9998, 0.9988, 0.9990, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 84 | Batch_idx: 0 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (2477/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (91.00%) (3642/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (92.00%) (4830/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (6004/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (92.00%) (7189/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (8349/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (9530/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (10688/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (11869/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (13043/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (14233/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (15408/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (16581/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (17747/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (18917/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (20066/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (21245/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (22404/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2445) |  Loss2: (0.0000) | Acc: (91.00%) (23574/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (24734/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (25905/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (27090/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (28260/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (29436/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (30602/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (31769/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (32919/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (34091/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (35256/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (36435/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (37611/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (38779/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (39963/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (41127/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (42316/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (43478/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (44638/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (45755/50000)
# TEST : Loss: (0.4432) | Acc: (85.00%) (8592/10000)
percent tensor([0.5433, 0.5410, 0.5471, 0.5436, 0.5544, 0.5489, 0.5466, 0.5479, 0.5417,
        0.5405, 0.5415, 0.5448, 0.5417, 0.5337, 0.5466, 0.5423],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.5011, 0.4999, 0.5012, 0.5001, 0.5035, 0.5010, 0.5014, 0.5015,
        0.5003, 0.5016, 0.5008, 0.5018, 0.5011, 0.5027, 0.5025],
       device='cuda:0') torch.Size([16])
percent tensor([0.5172, 0.5199, 0.5389, 0.5248, 0.5641, 0.5537, 0.5291, 0.5384, 0.5303,
        0.5114, 0.5148, 0.5366, 0.5214, 0.5172, 0.5409, 0.5192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5923, 0.5954, 0.5769, 0.5785, 0.5788, 0.5791, 0.5995, 0.5827, 0.5846,
        0.5912, 0.6079, 0.5843, 0.5869, 0.5995, 0.5995, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5545, 0.5421, 0.6308, 0.6867, 0.6322, 0.6715, 0.5508, 0.5400, 0.6591,
        0.5536, 0.6167, 0.5953, 0.5445, 0.6965, 0.5433, 0.5932],
       device='cuda:0') torch.Size([16])
percent tensor([0.6161, 0.5854, 0.6727, 0.6556, 0.6746, 0.6355, 0.6346, 0.6614, 0.6272,
        0.5839, 0.5819, 0.6557, 0.5855, 0.6084, 0.6295, 0.6139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.4911, 0.6477, 0.5932, 0.6645, 0.7087, 0.5395, 0.4900, 0.5692,
        0.4846, 0.5375, 0.4955, 0.4827, 0.5652, 0.4623, 0.5537],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9991, 0.9998, 0.9998, 0.9996, 0.9989, 0.9996, 0.9997, 0.9995,
        0.9996, 0.9996, 0.9998, 0.9986, 0.9993, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 85 | Batch_idx: 0 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (91.00%) (1288/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (90.00%) (2438/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (3595/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2766) |  Loss2: (0.0000) | Acc: (89.00%) (4719/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (89.00%) (5861/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (89.00%) (7003/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (89.00%) (8145/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (9286/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (89.00%) (10437/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2890) |  Loss2: (0.0000) | Acc: (89.00%) (11603/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2904) |  Loss2: (0.0000) | Acc: (89.00%) (12746/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2895) |  Loss2: (0.0000) | Acc: (89.00%) (13899/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2888) |  Loss2: (0.0000) | Acc: (89.00%) (15058/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2880) |  Loss2: (0.0000) | Acc: (89.00%) (16214/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (89.00%) (17360/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2857) |  Loss2: (0.0000) | Acc: (89.00%) (18528/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (89.00%) (19684/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (20863/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (22019/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (23176/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (24339/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (25487/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (26636/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (27807/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (28987/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (30135/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (31313/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (32467/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (33663/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (34839/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (36009/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (37176/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (38339/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (39510/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (40676/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (41838/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2737) |  Loss2: (0.0000) | Acc: (90.00%) (43019/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (44178/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (45308/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_085.pth.tar'
# TEST : Loss: (0.4179) | Acc: (86.00%) (8637/10000)
percent tensor([0.5545, 0.5535, 0.5591, 0.5544, 0.5688, 0.5597, 0.5597, 0.5603, 0.5534,
        0.5525, 0.5529, 0.5579, 0.5532, 0.5436, 0.5585, 0.5528],
       device='cuda:0') torch.Size([16])
percent tensor([0.5042, 0.5032, 0.5016, 0.5030, 0.5020, 0.5050, 0.5033, 0.5029, 0.5036,
        0.5025, 0.5035, 0.5029, 0.5037, 0.5035, 0.5046, 0.5040],
       device='cuda:0') torch.Size([16])
percent tensor([0.5172, 0.5231, 0.5326, 0.5159, 0.5561, 0.5438, 0.5303, 0.5286, 0.5311,
        0.5149, 0.5188, 0.5371, 0.5260, 0.5154, 0.5368, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.5970, 0.6039, 0.5798, 0.5812, 0.5804, 0.5818, 0.6071, 0.5862, 0.5883,
        0.5984, 0.6130, 0.5891, 0.5949, 0.6062, 0.6053, 0.5920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5569, 0.5573, 0.6240, 0.6748, 0.6167, 0.6485, 0.5501, 0.5325, 0.6551,
        0.5669, 0.6324, 0.6022, 0.5536, 0.6927, 0.5411, 0.5869],
       device='cuda:0') torch.Size([16])
percent tensor([0.6021, 0.5708, 0.6651, 0.6473, 0.6685, 0.6288, 0.6180, 0.6520, 0.6085,
        0.5631, 0.5626, 0.6351, 0.5614, 0.5887, 0.6220, 0.5976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5673, 0.5201, 0.6488, 0.5945, 0.6551, 0.7307, 0.5545, 0.4928, 0.5959,
        0.4978, 0.5571, 0.4938, 0.5231, 0.5853, 0.4807, 0.5796],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9992, 0.9998, 0.9998, 0.9996, 0.9987, 0.9996, 0.9998, 0.9994,
        0.9996, 0.9996, 0.9996, 0.9988, 0.9992, 0.9990, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 86 | Batch_idx: 0 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (91.00%) (1289/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (3633/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (91.00%) (4794/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (5966/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2573) |  Loss2: (0.0000) | Acc: (91.00%) (7124/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2579) |  Loss2: (0.0000) | Acc: (91.00%) (8289/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (9461/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (10642/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (11804/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (12976/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (14159/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (15340/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (16501/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (17687/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (18848/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (19996/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (21150/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (22309/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (23477/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (91.00%) (24646/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (25813/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (26978/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (28152/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (29303/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (30485/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (31633/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (32796/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (33974/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (35153/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (36331/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (91.00%) (37491/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (38673/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (39851/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (41019/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (42187/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (43359/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (44529/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (45665/50000)
# TEST : Loss: (0.4001) | Acc: (86.00%) (8669/10000)
percent tensor([0.5557, 0.5548, 0.5603, 0.5554, 0.5703, 0.5603, 0.5612, 0.5618, 0.5549,
        0.5538, 0.5542, 0.5592, 0.5546, 0.5449, 0.5595, 0.5537],
       device='cuda:0') torch.Size([16])
percent tensor([0.5049, 0.5038, 0.5021, 0.5035, 0.5025, 0.5056, 0.5039, 0.5033, 0.5044,
        0.5031, 0.5040, 0.5034, 0.5041, 0.5043, 0.5052, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5154, 0.5222, 0.5289, 0.5126, 0.5508, 0.5384, 0.5283, 0.5246, 0.5297,
        0.5143, 0.5184, 0.5345, 0.5260, 0.5151, 0.5327, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.6004, 0.6080, 0.5823, 0.5830, 0.5822, 0.5832, 0.6106, 0.5883, 0.5911,
        0.6024, 0.6162, 0.5926, 0.5997, 0.6090, 0.6081, 0.5950],
       device='cuda:0') torch.Size([16])
percent tensor([0.5600, 0.5606, 0.6351, 0.6829, 0.6229, 0.6534, 0.5537, 0.5390, 0.6655,
        0.5799, 0.6452, 0.6125, 0.5556, 0.7072, 0.5410, 0.5953],
       device='cuda:0') torch.Size([16])
percent tensor([0.6162, 0.5836, 0.6807, 0.6658, 0.6862, 0.6425, 0.6349, 0.6707, 0.6238,
        0.5731, 0.5760, 0.6503, 0.5687, 0.6053, 0.6387, 0.6104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5696, 0.5188, 0.6434, 0.5975, 0.6477, 0.7342, 0.5524, 0.4853, 0.5941,
        0.4961, 0.5634, 0.4877, 0.5213, 0.5916, 0.4821, 0.5799],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9992, 0.9997, 0.9998, 0.9996, 0.9988, 0.9996, 0.9998, 0.9994,
        0.9996, 0.9996, 0.9995, 0.9987, 0.9992, 0.9990, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 87 | Batch_idx: 0 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (2467/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (3637/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (4817/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (5978/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (7155/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (8333/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (9517/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (10710/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (11883/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (13063/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (14229/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2351) |  Loss2: (0.0000) | Acc: (91.00%) (15421/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (16583/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (17750/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (91.00%) (18926/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2396) |  Loss2: (0.0000) | Acc: (91.00%) (20098/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (21258/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (22436/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (23594/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (24787/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (25963/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (27131/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (28308/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (29487/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (30652/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (31818/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (32995/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (34182/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (35358/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (36541/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (37710/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (38880/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (40061/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (41245/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (42416/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (43582/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (44755/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (45896/50000)
# TEST : Loss: (0.3935) | Acc: (87.00%) (8714/10000)
percent tensor([0.5550, 0.5543, 0.5600, 0.5548, 0.5700, 0.5595, 0.5608, 0.5615, 0.5543,
        0.5533, 0.5536, 0.5588, 0.5540, 0.5444, 0.5588, 0.5530],
       device='cuda:0') torch.Size([16])
percent tensor([0.5047, 0.5035, 0.5019, 0.5032, 0.5023, 0.5058, 0.5037, 0.5030, 0.5044,
        0.5029, 0.5039, 0.5032, 0.5039, 0.5044, 0.5050, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5150, 0.5232, 0.5289, 0.5118, 0.5499, 0.5355, 0.5299, 0.5239, 0.5302,
        0.5153, 0.5196, 0.5349, 0.5271, 0.5151, 0.5315, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.5996, 0.6076, 0.5809, 0.5815, 0.5807, 0.5812, 0.6096, 0.5864, 0.5905,
        0.6015, 0.6152, 0.5921, 0.6003, 0.6075, 0.6067, 0.5938],
       device='cuda:0') torch.Size([16])
percent tensor([0.5630, 0.5614, 0.6472, 0.6929, 0.6335, 0.6628, 0.5564, 0.5457, 0.6731,
        0.5862, 0.6510, 0.6209, 0.5531, 0.7162, 0.5424, 0.6021],
       device='cuda:0') torch.Size([16])
percent tensor([0.6223, 0.5887, 0.6877, 0.6750, 0.6941, 0.6483, 0.6431, 0.6797, 0.6311,
        0.5768, 0.5815, 0.6569, 0.5690, 0.6148, 0.6468, 0.6149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5724, 0.5188, 0.6360, 0.5957, 0.6434, 0.7374, 0.5527, 0.4755, 0.5925,
        0.4992, 0.5665, 0.4794, 0.5251, 0.5961, 0.4841, 0.5842],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9992, 0.9998, 0.9998, 0.9996, 0.9989, 0.9996, 0.9998, 0.9994,
        0.9996, 0.9996, 0.9995, 0.9987, 0.9993, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (2479/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (91.00%) (3647/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (4822/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (5995/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (7174/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (8345/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (9523/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (91.00%) (10700/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (11869/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (13056/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (14220/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (15388/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (16571/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (17758/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (18932/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (20095/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (21262/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (22433/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2380) |  Loss2: (0.0000) | Acc: (91.00%) (23613/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (24803/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (25969/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (27151/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (28332/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (29508/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2380) |  Loss2: (0.0000) | Acc: (91.00%) (30697/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (91.00%) (31872/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (33048/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (34224/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (35410/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (36592/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (37777/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (38952/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (40132/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (41324/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (42508/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (43679/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (44862/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (45995/50000)
# TEST : Loss: (0.3893) | Acc: (87.00%) (8727/10000)
percent tensor([0.5537, 0.5530, 0.5589, 0.5536, 0.5687, 0.5580, 0.5596, 0.5604, 0.5533,
        0.5522, 0.5524, 0.5576, 0.5527, 0.5436, 0.5574, 0.5517],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.5037, 0.5021, 0.5035, 0.5026, 0.5062, 0.5040, 0.5033, 0.5048,
        0.5032, 0.5041, 0.5035, 0.5041, 0.5047, 0.5053, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5224, 0.5266, 0.5100, 0.5474, 0.5318, 0.5297, 0.5219, 0.5299,
        0.5147, 0.5191, 0.5336, 0.5263, 0.5143, 0.5288, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.6093, 0.5816, 0.5818, 0.5810, 0.5816, 0.6111, 0.5870, 0.5912,
        0.6030, 0.6162, 0.5935, 0.6022, 0.6084, 0.6076, 0.5948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5622, 0.5567, 0.6518, 0.6968, 0.6372, 0.6674, 0.5540, 0.5470, 0.6737,
        0.5853, 0.6508, 0.6200, 0.5473, 0.7175, 0.5399, 0.6048],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.5916, 0.6943, 0.6821, 0.7010, 0.6508, 0.6484, 0.6863, 0.6371,
        0.5771, 0.5856, 0.6624, 0.5703, 0.6202, 0.6516, 0.6160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5917, 0.5367, 0.6405, 0.6036, 0.6450, 0.7457, 0.5647, 0.4749, 0.6058,
        0.5142, 0.5851, 0.4898, 0.5451, 0.6139, 0.4952, 0.5932],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9993, 0.9998, 0.9998, 0.9997, 0.9989, 0.9996, 0.9998, 0.9995,
        0.9996, 0.9996, 0.9996, 0.9987, 0.9993, 0.9990, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 89 | Batch_idx: 0 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (92.00%) (2480/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (92.00%) (3655/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (4850/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (92.00%) (6031/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (92.00%) (7200/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2306) |  Loss2: (0.0000) | Acc: (92.00%) (8391/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (9576/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (92.00%) (10746/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (11926/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (92.00%) (13103/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (92.00%) (14286/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (15482/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (92.00%) (16642/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (92.00%) (17810/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (92.00%) (18978/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (92.00%) (20145/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (92.00%) (21321/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2336) |  Loss2: (0.0000) | Acc: (92.00%) (22501/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (92.00%) (23671/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (92.00%) (24849/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (92.00%) (26029/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (27191/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (28368/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (29546/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (30725/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (31900/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (33089/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (91.00%) (34264/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2336) |  Loss2: (0.0000) | Acc: (91.00%) (35438/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (92.00%) (36628/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (37796/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (38976/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (91.00%) (40138/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (41315/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (42496/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (91.00%) (43672/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (44863/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (92.00%) (46006/50000)
# TEST : Loss: (0.3868) | Acc: (87.00%) (8735/10000)
percent tensor([0.5538, 0.5532, 0.5589, 0.5537, 0.5690, 0.5581, 0.5598, 0.5603, 0.5536,
        0.5522, 0.5526, 0.5578, 0.5529, 0.5437, 0.5575, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.5051, 0.5037, 0.5019, 0.5034, 0.5026, 0.5064, 0.5039, 0.5032, 0.5049,
        0.5031, 0.5042, 0.5033, 0.5041, 0.5049, 0.5054, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5144, 0.5248, 0.5261, 0.5097, 0.5479, 0.5316, 0.5323, 0.5212, 0.5321,
        0.5167, 0.5218, 0.5345, 0.5290, 0.5154, 0.5296, 0.5128],
       device='cuda:0') torch.Size([16])
percent tensor([0.6032, 0.6124, 0.5832, 0.5832, 0.5824, 0.5828, 0.6137, 0.5886, 0.5936,
        0.6058, 0.6188, 0.5960, 0.6058, 0.6108, 0.6100, 0.5970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5570, 0.5508, 0.6526, 0.6958, 0.6369, 0.6644, 0.5509, 0.5477, 0.6689,
        0.5802, 0.6452, 0.6178, 0.5404, 0.7139, 0.5372, 0.5994],
       device='cuda:0') torch.Size([16])
percent tensor([0.6318, 0.5958, 0.7008, 0.6886, 0.7072, 0.6561, 0.6548, 0.6926, 0.6429,
        0.5795, 0.5907, 0.6684, 0.5723, 0.6280, 0.6572, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5834, 0.5233, 0.6352, 0.6007, 0.6396, 0.7426, 0.5568, 0.4641, 0.5957,
        0.5082, 0.5773, 0.4787, 0.5322, 0.6080, 0.4884, 0.5894],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9993, 0.9998, 0.9998, 0.9997, 0.9990, 0.9997, 0.9998, 0.9995,
        0.9996, 0.9997, 0.9996, 0.9987, 0.9994, 0.9991, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (93.00%) (1310/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (93.00%) (2506/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (93.00%) (3691/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (93.00%) (4881/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (6047/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (7206/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (92.00%) (8379/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (9580/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2324) |  Loss2: (0.0000) | Acc: (92.00%) (10744/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (11928/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (13101/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (92.00%) (14275/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2324) |  Loss2: (0.0000) | Acc: (92.00%) (15454/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (92.00%) (16628/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (92.00%) (17793/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (92.00%) (18963/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (92.00%) (20148/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (21304/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (22470/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (23658/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (91.00%) (24838/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2337) |  Loss2: (0.0000) | Acc: (91.00%) (26003/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2337) |  Loss2: (0.0000) | Acc: (91.00%) (27184/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (28335/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (29486/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (30661/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (31836/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (33014/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (34189/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (35368/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (36532/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (37708/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2375) |  Loss2: (0.0000) | Acc: (91.00%) (38873/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2386) |  Loss2: (0.0000) | Acc: (91.00%) (40015/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (41170/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (42349/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (43518/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (44681/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (45832/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_090.pth.tar'
# TEST : Loss: (0.4808) | Acc: (84.00%) (8479/10000)
percent tensor([0.5529, 0.5519, 0.5564, 0.5527, 0.5654, 0.5561, 0.5580, 0.5599, 0.5532,
        0.5510, 0.5513, 0.5548, 0.5522, 0.5440, 0.5559, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.5034, 0.5013, 0.5031, 0.5019, 0.5064, 0.5034, 0.5034, 0.5046,
        0.5028, 0.5038, 0.5022, 0.5037, 0.5041, 0.5051, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5243, 0.5183, 0.5086, 0.5396, 0.5284, 0.5283, 0.5172, 0.5295,
        0.5148, 0.5189, 0.5267, 0.5282, 0.5180, 0.5272, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.6086, 0.6146, 0.5867, 0.5827, 0.5837, 0.5810, 0.6180, 0.5858, 0.5970,
        0.6104, 0.6244, 0.6033, 0.6116, 0.6134, 0.6121, 0.5994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5562, 0.5330, 0.6451, 0.6921, 0.6370, 0.6874, 0.5469, 0.5603, 0.6628,
        0.5643, 0.6378, 0.5981, 0.5376, 0.7042, 0.5356, 0.6026],
       device='cuda:0') torch.Size([16])
percent tensor([0.6278, 0.5829, 0.6982, 0.7017, 0.7076, 0.6469, 0.6566, 0.6915, 0.6560,
        0.5763, 0.5957, 0.6687, 0.5696, 0.6266, 0.6494, 0.6237],
       device='cuda:0') torch.Size([16])
percent tensor([0.5832, 0.5118, 0.6315, 0.6157, 0.6435, 0.7231, 0.5311, 0.4746, 0.5794,
        0.5073, 0.5757, 0.4649, 0.5057, 0.5725, 0.4585, 0.5820],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9993, 0.9999, 0.9999, 0.9996, 0.9990, 0.9997, 0.9999, 0.9996,
        0.9997, 0.9998, 0.9998, 0.9984, 0.9994, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.4427, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(814.5504, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(812.7079, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1522.2798, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(497.8204, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2222.2292, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4287.9448, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1392.5824, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6130.4175, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11884.0537, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3944.0720, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16712.4375, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 91 | Batch_idx: 0 |  Loss: (0.2569) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (2480/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (3661/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (4848/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (6038/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (7228/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (8402/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (9576/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (10746/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (11919/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (13099/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (92.00%) (14256/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (92.00%) (15427/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (91.00%) (16597/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (91.00%) (17770/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (92.00%) (18961/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (20147/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (92.00%) (21319/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (22483/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (91.00%) (23659/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (24824/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (91.00%) (26017/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (27186/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (91.00%) (28360/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (29515/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (30687/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (31859/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (33038/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (34207/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (35389/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (36574/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (37759/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2367) |  Loss2: (0.0000) | Acc: (91.00%) (38917/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2375) |  Loss2: (0.0000) | Acc: (91.00%) (40079/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (91.00%) (41236/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (42400/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (91.00%) (43578/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (91.00%) (44764/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (45888/50000)
# TEST : Loss: (0.4230) | Acc: (86.00%) (8629/10000)
percent tensor([0.5531, 0.5534, 0.5590, 0.5537, 0.5673, 0.5572, 0.5595, 0.5612, 0.5528,
        0.5527, 0.5526, 0.5561, 0.5523, 0.5435, 0.5571, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.5038, 0.5019, 0.5034, 0.5023, 0.5064, 0.5040, 0.5037, 0.5046,
        0.5035, 0.5043, 0.5028, 0.5039, 0.5044, 0.5053, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5133, 0.5248, 0.5256, 0.5120, 0.5446, 0.5291, 0.5318, 0.5208, 0.5278,
        0.5175, 0.5210, 0.5311, 0.5286, 0.5169, 0.5266, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.6086, 0.6173, 0.5838, 0.5814, 0.5836, 0.5864, 0.6168, 0.5887, 0.6017,
        0.6088, 0.6274, 0.6020, 0.6129, 0.6155, 0.6144, 0.5995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5548, 0.5382, 0.6391, 0.6945, 0.6379, 0.6667, 0.5587, 0.5537, 0.6533,
        0.5757, 0.6181, 0.6025, 0.5390, 0.7096, 0.5353, 0.6021],
       device='cuda:0') torch.Size([16])
percent tensor([0.6375, 0.6016, 0.6923, 0.6875, 0.7081, 0.6652, 0.6646, 0.6875, 0.6526,
        0.5813, 0.5997, 0.6705, 0.5749, 0.6423, 0.6609, 0.6279],
       device='cuda:0') torch.Size([16])
percent tensor([0.5704, 0.5246, 0.6283, 0.5777, 0.6571, 0.7238, 0.5435, 0.4678, 0.5595,
        0.5198, 0.5577, 0.4788, 0.5091, 0.5968, 0.4731, 0.5621],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9999, 0.9997, 0.9995, 0.9983, 0.9997, 0.9998, 0.9998,
        0.9997, 0.9998, 0.9998, 0.9991, 0.9995, 0.9993, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 92 | Batch_idx: 0 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2375) |  Loss2: (0.0000) | Acc: (91.00%) (1294/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (92.00%) (2477/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (3661/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (4839/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (6010/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (7198/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (8376/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (9548/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (10739/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (11901/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (91.00%) (13062/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2336) |  Loss2: (0.0000) | Acc: (91.00%) (14236/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (15421/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (16600/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2337) |  Loss2: (0.0000) | Acc: (92.00%) (17784/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (92.00%) (18985/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (92.00%) (20176/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (21378/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (22550/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (23722/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (24898/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (26094/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (27270/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (28452/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (29618/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (30810/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (31988/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (33160/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (92.00%) (34336/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (92.00%) (35508/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (92.00%) (36679/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (92.00%) (37846/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (92.00%) (39024/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2337) |  Loss2: (0.0000) | Acc: (92.00%) (40189/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (92.00%) (41367/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2336) |  Loss2: (0.0000) | Acc: (92.00%) (42547/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (92.00%) (43718/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (92.00%) (44900/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (92.00%) (46033/50000)
# TEST : Loss: (0.4502) | Acc: (85.00%) (8547/10000)
percent tensor([0.5533, 0.5539, 0.5570, 0.5531, 0.5663, 0.5571, 0.5594, 0.5610, 0.5526,
        0.5522, 0.5530, 0.5550, 0.5524, 0.5445, 0.5570, 0.5514],
       device='cuda:0') torch.Size([16])
percent tensor([0.5051, 0.5042, 0.5013, 0.5032, 0.5018, 0.5066, 0.5041, 0.5032, 0.5048,
        0.5034, 0.5044, 0.5022, 0.5039, 0.5051, 0.5054, 0.5048],
       device='cuda:0') torch.Size([16])
percent tensor([0.5129, 0.5260, 0.5261, 0.5138, 0.5502, 0.5307, 0.5333, 0.5249, 0.5306,
        0.5167, 0.5203, 0.5345, 0.5292, 0.5200, 0.5285, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.6048, 0.6135, 0.5822, 0.5773, 0.5810, 0.5816, 0.6155, 0.5830, 0.5969,
        0.6081, 0.6240, 0.6002, 0.6091, 0.6095, 0.6113, 0.5950],
       device='cuda:0') torch.Size([16])
percent tensor([0.5676, 0.5427, 0.6579, 0.7085, 0.6424, 0.6882, 0.5684, 0.5690, 0.6577,
        0.5796, 0.6252, 0.6193, 0.5401, 0.7164, 0.5506, 0.6062],
       device='cuda:0') torch.Size([16])
percent tensor([0.6335, 0.6086, 0.6863, 0.6879, 0.6959, 0.6586, 0.6662, 0.6893, 0.6530,
        0.5911, 0.5993, 0.6824, 0.5808, 0.6505, 0.6629, 0.6348],
       device='cuda:0') torch.Size([16])
percent tensor([0.5746, 0.5198, 0.6314, 0.6029, 0.6543, 0.7389, 0.5320, 0.4691, 0.5644,
        0.4989, 0.5716, 0.5175, 0.5151, 0.6080, 0.4646, 0.5843],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9999, 0.9994, 0.9993, 0.9991, 0.9995, 0.9996, 0.9997,
        0.9997, 0.9998, 0.9999, 0.9990, 0.9995, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 93 | Batch_idx: 0 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (2523/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (3707/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (93.00%) (4893/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (93.00%) (6076/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (7244/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (8416/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (9607/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (10774/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (11952/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (13136/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (14309/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (15488/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (16675/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (17855/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (19036/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (20211/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (21404/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (22564/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (23732/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (24904/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (26084/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (27251/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (28416/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (29586/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (30761/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (31939/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (33128/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (34295/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (35480/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (36660/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (37847/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (39017/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (40192/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (41366/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (42552/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (43726/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (44899/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (46041/50000)
# TEST : Loss: (0.4638) | Acc: (85.00%) (8547/10000)
percent tensor([0.5534, 0.5526, 0.5583, 0.5531, 0.5675, 0.5583, 0.5591, 0.5600, 0.5527,
        0.5522, 0.5528, 0.5560, 0.5525, 0.5425, 0.5573, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.5049, 0.5036, 0.5011, 0.5032, 0.5019, 0.5063, 0.5035, 0.5032, 0.5048,
        0.5029, 0.5042, 0.5022, 0.5040, 0.5046, 0.5051, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5138, 0.5248, 0.5263, 0.5133, 0.5481, 0.5308, 0.5307, 0.5219, 0.5331,
        0.5173, 0.5229, 0.5321, 0.5307, 0.5174, 0.5273, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.6099, 0.6138, 0.5873, 0.5836, 0.5845, 0.5829, 0.6172, 0.5888, 0.6004,
        0.6109, 0.6255, 0.6045, 0.6130, 0.6116, 0.6119, 0.5988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5585, 0.5428, 0.6393, 0.6966, 0.6296, 0.6729, 0.5604, 0.5561, 0.6550,
        0.5811, 0.6273, 0.6044, 0.5426, 0.7174, 0.5387, 0.6030],
       device='cuda:0') torch.Size([16])
percent tensor([0.6235, 0.5940, 0.6823, 0.6770, 0.6936, 0.6572, 0.6435, 0.6782, 0.6368,
        0.5792, 0.5877, 0.6614, 0.5691, 0.6309, 0.6463, 0.6156],
       device='cuda:0') torch.Size([16])
percent tensor([0.5536, 0.5310, 0.6322, 0.5677, 0.6344, 0.7277, 0.5332, 0.4952, 0.5903,
        0.5066, 0.5563, 0.5068, 0.5208, 0.5941, 0.4759, 0.5492],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9999, 0.9994, 0.9995, 0.9995, 0.9996, 0.9998, 0.9998,
        0.9997, 0.9998, 0.9998, 0.9991, 0.9996, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 94 | Batch_idx: 0 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (2480/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (3656/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (4839/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (6042/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (7234/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (8420/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (9595/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (10773/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (11949/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (13125/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (14326/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (15517/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (16690/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (17877/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (19064/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (20254/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (21432/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (22623/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (23813/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (24999/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (26177/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (27347/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (28513/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (29693/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (30882/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (32064/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (33243/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (34390/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (35572/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (36749/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (37931/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (39101/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (40274/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (41447/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (42622/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (43788/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (44966/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (46101/50000)
# TEST : Loss: (0.5954) | Acc: (82.00%) (8205/10000)
percent tensor([0.5528, 0.5529, 0.5579, 0.5523, 0.5662, 0.5567, 0.5592, 0.5606, 0.5528,
        0.5519, 0.5529, 0.5555, 0.5523, 0.5437, 0.5565, 0.5512],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.5034, 0.5024, 0.5033, 0.5029, 0.5061, 0.5038, 0.5035, 0.5048,
        0.5030, 0.5037, 0.5031, 0.5037, 0.5043, 0.5050, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.5143, 0.5271, 0.5299, 0.5118, 0.5476, 0.5319, 0.5324, 0.5215, 0.5287,
        0.5178, 0.5209, 0.5363, 0.5315, 0.5118, 0.5298, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.6047, 0.6134, 0.5846, 0.5823, 0.5846, 0.5851, 0.6172, 0.5834, 0.5968,
        0.6088, 0.6232, 0.5980, 0.6082, 0.6132, 0.6124, 0.5988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.5326, 0.6396, 0.6940, 0.6265, 0.6851, 0.5489, 0.5433, 0.6337,
        0.5596, 0.6182, 0.6051, 0.5345, 0.6931, 0.5393, 0.5887],
       device='cuda:0') torch.Size([16])
percent tensor([0.6349, 0.6073, 0.6979, 0.6882, 0.6971, 0.6561, 0.6582, 0.6913, 0.6516,
        0.5911, 0.6024, 0.6726, 0.5891, 0.6328, 0.6525, 0.6308],
       device='cuda:0') torch.Size([16])
percent tensor([0.5716, 0.5524, 0.6648, 0.5939, 0.6383, 0.7406, 0.5576, 0.5190, 0.5619,
        0.5483, 0.5921, 0.5025, 0.5336, 0.5735, 0.4876, 0.5944],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9999, 0.9998, 0.9996, 0.9992, 0.9996, 0.9999, 0.9994,
        0.9997, 0.9999, 0.9999, 0.9987, 0.9995, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 95 | Batch_idx: 0 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (1289/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2586) |  Loss2: (0.0000) | Acc: (91.00%) (2450/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (3599/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (4734/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (5899/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (7044/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (8206/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (9370/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (10525/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (11672/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (12826/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (90.00%) (13960/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2890) |  Loss2: (0.0000) | Acc: (90.00%) (15100/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (89.00%) (16236/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2904) |  Loss2: (0.0000) | Acc: (89.00%) (17390/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (89.00%) (18530/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (89.00%) (19685/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2888) |  Loss2: (0.0000) | Acc: (90.00%) (20853/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2879) |  Loss2: (0.0000) | Acc: (89.00%) (21997/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (23166/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (24325/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (25476/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (26638/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (27797/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (28969/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (30131/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (31298/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (32462/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (33616/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (34776/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (35924/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (37087/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (38253/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (39406/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (40578/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (41749/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (42902/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (44063/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (45194/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_095.pth.tar'
# TEST : Loss: (0.4489) | Acc: (86.00%) (8609/10000)
percent tensor([0.5552, 0.5562, 0.5579, 0.5541, 0.5669, 0.5591, 0.5613, 0.5615, 0.5546,
        0.5535, 0.5554, 0.5558, 0.5546, 0.5474, 0.5590, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.5062, 0.5049, 0.5040, 0.5052, 0.5042, 0.5077, 0.5055, 0.5049, 0.5063,
        0.5047, 0.5051, 0.5046, 0.5049, 0.5061, 0.5065, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.5240, 0.5327, 0.5178, 0.5467, 0.5400, 0.5287, 0.5177, 0.5269,
        0.5152, 0.5181, 0.5360, 0.5272, 0.5112, 0.5291, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5870, 0.5974, 0.5625, 0.5653, 0.5644, 0.5697, 0.5965, 0.5622, 0.5802,
        0.5926, 0.6076, 0.5773, 0.5921, 0.5990, 0.5948, 0.5835],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5454, 0.6689, 0.7368, 0.6503, 0.7350, 0.5568, 0.5474, 0.6623,
        0.5875, 0.6502, 0.6309, 0.5456, 0.7326, 0.5377, 0.6319],
       device='cuda:0') torch.Size([16])
percent tensor([0.5881, 0.5637, 0.6512, 0.6349, 0.6465, 0.6044, 0.6117, 0.6418, 0.5957,
        0.5484, 0.5559, 0.6263, 0.5389, 0.5852, 0.6088, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.5297, 0.7095, 0.6455, 0.7151, 0.7360, 0.6024, 0.6213, 0.5489,
        0.5262, 0.5522, 0.5188, 0.4989, 0.5344, 0.5284, 0.5981],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9998, 0.9996, 0.9995, 0.9994, 0.9996, 0.9999, 0.9992,
        0.9995, 0.9997, 0.9997, 0.9988, 0.9993, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 96 | Batch_idx: 0 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (1289/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (91.00%) (2452/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (3611/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2375) |  Loss2: (0.0000) | Acc: (91.00%) (4792/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (5970/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (91.00%) (7157/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (91.00%) (8327/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (91.00%) (9512/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (10674/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (11848/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (91.00%) (12996/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (14171/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (15337/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (16496/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (17654/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (18837/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (20001/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (21164/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (22325/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (23489/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (24678/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (25848/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (26995/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (28163/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (29339/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (30518/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (31703/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (32883/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (34074/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (35240/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (36397/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (37571/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (38751/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (39933/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2432) |  Loss2: (0.0000) | Acc: (91.00%) (41112/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2432) |  Loss2: (0.0000) | Acc: (91.00%) (42279/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2432) |  Loss2: (0.0000) | Acc: (91.00%) (43459/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (44620/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2428) |  Loss2: (0.0000) | Acc: (91.00%) (45759/50000)
# TEST : Loss: (0.4239) | Acc: (86.00%) (8652/10000)
percent tensor([0.5529, 0.5535, 0.5550, 0.5516, 0.5638, 0.5572, 0.5582, 0.5584, 0.5524,
        0.5507, 0.5532, 0.5528, 0.5523, 0.5451, 0.5567, 0.5511],
       device='cuda:0') torch.Size([16])
percent tensor([0.5082, 0.5070, 0.5059, 0.5076, 0.5062, 0.5098, 0.5077, 0.5071, 0.5083,
        0.5069, 0.5071, 0.5066, 0.5068, 0.5083, 0.5088, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.5179, 0.5287, 0.5350, 0.5269, 0.5515, 0.5523, 0.5317, 0.5195, 0.5327,
        0.5194, 0.5241, 0.5405, 0.5323, 0.5168, 0.5372, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.5931, 0.6041, 0.5673, 0.5710, 0.5695, 0.5761, 0.6022, 0.5658, 0.5857,
        0.5995, 0.6156, 0.5823, 0.5984, 0.6059, 0.6013, 0.5903],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5445, 0.6733, 0.7471, 0.6541, 0.7444, 0.5496, 0.5409, 0.6635,
        0.5872, 0.6471, 0.6269, 0.5432, 0.7368, 0.5318, 0.6359],
       device='cuda:0') torch.Size([16])
percent tensor([0.5973, 0.5718, 0.6594, 0.6434, 0.6534, 0.6086, 0.6203, 0.6517, 0.6047,
        0.5597, 0.5660, 0.6340, 0.5467, 0.5937, 0.6174, 0.5905],
       device='cuda:0') torch.Size([16])
percent tensor([0.5735, 0.5230, 0.7268, 0.6558, 0.7335, 0.7386, 0.6073, 0.6453, 0.5479,
        0.5205, 0.5423, 0.5154, 0.4888, 0.5233, 0.5390, 0.5917],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9993, 0.9998, 0.9996, 0.9995, 0.9994, 0.9996, 0.9999, 0.9992,
        0.9995, 0.9997, 0.9997, 0.9988, 0.9993, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 97 | Batch_idx: 0 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2351) |  Loss2: (0.0000) | Acc: (92.00%) (2485/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (92.00%) (3656/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (4862/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (6045/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (7229/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2244) |  Loss2: (0.0000) | Acc: (92.00%) (8399/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (9581/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (10768/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (11941/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (13101/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (14267/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (92.00%) (15440/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (16629/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (17803/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (18974/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (20161/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (21337/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (22515/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (92.00%) (23675/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (24850/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (91.00%) (26015/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (27182/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (28349/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (29532/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (91.00%) (30726/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (31906/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (33087/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (91.00%) (34250/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (91.00%) (35431/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (36610/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (91.00%) (37778/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (38956/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (40116/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (41289/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (42470/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (91.00%) (43638/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (44836/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (91.00%) (45970/50000)
# TEST : Loss: (0.4149) | Acc: (86.00%) (8692/10000)
percent tensor([0.5511, 0.5515, 0.5525, 0.5495, 0.5613, 0.5555, 0.5559, 0.5559, 0.5505,
        0.5485, 0.5514, 0.5504, 0.5504, 0.5434, 0.5548, 0.5492],
       device='cuda:0') torch.Size([16])
percent tensor([0.5085, 0.5072, 0.5061, 0.5081, 0.5065, 0.5104, 0.5078, 0.5073, 0.5087,
        0.5072, 0.5073, 0.5067, 0.5071, 0.5088, 0.5091, 0.5083],
       device='cuda:0') torch.Size([16])
percent tensor([0.5176, 0.5294, 0.5366, 0.5303, 0.5542, 0.5543, 0.5328, 0.5203, 0.5339,
        0.5210, 0.5242, 0.5430, 0.5335, 0.5168, 0.5384, 0.5251],
       device='cuda:0') torch.Size([16])
percent tensor([0.5971, 0.6084, 0.5703, 0.5743, 0.5729, 0.5803, 0.6064, 0.5678, 0.5898,
        0.6043, 0.6214, 0.5859, 0.6025, 0.6107, 0.6055, 0.5949],
       device='cuda:0') torch.Size([16])
percent tensor([0.5478, 0.5359, 0.6564, 0.7321, 0.6415, 0.7334, 0.5331, 0.5282, 0.6451,
        0.5702, 0.6263, 0.6031, 0.5332, 0.7195, 0.5229, 0.6200],
       device='cuda:0') torch.Size([16])
percent tensor([0.6002, 0.5752, 0.6630, 0.6463, 0.6554, 0.6093, 0.6243, 0.6552, 0.6079,
        0.5643, 0.5690, 0.6375, 0.5495, 0.5982, 0.6215, 0.5942],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5143, 0.7264, 0.6528, 0.7304, 0.7383, 0.5988, 0.6362, 0.5449,
        0.5130, 0.5337, 0.5082, 0.4841, 0.5147, 0.5317, 0.5834],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9998, 0.9997, 0.9996, 0.9995, 0.9996, 0.9999, 0.9992,
        0.9996, 0.9997, 0.9997, 0.9989, 0.9993, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 98 | Batch_idx: 0 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (92.00%) (1309/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (2489/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (3690/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (4867/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2244) |  Loss2: (0.0000) | Acc: (92.00%) (6038/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (7209/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (8390/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2306) |  Loss2: (0.0000) | Acc: (92.00%) (9564/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (10751/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (11932/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (13124/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (14307/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (15474/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (16655/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (17830/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (19004/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (20192/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (21377/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (22545/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (23727/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (24882/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2264) |  Loss2: (0.0000) | Acc: (92.00%) (26062/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (27258/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (28422/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (29602/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (30779/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (31961/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (33154/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (34343/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (35531/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (36704/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (37904/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (39100/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (40283/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (41457/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (42629/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (43790/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (44971/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (46117/50000)
# TEST : Loss: (0.4034) | Acc: (87.00%) (8700/10000)
percent tensor([0.5510, 0.5513, 0.5523, 0.5495, 0.5611, 0.5557, 0.5556, 0.5557, 0.5503,
        0.5483, 0.5513, 0.5501, 0.5502, 0.5433, 0.5547, 0.5492],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.5078, 0.5067, 0.5090, 0.5071, 0.5112, 0.5084, 0.5080, 0.5094,
        0.5079, 0.5078, 0.5073, 0.5076, 0.5096, 0.5098, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.5159, 0.5276, 0.5359, 0.5323, 0.5528, 0.5555, 0.5295, 0.5187, 0.5309,
        0.5188, 0.5216, 0.5411, 0.5314, 0.5158, 0.5372, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.5968, 0.6086, 0.5697, 0.5736, 0.5724, 0.5801, 0.6062, 0.5666, 0.5898,
        0.6050, 0.6226, 0.5857, 0.6022, 0.6110, 0.6052, 0.5947],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5390, 0.6618, 0.7384, 0.6497, 0.7337, 0.5356, 0.5320, 0.6508,
        0.5755, 0.6296, 0.6062, 0.5348, 0.7211, 0.5247, 0.6224],
       device='cuda:0') torch.Size([16])
percent tensor([0.6066, 0.5818, 0.6672, 0.6510, 0.6594, 0.6121, 0.6306, 0.6606, 0.6146,
        0.5719, 0.5770, 0.6435, 0.5564, 0.6053, 0.6282, 0.5995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5750, 0.5199, 0.7218, 0.6468, 0.7272, 0.7425, 0.5946, 0.6261, 0.5500,
        0.5163, 0.5390, 0.5049, 0.4931, 0.5212, 0.5300, 0.5781],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9999, 0.9997, 0.9996, 0.9994, 0.9996, 0.9999, 0.9993,
        0.9996, 0.9998, 0.9997, 0.9989, 0.9994, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 99 | Batch_idx: 0 |  Loss: (0.2907) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (1289/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (2472/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (3664/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (4841/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (92.00%) (6014/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (7212/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (8387/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (9571/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (10741/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (11921/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (13100/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (14265/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (15456/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (16645/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (17828/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (18989/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (20163/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (21346/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (22540/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (23724/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (24897/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (26082/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (27277/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (28446/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (29637/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (30813/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (31996/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (33183/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (34370/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (35552/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (36722/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (37916/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (39107/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (40278/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (41463/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (42643/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (43832/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (45018/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (46145/50000)
# TEST : Loss: (0.4010) | Acc: (86.00%) (8699/10000)
percent tensor([0.5509, 0.5512, 0.5516, 0.5493, 0.5607, 0.5561, 0.5553, 0.5551, 0.5502,
        0.5479, 0.5514, 0.5495, 0.5500, 0.5432, 0.5549, 0.5492],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.5083, 0.5073, 0.5100, 0.5078, 0.5123, 0.5089, 0.5085, 0.5100,
        0.5083, 0.5084, 0.5077, 0.5081, 0.5105, 0.5105, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5187, 0.5311, 0.5376, 0.5372, 0.5570, 0.5603, 0.5331, 0.5208, 0.5352,
        0.5222, 0.5256, 0.5448, 0.5350, 0.5186, 0.5415, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5998, 0.6115, 0.5720, 0.5762, 0.5750, 0.5828, 0.6087, 0.5681, 0.5926,
        0.6082, 0.6262, 0.5879, 0.6056, 0.6139, 0.6078, 0.5978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5519, 0.5448, 0.6592, 0.7364, 0.6476, 0.7288, 0.5384, 0.5321, 0.6496,
        0.5785, 0.6312, 0.6054, 0.5396, 0.7195, 0.5273, 0.6213],
       device='cuda:0') torch.Size([16])
percent tensor([0.6089, 0.5843, 0.6700, 0.6529, 0.6619, 0.6145, 0.6336, 0.6651, 0.6167,
        0.5746, 0.5793, 0.6455, 0.5570, 0.6067, 0.6315, 0.6026],
       device='cuda:0') torch.Size([16])
percent tensor([0.5837, 0.5296, 0.7233, 0.6459, 0.7287, 0.7519, 0.6005, 0.6243, 0.5626,
        0.5236, 0.5532, 0.5079, 0.4994, 0.5335, 0.5364, 0.5814],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9998, 0.9997, 0.9996, 0.9995, 0.9996, 0.9999, 0.9993,
        0.9996, 0.9998, 0.9997, 0.9990, 0.9994, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 100 | Batch_idx: 0 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (2484/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (3660/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (4844/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (6032/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (7221/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (8395/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (9574/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (10756/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (11949/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (13142/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (14309/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (15478/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (16661/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2244) |  Loss2: (0.0000) | Acc: (92.00%) (17838/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (19023/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (20199/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (21366/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (22538/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (23741/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (24916/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (26094/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (27253/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (28437/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (29617/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (30810/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (31998/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (33182/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (34371/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (35577/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (36762/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (37957/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (39152/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (40336/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (41525/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (42674/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (43856/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (45045/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (46185/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_100.pth.tar'
# TEST : Loss: (0.4477) | Acc: (85.00%) (8599/10000)
percent tensor([0.5516, 0.5508, 0.5515, 0.5493, 0.5613, 0.5567, 0.5549, 0.5551, 0.5508,
        0.5482, 0.5515, 0.5496, 0.5513, 0.5422, 0.5554, 0.5495],
       device='cuda:0') torch.Size([16])
percent tensor([0.5100, 0.5085, 0.5064, 0.5092, 0.5076, 0.5117, 0.5083, 0.5082, 0.5108,
        0.5081, 0.5091, 0.5067, 0.5089, 0.5102, 0.5103, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5162, 0.5291, 0.5371, 0.5357, 0.5566, 0.5511, 0.5269, 0.5244, 0.5379,
        0.5201, 0.5234, 0.5386, 0.5334, 0.5169, 0.5373, 0.5259],
       device='cuda:0') torch.Size([16])
percent tensor([0.5982, 0.6105, 0.5722, 0.5778, 0.5752, 0.5810, 0.6086, 0.5702, 0.5901,
        0.6064, 0.6228, 0.5913, 0.6051, 0.6104, 0.6051, 0.5947],
       device='cuda:0') torch.Size([16])
percent tensor([0.5483, 0.5513, 0.6608, 0.7246, 0.6686, 0.7175, 0.5483, 0.5416, 0.6541,
        0.5659, 0.6234, 0.5954, 0.5447, 0.7052, 0.5328, 0.6089],
       device='cuda:0') torch.Size([16])
percent tensor([0.6115, 0.5848, 0.6519, 0.6451, 0.6630, 0.6198, 0.6347, 0.6630, 0.6241,
        0.5676, 0.5750, 0.6385, 0.5631, 0.6061, 0.6293, 0.6046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5807, 0.5332, 0.6815, 0.6209, 0.6938, 0.7541, 0.5529, 0.5549, 0.5677,
        0.5217, 0.5689, 0.4997, 0.5184, 0.5486, 0.5047, 0.5896],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9999, 0.9997, 0.9996, 0.9989, 0.9997, 0.9998, 0.9997,
        0.9995, 0.9997, 0.9999, 0.9991, 0.9991, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(181.1602, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(817.6447, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(816.4456, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.1566, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(496.1027, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2229.0811, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4286.0430, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1387.6193, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6142.6553, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11847.8174, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3928.8657, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16645.4961, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 101 | Batch_idx: 0 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (2478/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (3676/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (4838/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (6017/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (7217/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (8415/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (9577/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (10767/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (11950/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (13135/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (14315/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (15501/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (16707/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (17900/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (19097/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (20265/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (21446/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (22621/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (23801/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (24990/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (26183/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (27376/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (28562/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (29758/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (30945/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (32148/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (33332/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (34506/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (35689/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (36878/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (38057/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (39248/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (40435/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (41602/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (42781/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (43952/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (45130/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (46272/50000)
# TEST : Loss: (0.4857) | Acc: (84.00%) (8480/10000)
percent tensor([0.5510, 0.5497, 0.5522, 0.5498, 0.5614, 0.5567, 0.5545, 0.5548, 0.5498,
        0.5474, 0.5506, 0.5495, 0.5502, 0.5407, 0.5550, 0.5492],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.5082, 0.5055, 0.5080, 0.5067, 0.5114, 0.5081, 0.5077, 0.5099,
        0.5079, 0.5088, 0.5061, 0.5084, 0.5097, 0.5099, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5185, 0.5291, 0.5331, 0.5332, 0.5540, 0.5567, 0.5273, 0.5211, 0.5345,
        0.5207, 0.5259, 0.5366, 0.5326, 0.5205, 0.5382, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.6033, 0.6129, 0.5778, 0.5754, 0.5760, 0.5807, 0.6067, 0.5715, 0.5943,
        0.6087, 0.6259, 0.5943, 0.6092, 0.6109, 0.6062, 0.5965],
       device='cuda:0') torch.Size([16])
percent tensor([0.5599, 0.5467, 0.6611, 0.7201, 0.6611, 0.7044, 0.5562, 0.5372, 0.6638,
        0.5764, 0.6375, 0.6178, 0.5543, 0.7209, 0.5319, 0.6128],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.5815, 0.6526, 0.6490, 0.6576, 0.6208, 0.6358, 0.6609, 0.6229,
        0.5715, 0.5854, 0.6338, 0.5702, 0.6097, 0.6300, 0.6141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5922, 0.5657, 0.7200, 0.6684, 0.7372, 0.7620, 0.6138, 0.5924, 0.6080,
        0.5773, 0.5863, 0.5430, 0.5288, 0.5889, 0.5373, 0.6121],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9999, 0.9998, 0.9994, 0.9991, 0.9996, 0.9997, 0.9996,
        0.9998, 0.9998, 0.9999, 0.9991, 0.9995, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 102 | Batch_idx: 0 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (2497/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (3674/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (4861/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (6053/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (7242/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (8431/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (92.00%) (9636/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (10813/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (12001/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (92.00%) (13193/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (14359/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (15552/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (16738/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (17930/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (19104/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2128) |  Loss2: (0.0000) | Acc: (92.00%) (20293/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (21488/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2113) |  Loss2: (0.0000) | Acc: (92.00%) (22681/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (23851/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (25041/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (26240/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (27426/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (28615/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (29799/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (30986/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (32159/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (33343/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (34537/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (35726/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (36914/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (38111/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (39294/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (40478/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (41666/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (42851/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (44059/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (45232/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (46388/50000)
# TEST : Loss: (0.4388) | Acc: (85.00%) (8582/10000)
percent tensor([0.5523, 0.5500, 0.5528, 0.5510, 0.5624, 0.5578, 0.5551, 0.5558, 0.5509,
        0.5482, 0.5513, 0.5505, 0.5512, 0.5413, 0.5555, 0.5505],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5080, 0.5055, 0.5088, 0.5070, 0.5121, 0.5081, 0.5078, 0.5100,
        0.5077, 0.5084, 0.5060, 0.5081, 0.5104, 0.5100, 0.5094],
       device='cuda:0') torch.Size([16])
percent tensor([0.5193, 0.5279, 0.5339, 0.5345, 0.5597, 0.5560, 0.5317, 0.5249, 0.5378,
        0.5216, 0.5267, 0.5400, 0.5340, 0.5213, 0.5391, 0.5266],
       device='cuda:0') torch.Size([16])
percent tensor([0.6016, 0.6133, 0.5786, 0.5783, 0.5756, 0.5832, 0.6083, 0.5729, 0.5958,
        0.6075, 0.6251, 0.5916, 0.6079, 0.6127, 0.6064, 0.5955],
       device='cuda:0') torch.Size([16])
percent tensor([0.5490, 0.5494, 0.6493, 0.7186, 0.6510, 0.6943, 0.5546, 0.5314, 0.6682,
        0.5801, 0.6311, 0.6094, 0.5533, 0.7355, 0.5303, 0.6113],
       device='cuda:0') torch.Size([16])
percent tensor([0.6152, 0.5941, 0.6593, 0.6567, 0.6630, 0.6284, 0.6417, 0.6603, 0.6340,
        0.5767, 0.5866, 0.6494, 0.5731, 0.6277, 0.6424, 0.6152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.5420, 0.7046, 0.6336, 0.7105, 0.7701, 0.5768, 0.5380, 0.5695,
        0.5434, 0.5791, 0.5311, 0.5368, 0.5764, 0.5330, 0.5783],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9999, 0.9997, 0.9994, 0.9990, 0.9997, 0.9998, 0.9997,
        0.9998, 0.9998, 0.9999, 0.9992, 0.9995, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 103 | Batch_idx: 0 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (1309/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (93.00%) (2502/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (93.00%) (3696/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (93.00%) (4890/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (6087/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (93.00%) (7278/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (8464/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (92.00%) (9640/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (10851/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (12041/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (93.00%) (13237/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (93.00%) (14425/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (15632/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (16823/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (18015/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (19206/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (20395/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (21593/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (22789/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (23974/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (93.00%) (25165/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (93.00%) (26344/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (93.00%) (27527/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (93.00%) (28709/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (93.00%) (29894/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (93.00%) (31074/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (32259/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (93.00%) (33451/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (34633/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (35811/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (37002/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (38182/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (39370/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (40547/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (41725/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (42918/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (44092/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (45276/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (46412/50000)
# TEST : Loss: (0.4320) | Acc: (86.00%) (8631/10000)
percent tensor([0.5522, 0.5501, 0.5535, 0.5501, 0.5630, 0.5568, 0.5556, 0.5556, 0.5515,
        0.5486, 0.5515, 0.5517, 0.5511, 0.5416, 0.5550, 0.5501],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5081, 0.5061, 0.5091, 0.5073, 0.5120, 0.5080, 0.5081, 0.5097,
        0.5079, 0.5085, 0.5066, 0.5080, 0.5098, 0.5102, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5177, 0.5313, 0.5296, 0.5324, 0.5551, 0.5549, 0.5277, 0.5202, 0.5349,
        0.5218, 0.5259, 0.5363, 0.5333, 0.5251, 0.5393, 0.5275],
       device='cuda:0') torch.Size([16])
percent tensor([0.5991, 0.6108, 0.5775, 0.5789, 0.5768, 0.5792, 0.6060, 0.5715, 0.5918,
        0.6069, 0.6225, 0.5946, 0.6045, 0.6086, 0.6051, 0.5917],
       device='cuda:0') torch.Size([16])
percent tensor([0.5548, 0.5446, 0.6722, 0.7399, 0.6723, 0.6927, 0.5571, 0.5444, 0.6735,
        0.5736, 0.6262, 0.6082, 0.5465, 0.7322, 0.5279, 0.6146],
       device='cuda:0') torch.Size([16])
percent tensor([0.6157, 0.5788, 0.6611, 0.6522, 0.6723, 0.6163, 0.6373, 0.6647, 0.6252,
        0.5690, 0.5766, 0.6441, 0.5611, 0.6043, 0.6342, 0.6089],
       device='cuda:0') torch.Size([16])
percent tensor([0.5742, 0.5379, 0.6964, 0.6416, 0.7192, 0.7495, 0.6008, 0.5781, 0.5971,
        0.5201, 0.5852, 0.5221, 0.5172, 0.5518, 0.5374, 0.6042],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9996, 0.9997, 0.9985, 0.9997, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9995, 0.9996, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 104 | Batch_idx: 0 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (2499/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (3696/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (4885/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (6077/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (7264/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (8461/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (9643/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (10844/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (12027/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (13226/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (14417/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (15604/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (16787/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (92.00%) (17969/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (92.00%) (19159/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (92.00%) (20351/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (21550/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (93.00%) (22748/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (23949/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (25149/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (26344/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (27541/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (28736/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (29934/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (31121/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (32314/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (33496/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (34680/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (35879/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (37080/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (38259/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (39448/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (40636/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (41836/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (43032/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (44220/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (45415/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (46564/50000)
# TEST : Loss: (0.4361) | Acc: (86.00%) (8663/10000)
percent tensor([0.5512, 0.5502, 0.5514, 0.5505, 0.5613, 0.5578, 0.5547, 0.5549, 0.5495,
        0.5478, 0.5509, 0.5493, 0.5501, 0.5416, 0.5556, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5082, 0.5059, 0.5095, 0.5070, 0.5123, 0.5080, 0.5082, 0.5096,
        0.5078, 0.5084, 0.5063, 0.5081, 0.5097, 0.5104, 0.5094],
       device='cuda:0') torch.Size([16])
percent tensor([0.5195, 0.5292, 0.5337, 0.5380, 0.5565, 0.5567, 0.5295, 0.5234, 0.5341,
        0.5192, 0.5256, 0.5378, 0.5337, 0.5207, 0.5403, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.6124, 0.5764, 0.5741, 0.5763, 0.5781, 0.6063, 0.5703, 0.5967,
        0.6087, 0.6278, 0.5932, 0.6099, 0.6097, 0.6043, 0.5938],
       device='cuda:0') torch.Size([16])
percent tensor([0.5432, 0.5466, 0.6578, 0.7148, 0.6611, 0.6914, 0.5469, 0.5380, 0.6667,
        0.5724, 0.6261, 0.6060, 0.5453, 0.7244, 0.5282, 0.6007],
       device='cuda:0') torch.Size([16])
percent tensor([0.6151, 0.5908, 0.6648, 0.6499, 0.6695, 0.6276, 0.6409, 0.6605, 0.6257,
        0.5787, 0.5774, 0.6512, 0.5640, 0.6184, 0.6391, 0.6110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5906, 0.5722, 0.7175, 0.6418, 0.7036, 0.7750, 0.6184, 0.5840, 0.5817,
        0.5614, 0.5787, 0.5417, 0.5365, 0.5989, 0.5722, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9999, 0.9996, 0.9996, 0.9993, 0.9997, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9995, 0.9993, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 105 | Batch_idx: 0 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (1333/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (2496/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (3685/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2129) |  Loss2: (0.0000) | Acc: (92.00%) (4869/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (6051/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (7227/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (8387/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (9573/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (10752/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (11938/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (13122/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (14308/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (15488/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (16675/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (17865/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (19051/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (20243/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (21445/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (22637/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (23852/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (25025/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (26208/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (27398/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (28568/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (29756/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (30925/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (32117/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (33306/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (34503/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (35687/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (36865/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (38061/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (39239/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (40420/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (92.00%) (41614/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (42786/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (43980/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (45164/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (46303/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_105.pth.tar'
# TEST : Loss: (0.4163) | Acc: (87.00%) (8703/10000)
percent tensor([0.5631, 0.5630, 0.5652, 0.5627, 0.5757, 0.5709, 0.5685, 0.5688, 0.5621,
        0.5607, 0.5634, 0.5624, 0.5624, 0.5529, 0.5688, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5082, 0.5066, 0.5041, 0.5078, 0.5053, 0.5111, 0.5062, 0.5061, 0.5086,
        0.5062, 0.5073, 0.5045, 0.5066, 0.5094, 0.5088, 0.5082],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5323, 0.5438, 0.5424, 0.5660, 0.5598, 0.5352, 0.5321, 0.5426,
        0.5286, 0.5302, 0.5467, 0.5374, 0.5243, 0.5422, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.6140, 0.6236, 0.5896, 0.5893, 0.5901, 0.5917, 0.6196, 0.5875, 0.6068,
        0.6208, 0.6374, 0.6052, 0.6182, 0.6202, 0.6181, 0.6067],
       device='cuda:0') torch.Size([16])
percent tensor([0.5364, 0.5334, 0.6677, 0.7159, 0.6683, 0.7154, 0.5416, 0.5272, 0.6607,
        0.5501, 0.6100, 0.6077, 0.5359, 0.7245, 0.5223, 0.6081],
       device='cuda:0') torch.Size([16])
percent tensor([0.6161, 0.5887, 0.6680, 0.6610, 0.6779, 0.6238, 0.6484, 0.6716, 0.6278,
        0.5796, 0.5776, 0.6549, 0.5618, 0.6181, 0.6459, 0.6134],
       device='cuda:0') torch.Size([16])
percent tensor([0.6086, 0.5763, 0.7155, 0.6142, 0.6881, 0.7802, 0.6399, 0.5691, 0.6034,
        0.5694, 0.6071, 0.5427, 0.5699, 0.6262, 0.5724, 0.6137],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9999, 0.9996, 0.9997, 0.9992, 0.9998, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9994, 0.9992, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 106 | Batch_idx: 0 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (2491/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (3681/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (4854/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (6043/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (7227/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (8415/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (9606/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (10799/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (92.00%) (12001/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (13188/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (14385/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (93.00%) (15599/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (93.00%) (16785/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (92.00%) (17969/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (19162/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (93.00%) (20362/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (21558/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (22736/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (23923/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (25124/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (93.00%) (26319/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (27517/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (28711/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (29900/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (31100/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (32291/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (33468/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (34671/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (35850/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (37044/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (38237/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (39423/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (40626/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (41825/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (93.00%) (43019/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (44222/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (45422/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (46568/50000)
# TEST : Loss: (0.4025) | Acc: (87.00%) (8711/10000)
percent tensor([0.5638, 0.5637, 0.5654, 0.5632, 0.5763, 0.5720, 0.5691, 0.5690, 0.5627,
        0.5611, 0.5643, 0.5628, 0.5630, 0.5535, 0.5698, 0.5637],
       device='cuda:0') torch.Size([16])
percent tensor([0.5089, 0.5071, 0.5045, 0.5082, 0.5058, 0.5115, 0.5068, 0.5066, 0.5093,
        0.5067, 0.5081, 0.5051, 0.5072, 0.5099, 0.5094, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.5211, 0.5337, 0.5441, 0.5403, 0.5673, 0.5578, 0.5377, 0.5330, 0.5433,
        0.5310, 0.5304, 0.5483, 0.5391, 0.5241, 0.5416, 0.5288],
       device='cuda:0') torch.Size([16])
percent tensor([0.6191, 0.6274, 0.5956, 0.5954, 0.5965, 0.5971, 0.6247, 0.5946, 0.6109,
        0.6253, 0.6409, 0.6099, 0.6216, 0.6243, 0.6237, 0.6122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5380, 0.5329, 0.6739, 0.7275, 0.6750, 0.7310, 0.5418, 0.5281, 0.6633,
        0.5482, 0.6108, 0.6117, 0.5366, 0.7316, 0.5210, 0.6204],
       device='cuda:0') torch.Size([16])
percent tensor([0.6156, 0.5857, 0.6735, 0.6670, 0.6826, 0.6227, 0.6501, 0.6787, 0.6274,
        0.5783, 0.5760, 0.6596, 0.5574, 0.6155, 0.6486, 0.6138],
       device='cuda:0') torch.Size([16])
percent tensor([0.6175, 0.5832, 0.7229, 0.6233, 0.6971, 0.7843, 0.6496, 0.5829, 0.6139,
        0.5751, 0.6177, 0.5522, 0.5787, 0.6353, 0.5789, 0.6201],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9999, 0.9996, 0.9997, 0.9992, 0.9998, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9994, 0.9993, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 107 | Batch_idx: 0 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (1305/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (92.00%) (2497/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (3679/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (4869/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (92.00%) (6065/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (7266/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (92.00%) (8451/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (92.00%) (9641/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (10849/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (12048/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (13243/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (14428/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (15609/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (16808/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (18004/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (19204/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (20423/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (21621/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (22802/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (23998/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (25201/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (26393/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (27593/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (28788/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (29979/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (31176/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (32372/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (33557/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (34760/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (35961/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (37154/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (38353/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (39546/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.1919) |  Loss2: (0.0000) | Acc: (93.00%) (40742/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (41946/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (43143/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (44340/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (45540/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (46681/50000)
# TEST : Loss: (0.3964) | Acc: (87.00%) (8740/10000)
percent tensor([0.5629, 0.5630, 0.5646, 0.5623, 0.5754, 0.5712, 0.5683, 0.5681, 0.5618,
        0.5604, 0.5635, 0.5620, 0.5619, 0.5529, 0.5691, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5100, 0.5082, 0.5054, 0.5092, 0.5066, 0.5120, 0.5080, 0.5076, 0.5104,
        0.5079, 0.5092, 0.5062, 0.5083, 0.5110, 0.5105, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5191, 0.5317, 0.5470, 0.5417, 0.5690, 0.5562, 0.5371, 0.5358, 0.5436,
        0.5311, 0.5280, 0.5501, 0.5368, 0.5247, 0.5393, 0.5263],
       device='cuda:0') torch.Size([16])
percent tensor([0.6186, 0.6262, 0.5963, 0.5959, 0.5975, 0.5973, 0.6243, 0.5961, 0.6099,
        0.6246, 0.6393, 0.6094, 0.6199, 0.6230, 0.6237, 0.6122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5452, 0.5385, 0.6802, 0.7353, 0.6808, 0.7409, 0.5471, 0.5327, 0.6726,
        0.5520, 0.6165, 0.6193, 0.5452, 0.7375, 0.5258, 0.6316],
       device='cuda:0') torch.Size([16])
percent tensor([0.6166, 0.5856, 0.6771, 0.6704, 0.6857, 0.6223, 0.6526, 0.6831, 0.6284,
        0.5789, 0.5758, 0.6628, 0.5564, 0.6154, 0.6519, 0.6150],
       device='cuda:0') torch.Size([16])
percent tensor([0.6201, 0.5807, 0.7194, 0.6161, 0.6943, 0.7903, 0.6515, 0.5731, 0.6164,
        0.5703, 0.6187, 0.5409, 0.5789, 0.6400, 0.5741, 0.6246],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9999, 0.9996, 0.9997, 0.9992, 0.9998, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9994, 0.9994, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 108 | Batch_idx: 0 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (2488/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (3674/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (4863/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (92.00%) (6069/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (7264/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (8466/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (9663/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (10852/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.1945) |  Loss2: (0.0000) | Acc: (93.00%) (12059/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (13262/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (14466/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (15656/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (16859/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (18063/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (19252/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (20460/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (21639/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (22828/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (24019/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (25216/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (26421/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (27633/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (28823/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (29999/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (31186/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (32410/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (33599/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (34801/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (35998/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (37186/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (38390/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (39579/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (40769/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.1903) |  Loss2: (0.0000) | Acc: (93.00%) (41952/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (43136/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (44340/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (45542/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (46699/50000)
# TEST : Loss: (0.3929) | Acc: (87.00%) (8739/10000)
percent tensor([0.5653, 0.5658, 0.5668, 0.5643, 0.5780, 0.5737, 0.5711, 0.5706, 0.5640,
        0.5629, 0.5661, 0.5645, 0.5643, 0.5550, 0.5718, 0.5653],
       device='cuda:0') torch.Size([16])
percent tensor([0.5109, 0.5094, 0.5062, 0.5099, 0.5074, 0.5126, 0.5090, 0.5086, 0.5113,
        0.5089, 0.5103, 0.5072, 0.5093, 0.5118, 0.5114, 0.5107],
       device='cuda:0') torch.Size([16])
percent tensor([0.5194, 0.5329, 0.5485, 0.5423, 0.5696, 0.5565, 0.5385, 0.5376, 0.5444,
        0.5330, 0.5291, 0.5525, 0.5382, 0.5260, 0.5399, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.6192, 0.6262, 0.5977, 0.5972, 0.5989, 0.5979, 0.6248, 0.5976, 0.6103,
        0.6248, 0.6391, 0.6094, 0.6195, 0.6233, 0.6240, 0.6130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5467, 0.5431, 0.6728, 0.7335, 0.6757, 0.7368, 0.5483, 0.5315, 0.6707,
        0.5532, 0.6221, 0.6162, 0.5493, 0.7375, 0.5287, 0.6313],
       device='cuda:0') torch.Size([16])
percent tensor([0.6203, 0.5879, 0.6841, 0.6778, 0.6917, 0.6256, 0.6571, 0.6913, 0.6314,
        0.5808, 0.5782, 0.6684, 0.5570, 0.6166, 0.6576, 0.6185],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.5729, 0.7268, 0.6263, 0.7025, 0.7862, 0.6466, 0.5864, 0.6129,
        0.5592, 0.6111, 0.5448, 0.5662, 0.6281, 0.5716, 0.6208],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9999, 0.9996, 0.9997, 0.9992, 0.9998, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9994, 0.9994, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 109 | Batch_idx: 0 |  Loss: (0.2113) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (2507/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (3728/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (94.00%) (4938/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (6131/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (94.00%) (7344/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (94.00%) (8544/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (94.00%) (9759/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (10948/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (12137/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (13315/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (14518/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (15728/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (16919/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (18104/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (19300/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (20504/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (21696/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (22908/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (24106/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (25322/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (26509/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (27715/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (28922/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (30133/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (31322/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (32523/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (33718/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (34937/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (36140/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (37344/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (38544/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (39732/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (40929/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (42116/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (43308/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (44520/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (45709/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (46864/50000)
# TEST : Loss: (0.3886) | Acc: (87.00%) (8766/10000)
percent tensor([0.5672, 0.5679, 0.5687, 0.5662, 0.5803, 0.5758, 0.5733, 0.5725, 0.5660,
        0.5649, 0.5681, 0.5664, 0.5663, 0.5569, 0.5740, 0.5672],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5095, 0.5064, 0.5102, 0.5076, 0.5128, 0.5092, 0.5086, 0.5115,
        0.5090, 0.5105, 0.5074, 0.5096, 0.5121, 0.5116, 0.5109],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5332, 0.5500, 0.5446, 0.5708, 0.5593, 0.5384, 0.5384, 0.5453,
        0.5342, 0.5302, 0.5537, 0.5395, 0.5277, 0.5412, 0.5291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6203, 0.6266, 0.6000, 0.5994, 0.6009, 0.5992, 0.6260, 0.6000, 0.6113,
        0.6261, 0.6398, 0.6105, 0.6197, 0.6246, 0.6252, 0.6145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5458, 0.5450, 0.6664, 0.7294, 0.6710, 0.7300, 0.5483, 0.5322, 0.6663,
        0.5518, 0.6217, 0.6140, 0.5506, 0.7325, 0.5290, 0.6267],
       device='cuda:0') torch.Size([16])
percent tensor([0.6249, 0.5915, 0.6893, 0.6836, 0.6963, 0.6300, 0.6611, 0.6971, 0.6352,
        0.5841, 0.5812, 0.6734, 0.5601, 0.6184, 0.6631, 0.6232],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.5749, 0.7266, 0.6249, 0.7027, 0.7859, 0.6452, 0.5848, 0.6153,
        0.5589, 0.6124, 0.5469, 0.5690, 0.6257, 0.5689, 0.6194],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9999, 0.9996, 0.9997, 0.9992, 0.9998, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9994, 0.9994, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 110 | Batch_idx: 0 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (2530/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (3729/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (94.00%) (4935/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (94.00%) (6141/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (7315/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (8524/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (9708/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (10899/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (12090/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (13277/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (14473/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (15652/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (16851/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (18045/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (19230/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.1945) |  Loss2: (0.0000) | Acc: (93.00%) (20415/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (21607/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (22800/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (23989/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (25191/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (26373/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (27577/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (28762/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (29949/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (31117/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (32305/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (33493/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (34679/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (35869/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (37064/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (38237/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (39428/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (92.00%) (40592/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (41781/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (42984/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (44183/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (45362/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (46520/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_110.pth.tar'
# TEST : Loss: (0.4448) | Acc: (86.00%) (8624/10000)
percent tensor([0.5675, 0.5674, 0.5706, 0.5663, 0.5812, 0.5736, 0.5733, 0.5732, 0.5665,
        0.5647, 0.5677, 0.5677, 0.5667, 0.5553, 0.5727, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.5089, 0.5068, 0.5102, 0.5079, 0.5124, 0.5088, 0.5086, 0.5109,
        0.5089, 0.5098, 0.5077, 0.5093, 0.5108, 0.5112, 0.5107],
       device='cuda:0') torch.Size([16])
percent tensor([0.5251, 0.5344, 0.5494, 0.5482, 0.5711, 0.5623, 0.5378, 0.5389, 0.5483,
        0.5338, 0.5346, 0.5537, 0.5432, 0.5244, 0.5447, 0.5329],
       device='cuda:0') torch.Size([16])
percent tensor([0.6198, 0.6277, 0.6009, 0.6001, 0.6010, 0.6007, 0.6281, 0.6020, 0.6077,
        0.6256, 0.6381, 0.6097, 0.6178, 0.6287, 0.6273, 0.6142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5393, 0.5365, 0.6608, 0.7349, 0.6651, 0.7126, 0.5386, 0.5379, 0.6561,
        0.5495, 0.6027, 0.6150, 0.5434, 0.7296, 0.5229, 0.6074],
       device='cuda:0') torch.Size([16])
percent tensor([0.6292, 0.5967, 0.6769, 0.6698, 0.6803, 0.6360, 0.6624, 0.6917, 0.6382,
        0.5888, 0.5891, 0.6693, 0.5713, 0.6288, 0.6631, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.6056, 0.5818, 0.6828, 0.6132, 0.6933, 0.7819, 0.6086, 0.5594, 0.6232,
        0.5603, 0.6283, 0.5189, 0.5785, 0.6400, 0.5451, 0.6140],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9997, 0.9997, 0.9991, 0.9998, 0.9999, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9995, 0.9998, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(181.8016, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(820.7679, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(820.3917, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1519.7599, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(494.2930, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2235.8711, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4283.9238, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1382.7010, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6155.7158, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11812.7256, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3913.6326, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16579.2676, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 111 | Batch_idx: 0 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (1317/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (2508/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (3697/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (4909/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (6103/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (7301/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (8486/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (9683/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (10871/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.1945) |  Loss2: (0.0000) | Acc: (93.00%) (12060/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (13257/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (14460/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (15657/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (16853/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (18054/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.1903) |  Loss2: (0.0000) | Acc: (93.00%) (19259/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (20442/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (21631/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (22834/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (24012/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (25216/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (26410/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (27607/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (28805/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (30006/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (31202/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (32408/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (33610/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (34810/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (35999/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (37185/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (38375/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (39559/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (40754/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (41957/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (43156/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (44349/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (45547/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (46705/50000)
# TEST : Loss: (0.4259) | Acc: (86.00%) (8662/10000)
percent tensor([0.5671, 0.5669, 0.5667, 0.5655, 0.5800, 0.5744, 0.5721, 0.5712, 0.5655,
        0.5633, 0.5669, 0.5657, 0.5662, 0.5552, 0.5730, 0.5657],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5095, 0.5063, 0.5103, 0.5079, 0.5128, 0.5090, 0.5088, 0.5114,
        0.5091, 0.5102, 0.5071, 0.5098, 0.5113, 0.5118, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.5223, 0.5371, 0.5465, 0.5479, 0.5706, 0.5625, 0.5390, 0.5367, 0.5454,
        0.5345, 0.5313, 0.5544, 0.5415, 0.5302, 0.5460, 0.5305],
       device='cuda:0') torch.Size([16])
percent tensor([0.6227, 0.6280, 0.6025, 0.6006, 0.6025, 0.6045, 0.6299, 0.6008, 0.6130,
        0.6282, 0.6411, 0.6132, 0.6231, 0.6268, 0.6269, 0.6161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5518, 0.5591, 0.6736, 0.7436, 0.6686, 0.7075, 0.5574, 0.5511, 0.6849,
        0.5688, 0.6311, 0.6356, 0.5690, 0.7371, 0.5279, 0.6246],
       device='cuda:0') torch.Size([16])
percent tensor([0.6218, 0.5854, 0.6768, 0.6757, 0.6905, 0.6319, 0.6509, 0.6938, 0.6377,
        0.5708, 0.5778, 0.6602, 0.5618, 0.6121, 0.6528, 0.6176],
       device='cuda:0') torch.Size([16])
percent tensor([0.6139, 0.5737, 0.7264, 0.6561, 0.7500, 0.7855, 0.6008, 0.5884, 0.6340,
        0.5459, 0.6096, 0.5553, 0.5661, 0.6077, 0.5462, 0.6027],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9999, 0.9997, 0.9996, 0.9993, 0.9996, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9994, 0.9995, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 112 | Batch_idx: 0 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (2534/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (3741/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (93.00%) (4929/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (93.00%) (6121/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (7322/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (8526/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (9735/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (10935/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (93.00%) (12151/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (13349/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (14531/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (15743/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (16937/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (18139/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (19326/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (20518/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (21723/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (22904/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (24110/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (25295/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (26490/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (27676/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (28870/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (30073/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (31273/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (32475/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (33683/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (34887/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (36086/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (37281/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (38477/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (39672/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (40850/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (42053/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (43247/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (44436/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (45615/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (46755/50000)
# TEST : Loss: (0.4235) | Acc: (86.00%) (8653/10000)
percent tensor([0.5661, 0.5662, 0.5701, 0.5642, 0.5813, 0.5730, 0.5730, 0.5718, 0.5647,
        0.5640, 0.5661, 0.5671, 0.5646, 0.5539, 0.5719, 0.5647],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.5093, 0.5065, 0.5100, 0.5075, 0.5124, 0.5090, 0.5087, 0.5107,
        0.5091, 0.5099, 0.5072, 0.5092, 0.5114, 0.5113, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5374, 0.5441, 0.5405, 0.5673, 0.5642, 0.5411, 0.5355, 0.5461,
        0.5363, 0.5347, 0.5539, 0.5419, 0.5308, 0.5434, 0.5318],
       device='cuda:0') torch.Size([16])
percent tensor([0.6221, 0.6276, 0.5989, 0.5981, 0.5986, 0.6002, 0.6264, 0.5981, 0.6111,
        0.6260, 0.6420, 0.6108, 0.6210, 0.6261, 0.6270, 0.6151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5525, 0.5511, 0.6607, 0.7399, 0.6738, 0.7232, 0.5626, 0.5406, 0.6606,
        0.5619, 0.6263, 0.6173, 0.5494, 0.7372, 0.5272, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.6196, 0.5856, 0.6888, 0.6877, 0.6888, 0.6352, 0.6557, 0.6899, 0.6359,
        0.5760, 0.5808, 0.6659, 0.5489, 0.6270, 0.6502, 0.6172],
       device='cuda:0') torch.Size([16])
percent tensor([0.6110, 0.5836, 0.7127, 0.6274, 0.7214, 0.7857, 0.6185, 0.5478, 0.6342,
        0.5468, 0.6074, 0.5127, 0.5694, 0.6167, 0.5346, 0.5800],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9998, 0.9997, 0.9986, 0.9996, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9995, 0.9996, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 113 | Batch_idx: 0 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (2537/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (94.00%) (3738/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (4945/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (6132/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (7333/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (8536/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (9740/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (10942/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (12139/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (13336/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (14526/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (15724/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (16923/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (18121/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (19327/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (20532/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (21735/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (22922/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (24120/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (25308/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (26506/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (27709/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (28898/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (30095/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (31306/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (32485/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (33680/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (34882/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (36084/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (37290/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (38489/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (39674/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (40854/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (42048/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (43257/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (44437/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (45628/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (46782/50000)
# TEST : Loss: (0.4440) | Acc: (86.00%) (8615/10000)
percent tensor([0.5663, 0.5671, 0.5682, 0.5655, 0.5807, 0.5729, 0.5732, 0.5716, 0.5655,
        0.5639, 0.5666, 0.5667, 0.5653, 0.5561, 0.5722, 0.5652],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.5091, 0.5058, 0.5102, 0.5069, 0.5128, 0.5087, 0.5079, 0.5110,
        0.5088, 0.5100, 0.5064, 0.5093, 0.5121, 0.5112, 0.5111],
       device='cuda:0') torch.Size([16])
percent tensor([0.5190, 0.5343, 0.5486, 0.5453, 0.5702, 0.5505, 0.5409, 0.5408, 0.5479,
        0.5373, 0.5317, 0.5569, 0.5390, 0.5331, 0.5376, 0.5279],
       device='cuda:0') torch.Size([16])
percent tensor([0.6262, 0.6306, 0.6030, 0.5996, 0.6026, 0.6090, 0.6290, 0.6010, 0.6125,
        0.6287, 0.6453, 0.6139, 0.6219, 0.6262, 0.6321, 0.6171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5536, 0.5538, 0.6374, 0.7316, 0.6458, 0.7066, 0.5515, 0.5309, 0.6788,
        0.5666, 0.6324, 0.5965, 0.5617, 0.7440, 0.5274, 0.6196],
       device='cuda:0') torch.Size([16])
percent tensor([0.6317, 0.6027, 0.6976, 0.6885, 0.6998, 0.6401, 0.6664, 0.6947, 0.6448,
        0.5921, 0.5987, 0.6802, 0.5677, 0.6355, 0.6673, 0.6250],
       device='cuda:0') torch.Size([16])
percent tensor([0.5962, 0.5667, 0.7229, 0.6230, 0.7379, 0.7553, 0.6437, 0.5345, 0.6368,
        0.5515, 0.6214, 0.5090, 0.5607, 0.6376, 0.5117, 0.5977],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 1.0000, 0.9998, 0.9997, 0.9994, 0.9998, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9994, 0.9998, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 114 | Batch_idx: 0 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (1331/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (2534/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (3740/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (4941/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (6146/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (7351/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (8547/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (9751/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (10966/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (12173/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (13373/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (14586/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (15788/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (16992/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (18181/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (94.00%) (19378/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (94.00%) (20580/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (21779/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (22973/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (24173/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (25379/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (26580/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (27779/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (28963/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (30158/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (31359/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (32558/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (33778/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (34982/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (36175/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (37367/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (38551/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (39765/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (40960/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (42153/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (43360/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (44562/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (45747/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (46888/50000)
# TEST : Loss: (0.4448) | Acc: (85.00%) (8574/10000)
percent tensor([0.5661, 0.5671, 0.5655, 0.5647, 0.5790, 0.5724, 0.5719, 0.5714, 0.5645,
        0.5631, 0.5655, 0.5652, 0.5655, 0.5564, 0.5723, 0.5650],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.5094, 0.5066, 0.5108, 0.5078, 0.5131, 0.5090, 0.5081, 0.5111,
        0.5092, 0.5100, 0.5073, 0.5095, 0.5121, 0.5117, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.5207, 0.5312, 0.5519, 0.5473, 0.5741, 0.5559, 0.5374, 0.5420, 0.5496,
        0.5337, 0.5286, 0.5585, 0.5392, 0.5296, 0.5402, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.6247, 0.6293, 0.6006, 0.6009, 0.6028, 0.6051, 0.6291, 0.6003, 0.6134,
        0.6267, 0.6420, 0.6082, 0.6214, 0.6277, 0.6279, 0.6170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5561, 0.5690, 0.6657, 0.7564, 0.6780, 0.7213, 0.5687, 0.5555, 0.6730,
        0.5791, 0.6409, 0.6357, 0.5639, 0.7478, 0.5478, 0.6336],
       device='cuda:0') torch.Size([16])
percent tensor([0.6327, 0.5989, 0.6804, 0.6741, 0.6923, 0.6365, 0.6655, 0.6986, 0.6427,
        0.5871, 0.5920, 0.6742, 0.5700, 0.6298, 0.6689, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.6162, 0.5902, 0.6845, 0.6118, 0.7134, 0.7608, 0.6229, 0.5320, 0.6061,
        0.5613, 0.6186, 0.5266, 0.5702, 0.6117, 0.5424, 0.6238],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9995, 0.9996, 0.9992, 0.9998, 0.9998, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9994, 0.9996, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 115 | Batch_idx: 0 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (2495/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (3658/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (4812/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (91.00%) (5995/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (91.00%) (7158/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.2354) |  Loss2: (0.0000) | Acc: (91.00%) (8323/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (91.00%) (9508/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (10664/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (91.00%) (11847/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (91.00%) (13028/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (91.00%) (14214/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (91.00%) (15377/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (91.00%) (16549/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (17738/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (91.00%) (18918/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (91.00%) (20101/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (91.00%) (21278/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (91.00%) (22461/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (91.00%) (23646/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.2281) |  Loss2: (0.0000) | Acc: (91.00%) (24821/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (91.00%) (25998/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (91.00%) (27174/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (91.00%) (28370/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (91.00%) (29540/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (91.00%) (30724/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (31919/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (33096/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (34278/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (91.00%) (35439/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (36631/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (37829/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (39014/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (40186/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (41370/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (42555/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (43726/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (44898/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (46041/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_115.pth.tar'
# TEST : Loss: (0.4253) | Acc: (86.00%) (8664/10000)
percent tensor([0.5558, 0.5576, 0.5554, 0.5551, 0.5676, 0.5623, 0.5612, 0.5606, 0.5554,
        0.5531, 0.5561, 0.5550, 0.5554, 0.5496, 0.5619, 0.5554],
       device='cuda:0') torch.Size([16])
percent tensor([0.5152, 0.5144, 0.5101, 0.5146, 0.5119, 0.5169, 0.5141, 0.5125, 0.5152,
        0.5138, 0.5145, 0.5120, 0.5146, 0.5156, 0.5165, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5209, 0.5334, 0.5562, 0.5482, 0.5799, 0.5533, 0.5436, 0.5433, 0.5525,
        0.5380, 0.5293, 0.5647, 0.5414, 0.5290, 0.5426, 0.5281],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.6283, 0.6063, 0.6035, 0.6090, 0.6086, 0.6312, 0.6077, 0.6125,
        0.6275, 0.6378, 0.6110, 0.6196, 0.6260, 0.6304, 0.6195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5767, 0.5979, 0.6684, 0.7599, 0.6700, 0.7331, 0.5890, 0.5486, 0.6769,
        0.5974, 0.6528, 0.6579, 0.6107, 0.7374, 0.5667, 0.6623],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.5966, 0.6670, 0.6640, 0.6857, 0.6308, 0.6596, 0.6904, 0.6461,
        0.5838, 0.5936, 0.6636, 0.5692, 0.6286, 0.6592, 0.6184],
       device='cuda:0') torch.Size([16])
percent tensor([0.5396, 0.5396, 0.6515, 0.6038, 0.6956, 0.7132, 0.5650, 0.4884, 0.5878,
        0.5039, 0.5885, 0.4621, 0.4993, 0.5551, 0.4738, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9999, 0.9996, 0.9996, 0.9995, 0.9998, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9993, 0.9997, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 116 | Batch_idx: 0 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (93.00%) (2502/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (93.00%) (3694/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (93.00%) (4885/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.2048) |  Loss2: (0.0000) | Acc: (93.00%) (6081/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (93.00%) (7266/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (93.00%) (8452/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (9638/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (93.00%) (10836/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (93.00%) (12032/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (93.00%) (13216/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (14388/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (15580/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (93.00%) (16785/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (93.00%) (17979/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (92.00%) (19157/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (92.00%) (20347/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (21538/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (92.00%) (22711/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (23901/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (25105/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (92.00%) (26302/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (93.00%) (27499/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (28668/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (92.00%) (29855/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (92.00%) (31040/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (32237/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (33428/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (92.00%) (34632/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (92.00%) (35817/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (37008/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (92.00%) (38207/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (92.00%) (39387/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (40578/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (92.00%) (41762/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (42946/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (44149/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (45351/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (46508/50000)
# TEST : Loss: (0.4107) | Acc: (87.00%) (8708/10000)
percent tensor([0.5600, 0.5623, 0.5598, 0.5595, 0.5727, 0.5665, 0.5660, 0.5657, 0.5598,
        0.5576, 0.5605, 0.5595, 0.5600, 0.5536, 0.5665, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5166, 0.5117, 0.5161, 0.5138, 0.5186, 0.5162, 0.5144, 0.5170,
        0.5158, 0.5164, 0.5140, 0.5169, 0.5171, 0.5184, 0.5174],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.5318, 0.5598, 0.5490, 0.5845, 0.5537, 0.5450, 0.5457, 0.5535,
        0.5376, 0.5280, 0.5691, 0.5407, 0.5268, 0.5426, 0.5265],
       device='cuda:0') torch.Size([16])
percent tensor([0.6326, 0.6311, 0.6116, 0.6074, 0.6152, 0.6150, 0.6358, 0.6146, 0.6163,
        0.6300, 0.6404, 0.6147, 0.6225, 0.6291, 0.6355, 0.6248],
       device='cuda:0') torch.Size([16])
percent tensor([0.5701, 0.5962, 0.6581, 0.7540, 0.6595, 0.7319, 0.5804, 0.5347, 0.6727,
        0.5980, 0.6498, 0.6599, 0.6146, 0.7364, 0.5565, 0.6644],
       device='cuda:0') torch.Size([16])
percent tensor([0.6359, 0.6072, 0.6781, 0.6735, 0.6952, 0.6395, 0.6690, 0.6979, 0.6544,
        0.5947, 0.6041, 0.6744, 0.5808, 0.6410, 0.6668, 0.6271],
       device='cuda:0') torch.Size([16])
percent tensor([0.5438, 0.5503, 0.6528, 0.6025, 0.6931, 0.7067, 0.5695, 0.4851, 0.6080,
        0.5193, 0.6073, 0.4662, 0.5084, 0.5662, 0.4727, 0.5360],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9999, 0.9996, 0.9995, 0.9995, 0.9998, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9993, 0.9997, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 117 | Batch_idx: 0 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (2516/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (3701/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (4896/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (6082/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (7273/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (8470/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (9664/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (10856/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (12073/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (13264/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (14449/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (15645/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (16839/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (18040/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (19232/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (20431/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (21619/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (22818/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (24012/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (25206/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (26389/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (27605/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (28794/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (29995/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (31195/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (32389/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (33581/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (34789/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (35983/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (37171/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (38389/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (39586/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (40785/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (41976/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (43168/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (44349/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (45555/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (46721/50000)
# TEST : Loss: (0.3996) | Acc: (87.00%) (8736/10000)
percent tensor([0.5599, 0.5623, 0.5598, 0.5598, 0.5726, 0.5663, 0.5658, 0.5659, 0.5597,
        0.5575, 0.5604, 0.5594, 0.5600, 0.5536, 0.5664, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.5182, 0.5183, 0.5131, 0.5175, 0.5153, 0.5198, 0.5179, 0.5161, 0.5184,
        0.5174, 0.5177, 0.5156, 0.5187, 0.5183, 0.5199, 0.5188],
       device='cuda:0') torch.Size([16])
percent tensor([0.5176, 0.5302, 0.5629, 0.5491, 0.5887, 0.5518, 0.5457, 0.5495, 0.5535,
        0.5361, 0.5247, 0.5724, 0.5387, 0.5229, 0.5418, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.6323, 0.6292, 0.6106, 0.6057, 0.6146, 0.6152, 0.6344, 0.6147, 0.6145,
        0.6276, 0.6378, 0.6127, 0.6208, 0.6270, 0.6345, 0.6243],
       device='cuda:0') torch.Size([16])
percent tensor([0.5640, 0.5887, 0.6531, 0.7487, 0.6553, 0.7295, 0.5725, 0.5294, 0.6669,
        0.5944, 0.6415, 0.6538, 0.6096, 0.7282, 0.5480, 0.6625],
       device='cuda:0') torch.Size([16])
percent tensor([0.6379, 0.6097, 0.6817, 0.6774, 0.6991, 0.6426, 0.6716, 0.7000, 0.6568,
        0.5988, 0.6069, 0.6772, 0.5844, 0.6462, 0.6680, 0.6293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5668, 0.5756, 0.6641, 0.6171, 0.7018, 0.7190, 0.5945, 0.4953, 0.6391,
        0.5507, 0.6430, 0.4905, 0.5374, 0.6056, 0.4945, 0.5466],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9996, 0.9996, 0.9995, 0.9998, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9993, 0.9997, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 118 | Batch_idx: 0 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (94.00%) (1325/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (3721/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (4913/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (6107/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (7306/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (8509/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (9701/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (10897/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (12104/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (13321/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (14501/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (15707/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (16914/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (18111/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (19315/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (20524/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (21735/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (22943/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (24147/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (25348/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (26534/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (27741/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (28928/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (30129/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (31333/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (32529/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (33727/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (34931/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (36120/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (37328/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (38518/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (39719/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (40916/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (42109/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (43308/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (44504/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (45710/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (46858/50000)
# TEST : Loss: (0.4006) | Acc: (87.00%) (8742/10000)
percent tensor([0.5578, 0.5599, 0.5575, 0.5578, 0.5700, 0.5640, 0.5632, 0.5634, 0.5577,
        0.5552, 0.5583, 0.5571, 0.5580, 0.5516, 0.5639, 0.5575],
       device='cuda:0') torch.Size([16])
percent tensor([0.5189, 0.5191, 0.5136, 0.5181, 0.5160, 0.5206, 0.5186, 0.5168, 0.5191,
        0.5181, 0.5184, 0.5163, 0.5196, 0.5187, 0.5206, 0.5196],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5278, 0.5563, 0.5425, 0.5824, 0.5484, 0.5410, 0.5429, 0.5500,
        0.5310, 0.5215, 0.5670, 0.5351, 0.5198, 0.5371, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.6326, 0.6282, 0.6118, 0.6063, 0.6156, 0.6164, 0.6333, 0.6151, 0.6135,
        0.6267, 0.6362, 0.6114, 0.6199, 0.6256, 0.6345, 0.6249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5571, 0.5801, 0.6466, 0.7420, 0.6485, 0.7227, 0.5647, 0.5269, 0.6590,
        0.5853, 0.6290, 0.6465, 0.6038, 0.7196, 0.5418, 0.6531],
       device='cuda:0') torch.Size([16])
percent tensor([0.6372, 0.6076, 0.6818, 0.6779, 0.6985, 0.6428, 0.6689, 0.6988, 0.6551,
        0.5974, 0.6060, 0.6743, 0.5835, 0.6447, 0.6651, 0.6281],
       device='cuda:0') torch.Size([16])
percent tensor([0.5629, 0.5804, 0.6675, 0.6246, 0.7040, 0.7136, 0.5991, 0.5055, 0.6442,
        0.5515, 0.6485, 0.5005, 0.5327, 0.6156, 0.5044, 0.5400],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9996, 0.9996, 0.9995, 0.9998, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9993, 0.9997, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (1319/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (94.00%) (2528/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (3734/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (4927/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (6118/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (7325/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (8535/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (9739/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (10920/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (12127/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (13310/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (14512/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (15721/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (16929/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (18142/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (19342/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (20544/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (21746/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (22953/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (24155/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (25368/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (26564/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (27766/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (28964/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (30162/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (31362/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (32587/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (33791/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (34995/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (36207/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (37415/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (38608/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (39810/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (41016/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (42214/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (43419/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (44624/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (45820/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (46972/50000)
# TEST : Loss: (0.3939) | Acc: (87.00%) (8775/10000)
percent tensor([0.5614, 0.5640, 0.5615, 0.5619, 0.5744, 0.5675, 0.5674, 0.5679, 0.5615,
        0.5592, 0.5619, 0.5611, 0.5618, 0.5554, 0.5678, 0.5612],
       device='cuda:0') torch.Size([16])
percent tensor([0.5203, 0.5208, 0.5149, 0.5196, 0.5175, 0.5218, 0.5203, 0.5183, 0.5206,
        0.5197, 0.5199, 0.5179, 0.5213, 0.5202, 0.5221, 0.5211],
       device='cuda:0') torch.Size([16])
percent tensor([0.5148, 0.5278, 0.5597, 0.5454, 0.5857, 0.5487, 0.5434, 0.5464, 0.5523,
        0.5332, 0.5230, 0.5708, 0.5357, 0.5222, 0.5381, 0.5196],
       device='cuda:0') torch.Size([16])
percent tensor([0.6306, 0.6255, 0.6099, 0.6038, 0.6135, 0.6147, 0.6311, 0.6136, 0.6105,
        0.6236, 0.6333, 0.6086, 0.6167, 0.6227, 0.6321, 0.6228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.5805, 0.6588, 0.7538, 0.6620, 0.7260, 0.5696, 0.5332, 0.6692,
        0.5902, 0.6334, 0.6557, 0.6020, 0.7307, 0.5426, 0.6578],
       device='cuda:0') torch.Size([16])
percent tensor([0.6380, 0.6083, 0.6833, 0.6787, 0.6998, 0.6448, 0.6696, 0.6993, 0.6562,
        0.5976, 0.6074, 0.6753, 0.5847, 0.6455, 0.6658, 0.6282],
       device='cuda:0') torch.Size([16])
percent tensor([0.5615, 0.5793, 0.6647, 0.6176, 0.6992, 0.7124, 0.5934, 0.4986, 0.6421,
        0.5518, 0.6478, 0.4938, 0.5340, 0.6090, 0.4989, 0.5298],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9996, 0.9996, 0.9995, 0.9998, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9993, 0.9997, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (1320/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (93.00%) (2526/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (94.00%) (3733/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (94.00%) (4945/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (94.00%) (6150/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (7367/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (8561/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (9766/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (10977/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (12176/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (94.00%) (13362/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (94.00%) (14562/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (15761/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (16963/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (18157/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (19358/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (20570/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (21772/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (94.00%) (22983/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (94.00%) (24190/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (94.00%) (25399/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (26605/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (94.00%) (27802/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (28996/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (93.00%) (30199/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (94.00%) (31404/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (94.00%) (32610/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (33808/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (35001/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (36191/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (37399/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (38592/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (39791/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (40985/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (42185/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (43383/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (44574/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (45767/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (46922/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_120.pth.tar'
# TEST : Loss: (0.4122) | Acc: (87.00%) (8736/10000)
percent tensor([0.5643, 0.5636, 0.5662, 0.5644, 0.5773, 0.5693, 0.5689, 0.5699, 0.5630,
        0.5609, 0.5633, 0.5646, 0.5642, 0.5530, 0.5684, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5211, 0.5208, 0.5161, 0.5187, 0.5178, 0.5215, 0.5206, 0.5192, 0.5205,
        0.5198, 0.5202, 0.5187, 0.5212, 0.5189, 0.5219, 0.5206],
       device='cuda:0') torch.Size([16])
percent tensor([0.5159, 0.5307, 0.5544, 0.5375, 0.5783, 0.5534, 0.5437, 0.5463, 0.5518,
        0.5302, 0.5294, 0.5666, 0.5397, 0.5244, 0.5373, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.6274, 0.6242, 0.6091, 0.6055, 0.6123, 0.6165, 0.6285, 0.6093, 0.6071,
        0.6221, 0.6342, 0.6039, 0.6139, 0.6231, 0.6315, 0.6237],
       device='cuda:0') torch.Size([16])
percent tensor([0.5630, 0.5795, 0.6601, 0.7334, 0.6664, 0.7072, 0.5819, 0.5333, 0.7003,
        0.6045, 0.6351, 0.6623, 0.6021, 0.7684, 0.5353, 0.6368],
       device='cuda:0') torch.Size([16])
percent tensor([0.6343, 0.5997, 0.7008, 0.7039, 0.7084, 0.6495, 0.6676, 0.6990, 0.6506,
        0.5965, 0.5948, 0.6758, 0.5740, 0.6359, 0.6640, 0.6252],
       device='cuda:0') torch.Size([16])
percent tensor([0.5538, 0.5432, 0.6733, 0.5839, 0.6745, 0.7146, 0.5957, 0.5093, 0.6174,
        0.5638, 0.6203, 0.4770, 0.5390, 0.6033, 0.5207, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9999, 0.9997, 0.9998, 0.9991, 0.9997, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9995, 0.9996, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.3736, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.0974, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.6885, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1518.9841, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(492.7449, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2242.1292, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4282.5449, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1377.6078, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6167.8203, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11778.0342, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3898.5010, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16513.0156, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 121 | Batch_idx: 0 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (2546/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (3755/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (4956/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (6167/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (7373/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (8586/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (9788/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (11006/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (12204/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (13407/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (14626/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (15826/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (17022/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (18209/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (19422/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (20625/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (21829/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (23028/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (24225/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (25425/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (26629/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (27842/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (29053/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (30251/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (31452/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (32649/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (33853/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (35058/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (36268/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (37464/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (38656/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (39865/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (41060/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (42264/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (43475/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (44693/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (45904/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (47063/50000)
# TEST : Loss: (0.4855) | Acc: (85.00%) (8539/10000)
percent tensor([0.5631, 0.5642, 0.5642, 0.5640, 0.5763, 0.5679, 0.5684, 0.5701, 0.5623,
        0.5602, 0.5621, 0.5634, 0.5631, 0.5542, 0.5683, 0.5622],
       device='cuda:0') torch.Size([16])
percent tensor([0.5200, 0.5201, 0.5143, 0.5180, 0.5170, 0.5208, 0.5199, 0.5177, 0.5197,
        0.5192, 0.5196, 0.5176, 0.5205, 0.5192, 0.5212, 0.5199],
       device='cuda:0') torch.Size([16])
percent tensor([0.5171, 0.5343, 0.5524, 0.5429, 0.5819, 0.5515, 0.5469, 0.5445, 0.5534,
        0.5323, 0.5305, 0.5692, 0.5421, 0.5328, 0.5393, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.6296, 0.6235, 0.6131, 0.6031, 0.6144, 0.6175, 0.6284, 0.6092, 0.6089,
        0.6224, 0.6345, 0.6081, 0.6148, 0.6195, 0.6315, 0.6230],
       device='cuda:0') torch.Size([16])
percent tensor([0.5597, 0.5679, 0.6752, 0.7487, 0.6653, 0.7043, 0.5656, 0.5424, 0.6887,
        0.5864, 0.6345, 0.6572, 0.5792, 0.7517, 0.5390, 0.6395],
       device='cuda:0') torch.Size([16])
percent tensor([0.6426, 0.6064, 0.7002, 0.6956, 0.7123, 0.6482, 0.6696, 0.6961, 0.6526,
        0.6020, 0.6057, 0.6850, 0.5800, 0.6458, 0.6679, 0.6235],
       device='cuda:0') torch.Size([16])
percent tensor([0.5849, 0.5794, 0.6597, 0.5848, 0.6708, 0.7153, 0.6171, 0.5309, 0.6388,
        0.5578, 0.6399, 0.4786, 0.5505, 0.6046, 0.5310, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9995, 0.9997, 0.9998, 0.9999,
        0.9998, 1.0000, 0.9998, 0.9996, 0.9998, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 122 | Batch_idx: 0 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (2534/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (3745/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (4961/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (6157/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (7373/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (8599/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (9813/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (11026/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (12232/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (13448/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (14671/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (15875/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (17093/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (18305/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (19507/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (20718/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (21912/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (23133/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (24338/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (25542/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (26755/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (27951/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (29141/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (30345/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (31555/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (32745/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (33946/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (35151/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (36360/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (37550/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (38755/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (39942/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (41147/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (42355/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (43555/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (44747/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (45954/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (47119/50000)
# TEST : Loss: (0.4340) | Acc: (86.00%) (8639/10000)
percent tensor([0.5642, 0.5637, 0.5661, 0.5644, 0.5772, 0.5683, 0.5693, 0.5701, 0.5638,
        0.5610, 0.5629, 0.5645, 0.5640, 0.5531, 0.5683, 0.5625],
       device='cuda:0') torch.Size([16])
percent tensor([0.5210, 0.5210, 0.5156, 0.5190, 0.5179, 0.5216, 0.5210, 0.5188, 0.5207,
        0.5198, 0.5204, 0.5185, 0.5213, 0.5200, 0.5220, 0.5209],
       device='cuda:0') torch.Size([16])
percent tensor([0.5193, 0.5301, 0.5539, 0.5394, 0.5781, 0.5525, 0.5479, 0.5476, 0.5567,
        0.5335, 0.5321, 0.5691, 0.5411, 0.5290, 0.5399, 0.5234],
       device='cuda:0') torch.Size([16])
percent tensor([0.6265, 0.6257, 0.6088, 0.6031, 0.6102, 0.6141, 0.6290, 0.6089, 0.6056,
        0.6221, 0.6329, 0.6085, 0.6141, 0.6232, 0.6308, 0.6220],
       device='cuda:0') torch.Size([16])
percent tensor([0.5690, 0.5810, 0.6722, 0.7613, 0.6815, 0.7440, 0.5696, 0.5511, 0.7006,
        0.5917, 0.6465, 0.6537, 0.6083, 0.7553, 0.5429, 0.6599],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.6184, 0.7083, 0.6929, 0.7085, 0.6411, 0.6781, 0.7009, 0.6650,
        0.6114, 0.6205, 0.6914, 0.5971, 0.6472, 0.6709, 0.6360],
       device='cuda:0') torch.Size([16])
percent tensor([0.5639, 0.5729, 0.6652, 0.5791, 0.6795, 0.7337, 0.5872, 0.5062, 0.6445,
        0.5560, 0.6321, 0.4956, 0.5426, 0.6007, 0.5204, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9999, 0.9996, 0.9997, 0.9993, 0.9997, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9994, 0.9994, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 123 | Batch_idx: 0 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (2544/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (3764/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (4971/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (6177/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (7394/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (8604/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (9810/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (11021/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (12215/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (13429/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (14637/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (15860/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (17067/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (18278/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (19489/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (20704/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (21917/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (23128/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (24335/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (25554/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (26760/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (27965/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (29169/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (30356/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (31555/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (32745/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (33946/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (35147/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (36356/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (37555/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (38769/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (39967/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (41168/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (42378/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (43590/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (44817/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (46038/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (47197/50000)
# TEST : Loss: (0.3913) | Acc: (87.00%) (8765/10000)
percent tensor([0.5647, 0.5645, 0.5676, 0.5646, 0.5789, 0.5697, 0.5704, 0.5703, 0.5642,
        0.5620, 0.5641, 0.5657, 0.5641, 0.5550, 0.5692, 0.5634],
       device='cuda:0') torch.Size([16])
percent tensor([0.5199, 0.5208, 0.5138, 0.5177, 0.5168, 0.5206, 0.5204, 0.5183, 0.5202,
        0.5191, 0.5199, 0.5169, 0.5205, 0.5203, 0.5214, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.5178, 0.5349, 0.5562, 0.5418, 0.5796, 0.5574, 0.5480, 0.5436, 0.5542,
        0.5337, 0.5309, 0.5659, 0.5389, 0.5358, 0.5424, 0.5250],
       device='cuda:0') torch.Size([16])
percent tensor([0.6283, 0.6233, 0.6077, 0.6056, 0.6102, 0.6156, 0.6277, 0.6104, 0.6076,
        0.6202, 0.6320, 0.6053, 0.6160, 0.6193, 0.6314, 0.6218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5594, 0.5669, 0.6684, 0.7457, 0.6847, 0.7195, 0.5715, 0.5448, 0.6909,
        0.5853, 0.6399, 0.6364, 0.5800, 0.7438, 0.5321, 0.6459],
       device='cuda:0') torch.Size([16])
percent tensor([0.6403, 0.6063, 0.6923, 0.6822, 0.7035, 0.6453, 0.6743, 0.6950, 0.6505,
        0.6009, 0.6015, 0.6756, 0.5799, 0.6361, 0.6614, 0.6320],
       device='cuda:0') torch.Size([16])
percent tensor([0.5731, 0.5542, 0.6723, 0.6053, 0.6816, 0.7224, 0.5958, 0.5197, 0.6266,
        0.5536, 0.6253, 0.4902, 0.5388, 0.5897, 0.5199, 0.5332],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9999, 0.9997, 0.9996, 0.9993, 0.9998, 0.9999, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9995, 0.9991, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 124 | Batch_idx: 0 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (2540/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (3745/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (4955/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (6159/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (7370/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (8593/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (9796/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (11002/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (12215/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (13427/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (14622/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (15841/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (17048/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (18249/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (19460/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (20680/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (21899/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (23108/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (24318/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (25524/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (26726/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (27928/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (29152/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (30347/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (31550/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (32764/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (33968/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (35168/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (36367/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (37562/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (38779/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (39989/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (41188/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (42401/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (43600/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (44802/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (46000/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (47153/50000)
# TEST : Loss: (0.4359) | Acc: (86.00%) (8654/10000)
percent tensor([0.5635, 0.5641, 0.5652, 0.5627, 0.5767, 0.5691, 0.5691, 0.5693, 0.5634,
        0.5609, 0.5635, 0.5634, 0.5633, 0.5549, 0.5689, 0.5624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5202, 0.5210, 0.5154, 0.5187, 0.5177, 0.5209, 0.5205, 0.5190, 0.5202,
        0.5195, 0.5196, 0.5178, 0.5207, 0.5194, 0.5217, 0.5204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5172, 0.5356, 0.5506, 0.5434, 0.5758, 0.5586, 0.5434, 0.5418, 0.5494,
        0.5318, 0.5262, 0.5626, 0.5381, 0.5253, 0.5452, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.6240, 0.6081, 0.6029, 0.6118, 0.6104, 0.6295, 0.6081, 0.6072,
        0.6229, 0.6329, 0.6068, 0.6156, 0.6236, 0.6298, 0.6212],
       device='cuda:0') torch.Size([16])
percent tensor([0.5697, 0.5795, 0.7032, 0.7658, 0.6972, 0.7299, 0.5819, 0.5692, 0.6952,
        0.5905, 0.6439, 0.6683, 0.5906, 0.7433, 0.5408, 0.6543],
       device='cuda:0') torch.Size([16])
percent tensor([0.6482, 0.6140, 0.6938, 0.6899, 0.7068, 0.6508, 0.6761, 0.7027, 0.6660,
        0.6053, 0.6149, 0.6713, 0.5892, 0.6410, 0.6737, 0.6351],
       device='cuda:0') torch.Size([16])
percent tensor([0.5723, 0.5997, 0.7006, 0.6358, 0.7244, 0.6998, 0.5802, 0.5447, 0.6463,
        0.5532, 0.6399, 0.5236, 0.5795, 0.5948, 0.5329, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9998, 0.9995, 0.9992, 0.9997, 0.9998, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9997, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 125 | Batch_idx: 0 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (1324/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (2521/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (3703/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (4905/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (6073/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (7263/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (8441/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (92.00%) (9638/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (92.00%) (10832/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (92.00%) (12014/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (13221/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (14416/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (15604/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (16787/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (17994/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (19185/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (20377/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (21556/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (22749/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (23940/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (25131/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (26328/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (27534/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (28732/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (29917/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (31094/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (32288/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (33484/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (34655/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (35838/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (37022/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (38227/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (39419/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (40604/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (41794/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (92.00%) (42967/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (44187/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (45384/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (46553/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_125.pth.tar'
# TEST : Loss: (0.4238) | Acc: (87.00%) (8700/10000)
percent tensor([0.5636, 0.5631, 0.5647, 0.5625, 0.5764, 0.5696, 0.5683, 0.5686, 0.5629,
        0.5600, 0.5628, 0.5632, 0.5628, 0.5537, 0.5683, 0.5618],
       device='cuda:0') torch.Size([16])
percent tensor([0.5189, 0.5190, 0.5142, 0.5173, 0.5162, 0.5202, 0.5187, 0.5173, 0.5178,
        0.5177, 0.5177, 0.5168, 0.5189, 0.5169, 0.5202, 0.5188],
       device='cuda:0') torch.Size([16])
percent tensor([0.5139, 0.5326, 0.5460, 0.5412, 0.5732, 0.5576, 0.5404, 0.5337, 0.5512,
        0.5296, 0.5262, 0.5601, 0.5358, 0.5260, 0.5426, 0.5206],
       device='cuda:0') torch.Size([16])
percent tensor([0.6289, 0.6250, 0.6135, 0.6078, 0.6166, 0.6146, 0.6328, 0.6108, 0.6104,
        0.6246, 0.6355, 0.6131, 0.6170, 0.6268, 0.6321, 0.6233],
       device='cuda:0') torch.Size([16])
percent tensor([0.5704, 0.5705, 0.6922, 0.7566, 0.6831, 0.7288, 0.5844, 0.5600, 0.6885,
        0.5886, 0.6381, 0.6571, 0.5982, 0.7311, 0.5391, 0.6517],
       device='cuda:0') torch.Size([16])
percent tensor([0.6574, 0.6186, 0.7012, 0.6992, 0.7208, 0.6584, 0.6881, 0.7217, 0.6763,
        0.6121, 0.6210, 0.6808, 0.5917, 0.6586, 0.6858, 0.6413],
       device='cuda:0') torch.Size([16])
percent tensor([0.5530, 0.5698, 0.6567, 0.5875, 0.6852, 0.7013, 0.5462, 0.5117, 0.6408,
        0.5113, 0.6151, 0.4719, 0.5597, 0.5657, 0.5155, 0.5104],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9999, 0.9997, 0.9996, 0.9993, 0.9997, 0.9998, 0.9999,
        0.9997, 0.9999, 0.9997, 0.9996, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (92.00%) (1301/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (2500/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (3700/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (4900/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (6095/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (7286/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (8485/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (9685/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (10869/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (12067/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (13263/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (14469/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (15666/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (16861/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (18061/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (19251/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (20443/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (21650/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (22869/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (24071/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (25257/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (26466/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (27662/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (28861/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (30057/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (31257/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (32460/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (33673/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (34887/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (36083/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (37276/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (38474/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (39670/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (40870/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (42078/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (43295/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (44484/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (45691/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (46847/50000)
# TEST : Loss: (0.4113) | Acc: (87.00%) (8732/10000)
percent tensor([0.5614, 0.5603, 0.5631, 0.5610, 0.5745, 0.5680, 0.5657, 0.5664, 0.5607,
        0.5575, 0.5603, 0.5611, 0.5604, 0.5513, 0.5660, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.5192, 0.5146, 0.5180, 0.5166, 0.5210, 0.5188, 0.5177, 0.5179,
        0.5178, 0.5179, 0.5172, 0.5192, 0.5166, 0.5208, 0.5194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5161, 0.5365, 0.5473, 0.5451, 0.5745, 0.5619, 0.5417, 0.5318, 0.5549,
        0.5335, 0.5323, 0.5632, 0.5391, 0.5301, 0.5473, 0.5239],
       device='cuda:0') torch.Size([16])
percent tensor([0.6265, 0.6223, 0.6116, 0.6074, 0.6154, 0.6137, 0.6309, 0.6087, 0.6097,
        0.6221, 0.6344, 0.6120, 0.6144, 0.6258, 0.6308, 0.6211],
       device='cuda:0') torch.Size([16])
percent tensor([0.5568, 0.5549, 0.6850, 0.7539, 0.6766, 0.7291, 0.5738, 0.5536, 0.6790,
        0.5707, 0.6262, 0.6439, 0.5791, 0.7309, 0.5282, 0.6429],
       device='cuda:0') torch.Size([16])
percent tensor([0.6514, 0.6117, 0.6995, 0.6987, 0.7196, 0.6504, 0.6851, 0.7237, 0.6720,
        0.6072, 0.6138, 0.6820, 0.5805, 0.6548, 0.6846, 0.6334],
       device='cuda:0') torch.Size([16])
percent tensor([0.5492, 0.5727, 0.6533, 0.5853, 0.6865, 0.7051, 0.5397, 0.5024, 0.6362,
        0.5025, 0.6075, 0.4648, 0.5623, 0.5574, 0.5154, 0.5024],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9999, 0.9998, 0.9997, 0.9994, 0.9997, 0.9998, 0.9999,
        0.9997, 0.9999, 0.9998, 0.9996, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 127 | Batch_idx: 0 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (2538/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (3757/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (4965/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (6160/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (7378/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (8590/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (9782/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (10985/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (12192/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (13408/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (14619/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (15834/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (17034/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (18231/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (19425/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (20618/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (21812/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (23021/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (24242/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (25447/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (26655/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (27868/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (29068/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (30282/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (31484/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (32715/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (33923/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (35131/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (36339/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (37557/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (38778/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (39982/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (41193/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (42402/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (43628/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (44814/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (46018/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (47175/50000)
# TEST : Loss: (0.4032) | Acc: (87.00%) (8758/10000)
percent tensor([0.5626, 0.5614, 0.5651, 0.5628, 0.5765, 0.5695, 0.5671, 0.5681, 0.5617,
        0.5588, 0.5612, 0.5628, 0.5615, 0.5522, 0.5673, 0.5610],
       device='cuda:0') torch.Size([16])
percent tensor([0.5205, 0.5205, 0.5159, 0.5194, 0.5178, 0.5222, 0.5203, 0.5192, 0.5188,
        0.5192, 0.5190, 0.5187, 0.5206, 0.5175, 0.5223, 0.5210],
       device='cuda:0') torch.Size([16])
percent tensor([0.5157, 0.5395, 0.5456, 0.5435, 0.5724, 0.5592, 0.5422, 0.5288, 0.5548,
        0.5366, 0.5354, 0.5637, 0.5414, 0.5303, 0.5477, 0.5234],
       device='cuda:0') torch.Size([16])
percent tensor([0.6273, 0.6229, 0.6129, 0.6095, 0.6167, 0.6155, 0.6326, 0.6098, 0.6118,
        0.6228, 0.6361, 0.6139, 0.6149, 0.6281, 0.6325, 0.6218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5663, 0.5569, 0.6992, 0.7665, 0.6892, 0.7395, 0.5845, 0.5657, 0.6926,
        0.5796, 0.6370, 0.6570, 0.5863, 0.7446, 0.5337, 0.6544],
       device='cuda:0') torch.Size([16])
percent tensor([0.6488, 0.6096, 0.6993, 0.7010, 0.7208, 0.6464, 0.6865, 0.7271, 0.6715,
        0.6086, 0.6132, 0.6866, 0.5753, 0.6539, 0.6871, 0.6306],
       device='cuda:0') torch.Size([16])
percent tensor([0.5588, 0.5870, 0.6648, 0.5991, 0.6977, 0.7171, 0.5438, 0.5086, 0.6444,
        0.5131, 0.6221, 0.4688, 0.5731, 0.5689, 0.5266, 0.5038],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9998, 0.9996, 0.9994, 0.9997, 0.9998, 0.9999,
        0.9997, 0.9999, 0.9998, 0.9996, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 128 | Batch_idx: 0 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (2548/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (3763/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (4980/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (6201/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (7391/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (8608/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (9808/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (11015/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (12234/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (13442/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (14624/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (15831/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (17045/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (18256/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (19460/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (20658/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (21864/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (23076/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (24289/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (25500/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (26704/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (27915/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (29138/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (30348/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (31564/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (32766/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (33978/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (35199/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (36411/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (37638/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (38848/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (40056/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (41263/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (42480/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (43687/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (44891/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (46107/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (47280/50000)
# TEST : Loss: (0.3941) | Acc: (87.00%) (8786/10000)
percent tensor([0.5602, 0.5584, 0.5635, 0.5609, 0.5747, 0.5674, 0.5645, 0.5659, 0.5595,
        0.5563, 0.5584, 0.5609, 0.5588, 0.5497, 0.5646, 0.5585],
       device='cuda:0') torch.Size([16])
percent tensor([0.5209, 0.5209, 0.5165, 0.5201, 0.5184, 0.5228, 0.5207, 0.5199, 0.5191,
        0.5195, 0.5193, 0.5192, 0.5211, 0.5175, 0.5229, 0.5216],
       device='cuda:0') torch.Size([16])
percent tensor([0.5161, 0.5414, 0.5442, 0.5438, 0.5714, 0.5586, 0.5431, 0.5263, 0.5560,
        0.5380, 0.5380, 0.5640, 0.5429, 0.5315, 0.5483, 0.5237],
       device='cuda:0') torch.Size([16])
percent tensor([0.6332, 0.6291, 0.6187, 0.6159, 0.6228, 0.6220, 0.6395, 0.6162, 0.6186,
        0.6292, 0.6437, 0.6210, 0.6208, 0.6357, 0.6397, 0.6279],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5495, 0.6938, 0.7608, 0.6848, 0.7371, 0.5767, 0.5622, 0.6873,
        0.5703, 0.6276, 0.6478, 0.5771, 0.7376, 0.5285, 0.6451],
       device='cuda:0') torch.Size([16])
percent tensor([0.6535, 0.6126, 0.7066, 0.7078, 0.7269, 0.6493, 0.6925, 0.7355, 0.6772,
        0.6133, 0.6172, 0.6951, 0.5764, 0.6590, 0.6946, 0.6342],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.6006, 0.6690, 0.5983, 0.7011, 0.7233, 0.5485, 0.5051, 0.6559,
        0.5193, 0.6299, 0.4751, 0.5869, 0.5783, 0.5310, 0.5034],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9997, 0.9996, 0.9994, 0.9998, 0.9998, 0.9999,
        0.9997, 0.9999, 0.9998, 0.9996, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 129 | Batch_idx: 0 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (3752/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (4958/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (6176/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (7379/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (8588/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (9791/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (10994/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (12210/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (13433/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (14641/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (15846/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (17054/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (18262/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (19466/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (20678/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (21898/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (23103/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (24318/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (25530/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (26736/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (27962/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (29170/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (30396/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (31609/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (32822/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (34030/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (35234/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (36443/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (37658/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (38879/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (40095/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (41310/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (42525/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (43736/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (44949/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (46151/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (47314/50000)
# TEST : Loss: (0.3923) | Acc: (87.00%) (8796/10000)
percent tensor([0.5583, 0.5559, 0.5619, 0.5592, 0.5728, 0.5657, 0.5622, 0.5639, 0.5575,
        0.5541, 0.5562, 0.5589, 0.5566, 0.5475, 0.5624, 0.5565],
       device='cuda:0') torch.Size([16])
percent tensor([0.5223, 0.5220, 0.5179, 0.5215, 0.5197, 0.5242, 0.5219, 0.5213, 0.5203,
        0.5207, 0.5204, 0.5207, 0.5224, 0.5184, 0.5243, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.5179, 0.5432, 0.5444, 0.5458, 0.5717, 0.5602, 0.5431, 0.5248, 0.5570,
        0.5400, 0.5408, 0.5645, 0.5454, 0.5322, 0.5506, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.6345, 0.6304, 0.6198, 0.6174, 0.6242, 0.6242, 0.6411, 0.6170, 0.6208,
        0.6300, 0.6457, 0.6226, 0.6222, 0.6379, 0.6417, 0.6293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5612, 0.5494, 0.7024, 0.7681, 0.6938, 0.7423, 0.5851, 0.5693, 0.6931,
        0.5702, 0.6306, 0.6538, 0.5778, 0.7461, 0.5293, 0.6505],
       device='cuda:0') torch.Size([16])
percent tensor([0.6560, 0.6162, 0.7096, 0.7123, 0.7293, 0.6502, 0.6966, 0.7392, 0.6805,
        0.6192, 0.6205, 0.7009, 0.5783, 0.6621, 0.6998, 0.6370],
       device='cuda:0') torch.Size([16])
percent tensor([0.5705, 0.6078, 0.6766, 0.6052, 0.7086, 0.7311, 0.5454, 0.5070, 0.6566,
        0.5237, 0.6328, 0.4745, 0.5893, 0.5765, 0.5360, 0.5066],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9998, 0.9997, 0.9994, 0.9997, 0.9998, 0.9999,
        0.9997, 0.9999, 0.9998, 0.9996, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 130 | Batch_idx: 0 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (95.00%) (3776/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (4992/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (95.00%) (6202/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (7424/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (8633/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (9845/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (11064/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (95.00%) (12282/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (95.00%) (13507/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (95.00%) (14724/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (15928/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (95.00%) (17148/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (95.00%) (18362/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (95.00%) (19581/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (20790/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (21988/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (23197/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (24407/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (25616/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (26812/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (28011/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (29223/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (30425/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (31651/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (32857/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (34063/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (35264/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (36466/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (37663/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (38862/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (40067/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (41281/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (42488/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (43696/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (44909/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (46125/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (47287/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_130.pth.tar'
# TEST : Loss: (0.4180) | Acc: (87.00%) (8775/10000)
percent tensor([0.5585, 0.5555, 0.5652, 0.5609, 0.5754, 0.5660, 0.5632, 0.5652, 0.5578,
        0.5550, 0.5561, 0.5608, 0.5567, 0.5465, 0.5626, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.5221, 0.5221, 0.5183, 0.5222, 0.5200, 0.5244, 0.5223, 0.5217, 0.5211,
        0.5213, 0.5208, 0.5214, 0.5228, 0.5194, 0.5245, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.5200, 0.5396, 0.5471, 0.5390, 0.5745, 0.5573, 0.5465, 0.5295, 0.5562,
        0.5436, 0.5452, 0.5677, 0.5485, 0.5343, 0.5482, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.6357, 0.6342, 0.6175, 0.6197, 0.6210, 0.6266, 0.6412, 0.6184, 0.6249,
        0.6311, 0.6466, 0.6198, 0.6220, 0.6378, 0.6431, 0.6325],
       device='cuda:0') torch.Size([16])
percent tensor([0.5521, 0.5542, 0.6921, 0.7650, 0.6877, 0.7352, 0.5720, 0.5466, 0.6737,
        0.5790, 0.6231, 0.6850, 0.5699, 0.7510, 0.5275, 0.6410],
       device='cuda:0') torch.Size([16])
percent tensor([0.6605, 0.6262, 0.7224, 0.7211, 0.7317, 0.6505, 0.7038, 0.7387, 0.6745,
        0.6290, 0.6234, 0.7229, 0.5815, 0.6605, 0.7076, 0.6448],
       device='cuda:0') torch.Size([16])
percent tensor([0.5887, 0.5878, 0.6761, 0.5975, 0.6979, 0.7331, 0.5673, 0.5306, 0.6241,
        0.5668, 0.6351, 0.5010, 0.5609, 0.6266, 0.5256, 0.4988],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9999, 0.9998, 0.9996, 0.9992, 0.9998, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9992, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.9111, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(825.2410, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(826.3660, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1517.6647, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(491.1290, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2248.2268, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4280.0308, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1372.5594, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6179.9111, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11742.9502, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3883.4619, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16446.7422, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (2541/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (3743/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (4946/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (6155/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (7373/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (8588/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (9800/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (11000/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (12200/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (13400/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (14632/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (15858/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (17064/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (18281/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (19498/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (20700/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (21910/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (23118/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (24327/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (25548/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (26778/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (27992/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (29207/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (30417/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (31637/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (32829/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (34040/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (35243/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (36455/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (37661/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (38868/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (40082/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (41305/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (42498/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (43697/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (44904/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (46106/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (47277/50000)
# TEST : Loss: (0.4374) | Acc: (86.00%) (8654/10000)
percent tensor([0.5578, 0.5557, 0.5640, 0.5597, 0.5740, 0.5650, 0.5628, 0.5648, 0.5570,
        0.5546, 0.5556, 0.5601, 0.5559, 0.5469, 0.5619, 0.5565],
       device='cuda:0') torch.Size([16])
percent tensor([0.5216, 0.5223, 0.5183, 0.5214, 0.5196, 0.5226, 0.5221, 0.5219, 0.5211,
        0.5211, 0.5204, 0.5215, 0.5228, 0.5188, 0.5237, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.5180, 0.5351, 0.5448, 0.5422, 0.5710, 0.5593, 0.5387, 0.5248, 0.5558,
        0.5369, 0.5411, 0.5630, 0.5463, 0.5260, 0.5455, 0.5252],
       device='cuda:0') torch.Size([16])
percent tensor([0.6357, 0.6311, 0.6200, 0.6207, 0.6212, 0.6273, 0.6410, 0.6181, 0.6221,
        0.6288, 0.6468, 0.6169, 0.6209, 0.6400, 0.6417, 0.6319],
       device='cuda:0') torch.Size([16])
percent tensor([0.5570, 0.5581, 0.6890, 0.7626, 0.6863, 0.7321, 0.5787, 0.5433, 0.6684,
        0.5802, 0.6399, 0.6669, 0.5779, 0.7408, 0.5340, 0.6523],
       device='cuda:0') torch.Size([16])
percent tensor([0.6455, 0.5986, 0.7115, 0.7298, 0.7270, 0.6350, 0.6863, 0.7242, 0.6644,
        0.6051, 0.6119, 0.6980, 0.5650, 0.6522, 0.6831, 0.6277],
       device='cuda:0') torch.Size([16])
percent tensor([0.5635, 0.5817, 0.7010, 0.5974, 0.7306, 0.7455, 0.5899, 0.5260, 0.6171,
        0.5498, 0.5968, 0.4995, 0.5468, 0.5901, 0.5272, 0.4909],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9998, 0.9996, 0.9994, 0.9998, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9997, 0.9996, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 132 | Batch_idx: 0 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (2569/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (3783/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (4996/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (6215/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (7439/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (8655/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (9872/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (11072/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (95.00%) (12294/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (95.00%) (13511/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (95.00%) (14724/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (95.00%) (15936/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (95.00%) (17150/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (95.00%) (18372/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (95.00%) (19581/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (20791/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (95.00%) (22011/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (23222/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (95.00%) (24452/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (95.00%) (25663/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (26869/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (95.00%) (28090/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (29297/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (30512/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (31723/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (32939/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (34161/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (35374/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (36596/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (37813/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (39016/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (40234/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (41448/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (42652/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (43868/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (45089/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (46301/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (47472/50000)
# TEST : Loss: (0.4287) | Acc: (87.00%) (8708/10000)
percent tensor([0.5582, 0.5565, 0.5639, 0.5605, 0.5740, 0.5654, 0.5633, 0.5647, 0.5569,
        0.5553, 0.5559, 0.5605, 0.5565, 0.5475, 0.5623, 0.5567],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.5220, 0.5187, 0.5213, 0.5205, 0.5239, 0.5223, 0.5219, 0.5216,
        0.5212, 0.5210, 0.5215, 0.5230, 0.5191, 0.5241, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.5161, 0.5362, 0.5522, 0.5471, 0.5756, 0.5544, 0.5424, 0.5314, 0.5572,
        0.5392, 0.5397, 0.5697, 0.5447, 0.5281, 0.5422, 0.5237],
       device='cuda:0') torch.Size([16])
percent tensor([0.6326, 0.6332, 0.6131, 0.6164, 0.6185, 0.6227, 0.6391, 0.6185, 0.6170,
        0.6280, 0.6466, 0.6134, 0.6191, 0.6404, 0.6429, 0.6298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5506, 0.5444, 0.6748, 0.7392, 0.6734, 0.7250, 0.5619, 0.5529, 0.6889,
        0.5617, 0.6246, 0.6338, 0.5627, 0.7453, 0.5234, 0.6327],
       device='cuda:0') torch.Size([16])
percent tensor([0.6642, 0.6278, 0.7145, 0.7222, 0.7243, 0.6601, 0.7000, 0.7328, 0.6780,
        0.6331, 0.6340, 0.7166, 0.5810, 0.6649, 0.7092, 0.6493],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5754, 0.6569, 0.5503, 0.6597, 0.7285, 0.5650, 0.4969, 0.5883,
        0.5302, 0.6054, 0.4594, 0.5610, 0.5465, 0.4921, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9999, 0.9998, 0.9997, 0.9994, 0.9998, 0.9998, 0.9997,
        0.9998, 0.9999, 0.9999, 0.9995, 0.9996, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 133 | Batch_idx: 0 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (2555/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (3780/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (6209/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (7435/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (8648/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (9872/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (11082/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (12300/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (13503/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (14714/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (15923/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (17134/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (18335/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (19544/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (20768/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (21974/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (23200/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (24404/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (25633/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (26844/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (28060/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (29280/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (30502/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (31715/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (32935/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (34143/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (35366/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (36581/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (37775/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (39000/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (40221/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (41398/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (42596/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (43816/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (45022/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (46220/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (47392/50000)
# TEST : Loss: (0.4385) | Acc: (86.00%) (8697/10000)
percent tensor([0.5577, 0.5565, 0.5626, 0.5592, 0.5740, 0.5652, 0.5634, 0.5635, 0.5576,
        0.5550, 0.5559, 0.5594, 0.5560, 0.5488, 0.5619, 0.5570],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5224, 0.5182, 0.5213, 0.5198, 0.5238, 0.5223, 0.5213, 0.5212,
        0.5213, 0.5209, 0.5212, 0.5229, 0.5190, 0.5244, 0.5233],
       device='cuda:0') torch.Size([16])
percent tensor([0.5210, 0.5406, 0.5476, 0.5468, 0.5766, 0.5603, 0.5467, 0.5335, 0.5601,
        0.5439, 0.5438, 0.5694, 0.5494, 0.5356, 0.5493, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.6373, 0.6348, 0.6184, 0.6228, 0.6208, 0.6271, 0.6418, 0.6208, 0.6224,
        0.6320, 0.6483, 0.6194, 0.6240, 0.6404, 0.6453, 0.6347],
       device='cuda:0') torch.Size([16])
percent tensor([0.5636, 0.5673, 0.7026, 0.7658, 0.7011, 0.7437, 0.5768, 0.5693, 0.7007,
        0.5777, 0.6523, 0.6653, 0.5813, 0.7494, 0.5380, 0.6585],
       device='cuda:0') torch.Size([16])
percent tensor([0.6627, 0.6300, 0.7247, 0.7258, 0.7337, 0.6466, 0.7016, 0.7471, 0.6835,
        0.6354, 0.6320, 0.7181, 0.5870, 0.6643, 0.7089, 0.6452],
       device='cuda:0') torch.Size([16])
percent tensor([0.5834, 0.6288, 0.6620, 0.5847, 0.7017, 0.7395, 0.5816, 0.5567, 0.6159,
        0.5467, 0.6356, 0.4862, 0.5815, 0.5758, 0.5034, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9997, 0.9996, 0.9993, 0.9996, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9996, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (1331/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (3763/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (4971/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (6180/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (7394/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (8606/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (9828/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (11051/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (12266/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (13474/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (14693/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (15897/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (17112/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (18326/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (19548/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (20761/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (21983/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (23191/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (24411/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (25613/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (26818/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (28046/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (29252/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (30457/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (31674/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (32900/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (34123/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (35342/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (36559/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (37795/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (39012/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (40223/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (41449/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (42660/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (43877/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (45082/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (46297/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (47447/50000)
# TEST : Loss: (0.4782) | Acc: (86.00%) (8604/10000)
percent tensor([0.5578, 0.5562, 0.5630, 0.5605, 0.5733, 0.5653, 0.5626, 0.5641, 0.5565,
        0.5546, 0.5553, 0.5599, 0.5558, 0.5473, 0.5622, 0.5568],
       device='cuda:0') torch.Size([16])
percent tensor([0.5230, 0.5233, 0.5185, 0.5220, 0.5197, 0.5245, 0.5228, 0.5220, 0.5218,
        0.5220, 0.5216, 0.5216, 0.5236, 0.5202, 0.5251, 0.5239],
       device='cuda:0') torch.Size([16])
percent tensor([0.5225, 0.5419, 0.5491, 0.5478, 0.5795, 0.5675, 0.5512, 0.5275, 0.5637,
        0.5443, 0.5515, 0.5700, 0.5502, 0.5422, 0.5512, 0.5321],
       device='cuda:0') torch.Size([16])
percent tensor([0.6340, 0.6308, 0.6151, 0.6194, 0.6196, 0.6254, 0.6390, 0.6150, 0.6178,
        0.6280, 0.6449, 0.6173, 0.6210, 0.6359, 0.6422, 0.6318],
       device='cuda:0') torch.Size([16])
percent tensor([0.5676, 0.5593, 0.7000, 0.7689, 0.7066, 0.7375, 0.5836, 0.5623, 0.7066,
        0.5878, 0.6327, 0.6704, 0.5890, 0.7535, 0.5386, 0.6470],
       device='cuda:0') torch.Size([16])
percent tensor([0.6516, 0.6151, 0.7036, 0.7205, 0.7180, 0.6410, 0.6922, 0.7314, 0.6583,
        0.6203, 0.6096, 0.7026, 0.5721, 0.6550, 0.6940, 0.6376],
       device='cuda:0') torch.Size([16])
percent tensor([0.5482, 0.6013, 0.6886, 0.5701, 0.7161, 0.6909, 0.6023, 0.5637, 0.6350,
        0.5790, 0.6285, 0.5051, 0.5821, 0.6204, 0.5252, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9996, 0.9996, 0.9991, 0.9998, 0.9998, 0.9997,
        0.9998, 0.9999, 0.9999, 0.9996, 0.9996, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (2510/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (3693/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (4890/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (6073/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (7267/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (8468/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (9662/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (10864/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (12059/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (13261/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (14459/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (15655/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (16857/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (18050/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (19248/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (20442/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (21648/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (22856/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (24057/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (25269/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (26470/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (27675/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (28868/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (30065/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (31277/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (32478/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (33689/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (34906/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (36115/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (37318/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (38511/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (39718/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (40931/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (42130/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (43346/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (44553/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (93.00%) (45745/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (46911/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_135.pth.tar'
# TEST : Loss: (0.4249) | Acc: (86.00%) (8698/10000)
percent tensor([0.5556, 0.5545, 0.5625, 0.5578, 0.5715, 0.5616, 0.5612, 0.5621, 0.5546,
        0.5533, 0.5533, 0.5597, 0.5535, 0.5456, 0.5592, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.5236, 0.5180, 0.5214, 0.5191, 0.5229, 0.5233, 0.5215, 0.5213,
        0.5220, 0.5214, 0.5213, 0.5230, 0.5203, 0.5245, 0.5231],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.5242, 0.5411, 0.5374, 0.5682, 0.5557, 0.5361, 0.5206, 0.5449,
        0.5257, 0.5273, 0.5523, 0.5281, 0.5246, 0.5324, 0.5149],
       device='cuda:0') torch.Size([16])
percent tensor([0.6344, 0.6332, 0.6106, 0.6188, 0.6161, 0.6242, 0.6376, 0.6108, 0.6207,
        0.6314, 0.6505, 0.6186, 0.6262, 0.6395, 0.6434, 0.6330],
       device='cuda:0') torch.Size([16])
percent tensor([0.5781, 0.5907, 0.6902, 0.7595, 0.6938, 0.7295, 0.5927, 0.5532, 0.7263,
        0.6209, 0.6732, 0.6763, 0.6200, 0.7875, 0.5483, 0.6564],
       device='cuda:0') torch.Size([16])
percent tensor([0.6827, 0.6413, 0.7296, 0.7361, 0.7368, 0.6724, 0.7063, 0.7499, 0.6758,
        0.6489, 0.6361, 0.7324, 0.6061, 0.6712, 0.7207, 0.6626],
       device='cuda:0') torch.Size([16])
percent tensor([0.5781, 0.5822, 0.6878, 0.5510, 0.7238, 0.7436, 0.6128, 0.5383, 0.6266,
        0.5678, 0.6361, 0.4834, 0.5862, 0.6397, 0.5142, 0.5264],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9997, 0.9996, 0.9992, 0.9998, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9996, 0.9996, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 136 | Batch_idx: 0 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (3749/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (4953/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (6170/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (7373/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (8598/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (9796/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (10999/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (12197/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (13406/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (14613/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (15836/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (17054/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (18261/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (19459/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (20668/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (21874/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (23083/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (24295/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (25507/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (26722/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (27929/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (29148/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (30350/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (31573/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (32783/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (33991/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (35210/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (36431/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (37644/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (38840/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (40043/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (41249/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (42451/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (43663/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (44872/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (46097/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (47244/50000)
# TEST : Loss: (0.4105) | Acc: (87.00%) (8742/10000)
percent tensor([0.5533, 0.5523, 0.5598, 0.5552, 0.5684, 0.5587, 0.5587, 0.5596, 0.5524,
        0.5511, 0.5511, 0.5573, 0.5513, 0.5437, 0.5565, 0.5518],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5236, 0.5179, 0.5210, 0.5188, 0.5223, 0.5232, 0.5212, 0.5212,
        0.5220, 0.5214, 0.5213, 0.5230, 0.5203, 0.5243, 0.5228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5084, 0.5212, 0.5465, 0.5414, 0.5733, 0.5584, 0.5354, 0.5237, 0.5448,
        0.5244, 0.5242, 0.5556, 0.5249, 0.5217, 0.5327, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.6301, 0.6313, 0.6050, 0.6145, 0.6108, 0.6193, 0.6340, 0.6052, 0.6181,
        0.6304, 0.6492, 0.6154, 0.6238, 0.6380, 0.6389, 0.6294],
       device='cuda:0') torch.Size([16])
percent tensor([0.5835, 0.6001, 0.6982, 0.7672, 0.6976, 0.7373, 0.5962, 0.5606, 0.7345,
        0.6183, 0.6796, 0.6796, 0.6260, 0.7965, 0.5548, 0.6584],
       device='cuda:0') torch.Size([16])
percent tensor([0.6938, 0.6507, 0.7402, 0.7513, 0.7498, 0.6829, 0.7194, 0.7660, 0.6862,
        0.6596, 0.6426, 0.7451, 0.6132, 0.6833, 0.7332, 0.6758],
       device='cuda:0') torch.Size([16])
percent tensor([0.6048, 0.5966, 0.7012, 0.5658, 0.7365, 0.7646, 0.6323, 0.5548, 0.6420,
        0.5805, 0.6547, 0.4925, 0.5992, 0.6485, 0.5361, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9997, 0.9996, 0.9991, 0.9998, 0.9999, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9996, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 137 | Batch_idx: 0 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (3767/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (4977/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (6186/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (7402/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (8614/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (9830/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (11045/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (12251/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (13484/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (14686/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (15886/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (17101/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (18318/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (19533/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (20745/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (21957/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (23168/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (24382/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (25611/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (26826/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (28046/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (29263/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (30464/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (31686/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (32902/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (34125/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (35334/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (36554/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (37762/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (38958/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (40168/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (41384/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (42585/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (43808/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (45026/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (46243/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (47398/50000)
# TEST : Loss: (0.4013) | Acc: (87.00%) (8767/10000)
percent tensor([0.5569, 0.5570, 0.5636, 0.5587, 0.5726, 0.5616, 0.5633, 0.5639, 0.5565,
        0.5555, 0.5552, 0.5616, 0.5555, 0.5476, 0.5604, 0.5554],
       device='cuda:0') torch.Size([16])
percent tensor([0.5215, 0.5230, 0.5170, 0.5202, 0.5179, 0.5215, 0.5224, 0.5202, 0.5205,
        0.5213, 0.5207, 0.5204, 0.5224, 0.5198, 0.5235, 0.5222],
       device='cuda:0') torch.Size([16])
percent tensor([0.5109, 0.5236, 0.5455, 0.5412, 0.5716, 0.5591, 0.5361, 0.5230, 0.5455,
        0.5259, 0.5265, 0.5552, 0.5281, 0.5234, 0.5340, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.6318, 0.6345, 0.6051, 0.6157, 0.6114, 0.6211, 0.6355, 0.6042, 0.6210,
        0.6346, 0.6544, 0.6167, 0.6268, 0.6421, 0.6411, 0.6322],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5875, 0.6875, 0.7618, 0.6858, 0.7289, 0.5806, 0.5518, 0.7258,
        0.6001, 0.6709, 0.6691, 0.6069, 0.7941, 0.5437, 0.6403],
       device='cuda:0') torch.Size([16])
percent tensor([0.6966, 0.6511, 0.7442, 0.7571, 0.7545, 0.6882, 0.7212, 0.7703, 0.6876,
        0.6610, 0.6429, 0.7494, 0.6150, 0.6854, 0.7359, 0.6799],
       device='cuda:0') torch.Size([16])
percent tensor([0.5990, 0.5801, 0.7074, 0.5623, 0.7395, 0.7754, 0.6259, 0.5401, 0.6218,
        0.5636, 0.6371, 0.4768, 0.5881, 0.6359, 0.5264, 0.5586],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9997, 0.9996, 0.9992, 0.9998, 0.9999, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9996, 0.9996, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (2554/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (3765/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (4979/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (6205/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (7424/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (8630/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (9857/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (11080/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (12312/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (13531/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (14741/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (15949/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (17175/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (18403/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (19632/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (20863/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (22076/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (23300/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (24497/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (25712/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (26923/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (28136/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (29361/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (30579/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (31810/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (33021/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (34240/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (35458/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (36683/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (37891/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (39112/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (40336/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (41551/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (42769/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (43987/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (45192/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (46417/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (47591/50000)
# TEST : Loss: (0.3976) | Acc: (87.00%) (8789/10000)
percent tensor([0.5554, 0.5558, 0.5617, 0.5571, 0.5704, 0.5597, 0.5618, 0.5623, 0.5552,
        0.5543, 0.5540, 0.5600, 0.5543, 0.5467, 0.5589, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.5221, 0.5238, 0.5174, 0.5207, 0.5183, 0.5220, 0.5232, 0.5207, 0.5211,
        0.5220, 0.5214, 0.5210, 0.5231, 0.5205, 0.5242, 0.5228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5121, 0.5238, 0.5500, 0.5463, 0.5766, 0.5629, 0.5387, 0.5276, 0.5490,
        0.5282, 0.5287, 0.5596, 0.5294, 0.5257, 0.5375, 0.5194],
       device='cuda:0') torch.Size([16])
percent tensor([0.6325, 0.6369, 0.6049, 0.6165, 0.6113, 0.6218, 0.6367, 0.6034, 0.6223,
        0.6378, 0.6575, 0.6177, 0.6286, 0.6448, 0.6423, 0.6340],
       device='cuda:0') torch.Size([16])
percent tensor([0.5756, 0.5982, 0.6976, 0.7706, 0.6930, 0.7363, 0.5906, 0.5605, 0.7371,
        0.6089, 0.6851, 0.6801, 0.6174, 0.8055, 0.5527, 0.6478],
       device='cuda:0') torch.Size([16])
percent tensor([0.6961, 0.6500, 0.7442, 0.7592, 0.7554, 0.6883, 0.7215, 0.7711, 0.6870,
        0.6596, 0.6411, 0.7506, 0.6136, 0.6838, 0.7369, 0.6798],
       device='cuda:0') torch.Size([16])
percent tensor([0.5907, 0.5709, 0.7130, 0.5687, 0.7470, 0.7800, 0.6171, 0.5469, 0.6098,
        0.5448, 0.6259, 0.4720, 0.5698, 0.6211, 0.5324, 0.5586],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9997, 0.9997, 0.9992, 0.9998, 0.9999, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9996, 0.9996, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 139 | Batch_idx: 0 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (2572/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (3783/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (4994/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (6220/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (7435/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (8642/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (9854/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (11076/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (95.00%) (12296/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (13521/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (14736/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (15962/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (17186/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (18407/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (19631/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (20850/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (22071/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (23279/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (24493/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (25714/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (26937/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (28147/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (29358/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (30560/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (31774/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (32996/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (34221/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (35449/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (36665/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (37889/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (39108/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (40327/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (41552/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (42763/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (43980/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (45201/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (46431/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (47607/50000)
# TEST : Loss: (0.3928) | Acc: (87.00%) (8794/10000)
percent tensor([0.5538, 0.5544, 0.5599, 0.5555, 0.5685, 0.5577, 0.5602, 0.5606, 0.5537,
        0.5529, 0.5525, 0.5584, 0.5528, 0.5455, 0.5572, 0.5525],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5242, 0.5174, 0.5208, 0.5184, 0.5220, 0.5234, 0.5208, 0.5213,
        0.5222, 0.5217, 0.5211, 0.5235, 0.5207, 0.5244, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.5122, 0.5236, 0.5501, 0.5457, 0.5759, 0.5621, 0.5377, 0.5274, 0.5478,
        0.5274, 0.5269, 0.5588, 0.5289, 0.5248, 0.5361, 0.5192],
       device='cuda:0') torch.Size([16])
percent tensor([0.6360, 0.6418, 0.6064, 0.6194, 0.6134, 0.6254, 0.6403, 0.6049, 0.6261,
        0.6431, 0.6635, 0.6208, 0.6331, 0.6502, 0.6462, 0.6385],
       device='cuda:0') torch.Size([16])
percent tensor([0.5659, 0.5895, 0.6923, 0.7663, 0.6887, 0.7344, 0.5830, 0.5536, 0.7328,
        0.5975, 0.6790, 0.6691, 0.6068, 0.8043, 0.5447, 0.6397],
       device='cuda:0') torch.Size([16])
percent tensor([0.6843, 0.6350, 0.7368, 0.7520, 0.7485, 0.6787, 0.7103, 0.7634, 0.6750,
        0.6454, 0.6260, 0.7405, 0.5992, 0.6711, 0.7256, 0.6675],
       device='cuda:0') torch.Size([16])
percent tensor([0.5965, 0.5765, 0.7209, 0.5785, 0.7557, 0.7869, 0.6251, 0.5548, 0.6102,
        0.5480, 0.6203, 0.4779, 0.5692, 0.6138, 0.5449, 0.5670],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9998, 0.9997, 0.9991, 0.9998, 0.9999, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9995, 0.9996, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 140 | Batch_idx: 0 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (2574/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (3791/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (5017/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (6237/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (7463/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (8683/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (9890/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (11100/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (12332/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (13555/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (14767/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (15970/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (17185/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (18405/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (19614/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (95.00%) (20828/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (22041/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (23249/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (95.00%) (24465/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (25668/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (95.00%) (26877/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (95.00%) (28097/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (95.00%) (29320/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (95.00%) (30532/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (31743/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (32963/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (95.00%) (34184/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (35412/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (36620/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (95.00%) (37830/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (39048/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (40263/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (41473/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (95.00%) (42695/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (43917/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (45127/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (95.00%) (46348/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (95.00%) (47517/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_140.pth.tar'
# TEST : Loss: (0.4469) | Acc: (86.00%) (8689/10000)
percent tensor([0.5525, 0.5544, 0.5548, 0.5532, 0.5647, 0.5563, 0.5588, 0.5601, 0.5536,
        0.5519, 0.5523, 0.5541, 0.5530, 0.5469, 0.5567, 0.5519],
       device='cuda:0') torch.Size([16])
percent tensor([0.5218, 0.5223, 0.5179, 0.5208, 0.5188, 0.5222, 0.5221, 0.5209, 0.5211,
        0.5215, 0.5208, 0.5212, 0.5236, 0.5191, 0.5235, 0.5225],
       device='cuda:0') torch.Size([16])
percent tensor([0.5118, 0.5206, 0.5446, 0.5456, 0.5721, 0.5569, 0.5323, 0.5295, 0.5466,
        0.5244, 0.5231, 0.5549, 0.5306, 0.5254, 0.5363, 0.5183],
       device='cuda:0') torch.Size([16])
percent tensor([0.6417, 0.6426, 0.6200, 0.6237, 0.6244, 0.6300, 0.6407, 0.6071, 0.6222,
        0.6446, 0.6636, 0.6272, 0.6306, 0.6432, 0.6478, 0.6402],
       device='cuda:0') torch.Size([16])
percent tensor([0.5727, 0.5854, 0.7094, 0.7789, 0.7089, 0.7566, 0.5922, 0.5622, 0.7409,
        0.6016, 0.6977, 0.6752, 0.6072, 0.7830, 0.5444, 0.6433],
       device='cuda:0') torch.Size([16])
percent tensor([0.6825, 0.6313, 0.7286, 0.7643, 0.7558, 0.6785, 0.7264, 0.7651, 0.7046,
        0.6392, 0.6375, 0.7383, 0.6084, 0.6859, 0.7213, 0.6701],
       device='cuda:0') torch.Size([16])
percent tensor([0.5844, 0.5742, 0.6815, 0.5744, 0.7374, 0.7805, 0.6360, 0.5923, 0.6042,
        0.5304, 0.5945, 0.4698, 0.5549, 0.5580, 0.5304, 0.5437],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9997, 0.9998, 0.9988, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(183.2756, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(827.2874, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.9340, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1516.2972, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(489.4352, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2253.7776, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4278.5938, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1367.7775, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6192.8003, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11708.5352, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3868.4773, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16381.1367, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 141 | Batch_idx: 0 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (96.00%) (2582/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (3805/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (5031/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (6251/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (7463/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (8688/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (9910/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (11136/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (12364/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (13580/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (14805/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (16018/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (17248/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (18468/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (19687/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (20904/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (22110/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (23329/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (24543/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (25755/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (26985/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (28192/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (29416/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (30646/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (31870/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (33099/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (34313/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (35534/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (36745/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (37955/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (39172/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (40383/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (41598/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (42818/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (44023/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (45237/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (46443/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (47606/50000)
# TEST : Loss: (0.4510) | Acc: (86.00%) (8685/10000)
percent tensor([0.5531, 0.5543, 0.5576, 0.5547, 0.5665, 0.5575, 0.5598, 0.5607, 0.5549,
        0.5529, 0.5530, 0.5562, 0.5534, 0.5468, 0.5569, 0.5529],
       device='cuda:0') torch.Size([16])
percent tensor([0.5220, 0.5236, 0.5181, 0.5213, 0.5194, 0.5219, 0.5232, 0.5216, 0.5219,
        0.5221, 0.5213, 0.5209, 0.5237, 0.5203, 0.5239, 0.5233],
       device='cuda:0') torch.Size([16])
percent tensor([0.5123, 0.5240, 0.5544, 0.5493, 0.5772, 0.5563, 0.5389, 0.5360, 0.5514,
        0.5303, 0.5264, 0.5608, 0.5313, 0.5294, 0.5372, 0.5187],
       device='cuda:0') torch.Size([16])
percent tensor([0.6405, 0.6412, 0.6142, 0.6201, 0.6198, 0.6295, 0.6392, 0.6080, 0.6253,
        0.6418, 0.6603, 0.6229, 0.6343, 0.6468, 0.6450, 0.6364],
       device='cuda:0') torch.Size([16])
percent tensor([0.5717, 0.5728, 0.6936, 0.7648, 0.6951, 0.7409, 0.5798, 0.5636, 0.7213,
        0.5750, 0.6815, 0.6706, 0.5981, 0.7723, 0.5461, 0.6322],
       device='cuda:0') torch.Size([16])
percent tensor([0.6940, 0.6431, 0.7485, 0.7555, 0.7605, 0.6807, 0.7275, 0.7703, 0.7032,
        0.6481, 0.6521, 0.7476, 0.6058, 0.6794, 0.7357, 0.6811],
       device='cuda:0') torch.Size([16])
percent tensor([0.6350, 0.6136, 0.7176, 0.6132, 0.7327, 0.7847, 0.6185, 0.5863, 0.6225,
        0.5785, 0.6486, 0.4724, 0.5524, 0.5758, 0.5907, 0.5853],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9998, 0.9998, 0.9992, 0.9999, 0.9999, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9994, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 142 | Batch_idx: 0 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (96.00%) (2584/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (96.00%) (3812/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (96.00%) (5046/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (6264/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (7490/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (8701/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (9927/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (11148/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (12375/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (13607/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (14839/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (16040/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (17255/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (18479/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (19691/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (20904/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (22122/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (23351/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (24554/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (25786/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (27015/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (28237/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (29468/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (30684/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (31910/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (33129/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (34356/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (35568/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (36799/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (38028/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (39233/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (40443/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (41659/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (42858/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (44057/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (45260/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (46465/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (47626/50000)
# TEST : Loss: (0.4668) | Acc: (86.00%) (8668/10000)
percent tensor([0.5525, 0.5544, 0.5576, 0.5544, 0.5666, 0.5572, 0.5596, 0.5604, 0.5534,
        0.5523, 0.5525, 0.5557, 0.5525, 0.5462, 0.5569, 0.5521],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5232, 0.5178, 0.5213, 0.5189, 0.5224, 0.5225, 0.5210, 0.5217,
        0.5217, 0.5210, 0.5205, 0.5237, 0.5199, 0.5239, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.5140, 0.5247, 0.5597, 0.5478, 0.5804, 0.5586, 0.5353, 0.5348, 0.5521,
        0.5297, 0.5245, 0.5635, 0.5347, 0.5206, 0.5366, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.6388, 0.6412, 0.6132, 0.6214, 0.6182, 0.6283, 0.6414, 0.6092, 0.6250,
        0.6430, 0.6604, 0.6209, 0.6308, 0.6493, 0.6459, 0.6375],
       device='cuda:0') torch.Size([16])
percent tensor([0.5568, 0.5662, 0.6873, 0.7694, 0.6992, 0.7411, 0.5762, 0.5455, 0.7116,
        0.5783, 0.6654, 0.6701, 0.5857, 0.7712, 0.5356, 0.6204],
       device='cuda:0') torch.Size([16])
percent tensor([0.6865, 0.6304, 0.7365, 0.7586, 0.7554, 0.6757, 0.7242, 0.7567, 0.7006,
        0.6464, 0.6360, 0.7339, 0.6074, 0.6782, 0.7260, 0.6720],
       device='cuda:0') torch.Size([16])
percent tensor([0.6099, 0.6219, 0.6835, 0.5785, 0.7088, 0.7641, 0.5954, 0.5065, 0.6353,
        0.6117, 0.6570, 0.5201, 0.6114, 0.5700, 0.5363, 0.5568],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9990, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9995, 0.9995, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 143 | Batch_idx: 0 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (2558/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (3790/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (5008/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (6231/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (7467/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (8676/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (9896/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (11120/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (12337/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (13568/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (14776/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (15989/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (17217/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (18437/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (19657/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (20862/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (22082/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (23299/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (24519/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (25740/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (26946/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (28172/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (29387/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (30597/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (31815/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (33047/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (34274/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (35502/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (36720/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (37953/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (39170/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (40379/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (41599/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (42808/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (44032/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (45260/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (46474/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (47646/50000)
# TEST : Loss: (0.4340) | Acc: (87.00%) (8732/10000)
percent tensor([0.5529, 0.5542, 0.5582, 0.5549, 0.5676, 0.5575, 0.5600, 0.5605, 0.5537,
        0.5523, 0.5523, 0.5564, 0.5528, 0.5461, 0.5570, 0.5521],
       device='cuda:0') torch.Size([16])
percent tensor([0.5221, 0.5231, 0.5178, 0.5209, 0.5192, 0.5221, 0.5226, 0.5207, 0.5221,
        0.5214, 0.5214, 0.5206, 0.5239, 0.5199, 0.5237, 0.5227],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5241, 0.5469, 0.5477, 0.5695, 0.5527, 0.5334, 0.5334, 0.5445,
        0.5241, 0.5218, 0.5545, 0.5299, 0.5213, 0.5343, 0.5177],
       device='cuda:0') torch.Size([16])
percent tensor([0.6403, 0.6416, 0.6127, 0.6156, 0.6203, 0.6263, 0.6432, 0.6104, 0.6253,
        0.6457, 0.6618, 0.6240, 0.6330, 0.6478, 0.6463, 0.6374],
       device='cuda:0') torch.Size([16])
percent tensor([0.5589, 0.5780, 0.6844, 0.7516, 0.6859, 0.7372, 0.5865, 0.5520, 0.7236,
        0.5842, 0.6662, 0.6584, 0.5928, 0.7742, 0.5435, 0.6377],
       device='cuda:0') torch.Size([16])
percent tensor([0.6857, 0.6361, 0.7382, 0.7566, 0.7531, 0.6836, 0.7170, 0.7569, 0.7019,
        0.6481, 0.6351, 0.7354, 0.5964, 0.6692, 0.7225, 0.6834],
       device='cuda:0') torch.Size([16])
percent tensor([0.5565, 0.6002, 0.7358, 0.5888, 0.7446, 0.7758, 0.5970, 0.5731, 0.5727,
        0.5465, 0.5998, 0.4610, 0.5219, 0.5314, 0.5019, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9997, 0.9997, 0.9993, 0.9998, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9994, 0.9996, 0.9998, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (2574/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (3799/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (5020/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (6248/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (7460/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (8690/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (9933/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (11165/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (12393/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (13623/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (14844/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (16073/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (17307/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (18539/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (19774/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (21012/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (96.00%) (22244/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (23464/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (24681/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (25901/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (27104/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (28325/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (29546/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (30774/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (32017/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (33244/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (34460/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (35678/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (36904/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (38125/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (39346/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (40572/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (41805/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (43024/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (44245/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (45477/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (46689/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (47853/50000)
# TEST : Loss: (0.4999) | Acc: (85.00%) (8586/10000)
percent tensor([0.5532, 0.5546, 0.5578, 0.5542, 0.5669, 0.5574, 0.5598, 0.5601, 0.5550,
        0.5527, 0.5538, 0.5562, 0.5538, 0.5466, 0.5570, 0.5521],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.5234, 0.5189, 0.5220, 0.5197, 0.5232, 0.5228, 0.5208, 0.5220,
        0.5218, 0.5215, 0.5213, 0.5240, 0.5199, 0.5242, 0.5231],
       device='cuda:0') torch.Size([16])
percent tensor([0.5128, 0.5242, 0.5570, 0.5479, 0.5760, 0.5563, 0.5379, 0.5389, 0.5512,
        0.5276, 0.5261, 0.5613, 0.5307, 0.5262, 0.5378, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.6369, 0.6407, 0.6102, 0.6144, 0.6149, 0.6244, 0.6417, 0.6072, 0.6236,
        0.6430, 0.6597, 0.6234, 0.6299, 0.6470, 0.6424, 0.6358],
       device='cuda:0') torch.Size([16])
percent tensor([0.5615, 0.5873, 0.6745, 0.7689, 0.7005, 0.7417, 0.5864, 0.5574, 0.7198,
        0.5887, 0.6847, 0.6551, 0.5953, 0.7715, 0.5469, 0.6333],
       device='cuda:0') torch.Size([16])
percent tensor([0.6969, 0.6459, 0.7587, 0.7557, 0.7696, 0.6842, 0.7291, 0.7656, 0.7119,
        0.6659, 0.6547, 0.7459, 0.6149, 0.6849, 0.7269, 0.6878],
       device='cuda:0') torch.Size([16])
percent tensor([0.6111, 0.6503, 0.7496, 0.5961, 0.7508, 0.7709, 0.6402, 0.5605, 0.6371,
        0.6235, 0.6524, 0.4789, 0.5931, 0.5783, 0.5802, 0.5908],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9996, 0.9993, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (2560/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (3758/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (4963/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (6151/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (93.00%) (7339/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (93.00%) (8535/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (9747/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (93.00%) (10930/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (93.00%) (12134/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (93.00%) (13338/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (93.00%) (14548/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (93.00%) (15752/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (16970/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (93.00%) (18165/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (19377/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (20591/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (21801/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (23020/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (24228/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (25425/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (26639/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (27854/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (29052/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (30258/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (31467/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (32679/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (33906/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (35115/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (36327/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (37532/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (38751/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (39952/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (41169/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (42382/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (43592/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (44820/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (46035/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (47189/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_145.pth.tar'
# TEST : Loss: (0.4298) | Acc: (87.00%) (8726/10000)
percent tensor([0.5566, 0.5589, 0.5615, 0.5578, 0.5711, 0.5610, 0.5644, 0.5641, 0.5596,
        0.5568, 0.5580, 0.5603, 0.5574, 0.5512, 0.5609, 0.5559],
       device='cuda:0') torch.Size([16])
percent tensor([0.5279, 0.5291, 0.5241, 0.5275, 0.5250, 0.5288, 0.5284, 0.5263, 0.5277,
        0.5275, 0.5269, 0.5272, 0.5295, 0.5256, 0.5300, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5207, 0.5423, 0.5459, 0.5404, 0.5608, 0.5563, 0.5434, 0.5270, 0.5488,
        0.5398, 0.5395, 0.5575, 0.5472, 0.5320, 0.5435, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.6520, 0.6560, 0.6231, 0.6282, 0.6273, 0.6333, 0.6586, 0.6190, 0.6387,
        0.6599, 0.6764, 0.6412, 0.6469, 0.6613, 0.6562, 0.6494],
       device='cuda:0') torch.Size([16])
percent tensor([0.5809, 0.6037, 0.7182, 0.8074, 0.7231, 0.7468, 0.6283, 0.5923, 0.7602,
        0.6207, 0.7263, 0.7139, 0.6145, 0.8017, 0.5704, 0.6479],
       device='cuda:0') torch.Size([16])
percent tensor([0.6831, 0.6410, 0.7475, 0.7414, 0.7576, 0.6733, 0.7247, 0.7569, 0.6998,
        0.6616, 0.6516, 0.7338, 0.6066, 0.6762, 0.7162, 0.6814],
       device='cuda:0') torch.Size([16])
percent tensor([0.5757, 0.5918, 0.7389, 0.6149, 0.7573, 0.7860, 0.5564, 0.5368, 0.5640,
        0.5494, 0.6104, 0.4000, 0.5447, 0.5112, 0.5344, 0.5500],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9992, 0.9998, 0.9998, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9993, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 146 | Batch_idx: 0 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (94.00%) (2549/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (94.00%) (3763/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (94.00%) (4985/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (94.00%) (6196/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (94.00%) (7411/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (8635/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (9851/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (11078/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (12301/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (13515/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (14739/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (15961/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (17181/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (18395/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (19611/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (20827/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (22030/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (23248/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (24467/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (25689/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (26916/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (28127/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (29358/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (30580/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (31788/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (33013/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (34232/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (35452/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (36676/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (37893/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (39104/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (40316/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (41541/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (42768/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (43979/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (45197/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (46430/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (47595/50000)
# TEST : Loss: (0.4171) | Acc: (87.00%) (8776/10000)
percent tensor([0.5573, 0.5591, 0.5621, 0.5585, 0.5718, 0.5618, 0.5648, 0.5647, 0.5603,
        0.5572, 0.5585, 0.5607, 0.5580, 0.5517, 0.5613, 0.5565],
       device='cuda:0') torch.Size([16])
percent tensor([0.5304, 0.5311, 0.5264, 0.5301, 0.5271, 0.5317, 0.5303, 0.5285, 0.5298,
        0.5295, 0.5290, 0.5293, 0.5317, 0.5277, 0.5323, 0.5312],
       device='cuda:0') torch.Size([16])
percent tensor([0.5221, 0.5481, 0.5391, 0.5369, 0.5540, 0.5567, 0.5437, 0.5215, 0.5477,
        0.5433, 0.5443, 0.5546, 0.5521, 0.5352, 0.5451, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.6473, 0.6536, 0.6185, 0.6231, 0.6223, 0.6269, 0.6552, 0.6136, 0.6349,
        0.6571, 0.6737, 0.6381, 0.6442, 0.6575, 0.6522, 0.6443],
       device='cuda:0') torch.Size([16])
percent tensor([0.5784, 0.5989, 0.7266, 0.8096, 0.7222, 0.7337, 0.6238, 0.5992, 0.7606,
        0.6112, 0.7224, 0.7265, 0.6135, 0.7966, 0.5718, 0.6327],
       device='cuda:0') torch.Size([16])
percent tensor([0.6839, 0.6405, 0.7447, 0.7413, 0.7536, 0.6756, 0.7219, 0.7521, 0.6967,
        0.6617, 0.6501, 0.7323, 0.6090, 0.6749, 0.7143, 0.6838],
       device='cuda:0') torch.Size([16])
percent tensor([0.6038, 0.6226, 0.7577, 0.6360, 0.7789, 0.8141, 0.5827, 0.5676, 0.5923,
        0.5797, 0.6348, 0.4060, 0.5737, 0.5310, 0.5542, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9992, 0.9999, 0.9998, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9994, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 147 | Batch_idx: 0 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (95.00%) (2563/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (3789/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (5009/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (6230/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (7441/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (8668/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (9881/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (11101/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (12304/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (13521/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (14750/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (15973/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (17181/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (18399/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (19631/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (20849/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (22074/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (23296/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (24514/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (25747/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (26977/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (28199/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (29415/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (30625/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (31853/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (33068/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (34293/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (35533/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (36755/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (37976/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (39208/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (40448/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (41670/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (42886/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (44109/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (45321/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (46551/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (47728/50000)
# TEST : Loss: (0.4066) | Acc: (88.00%) (8801/10000)
percent tensor([0.5565, 0.5578, 0.5614, 0.5580, 0.5710, 0.5615, 0.5636, 0.5636, 0.5595,
        0.5560, 0.5574, 0.5595, 0.5569, 0.5508, 0.5603, 0.5558],
       device='cuda:0') torch.Size([16])
percent tensor([0.5348, 0.5353, 0.5304, 0.5344, 0.5312, 0.5364, 0.5345, 0.5327, 0.5341,
        0.5336, 0.5332, 0.5334, 0.5360, 0.5317, 0.5368, 0.5356],
       device='cuda:0') torch.Size([16])
percent tensor([0.5238, 0.5513, 0.5404, 0.5389, 0.5565, 0.5591, 0.5459, 0.5220, 0.5515,
        0.5469, 0.5481, 0.5573, 0.5554, 0.5388, 0.5483, 0.5326],
       device='cuda:0') torch.Size([16])
percent tensor([0.6492, 0.6583, 0.6191, 0.6242, 0.6232, 0.6262, 0.6589, 0.6151, 0.6382,
        0.6612, 0.6781, 0.6421, 0.6484, 0.6617, 0.6546, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.5791, 0.6017, 0.7330, 0.8098, 0.7242, 0.7304, 0.6287, 0.6020, 0.7642,
        0.6140, 0.7265, 0.7369, 0.6189, 0.8001, 0.5731, 0.6307],
       device='cuda:0') torch.Size([16])
percent tensor([0.6838, 0.6402, 0.7395, 0.7375, 0.7477, 0.6754, 0.7196, 0.7467, 0.6931,
        0.6611, 0.6491, 0.7282, 0.6101, 0.6735, 0.7131, 0.6838],
       device='cuda:0') torch.Size([16])
percent tensor([0.6013, 0.6196, 0.7578, 0.6330, 0.7773, 0.8173, 0.5732, 0.5710, 0.5887,
        0.5710, 0.6261, 0.3988, 0.5691, 0.5176, 0.5485, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9992, 0.9998, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9994, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 148 | Batch_idx: 0 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (2575/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (96.00%) (3815/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (5036/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (6252/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (7458/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (8678/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (9904/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (11141/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (12376/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (13604/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (14829/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (16048/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (17274/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (18500/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (19716/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (20937/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (22163/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (23376/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (24609/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (25839/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (27084/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (28305/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (29532/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (30746/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (31969/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (33183/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (34400/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (35620/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (36846/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (38075/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (39285/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (40512/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (41733/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (42959/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (44180/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (45408/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (46631/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (47811/50000)
# TEST : Loss: (0.3973) | Acc: (88.00%) (8816/10000)
percent tensor([0.5563, 0.5573, 0.5613, 0.5579, 0.5708, 0.5616, 0.5633, 0.5634, 0.5591,
        0.5556, 0.5570, 0.5592, 0.5565, 0.5504, 0.5601, 0.5556],
       device='cuda:0') torch.Size([16])
percent tensor([0.5373, 0.5377, 0.5325, 0.5367, 0.5333, 0.5392, 0.5368, 0.5350, 0.5363,
        0.5359, 0.5356, 0.5358, 0.5386, 0.5338, 0.5394, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.5220, 0.5496, 0.5393, 0.5378, 0.5553, 0.5590, 0.5445, 0.5206, 0.5496,
        0.5447, 0.5461, 0.5556, 0.5531, 0.5374, 0.5476, 0.5313],
       device='cuda:0') torch.Size([16])
percent tensor([0.6508, 0.6612, 0.6197, 0.6241, 0.6237, 0.6257, 0.6614, 0.6159, 0.6409,
        0.6638, 0.6812, 0.6450, 0.6515, 0.6647, 0.6564, 0.6468],
       device='cuda:0') torch.Size([16])
percent tensor([0.5758, 0.5977, 0.7298, 0.8060, 0.7215, 0.7284, 0.6248, 0.5956, 0.7600,
        0.6045, 0.7208, 0.7326, 0.6140, 0.7960, 0.5695, 0.6253],
       device='cuda:0') torch.Size([16])
percent tensor([0.6820, 0.6380, 0.7349, 0.7340, 0.7440, 0.6744, 0.7168, 0.7417, 0.6882,
        0.6586, 0.6462, 0.7230, 0.6080, 0.6710, 0.7102, 0.6823],
       device='cuda:0') torch.Size([16])
percent tensor([0.5959, 0.6143, 0.7660, 0.6441, 0.7842, 0.8168, 0.5667, 0.5889, 0.5766,
        0.5661, 0.6157, 0.3985, 0.5608, 0.5046, 0.5446, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9992, 0.9998, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9994, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 149 | Batch_idx: 0 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (2562/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (3781/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (5009/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (6230/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (7468/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (8697/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (9911/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (11135/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (12362/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (13587/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (14814/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (16038/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (17271/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (18489/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (19710/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (20939/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (22167/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (23392/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (24629/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (25866/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (27090/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (28316/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (29543/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (30773/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (32001/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (33216/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (34439/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (35668/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (36871/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (38107/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (39342/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (40577/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (41802/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (43032/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (44256/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (45493/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (46727/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (47911/50000)
# TEST : Loss: (0.3947) | Acc: (88.00%) (8819/10000)
percent tensor([0.5559, 0.5566, 0.5609, 0.5576, 0.5703, 0.5613, 0.5626, 0.5628, 0.5586,
        0.5549, 0.5565, 0.5587, 0.5559, 0.5499, 0.5595, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.5384, 0.5330, 0.5375, 0.5339, 0.5403, 0.5374, 0.5356, 0.5368,
        0.5365, 0.5363, 0.5365, 0.5394, 0.5343, 0.5403, 0.5391],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5493, 0.5397, 0.5389, 0.5562, 0.5603, 0.5443, 0.5204, 0.5498,
        0.5444, 0.5461, 0.5559, 0.5523, 0.5379, 0.5487, 0.5313],
       device='cuda:0') torch.Size([16])
percent tensor([0.6498, 0.6615, 0.6191, 0.6236, 0.6230, 0.6239, 0.6616, 0.6153, 0.6409,
        0.6641, 0.6814, 0.6455, 0.6511, 0.6651, 0.6561, 0.6458],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.5976, 0.7331, 0.8072, 0.7226, 0.7314, 0.6251, 0.5957, 0.7596,
        0.6020, 0.7205, 0.7339, 0.6150, 0.7957, 0.5687, 0.6280],
       device='cuda:0') torch.Size([16])
percent tensor([0.6856, 0.6420, 0.7372, 0.7371, 0.7462, 0.6791, 0.7194, 0.7428, 0.6912,
        0.6621, 0.6496, 0.7258, 0.6138, 0.6744, 0.7132, 0.6872],
       device='cuda:0') torch.Size([16])
percent tensor([0.6081, 0.6260, 0.7643, 0.6389, 0.7803, 0.8197, 0.5706, 0.5936, 0.5885,
        0.5766, 0.6278, 0.4002, 0.5795, 0.5072, 0.5492, 0.5798],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9993, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9994, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 150 | Batch_idx: 0 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (2554/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (3785/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (5017/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (6248/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (7471/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (8694/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (9922/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (11151/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (12378/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (13601/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (14833/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (16058/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (17284/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (18499/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (19724/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (20942/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (22180/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (23405/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (24625/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (25846/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (27063/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (28279/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (29497/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (30707/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (31917/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (33126/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (34346/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (35574/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (36786/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (38000/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (39217/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (40430/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (41653/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (42871/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (44097/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (45307/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (46538/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (47715/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_150.pth.tar'
# TEST : Loss: (0.4253) | Acc: (87.00%) (8754/10000)
percent tensor([0.5576, 0.5559, 0.5623, 0.5596, 0.5720, 0.5639, 0.5625, 0.5635, 0.5570,
        0.5549, 0.5552, 0.5596, 0.5559, 0.5484, 0.5604, 0.5565],
       device='cuda:0') torch.Size([16])
percent tensor([0.5384, 0.5379, 0.5319, 0.5375, 0.5335, 0.5408, 0.5366, 0.5355, 0.5358,
        0.5364, 0.5363, 0.5356, 0.5390, 0.5335, 0.5406, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.5239, 0.5479, 0.5371, 0.5412, 0.5603, 0.5610, 0.5438, 0.5200, 0.5474,
        0.5454, 0.5446, 0.5587, 0.5541, 0.5366, 0.5504, 0.5335],
       device='cuda:0') torch.Size([16])
percent tensor([0.6489, 0.6622, 0.6184, 0.6214, 0.6206, 0.6188, 0.6604, 0.6169, 0.6440,
        0.6640, 0.6847, 0.6420, 0.6533, 0.6673, 0.6577, 0.6426],
       device='cuda:0') torch.Size([16])
percent tensor([0.5723, 0.5825, 0.7142, 0.7892, 0.6977, 0.7365, 0.5843, 0.5794, 0.7404,
        0.5898, 0.6832, 0.7000, 0.6132, 0.7794, 0.5606, 0.6361],
       device='cuda:0') torch.Size([16])
percent tensor([0.6835, 0.6352, 0.7201, 0.7250, 0.7327, 0.6877, 0.7095, 0.7339, 0.6923,
        0.6509, 0.6365, 0.7161, 0.6085, 0.6832, 0.7095, 0.6772],
       device='cuda:0') torch.Size([16])
percent tensor([0.5755, 0.5556, 0.7444, 0.6262, 0.7478, 0.8029, 0.5668, 0.5414, 0.5919,
        0.5020, 0.5756, 0.4428, 0.5348, 0.5323, 0.5149, 0.5185],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9999, 0.9994, 0.9998, 0.9998, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9997, 0.9996, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(183.7639, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.7897, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.8893, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1514.4969, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(487.8882, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2259.6172, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4276.5073, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1362.8391, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6206.0190, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11674.4004, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3853.4507, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16315.8516, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 151 | Batch_idx: 0 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (2578/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (3809/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (96.00%) (5039/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (96.00%) (6268/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (96.00%) (7503/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (96.00%) (8729/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (96.00%) (9954/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (96.00%) (11183/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (96.00%) (12412/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (13634/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (14865/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (16093/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (17318/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (18540/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (19772/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (20988/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (22212/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (23436/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (24662/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (25891/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (27109/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (28346/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (29576/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (30801/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (32036/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (33275/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (34498/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (35721/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (36945/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (38156/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (39372/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (40590/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (41813/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (43040/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (44237/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (45461/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (46691/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (47860/50000)
# TEST : Loss: (0.3966) | Acc: (87.00%) (8789/10000)
percent tensor([0.5566, 0.5559, 0.5587, 0.5591, 0.5696, 0.5610, 0.5612, 0.5625, 0.5563,
        0.5538, 0.5542, 0.5573, 0.5557, 0.5488, 0.5591, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.5378, 0.5307, 0.5366, 0.5328, 0.5397, 0.5361, 0.5344, 0.5362,
        0.5362, 0.5358, 0.5348, 0.5387, 0.5338, 0.5396, 0.5389],
       device='cuda:0') torch.Size([16])
percent tensor([0.5237, 0.5491, 0.5374, 0.5422, 0.5621, 0.5630, 0.5413, 0.5195, 0.5550,
        0.5456, 0.5470, 0.5575, 0.5557, 0.5349, 0.5495, 0.5317],
       device='cuda:0') torch.Size([16])
percent tensor([0.6455, 0.6597, 0.6184, 0.6193, 0.6174, 0.6198, 0.6595, 0.6162, 0.6374,
        0.6615, 0.6812, 0.6402, 0.6479, 0.6668, 0.6547, 0.6430],
       device='cuda:0') torch.Size([16])
percent tensor([0.5857, 0.5953, 0.7430, 0.8073, 0.7322, 0.7484, 0.6120, 0.5918, 0.7524,
        0.6210, 0.6997, 0.7238, 0.6354, 0.7864, 0.5677, 0.6507],
       device='cuda:0') torch.Size([16])
percent tensor([0.6907, 0.6462, 0.7313, 0.7355, 0.7450, 0.6907, 0.7221, 0.7404, 0.6895,
        0.6604, 0.6348, 0.7227, 0.6157, 0.6819, 0.7227, 0.6887],
       device='cuda:0') torch.Size([16])
percent tensor([0.6093, 0.6319, 0.7162, 0.5842, 0.7237, 0.7842, 0.5720, 0.5642, 0.6132,
        0.5630, 0.5999, 0.4310, 0.5888, 0.5288, 0.5044, 0.5563],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9997, 0.9998, 0.9995, 0.9999, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9995, 0.9995, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 152 | Batch_idx: 0 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (2578/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (3795/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (5029/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (6249/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (7468/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (8702/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (9931/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (11165/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (12393/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (13627/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (14848/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (16071/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (17292/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (18523/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (19738/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (20968/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (22191/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (23420/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (24645/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (25876/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (27099/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (28321/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (29558/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (30774/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (32001/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (33230/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (34449/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (35664/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (36888/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (38123/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (39346/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (40572/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (41801/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (43033/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (44253/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (45466/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (46693/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (47883/50000)
# TEST : Loss: (0.4148) | Acc: (87.00%) (8798/10000)
percent tensor([0.5555, 0.5560, 0.5595, 0.5581, 0.5694, 0.5614, 0.5614, 0.5625, 0.5565,
        0.5544, 0.5545, 0.5576, 0.5552, 0.5495, 0.5592, 0.5554],
       device='cuda:0') torch.Size([16])
percent tensor([0.5376, 0.5379, 0.5305, 0.5366, 0.5324, 0.5403, 0.5361, 0.5346, 0.5354,
        0.5354, 0.5355, 0.5345, 0.5380, 0.5335, 0.5402, 0.5388],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5497, 0.5319, 0.5402, 0.5529, 0.5585, 0.5423, 0.5174, 0.5500,
        0.5459, 0.5451, 0.5533, 0.5521, 0.5389, 0.5494, 0.5323],
       device='cuda:0') torch.Size([16])
percent tensor([0.6488, 0.6605, 0.6204, 0.6216, 0.6234, 0.6212, 0.6595, 0.6172, 0.6377,
        0.6630, 0.6815, 0.6428, 0.6509, 0.6645, 0.6578, 0.6449],
       device='cuda:0') torch.Size([16])
percent tensor([0.5695, 0.5986, 0.7026, 0.7995, 0.6902, 0.7464, 0.5980, 0.5803, 0.7393,
        0.5921, 0.6968, 0.6973, 0.6070, 0.7944, 0.5674, 0.6417],
       device='cuda:0') torch.Size([16])
percent tensor([0.6879, 0.6466, 0.7289, 0.7403, 0.7506, 0.7035, 0.7166, 0.7380, 0.6883,
        0.6469, 0.6392, 0.7137, 0.6029, 0.6692, 0.7236, 0.6840],
       device='cuda:0') torch.Size([16])
percent tensor([0.5943, 0.6378, 0.7738, 0.6336, 0.7753, 0.7892, 0.6153, 0.6245, 0.6161,
        0.5355, 0.6344, 0.4592, 0.5558, 0.5232, 0.5183, 0.5544],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9998, 0.9994, 0.9998, 0.9999, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9995, 0.9995, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 153 | Batch_idx: 0 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (2591/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (3826/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (5064/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (6300/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (7540/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (8774/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (10005/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (11238/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (12467/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (13703/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (14938/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (16160/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (17389/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (18608/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (19843/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (21071/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (22286/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (23507/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (24728/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (25966/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (27181/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (28409/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (29638/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (30871/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (32102/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (33327/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (34546/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (35771/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (36984/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (38206/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (39418/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (40647/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (41865/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (43093/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (44319/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (45537/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (46750/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (47911/50000)
# TEST : Loss: (0.4649) | Acc: (87.00%) (8734/10000)
percent tensor([0.5560, 0.5550, 0.5624, 0.5586, 0.5713, 0.5609, 0.5616, 0.5637, 0.5566,
        0.5547, 0.5543, 0.5592, 0.5551, 0.5474, 0.5587, 0.5550],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5376, 0.5320, 0.5361, 0.5339, 0.5390, 0.5365, 0.5354, 0.5358,
        0.5359, 0.5353, 0.5356, 0.5383, 0.5332, 0.5395, 0.5384],
       device='cuda:0') torch.Size([16])
percent tensor([0.5203, 0.5501, 0.5342, 0.5407, 0.5624, 0.5605, 0.5434, 0.5191, 0.5488,
        0.5457, 0.5458, 0.5550, 0.5527, 0.5336, 0.5498, 0.5343],
       device='cuda:0') torch.Size([16])
percent tensor([0.6494, 0.6635, 0.6152, 0.6206, 0.6184, 0.6261, 0.6598, 0.6150, 0.6380,
        0.6616, 0.6828, 0.6378, 0.6524, 0.6667, 0.6594, 0.6464],
       device='cuda:0') torch.Size([16])
percent tensor([0.5738, 0.5857, 0.7020, 0.7776, 0.7031, 0.7374, 0.6048, 0.5740, 0.7414,
        0.5835, 0.6930, 0.7023, 0.6301, 0.7834, 0.5630, 0.6281],
       device='cuda:0') torch.Size([16])
percent tensor([0.6857, 0.6326, 0.7277, 0.7248, 0.7406, 0.6783, 0.7117, 0.7305, 0.6911,
        0.6463, 0.6396, 0.7191, 0.6138, 0.6652, 0.7071, 0.6785],
       device='cuda:0') torch.Size([16])
percent tensor([0.5934, 0.5837, 0.7792, 0.6600, 0.7812, 0.7998, 0.6271, 0.5976, 0.6404,
        0.5435, 0.6314, 0.4982, 0.5738, 0.5174, 0.5267, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9999, 0.9997, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9998, 1.0000, 0.9998, 0.9996, 0.9994, 0.9994, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 154 | Batch_idx: 0 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (95.00%) (2579/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (95.00%) (3809/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (5045/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (6280/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (7498/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (8736/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (9964/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (11196/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (12425/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (13662/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (14897/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (16134/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (17354/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (18579/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (19807/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (21048/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (22282/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (23502/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (24723/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (25947/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (27189/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (28418/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (29647/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (30873/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (32107/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (33337/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (34560/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (35773/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (37004/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (38237/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (39461/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (40694/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (41929/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (43141/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (44361/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (95.00%) (45585/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (95.00%) (46813/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (95.00%) (47991/50000)
# TEST : Loss: (0.4099) | Acc: (88.00%) (8829/10000)
percent tensor([0.5560, 0.5558, 0.5604, 0.5578, 0.5703, 0.5613, 0.5614, 0.5626, 0.5570,
        0.5541, 0.5549, 0.5580, 0.5553, 0.5484, 0.5593, 0.5549],
       device='cuda:0') torch.Size([16])
percent tensor([0.5379, 0.5379, 0.5322, 0.5369, 0.5336, 0.5394, 0.5367, 0.5354, 0.5360,
        0.5360, 0.5358, 0.5358, 0.5386, 0.5335, 0.5399, 0.5389],
       device='cuda:0') torch.Size([16])
percent tensor([0.5221, 0.5491, 0.5377, 0.5397, 0.5608, 0.5582, 0.5432, 0.5208, 0.5503,
        0.5453, 0.5460, 0.5596, 0.5547, 0.5333, 0.5492, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.6468, 0.6583, 0.6169, 0.6224, 0.6220, 0.6261, 0.6580, 0.6152, 0.6357,
        0.6591, 0.6815, 0.6408, 0.6494, 0.6618, 0.6573, 0.6439],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5889, 0.7276, 0.7954, 0.7145, 0.7569, 0.6049, 0.5774, 0.7539,
        0.6095, 0.7043, 0.7276, 0.6297, 0.7957, 0.5683, 0.6325],
       device='cuda:0') torch.Size([16])
percent tensor([0.6881, 0.6459, 0.7232, 0.7348, 0.7421, 0.6941, 0.7176, 0.7370, 0.6945,
        0.6483, 0.6478, 0.7164, 0.6124, 0.6801, 0.7127, 0.6878],
       device='cuda:0') torch.Size([16])
percent tensor([0.6032, 0.6096, 0.7626, 0.6355, 0.7394, 0.7946, 0.6250, 0.6220, 0.6526,
        0.5691, 0.6385, 0.4669, 0.5523, 0.5442, 0.5484, 0.5550],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9999, 0.9998, 0.9995, 0.9998, 0.9999, 0.9999,
        0.9998, 1.0000, 0.9998, 0.9994, 0.9993, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 155 | Batch_idx: 0 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (3778/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (4992/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (6209/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (7438/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (8656/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (9876/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (11097/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (12306/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (13524/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (14760/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (15977/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (17193/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (18418/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (19649/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (20868/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (22100/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (23324/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (24551/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (25787/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (27012/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (28222/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (29439/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (30670/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (31890/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (33124/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (34364/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (35602/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (36819/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (38055/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (39272/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (40495/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (41716/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (42937/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (44165/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (45392/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (46628/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (47794/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_155.pth.tar'
# TEST : Loss: (0.4138) | Acc: (88.00%) (8817/10000)
percent tensor([0.5682, 0.5688, 0.5741, 0.5700, 0.5845, 0.5727, 0.5753, 0.5770, 0.5693,
        0.5673, 0.5667, 0.5723, 0.5680, 0.5594, 0.5716, 0.5666],
       device='cuda:0') torch.Size([16])
percent tensor([0.5358, 0.5359, 0.5298, 0.5351, 0.5311, 0.5378, 0.5347, 0.5327, 0.5336,
        0.5340, 0.5339, 0.5339, 0.5359, 0.5325, 0.5377, 0.5367],
       device='cuda:0') torch.Size([16])
percent tensor([0.5295, 0.5649, 0.5285, 0.5344, 0.5534, 0.5627, 0.5523, 0.5171, 0.5503,
        0.5540, 0.5570, 0.5582, 0.5672, 0.5421, 0.5578, 0.5403],
       device='cuda:0') torch.Size([16])
percent tensor([0.6618, 0.6766, 0.6313, 0.6359, 0.6354, 0.6378, 0.6752, 0.6277, 0.6539,
        0.6772, 0.7004, 0.6587, 0.6685, 0.6791, 0.6742, 0.6594],
       device='cuda:0') torch.Size([16])
percent tensor([0.5953, 0.6057, 0.7332, 0.8057, 0.7071, 0.7653, 0.6193, 0.5902, 0.7613,
        0.6223, 0.7169, 0.7322, 0.6404, 0.8059, 0.5832, 0.6416],
       device='cuda:0') torch.Size([16])
percent tensor([0.6811, 0.6399, 0.7174, 0.7268, 0.7344, 0.6866, 0.7098, 0.7283, 0.6848,
        0.6403, 0.6414, 0.7085, 0.6036, 0.6692, 0.7047, 0.6790],
       device='cuda:0') torch.Size([16])
percent tensor([0.5730, 0.5631, 0.7498, 0.6042, 0.7074, 0.7802, 0.5673, 0.5769, 0.5950,
        0.5189, 0.5868, 0.4322, 0.5273, 0.5087, 0.5003, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9999, 0.9999,
        0.9998, 1.0000, 0.9998, 0.9995, 0.9993, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 156 | Batch_idx: 0 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (2572/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (3799/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (5028/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (6251/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (7482/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (8711/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (9947/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (11157/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (12383/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (13610/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (14849/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (16081/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (17309/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (18538/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (19761/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (20974/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (22202/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (23433/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (24662/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (25900/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (27106/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (28331/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (29565/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (30794/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (32029/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (33257/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (34479/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (35704/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (36948/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (38166/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (39401/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (40636/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (41855/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (43089/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (44311/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (45537/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (46770/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (47968/50000)
# TEST : Loss: (0.4023) | Acc: (88.00%) (8846/10000)
percent tensor([0.5693, 0.5696, 0.5758, 0.5712, 0.5863, 0.5735, 0.5766, 0.5786, 0.5707,
        0.5686, 0.5675, 0.5741, 0.5692, 0.5602, 0.5724, 0.5674],
       device='cuda:0') torch.Size([16])
percent tensor([0.5373, 0.5375, 0.5310, 0.5366, 0.5326, 0.5398, 0.5363, 0.5341, 0.5353,
        0.5356, 0.5357, 0.5352, 0.5373, 0.5343, 0.5395, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.5312, 0.5683, 0.5244, 0.5300, 0.5515, 0.5651, 0.5542, 0.5141, 0.5513,
        0.5546, 0.5605, 0.5567, 0.5715, 0.5428, 0.5610, 0.5415],
       device='cuda:0') torch.Size([16])
percent tensor([0.6592, 0.6766, 0.6285, 0.6318, 0.6323, 0.6324, 0.6736, 0.6248, 0.6527,
        0.6760, 0.6991, 0.6577, 0.6685, 0.6774, 0.6723, 0.6554],
       device='cuda:0') torch.Size([16])
percent tensor([0.5943, 0.6079, 0.7359, 0.8075, 0.7077, 0.7611, 0.6223, 0.5935, 0.7621,
        0.6231, 0.7184, 0.7345, 0.6413, 0.8099, 0.5838, 0.6381],
       device='cuda:0') torch.Size([16])
percent tensor([0.6866, 0.6447, 0.7256, 0.7333, 0.7410, 0.6929, 0.7157, 0.7347, 0.6916,
        0.6458, 0.6480, 0.7169, 0.6092, 0.6749, 0.7097, 0.6831],
       device='cuda:0') torch.Size([16])
percent tensor([0.5644, 0.5609, 0.7452, 0.6028, 0.7025, 0.7790, 0.5624, 0.5664, 0.5834,
        0.5149, 0.5814, 0.4283, 0.5227, 0.5012, 0.5044, 0.5054],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9999, 0.9999,
        0.9998, 1.0000, 0.9999, 0.9995, 0.9993, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 157 | Batch_idx: 0 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (2579/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (3816/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (5048/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (6286/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (7532/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (8757/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (9979/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (11203/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (12430/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (13654/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (14887/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (16112/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (17341/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (18574/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (19807/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (21030/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (22259/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (23490/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (24719/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (25957/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (27193/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (28432/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (29673/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (30911/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (32140/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (33367/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (34601/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (35830/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (37055/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (38295/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (39529/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (40772/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (42008/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (43235/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (44478/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (45718/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (46953/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (48130/50000)
# TEST : Loss: (0.3952) | Acc: (88.00%) (8853/10000)
percent tensor([0.5687, 0.5690, 0.5761, 0.5708, 0.5862, 0.5726, 0.5762, 0.5785, 0.5703,
        0.5684, 0.5668, 0.5742, 0.5687, 0.5596, 0.5716, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.5392, 0.5396, 0.5326, 0.5384, 0.5345, 0.5418, 0.5384, 0.5359, 0.5373,
        0.5376, 0.5377, 0.5372, 0.5392, 0.5363, 0.5415, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.5298, 0.5695, 0.5237, 0.5288, 0.5530, 0.5655, 0.5559, 0.5150, 0.5519,
        0.5542, 0.5605, 0.5568, 0.5708, 0.5431, 0.5617, 0.5411],
       device='cuda:0') torch.Size([16])
percent tensor([0.6521, 0.6711, 0.6217, 0.6245, 0.6251, 0.6248, 0.6670, 0.6172, 0.6465,
        0.6696, 0.6932, 0.6516, 0.6626, 0.6706, 0.6656, 0.6478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5844, 0.6029, 0.7288, 0.8030, 0.6990, 0.7506, 0.6152, 0.5850, 0.7584,
        0.6159, 0.7164, 0.7300, 0.6345, 0.8093, 0.5770, 0.6254],
       device='cuda:0') torch.Size([16])
percent tensor([0.6921, 0.6514, 0.7332, 0.7398, 0.7480, 0.6982, 0.7217, 0.7409, 0.6995,
        0.6534, 0.6545, 0.7252, 0.6168, 0.6825, 0.7148, 0.6882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5761, 0.5794, 0.7625, 0.6204, 0.7185, 0.7859, 0.5850, 0.5867, 0.6040,
        0.5372, 0.5991, 0.4504, 0.5445, 0.5115, 0.5291, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9998, 1.0000, 0.9999, 0.9995, 0.9993, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 158 | Batch_idx: 0 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (1358/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (95.00%) (2580/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (3816/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (5059/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (6290/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (7530/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (8760/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (9990/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (11222/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (12453/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (13690/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (14925/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (16161/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (17397/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (18635/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (19873/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (21104/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (22334/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (23564/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (24790/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (26021/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (27267/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (28506/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (29730/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (30963/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (32212/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (33450/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (34681/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (35918/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (37145/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (38389/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (39626/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (40860/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (42095/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (43327/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (44556/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (45796/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (47040/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (48219/50000)
# TEST : Loss: (0.3924) | Acc: (88.00%) (8854/10000)
percent tensor([0.5699, 0.5701, 0.5779, 0.5721, 0.5880, 0.5736, 0.5777, 0.5803, 0.5717,
        0.5699, 0.5678, 0.5760, 0.5700, 0.5606, 0.5727, 0.5678],
       device='cuda:0') torch.Size([16])
percent tensor([0.5398, 0.5403, 0.5331, 0.5391, 0.5350, 0.5426, 0.5390, 0.5363, 0.5379,
        0.5382, 0.5383, 0.5378, 0.5397, 0.5372, 0.5421, 0.5408],
       device='cuda:0') torch.Size([16])
percent tensor([0.5263, 0.5637, 0.5218, 0.5268, 0.5494, 0.5639, 0.5514, 0.5126, 0.5473,
        0.5485, 0.5552, 0.5527, 0.5652, 0.5388, 0.5575, 0.5376],
       device='cuda:0') torch.Size([16])
percent tensor([0.6517, 0.6715, 0.6220, 0.6236, 0.6243, 0.6221, 0.6677, 0.6172, 0.6472,
        0.6702, 0.6927, 0.6527, 0.6633, 0.6708, 0.6649, 0.6464],
       device='cuda:0') torch.Size([16])
percent tensor([0.5769, 0.5987, 0.7186, 0.7972, 0.6904, 0.7459, 0.6060, 0.5741, 0.7483,
        0.6055, 0.7071, 0.7192, 0.6274, 0.8047, 0.5701, 0.6151],
       device='cuda:0') torch.Size([16])
percent tensor([0.6964, 0.6552, 0.7378, 0.7438, 0.7532, 0.7023, 0.7258, 0.7465, 0.7044,
        0.6568, 0.6593, 0.7297, 0.6215, 0.6872, 0.7179, 0.6921],
       device='cuda:0') torch.Size([16])
percent tensor([0.5753, 0.5860, 0.7637, 0.6219, 0.7235, 0.7852, 0.5922, 0.5964, 0.6030,
        0.5422, 0.6095, 0.4576, 0.5475, 0.5181, 0.5356, 0.5205],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9998, 1.0000, 0.9999, 0.9996, 0.9993, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 159 | Batch_idx: 0 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (2602/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (3845/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (5079/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (6327/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (7559/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (8794/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (10029/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (11260/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (12487/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (13731/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (14970/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (16197/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (17428/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (18662/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (19901/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (21143/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (22379/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (23614/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (24840/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (26071/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (27312/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (28545/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (29779/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (31015/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (32247/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (33477/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (34717/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (35959/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (37197/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (38428/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (39670/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (40911/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (42155/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (43383/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (44621/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (45861/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (47102/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (48291/50000)
# TEST : Loss: (0.3844) | Acc: (88.00%) (8876/10000)
percent tensor([0.5681, 0.5684, 0.5765, 0.5705, 0.5863, 0.5714, 0.5760, 0.5788, 0.5702,
        0.5685, 0.5661, 0.5747, 0.5684, 0.5591, 0.5707, 0.5660],
       device='cuda:0') torch.Size([16])
percent tensor([0.5404, 0.5409, 0.5334, 0.5395, 0.5356, 0.5434, 0.5396, 0.5368, 0.5388,
        0.5389, 0.5391, 0.5383, 0.5403, 0.5378, 0.5427, 0.5413],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.5671, 0.5241, 0.5303, 0.5539, 0.5690, 0.5561, 0.5154, 0.5529,
        0.5513, 0.5600, 0.5572, 0.5687, 0.5447, 0.5624, 0.5407],
       device='cuda:0') torch.Size([16])
percent tensor([0.6560, 0.6759, 0.6259, 0.6271, 0.6284, 0.6247, 0.6719, 0.6215, 0.6518,
        0.6746, 0.6976, 0.6577, 0.6683, 0.6750, 0.6695, 0.6498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5793, 0.6024, 0.7208, 0.7982, 0.6927, 0.7448, 0.6115, 0.5784, 0.7501,
        0.6061, 0.7065, 0.7228, 0.6307, 0.8034, 0.5742, 0.6158],
       device='cuda:0') torch.Size([16])
percent tensor([0.6874, 0.6467, 0.7307, 0.7362, 0.7455, 0.6947, 0.7168, 0.7381, 0.6956,
        0.6482, 0.6511, 0.7205, 0.6118, 0.6784, 0.7091, 0.6822],
       device='cuda:0') torch.Size([16])
percent tensor([0.5634, 0.5813, 0.7568, 0.6119, 0.7168, 0.7859, 0.5814, 0.5793, 0.5922,
        0.5325, 0.6082, 0.4473, 0.5446, 0.5139, 0.5272, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9998, 1.0000, 0.9999, 0.9996, 0.9993, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 160 | Batch_idx: 0 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (2602/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (3830/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (5060/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (6285/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (7520/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (8747/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (9979/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (11207/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (12437/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (13675/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (14905/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (16136/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (17363/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (18589/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (19819/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (21045/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (22283/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (23506/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (24735/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (25956/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (27191/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (28428/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (29659/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (30880/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (32102/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (33333/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (34572/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (35796/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (37027/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (38251/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (39474/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (40711/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (41933/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (96.00%) (43155/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (44387/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (45616/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (46840/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (48030/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_160.pth.tar'
# TEST : Loss: (0.4090) | Acc: (88.00%) (8823/10000)
percent tensor([0.5666, 0.5685, 0.5741, 0.5704, 0.5845, 0.5714, 0.5751, 0.5789, 0.5696,
        0.5679, 0.5658, 0.5720, 0.5678, 0.5603, 0.5708, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.5403, 0.5330, 0.5382, 0.5356, 0.5424, 0.5390, 0.5369, 0.5391,
        0.5389, 0.5389, 0.5377, 0.5403, 0.5375, 0.5420, 0.5410],
       device='cuda:0') torch.Size([16])
percent tensor([0.5279, 0.5661, 0.5330, 0.5361, 0.5620, 0.5739, 0.5573, 0.5197, 0.5567,
        0.5559, 0.5598, 0.5647, 0.5679, 0.5435, 0.5646, 0.5431],
       device='cuda:0') torch.Size([16])
percent tensor([0.6584, 0.6752, 0.6271, 0.6251, 0.6247, 0.6208, 0.6723, 0.6216, 0.6514,
        0.6752, 0.6952, 0.6577, 0.6684, 0.6730, 0.6668, 0.6477],
       device='cuda:0') torch.Size([16])
percent tensor([0.5737, 0.6033, 0.7152, 0.8088, 0.7080, 0.7339, 0.5975, 0.5798, 0.7375,
        0.5997, 0.6984, 0.7116, 0.6077, 0.8007, 0.5733, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.6844, 0.6379, 0.7224, 0.7364, 0.7491, 0.6932, 0.7169, 0.7358, 0.6964,
        0.6453, 0.6422, 0.7254, 0.6138, 0.6834, 0.7064, 0.6800],
       device='cuda:0') torch.Size([16])
percent tensor([0.5804, 0.6003, 0.7174, 0.6020, 0.7576, 0.7950, 0.6051, 0.5455, 0.6271,
        0.5737, 0.6123, 0.4776, 0.5330, 0.5479, 0.5416, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9997, 0.9993, 0.9999, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9995, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.1001, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.3105, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(834.0597, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1512.8674, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(486.2790, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2264.5208, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4274.3413, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1357.8521, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6217.3521, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11639.8311, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3838.5833, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16250.7119, device='cuda:0', grad_fn=<NormBackward0>)


Files already downloaded and verified
USE 1 GPUs!
=> loading checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_160.pth.tar'
Epoch: 161 | Batch_idx: 0 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (2599/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (3824/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (5066/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (6297/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (7537/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (8772/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (10010/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (11243/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (12466/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (13685/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (14916/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (16148/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (17393/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (18623/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (19854/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (21090/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (22319/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (23554/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (24780/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (26013/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (27250/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (28479/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (29701/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (30920/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (32152/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (33381/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (34608/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (35828/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (37053/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (38277/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (39504/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (40735/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (41944/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (43179/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (44404/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (45632/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (46851/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (48030/50000)
# TEST : Loss: (0.4262) | Acc: (87.00%) (8778/10000)
percent tensor([0.5678, 0.5669, 0.5763, 0.5708, 0.5866, 0.5710, 0.5755, 0.5786, 0.5696,
        0.5677, 0.5653, 0.5745, 0.5680, 0.5585, 0.5696, 0.5652],
       device='cuda:0') torch.Size([16])
percent tensor([0.5403, 0.5400, 0.5330, 0.5387, 0.5359, 0.5426, 0.5389, 0.5366, 0.5395,
        0.5385, 0.5392, 0.5377, 0.5407, 0.5365, 0.5420, 0.5409],
       device='cuda:0') torch.Size([16])
percent tensor([0.5325, 0.5633, 0.5289, 0.5387, 0.5613, 0.5746, 0.5543, 0.5179, 0.5549,
        0.5493, 0.5584, 0.5610, 0.5685, 0.5401, 0.5655, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.6564, 0.6798, 0.6271, 0.6243, 0.6250, 0.6251, 0.6716, 0.6233, 0.6521,
        0.6764, 0.6977, 0.6538, 0.6658, 0.6766, 0.6700, 0.6498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5729, 0.5922, 0.7324, 0.8020, 0.7106, 0.7318, 0.6038, 0.5878, 0.7466,
        0.6018, 0.6974, 0.7257, 0.6146, 0.7991, 0.5616, 0.6193],
       device='cuda:0') torch.Size([16])
percent tensor([0.6815, 0.6326, 0.7215, 0.7337, 0.7442, 0.6930, 0.7161, 0.7397, 0.6817,
        0.6472, 0.6358, 0.7174, 0.5980, 0.6718, 0.7088, 0.6767],
       device='cuda:0') torch.Size([16])
percent tensor([0.5523, 0.5970, 0.6778, 0.5561, 0.7467, 0.7642, 0.5896, 0.5597, 0.5615,
        0.5519, 0.6108, 0.4849, 0.5479, 0.5056, 0.4995, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9993, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9994, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 162 | Batch_idx: 0 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (2573/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (3805/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (5024/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (6260/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (95.00%) (7492/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (8709/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (9950/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (11180/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (12425/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (13657/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (14901/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (16135/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (17360/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (18599/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (19829/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (21063/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (22298/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (23536/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (24764/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (26004/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (27222/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (28454/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (29682/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (30912/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (32130/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (33349/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (34567/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (35793/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (37022/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (38247/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (39476/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (40696/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (41937/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (43173/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (44412/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (45657/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (46884/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (48068/50000)
# TEST : Loss: (0.4674) | Acc: (86.00%) (8642/10000)
percent tensor([0.5683, 0.5668, 0.5785, 0.5721, 0.5881, 0.5729, 0.5757, 0.5794, 0.5699,
        0.5682, 0.5652, 0.5756, 0.5678, 0.5578, 0.5707, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.5403, 0.5402, 0.5333, 0.5390, 0.5355, 0.5426, 0.5389, 0.5367, 0.5390,
        0.5387, 0.5390, 0.5378, 0.5407, 0.5365, 0.5419, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5335, 0.5686, 0.5311, 0.5363, 0.5644, 0.5787, 0.5592, 0.5193, 0.5576,
        0.5522, 0.5600, 0.5622, 0.5707, 0.5504, 0.5672, 0.5447],
       device='cuda:0') torch.Size([16])
percent tensor([0.6528, 0.6749, 0.6247, 0.6243, 0.6267, 0.6221, 0.6687, 0.6191, 0.6487,
        0.6746, 0.6930, 0.6546, 0.6654, 0.6699, 0.6661, 0.6487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5792, 0.5972, 0.7366, 0.8066, 0.7012, 0.7191, 0.5946, 0.5789, 0.7344,
        0.6008, 0.6991, 0.7274, 0.6236, 0.8013, 0.5639, 0.6334],
       device='cuda:0') torch.Size([16])
percent tensor([0.6843, 0.6410, 0.7227, 0.7342, 0.7348, 0.6890, 0.7040, 0.7262, 0.6879,
        0.6488, 0.6409, 0.7219, 0.6184, 0.6785, 0.7043, 0.6814],
       device='cuda:0') torch.Size([16])
percent tensor([0.5964, 0.6393, 0.6922, 0.6176, 0.7588, 0.7884, 0.6189, 0.5648, 0.6242,
        0.6279, 0.6555, 0.5032, 0.5668, 0.6052, 0.5584, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9998, 0.9997, 0.9995, 0.9998, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9997, 0.9992, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 163 | Batch_idx: 0 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (2588/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (3833/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (5067/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (6295/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (7532/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (8764/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (9997/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (11226/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (12470/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (13714/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (14954/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (16196/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (17423/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (18651/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (19889/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (21126/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (22360/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (23588/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (24816/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (26056/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (27298/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (28522/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (29753/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (30985/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (32217/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (33448/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (34683/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (35901/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (37123/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (38343/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (39575/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (40812/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (42043/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (43285/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (44517/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (45744/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (46971/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (48157/50000)
# TEST : Loss: (0.4332) | Acc: (87.00%) (8748/10000)
percent tensor([0.5672, 0.5661, 0.5777, 0.5702, 0.5877, 0.5702, 0.5755, 0.5789, 0.5705,
        0.5684, 0.5655, 0.5749, 0.5676, 0.5575, 0.5691, 0.5652],
       device='cuda:0') torch.Size([16])
percent tensor([0.5401, 0.5405, 0.5339, 0.5392, 0.5361, 0.5423, 0.5394, 0.5375, 0.5399,
        0.5393, 0.5396, 0.5384, 0.5409, 0.5375, 0.5423, 0.5413],
       device='cuda:0') torch.Size([16])
percent tensor([0.5297, 0.5608, 0.5341, 0.5388, 0.5615, 0.5749, 0.5550, 0.5208, 0.5587,
        0.5498, 0.5583, 0.5616, 0.5670, 0.5434, 0.5617, 0.5426],
       device='cuda:0') torch.Size([16])
percent tensor([0.6533, 0.6754, 0.6212, 0.6195, 0.6221, 0.6194, 0.6706, 0.6175, 0.6487,
        0.6745, 0.6955, 0.6515, 0.6613, 0.6736, 0.6684, 0.6448],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.6035, 0.7319, 0.8219, 0.7261, 0.7571, 0.6068, 0.5960, 0.7594,
        0.6031, 0.7139, 0.7369, 0.6302, 0.8140, 0.5738, 0.6532],
       device='cuda:0') torch.Size([16])
percent tensor([0.6863, 0.6500, 0.7253, 0.7339, 0.7445, 0.6789, 0.7168, 0.7374, 0.7025,
        0.6517, 0.6503, 0.7322, 0.6186, 0.6819, 0.7097, 0.6785],
       device='cuda:0') torch.Size([16])
percent tensor([0.5796, 0.6226, 0.6846, 0.6331, 0.7467, 0.7786, 0.5946, 0.5351, 0.6002,
        0.5948, 0.6379, 0.4447, 0.5589, 0.5392, 0.5097, 0.5521],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9996, 0.9994, 0.9999, 0.9998, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9996, 0.9997, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 164 | Batch_idx: 0 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (2594/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (3828/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (5071/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (6315/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (7543/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (8787/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (10016/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (11258/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (12499/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (13731/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (14971/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (16209/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (17435/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (18669/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (19907/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (21128/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (22360/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (23595/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (24831/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (26066/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (27300/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (28530/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (29770/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (31003/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (32246/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (33482/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (34710/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (35942/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (37177/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (38401/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (39632/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (40861/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (42100/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (43336/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (44571/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (45798/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (47034/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (48221/50000)
# TEST : Loss: (0.4574) | Acc: (87.00%) (8741/10000)
percent tensor([0.5678, 0.5666, 0.5788, 0.5710, 0.5884, 0.5714, 0.5759, 0.5799, 0.5701,
        0.5684, 0.5651, 0.5756, 0.5677, 0.5576, 0.5697, 0.5656],
       device='cuda:0') torch.Size([16])
percent tensor([0.5398, 0.5403, 0.5320, 0.5380, 0.5356, 0.5417, 0.5389, 0.5364, 0.5397,
        0.5387, 0.5389, 0.5374, 0.5409, 0.5373, 0.5415, 0.5406],
       device='cuda:0') torch.Size([16])
percent tensor([0.5318, 0.5601, 0.5307, 0.5343, 0.5663, 0.5742, 0.5531, 0.5181, 0.5619,
        0.5470, 0.5566, 0.5595, 0.5700, 0.5432, 0.5607, 0.5406],
       device='cuda:0') torch.Size([16])
percent tensor([0.6531, 0.6762, 0.6247, 0.6242, 0.6227, 0.6250, 0.6682, 0.6182, 0.6455,
        0.6721, 0.6950, 0.6503, 0.6616, 0.6728, 0.6671, 0.6499],
       device='cuda:0') torch.Size([16])
percent tensor([0.5783, 0.5940, 0.7408, 0.8177, 0.7191, 0.7497, 0.6022, 0.5817, 0.7487,
        0.5997, 0.7014, 0.7256, 0.6268, 0.8103, 0.5660, 0.6388],
       device='cuda:0') torch.Size([16])
percent tensor([0.6856, 0.6490, 0.7308, 0.7367, 0.7442, 0.6825, 0.7251, 0.7393, 0.6948,
        0.6618, 0.6483, 0.7261, 0.6182, 0.6852, 0.7077, 0.6833],
       device='cuda:0') torch.Size([16])
percent tensor([0.5789, 0.6261, 0.7449, 0.6447, 0.7829, 0.7856, 0.6608, 0.5774, 0.6510,
        0.6159, 0.6745, 0.5024, 0.5947, 0.5730, 0.5528, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9998, 0.9996, 0.9995, 0.9999, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9994, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 165 | Batch_idx: 0 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 165 | Batch_idx: 10 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 165 | Batch_idx: 20 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (96.00%) (2587/2688)
Epoch: 165 | Batch_idx: 30 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (96.00%) (3812/3968)
Epoch: 165 | Batch_idx: 40 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (5019/5248)
Epoch: 165 | Batch_idx: 50 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (6227/6528)
Epoch: 165 | Batch_idx: 60 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (7440/7808)
Epoch: 165 | Batch_idx: 70 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (8653/9088)
Epoch: 165 | Batch_idx: 80 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (9877/10368)
Epoch: 165 | Batch_idx: 90 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (11094/11648)
Epoch: 165 | Batch_idx: 100 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (12305/12928)
Epoch: 165 | Batch_idx: 110 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (13518/14208)
Epoch: 165 | Batch_idx: 120 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (14723/15488)
Epoch: 165 | Batch_idx: 130 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (15947/16768)
Epoch: 165 | Batch_idx: 140 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (17172/18048)
Epoch: 165 | Batch_idx: 150 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (18386/19328)
Epoch: 165 | Batch_idx: 160 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (19600/20608)
Epoch: 165 | Batch_idx: 170 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (20814/21888)
Epoch: 165 | Batch_idx: 180 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (22033/23168)
Epoch: 165 | Batch_idx: 190 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (23252/24448)
Epoch: 165 | Batch_idx: 200 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (24483/25728)
Epoch: 165 | Batch_idx: 210 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (25703/27008)
Epoch: 165 | Batch_idx: 220 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (26931/28288)
Epoch: 165 | Batch_idx: 230 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (28155/29568)
Epoch: 165 | Batch_idx: 240 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (29388/30848)
Epoch: 165 | Batch_idx: 250 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (30616/32128)
Epoch: 165 | Batch_idx: 260 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (31834/33408)
Epoch: 165 | Batch_idx: 270 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (33052/34688)
Epoch: 165 | Batch_idx: 280 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (34271/35968)
Epoch: 165 | Batch_idx: 290 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (35495/37248)
Epoch: 165 | Batch_idx: 300 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (36714/38528)
Epoch: 165 | Batch_idx: 310 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (37935/39808)
Epoch: 165 | Batch_idx: 320 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (39158/41088)
Epoch: 165 | Batch_idx: 330 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (40380/42368)
Epoch: 165 | Batch_idx: 340 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (41598/43648)
Epoch: 165 | Batch_idx: 350 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (42810/44928)
Epoch: 165 | Batch_idx: 360 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (44035/46208)
Epoch: 165 | Batch_idx: 370 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (45243/47488)
Epoch: 165 | Batch_idx: 380 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (46463/48768)
Epoch: 165 | Batch_idx: 390 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (47634/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_165.pth.tar'
# TEST : Loss: (0.4273) | Acc: (87.00%) (8776/10000)
percent tensor([0.5678, 0.5657, 0.5778, 0.5716, 0.5880, 0.5707, 0.5753, 0.5796, 0.5701,
        0.5676, 0.5642, 0.5749, 0.5675, 0.5579, 0.5689, 0.5652],
       device='cuda:0') torch.Size([16])
percent tensor([0.5352, 0.5350, 0.5282, 0.5345, 0.5316, 0.5377, 0.5335, 0.5319, 0.5348,
        0.5337, 0.5338, 0.5327, 0.5354, 0.5329, 0.5369, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.5279, 0.5541, 0.5310, 0.5351, 0.5655, 0.5648, 0.5494, 0.5202, 0.5562,
        0.5399, 0.5454, 0.5571, 0.5644, 0.5355, 0.5537, 0.5345],
       device='cuda:0') torch.Size([16])
percent tensor([0.6580, 0.6819, 0.6277, 0.6234, 0.6268, 0.6295, 0.6734, 0.6254, 0.6496,
        0.6722, 0.6955, 0.6517, 0.6679, 0.6748, 0.6739, 0.6531],
       device='cuda:0') torch.Size([16])
percent tensor([0.5849, 0.6055, 0.7368, 0.8148, 0.7282, 0.7554, 0.6144, 0.5891, 0.7480,
        0.6094, 0.7085, 0.7144, 0.6318, 0.8125, 0.5812, 0.6446],
       device='cuda:0') torch.Size([16])
percent tensor([0.6844, 0.6501, 0.7248, 0.7308, 0.7411, 0.6849, 0.7212, 0.7337, 0.6951,
        0.6576, 0.6458, 0.7207, 0.6178, 0.6871, 0.7031, 0.6829],
       device='cuda:0') torch.Size([16])
percent tensor([0.5736, 0.6301, 0.7220, 0.6330, 0.7760, 0.7975, 0.6339, 0.5593, 0.6227,
        0.6090, 0.6772, 0.4888, 0.5753, 0.5482, 0.5346, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9997, 0.9992, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 166 | Batch_idx: 0 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 166 | Batch_idx: 10 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 166 | Batch_idx: 20 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (2582/2688)
Epoch: 166 | Batch_idx: 30 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (3792/3968)
Epoch: 166 | Batch_idx: 40 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (5011/5248)
Epoch: 166 | Batch_idx: 50 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (6231/6528)
Epoch: 166 | Batch_idx: 60 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (7458/7808)
Epoch: 166 | Batch_idx: 70 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (8677/9088)
Epoch: 166 | Batch_idx: 80 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (9897/10368)
Epoch: 166 | Batch_idx: 90 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (11129/11648)
Epoch: 166 | Batch_idx: 100 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (12357/12928)
Epoch: 166 | Batch_idx: 110 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (13585/14208)
Epoch: 166 | Batch_idx: 120 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (14818/15488)
Epoch: 166 | Batch_idx: 130 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (16039/16768)
Epoch: 166 | Batch_idx: 140 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (17268/18048)
Epoch: 166 | Batch_idx: 150 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (18492/19328)
Epoch: 166 | Batch_idx: 160 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (19709/20608)
Epoch: 166 | Batch_idx: 170 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (20933/21888)
Epoch: 166 | Batch_idx: 180 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (22172/23168)
Epoch: 166 | Batch_idx: 190 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (23401/24448)
Epoch: 166 | Batch_idx: 200 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (24627/25728)
Epoch: 166 | Batch_idx: 210 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (25860/27008)
Epoch: 166 | Batch_idx: 220 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (27086/28288)
Epoch: 166 | Batch_idx: 230 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (28322/29568)
Epoch: 166 | Batch_idx: 240 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (29561/30848)
Epoch: 166 | Batch_idx: 250 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (30785/32128)
Epoch: 166 | Batch_idx: 260 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (32018/33408)
Epoch: 166 | Batch_idx: 270 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (33251/34688)
Epoch: 166 | Batch_idx: 280 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (34480/35968)
Epoch: 166 | Batch_idx: 290 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (95.00%) (35721/37248)
Epoch: 166 | Batch_idx: 300 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (36939/38528)
Epoch: 166 | Batch_idx: 310 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (38156/39808)
Epoch: 166 | Batch_idx: 320 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (39384/41088)
Epoch: 166 | Batch_idx: 330 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (95.00%) (40618/42368)
Epoch: 166 | Batch_idx: 340 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (95.00%) (41841/43648)
Epoch: 166 | Batch_idx: 350 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (43069/44928)
Epoch: 166 | Batch_idx: 360 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (95.00%) (44307/46208)
Epoch: 166 | Batch_idx: 370 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (45537/47488)
Epoch: 166 | Batch_idx: 380 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (46764/48768)
Epoch: 166 | Batch_idx: 390 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (47948/50000)
# TEST : Loss: (0.4131) | Acc: (88.00%) (8810/10000)
percent tensor([0.5667, 0.5640, 0.5769, 0.5706, 0.5869, 0.5693, 0.5740, 0.5787, 0.5691,
        0.5662, 0.5627, 0.5736, 0.5662, 0.5567, 0.5674, 0.5640],
       device='cuda:0') torch.Size([16])
percent tensor([0.5336, 0.5330, 0.5271, 0.5336, 0.5302, 0.5363, 0.5316, 0.5304, 0.5330,
        0.5319, 0.5320, 0.5310, 0.5333, 0.5312, 0.5353, 0.5346],
       device='cuda:0') torch.Size([16])
percent tensor([0.5219, 0.5488, 0.5288, 0.5317, 0.5616, 0.5570, 0.5454, 0.5190, 0.5495,
        0.5341, 0.5379, 0.5518, 0.5585, 0.5300, 0.5475, 0.5285],
       device='cuda:0') torch.Size([16])
percent tensor([0.6654, 0.6882, 0.6344, 0.6286, 0.6328, 0.6356, 0.6805, 0.6338, 0.6554,
        0.6767, 0.6991, 0.6582, 0.6758, 0.6785, 0.6811, 0.6593],
       device='cuda:0') torch.Size([16])
percent tensor([0.5793, 0.5981, 0.7296, 0.8125, 0.7274, 0.7498, 0.6075, 0.5841, 0.7420,
        0.6029, 0.7017, 0.7088, 0.6220, 0.8066, 0.5746, 0.6390],
       device='cuda:0') torch.Size([16])
percent tensor([0.6880, 0.6542, 0.7291, 0.7318, 0.7442, 0.6915, 0.7234, 0.7371, 0.6966,
        0.6595, 0.6477, 0.7224, 0.6186, 0.6887, 0.7066, 0.6872],
       device='cuda:0') torch.Size([16])
percent tensor([0.5871, 0.6476, 0.7302, 0.6364, 0.7791, 0.8065, 0.6515, 0.5681, 0.6294,
        0.6247, 0.6929, 0.4992, 0.5865, 0.5544, 0.5413, 0.5430],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9993, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 167 | Batch_idx: 0 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 167 | Batch_idx: 10 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 167 | Batch_idx: 20 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 167 | Batch_idx: 30 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 167 | Batch_idx: 40 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (5052/5248)
Epoch: 167 | Batch_idx: 50 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (6290/6528)
Epoch: 167 | Batch_idx: 60 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (7524/7808)
Epoch: 167 | Batch_idx: 70 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (8755/9088)
Epoch: 167 | Batch_idx: 80 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (9984/10368)
Epoch: 167 | Batch_idx: 90 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (11212/11648)
Epoch: 167 | Batch_idx: 100 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (12443/12928)
Epoch: 167 | Batch_idx: 110 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (13670/14208)
Epoch: 167 | Batch_idx: 120 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (14909/15488)
Epoch: 167 | Batch_idx: 130 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (16140/16768)
Epoch: 167 | Batch_idx: 140 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (17367/18048)
Epoch: 167 | Batch_idx: 150 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (18603/19328)
Epoch: 167 | Batch_idx: 160 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (19838/20608)
Epoch: 167 | Batch_idx: 170 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (21061/21888)
Epoch: 167 | Batch_idx: 180 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (22285/23168)
Epoch: 167 | Batch_idx: 190 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (23525/24448)
Epoch: 167 | Batch_idx: 200 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (24763/25728)
Epoch: 167 | Batch_idx: 210 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (25988/27008)
Epoch: 167 | Batch_idx: 220 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (27227/28288)
Epoch: 167 | Batch_idx: 230 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (28458/29568)
Epoch: 167 | Batch_idx: 240 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (29689/30848)
Epoch: 167 | Batch_idx: 250 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (30915/32128)
Epoch: 167 | Batch_idx: 260 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (32151/33408)
Epoch: 167 | Batch_idx: 270 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (33379/34688)
Epoch: 167 | Batch_idx: 280 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (34614/35968)
Epoch: 167 | Batch_idx: 290 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (35836/37248)
Epoch: 167 | Batch_idx: 300 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (37063/38528)
Epoch: 167 | Batch_idx: 310 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (38295/39808)
Epoch: 167 | Batch_idx: 320 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (39527/41088)
Epoch: 167 | Batch_idx: 330 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (40771/42368)
Epoch: 167 | Batch_idx: 340 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (41997/43648)
Epoch: 167 | Batch_idx: 350 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (43228/44928)
Epoch: 167 | Batch_idx: 360 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (44466/46208)
Epoch: 167 | Batch_idx: 370 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (45700/47488)
Epoch: 167 | Batch_idx: 380 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (46934/48768)
Epoch: 167 | Batch_idx: 390 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (48129/50000)
# TEST : Loss: (0.4018) | Acc: (88.00%) (8822/10000)
percent tensor([0.5681, 0.5652, 0.5787, 0.5722, 0.5891, 0.5707, 0.5756, 0.5805, 0.5707,
        0.5675, 0.5639, 0.5752, 0.5674, 0.5577, 0.5687, 0.5652],
       device='cuda:0') torch.Size([16])
percent tensor([0.5332, 0.5323, 0.5269, 0.5335, 0.5299, 0.5362, 0.5309, 0.5300, 0.5326,
        0.5314, 0.5315, 0.5305, 0.5327, 0.5307, 0.5351, 0.5341],
       device='cuda:0') torch.Size([16])
percent tensor([0.5251, 0.5531, 0.5329, 0.5350, 0.5656, 0.5607, 0.5510, 0.5236, 0.5537,
        0.5372, 0.5413, 0.5557, 0.5620, 0.5353, 0.5518, 0.5321],
       device='cuda:0') torch.Size([16])
percent tensor([0.6709, 0.6929, 0.6391, 0.6320, 0.6371, 0.6397, 0.6856, 0.6397, 0.6597,
        0.6798, 0.7019, 0.6629, 0.6819, 0.6815, 0.6866, 0.6638],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.5935, 0.7223, 0.8089, 0.7264, 0.7452, 0.6065, 0.5798, 0.7394,
        0.6016, 0.6996, 0.7053, 0.6152, 0.8081, 0.5718, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.6839, 0.6507, 0.7255, 0.7282, 0.7419, 0.6904, 0.7198, 0.7328, 0.6914,
        0.6545, 0.6433, 0.7177, 0.6124, 0.6857, 0.7031, 0.6839],
       device='cuda:0') torch.Size([16])
percent tensor([0.5764, 0.6461, 0.7283, 0.6367, 0.7791, 0.8119, 0.6445, 0.5596, 0.6172,
        0.6168, 0.6870, 0.4951, 0.5791, 0.5372, 0.5354, 0.5435],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9997, 0.9993, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 168 | Batch_idx: 0 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 168 | Batch_idx: 10 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 168 | Batch_idx: 20 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (95.00%) (2579/2688)
Epoch: 168 | Batch_idx: 30 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (3814/3968)
Epoch: 168 | Batch_idx: 40 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (5046/5248)
Epoch: 168 | Batch_idx: 50 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (6281/6528)
Epoch: 168 | Batch_idx: 60 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (7512/7808)
Epoch: 168 | Batch_idx: 70 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (8739/9088)
Epoch: 168 | Batch_idx: 80 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (9969/10368)
Epoch: 168 | Batch_idx: 90 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (11211/11648)
Epoch: 168 | Batch_idx: 100 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (12446/12928)
Epoch: 168 | Batch_idx: 110 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (13672/14208)
Epoch: 168 | Batch_idx: 120 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (14915/15488)
Epoch: 168 | Batch_idx: 130 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (16147/16768)
Epoch: 168 | Batch_idx: 140 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (17375/18048)
Epoch: 168 | Batch_idx: 150 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (18617/19328)
Epoch: 168 | Batch_idx: 160 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (19851/20608)
Epoch: 168 | Batch_idx: 170 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (21091/21888)
Epoch: 168 | Batch_idx: 180 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (22327/23168)
Epoch: 168 | Batch_idx: 190 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (23577/24448)
Epoch: 168 | Batch_idx: 200 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (24818/25728)
Epoch: 168 | Batch_idx: 210 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (26065/27008)
Epoch: 168 | Batch_idx: 220 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (27303/28288)
Epoch: 168 | Batch_idx: 230 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (28548/29568)
Epoch: 168 | Batch_idx: 240 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (29789/30848)
Epoch: 168 | Batch_idx: 250 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (31021/32128)
Epoch: 168 | Batch_idx: 260 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (32260/33408)
Epoch: 168 | Batch_idx: 270 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (33491/34688)
Epoch: 168 | Batch_idx: 280 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (34729/35968)
Epoch: 168 | Batch_idx: 290 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (35962/37248)
Epoch: 168 | Batch_idx: 300 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (37206/38528)
Epoch: 168 | Batch_idx: 310 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (38443/39808)
Epoch: 168 | Batch_idx: 320 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (39673/41088)
Epoch: 168 | Batch_idx: 330 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (40909/42368)
Epoch: 168 | Batch_idx: 340 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (42141/43648)
Epoch: 168 | Batch_idx: 350 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (43375/44928)
Epoch: 168 | Batch_idx: 360 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (44604/46208)
Epoch: 168 | Batch_idx: 370 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (45848/47488)
Epoch: 168 | Batch_idx: 380 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (47080/48768)
Epoch: 168 | Batch_idx: 390 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (48266/50000)
# TEST : Loss: (0.3966) | Acc: (88.00%) (8842/10000)
percent tensor([0.5676, 0.5642, 0.5782, 0.5719, 0.5884, 0.5706, 0.5748, 0.5799, 0.5699,
        0.5667, 0.5632, 0.5743, 0.5666, 0.5572, 0.5681, 0.5647],
       device='cuda:0') torch.Size([16])
percent tensor([0.5325, 0.5317, 0.5266, 0.5333, 0.5294, 0.5357, 0.5303, 0.5295, 0.5318,
        0.5308, 0.5307, 0.5299, 0.5318, 0.5302, 0.5346, 0.5335],
       device='cuda:0') torch.Size([16])
percent tensor([0.5235, 0.5506, 0.5334, 0.5359, 0.5644, 0.5590, 0.5493, 0.5240, 0.5499,
        0.5351, 0.5380, 0.5547, 0.5592, 0.5323, 0.5498, 0.5311],
       device='cuda:0') torch.Size([16])
percent tensor([0.6627, 0.6840, 0.6322, 0.6243, 0.6294, 0.6313, 0.6774, 0.6326, 0.6519,
        0.6702, 0.6915, 0.6547, 0.6743, 0.6715, 0.6777, 0.6549],
       device='cuda:0') torch.Size([16])
percent tensor([0.5700, 0.5851, 0.7149, 0.8069, 0.7223, 0.7384, 0.6007, 0.5760, 0.7332,
        0.5933, 0.6937, 0.6970, 0.6049, 0.8036, 0.5661, 0.6291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6803, 0.6465, 0.7224, 0.7236, 0.7395, 0.6905, 0.7151, 0.7299, 0.6875,
        0.6499, 0.6382, 0.7108, 0.6062, 0.6807, 0.6985, 0.6811],
       device='cuda:0') torch.Size([16])
percent tensor([0.5861, 0.6648, 0.7393, 0.6469, 0.7843, 0.8154, 0.6590, 0.5713, 0.6280,
        0.6283, 0.7040, 0.5207, 0.6039, 0.5460, 0.5483, 0.5551],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9998, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9993, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 169 | Batch_idx: 0 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 169 | Batch_idx: 10 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 169 | Batch_idx: 20 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (2582/2688)
Epoch: 169 | Batch_idx: 30 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (3826/3968)
Epoch: 169 | Batch_idx: 40 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (5053/5248)
Epoch: 169 | Batch_idx: 50 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (6286/6528)
Epoch: 169 | Batch_idx: 60 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (7526/7808)
Epoch: 169 | Batch_idx: 70 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (8771/9088)
Epoch: 169 | Batch_idx: 80 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (10009/10368)
Epoch: 169 | Batch_idx: 90 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (11249/11648)
Epoch: 169 | Batch_idx: 100 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (12484/12928)
Epoch: 169 | Batch_idx: 110 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (13727/14208)
Epoch: 169 | Batch_idx: 120 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (14964/15488)
Epoch: 169 | Batch_idx: 130 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (16195/16768)
Epoch: 169 | Batch_idx: 140 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (17429/18048)
Epoch: 169 | Batch_idx: 150 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (18671/19328)
Epoch: 169 | Batch_idx: 160 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (19910/20608)
Epoch: 169 | Batch_idx: 170 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (21126/21888)
Epoch: 169 | Batch_idx: 180 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (22371/23168)
Epoch: 169 | Batch_idx: 190 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (23611/24448)
Epoch: 169 | Batch_idx: 200 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (24852/25728)
Epoch: 169 | Batch_idx: 210 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (26085/27008)
Epoch: 169 | Batch_idx: 220 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (27317/28288)
Epoch: 169 | Batch_idx: 230 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (28553/29568)
Epoch: 169 | Batch_idx: 240 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (29786/30848)
Epoch: 169 | Batch_idx: 250 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (31023/32128)
Epoch: 169 | Batch_idx: 260 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (32266/33408)
Epoch: 169 | Batch_idx: 270 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (33506/34688)
Epoch: 169 | Batch_idx: 280 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (34749/35968)
Epoch: 169 | Batch_idx: 290 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (35997/37248)
Epoch: 169 | Batch_idx: 300 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (37246/38528)
Epoch: 169 | Batch_idx: 310 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (38475/39808)
Epoch: 169 | Batch_idx: 320 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (39707/41088)
Epoch: 169 | Batch_idx: 330 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (40942/42368)
Epoch: 169 | Batch_idx: 340 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (42180/43648)
Epoch: 169 | Batch_idx: 350 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (43422/44928)
Epoch: 169 | Batch_idx: 360 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (44646/46208)
Epoch: 169 | Batch_idx: 370 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (45897/47488)
Epoch: 169 | Batch_idx: 380 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (47135/48768)
Epoch: 169 | Batch_idx: 390 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (48326/50000)
# TEST : Loss: (0.3942) | Acc: (88.00%) (8850/10000)
percent tensor([0.5714, 0.5680, 0.5823, 0.5759, 0.5931, 0.5744, 0.5789, 0.5841, 0.5738,
        0.5704, 0.5669, 0.5783, 0.5704, 0.5605, 0.5721, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.5335, 0.5325, 0.5275, 0.5342, 0.5304, 0.5366, 0.5312, 0.5303, 0.5326,
        0.5315, 0.5316, 0.5307, 0.5327, 0.5309, 0.5357, 0.5344],
       device='cuda:0') torch.Size([16])
percent tensor([0.5223, 0.5506, 0.5344, 0.5368, 0.5671, 0.5594, 0.5503, 0.5255, 0.5502,
        0.5341, 0.5368, 0.5550, 0.5585, 0.5323, 0.5503, 0.5305],
       device='cuda:0') torch.Size([16])
percent tensor([0.6663, 0.6874, 0.6354, 0.6272, 0.6327, 0.6343, 0.6809, 0.6369, 0.6551,
        0.6729, 0.6938, 0.6585, 0.6783, 0.6739, 0.6814, 0.6581],
       device='cuda:0') torch.Size([16])
percent tensor([0.5699, 0.5849, 0.7196, 0.8081, 0.7279, 0.7378, 0.6018, 0.5763, 0.7360,
        0.5963, 0.6948, 0.6995, 0.6031, 0.8050, 0.5638, 0.6312],
       device='cuda:0') torch.Size([16])
percent tensor([0.6798, 0.6463, 0.7209, 0.7210, 0.7382, 0.6918, 0.7143, 0.7291, 0.6852,
        0.6480, 0.6372, 0.7093, 0.6036, 0.6806, 0.6982, 0.6809],
       device='cuda:0') torch.Size([16])
percent tensor([0.5785, 0.6661, 0.7310, 0.6420, 0.7784, 0.8099, 0.6547, 0.5620, 0.6176,
        0.6276, 0.6983, 0.5198, 0.5993, 0.5376, 0.5476, 0.5463],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9994, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 170 | Batch_idx: 0 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 170 | Batch_idx: 10 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 170 | Batch_idx: 20 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (2603/2688)
Epoch: 170 | Batch_idx: 30 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (3837/3968)
Epoch: 170 | Batch_idx: 40 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (5075/5248)
Epoch: 170 | Batch_idx: 50 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (6295/6528)
Epoch: 170 | Batch_idx: 60 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (7529/7808)
Epoch: 170 | Batch_idx: 70 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (8775/9088)
Epoch: 170 | Batch_idx: 80 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (10000/10368)
Epoch: 170 | Batch_idx: 90 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (11242/11648)
Epoch: 170 | Batch_idx: 100 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (12462/12928)
Epoch: 170 | Batch_idx: 110 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (13709/14208)
Epoch: 170 | Batch_idx: 120 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (14944/15488)
Epoch: 170 | Batch_idx: 130 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (16171/16768)
Epoch: 170 | Batch_idx: 140 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (17394/18048)
Epoch: 170 | Batch_idx: 150 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (18623/19328)
Epoch: 170 | Batch_idx: 160 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (19864/20608)
Epoch: 170 | Batch_idx: 170 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (21099/21888)
Epoch: 170 | Batch_idx: 180 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (22324/23168)
Epoch: 170 | Batch_idx: 190 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (23559/24448)
Epoch: 170 | Batch_idx: 200 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (24802/25728)
Epoch: 170 | Batch_idx: 210 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (26032/27008)
Epoch: 170 | Batch_idx: 220 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (27259/28288)
Epoch: 170 | Batch_idx: 230 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (28501/29568)
Epoch: 170 | Batch_idx: 240 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (29742/30848)
Epoch: 170 | Batch_idx: 250 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (30980/32128)
Epoch: 170 | Batch_idx: 260 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (32201/33408)
Epoch: 170 | Batch_idx: 270 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (33436/34688)
Epoch: 170 | Batch_idx: 280 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (34667/35968)
Epoch: 170 | Batch_idx: 290 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (35903/37248)
Epoch: 170 | Batch_idx: 300 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (37131/38528)
Epoch: 170 | Batch_idx: 310 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (38373/39808)
Epoch: 170 | Batch_idx: 320 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (39599/41088)
Epoch: 170 | Batch_idx: 330 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (40836/42368)
Epoch: 170 | Batch_idx: 340 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (42067/43648)
Epoch: 170 | Batch_idx: 350 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (43290/44928)
Epoch: 170 | Batch_idx: 360 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (44522/46208)
Epoch: 170 | Batch_idx: 370 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (45755/47488)
Epoch: 170 | Batch_idx: 380 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (46989/48768)
Epoch: 170 | Batch_idx: 390 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (48181/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_170.pth.tar'
# TEST : Loss: (0.4541) | Acc: (87.00%) (8728/10000)
percent tensor([0.5705, 0.5685, 0.5811, 0.5750, 0.5919, 0.5747, 0.5787, 0.5831, 0.5727,
        0.5701, 0.5668, 0.5769, 0.5699, 0.5608, 0.5727, 0.5687],
       device='cuda:0') torch.Size([16])
percent tensor([0.5337, 0.5312, 0.5290, 0.5344, 0.5302, 0.5378, 0.5306, 0.5305, 0.5325,
        0.5314, 0.5315, 0.5313, 0.5323, 0.5304, 0.5356, 0.5347],
       device='cuda:0') torch.Size([16])
percent tensor([0.5178, 0.5498, 0.5320, 0.5325, 0.5584, 0.5602, 0.5503, 0.5216, 0.5451,
        0.5373, 0.5378, 0.5527, 0.5538, 0.5360, 0.5496, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.6678, 0.6875, 0.6376, 0.6255, 0.6336, 0.6278, 0.6814, 0.6352, 0.6585,
        0.6744, 0.6960, 0.6598, 0.6804, 0.6709, 0.6787, 0.6566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5613, 0.5672, 0.7011, 0.7961, 0.7182, 0.7260, 0.5928, 0.5701, 0.7224,
        0.5832, 0.6597, 0.6867, 0.5814, 0.7945, 0.5448, 0.6195],
       device='cuda:0') torch.Size([16])
percent tensor([0.6806, 0.6343, 0.7126, 0.7078, 0.7341, 0.6845, 0.7053, 0.7245, 0.6720,
        0.6426, 0.6306, 0.6886, 0.6027, 0.6724, 0.6948, 0.6803],
       device='cuda:0') torch.Size([16])
percent tensor([0.5927, 0.6223, 0.7379, 0.6435, 0.7856, 0.8017, 0.6713, 0.5697, 0.6420,
        0.6691, 0.6847, 0.5300, 0.5903, 0.5601, 0.5357, 0.5660],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9997, 0.9994, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.3000, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.7216, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(836.4363, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1511.5278, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(484.5895, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2269.0398, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4272.1973, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1352.8096, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6228.4385, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11605.7744, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3823.7312, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16186.2324, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 171 | Batch_idx: 0 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 171 | Batch_idx: 10 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 171 | Batch_idx: 20 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (2611/2688)
Epoch: 171 | Batch_idx: 30 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (3851/3968)
Epoch: 171 | Batch_idx: 40 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (97.00%) (5094/5248)
Epoch: 171 | Batch_idx: 50 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (6332/6528)
Epoch: 171 | Batch_idx: 60 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (7567/7808)
Epoch: 171 | Batch_idx: 70 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (8802/9088)
Epoch: 171 | Batch_idx: 80 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (10047/10368)
Epoch: 171 | Batch_idx: 90 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (11288/11648)
Epoch: 171 | Batch_idx: 100 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (12518/12928)
Epoch: 171 | Batch_idx: 110 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (13752/14208)
Epoch: 171 | Batch_idx: 120 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (14981/15488)
Epoch: 171 | Batch_idx: 130 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (16217/16768)
Epoch: 171 | Batch_idx: 140 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (17447/18048)
Epoch: 171 | Batch_idx: 150 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (18679/19328)
Epoch: 171 | Batch_idx: 160 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (19923/20608)
Epoch: 171 | Batch_idx: 170 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (21161/21888)
Epoch: 171 | Batch_idx: 180 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (22407/23168)
Epoch: 171 | Batch_idx: 190 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (23643/24448)
Epoch: 171 | Batch_idx: 200 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (24881/25728)
Epoch: 171 | Batch_idx: 210 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (26121/27008)
Epoch: 171 | Batch_idx: 220 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (27361/28288)
Epoch: 171 | Batch_idx: 230 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (28601/29568)
Epoch: 171 | Batch_idx: 240 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (29832/30848)
Epoch: 171 | Batch_idx: 250 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (31072/32128)
Epoch: 171 | Batch_idx: 260 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (32303/33408)
Epoch: 171 | Batch_idx: 270 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (33540/34688)
Epoch: 171 | Batch_idx: 280 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (34783/35968)
Epoch: 171 | Batch_idx: 290 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (36008/37248)
Epoch: 171 | Batch_idx: 300 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (37240/38528)
Epoch: 171 | Batch_idx: 310 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (38485/39808)
Epoch: 171 | Batch_idx: 320 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (39724/41088)
Epoch: 171 | Batch_idx: 330 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (40946/42368)
Epoch: 171 | Batch_idx: 340 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (42170/43648)
Epoch: 171 | Batch_idx: 350 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (43392/44928)
Epoch: 171 | Batch_idx: 360 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (44627/46208)
Epoch: 171 | Batch_idx: 370 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (45859/47488)
Epoch: 171 | Batch_idx: 380 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (47085/48768)
Epoch: 171 | Batch_idx: 390 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (48262/50000)
# TEST : Loss: (0.4852) | Acc: (86.00%) (8651/10000)
percent tensor([0.5707, 0.5692, 0.5795, 0.5757, 0.5908, 0.5754, 0.5785, 0.5828, 0.5729,
        0.5700, 0.5670, 0.5761, 0.5702, 0.5633, 0.5732, 0.5694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5338, 0.5320, 0.5273, 0.5349, 0.5300, 0.5390, 0.5307, 0.5296, 0.5327,
        0.5314, 0.5322, 0.5302, 0.5327, 0.5310, 0.5366, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.5196, 0.5527, 0.5344, 0.5367, 0.5666, 0.5676, 0.5518, 0.5242, 0.5488,
        0.5372, 0.5388, 0.5546, 0.5539, 0.5339, 0.5565, 0.5322],
       device='cuda:0') torch.Size([16])
percent tensor([0.6710, 0.6882, 0.6384, 0.6314, 0.6325, 0.6304, 0.6845, 0.6427, 0.6567,
        0.6786, 0.6947, 0.6613, 0.6792, 0.6758, 0.6824, 0.6567],
       device='cuda:0') torch.Size([16])
percent tensor([0.5677, 0.5856, 0.7353, 0.8105, 0.7481, 0.7459, 0.6090, 0.5873, 0.7321,
        0.5858, 0.6598, 0.7109, 0.5879, 0.7911, 0.5581, 0.6163],
       device='cuda:0') torch.Size([16])
percent tensor([0.6913, 0.6435, 0.7224, 0.7233, 0.7395, 0.6890, 0.7061, 0.7348, 0.6808,
        0.6471, 0.6380, 0.7029, 0.6162, 0.6767, 0.7048, 0.6799],
       device='cuda:0') torch.Size([16])
percent tensor([0.5698, 0.5972, 0.7116, 0.6405, 0.7568, 0.7641, 0.6507, 0.5790, 0.6321,
        0.5850, 0.6647, 0.5263, 0.5634, 0.4871, 0.5585, 0.5279],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9995, 0.9998, 0.9998, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 172 | Batch_idx: 0 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 172 | Batch_idx: 10 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 172 | Batch_idx: 20 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (2602/2688)
Epoch: 172 | Batch_idx: 30 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (3840/3968)
Epoch: 172 | Batch_idx: 40 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (5074/5248)
Epoch: 172 | Batch_idx: 50 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (6309/6528)
Epoch: 172 | Batch_idx: 60 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (7545/7808)
Epoch: 172 | Batch_idx: 70 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (8788/9088)
Epoch: 172 | Batch_idx: 80 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (10042/10368)
Epoch: 172 | Batch_idx: 90 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (11277/11648)
Epoch: 172 | Batch_idx: 100 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (12515/12928)
Epoch: 172 | Batch_idx: 110 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (13761/14208)
Epoch: 172 | Batch_idx: 120 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (15002/15488)
Epoch: 172 | Batch_idx: 130 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (16246/16768)
Epoch: 172 | Batch_idx: 140 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (17485/18048)
Epoch: 172 | Batch_idx: 150 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (18720/19328)
Epoch: 172 | Batch_idx: 160 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (19951/20608)
Epoch: 172 | Batch_idx: 170 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (21187/21888)
Epoch: 172 | Batch_idx: 180 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (22435/23168)
Epoch: 172 | Batch_idx: 190 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (23652/24448)
Epoch: 172 | Batch_idx: 200 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (24896/25728)
Epoch: 172 | Batch_idx: 210 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (26120/27008)
Epoch: 172 | Batch_idx: 220 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (27363/28288)
Epoch: 172 | Batch_idx: 230 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (28600/29568)
Epoch: 172 | Batch_idx: 240 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (29833/30848)
Epoch: 172 | Batch_idx: 250 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (31073/32128)
Epoch: 172 | Batch_idx: 260 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (32316/33408)
Epoch: 172 | Batch_idx: 270 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (33561/34688)
Epoch: 172 | Batch_idx: 280 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (34810/35968)
Epoch: 172 | Batch_idx: 290 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (36052/37248)
Epoch: 172 | Batch_idx: 300 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (37286/38528)
Epoch: 172 | Batch_idx: 310 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (38513/39808)
Epoch: 172 | Batch_idx: 320 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (39744/41088)
Epoch: 172 | Batch_idx: 330 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (40971/42368)
Epoch: 172 | Batch_idx: 340 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (42211/43648)
Epoch: 172 | Batch_idx: 350 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (43451/44928)
Epoch: 172 | Batch_idx: 360 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (44691/46208)
Epoch: 172 | Batch_idx: 370 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (45921/47488)
Epoch: 172 | Batch_idx: 380 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (47160/48768)
Epoch: 172 | Batch_idx: 390 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (48345/50000)
# TEST : Loss: (0.4741) | Acc: (87.00%) (8701/10000)
percent tensor([0.5700, 0.5683, 0.5812, 0.5744, 0.5920, 0.5746, 0.5784, 0.5837, 0.5726,
        0.5701, 0.5663, 0.5776, 0.5695, 0.5614, 0.5725, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.5334, 0.5318, 0.5290, 0.5348, 0.5307, 0.5389, 0.5309, 0.5307, 0.5321,
        0.5316, 0.5310, 0.5311, 0.5320, 0.5303, 0.5363, 0.5349],
       device='cuda:0') torch.Size([16])
percent tensor([0.5155, 0.5553, 0.5268, 0.5341, 0.5546, 0.5645, 0.5498, 0.5216, 0.5403,
        0.5375, 0.5378, 0.5474, 0.5521, 0.5314, 0.5532, 0.5317],
       device='cuda:0') torch.Size([16])
percent tensor([0.6701, 0.6852, 0.6378, 0.6313, 0.6355, 0.6281, 0.6824, 0.6386, 0.6572,
        0.6745, 0.6906, 0.6638, 0.6801, 0.6719, 0.6813, 0.6547],
       device='cuda:0') torch.Size([16])
percent tensor([0.5666, 0.5882, 0.7105, 0.8030, 0.7224, 0.7575, 0.6064, 0.5763, 0.7242,
        0.5962, 0.6706, 0.6898, 0.5943, 0.7987, 0.5476, 0.6424],
       device='cuda:0') torch.Size([16])
percent tensor([0.6852, 0.6400, 0.7246, 0.7189, 0.7407, 0.6928, 0.7023, 0.7266, 0.6857,
        0.6482, 0.6425, 0.7038, 0.6078, 0.6728, 0.7012, 0.6785],
       device='cuda:0') torch.Size([16])
percent tensor([0.5313, 0.5776, 0.7099, 0.5780, 0.7405, 0.7672, 0.6065, 0.5478, 0.6032,
        0.5662, 0.6355, 0.4709, 0.5475, 0.4878, 0.4625, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9996, 0.9999, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 173 | Batch_idx: 0 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 173 | Batch_idx: 10 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 173 | Batch_idx: 20 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (2602/2688)
Epoch: 173 | Batch_idx: 30 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (3831/3968)
Epoch: 173 | Batch_idx: 40 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (5081/5248)
Epoch: 173 | Batch_idx: 50 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (6338/6528)
Epoch: 173 | Batch_idx: 60 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (7578/7808)
Epoch: 173 | Batch_idx: 70 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (8814/9088)
Epoch: 173 | Batch_idx: 80 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (10050/10368)
Epoch: 173 | Batch_idx: 90 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (11284/11648)
Epoch: 173 | Batch_idx: 100 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (12518/12928)
Epoch: 173 | Batch_idx: 110 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (13758/14208)
Epoch: 173 | Batch_idx: 120 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (14996/15488)
Epoch: 173 | Batch_idx: 130 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (16234/16768)
Epoch: 173 | Batch_idx: 140 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (17469/18048)
Epoch: 173 | Batch_idx: 150 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (18695/19328)
Epoch: 173 | Batch_idx: 160 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (19932/20608)
Epoch: 173 | Batch_idx: 170 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (21180/21888)
Epoch: 173 | Batch_idx: 180 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (22424/23168)
Epoch: 173 | Batch_idx: 190 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (23664/24448)
Epoch: 173 | Batch_idx: 200 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (24900/25728)
Epoch: 173 | Batch_idx: 210 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (26144/27008)
Epoch: 173 | Batch_idx: 220 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (27380/28288)
Epoch: 173 | Batch_idx: 230 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (28618/29568)
Epoch: 173 | Batch_idx: 240 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (29858/30848)
Epoch: 173 | Batch_idx: 250 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (31105/32128)
Epoch: 173 | Batch_idx: 260 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (32345/33408)
Epoch: 173 | Batch_idx: 270 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (33579/34688)
Epoch: 173 | Batch_idx: 280 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (34812/35968)
Epoch: 173 | Batch_idx: 290 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (36051/37248)
Epoch: 173 | Batch_idx: 300 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (37288/38528)
Epoch: 173 | Batch_idx: 310 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (38518/39808)
Epoch: 173 | Batch_idx: 320 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (39760/41088)
Epoch: 173 | Batch_idx: 330 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (41000/42368)
Epoch: 173 | Batch_idx: 340 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (42237/43648)
Epoch: 173 | Batch_idx: 350 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (43474/44928)
Epoch: 173 | Batch_idx: 360 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (44699/46208)
Epoch: 173 | Batch_idx: 370 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (45938/47488)
Epoch: 173 | Batch_idx: 380 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (47184/48768)
Epoch: 173 | Batch_idx: 390 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (48380/50000)
# TEST : Loss: (0.4505) | Acc: (87.00%) (8732/10000)
percent tensor([0.5702, 0.5677, 0.5781, 0.5738, 0.5891, 0.5738, 0.5772, 0.5814, 0.5717,
        0.5688, 0.5662, 0.5749, 0.5697, 0.5607, 0.5720, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.5336, 0.5318, 0.5278, 0.5346, 0.5300, 0.5377, 0.5308, 0.5308, 0.5320,
        0.5316, 0.5312, 0.5304, 0.5324, 0.5311, 0.5356, 0.5347],
       device='cuda:0') torch.Size([16])
percent tensor([0.5180, 0.5484, 0.5322, 0.5342, 0.5608, 0.5639, 0.5485, 0.5234, 0.5429,
        0.5354, 0.5361, 0.5513, 0.5510, 0.5295, 0.5487, 0.5313],
       device='cuda:0') torch.Size([16])
percent tensor([0.6661, 0.6812, 0.6373, 0.6318, 0.6331, 0.6347, 0.6788, 0.6341, 0.6525,
        0.6703, 0.6900, 0.6581, 0.6726, 0.6704, 0.6809, 0.6563],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5791, 0.7028, 0.7871, 0.7220, 0.7142, 0.6012, 0.5817, 0.7316,
        0.5985, 0.6758, 0.6851, 0.6036, 0.7906, 0.5437, 0.6254],
       device='cuda:0') torch.Size([16])
percent tensor([0.6877, 0.6449, 0.7151, 0.7264, 0.7447, 0.6934, 0.7082, 0.7276, 0.6817,
        0.6475, 0.6432, 0.7034, 0.6124, 0.6812, 0.7054, 0.6799],
       device='cuda:0') torch.Size([16])
percent tensor([0.5724, 0.6449, 0.7222, 0.6155, 0.7508, 0.7513, 0.6645, 0.5862, 0.6795,
        0.6344, 0.7081, 0.5618, 0.6080, 0.5635, 0.5603, 0.5027],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 1.0000, 0.9997, 0.9996, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 174 | Batch_idx: 0 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 174 | Batch_idx: 10 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 174 | Batch_idx: 20 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (2601/2688)
Epoch: 174 | Batch_idx: 30 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (3846/3968)
Epoch: 174 | Batch_idx: 40 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (97.00%) (5100/5248)
Epoch: 174 | Batch_idx: 50 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (97.00%) (6333/6528)
Epoch: 174 | Batch_idx: 60 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (97.00%) (7575/7808)
Epoch: 174 | Batch_idx: 70 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (97.00%) (8819/9088)
Epoch: 174 | Batch_idx: 80 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (10067/10368)
Epoch: 174 | Batch_idx: 90 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (11309/11648)
Epoch: 174 | Batch_idx: 100 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (12566/12928)
Epoch: 174 | Batch_idx: 110 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (13806/14208)
Epoch: 174 | Batch_idx: 120 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (15055/15488)
Epoch: 174 | Batch_idx: 130 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (16297/16768)
Epoch: 174 | Batch_idx: 140 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (17540/18048)
Epoch: 174 | Batch_idx: 150 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (18789/19328)
Epoch: 174 | Batch_idx: 160 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (20036/20608)
Epoch: 174 | Batch_idx: 170 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (21275/21888)
Epoch: 174 | Batch_idx: 180 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (22515/23168)
Epoch: 174 | Batch_idx: 190 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (23767/24448)
Epoch: 174 | Batch_idx: 200 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (25001/25728)
Epoch: 174 | Batch_idx: 210 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (26239/27008)
Epoch: 174 | Batch_idx: 220 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (27486/28288)
Epoch: 174 | Batch_idx: 230 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (28719/29568)
Epoch: 174 | Batch_idx: 240 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (29954/30848)
Epoch: 174 | Batch_idx: 250 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (31183/32128)
Epoch: 174 | Batch_idx: 260 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (32425/33408)
Epoch: 174 | Batch_idx: 270 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (33661/34688)
Epoch: 174 | Batch_idx: 280 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (34900/35968)
Epoch: 174 | Batch_idx: 290 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (36126/37248)
Epoch: 174 | Batch_idx: 300 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (37352/38528)
Epoch: 174 | Batch_idx: 310 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (38574/39808)
Epoch: 174 | Batch_idx: 320 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (39816/41088)
Epoch: 174 | Batch_idx: 330 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (41046/42368)
Epoch: 174 | Batch_idx: 340 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (42290/43648)
Epoch: 174 | Batch_idx: 350 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (43535/44928)
Epoch: 174 | Batch_idx: 360 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (44777/46208)
Epoch: 174 | Batch_idx: 370 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (46017/47488)
Epoch: 174 | Batch_idx: 380 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (47256/48768)
Epoch: 174 | Batch_idx: 390 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (48443/50000)
# TEST : Loss: (0.4082) | Acc: (88.00%) (8888/10000)
percent tensor([0.5698, 0.5666, 0.5822, 0.5747, 0.5918, 0.5729, 0.5776, 0.5836, 0.5724,
        0.5696, 0.5660, 0.5773, 0.5694, 0.5589, 0.5711, 0.5680],
       device='cuda:0') torch.Size([16])
percent tensor([0.5333, 0.5317, 0.5293, 0.5342, 0.5303, 0.5373, 0.5307, 0.5302, 0.5324,
        0.5315, 0.5313, 0.5310, 0.5323, 0.5305, 0.5355, 0.5347],
       device='cuda:0') torch.Size([16])
percent tensor([0.5208, 0.5496, 0.5416, 0.5395, 0.5635, 0.5666, 0.5485, 0.5257, 0.5441,
        0.5365, 0.5380, 0.5544, 0.5558, 0.5293, 0.5517, 0.5351],
       device='cuda:0') torch.Size([16])
percent tensor([0.6679, 0.6838, 0.6328, 0.6278, 0.6339, 0.6285, 0.6826, 0.6378, 0.6574,
        0.6732, 0.6915, 0.6561, 0.6756, 0.6734, 0.6791, 0.6552],
       device='cuda:0') torch.Size([16])
percent tensor([0.5716, 0.5879, 0.7134, 0.7911, 0.7138, 0.7242, 0.6159, 0.5774, 0.7533,
        0.6138, 0.7044, 0.7167, 0.6268, 0.8219, 0.5571, 0.6365],
       device='cuda:0') torch.Size([16])
percent tensor([0.6807, 0.6439, 0.7169, 0.7282, 0.7361, 0.6844, 0.7066, 0.7318, 0.6791,
        0.6468, 0.6424, 0.7072, 0.6100, 0.6824, 0.6974, 0.6790],
       device='cuda:0') torch.Size([16])
percent tensor([0.5670, 0.6383, 0.7154, 0.6068, 0.7544, 0.7658, 0.6652, 0.5945, 0.6075,
        0.6280, 0.6701, 0.5272, 0.5736, 0.5584, 0.5619, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 1.0000, 0.9999, 0.9999, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9995, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 175 | Batch_idx: 0 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 175 | Batch_idx: 10 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 175 | Batch_idx: 20 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 175 | Batch_idx: 30 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (3835/3968)
Epoch: 175 | Batch_idx: 40 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (5057/5248)
Epoch: 175 | Batch_idx: 50 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (6283/6528)
Epoch: 175 | Batch_idx: 60 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (7511/7808)
Epoch: 175 | Batch_idx: 70 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (8748/9088)
Epoch: 175 | Batch_idx: 80 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (9980/10368)
Epoch: 175 | Batch_idx: 90 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (11225/11648)
Epoch: 175 | Batch_idx: 100 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (12449/12928)
Epoch: 175 | Batch_idx: 110 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (13688/14208)
Epoch: 175 | Batch_idx: 120 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (14931/15488)
Epoch: 175 | Batch_idx: 130 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (16169/16768)
Epoch: 175 | Batch_idx: 140 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (17394/18048)
Epoch: 175 | Batch_idx: 150 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (18628/19328)
Epoch: 175 | Batch_idx: 160 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (19864/20608)
Epoch: 175 | Batch_idx: 170 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (21081/21888)
Epoch: 175 | Batch_idx: 180 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (22314/23168)
Epoch: 175 | Batch_idx: 190 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (23549/24448)
Epoch: 175 | Batch_idx: 200 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (24787/25728)
Epoch: 175 | Batch_idx: 210 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (26027/27008)
Epoch: 175 | Batch_idx: 220 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (27261/28288)
Epoch: 175 | Batch_idx: 230 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (28500/29568)
Epoch: 175 | Batch_idx: 240 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (29738/30848)
Epoch: 175 | Batch_idx: 250 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (30980/32128)
Epoch: 175 | Batch_idx: 260 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (32222/33408)
Epoch: 175 | Batch_idx: 270 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (33452/34688)
Epoch: 175 | Batch_idx: 280 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (34698/35968)
Epoch: 175 | Batch_idx: 290 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (35936/37248)
Epoch: 175 | Batch_idx: 300 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (37173/38528)
Epoch: 175 | Batch_idx: 310 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (38417/39808)
Epoch: 175 | Batch_idx: 320 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (39655/41088)
Epoch: 175 | Batch_idx: 330 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (40893/42368)
Epoch: 175 | Batch_idx: 340 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (42125/43648)
Epoch: 175 | Batch_idx: 350 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (43353/44928)
Epoch: 175 | Batch_idx: 360 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (44600/46208)
Epoch: 175 | Batch_idx: 370 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (45842/47488)
Epoch: 175 | Batch_idx: 380 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (47086/48768)
Epoch: 175 | Batch_idx: 390 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (48279/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_175.pth.tar'
# TEST : Loss: (0.3885) | Acc: (88.00%) (8874/10000)
percent tensor([0.5724, 0.5685, 0.5855, 0.5777, 0.5946, 0.5759, 0.5801, 0.5863, 0.5741,
        0.5717, 0.5677, 0.5805, 0.5715, 0.5607, 0.5736, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5356, 0.5336, 0.5323, 0.5370, 0.5328, 0.5395, 0.5328, 0.5328, 0.5340,
        0.5337, 0.5331, 0.5336, 0.5345, 0.5319, 0.5380, 0.5370],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.5584, 0.5478, 0.5527, 0.5743, 0.5754, 0.5583, 0.5349, 0.5526,
        0.5451, 0.5454, 0.5647, 0.5636, 0.5378, 0.5632, 0.5458],
       device='cuda:0') torch.Size([16])
percent tensor([0.6705, 0.6851, 0.6386, 0.6326, 0.6401, 0.6321, 0.6849, 0.6438, 0.6612,
        0.6751, 0.6928, 0.6599, 0.6774, 0.6759, 0.6813, 0.6586],
       device='cuda:0') torch.Size([16])
percent tensor([0.5690, 0.5690, 0.7358, 0.8082, 0.7392, 0.7276, 0.6140, 0.6005, 0.7533,
        0.6020, 0.6875, 0.7391, 0.6096, 0.8123, 0.5512, 0.6262],
       device='cuda:0') torch.Size([16])
percent tensor([0.7054, 0.6661, 0.7314, 0.7454, 0.7536, 0.7102, 0.7269, 0.7489, 0.6999,
        0.6708, 0.6622, 0.7228, 0.6312, 0.7007, 0.7197, 0.7062],
       device='cuda:0') torch.Size([16])
percent tensor([0.5959, 0.6668, 0.7217, 0.5919, 0.7564, 0.7789, 0.6961, 0.6092, 0.6015,
        0.6504, 0.6894, 0.5387, 0.5928, 0.5736, 0.5900, 0.5615],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9997, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9995, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 176 | Batch_idx: 0 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 176 | Batch_idx: 10 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 176 | Batch_idx: 20 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (2594/2688)
Epoch: 176 | Batch_idx: 30 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (3845/3968)
Epoch: 176 | Batch_idx: 40 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (5079/5248)
Epoch: 176 | Batch_idx: 50 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (6309/6528)
Epoch: 176 | Batch_idx: 60 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (7544/7808)
Epoch: 176 | Batch_idx: 70 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (8787/9088)
Epoch: 176 | Batch_idx: 80 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (10029/10368)
Epoch: 176 | Batch_idx: 90 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (11266/11648)
Epoch: 176 | Batch_idx: 100 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (12504/12928)
Epoch: 176 | Batch_idx: 110 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (13739/14208)
Epoch: 176 | Batch_idx: 120 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (14968/15488)
Epoch: 176 | Batch_idx: 130 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (16214/16768)
Epoch: 176 | Batch_idx: 140 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (17450/18048)
Epoch: 176 | Batch_idx: 150 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (18686/19328)
Epoch: 176 | Batch_idx: 160 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (19924/20608)
Epoch: 176 | Batch_idx: 170 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (21160/21888)
Epoch: 176 | Batch_idx: 180 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (22390/23168)
Epoch: 176 | Batch_idx: 190 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (23638/24448)
Epoch: 176 | Batch_idx: 200 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (24884/25728)
Epoch: 176 | Batch_idx: 210 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (26133/27008)
Epoch: 176 | Batch_idx: 220 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (27390/28288)
Epoch: 176 | Batch_idx: 230 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (28629/29568)
Epoch: 176 | Batch_idx: 240 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (29870/30848)
Epoch: 176 | Batch_idx: 250 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (31101/32128)
Epoch: 176 | Batch_idx: 260 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (32350/33408)
Epoch: 176 | Batch_idx: 270 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (33599/34688)
Epoch: 176 | Batch_idx: 280 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (34846/35968)
Epoch: 176 | Batch_idx: 290 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (36087/37248)
Epoch: 176 | Batch_idx: 300 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (37323/38528)
Epoch: 176 | Batch_idx: 310 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (38560/39808)
Epoch: 176 | Batch_idx: 320 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (39806/41088)
Epoch: 176 | Batch_idx: 330 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (41052/42368)
Epoch: 176 | Batch_idx: 340 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (42292/43648)
Epoch: 176 | Batch_idx: 350 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (43536/44928)
Epoch: 176 | Batch_idx: 360 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (44784/46208)
Epoch: 176 | Batch_idx: 370 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (46021/47488)
Epoch: 176 | Batch_idx: 380 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (47270/48768)
Epoch: 176 | Batch_idx: 390 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (48465/50000)
# TEST : Loss: (0.3802) | Acc: (89.00%) (8912/10000)
percent tensor([0.5701, 0.5655, 0.5830, 0.5750, 0.5918, 0.5734, 0.5772, 0.5835, 0.5718,
        0.5689, 0.5652, 0.5779, 0.5689, 0.5584, 0.5707, 0.5677],
       device='cuda:0') torch.Size([16])
percent tensor([0.5367, 0.5347, 0.5333, 0.5381, 0.5337, 0.5408, 0.5338, 0.5338, 0.5350,
        0.5348, 0.5342, 0.5347, 0.5357, 0.5327, 0.5393, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.5601, 0.5497, 0.5542, 0.5779, 0.5737, 0.5609, 0.5376, 0.5535,
        0.5463, 0.5458, 0.5664, 0.5645, 0.5378, 0.5643, 0.5459],
       device='cuda:0') torch.Size([16])
percent tensor([0.6726, 0.6869, 0.6425, 0.6361, 0.6444, 0.6358, 0.6867, 0.6475, 0.6630,
        0.6772, 0.6949, 0.6629, 0.6785, 0.6777, 0.6838, 0.6614],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.5651, 0.7447, 0.8187, 0.7478, 0.7299, 0.6108, 0.6066, 0.7576,
        0.6006, 0.6827, 0.7446, 0.6081, 0.8105, 0.5497, 0.6267],
       device='cuda:0') torch.Size([16])
percent tensor([0.7019, 0.6617, 0.7275, 0.7396, 0.7499, 0.7104, 0.7213, 0.7422, 0.6946,
        0.6668, 0.6567, 0.7154, 0.6271, 0.6968, 0.7138, 0.7032],
       device='cuda:0') torch.Size([16])
percent tensor([0.5967, 0.6625, 0.7180, 0.5843, 0.7537, 0.7811, 0.6975, 0.5994, 0.6029,
        0.6465, 0.6879, 0.5295, 0.5942, 0.5715, 0.5924, 0.5693],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 1.0000, 0.9997, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9995, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 177 | Batch_idx: 0 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 177 | Batch_idx: 10 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 177 | Batch_idx: 20 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (2611/2688)
Epoch: 177 | Batch_idx: 30 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (3848/3968)
Epoch: 177 | Batch_idx: 40 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (5093/5248)
Epoch: 177 | Batch_idx: 50 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (6340/6528)
Epoch: 177 | Batch_idx: 60 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (7577/7808)
Epoch: 177 | Batch_idx: 70 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (8817/9088)
Epoch: 177 | Batch_idx: 80 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (10071/10368)
Epoch: 177 | Batch_idx: 90 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (11312/11648)
Epoch: 177 | Batch_idx: 100 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (12563/12928)
Epoch: 177 | Batch_idx: 110 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (13801/14208)
Epoch: 177 | Batch_idx: 120 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (15052/15488)
Epoch: 177 | Batch_idx: 130 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (16300/16768)
Epoch: 177 | Batch_idx: 140 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (17549/18048)
Epoch: 177 | Batch_idx: 150 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (18791/19328)
Epoch: 177 | Batch_idx: 160 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (20038/20608)
Epoch: 177 | Batch_idx: 170 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (21269/21888)
Epoch: 177 | Batch_idx: 180 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (22517/23168)
Epoch: 177 | Batch_idx: 190 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (23768/24448)
Epoch: 177 | Batch_idx: 200 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (25003/25728)
Epoch: 177 | Batch_idx: 210 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (26243/27008)
Epoch: 177 | Batch_idx: 220 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (27485/28288)
Epoch: 177 | Batch_idx: 230 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (28738/29568)
Epoch: 177 | Batch_idx: 240 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (29990/30848)
Epoch: 177 | Batch_idx: 250 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (31235/32128)
Epoch: 177 | Batch_idx: 260 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (32484/33408)
Epoch: 177 | Batch_idx: 270 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (33732/34688)
Epoch: 177 | Batch_idx: 280 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (34980/35968)
Epoch: 177 | Batch_idx: 290 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (36224/37248)
Epoch: 177 | Batch_idx: 300 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (37470/38528)
Epoch: 177 | Batch_idx: 310 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (38715/39808)
Epoch: 177 | Batch_idx: 320 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (39952/41088)
Epoch: 177 | Batch_idx: 330 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (41194/42368)
Epoch: 177 | Batch_idx: 340 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (42432/43648)
Epoch: 177 | Batch_idx: 350 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (43684/44928)
Epoch: 177 | Batch_idx: 360 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (44935/46208)
Epoch: 177 | Batch_idx: 370 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (46164/47488)
Epoch: 177 | Batch_idx: 380 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (47401/48768)
Epoch: 177 | Batch_idx: 390 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (48603/50000)
# TEST : Loss: (0.3754) | Acc: (89.00%) (8918/10000)
percent tensor([0.5703, 0.5654, 0.5827, 0.5746, 0.5917, 0.5735, 0.5773, 0.5833, 0.5718,
        0.5689, 0.5652, 0.5778, 0.5688, 0.5585, 0.5707, 0.5675],
       device='cuda:0') torch.Size([16])
percent tensor([0.5364, 0.5346, 0.5328, 0.5378, 0.5332, 0.5409, 0.5335, 0.5333, 0.5344,
        0.5345, 0.5339, 0.5343, 0.5355, 0.5324, 0.5394, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.5282, 0.5585, 0.5484, 0.5540, 0.5763, 0.5734, 0.5590, 0.5364, 0.5521,
        0.5449, 0.5443, 0.5646, 0.5627, 0.5372, 0.5627, 0.5451],
       device='cuda:0') torch.Size([16])
percent tensor([0.6797, 0.6926, 0.6510, 0.6439, 0.6520, 0.6424, 0.6934, 0.6556, 0.6700,
        0.6838, 0.7010, 0.6705, 0.6846, 0.6842, 0.6905, 0.6686],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.5720, 0.7480, 0.8223, 0.7518, 0.7378, 0.6171, 0.6115, 0.7616,
        0.6060, 0.6880, 0.7488, 0.6172, 0.8101, 0.5560, 0.6340],
       device='cuda:0') torch.Size([16])
percent tensor([0.7068, 0.6680, 0.7304, 0.7420, 0.7529, 0.7157, 0.7260, 0.7442, 0.6980,
        0.6722, 0.6625, 0.7180, 0.6329, 0.7027, 0.7168, 0.7099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5808, 0.6523, 0.7132, 0.5722, 0.7492, 0.7804, 0.6890, 0.5839, 0.5827,
        0.6319, 0.6800, 0.5101, 0.5812, 0.5664, 0.5752, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 1.0000, 0.9997, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9995, 0.9994, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 178 | Batch_idx: 0 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 178 | Batch_idx: 10 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 178 | Batch_idx: 20 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (2603/2688)
Epoch: 178 | Batch_idx: 30 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 178 | Batch_idx: 40 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (5106/5248)
Epoch: 178 | Batch_idx: 50 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (6351/6528)
Epoch: 178 | Batch_idx: 60 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (7600/7808)
Epoch: 178 | Batch_idx: 70 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (8849/9088)
Epoch: 178 | Batch_idx: 80 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (10105/10368)
Epoch: 178 | Batch_idx: 90 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (11343/11648)
Epoch: 178 | Batch_idx: 100 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (12589/12928)
Epoch: 178 | Batch_idx: 110 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (13824/14208)
Epoch: 178 | Batch_idx: 120 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (15057/15488)
Epoch: 178 | Batch_idx: 130 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (16310/16768)
Epoch: 178 | Batch_idx: 140 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (17559/18048)
Epoch: 178 | Batch_idx: 150 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (18798/19328)
Epoch: 178 | Batch_idx: 160 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (20041/20608)
Epoch: 178 | Batch_idx: 170 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (21295/21888)
Epoch: 178 | Batch_idx: 180 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (22537/23168)
Epoch: 178 | Batch_idx: 190 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (23772/24448)
Epoch: 178 | Batch_idx: 200 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (25016/25728)
Epoch: 178 | Batch_idx: 210 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (26253/27008)
Epoch: 178 | Batch_idx: 220 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (27499/28288)
Epoch: 178 | Batch_idx: 230 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (28749/29568)
Epoch: 178 | Batch_idx: 240 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (29997/30848)
Epoch: 178 | Batch_idx: 250 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (31242/32128)
Epoch: 178 | Batch_idx: 260 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (32484/33408)
Epoch: 178 | Batch_idx: 270 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (33734/34688)
Epoch: 178 | Batch_idx: 280 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (34974/35968)
Epoch: 178 | Batch_idx: 290 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (36220/37248)
Epoch: 178 | Batch_idx: 300 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (37471/38528)
Epoch: 178 | Batch_idx: 310 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (38723/39808)
Epoch: 178 | Batch_idx: 320 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (39974/41088)
Epoch: 178 | Batch_idx: 330 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (41227/42368)
Epoch: 178 | Batch_idx: 340 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (42471/43648)
Epoch: 178 | Batch_idx: 350 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (43710/44928)
Epoch: 178 | Batch_idx: 360 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (44951/46208)
Epoch: 178 | Batch_idx: 370 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (46186/47488)
Epoch: 178 | Batch_idx: 380 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (47420/48768)
Epoch: 178 | Batch_idx: 390 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (48618/50000)
# TEST : Loss: (0.3705) | Acc: (89.00%) (8927/10000)
percent tensor([0.5712, 0.5660, 0.5837, 0.5752, 0.5929, 0.5740, 0.5781, 0.5843, 0.5728,
        0.5696, 0.5660, 0.5788, 0.5697, 0.5588, 0.5713, 0.5680],
       device='cuda:0') torch.Size([16])
percent tensor([0.5368, 0.5348, 0.5330, 0.5381, 0.5333, 0.5415, 0.5336, 0.5334, 0.5346,
        0.5347, 0.5343, 0.5345, 0.5359, 0.5325, 0.5399, 0.5386],
       device='cuda:0') torch.Size([16])
percent tensor([0.5301, 0.5597, 0.5516, 0.5578, 0.5797, 0.5760, 0.5605, 0.5399, 0.5545,
        0.5469, 0.5453, 0.5669, 0.5635, 0.5392, 0.5644, 0.5470],
       device='cuda:0') torch.Size([16])
percent tensor([0.6774, 0.6901, 0.6489, 0.6414, 0.6500, 0.6401, 0.6906, 0.6532, 0.6671,
        0.6812, 0.6983, 0.6677, 0.6819, 0.6812, 0.6880, 0.6661],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.5686, 0.7436, 0.8190, 0.7471, 0.7301, 0.6087, 0.6022, 0.7583,
        0.6003, 0.6798, 0.7436, 0.6105, 0.8047, 0.5500, 0.6234],
       device='cuda:0') torch.Size([16])
percent tensor([0.7022, 0.6624, 0.7257, 0.7368, 0.7494, 0.7127, 0.7210, 0.7387, 0.6932,
        0.6669, 0.6569, 0.7125, 0.6272, 0.6998, 0.7108, 0.7046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5802, 0.6476, 0.7063, 0.5602, 0.7461, 0.7878, 0.6908, 0.5709, 0.5816,
        0.6345, 0.6804, 0.5041, 0.5866, 0.5684, 0.5641, 0.5721],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 1.0000, 0.9997, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9996, 0.9994, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 179 | Batch_idx: 0 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 179 | Batch_idx: 10 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 179 | Batch_idx: 20 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 179 | Batch_idx: 30 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (3873/3968)
Epoch: 179 | Batch_idx: 40 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (5112/5248)
Epoch: 179 | Batch_idx: 50 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (6363/6528)
Epoch: 179 | Batch_idx: 60 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (7617/7808)
Epoch: 179 | Batch_idx: 70 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (8868/9088)
Epoch: 179 | Batch_idx: 80 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (10117/10368)
Epoch: 179 | Batch_idx: 90 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (11358/11648)
Epoch: 179 | Batch_idx: 100 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (12611/12928)
Epoch: 179 | Batch_idx: 110 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (13843/14208)
Epoch: 179 | Batch_idx: 120 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (15086/15488)
Epoch: 179 | Batch_idx: 130 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (16332/16768)
Epoch: 179 | Batch_idx: 140 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (17578/18048)
Epoch: 179 | Batch_idx: 150 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (18834/19328)
Epoch: 179 | Batch_idx: 160 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (20071/20608)
Epoch: 179 | Batch_idx: 170 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (21326/21888)
Epoch: 179 | Batch_idx: 180 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (22577/23168)
Epoch: 179 | Batch_idx: 190 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (23823/24448)
Epoch: 179 | Batch_idx: 200 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (25073/25728)
Epoch: 179 | Batch_idx: 210 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (26319/27008)
Epoch: 179 | Batch_idx: 220 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (27552/28288)
Epoch: 179 | Batch_idx: 230 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (28804/29568)
Epoch: 179 | Batch_idx: 240 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (30051/30848)
Epoch: 179 | Batch_idx: 250 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (31301/32128)
Epoch: 179 | Batch_idx: 260 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (32543/33408)
Epoch: 179 | Batch_idx: 270 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (33793/34688)
Epoch: 179 | Batch_idx: 280 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (35042/35968)
Epoch: 179 | Batch_idx: 290 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (36284/37248)
Epoch: 179 | Batch_idx: 300 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (37528/38528)
Epoch: 179 | Batch_idx: 310 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (38774/39808)
Epoch: 179 | Batch_idx: 320 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (40009/41088)
Epoch: 179 | Batch_idx: 330 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (41268/42368)
Epoch: 179 | Batch_idx: 340 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (42511/43648)
Epoch: 179 | Batch_idx: 350 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (43761/44928)
Epoch: 179 | Batch_idx: 360 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (45008/46208)
Epoch: 179 | Batch_idx: 370 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (46258/47488)
Epoch: 179 | Batch_idx: 380 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (47503/48768)
Epoch: 179 | Batch_idx: 390 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (48700/50000)
# TEST : Loss: (0.3704) | Acc: (89.00%) (8920/10000)
percent tensor([0.5719, 0.5667, 0.5843, 0.5758, 0.5936, 0.5747, 0.5788, 0.5849, 0.5735,
        0.5703, 0.5667, 0.5794, 0.5703, 0.5596, 0.5720, 0.5688],
       device='cuda:0') torch.Size([16])
percent tensor([0.5369, 0.5349, 0.5331, 0.5381, 0.5333, 0.5419, 0.5337, 0.5334, 0.5346,
        0.5347, 0.5344, 0.5345, 0.5360, 0.5326, 0.5402, 0.5389],
       device='cuda:0') torch.Size([16])
percent tensor([0.5278, 0.5560, 0.5502, 0.5569, 0.5777, 0.5735, 0.5575, 0.5388, 0.5518,
        0.5442, 0.5423, 0.5644, 0.5602, 0.5364, 0.5613, 0.5448],
       device='cuda:0') torch.Size([16])
percent tensor([0.6677, 0.6804, 0.6409, 0.6327, 0.6417, 0.6319, 0.6805, 0.6442, 0.6579,
        0.6718, 0.6883, 0.6581, 0.6723, 0.6716, 0.6777, 0.6569],
       device='cuda:0') torch.Size([16])
percent tensor([0.5771, 0.5824, 0.7454, 0.8209, 0.7462, 0.7353, 0.6191, 0.6049, 0.7649,
        0.6146, 0.6918, 0.7497, 0.6270, 0.8092, 0.5601, 0.6360],
       device='cuda:0') torch.Size([16])
percent tensor([0.7053, 0.6648, 0.7280, 0.7391, 0.7525, 0.7161, 0.7239, 0.7404, 0.6951,
        0.6699, 0.6603, 0.7136, 0.6290, 0.7026, 0.7122, 0.7092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5960, 0.6653, 0.7274, 0.5832, 0.7647, 0.7923, 0.7119, 0.5971, 0.6028,
        0.6529, 0.6983, 0.5198, 0.5892, 0.5883, 0.5781, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 1.0000, 0.9997, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9996, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 180 | Batch_idx: 0 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 180 | Batch_idx: 10 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 180 | Batch_idx: 20 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (2617/2688)
Epoch: 180 | Batch_idx: 30 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 180 | Batch_idx: 40 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (5106/5248)
Epoch: 180 | Batch_idx: 50 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (6346/6528)
Epoch: 180 | Batch_idx: 60 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (7591/7808)
Epoch: 180 | Batch_idx: 70 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (8837/9088)
Epoch: 180 | Batch_idx: 80 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (10068/10368)
Epoch: 180 | Batch_idx: 90 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (11315/11648)
Epoch: 180 | Batch_idx: 100 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (12554/12928)
Epoch: 180 | Batch_idx: 110 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (13799/14208)
Epoch: 180 | Batch_idx: 120 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (15042/15488)
Epoch: 180 | Batch_idx: 130 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (16284/16768)
Epoch: 180 | Batch_idx: 140 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (17524/18048)
Epoch: 180 | Batch_idx: 150 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (18745/19328)
Epoch: 180 | Batch_idx: 160 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (19970/20608)
Epoch: 180 | Batch_idx: 170 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (21208/21888)
Epoch: 180 | Batch_idx: 180 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (22441/23168)
Epoch: 180 | Batch_idx: 190 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (23687/24448)
Epoch: 180 | Batch_idx: 200 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (24935/25728)
Epoch: 180 | Batch_idx: 210 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (26180/27008)
Epoch: 180 | Batch_idx: 220 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (27422/28288)
Epoch: 180 | Batch_idx: 230 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (28657/29568)
Epoch: 180 | Batch_idx: 240 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (29902/30848)
Epoch: 180 | Batch_idx: 250 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (31148/32128)
Epoch: 180 | Batch_idx: 260 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (32397/33408)
Epoch: 180 | Batch_idx: 270 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (33632/34688)
Epoch: 180 | Batch_idx: 280 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (34865/35968)
Epoch: 180 | Batch_idx: 290 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (36105/37248)
Epoch: 180 | Batch_idx: 300 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (37348/38528)
Epoch: 180 | Batch_idx: 310 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (38588/39808)
Epoch: 180 | Batch_idx: 320 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (39824/41088)
Epoch: 180 | Batch_idx: 330 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (41057/42368)
Epoch: 180 | Batch_idx: 340 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (42286/43648)
Epoch: 180 | Batch_idx: 350 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (43526/44928)
Epoch: 180 | Batch_idx: 360 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (44766/46208)
Epoch: 180 | Batch_idx: 370 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (46017/47488)
Epoch: 180 | Batch_idx: 380 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (47265/48768)
Epoch: 180 | Batch_idx: 390 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (48459/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_180.pth.tar'
# TEST : Loss: (0.4395) | Acc: (88.00%) (8802/10000)
percent tensor([0.5725, 0.5676, 0.5854, 0.5752, 0.5954, 0.5747, 0.5799, 0.5856, 0.5747,
        0.5710, 0.5677, 0.5808, 0.5709, 0.5600, 0.5724, 0.5688],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5353, 0.5320, 0.5378, 0.5328, 0.5428, 0.5339, 0.5326, 0.5344,
        0.5345, 0.5342, 0.5345, 0.5356, 0.5324, 0.5407, 0.5391],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.5550, 0.5500, 0.5512, 0.5779, 0.5718, 0.5566, 0.5383, 0.5543,
        0.5462, 0.5422, 0.5660, 0.5568, 0.5360, 0.5603, 0.5423],
       device='cuda:0') torch.Size([16])
percent tensor([0.6658, 0.6804, 0.6354, 0.6361, 0.6386, 0.6309, 0.6802, 0.6413, 0.6561,
        0.6735, 0.6886, 0.6553, 0.6717, 0.6714, 0.6789, 0.6555],
       device='cuda:0') torch.Size([16])
percent tensor([0.5833, 0.5972, 0.7343, 0.8281, 0.7600, 0.7549, 0.6156, 0.5938, 0.7652,
        0.6161, 0.7153, 0.7312, 0.6289, 0.8038, 0.5663, 0.6469],
       device='cuda:0') torch.Size([16])
percent tensor([0.7055, 0.6598, 0.7375, 0.7439, 0.7630, 0.7242, 0.7300, 0.7406, 0.6985,
        0.6625, 0.6613, 0.7135, 0.6298, 0.6984, 0.7151, 0.7040],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.6873, 0.7455, 0.6152, 0.7752, 0.7932, 0.7002, 0.6287, 0.6555,
        0.6676, 0.7105, 0.5351, 0.5727, 0.5813, 0.5839, 0.5539],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 1.0000, 0.9999, 0.9998, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9997, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.4634, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(832.5497, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(837.9138, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1509.5612, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(482.8680, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2273.0732, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4269.2041, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1347.8680, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6237.3711, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11571.5957, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3808.9487, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16121.6680, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 181 | Batch_idx: 0 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 181 | Batch_idx: 10 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 181 | Batch_idx: 20 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (2618/2688)
Epoch: 181 | Batch_idx: 30 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (3862/3968)
Epoch: 181 | Batch_idx: 40 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (5109/5248)
Epoch: 181 | Batch_idx: 50 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (6357/6528)
Epoch: 181 | Batch_idx: 60 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (7591/7808)
Epoch: 181 | Batch_idx: 70 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (8821/9088)
Epoch: 181 | Batch_idx: 80 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (10059/10368)
Epoch: 181 | Batch_idx: 90 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (11297/11648)
Epoch: 181 | Batch_idx: 100 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (12544/12928)
Epoch: 181 | Batch_idx: 110 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (13784/14208)
Epoch: 181 | Batch_idx: 120 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (15018/15488)
Epoch: 181 | Batch_idx: 130 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (16268/16768)
Epoch: 181 | Batch_idx: 140 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (17506/18048)
Epoch: 181 | Batch_idx: 150 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (18740/19328)
Epoch: 181 | Batch_idx: 160 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (19981/20608)
Epoch: 181 | Batch_idx: 170 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (21221/21888)
Epoch: 181 | Batch_idx: 180 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (22456/23168)
Epoch: 181 | Batch_idx: 190 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (23695/24448)
Epoch: 181 | Batch_idx: 200 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (24942/25728)
Epoch: 181 | Batch_idx: 210 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (26185/27008)
Epoch: 181 | Batch_idx: 220 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (27426/28288)
Epoch: 181 | Batch_idx: 230 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (28659/29568)
Epoch: 181 | Batch_idx: 240 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (29899/30848)
Epoch: 181 | Batch_idx: 250 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (31144/32128)
Epoch: 181 | Batch_idx: 260 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (32369/33408)
Epoch: 181 | Batch_idx: 270 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (33605/34688)
Epoch: 181 | Batch_idx: 280 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (34842/35968)
Epoch: 181 | Batch_idx: 290 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (36090/37248)
Epoch: 181 | Batch_idx: 300 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (37331/38528)
Epoch: 181 | Batch_idx: 310 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (38578/39808)
Epoch: 181 | Batch_idx: 320 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (39822/41088)
Epoch: 181 | Batch_idx: 330 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (41070/42368)
Epoch: 181 | Batch_idx: 340 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (42310/43648)
Epoch: 181 | Batch_idx: 350 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (43547/44928)
Epoch: 181 | Batch_idx: 360 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (44787/46208)
Epoch: 181 | Batch_idx: 370 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (46031/47488)
Epoch: 181 | Batch_idx: 380 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (47267/48768)
Epoch: 181 | Batch_idx: 390 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (48457/50000)
# TEST : Loss: (0.4251) | Acc: (88.00%) (8817/10000)
percent tensor([0.5721, 0.5671, 0.5831, 0.5748, 0.5927, 0.5743, 0.5789, 0.5850, 0.5744,
        0.5708, 0.5672, 0.5791, 0.5706, 0.5603, 0.5718, 0.5689],
       device='cuda:0') torch.Size([16])
percent tensor([0.5359, 0.5350, 0.5303, 0.5368, 0.5315, 0.5413, 0.5334, 0.5323, 0.5342,
        0.5341, 0.5344, 0.5335, 0.5353, 0.5326, 0.5400, 0.5381],
       device='cuda:0') torch.Size([16])
percent tensor([0.5263, 0.5576, 0.5439, 0.5465, 0.5766, 0.5699, 0.5615, 0.5358, 0.5547,
        0.5473, 0.5465, 0.5651, 0.5588, 0.5392, 0.5611, 0.5402],
       device='cuda:0') torch.Size([16])
percent tensor([0.6668, 0.6783, 0.6431, 0.6340, 0.6403, 0.6361, 0.6784, 0.6415, 0.6568,
        0.6724, 0.6878, 0.6592, 0.6737, 0.6673, 0.6783, 0.6566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5831, 0.5935, 0.7400, 0.8164, 0.7396, 0.7396, 0.6201, 0.5969, 0.7566,
        0.6141, 0.6904, 0.7435, 0.6218, 0.7982, 0.5560, 0.6375],
       device='cuda:0') torch.Size([16])
percent tensor([0.7022, 0.6616, 0.7417, 0.7307, 0.7568, 0.7055, 0.7281, 0.7414, 0.6952,
        0.6634, 0.6562, 0.7194, 0.6283, 0.6987, 0.7079, 0.7001],
       device='cuda:0') torch.Size([16])
percent tensor([0.6121, 0.6357, 0.7913, 0.6752, 0.8059, 0.7897, 0.7021, 0.6176, 0.6357,
        0.6147, 0.6958, 0.5450, 0.5748, 0.5798, 0.5247, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9999, 0.9996, 0.9990, 0.9998, 0.9999, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9996, 0.9995, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 182 | Batch_idx: 0 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 182 | Batch_idx: 10 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 182 | Batch_idx: 20 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (2617/2688)
Epoch: 182 | Batch_idx: 30 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (97.00%) (3850/3968)
Epoch: 182 | Batch_idx: 40 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (5090/5248)
Epoch: 182 | Batch_idx: 50 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (6325/6528)
Epoch: 182 | Batch_idx: 60 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (7577/7808)
Epoch: 182 | Batch_idx: 70 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (8815/9088)
Epoch: 182 | Batch_idx: 80 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (10047/10368)
Epoch: 182 | Batch_idx: 90 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (11288/11648)
Epoch: 182 | Batch_idx: 100 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (12532/12928)
Epoch: 182 | Batch_idx: 110 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (13762/14208)
Epoch: 182 | Batch_idx: 120 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (15003/15488)
Epoch: 182 | Batch_idx: 130 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (16240/16768)
Epoch: 182 | Batch_idx: 140 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (17482/18048)
Epoch: 182 | Batch_idx: 150 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (18721/19328)
Epoch: 182 | Batch_idx: 160 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (19957/20608)
Epoch: 182 | Batch_idx: 170 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (21202/21888)
Epoch: 182 | Batch_idx: 180 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (22448/23168)
Epoch: 182 | Batch_idx: 190 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (23702/24448)
Epoch: 182 | Batch_idx: 200 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (24944/25728)
Epoch: 182 | Batch_idx: 210 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (26182/27008)
Epoch: 182 | Batch_idx: 220 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (27404/28288)
Epoch: 182 | Batch_idx: 230 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (28645/29568)
Epoch: 182 | Batch_idx: 240 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (29868/30848)
Epoch: 182 | Batch_idx: 250 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (31103/32128)
Epoch: 182 | Batch_idx: 260 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (32358/33408)
Epoch: 182 | Batch_idx: 270 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (33595/34688)
Epoch: 182 | Batch_idx: 280 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (34837/35968)
Epoch: 182 | Batch_idx: 290 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (36078/37248)
Epoch: 182 | Batch_idx: 300 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (37321/38528)
Epoch: 182 | Batch_idx: 310 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (38559/39808)
Epoch: 182 | Batch_idx: 320 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (39791/41088)
Epoch: 182 | Batch_idx: 330 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (41032/42368)
Epoch: 182 | Batch_idx: 340 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (42270/43648)
Epoch: 182 | Batch_idx: 350 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (43504/44928)
Epoch: 182 | Batch_idx: 360 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (44734/46208)
Epoch: 182 | Batch_idx: 370 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (45979/47488)
Epoch: 182 | Batch_idx: 380 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (47216/48768)
Epoch: 182 | Batch_idx: 390 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (48411/50000)
# TEST : Loss: (0.4093) | Acc: (88.00%) (8861/10000)
percent tensor([0.5725, 0.5678, 0.5819, 0.5749, 0.5922, 0.5757, 0.5791, 0.5840, 0.5744,
        0.5701, 0.5676, 0.5780, 0.5711, 0.5615, 0.5725, 0.5699],
       device='cuda:0') torch.Size([16])
percent tensor([0.5368, 0.5350, 0.5320, 0.5376, 0.5326, 0.5413, 0.5338, 0.5330, 0.5352,
        0.5345, 0.5346, 0.5342, 0.5360, 0.5328, 0.5399, 0.5387],
       device='cuda:0') torch.Size([16])
percent tensor([0.5294, 0.5608, 0.5469, 0.5499, 0.5782, 0.5734, 0.5633, 0.5391, 0.5583,
        0.5490, 0.5479, 0.5665, 0.5631, 0.5428, 0.5611, 0.5457],
       device='cuda:0') torch.Size([16])
percent tensor([0.6648, 0.6787, 0.6410, 0.6345, 0.6411, 0.6340, 0.6766, 0.6415, 0.6542,
        0.6716, 0.6872, 0.6597, 0.6716, 0.6692, 0.6773, 0.6553],
       device='cuda:0') torch.Size([16])
percent tensor([0.5718, 0.5818, 0.7252, 0.8100, 0.7218, 0.7268, 0.6077, 0.5891, 0.7534,
        0.5950, 0.6918, 0.7094, 0.6117, 0.7871, 0.5490, 0.6259],
       device='cuda:0') torch.Size([16])
percent tensor([0.7000, 0.6628, 0.7287, 0.7350, 0.7490, 0.7168, 0.7251, 0.7406, 0.6940,
        0.6624, 0.6613, 0.7171, 0.6311, 0.6942, 0.7131, 0.6979],
       device='cuda:0') torch.Size([16])
percent tensor([0.6184, 0.6598, 0.7797, 0.6791, 0.7704, 0.8085, 0.6897, 0.6423, 0.6288,
        0.6302, 0.7019, 0.5565, 0.5926, 0.5818, 0.5842, 0.5484],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 183 | Batch_idx: 0 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 183 | Batch_idx: 10 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 183 | Batch_idx: 20 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (2612/2688)
Epoch: 183 | Batch_idx: 30 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (3857/3968)
Epoch: 183 | Batch_idx: 40 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (5099/5248)
Epoch: 183 | Batch_idx: 50 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (6340/6528)
Epoch: 183 | Batch_idx: 60 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (7587/7808)
Epoch: 183 | Batch_idx: 70 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (8831/9088)
Epoch: 183 | Batch_idx: 80 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (10074/10368)
Epoch: 183 | Batch_idx: 90 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (11320/11648)
Epoch: 183 | Batch_idx: 100 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (12556/12928)
Epoch: 183 | Batch_idx: 110 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (13802/14208)
Epoch: 183 | Batch_idx: 120 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (15053/15488)
Epoch: 183 | Batch_idx: 130 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (16290/16768)
Epoch: 183 | Batch_idx: 140 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (17543/18048)
Epoch: 183 | Batch_idx: 150 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (18791/19328)
Epoch: 183 | Batch_idx: 160 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (20035/20608)
Epoch: 183 | Batch_idx: 170 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (21279/21888)
Epoch: 183 | Batch_idx: 180 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (22524/23168)
Epoch: 183 | Batch_idx: 190 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (23765/24448)
Epoch: 183 | Batch_idx: 200 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (25001/25728)
Epoch: 183 | Batch_idx: 210 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (26246/27008)
Epoch: 183 | Batch_idx: 220 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (27485/28288)
Epoch: 183 | Batch_idx: 230 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (28735/29568)
Epoch: 183 | Batch_idx: 240 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (29980/30848)
Epoch: 183 | Batch_idx: 250 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (31222/32128)
Epoch: 183 | Batch_idx: 260 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (32450/33408)
Epoch: 183 | Batch_idx: 270 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (33695/34688)
Epoch: 183 | Batch_idx: 280 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (34942/35968)
Epoch: 183 | Batch_idx: 290 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (36185/37248)
Epoch: 183 | Batch_idx: 300 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (37415/38528)
Epoch: 183 | Batch_idx: 310 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (38649/39808)
Epoch: 183 | Batch_idx: 320 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (39884/41088)
Epoch: 183 | Batch_idx: 330 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (41124/42368)
Epoch: 183 | Batch_idx: 340 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (42368/43648)
Epoch: 183 | Batch_idx: 350 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (43622/44928)
Epoch: 183 | Batch_idx: 360 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (44857/46208)
Epoch: 183 | Batch_idx: 370 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (46105/47488)
Epoch: 183 | Batch_idx: 380 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (47352/48768)
Epoch: 183 | Batch_idx: 390 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (48539/50000)
# TEST : Loss: (0.4376) | Acc: (88.00%) (8801/10000)
percent tensor([0.5719, 0.5672, 0.5816, 0.5743, 0.5922, 0.5759, 0.5784, 0.5826, 0.5731,
        0.5695, 0.5663, 0.5782, 0.5698, 0.5596, 0.5729, 0.5690],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5343, 0.5314, 0.5370, 0.5326, 0.5423, 0.5332, 0.5319, 0.5345,
        0.5338, 0.5344, 0.5344, 0.5358, 0.5312, 0.5399, 0.5379],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.5577, 0.5425, 0.5512, 0.5770, 0.5697, 0.5605, 0.5354, 0.5537,
        0.5459, 0.5452, 0.5661, 0.5630, 0.5322, 0.5627, 0.5414],
       device='cuda:0') torch.Size([16])
percent tensor([0.6669, 0.6792, 0.6452, 0.6363, 0.6432, 0.6320, 0.6801, 0.6462, 0.6590,
        0.6713, 0.6890, 0.6613, 0.6739, 0.6706, 0.6758, 0.6572],
       device='cuda:0') torch.Size([16])
percent tensor([0.5649, 0.5871, 0.7050, 0.8031, 0.7114, 0.7394, 0.5957, 0.5815, 0.7394,
        0.6009, 0.6805, 0.7125, 0.6103, 0.7962, 0.5495, 0.6348],
       device='cuda:0') torch.Size([16])
percent tensor([0.7042, 0.6578, 0.7332, 0.7428, 0.7532, 0.7238, 0.7235, 0.7350, 0.6960,
        0.6601, 0.6556, 0.7163, 0.6252, 0.7041, 0.7082, 0.7070],
       device='cuda:0') torch.Size([16])
percent tensor([0.5764, 0.6385, 0.7627, 0.5962, 0.7466, 0.7759, 0.6711, 0.6025, 0.6054,
        0.5985, 0.6474, 0.5109, 0.5630, 0.5354, 0.5441, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9998, 0.9998, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9995, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 184 | Batch_idx: 0 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 184 | Batch_idx: 10 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 184 | Batch_idx: 20 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (2617/2688)
Epoch: 184 | Batch_idx: 30 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (3866/3968)
Epoch: 184 | Batch_idx: 40 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (5116/5248)
Epoch: 184 | Batch_idx: 50 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (6364/6528)
Epoch: 184 | Batch_idx: 60 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (7608/7808)
Epoch: 184 | Batch_idx: 70 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (8855/9088)
Epoch: 184 | Batch_idx: 80 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (10101/10368)
Epoch: 184 | Batch_idx: 90 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (11344/11648)
Epoch: 184 | Batch_idx: 100 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (12576/12928)
Epoch: 184 | Batch_idx: 110 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (13816/14208)
Epoch: 184 | Batch_idx: 120 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (15042/15488)
Epoch: 184 | Batch_idx: 130 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (16282/16768)
Epoch: 184 | Batch_idx: 140 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (17522/18048)
Epoch: 184 | Batch_idx: 150 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (18765/19328)
Epoch: 184 | Batch_idx: 160 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (20008/20608)
Epoch: 184 | Batch_idx: 170 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (21247/21888)
Epoch: 184 | Batch_idx: 180 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (22492/23168)
Epoch: 184 | Batch_idx: 190 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (23719/24448)
Epoch: 184 | Batch_idx: 200 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (24962/25728)
Epoch: 184 | Batch_idx: 210 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (96.00%) (26193/27008)
Epoch: 184 | Batch_idx: 220 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (96.00%) (27434/28288)
Epoch: 184 | Batch_idx: 230 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (28674/29568)
Epoch: 184 | Batch_idx: 240 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (96.00%) (29912/30848)
Epoch: 184 | Batch_idx: 250 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (31158/32128)
Epoch: 184 | Batch_idx: 260 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (32414/33408)
Epoch: 184 | Batch_idx: 270 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (33658/34688)
Epoch: 184 | Batch_idx: 280 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (34907/35968)
Epoch: 184 | Batch_idx: 290 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (36155/37248)
Epoch: 184 | Batch_idx: 300 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (37391/38528)
Epoch: 184 | Batch_idx: 310 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (38634/39808)
Epoch: 184 | Batch_idx: 320 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (39870/41088)
Epoch: 184 | Batch_idx: 330 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (41118/42368)
Epoch: 184 | Batch_idx: 340 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (42357/43648)
Epoch: 184 | Batch_idx: 350 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (43590/44928)
Epoch: 184 | Batch_idx: 360 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (44829/46208)
Epoch: 184 | Batch_idx: 370 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (46065/47488)
Epoch: 184 | Batch_idx: 380 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (47304/48768)
Epoch: 184 | Batch_idx: 390 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (48494/50000)
# TEST : Loss: (0.4235) | Acc: (88.00%) (8819/10000)
percent tensor([0.5721, 0.5679, 0.5819, 0.5752, 0.5919, 0.5758, 0.5788, 0.5837, 0.5736,
        0.5700, 0.5671, 0.5776, 0.5700, 0.5605, 0.5731, 0.5692],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5349, 0.5313, 0.5380, 0.5323, 0.5416, 0.5337, 0.5330, 0.5350,
        0.5348, 0.5348, 0.5344, 0.5360, 0.5329, 0.5400, 0.5389],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.5566, 0.5477, 0.5504, 0.5791, 0.5667, 0.5622, 0.5389, 0.5552,
        0.5461, 0.5439, 0.5651, 0.5597, 0.5388, 0.5577, 0.5409],
       device='cuda:0') torch.Size([16])
percent tensor([0.6666, 0.6783, 0.6435, 0.6319, 0.6402, 0.6317, 0.6778, 0.6416, 0.6567,
        0.6718, 0.6866, 0.6609, 0.6720, 0.6713, 0.6764, 0.6539],
       device='cuda:0') torch.Size([16])
percent tensor([0.5700, 0.5793, 0.7096, 0.8175, 0.7154, 0.7318, 0.6080, 0.5852, 0.7391,
        0.5921, 0.6724, 0.7122, 0.6133, 0.7757, 0.5545, 0.6256],
       device='cuda:0') torch.Size([16])
percent tensor([0.7078, 0.6600, 0.7329, 0.7350, 0.7466, 0.7212, 0.7307, 0.7367, 0.7036,
        0.6699, 0.6606, 0.7137, 0.6359, 0.7027, 0.7140, 0.7061],
       device='cuda:0') torch.Size([16])
percent tensor([0.5934, 0.6428, 0.7577, 0.6264, 0.7400, 0.7958, 0.6608, 0.5969, 0.5885,
        0.5786, 0.6639, 0.5007, 0.5844, 0.5051, 0.5873, 0.5690],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9998, 0.9991, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9995, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 185 | Batch_idx: 0 |  Loss: (0.0231) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 185 | Batch_idx: 10 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 185 | Batch_idx: 20 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (95.00%) (2574/2688)
Epoch: 185 | Batch_idx: 30 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (95.00%) (3794/3968)
Epoch: 185 | Batch_idx: 40 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 185 | Batch_idx: 50 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (6214/6528)
Epoch: 185 | Batch_idx: 60 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (7430/7808)
Epoch: 185 | Batch_idx: 70 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (8654/9088)
Epoch: 185 | Batch_idx: 80 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (9869/10368)
Epoch: 185 | Batch_idx: 90 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (11096/11648)
Epoch: 185 | Batch_idx: 100 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (12304/12928)
Epoch: 185 | Batch_idx: 110 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (13513/14208)
Epoch: 185 | Batch_idx: 120 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (14728/15488)
Epoch: 185 | Batch_idx: 130 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (15945/16768)
Epoch: 185 | Batch_idx: 140 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (17165/18048)
Epoch: 185 | Batch_idx: 150 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (18402/19328)
Epoch: 185 | Batch_idx: 160 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (19624/20608)
Epoch: 185 | Batch_idx: 170 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (20857/21888)
Epoch: 185 | Batch_idx: 180 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (22063/23168)
Epoch: 185 | Batch_idx: 190 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (23277/24448)
Epoch: 185 | Batch_idx: 200 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (24505/25728)
Epoch: 185 | Batch_idx: 210 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (25729/27008)
Epoch: 185 | Batch_idx: 220 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (26960/28288)
Epoch: 185 | Batch_idx: 230 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (28191/29568)
Epoch: 185 | Batch_idx: 240 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (29422/30848)
Epoch: 185 | Batch_idx: 250 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (30657/32128)
Epoch: 185 | Batch_idx: 260 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (31880/33408)
Epoch: 185 | Batch_idx: 270 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (33108/34688)
Epoch: 185 | Batch_idx: 280 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (34345/35968)
Epoch: 185 | Batch_idx: 290 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (35585/37248)
Epoch: 185 | Batch_idx: 300 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (36813/38528)
Epoch: 185 | Batch_idx: 310 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (38044/39808)
Epoch: 185 | Batch_idx: 320 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (39280/41088)
Epoch: 185 | Batch_idx: 330 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (40515/42368)
Epoch: 185 | Batch_idx: 340 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (41756/43648)
Epoch: 185 | Batch_idx: 350 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (42991/44928)
Epoch: 185 | Batch_idx: 360 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (44214/46208)
Epoch: 185 | Batch_idx: 370 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (45443/47488)
Epoch: 185 | Batch_idx: 380 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (46674/48768)
Epoch: 185 | Batch_idx: 390 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (47850/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_185.pth.tar'
# TEST : Loss: (0.4398) | Acc: (87.00%) (8784/10000)
percent tensor([0.5913, 0.5874, 0.6028, 0.5935, 0.6138, 0.5935, 0.5997, 0.6038, 0.5931,
        0.5897, 0.5859, 0.5992, 0.5894, 0.5775, 0.5920, 0.5872],
       device='cuda:0') torch.Size([16])
percent tensor([0.5427, 0.5422, 0.5335, 0.5413, 0.5359, 0.5468, 0.5403, 0.5365, 0.5403,
        0.5408, 0.5419, 0.5398, 0.5426, 0.5391, 0.5467, 0.5445],
       device='cuda:0') torch.Size([16])
percent tensor([0.5271, 0.5579, 0.5438, 0.5546, 0.5792, 0.5797, 0.5607, 0.5378, 0.5537,
        0.5448, 0.5419, 0.5630, 0.5595, 0.5420, 0.5631, 0.5460],
       device='cuda:0') torch.Size([16])
percent tensor([0.6399, 0.6517, 0.6164, 0.6081, 0.6147, 0.6087, 0.6507, 0.6139, 0.6318,
        0.6452, 0.6606, 0.6321, 0.6473, 0.6449, 0.6491, 0.6288],
       device='cuda:0') torch.Size([16])
percent tensor([0.5667, 0.5928, 0.7059, 0.7964, 0.6836, 0.7155, 0.5975, 0.5572, 0.7506,
        0.6295, 0.7154, 0.7264, 0.6356, 0.8071, 0.5421, 0.6252],
       device='cuda:0') torch.Size([16])
percent tensor([0.7055, 0.6543, 0.7321, 0.7324, 0.7489, 0.7162, 0.7262, 0.7372, 0.7032,
        0.6642, 0.6506, 0.7136, 0.6366, 0.6956, 0.7083, 0.7021],
       device='cuda:0') torch.Size([16])
percent tensor([0.5434, 0.5847, 0.7479, 0.6342, 0.7403, 0.7628, 0.6379, 0.5855, 0.5661,
        0.5344, 0.5646, 0.4592, 0.5173, 0.4858, 0.5608, 0.5363],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9997, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9996, 0.9993, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 186 | Batch_idx: 0 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 186 | Batch_idx: 10 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 186 | Batch_idx: 20 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (2607/2688)
Epoch: 186 | Batch_idx: 30 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (3830/3968)
Epoch: 186 | Batch_idx: 40 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (5055/5248)
Epoch: 186 | Batch_idx: 50 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (6287/6528)
Epoch: 186 | Batch_idx: 60 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (7517/7808)
Epoch: 186 | Batch_idx: 70 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (8750/9088)
Epoch: 186 | Batch_idx: 80 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (9989/10368)
Epoch: 186 | Batch_idx: 90 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (11223/11648)
Epoch: 186 | Batch_idx: 100 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (12454/12928)
Epoch: 186 | Batch_idx: 110 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (13689/14208)
Epoch: 186 | Batch_idx: 120 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (14929/15488)
Epoch: 186 | Batch_idx: 130 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (16164/16768)
Epoch: 186 | Batch_idx: 140 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (17397/18048)
Epoch: 186 | Batch_idx: 150 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (18623/19328)
Epoch: 186 | Batch_idx: 160 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (19862/20608)
Epoch: 186 | Batch_idx: 170 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (21092/21888)
Epoch: 186 | Batch_idx: 180 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (22321/23168)
Epoch: 186 | Batch_idx: 190 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (23557/24448)
Epoch: 186 | Batch_idx: 200 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (24782/25728)
Epoch: 186 | Batch_idx: 210 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (26009/27008)
Epoch: 186 | Batch_idx: 220 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (27243/28288)
Epoch: 186 | Batch_idx: 230 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (28492/29568)
Epoch: 186 | Batch_idx: 240 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (29734/30848)
Epoch: 186 | Batch_idx: 250 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (30960/32128)
Epoch: 186 | Batch_idx: 260 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (32212/33408)
Epoch: 186 | Batch_idx: 270 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (33450/34688)
Epoch: 186 | Batch_idx: 280 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (34678/35968)
Epoch: 186 | Batch_idx: 290 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (35928/37248)
Epoch: 186 | Batch_idx: 300 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (37169/38528)
Epoch: 186 | Batch_idx: 310 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (38406/39808)
Epoch: 186 | Batch_idx: 320 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (39629/41088)
Epoch: 186 | Batch_idx: 330 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (40852/42368)
Epoch: 186 | Batch_idx: 340 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (42086/43648)
Epoch: 186 | Batch_idx: 350 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (43328/44928)
Epoch: 186 | Batch_idx: 360 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (44563/46208)
Epoch: 186 | Batch_idx: 370 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (45806/47488)
Epoch: 186 | Batch_idx: 380 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (47050/48768)
Epoch: 186 | Batch_idx: 390 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (48254/50000)
# TEST : Loss: (0.4184) | Acc: (88.00%) (8840/10000)
percent tensor([0.5907, 0.5863, 0.6016, 0.5922, 0.6127, 0.5927, 0.5987, 0.6025, 0.5924,
        0.5888, 0.5852, 0.5984, 0.5887, 0.5763, 0.5910, 0.5860],
       device='cuda:0') torch.Size([16])
percent tensor([0.5426, 0.5425, 0.5323, 0.5406, 0.5347, 0.5467, 0.5399, 0.5351, 0.5401,
        0.5410, 0.5423, 0.5393, 0.5425, 0.5395, 0.5467, 0.5445],
       device='cuda:0') torch.Size([16])
percent tensor([0.5258, 0.5559, 0.5452, 0.5593, 0.5825, 0.5868, 0.5576, 0.5383, 0.5516,
        0.5438, 0.5379, 0.5628, 0.5573, 0.5391, 0.5639, 0.5489],
       device='cuda:0') torch.Size([16])
percent tensor([0.6424, 0.6551, 0.6184, 0.6104, 0.6158, 0.6105, 0.6535, 0.6144, 0.6353,
        0.6490, 0.6648, 0.6349, 0.6511, 0.6488, 0.6519, 0.6319],
       device='cuda:0') torch.Size([16])
percent tensor([0.5647, 0.5973, 0.6987, 0.7902, 0.6731, 0.7074, 0.6009, 0.5489, 0.7542,
        0.6451, 0.7396, 0.7226, 0.6375, 0.8227, 0.5371, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.7062, 0.6528, 0.7377, 0.7349, 0.7538, 0.7175, 0.7245, 0.7430, 0.7019,
        0.6614, 0.6454, 0.7115, 0.6314, 0.6911, 0.7090, 0.7014],
       device='cuda:0') torch.Size([16])
percent tensor([0.5452, 0.5856, 0.7596, 0.6331, 0.7471, 0.7516, 0.6331, 0.6022, 0.5616,
        0.5283, 0.5447, 0.4606, 0.5085, 0.4806, 0.5754, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9996, 0.9993, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 187 | Batch_idx: 0 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 187 | Batch_idx: 10 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 187 | Batch_idx: 20 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (2600/2688)
Epoch: 187 | Batch_idx: 30 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (3842/3968)
Epoch: 187 | Batch_idx: 40 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (5082/5248)
Epoch: 187 | Batch_idx: 50 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (6324/6528)
Epoch: 187 | Batch_idx: 60 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (7567/7808)
Epoch: 187 | Batch_idx: 70 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (8812/9088)
Epoch: 187 | Batch_idx: 80 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (10046/10368)
Epoch: 187 | Batch_idx: 90 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (11284/11648)
Epoch: 187 | Batch_idx: 100 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (12522/12928)
Epoch: 187 | Batch_idx: 110 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (13765/14208)
Epoch: 187 | Batch_idx: 120 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (15011/15488)
Epoch: 187 | Batch_idx: 130 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (16241/16768)
Epoch: 187 | Batch_idx: 140 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (17471/18048)
Epoch: 187 | Batch_idx: 150 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (18707/19328)
Epoch: 187 | Batch_idx: 160 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (19947/20608)
Epoch: 187 | Batch_idx: 170 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (21182/21888)
Epoch: 187 | Batch_idx: 180 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (22420/23168)
Epoch: 187 | Batch_idx: 190 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (23661/24448)
Epoch: 187 | Batch_idx: 200 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (24906/25728)
Epoch: 187 | Batch_idx: 210 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (26143/27008)
Epoch: 187 | Batch_idx: 220 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (27387/28288)
Epoch: 187 | Batch_idx: 230 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (28627/29568)
Epoch: 187 | Batch_idx: 240 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (29854/30848)
Epoch: 187 | Batch_idx: 250 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (31087/32128)
Epoch: 187 | Batch_idx: 260 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (32336/33408)
Epoch: 187 | Batch_idx: 270 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (33563/34688)
Epoch: 187 | Batch_idx: 280 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (34812/35968)
Epoch: 187 | Batch_idx: 290 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (36055/37248)
Epoch: 187 | Batch_idx: 300 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (37301/38528)
Epoch: 187 | Batch_idx: 310 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (38543/39808)
Epoch: 187 | Batch_idx: 320 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (39799/41088)
Epoch: 187 | Batch_idx: 330 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (41042/42368)
Epoch: 187 | Batch_idx: 340 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (42289/43648)
Epoch: 187 | Batch_idx: 350 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (43534/44928)
Epoch: 187 | Batch_idx: 360 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (44782/46208)
Epoch: 187 | Batch_idx: 370 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (46029/47488)
Epoch: 187 | Batch_idx: 380 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (47262/48768)
Epoch: 187 | Batch_idx: 390 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (48451/50000)
# TEST : Loss: (0.4071) | Acc: (88.00%) (8858/10000)
percent tensor([0.5880, 0.5834, 0.5984, 0.5890, 0.6092, 0.5896, 0.5956, 0.5990, 0.5899,
        0.5859, 0.5827, 0.5954, 0.5860, 0.5740, 0.5878, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.5413, 0.5411, 0.5306, 0.5389, 0.5328, 0.5456, 0.5383, 0.5329, 0.5387,
        0.5397, 0.5412, 0.5377, 0.5412, 0.5384, 0.5453, 0.5431],
       device='cuda:0') torch.Size([16])
percent tensor([0.5261, 0.5566, 0.5465, 0.5622, 0.5835, 0.5912, 0.5572, 0.5379, 0.5528,
        0.5451, 0.5392, 0.5634, 0.5577, 0.5418, 0.5657, 0.5517],
       device='cuda:0') torch.Size([16])
percent tensor([0.6395, 0.6526, 0.6154, 0.6076, 0.6128, 0.6081, 0.6505, 0.6110, 0.6321,
        0.6465, 0.6619, 0.6320, 0.6484, 0.6461, 0.6493, 0.6293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5677, 0.6055, 0.6939, 0.7857, 0.6688, 0.7077, 0.6038, 0.5447, 0.7551,
        0.6552, 0.7533, 0.7174, 0.6433, 0.8297, 0.5373, 0.6336],
       device='cuda:0') torch.Size([16])
percent tensor([0.7107, 0.6557, 0.7441, 0.7408, 0.7610, 0.7217, 0.7286, 0.7505, 0.7051,
        0.6633, 0.6458, 0.7137, 0.6320, 0.6921, 0.7133, 0.7049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5417, 0.5803, 0.7618, 0.6279, 0.7463, 0.7464, 0.6300, 0.6028, 0.5665,
        0.5141, 0.5403, 0.4557, 0.4950, 0.4807, 0.5770, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 1.0000, 0.9999, 0.9998, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9996, 0.9993, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 188 | Batch_idx: 0 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 188 | Batch_idx: 10 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 188 | Batch_idx: 20 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (2613/2688)
Epoch: 188 | Batch_idx: 30 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 188 | Batch_idx: 40 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (5106/5248)
Epoch: 188 | Batch_idx: 50 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (6346/6528)
Epoch: 188 | Batch_idx: 60 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (7596/7808)
Epoch: 188 | Batch_idx: 70 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (8831/9088)
Epoch: 188 | Batch_idx: 80 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (10077/10368)
Epoch: 188 | Batch_idx: 90 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (11328/11648)
Epoch: 188 | Batch_idx: 100 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (12573/12928)
Epoch: 188 | Batch_idx: 110 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (13809/14208)
Epoch: 188 | Batch_idx: 120 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (15047/15488)
Epoch: 188 | Batch_idx: 130 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (16295/16768)
Epoch: 188 | Batch_idx: 140 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (17531/18048)
Epoch: 188 | Batch_idx: 150 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (18774/19328)
Epoch: 188 | Batch_idx: 160 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (20016/20608)
Epoch: 188 | Batch_idx: 170 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (21254/21888)
Epoch: 188 | Batch_idx: 180 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (22495/23168)
Epoch: 188 | Batch_idx: 190 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (23730/24448)
Epoch: 188 | Batch_idx: 200 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (24979/25728)
Epoch: 188 | Batch_idx: 210 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (26219/27008)
Epoch: 188 | Batch_idx: 220 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (27455/28288)
Epoch: 188 | Batch_idx: 230 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (28701/29568)
Epoch: 188 | Batch_idx: 240 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (29946/30848)
Epoch: 188 | Batch_idx: 250 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (31192/32128)
Epoch: 188 | Batch_idx: 260 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (32432/33408)
Epoch: 188 | Batch_idx: 270 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (33676/34688)
Epoch: 188 | Batch_idx: 280 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (34917/35968)
Epoch: 188 | Batch_idx: 290 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (36161/37248)
Epoch: 188 | Batch_idx: 300 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (37414/38528)
Epoch: 188 | Batch_idx: 310 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (38646/39808)
Epoch: 188 | Batch_idx: 320 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (39886/41088)
Epoch: 188 | Batch_idx: 330 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (41134/42368)
Epoch: 188 | Batch_idx: 340 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (42379/43648)
Epoch: 188 | Batch_idx: 350 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (43624/44928)
Epoch: 188 | Batch_idx: 360 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (44865/46208)
Epoch: 188 | Batch_idx: 370 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (46115/47488)
Epoch: 188 | Batch_idx: 380 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (47365/48768)
Epoch: 188 | Batch_idx: 390 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (48564/50000)
# TEST : Loss: (0.4132) | Acc: (88.00%) (8856/10000)
percent tensor([0.5895, 0.5852, 0.5997, 0.5904, 0.6108, 0.5909, 0.5974, 0.6004, 0.5916,
        0.5875, 0.5844, 0.5969, 0.5876, 0.5757, 0.5894, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5413, 0.5302, 0.5387, 0.5323, 0.5455, 0.5382, 0.5324, 0.5385,
        0.5399, 0.5415, 0.5375, 0.5412, 0.5386, 0.5455, 0.5431],
       device='cuda:0') torch.Size([16])
percent tensor([0.5250, 0.5553, 0.5439, 0.5603, 0.5810, 0.5880, 0.5559, 0.5350, 0.5511,
        0.5445, 0.5379, 0.5608, 0.5567, 0.5400, 0.5628, 0.5493],
       device='cuda:0') torch.Size([16])
percent tensor([0.6438, 0.6564, 0.6196, 0.6115, 0.6163, 0.6124, 0.6542, 0.6145, 0.6364,
        0.6510, 0.6663, 0.6364, 0.6528, 0.6507, 0.6533, 0.6336],
       device='cuda:0') torch.Size([16])
percent tensor([0.5550, 0.5886, 0.6834, 0.7761, 0.6595, 0.6987, 0.5901, 0.5364, 0.7436,
        0.6417, 0.7458, 0.7022, 0.6230, 0.8222, 0.5227, 0.6221],
       device='cuda:0') torch.Size([16])
percent tensor([0.7086, 0.6504, 0.7436, 0.7411, 0.7621, 0.7218, 0.7247, 0.7507, 0.7010,
        0.6560, 0.6375, 0.7087, 0.6261, 0.6862, 0.7103, 0.7025],
       device='cuda:0') torch.Size([16])
percent tensor([0.5591, 0.6034, 0.7709, 0.6330, 0.7478, 0.7554, 0.6496, 0.6037, 0.5904,
        0.5366, 0.5599, 0.4751, 0.5240, 0.4963, 0.5938, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 1.0000, 0.9999, 0.9998, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9994, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 189 | Batch_idx: 0 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 189 | Batch_idx: 10 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 189 | Batch_idx: 20 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (2605/2688)
Epoch: 189 | Batch_idx: 30 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (3840/3968)
Epoch: 189 | Batch_idx: 40 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (96.00%) (5085/5248)
Epoch: 189 | Batch_idx: 50 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (6340/6528)
Epoch: 189 | Batch_idx: 60 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (7585/7808)
Epoch: 189 | Batch_idx: 70 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (8836/9088)
Epoch: 189 | Batch_idx: 80 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (10084/10368)
Epoch: 189 | Batch_idx: 90 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (11328/11648)
Epoch: 189 | Batch_idx: 100 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (12573/12928)
Epoch: 189 | Batch_idx: 110 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (13833/14208)
Epoch: 189 | Batch_idx: 120 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (15070/15488)
Epoch: 189 | Batch_idx: 130 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (16313/16768)
Epoch: 189 | Batch_idx: 140 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (17549/18048)
Epoch: 189 | Batch_idx: 150 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (18803/19328)
Epoch: 189 | Batch_idx: 160 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (20039/20608)
Epoch: 189 | Batch_idx: 170 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (21270/21888)
Epoch: 189 | Batch_idx: 180 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (22500/23168)
Epoch: 189 | Batch_idx: 190 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (23752/24448)
Epoch: 189 | Batch_idx: 200 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (24995/25728)
Epoch: 189 | Batch_idx: 210 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (26248/27008)
Epoch: 189 | Batch_idx: 220 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (27495/28288)
Epoch: 189 | Batch_idx: 230 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (28743/29568)
Epoch: 189 | Batch_idx: 240 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (29984/30848)
Epoch: 189 | Batch_idx: 250 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (31232/32128)
Epoch: 189 | Batch_idx: 260 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (32470/33408)
Epoch: 189 | Batch_idx: 270 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (33719/34688)
Epoch: 189 | Batch_idx: 280 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (34970/35968)
Epoch: 189 | Batch_idx: 290 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (36201/37248)
Epoch: 189 | Batch_idx: 300 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (37442/38528)
Epoch: 189 | Batch_idx: 310 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (38682/39808)
Epoch: 189 | Batch_idx: 320 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (39925/41088)
Epoch: 189 | Batch_idx: 330 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (41168/42368)
Epoch: 189 | Batch_idx: 340 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (42418/43648)
Epoch: 189 | Batch_idx: 350 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (43673/44928)
Epoch: 189 | Batch_idx: 360 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (44911/46208)
Epoch: 189 | Batch_idx: 370 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (46166/47488)
Epoch: 189 | Batch_idx: 380 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (47410/48768)
Epoch: 189 | Batch_idx: 390 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (48603/50000)
# TEST : Loss: (0.3997) | Acc: (88.00%) (8869/10000)
percent tensor([0.5898, 0.5855, 0.5999, 0.5906, 0.6110, 0.5914, 0.5977, 0.6006, 0.5919,
        0.5877, 0.5847, 0.5970, 0.5879, 0.5763, 0.5898, 0.5849],
       device='cuda:0') torch.Size([16])
percent tensor([0.5402, 0.5401, 0.5288, 0.5374, 0.5308, 0.5446, 0.5368, 0.5308, 0.5373,
        0.5388, 0.5405, 0.5362, 0.5401, 0.5376, 0.5444, 0.5420],
       device='cuda:0') torch.Size([16])
percent tensor([0.5252, 0.5562, 0.5464, 0.5631, 0.5854, 0.5904, 0.5585, 0.5384, 0.5539,
        0.5456, 0.5387, 0.5640, 0.5576, 0.5421, 0.5651, 0.5509],
       device='cuda:0') torch.Size([16])
percent tensor([0.6482, 0.6610, 0.6227, 0.6143, 0.6196, 0.6167, 0.6583, 0.6176, 0.6402,
        0.6559, 0.6712, 0.6403, 0.6574, 0.6550, 0.6579, 0.6380],
       device='cuda:0') torch.Size([16])
percent tensor([0.5665, 0.6017, 0.6959, 0.7831, 0.6734, 0.7102, 0.6037, 0.5459, 0.7532,
        0.6538, 0.7558, 0.7097, 0.6328, 0.8306, 0.5330, 0.6349],
       device='cuda:0') torch.Size([16])
percent tensor([0.7184, 0.6620, 0.7533, 0.7510, 0.7718, 0.7306, 0.7346, 0.7610, 0.7105,
        0.6659, 0.6465, 0.7190, 0.6354, 0.6974, 0.7206, 0.7117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5718, 0.6158, 0.7787, 0.6407, 0.7545, 0.7628, 0.6598, 0.6103, 0.6072,
        0.5498, 0.5782, 0.4779, 0.5283, 0.5142, 0.6009, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 1.0000, 0.9999, 0.9998, 0.9993, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9993, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 190 | Batch_idx: 0 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 190 | Batch_idx: 10 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 190 | Batch_idx: 20 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 190 | Batch_idx: 30 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (3857/3968)
Epoch: 190 | Batch_idx: 40 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (5087/5248)
Epoch: 190 | Batch_idx: 50 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (6326/6528)
Epoch: 190 | Batch_idx: 60 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (96.00%) (7573/7808)
Epoch: 190 | Batch_idx: 70 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (8811/9088)
Epoch: 190 | Batch_idx: 80 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (10058/10368)
Epoch: 190 | Batch_idx: 90 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (11300/11648)
Epoch: 190 | Batch_idx: 100 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (12543/12928)
Epoch: 190 | Batch_idx: 110 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (13783/14208)
Epoch: 190 | Batch_idx: 120 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (15021/15488)
Epoch: 190 | Batch_idx: 130 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (16274/16768)
Epoch: 190 | Batch_idx: 140 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (17518/18048)
Epoch: 190 | Batch_idx: 150 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (18768/19328)
Epoch: 190 | Batch_idx: 160 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (20015/20608)
Epoch: 190 | Batch_idx: 170 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (21263/21888)
Epoch: 190 | Batch_idx: 180 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (22497/23168)
Epoch: 190 | Batch_idx: 190 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (23745/24448)
Epoch: 190 | Batch_idx: 200 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (24989/25728)
Epoch: 190 | Batch_idx: 210 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (26239/27008)
Epoch: 190 | Batch_idx: 220 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (27482/28288)
Epoch: 190 | Batch_idx: 230 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (28730/29568)
Epoch: 190 | Batch_idx: 240 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (29975/30848)
Epoch: 190 | Batch_idx: 250 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (31226/32128)
Epoch: 190 | Batch_idx: 260 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (32465/33408)
Epoch: 190 | Batch_idx: 270 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (33712/34688)
Epoch: 190 | Batch_idx: 280 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (34951/35968)
Epoch: 190 | Batch_idx: 290 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (36192/37248)
Epoch: 190 | Batch_idx: 300 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (37443/38528)
Epoch: 190 | Batch_idx: 310 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (38684/39808)
Epoch: 190 | Batch_idx: 320 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (39933/41088)
Epoch: 190 | Batch_idx: 330 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (41170/42368)
Epoch: 190 | Batch_idx: 340 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (42411/43648)
Epoch: 190 | Batch_idx: 350 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (43643/44928)
Epoch: 190 | Batch_idx: 360 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (44882/46208)
Epoch: 190 | Batch_idx: 370 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (46123/47488)
Epoch: 190 | Batch_idx: 380 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (47365/48768)
Epoch: 190 | Batch_idx: 390 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (48565/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_190.pth.tar'
# TEST : Loss: (0.4612) | Acc: (87.00%) (8749/10000)
percent tensor([0.5871, 0.5856, 0.5968, 0.5889, 0.6105, 0.5901, 0.5975, 0.6000, 0.5913,
        0.5872, 0.5841, 0.5950, 0.5868, 0.5777, 0.5888, 0.5838],
       device='cuda:0') torch.Size([16])
percent tensor([0.5409, 0.5416, 0.5305, 0.5386, 0.5321, 0.5454, 0.5370, 0.5312, 0.5380,
        0.5392, 0.5414, 0.5363, 0.5413, 0.5379, 0.5450, 0.5431],
       device='cuda:0') torch.Size([16])
percent tensor([0.5271, 0.5616, 0.5570, 0.5628, 0.5907, 0.5794, 0.5617, 0.5452, 0.5575,
        0.5517, 0.5430, 0.5721, 0.5626, 0.5362, 0.5662, 0.5523],
       device='cuda:0') torch.Size([16])
percent tensor([0.6482, 0.6625, 0.6191, 0.6121, 0.6169, 0.6174, 0.6603, 0.6158, 0.6416,
        0.6566, 0.6713, 0.6391, 0.6570, 0.6549, 0.6564, 0.6380],
       device='cuda:0') torch.Size([16])
percent tensor([0.5590, 0.6026, 0.7033, 0.7868, 0.6952, 0.6968, 0.6035, 0.5564, 0.7599,
        0.6260, 0.7451, 0.7092, 0.6224, 0.8243, 0.5300, 0.6202],
       device='cuda:0') torch.Size([16])
percent tensor([0.7180, 0.6641, 0.7634, 0.7532, 0.7806, 0.7388, 0.7340, 0.7687, 0.7099,
        0.6647, 0.6607, 0.7163, 0.6350, 0.6890, 0.7282, 0.7138],
       device='cuda:0') torch.Size([16])
percent tensor([0.5464, 0.6268, 0.7514, 0.6205, 0.7795, 0.7284, 0.6741, 0.6319, 0.5444,
        0.5978, 0.6367, 0.5028, 0.5434, 0.4881, 0.5820, 0.4680],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9995, 0.9997, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.5478, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(833.7154, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(839.3693, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1507.8180, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(481.2183, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2276.4136, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4265.9390, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1342.8783, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6247.0273, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11537.5928, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3794.0808, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16057.7979, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 191 | Batch_idx: 0 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 191 | Batch_idx: 10 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 191 | Batch_idx: 20 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 191 | Batch_idx: 30 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (3870/3968)
Epoch: 191 | Batch_idx: 40 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (5116/5248)
Epoch: 191 | Batch_idx: 50 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (6363/6528)
Epoch: 191 | Batch_idx: 60 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (7607/7808)
Epoch: 191 | Batch_idx: 70 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (8851/9088)
Epoch: 191 | Batch_idx: 80 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (10102/10368)
Epoch: 191 | Batch_idx: 90 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (11344/11648)
Epoch: 191 | Batch_idx: 100 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (12576/12928)
Epoch: 191 | Batch_idx: 110 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (13823/14208)
Epoch: 191 | Batch_idx: 120 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (15075/15488)
Epoch: 191 | Batch_idx: 130 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (16332/16768)
Epoch: 191 | Batch_idx: 140 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (17580/18048)
Epoch: 191 | Batch_idx: 150 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (18832/19328)
Epoch: 191 | Batch_idx: 160 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (20080/20608)
Epoch: 191 | Batch_idx: 170 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (21318/21888)
Epoch: 191 | Batch_idx: 180 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (22560/23168)
Epoch: 191 | Batch_idx: 190 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (23810/24448)
Epoch: 191 | Batch_idx: 200 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (25059/25728)
Epoch: 191 | Batch_idx: 210 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (26304/27008)
Epoch: 191 | Batch_idx: 220 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (27561/28288)
Epoch: 191 | Batch_idx: 230 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (28813/29568)
Epoch: 191 | Batch_idx: 240 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (30059/30848)
Epoch: 191 | Batch_idx: 250 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (31303/32128)
Epoch: 191 | Batch_idx: 260 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (32554/33408)
Epoch: 191 | Batch_idx: 270 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (33798/34688)
Epoch: 191 | Batch_idx: 280 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (35044/35968)
Epoch: 191 | Batch_idx: 290 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (36291/37248)
Epoch: 191 | Batch_idx: 300 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (37534/38528)
Epoch: 191 | Batch_idx: 310 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (38779/39808)
Epoch: 191 | Batch_idx: 320 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (40015/41088)
Epoch: 191 | Batch_idx: 330 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (41248/42368)
Epoch: 191 | Batch_idx: 340 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (42493/43648)
Epoch: 191 | Batch_idx: 350 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (43738/44928)
Epoch: 191 | Batch_idx: 360 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (44975/46208)
Epoch: 191 | Batch_idx: 370 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (46206/47488)
Epoch: 191 | Batch_idx: 380 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (47442/48768)
Epoch: 191 | Batch_idx: 390 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (48634/50000)
# TEST : Loss: (0.4129) | Acc: (88.00%) (8858/10000)
percent tensor([0.5875, 0.5841, 0.5952, 0.5877, 0.6085, 0.5904, 0.5960, 0.5985, 0.5904,
        0.5859, 0.5838, 0.5933, 0.5867, 0.5750, 0.5886, 0.5830],
       device='cuda:0') torch.Size([16])
percent tensor([0.5399, 0.5393, 0.5306, 0.5377, 0.5318, 0.5436, 0.5358, 0.5311, 0.5371,
        0.5384, 0.5394, 0.5361, 0.5401, 0.5358, 0.5433, 0.5411],
       device='cuda:0') torch.Size([16])
percent tensor([0.5227, 0.5542, 0.5497, 0.5626, 0.5862, 0.5861, 0.5544, 0.5379, 0.5477,
        0.5447, 0.5353, 0.5650, 0.5563, 0.5345, 0.5627, 0.5499],
       device='cuda:0') torch.Size([16])
percent tensor([0.6469, 0.6602, 0.6208, 0.6143, 0.6175, 0.6143, 0.6562, 0.6162, 0.6406,
        0.6540, 0.6696, 0.6391, 0.6566, 0.6509, 0.6546, 0.6372],
       device='cuda:0') torch.Size([16])
percent tensor([0.5722, 0.5991, 0.7340, 0.8046, 0.7241, 0.7333, 0.6041, 0.5722, 0.7454,
        0.6359, 0.7279, 0.7310, 0.6130, 0.8197, 0.5433, 0.6333],
       device='cuda:0') torch.Size([16])
percent tensor([0.7157, 0.6596, 0.7512, 0.7492, 0.7768, 0.7222, 0.7299, 0.7680, 0.7099,
        0.6568, 0.6486, 0.7109, 0.6338, 0.6939, 0.7177, 0.7077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5410, 0.6139, 0.7235, 0.6253, 0.7387, 0.7656, 0.6803, 0.5607, 0.5717,
        0.5780, 0.6224, 0.5236, 0.5449, 0.5349, 0.5719, 0.4904],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 1.0000, 0.9999, 0.9997, 0.9994, 0.9999, 0.9998, 0.9999,
        0.9998, 1.0000, 0.9999, 0.9995, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 192 | Batch_idx: 0 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 192 | Batch_idx: 10 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 192 | Batch_idx: 20 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 192 | Batch_idx: 30 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (3875/3968)
Epoch: 192 | Batch_idx: 40 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (5124/5248)
Epoch: 192 | Batch_idx: 50 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (6366/6528)
Epoch: 192 | Batch_idx: 60 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (7616/7808)
Epoch: 192 | Batch_idx: 70 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (8859/9088)
Epoch: 192 | Batch_idx: 80 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (10103/10368)
Epoch: 192 | Batch_idx: 90 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (11351/11648)
Epoch: 192 | Batch_idx: 100 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (12604/12928)
Epoch: 192 | Batch_idx: 110 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (13856/14208)
Epoch: 192 | Batch_idx: 120 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (15099/15488)
Epoch: 192 | Batch_idx: 130 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (16343/16768)
Epoch: 192 | Batch_idx: 140 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (17595/18048)
Epoch: 192 | Batch_idx: 150 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (18846/19328)
Epoch: 192 | Batch_idx: 160 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (20086/20608)
Epoch: 192 | Batch_idx: 170 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (21323/21888)
Epoch: 192 | Batch_idx: 180 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (22566/23168)
Epoch: 192 | Batch_idx: 190 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (23808/24448)
Epoch: 192 | Batch_idx: 200 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (25056/25728)
Epoch: 192 | Batch_idx: 210 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (26304/27008)
Epoch: 192 | Batch_idx: 220 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (27550/28288)
Epoch: 192 | Batch_idx: 230 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (28796/29568)
Epoch: 192 | Batch_idx: 240 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (30034/30848)
Epoch: 192 | Batch_idx: 250 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (31281/32128)
Epoch: 192 | Batch_idx: 260 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (32516/33408)
Epoch: 192 | Batch_idx: 270 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (33756/34688)
Epoch: 192 | Batch_idx: 280 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (34997/35968)
Epoch: 192 | Batch_idx: 290 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (36237/37248)
Epoch: 192 | Batch_idx: 300 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (37487/38528)
Epoch: 192 | Batch_idx: 310 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (38728/39808)
Epoch: 192 | Batch_idx: 320 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (39977/41088)
Epoch: 192 | Batch_idx: 330 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (41225/42368)
Epoch: 192 | Batch_idx: 340 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (42472/43648)
Epoch: 192 | Batch_idx: 350 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (43702/44928)
Epoch: 192 | Batch_idx: 360 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (44948/46208)
Epoch: 192 | Batch_idx: 370 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (46183/47488)
Epoch: 192 | Batch_idx: 380 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (47427/48768)
Epoch: 192 | Batch_idx: 390 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (48627/50000)
# TEST : Loss: (0.4142) | Acc: (88.00%) (8857/10000)
percent tensor([0.5869, 0.5832, 0.5961, 0.5865, 0.6084, 0.5881, 0.5953, 0.5987, 0.5908,
        0.5859, 0.5838, 0.5936, 0.5862, 0.5733, 0.5870, 0.5825],
       device='cuda:0') torch.Size([16])
percent tensor([0.5400, 0.5403, 0.5306, 0.5381, 0.5313, 0.5431, 0.5365, 0.5312, 0.5374,
        0.5390, 0.5401, 0.5361, 0.5402, 0.5372, 0.5439, 0.5418],
       device='cuda:0') torch.Size([16])
percent tensor([0.5258, 0.5535, 0.5545, 0.5606, 0.5843, 0.5799, 0.5543, 0.5388, 0.5551,
        0.5469, 0.5403, 0.5685, 0.5616, 0.5313, 0.5620, 0.5501],
       device='cuda:0') torch.Size([16])
percent tensor([0.6487, 0.6638, 0.6233, 0.6150, 0.6195, 0.6173, 0.6611, 0.6177, 0.6384,
        0.6578, 0.6715, 0.6398, 0.6563, 0.6550, 0.6607, 0.6396],
       device='cuda:0') torch.Size([16])
percent tensor([0.5729, 0.5933, 0.7001, 0.8032, 0.7187, 0.7392, 0.6058, 0.5696, 0.7559,
        0.6296, 0.7400, 0.7041, 0.6101, 0.8236, 0.5462, 0.6319],
       device='cuda:0') torch.Size([16])
percent tensor([0.7111, 0.6555, 0.7497, 0.7463, 0.7754, 0.7264, 0.7360, 0.7562, 0.7000,
        0.6502, 0.6457, 0.7060, 0.6203, 0.6793, 0.7194, 0.7102],
       device='cuda:0') torch.Size([16])
percent tensor([0.5708, 0.6283, 0.7243, 0.6157, 0.7297, 0.7544, 0.6629, 0.5944, 0.6223,
        0.6206, 0.6184, 0.5027, 0.5517, 0.5114, 0.5688, 0.4985],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 1.0000, 0.9999, 0.9998, 0.9995, 0.9999, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 193 | Batch_idx: 0 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 193 | Batch_idx: 10 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 193 | Batch_idx: 20 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (2633/2688)
Epoch: 193 | Batch_idx: 30 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (98.00%) (3890/3968)
Epoch: 193 | Batch_idx: 40 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (5140/5248)
Epoch: 193 | Batch_idx: 50 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (6392/6528)
Epoch: 193 | Batch_idx: 60 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (7628/7808)
Epoch: 193 | Batch_idx: 70 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (8879/9088)
Epoch: 193 | Batch_idx: 80 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (10125/10368)
Epoch: 193 | Batch_idx: 90 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (11371/11648)
Epoch: 193 | Batch_idx: 100 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (12617/12928)
Epoch: 193 | Batch_idx: 110 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (13863/14208)
Epoch: 193 | Batch_idx: 120 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (15107/15488)
Epoch: 193 | Batch_idx: 130 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (16367/16768)
Epoch: 193 | Batch_idx: 140 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (17605/18048)
Epoch: 193 | Batch_idx: 150 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (18856/19328)
Epoch: 193 | Batch_idx: 160 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (20103/20608)
Epoch: 193 | Batch_idx: 170 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (21349/21888)
Epoch: 193 | Batch_idx: 180 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (22592/23168)
Epoch: 193 | Batch_idx: 190 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (23845/24448)
Epoch: 193 | Batch_idx: 200 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (25093/25728)
Epoch: 193 | Batch_idx: 210 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (26337/27008)
Epoch: 193 | Batch_idx: 220 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (27584/28288)
Epoch: 193 | Batch_idx: 230 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (28833/29568)
Epoch: 193 | Batch_idx: 240 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (30058/30848)
Epoch: 193 | Batch_idx: 250 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (31300/32128)
Epoch: 193 | Batch_idx: 260 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (32546/33408)
Epoch: 193 | Batch_idx: 270 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (33793/34688)
Epoch: 193 | Batch_idx: 280 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (35035/35968)
Epoch: 193 | Batch_idx: 290 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (36279/37248)
Epoch: 193 | Batch_idx: 300 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (37521/38528)
Epoch: 193 | Batch_idx: 310 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (38768/39808)
Epoch: 193 | Batch_idx: 320 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (40000/41088)
Epoch: 193 | Batch_idx: 330 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (41246/42368)
Epoch: 193 | Batch_idx: 340 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (42493/43648)
Epoch: 193 | Batch_idx: 350 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (43726/44928)
Epoch: 193 | Batch_idx: 360 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (44977/46208)
Epoch: 193 | Batch_idx: 370 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (46215/47488)
Epoch: 193 | Batch_idx: 380 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (47456/48768)
Epoch: 193 | Batch_idx: 390 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (48648/50000)
# TEST : Loss: (0.4304) | Acc: (88.00%) (8818/10000)
percent tensor([0.5866, 0.5837, 0.5964, 0.5860, 0.6092, 0.5888, 0.5962, 0.5989, 0.5921,
        0.5857, 0.5841, 0.5946, 0.5867, 0.5759, 0.5874, 0.5827],
       device='cuda:0') torch.Size([16])
percent tensor([0.5405, 0.5402, 0.5333, 0.5396, 0.5331, 0.5443, 0.5369, 0.5325, 0.5378,
        0.5392, 0.5397, 0.5375, 0.5405, 0.5365, 0.5441, 0.5419],
       device='cuda:0') torch.Size([16])
percent tensor([0.5231, 0.5533, 0.5534, 0.5626, 0.5845, 0.5842, 0.5547, 0.5347, 0.5531,
        0.5429, 0.5379, 0.5625, 0.5584, 0.5332, 0.5636, 0.5473],
       device='cuda:0') torch.Size([16])
percent tensor([0.6507, 0.6636, 0.6198, 0.6155, 0.6187, 0.6171, 0.6587, 0.6169, 0.6416,
        0.6602, 0.6713, 0.6412, 0.6607, 0.6545, 0.6575, 0.6404],
       device='cuda:0') torch.Size([16])
percent tensor([0.5627, 0.5951, 0.7341, 0.8115, 0.7245, 0.7162, 0.6133, 0.5833, 0.7570,
        0.6148, 0.7355, 0.7225, 0.6121, 0.8022, 0.5394, 0.6271],
       device='cuda:0') torch.Size([16])
percent tensor([0.7159, 0.6698, 0.7521, 0.7491, 0.7741, 0.7333, 0.7462, 0.7666, 0.7079,
        0.6608, 0.6548, 0.7137, 0.6317, 0.6881, 0.7241, 0.7146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5720, 0.6783, 0.7278, 0.6072, 0.7398, 0.7623, 0.6864, 0.5750, 0.5605,
        0.6168, 0.6738, 0.5342, 0.5675, 0.5146, 0.5896, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9997, 0.9994, 0.9999, 0.9997, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 194 | Batch_idx: 0 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 194 | Batch_idx: 10 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 194 | Batch_idx: 20 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (2635/2688)
Epoch: 194 | Batch_idx: 30 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (3880/3968)
Epoch: 194 | Batch_idx: 40 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (5130/5248)
Epoch: 194 | Batch_idx: 50 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (6372/6528)
Epoch: 194 | Batch_idx: 60 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (7612/7808)
Epoch: 194 | Batch_idx: 70 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (8867/9088)
Epoch: 194 | Batch_idx: 80 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (10114/10368)
Epoch: 194 | Batch_idx: 90 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (11364/11648)
Epoch: 194 | Batch_idx: 100 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (12611/12928)
Epoch: 194 | Batch_idx: 110 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (13857/14208)
Epoch: 194 | Batch_idx: 120 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (15109/15488)
Epoch: 194 | Batch_idx: 130 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (16357/16768)
Epoch: 194 | Batch_idx: 140 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (17602/18048)
Epoch: 194 | Batch_idx: 150 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (18859/19328)
Epoch: 194 | Batch_idx: 160 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (20108/20608)
Epoch: 194 | Batch_idx: 170 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (21357/21888)
Epoch: 194 | Batch_idx: 180 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (22606/23168)
Epoch: 194 | Batch_idx: 190 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (23852/24448)
Epoch: 194 | Batch_idx: 200 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (25094/25728)
Epoch: 194 | Batch_idx: 210 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (26348/27008)
Epoch: 194 | Batch_idx: 220 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (27598/28288)
Epoch: 194 | Batch_idx: 230 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (28853/29568)
Epoch: 194 | Batch_idx: 240 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (30098/30848)
Epoch: 194 | Batch_idx: 250 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (31345/32128)
Epoch: 194 | Batch_idx: 260 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (32588/33408)
Epoch: 194 | Batch_idx: 270 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (33838/34688)
Epoch: 194 | Batch_idx: 280 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (35085/35968)
Epoch: 194 | Batch_idx: 290 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (36341/37248)
Epoch: 194 | Batch_idx: 300 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (37586/38528)
Epoch: 194 | Batch_idx: 310 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (38833/39808)
Epoch: 194 | Batch_idx: 320 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (40078/41088)
Epoch: 194 | Batch_idx: 330 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (41316/42368)
Epoch: 194 | Batch_idx: 340 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (42555/43648)
Epoch: 194 | Batch_idx: 350 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (43795/44928)
Epoch: 194 | Batch_idx: 360 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (45032/46208)
Epoch: 194 | Batch_idx: 370 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (46279/47488)
Epoch: 194 | Batch_idx: 380 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (47521/48768)
Epoch: 194 | Batch_idx: 390 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (48722/50000)
# TEST : Loss: (0.4354) | Acc: (88.00%) (8848/10000)
percent tensor([0.5863, 0.5840, 0.5942, 0.5860, 0.6066, 0.5885, 0.5954, 0.5980, 0.5914,
        0.5848, 0.5843, 0.5922, 0.5865, 0.5766, 0.5874, 0.5828],
       device='cuda:0') torch.Size([16])
percent tensor([0.5398, 0.5406, 0.5303, 0.5383, 0.5318, 0.5441, 0.5368, 0.5306, 0.5368,
        0.5388, 0.5401, 0.5360, 0.5403, 0.5373, 0.5446, 0.5423],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5552, 0.5448, 0.5566, 0.5780, 0.5790, 0.5547, 0.5322, 0.5520,
        0.5438, 0.5370, 0.5609, 0.5577, 0.5399, 0.5621, 0.5481],
       device='cuda:0') torch.Size([16])
percent tensor([0.6522, 0.6638, 0.6265, 0.6168, 0.6229, 0.6172, 0.6589, 0.6207, 0.6393,
        0.6615, 0.6700, 0.6431, 0.6583, 0.6545, 0.6574, 0.6401],
       device='cuda:0') torch.Size([16])
percent tensor([0.5734, 0.5952, 0.7178, 0.7984, 0.7015, 0.7218, 0.6068, 0.5752, 0.7555,
        0.6371, 0.7482, 0.7218, 0.6217, 0.8140, 0.5398, 0.6354],
       device='cuda:0') torch.Size([16])
percent tensor([0.7118, 0.6582, 0.7440, 0.7463, 0.7687, 0.7408, 0.7345, 0.7624, 0.7031,
        0.6531, 0.6451, 0.7099, 0.6232, 0.6848, 0.7202, 0.7049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5791, 0.6563, 0.7119, 0.5978, 0.7464, 0.7597, 0.6998, 0.6027, 0.5930,
        0.6081, 0.6413, 0.4833, 0.5486, 0.5044, 0.5802, 0.4809],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 195 | Batch_idx: 0 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 195 | Batch_idx: 10 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 195 | Batch_idx: 20 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (2620/2688)
Epoch: 195 | Batch_idx: 30 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 195 | Batch_idx: 40 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (5088/5248)
Epoch: 195 | Batch_idx: 50 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (6318/6528)
Epoch: 195 | Batch_idx: 60 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (7549/7808)
Epoch: 195 | Batch_idx: 70 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (8780/9088)
Epoch: 195 | Batch_idx: 80 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (10013/10368)
Epoch: 195 | Batch_idx: 90 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (11242/11648)
Epoch: 195 | Batch_idx: 100 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (12466/12928)
Epoch: 195 | Batch_idx: 110 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (13702/14208)
Epoch: 195 | Batch_idx: 120 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (14943/15488)
Epoch: 195 | Batch_idx: 130 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (16180/16768)
Epoch: 195 | Batch_idx: 140 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (17414/18048)
Epoch: 195 | Batch_idx: 150 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (18640/19328)
Epoch: 195 | Batch_idx: 160 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (19889/20608)
Epoch: 195 | Batch_idx: 170 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (21122/21888)
Epoch: 195 | Batch_idx: 180 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (22363/23168)
Epoch: 195 | Batch_idx: 190 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (23598/24448)
Epoch: 195 | Batch_idx: 200 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (24845/25728)
Epoch: 195 | Batch_idx: 210 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (26075/27008)
Epoch: 195 | Batch_idx: 220 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (27321/28288)
Epoch: 195 | Batch_idx: 230 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (28545/29568)
Epoch: 195 | Batch_idx: 240 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (29779/30848)
Epoch: 195 | Batch_idx: 250 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (31014/32128)
Epoch: 195 | Batch_idx: 260 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (32255/33408)
Epoch: 195 | Batch_idx: 270 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (33499/34688)
Epoch: 195 | Batch_idx: 280 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (34744/35968)
Epoch: 195 | Batch_idx: 290 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (35987/37248)
Epoch: 195 | Batch_idx: 300 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (37229/38528)
Epoch: 195 | Batch_idx: 310 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (38474/39808)
Epoch: 195 | Batch_idx: 320 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (39706/41088)
Epoch: 195 | Batch_idx: 330 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (40942/42368)
Epoch: 195 | Batch_idx: 340 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (42198/43648)
Epoch: 195 | Batch_idx: 350 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (43437/44928)
Epoch: 195 | Batch_idx: 360 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (44689/46208)
Epoch: 195 | Batch_idx: 370 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (45933/47488)
Epoch: 195 | Batch_idx: 380 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (47163/48768)
Epoch: 195 | Batch_idx: 390 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (48359/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_195.pth.tar'
# TEST : Loss: (0.4231) | Acc: (88.00%) (8843/10000)
percent tensor([0.5811, 0.5786, 0.5889, 0.5814, 0.6001, 0.5839, 0.5894, 0.5925, 0.5855,
        0.5795, 0.5787, 0.5865, 0.5809, 0.5711, 0.5820, 0.5779],
       device='cuda:0') torch.Size([16])
percent tensor([0.5340, 0.5342, 0.5254, 0.5326, 0.5262, 0.5385, 0.5307, 0.5249, 0.5317,
        0.5329, 0.5343, 0.5301, 0.5342, 0.5326, 0.5378, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.5230, 0.5541, 0.5497, 0.5614, 0.5775, 0.5851, 0.5546, 0.5345, 0.5553,
        0.5464, 0.5390, 0.5633, 0.5564, 0.5477, 0.5612, 0.5520],
       device='cuda:0') torch.Size([16])
percent tensor([0.6742, 0.6852, 0.6446, 0.6366, 0.6420, 0.6385, 0.6793, 0.6410, 0.6585,
        0.6828, 0.6902, 0.6626, 0.6789, 0.6744, 0.6790, 0.6624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5679, 0.5913, 0.7187, 0.7976, 0.7116, 0.7166, 0.6119, 0.5791, 0.7532,
        0.6203, 0.7406, 0.7165, 0.6118, 0.8127, 0.5421, 0.6245],
       device='cuda:0') torch.Size([16])
percent tensor([0.7202, 0.6705, 0.7454, 0.7504, 0.7687, 0.7457, 0.7413, 0.7619, 0.7063,
        0.6649, 0.6568, 0.7166, 0.6367, 0.6921, 0.7287, 0.7133],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.6391, 0.7335, 0.6045, 0.7638, 0.7767, 0.7167, 0.6429, 0.5833,
        0.5841, 0.6577, 0.4798, 0.5323, 0.4874, 0.5809, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 196 | Batch_idx: 0 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 196 | Batch_idx: 10 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 196 | Batch_idx: 20 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (2621/2688)
Epoch: 196 | Batch_idx: 30 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (3865/3968)
Epoch: 196 | Batch_idx: 40 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (5103/5248)
Epoch: 196 | Batch_idx: 50 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (6350/6528)
Epoch: 196 | Batch_idx: 60 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (7596/7808)
Epoch: 196 | Batch_idx: 70 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (8844/9088)
Epoch: 196 | Batch_idx: 80 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (10074/10368)
Epoch: 196 | Batch_idx: 90 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (11318/11648)
Epoch: 196 | Batch_idx: 100 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (12564/12928)
Epoch: 196 | Batch_idx: 110 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (13814/14208)
Epoch: 196 | Batch_idx: 120 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (15056/15488)
Epoch: 196 | Batch_idx: 130 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (16302/16768)
Epoch: 196 | Batch_idx: 140 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (17531/18048)
Epoch: 196 | Batch_idx: 150 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (18771/19328)
Epoch: 196 | Batch_idx: 160 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (20011/20608)
Epoch: 196 | Batch_idx: 170 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (21258/21888)
Epoch: 196 | Batch_idx: 180 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (22504/23168)
Epoch: 196 | Batch_idx: 190 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (23743/24448)
Epoch: 196 | Batch_idx: 200 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (24992/25728)
Epoch: 196 | Batch_idx: 210 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (26232/27008)
Epoch: 196 | Batch_idx: 220 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (27481/28288)
Epoch: 196 | Batch_idx: 230 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (28733/29568)
Epoch: 196 | Batch_idx: 240 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (29973/30848)
Epoch: 196 | Batch_idx: 250 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (31219/32128)
Epoch: 196 | Batch_idx: 260 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (32469/33408)
Epoch: 196 | Batch_idx: 270 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (33715/34688)
Epoch: 196 | Batch_idx: 280 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (34957/35968)
Epoch: 196 | Batch_idx: 290 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (36205/37248)
Epoch: 196 | Batch_idx: 300 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (37456/38528)
Epoch: 196 | Batch_idx: 310 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (38711/39808)
Epoch: 196 | Batch_idx: 320 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (39949/41088)
Epoch: 196 | Batch_idx: 330 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (41196/42368)
Epoch: 196 | Batch_idx: 340 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (42439/43648)
Epoch: 196 | Batch_idx: 350 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (43681/44928)
Epoch: 196 | Batch_idx: 360 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (44917/46208)
Epoch: 196 | Batch_idx: 370 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (46157/47488)
Epoch: 196 | Batch_idx: 380 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (47395/48768)
Epoch: 196 | Batch_idx: 390 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (48593/50000)
# TEST : Loss: (0.4102) | Acc: (88.00%) (8882/10000)
percent tensor([0.5854, 0.5835, 0.5938, 0.5856, 0.6055, 0.5879, 0.5945, 0.5975, 0.5901,
        0.5844, 0.5829, 0.5916, 0.5856, 0.5751, 0.5865, 0.5820],
       device='cuda:0') torch.Size([16])
percent tensor([0.5330, 0.5331, 0.5242, 0.5314, 0.5249, 0.5372, 0.5296, 0.5237, 0.5308,
        0.5318, 0.5333, 0.5289, 0.5331, 0.5320, 0.5365, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.5220, 0.5523, 0.5483, 0.5588, 0.5762, 0.5841, 0.5531, 0.5317, 0.5543,
        0.5462, 0.5387, 0.5629, 0.5558, 0.5455, 0.5587, 0.5510],
       device='cuda:0') torch.Size([16])
percent tensor([0.6774, 0.6872, 0.6458, 0.6393, 0.6436, 0.6432, 0.6815, 0.6425, 0.6603,
        0.6844, 0.6926, 0.6640, 0.6811, 0.6765, 0.6821, 0.6666],
       device='cuda:0') torch.Size([16])
percent tensor([0.5666, 0.5902, 0.7126, 0.7947, 0.7098, 0.7209, 0.6109, 0.5751, 0.7490,
        0.6101, 0.7347, 0.7089, 0.6078, 0.8133, 0.5422, 0.6200],
       device='cuda:0') torch.Size([16])
percent tensor([0.7169, 0.6691, 0.7424, 0.7450, 0.7637, 0.7378, 0.7378, 0.7574, 0.7035,
        0.6635, 0.6563, 0.7150, 0.6363, 0.6905, 0.7237, 0.7091],
       device='cuda:0') torch.Size([16])
percent tensor([0.6076, 0.6496, 0.7434, 0.6093, 0.7741, 0.7855, 0.7294, 0.6590, 0.5815,
        0.6028, 0.6736, 0.4890, 0.5384, 0.4858, 0.5802, 0.5067],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9996, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 197 | Batch_idx: 0 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 197 | Batch_idx: 10 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 197 | Batch_idx: 20 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 197 | Batch_idx: 30 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (3885/3968)
Epoch: 197 | Batch_idx: 40 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (5121/5248)
Epoch: 197 | Batch_idx: 50 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (6360/6528)
Epoch: 197 | Batch_idx: 60 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (7605/7808)
Epoch: 197 | Batch_idx: 70 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (8847/9088)
Epoch: 197 | Batch_idx: 80 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (10092/10368)
Epoch: 197 | Batch_idx: 90 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (11351/11648)
Epoch: 197 | Batch_idx: 100 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (12606/12928)
Epoch: 197 | Batch_idx: 110 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (13853/14208)
Epoch: 197 | Batch_idx: 120 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (15094/15488)
Epoch: 197 | Batch_idx: 130 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (16344/16768)
Epoch: 197 | Batch_idx: 140 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (17586/18048)
Epoch: 197 | Batch_idx: 150 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (18829/19328)
Epoch: 197 | Batch_idx: 160 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (20073/20608)
Epoch: 197 | Batch_idx: 170 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (21317/21888)
Epoch: 197 | Batch_idx: 180 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (22563/23168)
Epoch: 197 | Batch_idx: 190 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (23814/24448)
Epoch: 197 | Batch_idx: 200 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (25062/25728)
Epoch: 197 | Batch_idx: 210 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (26314/27008)
Epoch: 197 | Batch_idx: 220 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (27555/28288)
Epoch: 197 | Batch_idx: 230 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (28810/29568)
Epoch: 197 | Batch_idx: 240 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (30061/30848)
Epoch: 197 | Batch_idx: 250 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (31304/32128)
Epoch: 197 | Batch_idx: 260 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (32553/33408)
Epoch: 197 | Batch_idx: 270 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (33792/34688)
Epoch: 197 | Batch_idx: 280 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (35039/35968)
Epoch: 197 | Batch_idx: 290 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (36291/37248)
Epoch: 197 | Batch_idx: 300 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (37541/38528)
Epoch: 197 | Batch_idx: 310 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (38785/39808)
Epoch: 197 | Batch_idx: 320 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (40032/41088)
Epoch: 197 | Batch_idx: 330 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (41282/42368)
Epoch: 197 | Batch_idx: 340 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (42534/43648)
Epoch: 197 | Batch_idx: 350 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (43786/44928)
Epoch: 197 | Batch_idx: 360 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (45033/46208)
Epoch: 197 | Batch_idx: 370 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (46284/47488)
Epoch: 197 | Batch_idx: 380 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (47528/48768)
Epoch: 197 | Batch_idx: 390 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (48732/50000)
# TEST : Loss: (0.3992) | Acc: (89.00%) (8913/10000)
percent tensor([0.5846, 0.5831, 0.5930, 0.5851, 0.6046, 0.5869, 0.5939, 0.5968, 0.5895,
        0.5839, 0.5824, 0.5910, 0.5850, 0.5748, 0.5859, 0.5814],
       device='cuda:0') torch.Size([16])
percent tensor([0.5334, 0.5334, 0.5244, 0.5315, 0.5252, 0.5377, 0.5299, 0.5239, 0.5312,
        0.5320, 0.5338, 0.5290, 0.5335, 0.5323, 0.5369, 0.5357],
       device='cuda:0') torch.Size([16])
percent tensor([0.5233, 0.5536, 0.5507, 0.5609, 0.5804, 0.5882, 0.5550, 0.5341, 0.5569,
        0.5471, 0.5403, 0.5652, 0.5566, 0.5471, 0.5620, 0.5531],
       device='cuda:0') torch.Size([16])
percent tensor([0.6792, 0.6881, 0.6465, 0.6410, 0.6448, 0.6459, 0.6823, 0.6436, 0.6613,
        0.6850, 0.6941, 0.6645, 0.6821, 0.6775, 0.6840, 0.6688],
       device='cuda:0') torch.Size([16])
percent tensor([0.5613, 0.5825, 0.7092, 0.7923, 0.7087, 0.7237, 0.6054, 0.5703, 0.7433,
        0.5972, 0.7220, 0.7008, 0.5983, 0.8081, 0.5368, 0.6143],
       device='cuda:0') torch.Size([16])
percent tensor([0.7197, 0.6724, 0.7443, 0.7462, 0.7645, 0.7376, 0.7401, 0.7580, 0.7057,
        0.6678, 0.6597, 0.7180, 0.6418, 0.6959, 0.7244, 0.7114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5974, 0.6435, 0.7343, 0.5984, 0.7676, 0.7829, 0.7265, 0.6509, 0.5748,
        0.5987, 0.6716, 0.4858, 0.5345, 0.4733, 0.5746, 0.5038],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 198 | Batch_idx: 0 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 198 | Batch_idx: 10 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 198 | Batch_idx: 20 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (2631/2688)
Epoch: 198 | Batch_idx: 30 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (3881/3968)
Epoch: 198 | Batch_idx: 40 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (5126/5248)
Epoch: 198 | Batch_idx: 50 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (6372/6528)
Epoch: 198 | Batch_idx: 60 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (7628/7808)
Epoch: 198 | Batch_idx: 70 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (8875/9088)
Epoch: 198 | Batch_idx: 80 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (10121/10368)
Epoch: 198 | Batch_idx: 90 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (11377/11648)
Epoch: 198 | Batch_idx: 100 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (12625/12928)
Epoch: 198 | Batch_idx: 110 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (13866/14208)
Epoch: 198 | Batch_idx: 120 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (15120/15488)
Epoch: 198 | Batch_idx: 130 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (16373/16768)
Epoch: 198 | Batch_idx: 140 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (17634/18048)
Epoch: 198 | Batch_idx: 150 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (18877/19328)
Epoch: 198 | Batch_idx: 160 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (20129/20608)
Epoch: 198 | Batch_idx: 170 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (21381/21888)
Epoch: 198 | Batch_idx: 180 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (22639/23168)
Epoch: 198 | Batch_idx: 190 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (23894/24448)
Epoch: 198 | Batch_idx: 200 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (25149/25728)
Epoch: 198 | Batch_idx: 210 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (26388/27008)
Epoch: 198 | Batch_idx: 220 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (27638/28288)
Epoch: 198 | Batch_idx: 230 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (28891/29568)
Epoch: 198 | Batch_idx: 240 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (30142/30848)
Epoch: 198 | Batch_idx: 250 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (31393/32128)
Epoch: 198 | Batch_idx: 260 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (32641/33408)
Epoch: 198 | Batch_idx: 270 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (33882/34688)
Epoch: 198 | Batch_idx: 280 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (35131/35968)
Epoch: 198 | Batch_idx: 290 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (36389/37248)
Epoch: 198 | Batch_idx: 300 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (37644/38528)
Epoch: 198 | Batch_idx: 310 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (38892/39808)
Epoch: 198 | Batch_idx: 320 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (40142/41088)
Epoch: 198 | Batch_idx: 330 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (41389/42368)
Epoch: 198 | Batch_idx: 340 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (42640/43648)
Epoch: 198 | Batch_idx: 350 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (43879/44928)
Epoch: 198 | Batch_idx: 360 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (45120/46208)
Epoch: 198 | Batch_idx: 370 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (46358/47488)
Epoch: 198 | Batch_idx: 380 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (47603/48768)
Epoch: 198 | Batch_idx: 390 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (48807/50000)
# TEST : Loss: (0.3959) | Acc: (89.00%) (8913/10000)
percent tensor([0.5861, 0.5848, 0.5950, 0.5868, 0.6067, 0.5886, 0.5958, 0.5987, 0.5911,
        0.5856, 0.5838, 0.5929, 0.5864, 0.5764, 0.5876, 0.5830],
       device='cuda:0') torch.Size([16])
percent tensor([0.5341, 0.5342, 0.5247, 0.5320, 0.5257, 0.5382, 0.5307, 0.5245, 0.5320,
        0.5328, 0.5346, 0.5296, 0.5342, 0.5333, 0.5377, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.5205, 0.5501, 0.5479, 0.5563, 0.5779, 0.5859, 0.5522, 0.5313, 0.5536,
        0.5442, 0.5363, 0.5620, 0.5535, 0.5430, 0.5584, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.6757, 0.6842, 0.6427, 0.6377, 0.6408, 0.6441, 0.6784, 0.6393, 0.6580,
        0.6811, 0.6904, 0.6602, 0.6782, 0.6742, 0.6802, 0.6661],
       device='cuda:0') torch.Size([16])
percent tensor([0.5637, 0.5860, 0.7034, 0.7888, 0.7070, 0.7228, 0.6081, 0.5680, 0.7447,
        0.6009, 0.7259, 0.7003, 0.6023, 0.8117, 0.5394, 0.6153],
       device='cuda:0') torch.Size([16])
percent tensor([0.7265, 0.6811, 0.7503, 0.7510, 0.7700, 0.7412, 0.7469, 0.7635, 0.7135,
        0.6774, 0.6692, 0.7256, 0.6518, 0.7036, 0.7300, 0.7193],
       device='cuda:0') torch.Size([16])
percent tensor([0.6044, 0.6545, 0.7412, 0.6058, 0.7714, 0.7883, 0.7324, 0.6580, 0.5756,
        0.6039, 0.6791, 0.4931, 0.5415, 0.4781, 0.5843, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 199 | Batch_idx: 0 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 199 | Batch_idx: 10 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 199 | Batch_idx: 20 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (2629/2688)
Epoch: 199 | Batch_idx: 30 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (3881/3968)
Epoch: 199 | Batch_idx: 40 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (5134/5248)
Epoch: 199 | Batch_idx: 50 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (6382/6528)
Epoch: 199 | Batch_idx: 60 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (7629/7808)
Epoch: 199 | Batch_idx: 70 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (8867/9088)
Epoch: 199 | Batch_idx: 80 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (10122/10368)
Epoch: 199 | Batch_idx: 90 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (11374/11648)
Epoch: 199 | Batch_idx: 100 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (12617/12928)
Epoch: 199 | Batch_idx: 110 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (13862/14208)
Epoch: 199 | Batch_idx: 120 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (15117/15488)
Epoch: 199 | Batch_idx: 130 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (16374/16768)
Epoch: 199 | Batch_idx: 140 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (17620/18048)
Epoch: 199 | Batch_idx: 150 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (18870/19328)
Epoch: 199 | Batch_idx: 160 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (20118/20608)
Epoch: 199 | Batch_idx: 170 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (21369/21888)
Epoch: 199 | Batch_idx: 180 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (22623/23168)
Epoch: 199 | Batch_idx: 190 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (23877/24448)
Epoch: 199 | Batch_idx: 200 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (25129/25728)
Epoch: 199 | Batch_idx: 210 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (26384/27008)
Epoch: 199 | Batch_idx: 220 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (27636/28288)
Epoch: 199 | Batch_idx: 230 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (28884/29568)
Epoch: 199 | Batch_idx: 240 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (30142/30848)
Epoch: 199 | Batch_idx: 250 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (31392/32128)
Epoch: 199 | Batch_idx: 260 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (32640/33408)
Epoch: 199 | Batch_idx: 270 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (33897/34688)
Epoch: 199 | Batch_idx: 280 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (35144/35968)
Epoch: 199 | Batch_idx: 290 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (36394/37248)
Epoch: 199 | Batch_idx: 300 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (37642/38528)
Epoch: 199 | Batch_idx: 310 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (38892/39808)
Epoch: 199 | Batch_idx: 320 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (40151/41088)
Epoch: 199 | Batch_idx: 330 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (41406/42368)
Epoch: 199 | Batch_idx: 340 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (42658/43648)
Epoch: 199 | Batch_idx: 350 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (43909/44928)
Epoch: 199 | Batch_idx: 360 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (45163/46208)
Epoch: 199 | Batch_idx: 370 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (46419/47488)
Epoch: 199 | Batch_idx: 380 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (47667/48768)
Epoch: 199 | Batch_idx: 390 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (48877/50000)
# TEST : Loss: (0.3921) | Acc: (89.00%) (8933/10000)
percent tensor([0.5871, 0.5859, 0.5956, 0.5876, 0.6075, 0.5894, 0.5966, 0.5995, 0.5921,
        0.5864, 0.5848, 0.5936, 0.5875, 0.5774, 0.5886, 0.5841],
       device='cuda:0') torch.Size([16])
percent tensor([0.5351, 0.5352, 0.5255, 0.5328, 0.5266, 0.5391, 0.5318, 0.5253, 0.5330,
        0.5337, 0.5357, 0.5305, 0.5352, 0.5343, 0.5387, 0.5373],
       device='cuda:0') torch.Size([16])
percent tensor([0.5200, 0.5478, 0.5504, 0.5568, 0.5798, 0.5866, 0.5517, 0.5331, 0.5532,
        0.5430, 0.5356, 0.5631, 0.5518, 0.5416, 0.5581, 0.5496],
       device='cuda:0') torch.Size([16])
percent tensor([0.6725, 0.6803, 0.6386, 0.6345, 0.6372, 0.6417, 0.6746, 0.6358, 0.6547,
        0.6772, 0.6877, 0.6564, 0.6745, 0.6708, 0.6767, 0.6628],
       device='cuda:0') torch.Size([16])
percent tensor([0.5643, 0.5885, 0.7032, 0.7887, 0.7047, 0.7216, 0.6110, 0.5678, 0.7463,
        0.6043, 0.7278, 0.7020, 0.6048, 0.8173, 0.5408, 0.6170],
       device='cuda:0') torch.Size([16])
percent tensor([0.7265, 0.6823, 0.7479, 0.7478, 0.7668, 0.7388, 0.7464, 0.7623, 0.7137,
        0.6788, 0.6704, 0.7252, 0.6531, 0.7049, 0.7285, 0.7178],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.6655, 0.7352, 0.6026, 0.7696, 0.7901, 0.7372, 0.6530, 0.5763,
        0.6135, 0.6924, 0.4969, 0.5480, 0.4790, 0.5927, 0.5199],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 200 | Batch_idx: 0 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 200 | Batch_idx: 10 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 200 | Batch_idx: 20 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 200 | Batch_idx: 30 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (3882/3968)
Epoch: 200 | Batch_idx: 40 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (5123/5248)
Epoch: 200 | Batch_idx: 50 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (6365/6528)
Epoch: 200 | Batch_idx: 60 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (7610/7808)
Epoch: 200 | Batch_idx: 70 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (8861/9088)
Epoch: 200 | Batch_idx: 80 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (10115/10368)
Epoch: 200 | Batch_idx: 90 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (11368/11648)
Epoch: 200 | Batch_idx: 100 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (12619/12928)
Epoch: 200 | Batch_idx: 110 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (13863/14208)
Epoch: 200 | Batch_idx: 120 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (15114/15488)
Epoch: 200 | Batch_idx: 130 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (16356/16768)
Epoch: 200 | Batch_idx: 140 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (17615/18048)
Epoch: 200 | Batch_idx: 150 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (18869/19328)
Epoch: 200 | Batch_idx: 160 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (20118/20608)
Epoch: 200 | Batch_idx: 170 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (21366/21888)
Epoch: 200 | Batch_idx: 180 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (22617/23168)
Epoch: 200 | Batch_idx: 190 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (23870/24448)
Epoch: 200 | Batch_idx: 200 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (25120/25728)
Epoch: 200 | Batch_idx: 210 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (26369/27008)
Epoch: 200 | Batch_idx: 220 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (27612/28288)
Epoch: 200 | Batch_idx: 230 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (28852/29568)
Epoch: 200 | Batch_idx: 240 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (30090/30848)
Epoch: 200 | Batch_idx: 250 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (31335/32128)
Epoch: 200 | Batch_idx: 260 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (32568/33408)
Epoch: 200 | Batch_idx: 270 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (33820/34688)
Epoch: 200 | Batch_idx: 280 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (35070/35968)
Epoch: 200 | Batch_idx: 290 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (36315/37248)
Epoch: 200 | Batch_idx: 300 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (37561/38528)
Epoch: 200 | Batch_idx: 310 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (38807/39808)
Epoch: 200 | Batch_idx: 320 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (40061/41088)
Epoch: 200 | Batch_idx: 330 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (41299/42368)
Epoch: 200 | Batch_idx: 340 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (42548/43648)
Epoch: 200 | Batch_idx: 350 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (43793/44928)
Epoch: 200 | Batch_idx: 360 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (45034/46208)
Epoch: 200 | Batch_idx: 370 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (46277/47488)
Epoch: 200 | Batch_idx: 380 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (47512/48768)
Epoch: 200 | Batch_idx: 390 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (48711/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_200.pth.tar'
# TEST : Loss: (0.4097) | Acc: (88.00%) (8869/10000)
percent tensor([0.5863, 0.5845, 0.5959, 0.5867, 0.6081, 0.5869, 0.5960, 0.5986, 0.5914,
        0.5863, 0.5834, 0.5941, 0.5865, 0.5771, 0.5868, 0.5822],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5367, 0.5270, 0.5352, 0.5284, 0.5405, 0.5330, 0.5279, 0.5349,
        0.5356, 0.5373, 0.5319, 0.5370, 0.5353, 0.5402, 0.5388],
       device='cuda:0') torch.Size([16])
percent tensor([0.5258, 0.5535, 0.5585, 0.5679, 0.5910, 0.5894, 0.5547, 0.5386, 0.5597,
        0.5498, 0.5411, 0.5706, 0.5568, 0.5427, 0.5643, 0.5545],
       device='cuda:0') torch.Size([16])
percent tensor([0.6685, 0.6812, 0.6306, 0.6332, 0.6338, 0.6458, 0.6725, 0.6294, 0.6499,
        0.6711, 0.6890, 0.6519, 0.6730, 0.6692, 0.6804, 0.6630],
       device='cuda:0') torch.Size([16])
percent tensor([0.5710, 0.5967, 0.6992, 0.8111, 0.7199, 0.7379, 0.6136, 0.5655, 0.7578,
        0.6062, 0.7206, 0.7026, 0.6046, 0.8298, 0.5439, 0.6293],
       device='cuda:0') torch.Size([16])
percent tensor([0.7323, 0.6876, 0.7469, 0.7466, 0.7707, 0.7380, 0.7527, 0.7662, 0.7232,
        0.6810, 0.6769, 0.7252, 0.6608, 0.7215, 0.7368, 0.7231],
       device='cuda:0') torch.Size([16])
percent tensor([0.5831, 0.5934, 0.7408, 0.6090, 0.7530, 0.7742, 0.6950, 0.5784, 0.5973,
        0.6127, 0.6474, 0.4809, 0.5302, 0.5101, 0.5597, 0.5061],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9995, 0.9999, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.6751, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(834.3962, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(840.4180, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1505.8295, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(479.6312, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2278.8823, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4262.5625, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1337.9286, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6255.2671, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11502.5908, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3779.3574, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15993.9629, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 201 | Batch_idx: 0 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 201 | Batch_idx: 10 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 201 | Batch_idx: 20 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (2620/2688)
Epoch: 201 | Batch_idx: 30 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (3877/3968)
Epoch: 201 | Batch_idx: 40 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (5118/5248)
Epoch: 201 | Batch_idx: 50 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (6367/6528)
Epoch: 201 | Batch_idx: 60 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (7618/7808)
Epoch: 201 | Batch_idx: 70 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (8871/9088)
Epoch: 201 | Batch_idx: 80 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (10122/10368)
Epoch: 201 | Batch_idx: 90 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (11379/11648)
Epoch: 201 | Batch_idx: 100 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (12631/12928)
Epoch: 201 | Batch_idx: 110 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (13880/14208)
Epoch: 201 | Batch_idx: 120 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (15125/15488)
Epoch: 201 | Batch_idx: 130 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (16374/16768)
Epoch: 201 | Batch_idx: 140 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (17620/18048)
Epoch: 201 | Batch_idx: 150 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (18860/19328)
Epoch: 201 | Batch_idx: 160 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (20108/20608)
Epoch: 201 | Batch_idx: 170 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (21362/21888)
Epoch: 201 | Batch_idx: 180 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (22612/23168)
Epoch: 201 | Batch_idx: 190 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (23863/24448)
Epoch: 201 | Batch_idx: 200 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (25108/25728)
Epoch: 201 | Batch_idx: 210 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (26356/27008)
Epoch: 201 | Batch_idx: 220 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (27606/28288)
Epoch: 201 | Batch_idx: 230 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (28843/29568)
Epoch: 201 | Batch_idx: 240 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (30093/30848)
Epoch: 201 | Batch_idx: 250 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (31333/32128)
Epoch: 201 | Batch_idx: 260 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (32569/33408)
Epoch: 201 | Batch_idx: 270 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (33816/34688)
Epoch: 201 | Batch_idx: 280 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (35060/35968)
Epoch: 201 | Batch_idx: 290 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (36296/37248)
Epoch: 201 | Batch_idx: 300 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (37542/38528)
Epoch: 201 | Batch_idx: 310 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (38792/39808)
Epoch: 201 | Batch_idx: 320 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (40033/41088)
Epoch: 201 | Batch_idx: 330 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (41280/42368)
Epoch: 201 | Batch_idx: 340 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (42531/43648)
Epoch: 201 | Batch_idx: 350 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (43787/44928)
Epoch: 201 | Batch_idx: 360 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (45032/46208)
Epoch: 201 | Batch_idx: 370 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (46271/47488)
Epoch: 201 | Batch_idx: 380 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (47510/48768)
Epoch: 201 | Batch_idx: 390 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (48709/50000)
# TEST : Loss: (0.4162) | Acc: (88.00%) (8876/10000)
percent tensor([0.5870, 0.5863, 0.5998, 0.5892, 0.6110, 0.5894, 0.5978, 0.6007, 0.5916,
        0.5880, 0.5836, 0.5973, 0.5867, 0.5760, 0.5890, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.5378, 0.5382, 0.5277, 0.5353, 0.5282, 0.5409, 0.5343, 0.5283, 0.5352,
        0.5365, 0.5386, 0.5326, 0.5379, 0.5361, 0.5410, 0.5395],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.5574, 0.5570, 0.5611, 0.5879, 0.5921, 0.5612, 0.5405, 0.5589,
        0.5516, 0.5457, 0.5709, 0.5613, 0.5428, 0.5644, 0.5566],
       device='cuda:0') torch.Size([16])
percent tensor([0.6688, 0.6791, 0.6357, 0.6316, 0.6344, 0.6393, 0.6745, 0.6314, 0.6572,
        0.6741, 0.6911, 0.6559, 0.6742, 0.6733, 0.6777, 0.6609],
       device='cuda:0') torch.Size([16])
percent tensor([0.5713, 0.6022, 0.7393, 0.8160, 0.7340, 0.7273, 0.6166, 0.5861, 0.7456,
        0.6213, 0.7023, 0.7277, 0.6197, 0.8190, 0.5578, 0.6261],
       device='cuda:0') torch.Size([16])
percent tensor([0.7454, 0.6942, 0.7738, 0.7604, 0.7843, 0.7420, 0.7565, 0.7802, 0.7298,
        0.6939, 0.6778, 0.7406, 0.6708, 0.7133, 0.7414, 0.7355],
       device='cuda:0') torch.Size([16])
percent tensor([0.6243, 0.6756, 0.7611, 0.5898, 0.7459, 0.7823, 0.7252, 0.6262, 0.6290,
        0.6357, 0.6668, 0.5410, 0.5869, 0.5013, 0.6256, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9997, 0.9996, 0.9999, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 202 | Batch_idx: 0 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 202 | Batch_idx: 10 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 202 | Batch_idx: 20 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (2621/2688)
Epoch: 202 | Batch_idx: 30 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (3863/3968)
Epoch: 202 | Batch_idx: 40 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (5102/5248)
Epoch: 202 | Batch_idx: 50 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (6355/6528)
Epoch: 202 | Batch_idx: 60 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (7605/7808)
Epoch: 202 | Batch_idx: 70 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (8852/9088)
Epoch: 202 | Batch_idx: 80 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (10083/10368)
Epoch: 202 | Batch_idx: 90 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (11335/11648)
Epoch: 202 | Batch_idx: 100 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (12584/12928)
Epoch: 202 | Batch_idx: 110 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (13824/14208)
Epoch: 202 | Batch_idx: 120 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (15071/15488)
Epoch: 202 | Batch_idx: 130 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (16315/16768)
Epoch: 202 | Batch_idx: 140 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (17564/18048)
Epoch: 202 | Batch_idx: 150 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (18804/19328)
Epoch: 202 | Batch_idx: 160 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (20055/20608)
Epoch: 202 | Batch_idx: 170 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (21303/21888)
Epoch: 202 | Batch_idx: 180 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (22555/23168)
Epoch: 202 | Batch_idx: 190 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (23801/24448)
Epoch: 202 | Batch_idx: 200 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (25049/25728)
Epoch: 202 | Batch_idx: 210 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (26292/27008)
Epoch: 202 | Batch_idx: 220 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (27544/28288)
Epoch: 202 | Batch_idx: 230 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (28776/29568)
Epoch: 202 | Batch_idx: 240 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (30013/30848)
Epoch: 202 | Batch_idx: 250 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (31263/32128)
Epoch: 202 | Batch_idx: 260 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (32511/33408)
Epoch: 202 | Batch_idx: 270 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (33743/34688)
Epoch: 202 | Batch_idx: 280 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (34983/35968)
Epoch: 202 | Batch_idx: 290 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (36230/37248)
Epoch: 202 | Batch_idx: 300 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (37476/38528)
Epoch: 202 | Batch_idx: 310 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (38716/39808)
Epoch: 202 | Batch_idx: 320 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (39956/41088)
Epoch: 202 | Batch_idx: 330 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (41197/42368)
Epoch: 202 | Batch_idx: 340 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (42444/43648)
Epoch: 202 | Batch_idx: 350 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (43696/44928)
Epoch: 202 | Batch_idx: 360 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (44946/46208)
Epoch: 202 | Batch_idx: 370 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (46193/47488)
Epoch: 202 | Batch_idx: 380 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (47444/48768)
Epoch: 202 | Batch_idx: 390 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (48651/50000)
# TEST : Loss: (0.4449) | Acc: (88.00%) (8862/10000)
percent tensor([0.5874, 0.5859, 0.6001, 0.5888, 0.6104, 0.5875, 0.5982, 0.6009, 0.5921,
        0.5886, 0.5842, 0.5979, 0.5875, 0.5766, 0.5880, 0.5834],
       device='cuda:0') torch.Size([16])
percent tensor([0.5375, 0.5377, 0.5276, 0.5356, 0.5283, 0.5408, 0.5341, 0.5281, 0.5352,
        0.5363, 0.5381, 0.5325, 0.5374, 0.5362, 0.5409, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.5310, 0.5619, 0.5550, 0.5645, 0.5894, 0.5871, 0.5635, 0.5405, 0.5636,
        0.5548, 0.5468, 0.5716, 0.5658, 0.5487, 0.5674, 0.5581],
       device='cuda:0') torch.Size([16])
percent tensor([0.6696, 0.6812, 0.6395, 0.6318, 0.6379, 0.6444, 0.6751, 0.6318, 0.6560,
        0.6752, 0.6919, 0.6557, 0.6748, 0.6734, 0.6809, 0.6635],
       device='cuda:0') torch.Size([16])
percent tensor([0.5713, 0.5972, 0.6917, 0.7990, 0.7100, 0.7400, 0.6114, 0.5638, 0.7532,
        0.6030, 0.7081, 0.7015, 0.6194, 0.8253, 0.5548, 0.6259],
       device='cuda:0') torch.Size([16])
percent tensor([0.7418, 0.7000, 0.7757, 0.7662, 0.7876, 0.7474, 0.7580, 0.7797, 0.7320,
        0.6950, 0.6848, 0.7386, 0.6689, 0.7218, 0.7456, 0.7368],
       device='cuda:0') torch.Size([16])
percent tensor([0.6263, 0.6652, 0.7887, 0.6230, 0.7854, 0.7854, 0.7202, 0.6326, 0.6307,
        0.6750, 0.6720, 0.5592, 0.5823, 0.4891, 0.6330, 0.5386],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9997, 0.9996, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 203 | Batch_idx: 0 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 203 | Batch_idx: 10 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 203 | Batch_idx: 20 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (2626/2688)
Epoch: 203 | Batch_idx: 30 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (3874/3968)
Epoch: 203 | Batch_idx: 40 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (5127/5248)
Epoch: 203 | Batch_idx: 50 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (6383/6528)
Epoch: 203 | Batch_idx: 60 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (7637/7808)
Epoch: 203 | Batch_idx: 70 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (8882/9088)
Epoch: 203 | Batch_idx: 80 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (10137/10368)
Epoch: 203 | Batch_idx: 90 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (11389/11648)
Epoch: 203 | Batch_idx: 100 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (12636/12928)
Epoch: 203 | Batch_idx: 110 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (13891/14208)
Epoch: 203 | Batch_idx: 120 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (15135/15488)
Epoch: 203 | Batch_idx: 130 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (16391/16768)
Epoch: 203 | Batch_idx: 140 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (17633/18048)
Epoch: 203 | Batch_idx: 150 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (18882/19328)
Epoch: 203 | Batch_idx: 160 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (20130/20608)
Epoch: 203 | Batch_idx: 170 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (21385/21888)
Epoch: 203 | Batch_idx: 180 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (22633/23168)
Epoch: 203 | Batch_idx: 190 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (23890/24448)
Epoch: 203 | Batch_idx: 200 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (25143/25728)
Epoch: 203 | Batch_idx: 210 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (26391/27008)
Epoch: 203 | Batch_idx: 220 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (27648/28288)
Epoch: 203 | Batch_idx: 230 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (28886/29568)
Epoch: 203 | Batch_idx: 240 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (30135/30848)
Epoch: 203 | Batch_idx: 250 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (31373/32128)
Epoch: 203 | Batch_idx: 260 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (32616/33408)
Epoch: 203 | Batch_idx: 270 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (33871/34688)
Epoch: 203 | Batch_idx: 280 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (35116/35968)
Epoch: 203 | Batch_idx: 290 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (36359/37248)
Epoch: 203 | Batch_idx: 300 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (37606/38528)
Epoch: 203 | Batch_idx: 310 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (38840/39808)
Epoch: 203 | Batch_idx: 320 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (40086/41088)
Epoch: 203 | Batch_idx: 330 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (41329/42368)
Epoch: 203 | Batch_idx: 340 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (42566/43648)
Epoch: 203 | Batch_idx: 350 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (43805/44928)
Epoch: 203 | Batch_idx: 360 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (45052/46208)
Epoch: 203 | Batch_idx: 370 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (46309/47488)
Epoch: 203 | Batch_idx: 380 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (47556/48768)
Epoch: 203 | Batch_idx: 390 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (48760/50000)
# TEST : Loss: (0.4281) | Acc: (88.00%) (8854/10000)
percent tensor([0.5853, 0.5829, 0.5939, 0.5863, 0.6056, 0.5859, 0.5937, 0.5972, 0.5887,
        0.5844, 0.5816, 0.5922, 0.5850, 0.5741, 0.5855, 0.5809],
       device='cuda:0') torch.Size([16])
percent tensor([0.5389, 0.5384, 0.5285, 0.5365, 0.5298, 0.5416, 0.5352, 0.5292, 0.5360,
        0.5370, 0.5389, 0.5338, 0.5383, 0.5361, 0.5420, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.5323, 0.5562, 0.5599, 0.5691, 0.5976, 0.5959, 0.5626, 0.5471, 0.5637,
        0.5507, 0.5469, 0.5760, 0.5622, 0.5477, 0.5696, 0.5580],
       device='cuda:0') torch.Size([16])
percent tensor([0.6696, 0.6814, 0.6389, 0.6377, 0.6386, 0.6447, 0.6752, 0.6327, 0.6546,
        0.6761, 0.6910, 0.6564, 0.6750, 0.6715, 0.6806, 0.6651],
       device='cuda:0') torch.Size([16])
percent tensor([0.5854, 0.5881, 0.7241, 0.8126, 0.7366, 0.7448, 0.6166, 0.5953, 0.7667,
        0.5985, 0.7104, 0.7302, 0.6239, 0.8130, 0.5567, 0.6233],
       device='cuda:0') torch.Size([16])
percent tensor([0.7272, 0.6843, 0.7512, 0.7540, 0.7761, 0.7290, 0.7400, 0.7673, 0.7205,
        0.6813, 0.6783, 0.7347, 0.6596, 0.7141, 0.7325, 0.7236],
       device='cuda:0') torch.Size([16])
percent tensor([0.6490, 0.7003, 0.7758, 0.6260, 0.7760, 0.7920, 0.7077, 0.6426, 0.6588,
        0.6612, 0.7101, 0.5316, 0.5957, 0.5457, 0.6185, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9993, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9998, 0.9997, 0.9996, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 204 | Batch_idx: 0 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 204 | Batch_idx: 10 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 204 | Batch_idx: 20 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (2625/2688)
Epoch: 204 | Batch_idx: 30 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (3873/3968)
Epoch: 204 | Batch_idx: 40 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (5123/5248)
Epoch: 204 | Batch_idx: 50 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (6371/6528)
Epoch: 204 | Batch_idx: 60 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (7627/7808)
Epoch: 204 | Batch_idx: 70 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (8879/9088)
Epoch: 204 | Batch_idx: 80 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (10127/10368)
Epoch: 204 | Batch_idx: 90 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (11383/11648)
Epoch: 204 | Batch_idx: 100 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (12629/12928)
Epoch: 204 | Batch_idx: 110 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (13879/14208)
Epoch: 204 | Batch_idx: 120 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (15133/15488)
Epoch: 204 | Batch_idx: 130 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (16388/16768)
Epoch: 204 | Batch_idx: 140 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (17643/18048)
Epoch: 204 | Batch_idx: 150 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (18905/19328)
Epoch: 204 | Batch_idx: 160 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (20156/20608)
Epoch: 204 | Batch_idx: 170 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (21409/21888)
Epoch: 204 | Batch_idx: 180 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (22657/23168)
Epoch: 204 | Batch_idx: 190 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (23907/24448)
Epoch: 204 | Batch_idx: 200 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (25153/25728)
Epoch: 204 | Batch_idx: 210 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (26409/27008)
Epoch: 204 | Batch_idx: 220 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (27668/28288)
Epoch: 204 | Batch_idx: 230 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (28911/29568)
Epoch: 204 | Batch_idx: 240 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (30159/30848)
Epoch: 204 | Batch_idx: 250 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (31402/32128)
Epoch: 204 | Batch_idx: 260 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (32649/33408)
Epoch: 204 | Batch_idx: 270 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (33892/34688)
Epoch: 204 | Batch_idx: 280 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (35135/35968)
Epoch: 204 | Batch_idx: 290 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (36378/37248)
Epoch: 204 | Batch_idx: 300 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (37625/38528)
Epoch: 204 | Batch_idx: 310 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (38876/39808)
Epoch: 204 | Batch_idx: 320 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (40126/41088)
Epoch: 204 | Batch_idx: 330 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (41378/42368)
Epoch: 204 | Batch_idx: 340 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (42633/43648)
Epoch: 204 | Batch_idx: 350 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (43884/44928)
Epoch: 204 | Batch_idx: 360 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (45143/46208)
Epoch: 204 | Batch_idx: 370 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (46390/47488)
Epoch: 204 | Batch_idx: 380 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (47630/48768)
Epoch: 204 | Batch_idx: 390 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (48826/50000)
# TEST : Loss: (0.5261) | Acc: (86.00%) (8680/10000)
percent tensor([0.5850, 0.5826, 0.5963, 0.5869, 0.6076, 0.5878, 0.5943, 0.5976, 0.5898,
        0.5849, 0.5815, 0.5936, 0.5842, 0.5747, 0.5860, 0.5815],
       device='cuda:0') torch.Size([16])
percent tensor([0.5385, 0.5383, 0.5275, 0.5370, 0.5295, 0.5423, 0.5345, 0.5294, 0.5352,
        0.5367, 0.5384, 0.5324, 0.5378, 0.5368, 0.5421, 0.5409],
       device='cuda:0') torch.Size([16])
percent tensor([0.5339, 0.5603, 0.5565, 0.5686, 0.5962, 0.6032, 0.5637, 0.5447, 0.5637,
        0.5508, 0.5472, 0.5699, 0.5626, 0.5469, 0.5746, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.6652, 0.6770, 0.6366, 0.6336, 0.6318, 0.6403, 0.6716, 0.6301, 0.6515,
        0.6723, 0.6860, 0.6556, 0.6692, 0.6723, 0.6755, 0.6602],
       device='cuda:0') torch.Size([16])
percent tensor([0.5739, 0.5905, 0.7306, 0.8192, 0.7384, 0.7314, 0.6156, 0.5955, 0.7522,
        0.6040, 0.7109, 0.7181, 0.6059, 0.8179, 0.5582, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.7370, 0.6793, 0.7647, 0.7552, 0.7855, 0.7425, 0.7435, 0.7674, 0.7240,
        0.6868, 0.6806, 0.7362, 0.6610, 0.7084, 0.7335, 0.7291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6273, 0.6528, 0.7724, 0.6558, 0.7799, 0.8054, 0.7248, 0.6448, 0.6395,
        0.6648, 0.6979, 0.4911, 0.6024, 0.5114, 0.6227, 0.5517],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9995, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 205 | Batch_idx: 0 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 205 | Batch_idx: 10 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 205 | Batch_idx: 20 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (98.00%) (2636/2688)
Epoch: 205 | Batch_idx: 30 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (98.00%) (3892/3968)
Epoch: 205 | Batch_idx: 40 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (5142/5248)
Epoch: 205 | Batch_idx: 50 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (6391/6528)
Epoch: 205 | Batch_idx: 60 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (7643/7808)
Epoch: 205 | Batch_idx: 70 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (8901/9088)
Epoch: 205 | Batch_idx: 80 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (10152/10368)
Epoch: 205 | Batch_idx: 90 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (11398/11648)
Epoch: 205 | Batch_idx: 100 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (12646/12928)
Epoch: 205 | Batch_idx: 110 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (13899/14208)
Epoch: 205 | Batch_idx: 120 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (15156/15488)
Epoch: 205 | Batch_idx: 130 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (16404/16768)
Epoch: 205 | Batch_idx: 140 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (17654/18048)
Epoch: 205 | Batch_idx: 150 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (18909/19328)
Epoch: 205 | Batch_idx: 160 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (20165/20608)
Epoch: 205 | Batch_idx: 170 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (21410/21888)
Epoch: 205 | Batch_idx: 180 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (22660/23168)
Epoch: 205 | Batch_idx: 190 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (23919/24448)
Epoch: 205 | Batch_idx: 200 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (25168/25728)
Epoch: 205 | Batch_idx: 210 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (26421/27008)
Epoch: 205 | Batch_idx: 220 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (27664/28288)
Epoch: 205 | Batch_idx: 230 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (28914/29568)
Epoch: 205 | Batch_idx: 240 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (30164/30848)
Epoch: 205 | Batch_idx: 250 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (31417/32128)
Epoch: 205 | Batch_idx: 260 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (32671/33408)
Epoch: 205 | Batch_idx: 270 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (33916/34688)
Epoch: 205 | Batch_idx: 280 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (35160/35968)
Epoch: 205 | Batch_idx: 290 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (36409/37248)
Epoch: 205 | Batch_idx: 300 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (37645/38528)
Epoch: 205 | Batch_idx: 310 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (38895/39808)
Epoch: 205 | Batch_idx: 320 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (40145/41088)
Epoch: 205 | Batch_idx: 330 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (41387/42368)
Epoch: 205 | Batch_idx: 340 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (42631/43648)
Epoch: 205 | Batch_idx: 350 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (43876/44928)
Epoch: 205 | Batch_idx: 360 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (45129/46208)
Epoch: 205 | Batch_idx: 370 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (46371/47488)
Epoch: 205 | Batch_idx: 380 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (47629/48768)
Epoch: 205 | Batch_idx: 390 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (48833/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_205.pth.tar'
# TEST : Loss: (0.4585) | Acc: (87.00%) (8798/10000)
percent tensor([0.5833, 0.5838, 0.5932, 0.5870, 0.6056, 0.5864, 0.5944, 0.5970, 0.5892,
        0.5844, 0.5807, 0.5915, 0.5833, 0.5785, 0.5860, 0.5816],
       device='cuda:0') torch.Size([16])
percent tensor([0.5385, 0.5380, 0.5285, 0.5362, 0.5304, 0.5425, 0.5347, 0.5294, 0.5363,
        0.5371, 0.5389, 0.5339, 0.5383, 0.5372, 0.5419, 0.5404],
       device='cuda:0') torch.Size([16])
percent tensor([0.5367, 0.5652, 0.5598, 0.5678, 0.5946, 0.6019, 0.5670, 0.5440, 0.5678,
        0.5591, 0.5521, 0.5782, 0.5699, 0.5517, 0.5774, 0.5615],
       device='cuda:0') torch.Size([16])
percent tensor([0.6713, 0.6832, 0.6393, 0.6321, 0.6355, 0.6398, 0.6764, 0.6378, 0.6604,
        0.6757, 0.6925, 0.6596, 0.6794, 0.6762, 0.6788, 0.6619],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.5837, 0.7366, 0.8271, 0.7425, 0.7442, 0.6185, 0.5869, 0.7653,
        0.6109, 0.7198, 0.7405, 0.6141, 0.8170, 0.5595, 0.6321],
       device='cuda:0') torch.Size([16])
percent tensor([0.7477, 0.6908, 0.7672, 0.7584, 0.7817, 0.7444, 0.7542, 0.7820, 0.7254,
        0.6948, 0.6883, 0.7391, 0.6675, 0.7110, 0.7468, 0.7391],
       device='cuda:0') torch.Size([16])
percent tensor([0.5920, 0.6085, 0.7441, 0.6124, 0.7480, 0.7879, 0.7000, 0.6114, 0.5303,
        0.6213, 0.6647, 0.4627, 0.5629, 0.4727, 0.5576, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 1.0000, 0.9999, 0.9998, 0.9994, 0.9999, 0.9999, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 206 | Batch_idx: 0 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 206 | Batch_idx: 10 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 206 | Batch_idx: 20 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (98.00%) (2635/2688)
Epoch: 206 | Batch_idx: 30 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (3886/3968)
Epoch: 206 | Batch_idx: 40 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (5143/5248)
Epoch: 206 | Batch_idx: 50 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (6391/6528)
Epoch: 206 | Batch_idx: 60 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (7635/7808)
Epoch: 206 | Batch_idx: 70 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (8871/9088)
Epoch: 206 | Batch_idx: 80 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (10120/10368)
Epoch: 206 | Batch_idx: 90 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (11375/11648)
Epoch: 206 | Batch_idx: 100 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (12628/12928)
Epoch: 206 | Batch_idx: 110 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (13880/14208)
Epoch: 206 | Batch_idx: 120 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (15132/15488)
Epoch: 206 | Batch_idx: 130 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (16381/16768)
Epoch: 206 | Batch_idx: 140 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (17630/18048)
Epoch: 206 | Batch_idx: 150 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (18881/19328)
Epoch: 206 | Batch_idx: 160 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (20129/20608)
Epoch: 206 | Batch_idx: 170 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (21379/21888)
Epoch: 206 | Batch_idx: 180 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (22622/23168)
Epoch: 206 | Batch_idx: 190 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (23867/24448)
Epoch: 206 | Batch_idx: 200 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (25117/25728)
Epoch: 206 | Batch_idx: 210 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (26370/27008)
Epoch: 206 | Batch_idx: 220 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (27626/28288)
Epoch: 206 | Batch_idx: 230 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (28880/29568)
Epoch: 206 | Batch_idx: 240 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (30131/30848)
Epoch: 206 | Batch_idx: 250 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (31377/32128)
Epoch: 206 | Batch_idx: 260 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (32640/33408)
Epoch: 206 | Batch_idx: 270 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (33887/34688)
Epoch: 206 | Batch_idx: 280 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (35144/35968)
Epoch: 206 | Batch_idx: 290 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (36393/37248)
Epoch: 206 | Batch_idx: 300 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (37646/38528)
Epoch: 206 | Batch_idx: 310 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (38895/39808)
Epoch: 206 | Batch_idx: 320 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (40146/41088)
Epoch: 206 | Batch_idx: 330 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (41397/42368)
Epoch: 206 | Batch_idx: 340 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (42644/43648)
Epoch: 206 | Batch_idx: 350 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (43886/44928)
Epoch: 206 | Batch_idx: 360 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (45140/46208)
Epoch: 206 | Batch_idx: 370 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (46392/47488)
Epoch: 206 | Batch_idx: 380 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (47648/48768)
Epoch: 206 | Batch_idx: 390 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (48847/50000)
# TEST : Loss: (0.4535) | Acc: (88.00%) (8819/10000)
percent tensor([0.5861, 0.5822, 0.5976, 0.5870, 0.6084, 0.5872, 0.5954, 0.5984, 0.5909,
        0.5854, 0.5819, 0.5946, 0.5854, 0.5750, 0.5853, 0.5818],
       device='cuda:0') torch.Size([16])
percent tensor([0.5387, 0.5382, 0.5284, 0.5362, 0.5295, 0.5414, 0.5348, 0.5297, 0.5361,
        0.5369, 0.5386, 0.5338, 0.5385, 0.5362, 0.5415, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.5366, 0.5628, 0.5562, 0.5601, 0.5905, 0.5995, 0.5673, 0.5441, 0.5669,
        0.5539, 0.5523, 0.5748, 0.5668, 0.5518, 0.5735, 0.5601],
       device='cuda:0') torch.Size([16])
percent tensor([0.6760, 0.6887, 0.6414, 0.6398, 0.6404, 0.6478, 0.6807, 0.6382, 0.6598,
        0.6808, 0.6983, 0.6610, 0.6792, 0.6782, 0.6870, 0.6697],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.5950, 0.7241, 0.8126, 0.7198, 0.7306, 0.6096, 0.5767, 0.7547,
        0.6209, 0.7119, 0.7185, 0.6192, 0.8285, 0.5488, 0.6338],
       device='cuda:0') torch.Size([16])
percent tensor([0.7484, 0.7066, 0.7648, 0.7734, 0.7918, 0.7386, 0.7615, 0.7786, 0.7298,
        0.7002, 0.6917, 0.7464, 0.6691, 0.7356, 0.7474, 0.7473],
       device='cuda:0') torch.Size([16])
percent tensor([0.6166, 0.6911, 0.7632, 0.6584, 0.7770, 0.7676, 0.7322, 0.6387, 0.6245,
        0.6916, 0.6984, 0.5345, 0.5890, 0.5816, 0.5973, 0.5765],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 207 | Batch_idx: 0 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 207 | Batch_idx: 10 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 207 | Batch_idx: 20 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (2643/2688)
Epoch: 207 | Batch_idx: 30 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (3904/3968)
Epoch: 207 | Batch_idx: 40 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (5154/5248)
Epoch: 207 | Batch_idx: 50 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (98.00%) (6406/6528)
Epoch: 207 | Batch_idx: 60 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (7661/7808)
Epoch: 207 | Batch_idx: 70 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (8922/9088)
Epoch: 207 | Batch_idx: 80 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (10174/10368)
Epoch: 207 | Batch_idx: 90 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (11435/11648)
Epoch: 207 | Batch_idx: 100 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (12684/12928)
Epoch: 207 | Batch_idx: 110 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (13943/14208)
Epoch: 207 | Batch_idx: 120 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (15194/15488)
Epoch: 207 | Batch_idx: 130 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (16447/16768)
Epoch: 207 | Batch_idx: 140 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (17694/18048)
Epoch: 207 | Batch_idx: 150 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (18941/19328)
Epoch: 207 | Batch_idx: 160 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (20189/20608)
Epoch: 207 | Batch_idx: 170 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (21433/21888)
Epoch: 207 | Batch_idx: 180 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (22686/23168)
Epoch: 207 | Batch_idx: 190 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (23928/24448)
Epoch: 207 | Batch_idx: 200 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (25179/25728)
Epoch: 207 | Batch_idx: 210 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (26424/27008)
Epoch: 207 | Batch_idx: 220 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (27669/28288)
Epoch: 207 | Batch_idx: 230 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (28923/29568)
Epoch: 207 | Batch_idx: 240 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (30173/30848)
Epoch: 207 | Batch_idx: 250 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (31421/32128)
Epoch: 207 | Batch_idx: 260 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (32666/33408)
Epoch: 207 | Batch_idx: 270 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (33914/34688)
Epoch: 207 | Batch_idx: 280 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (35157/35968)
Epoch: 207 | Batch_idx: 290 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (36409/37248)
Epoch: 207 | Batch_idx: 300 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (37665/38528)
Epoch: 207 | Batch_idx: 310 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (38917/39808)
Epoch: 207 | Batch_idx: 320 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (40155/41088)
Epoch: 207 | Batch_idx: 330 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (41408/42368)
Epoch: 207 | Batch_idx: 340 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (42667/43648)
Epoch: 207 | Batch_idx: 350 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (43923/44928)
Epoch: 207 | Batch_idx: 360 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (45175/46208)
Epoch: 207 | Batch_idx: 370 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (46415/47488)
Epoch: 207 | Batch_idx: 380 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (47658/48768)
Epoch: 207 | Batch_idx: 390 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (48858/50000)
# TEST : Loss: (0.4386) | Acc: (87.00%) (8799/10000)
percent tensor([0.5837, 0.5814, 0.5933, 0.5846, 0.6051, 0.5844, 0.5931, 0.5965, 0.5893,
        0.5831, 0.5805, 0.5909, 0.5833, 0.5752, 0.5836, 0.5793],
       device='cuda:0') torch.Size([16])
percent tensor([0.5398, 0.5395, 0.5295, 0.5378, 0.5311, 0.5435, 0.5358, 0.5298, 0.5369,
        0.5380, 0.5400, 0.5352, 0.5399, 0.5368, 0.5430, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5358, 0.5653, 0.5562, 0.5598, 0.5924, 0.5943, 0.5662, 0.5465, 0.5676,
        0.5560, 0.5499, 0.5773, 0.5697, 0.5505, 0.5721, 0.5563],
       device='cuda:0') torch.Size([16])
percent tensor([0.6779, 0.6855, 0.6464, 0.6445, 0.6425, 0.6521, 0.6826, 0.6396, 0.6618,
        0.6790, 0.6954, 0.6651, 0.6803, 0.6768, 0.6848, 0.6688],
       device='cuda:0') torch.Size([16])
percent tensor([0.5715, 0.5785, 0.7164, 0.8188, 0.7198, 0.7239, 0.6013, 0.5723, 0.7397,
        0.5903, 0.6916, 0.6793, 0.6005, 0.7942, 0.5484, 0.6243],
       device='cuda:0') torch.Size([16])
percent tensor([0.7514, 0.7056, 0.7773, 0.7697, 0.7943, 0.7471, 0.7636, 0.7851, 0.7438,
        0.7042, 0.7014, 0.7432, 0.6760, 0.7432, 0.7492, 0.7490],
       device='cuda:0') torch.Size([16])
percent tensor([0.5992, 0.6400, 0.7425, 0.6381, 0.7433, 0.7763, 0.6787, 0.5938, 0.6330,
        0.6020, 0.6783, 0.4634, 0.5843, 0.4426, 0.5946, 0.5301],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9996, 0.9997, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 208 | Batch_idx: 0 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 208 | Batch_idx: 10 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 208 | Batch_idx: 20 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (2623/2688)
Epoch: 208 | Batch_idx: 30 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (3878/3968)
Epoch: 208 | Batch_idx: 40 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (5130/5248)
Epoch: 208 | Batch_idx: 50 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (6388/6528)
Epoch: 208 | Batch_idx: 60 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (7643/7808)
Epoch: 208 | Batch_idx: 70 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (8892/9088)
Epoch: 208 | Batch_idx: 80 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (10135/10368)
Epoch: 208 | Batch_idx: 90 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (11388/11648)
Epoch: 208 | Batch_idx: 100 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (12641/12928)
Epoch: 208 | Batch_idx: 110 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (13898/14208)
Epoch: 208 | Batch_idx: 120 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (15148/15488)
Epoch: 208 | Batch_idx: 130 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (16398/16768)
Epoch: 208 | Batch_idx: 140 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (17648/18048)
Epoch: 208 | Batch_idx: 150 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (18903/19328)
Epoch: 208 | Batch_idx: 160 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (20157/20608)
Epoch: 208 | Batch_idx: 170 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (21408/21888)
Epoch: 208 | Batch_idx: 180 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (22667/23168)
Epoch: 208 | Batch_idx: 190 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (23918/24448)
Epoch: 208 | Batch_idx: 200 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (25168/25728)
Epoch: 208 | Batch_idx: 210 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (26418/27008)
Epoch: 208 | Batch_idx: 220 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (27662/28288)
Epoch: 208 | Batch_idx: 230 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (28924/29568)
Epoch: 208 | Batch_idx: 240 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (30178/30848)
Epoch: 208 | Batch_idx: 250 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (31430/32128)
Epoch: 208 | Batch_idx: 260 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (32683/33408)
Epoch: 208 | Batch_idx: 270 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (33936/34688)
Epoch: 208 | Batch_idx: 280 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (35190/35968)
Epoch: 208 | Batch_idx: 290 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (36443/37248)
Epoch: 208 | Batch_idx: 300 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (37695/38528)
Epoch: 208 | Batch_idx: 310 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (38944/39808)
Epoch: 208 | Batch_idx: 320 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (40197/41088)
Epoch: 208 | Batch_idx: 330 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (41446/42368)
Epoch: 208 | Batch_idx: 340 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (42694/43648)
Epoch: 208 | Batch_idx: 350 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (43944/44928)
Epoch: 208 | Batch_idx: 360 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (45199/46208)
Epoch: 208 | Batch_idx: 370 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (46450/47488)
Epoch: 208 | Batch_idx: 380 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (47702/48768)
Epoch: 208 | Batch_idx: 390 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (48899/50000)
# TEST : Loss: (0.4543) | Acc: (88.00%) (8814/10000)
percent tensor([0.5877, 0.5844, 0.6002, 0.5906, 0.6110, 0.5910, 0.5973, 0.6009, 0.5905,
        0.5871, 0.5831, 0.5972, 0.5862, 0.5751, 0.5891, 0.5838],
       device='cuda:0') torch.Size([16])
percent tensor([0.5404, 0.5403, 0.5298, 0.5381, 0.5315, 0.5432, 0.5369, 0.5304, 0.5379,
        0.5388, 0.5407, 0.5356, 0.5404, 0.5374, 0.5435, 0.5418],
       device='cuda:0') torch.Size([16])
percent tensor([0.5426, 0.5700, 0.5637, 0.5718, 0.5978, 0.5980, 0.5752, 0.5545, 0.5667,
        0.5642, 0.5548, 0.5873, 0.5742, 0.5545, 0.5789, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.6784, 0.6892, 0.6435, 0.6391, 0.6423, 0.6475, 0.6846, 0.6416, 0.6668,
        0.6824, 0.7007, 0.6655, 0.6858, 0.6833, 0.6851, 0.6713],
       device='cuda:0') torch.Size([16])
percent tensor([0.5623, 0.5848, 0.7194, 0.8003, 0.7213, 0.7035, 0.6125, 0.5781, 0.7558,
        0.6160, 0.7058, 0.7042, 0.6106, 0.8278, 0.5490, 0.6187],
       device='cuda:0') torch.Size([16])
percent tensor([0.7392, 0.6937, 0.7727, 0.7598, 0.7870, 0.7463, 0.7547, 0.7746, 0.7251,
        0.6930, 0.6874, 0.7393, 0.6608, 0.7258, 0.7406, 0.7399],
       device='cuda:0') torch.Size([16])
percent tensor([0.5903, 0.6497, 0.7504, 0.6472, 0.7277, 0.7771, 0.6852, 0.5785, 0.6251,
        0.6654, 0.7118, 0.5158, 0.5763, 0.4904, 0.5739, 0.5452],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 1.0000, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9997, 0.9996, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 209 | Batch_idx: 0 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 209 | Batch_idx: 10 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 209 | Batch_idx: 20 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 209 | Batch_idx: 30 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (3891/3968)
Epoch: 209 | Batch_idx: 40 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (5153/5248)
Epoch: 209 | Batch_idx: 50 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (6408/6528)
Epoch: 209 | Batch_idx: 60 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (7664/7808)
Epoch: 209 | Batch_idx: 70 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (8913/9088)
Epoch: 209 | Batch_idx: 80 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (10161/10368)
Epoch: 209 | Batch_idx: 90 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (11417/11648)
Epoch: 209 | Batch_idx: 100 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (12669/12928)
Epoch: 209 | Batch_idx: 110 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (13916/14208)
Epoch: 209 | Batch_idx: 120 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (15162/15488)
Epoch: 209 | Batch_idx: 130 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (16413/16768)
Epoch: 209 | Batch_idx: 140 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (17657/18048)
Epoch: 209 | Batch_idx: 150 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (18908/19328)
Epoch: 209 | Batch_idx: 160 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (20159/20608)
Epoch: 209 | Batch_idx: 170 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (21413/21888)
Epoch: 209 | Batch_idx: 180 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (22659/23168)
Epoch: 209 | Batch_idx: 190 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (23911/24448)
Epoch: 209 | Batch_idx: 200 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (25158/25728)
Epoch: 209 | Batch_idx: 210 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (26407/27008)
Epoch: 209 | Batch_idx: 220 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (27662/28288)
Epoch: 209 | Batch_idx: 230 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (28920/29568)
Epoch: 209 | Batch_idx: 240 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (30175/30848)
Epoch: 209 | Batch_idx: 250 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (31433/32128)
Epoch: 209 | Batch_idx: 260 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (32687/33408)
Epoch: 209 | Batch_idx: 270 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (33938/34688)
Epoch: 209 | Batch_idx: 280 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (35192/35968)
Epoch: 209 | Batch_idx: 290 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (36441/37248)
Epoch: 209 | Batch_idx: 300 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (37694/38528)
Epoch: 209 | Batch_idx: 310 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (38947/39808)
Epoch: 209 | Batch_idx: 320 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (40198/41088)
Epoch: 209 | Batch_idx: 330 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (41458/42368)
Epoch: 209 | Batch_idx: 340 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (42702/43648)
Epoch: 209 | Batch_idx: 350 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (43961/44928)
Epoch: 209 | Batch_idx: 360 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (45217/46208)
Epoch: 209 | Batch_idx: 370 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (46472/47488)
Epoch: 209 | Batch_idx: 380 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (47725/48768)
Epoch: 209 | Batch_idx: 390 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (48925/50000)
# TEST : Loss: (0.4463) | Acc: (88.00%) (8832/10000)
percent tensor([0.5884, 0.5865, 0.5990, 0.5908, 0.6113, 0.5908, 0.5989, 0.6021, 0.5929,
        0.5882, 0.5850, 0.5961, 0.5880, 0.5790, 0.5897, 0.5852],
       device='cuda:0') torch.Size([16])
percent tensor([0.5409, 0.5421, 0.5306, 0.5379, 0.5322, 0.5438, 0.5384, 0.5316, 0.5391,
        0.5398, 0.5419, 0.5363, 0.5418, 0.5394, 0.5446, 0.5427],
       device='cuda:0') torch.Size([16])
percent tensor([0.5443, 0.5733, 0.5709, 0.5746, 0.6062, 0.6017, 0.5810, 0.5615, 0.5751,
        0.5660, 0.5585, 0.5904, 0.5770, 0.5606, 0.5824, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.6803, 0.6903, 0.6491, 0.6450, 0.6460, 0.6559, 0.6849, 0.6410, 0.6660,
        0.6839, 0.7007, 0.6684, 0.6847, 0.6822, 0.6888, 0.6746],
       device='cuda:0') torch.Size([16])
percent tensor([0.5774, 0.5896, 0.6994, 0.8046, 0.7066, 0.7447, 0.6136, 0.5763, 0.7611,
        0.6063, 0.7319, 0.6948, 0.6182, 0.8238, 0.5562, 0.6206],
       device='cuda:0') torch.Size([16])
percent tensor([0.7524, 0.7095, 0.7753, 0.7791, 0.7924, 0.7485, 0.7609, 0.7853, 0.7352,
        0.7044, 0.6947, 0.7439, 0.6739, 0.7349, 0.7518, 0.7510],
       device='cuda:0') torch.Size([16])
percent tensor([0.5699, 0.6784, 0.7692, 0.6763, 0.7375, 0.7586, 0.6889, 0.6737, 0.6158,
        0.6786, 0.6875, 0.5201, 0.5860, 0.4898, 0.5891, 0.5219],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 0.9999, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9996, 0.9996, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 210 | Batch_idx: 0 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 210 | Batch_idx: 10 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 210 | Batch_idx: 20 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (2636/2688)
Epoch: 210 | Batch_idx: 30 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (98.00%) (3893/3968)
Epoch: 210 | Batch_idx: 40 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (5141/5248)
Epoch: 210 | Batch_idx: 50 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (6392/6528)
Epoch: 210 | Batch_idx: 60 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (7639/7808)
Epoch: 210 | Batch_idx: 70 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (8888/9088)
Epoch: 210 | Batch_idx: 80 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (10144/10368)
Epoch: 210 | Batch_idx: 90 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (11406/11648)
Epoch: 210 | Batch_idx: 100 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (12669/12928)
Epoch: 210 | Batch_idx: 110 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (13906/14208)
Epoch: 210 | Batch_idx: 120 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (15163/15488)
Epoch: 210 | Batch_idx: 130 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (16409/16768)
Epoch: 210 | Batch_idx: 140 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (17651/18048)
Epoch: 210 | Batch_idx: 150 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (18893/19328)
Epoch: 210 | Batch_idx: 160 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (20152/20608)
Epoch: 210 | Batch_idx: 170 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (21403/21888)
Epoch: 210 | Batch_idx: 180 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (22658/23168)
Epoch: 210 | Batch_idx: 190 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (23912/24448)
Epoch: 210 | Batch_idx: 200 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (25171/25728)
Epoch: 210 | Batch_idx: 210 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (26427/27008)
Epoch: 210 | Batch_idx: 220 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (27684/28288)
Epoch: 210 | Batch_idx: 230 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (28936/29568)
Epoch: 210 | Batch_idx: 240 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (30190/30848)
Epoch: 210 | Batch_idx: 250 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (31450/32128)
Epoch: 210 | Batch_idx: 260 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (32706/33408)
Epoch: 210 | Batch_idx: 270 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (33961/34688)
Epoch: 210 | Batch_idx: 280 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (35221/35968)
Epoch: 210 | Batch_idx: 290 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (36478/37248)
Epoch: 210 | Batch_idx: 300 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (37742/38528)
Epoch: 210 | Batch_idx: 310 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (39007/39808)
Epoch: 210 | Batch_idx: 320 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (40263/41088)
Epoch: 210 | Batch_idx: 330 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (41513/42368)
Epoch: 210 | Batch_idx: 340 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (42771/43648)
Epoch: 210 | Batch_idx: 350 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (44025/44928)
Epoch: 210 | Batch_idx: 360 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (45274/46208)
Epoch: 210 | Batch_idx: 370 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (46524/47488)
Epoch: 210 | Batch_idx: 380 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (47784/48768)
Epoch: 210 | Batch_idx: 390 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (48987/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_210.pth.tar'
# TEST : Loss: (0.4277) | Acc: (88.00%) (8837/10000)
percent tensor([0.5872, 0.5846, 0.5987, 0.5896, 0.6109, 0.5891, 0.5975, 0.6016, 0.5908,
        0.5868, 0.5822, 0.5962, 0.5859, 0.5770, 0.5881, 0.5830],
       device='cuda:0') torch.Size([16])
percent tensor([0.5411, 0.5422, 0.5306, 0.5390, 0.5322, 0.5444, 0.5386, 0.5313, 0.5389,
        0.5400, 0.5417, 0.5366, 0.5414, 0.5394, 0.5451, 0.5428],
       device='cuda:0') torch.Size([16])
percent tensor([0.5426, 0.5671, 0.5672, 0.5748, 0.6024, 0.5979, 0.5741, 0.5571, 0.5684,
        0.5616, 0.5513, 0.5877, 0.5709, 0.5566, 0.5770, 0.5625],
       device='cuda:0') torch.Size([16])
percent tensor([0.6847, 0.6961, 0.6524, 0.6433, 0.6465, 0.6495, 0.6911, 0.6478, 0.6719,
        0.6877, 0.7060, 0.6710, 0.6922, 0.6912, 0.6915, 0.6750],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5797, 0.7078, 0.8131, 0.7229, 0.7328, 0.5942, 0.5713, 0.7286,
        0.5980, 0.6890, 0.7020, 0.5980, 0.8067, 0.5472, 0.6229],
       device='cuda:0') torch.Size([16])
percent tensor([0.7494, 0.7058, 0.7748, 0.7741, 0.7920, 0.7454, 0.7552, 0.7781, 0.7360,
        0.6985, 0.6884, 0.7482, 0.6789, 0.7292, 0.7500, 0.7457],
       device='cuda:0') torch.Size([16])
percent tensor([0.5401, 0.6508, 0.7646, 0.6890, 0.7530, 0.7577, 0.6516, 0.6231, 0.6053,
        0.6543, 0.6549, 0.4924, 0.5812, 0.4331, 0.5451, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9997, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(185.5752, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(838.4525, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(845.3057, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1507.5128, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(478.2866, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2293.0745, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4270.6724, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1333.1766, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6293.4102, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11477.8965, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3764.8328, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15929.7031, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 211 | Batch_idx: 0 |  Loss: (0.0250) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 211 | Batch_idx: 10 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 211 | Batch_idx: 20 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (2652/2688)
Epoch: 211 | Batch_idx: 30 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (3906/3968)
Epoch: 211 | Batch_idx: 40 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (5159/5248)
Epoch: 211 | Batch_idx: 50 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (6411/6528)
Epoch: 211 | Batch_idx: 60 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (7678/7808)
Epoch: 211 | Batch_idx: 70 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (8934/9088)
Epoch: 211 | Batch_idx: 80 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (10190/10368)
Epoch: 211 | Batch_idx: 90 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (11442/11648)
Epoch: 211 | Batch_idx: 100 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (12695/12928)
Epoch: 211 | Batch_idx: 110 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (13949/14208)
Epoch: 211 | Batch_idx: 120 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (15211/15488)
Epoch: 211 | Batch_idx: 130 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (16467/16768)
Epoch: 211 | Batch_idx: 140 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (17727/18048)
Epoch: 211 | Batch_idx: 150 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (18980/19328)
Epoch: 211 | Batch_idx: 160 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (20235/20608)
Epoch: 211 | Batch_idx: 170 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (21493/21888)
Epoch: 211 | Batch_idx: 180 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (22763/23168)
Epoch: 211 | Batch_idx: 190 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (24020/24448)
Epoch: 211 | Batch_idx: 200 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (25260/25728)
Epoch: 211 | Batch_idx: 210 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (26506/27008)
Epoch: 211 | Batch_idx: 220 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (27765/28288)
Epoch: 211 | Batch_idx: 230 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (29015/29568)
Epoch: 211 | Batch_idx: 240 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (30274/30848)
Epoch: 211 | Batch_idx: 250 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (31522/32128)
Epoch: 211 | Batch_idx: 260 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (32767/33408)
Epoch: 211 | Batch_idx: 270 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (34025/34688)
Epoch: 211 | Batch_idx: 280 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (35278/35968)
Epoch: 211 | Batch_idx: 290 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (36529/37248)
Epoch: 211 | Batch_idx: 300 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (37778/38528)
Epoch: 211 | Batch_idx: 310 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (39025/39808)
Epoch: 211 | Batch_idx: 320 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (40272/41088)
Epoch: 211 | Batch_idx: 330 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (41532/42368)
Epoch: 211 | Batch_idx: 340 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (42778/43648)
Epoch: 211 | Batch_idx: 350 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (44021/44928)
Epoch: 211 | Batch_idx: 360 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (45275/46208)
Epoch: 211 | Batch_idx: 370 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (46525/47488)
Epoch: 211 | Batch_idx: 380 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (47788/48768)
Epoch: 211 | Batch_idx: 390 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (48985/50000)
# TEST : Loss: (0.4533) | Acc: (87.00%) (8798/10000)
percent tensor([0.5870, 0.5841, 0.5991, 0.5901, 0.6100, 0.5890, 0.5965, 0.6019, 0.5907,
        0.5863, 0.5827, 0.5958, 0.5860, 0.5764, 0.5878, 0.5836],
       device='cuda:0') torch.Size([16])
percent tensor([0.5419, 0.5423, 0.5327, 0.5403, 0.5339, 0.5443, 0.5392, 0.5329, 0.5398,
        0.5408, 0.5420, 0.5381, 0.5420, 0.5393, 0.5452, 0.5436],
       device='cuda:0') torch.Size([16])
percent tensor([0.5416, 0.5680, 0.5679, 0.5769, 0.6010, 0.5950, 0.5723, 0.5587, 0.5654,
        0.5612, 0.5506, 0.5878, 0.5714, 0.5523, 0.5779, 0.5651],
       device='cuda:0') torch.Size([16])
percent tensor([0.6848, 0.6966, 0.6502, 0.6476, 0.6472, 0.6553, 0.6892, 0.6468, 0.6720,
        0.6884, 0.7060, 0.6694, 0.6908, 0.6898, 0.6926, 0.6761],
       device='cuda:0') torch.Size([16])
percent tensor([0.5736, 0.5813, 0.7195, 0.8147, 0.7194, 0.7435, 0.6095, 0.5737, 0.7571,
        0.5961, 0.7106, 0.7246, 0.6154, 0.8148, 0.5470, 0.6275],
       device='cuda:0') torch.Size([16])
percent tensor([0.7467, 0.7064, 0.7681, 0.7750, 0.7905, 0.7531, 0.7629, 0.7778, 0.7361,
        0.7008, 0.6964, 0.7438, 0.6749, 0.7360, 0.7499, 0.7458],
       device='cuda:0') torch.Size([16])
percent tensor([0.5707, 0.6645, 0.7399, 0.6151, 0.7344, 0.7805, 0.6592, 0.5916, 0.5446,
        0.6422, 0.6573, 0.4823, 0.5522, 0.4475, 0.5843, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9997, 1.0000, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 212 | Batch_idx: 0 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 212 | Batch_idx: 10 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 212 | Batch_idx: 20 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (2643/2688)
Epoch: 212 | Batch_idx: 30 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (3907/3968)
Epoch: 212 | Batch_idx: 40 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (5158/5248)
Epoch: 212 | Batch_idx: 50 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (6408/6528)
Epoch: 212 | Batch_idx: 60 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (7671/7808)
Epoch: 212 | Batch_idx: 70 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (8923/9088)
Epoch: 212 | Batch_idx: 80 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (10184/10368)
Epoch: 212 | Batch_idx: 90 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (11439/11648)
Epoch: 212 | Batch_idx: 100 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (12696/12928)
Epoch: 212 | Batch_idx: 110 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (13943/14208)
Epoch: 212 | Batch_idx: 120 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (15200/15488)
Epoch: 212 | Batch_idx: 130 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (16452/16768)
Epoch: 212 | Batch_idx: 140 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (17701/18048)
Epoch: 212 | Batch_idx: 150 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (18957/19328)
Epoch: 212 | Batch_idx: 160 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (20216/20608)
Epoch: 212 | Batch_idx: 170 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (21472/21888)
Epoch: 212 | Batch_idx: 180 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (22739/23168)
Epoch: 212 | Batch_idx: 190 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (23996/24448)
Epoch: 212 | Batch_idx: 200 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (25263/25728)
Epoch: 212 | Batch_idx: 210 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (26518/27008)
Epoch: 212 | Batch_idx: 220 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (27772/28288)
Epoch: 212 | Batch_idx: 230 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (29026/29568)
Epoch: 212 | Batch_idx: 240 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (30271/30848)
Epoch: 212 | Batch_idx: 250 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (31519/32128)
Epoch: 212 | Batch_idx: 260 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (32775/33408)
Epoch: 212 | Batch_idx: 270 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (34035/34688)
Epoch: 212 | Batch_idx: 280 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (35287/35968)
Epoch: 212 | Batch_idx: 290 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (36541/37248)
Epoch: 212 | Batch_idx: 300 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (37799/38528)
Epoch: 212 | Batch_idx: 310 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (39056/39808)
Epoch: 212 | Batch_idx: 320 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (40306/41088)
Epoch: 212 | Batch_idx: 330 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (41560/42368)
Epoch: 212 | Batch_idx: 340 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (42805/43648)
Epoch: 212 | Batch_idx: 350 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (44055/44928)
Epoch: 212 | Batch_idx: 360 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (45311/46208)
Epoch: 212 | Batch_idx: 370 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (46555/47488)
Epoch: 212 | Batch_idx: 380 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (47799/48768)
Epoch: 212 | Batch_idx: 390 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (49003/50000)
# TEST : Loss: (0.4405) | Acc: (88.00%) (8867/10000)
percent tensor([0.5878, 0.5845, 0.5989, 0.5897, 0.6104, 0.5899, 0.5972, 0.6013, 0.5924,
        0.5864, 0.5836, 0.5957, 0.5864, 0.5773, 0.5882, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.5423, 0.5323, 0.5407, 0.5337, 0.5451, 0.5391, 0.5330, 0.5398,
        0.5409, 0.5423, 0.5383, 0.5419, 0.5394, 0.5455, 0.5440],
       device='cuda:0') torch.Size([16])
percent tensor([0.5409, 0.5683, 0.5665, 0.5739, 0.6067, 0.5995, 0.5787, 0.5606, 0.5742,
        0.5625, 0.5534, 0.5885, 0.5689, 0.5640, 0.5790, 0.5643],
       device='cuda:0') torch.Size([16])
percent tensor([0.6817, 0.6939, 0.6500, 0.6446, 0.6460, 0.6510, 0.6869, 0.6430, 0.6683,
        0.6869, 0.7043, 0.6710, 0.6887, 0.6833, 0.6890, 0.6731],
       device='cuda:0') torch.Size([16])
percent tensor([0.5753, 0.5949, 0.7324, 0.8161, 0.7199, 0.7362, 0.6027, 0.5811, 0.7730,
        0.6242, 0.7147, 0.7127, 0.6190, 0.8261, 0.5466, 0.6320],
       device='cuda:0') torch.Size([16])
percent tensor([0.7448, 0.7039, 0.7711, 0.7700, 0.7835, 0.7460, 0.7603, 0.7802, 0.7307,
        0.6951, 0.6920, 0.7419, 0.6735, 0.7317, 0.7492, 0.7400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5722, 0.6178, 0.7444, 0.6564, 0.7281, 0.7794, 0.6774, 0.6492, 0.5849,
        0.6193, 0.6388, 0.4629, 0.5363, 0.4794, 0.5835, 0.5437],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9997, 0.9997, 0.9999, 1.0000, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9997, 0.9994, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 213 | Batch_idx: 0 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 213 | Batch_idx: 10 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 213 | Batch_idx: 20 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (2629/2688)
Epoch: 213 | Batch_idx: 30 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (98.00%) (3893/3968)
Epoch: 213 | Batch_idx: 40 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (5156/5248)
Epoch: 213 | Batch_idx: 50 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (6415/6528)
Epoch: 213 | Batch_idx: 60 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (7670/7808)
Epoch: 213 | Batch_idx: 70 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (8922/9088)
Epoch: 213 | Batch_idx: 80 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (10186/10368)
Epoch: 213 | Batch_idx: 90 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (11440/11648)
Epoch: 213 | Batch_idx: 100 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (12693/12928)
Epoch: 213 | Batch_idx: 110 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (13952/14208)
Epoch: 213 | Batch_idx: 120 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (15206/15488)
Epoch: 213 | Batch_idx: 130 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (16465/16768)
Epoch: 213 | Batch_idx: 140 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (17723/18048)
Epoch: 213 | Batch_idx: 150 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (18982/19328)
Epoch: 213 | Batch_idx: 160 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (20240/20608)
Epoch: 213 | Batch_idx: 170 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (21494/21888)
Epoch: 213 | Batch_idx: 180 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (22759/23168)
Epoch: 213 | Batch_idx: 190 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (24010/24448)
Epoch: 213 | Batch_idx: 200 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (25271/25728)
Epoch: 213 | Batch_idx: 210 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (26517/27008)
Epoch: 213 | Batch_idx: 220 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (27769/28288)
Epoch: 213 | Batch_idx: 230 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (29013/29568)
Epoch: 213 | Batch_idx: 240 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (30269/30848)
Epoch: 213 | Batch_idx: 250 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (31526/32128)
Epoch: 213 | Batch_idx: 260 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (32784/33408)
Epoch: 213 | Batch_idx: 270 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (34039/34688)
Epoch: 213 | Batch_idx: 280 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (35286/35968)
Epoch: 213 | Batch_idx: 290 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (36543/37248)
Epoch: 213 | Batch_idx: 300 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (37797/38528)
Epoch: 213 | Batch_idx: 310 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (39058/39808)
Epoch: 213 | Batch_idx: 320 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (40309/41088)
Epoch: 213 | Batch_idx: 330 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (41565/42368)
Epoch: 213 | Batch_idx: 340 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (42822/43648)
Epoch: 213 | Batch_idx: 350 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (44074/44928)
Epoch: 213 | Batch_idx: 360 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (45324/46208)
Epoch: 213 | Batch_idx: 370 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (46584/47488)
Epoch: 213 | Batch_idx: 380 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (47830/48768)
Epoch: 213 | Batch_idx: 390 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (49041/50000)
# TEST : Loss: (0.4358) | Acc: (88.00%) (8884/10000)
percent tensor([0.5894, 0.5839, 0.5998, 0.5908, 0.6123, 0.5922, 0.5970, 0.6007, 0.5925,
        0.5862, 0.5842, 0.5967, 0.5870, 0.5759, 0.5890, 0.5842],
       device='cuda:0') torch.Size([16])
percent tensor([0.5432, 0.5422, 0.5328, 0.5405, 0.5347, 0.5463, 0.5392, 0.5332, 0.5407,
        0.5411, 0.5428, 0.5390, 0.5431, 0.5398, 0.5463, 0.5443],
       device='cuda:0') torch.Size([16])
percent tensor([0.5462, 0.5682, 0.5708, 0.5757, 0.6144, 0.6116, 0.5774, 0.5603, 0.5784,
        0.5628, 0.5572, 0.5920, 0.5752, 0.5599, 0.5836, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.6851, 0.6979, 0.6524, 0.6517, 0.6496, 0.6556, 0.6894, 0.6490, 0.6711,
        0.6896, 0.7053, 0.6719, 0.6913, 0.6891, 0.6956, 0.6766],
       device='cuda:0') torch.Size([16])
percent tensor([0.5690, 0.5928, 0.7039, 0.8084, 0.7135, 0.7403, 0.6005, 0.5586, 0.7565,
        0.6038, 0.7048, 0.7085, 0.6084, 0.8184, 0.5560, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.7478, 0.7038, 0.7779, 0.7768, 0.7963, 0.7544, 0.7621, 0.7798, 0.7325,
        0.7006, 0.6899, 0.7484, 0.6771, 0.7279, 0.7507, 0.7499],
       device='cuda:0') torch.Size([16])
percent tensor([0.5609, 0.6720, 0.7627, 0.6692, 0.7241, 0.7636, 0.6827, 0.6099, 0.6378,
        0.6537, 0.6379, 0.4912, 0.5809, 0.4940, 0.5931, 0.5409],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9994, 1.0000, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 214 | Batch_idx: 0 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 214 | Batch_idx: 10 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 214 | Batch_idx: 20 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (2638/2688)
Epoch: 214 | Batch_idx: 30 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (3903/3968)
Epoch: 214 | Batch_idx: 40 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (5164/5248)
Epoch: 214 | Batch_idx: 50 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (6427/6528)
Epoch: 214 | Batch_idx: 60 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (7693/7808)
Epoch: 214 | Batch_idx: 70 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (8950/9088)
Epoch: 214 | Batch_idx: 80 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (10212/10368)
Epoch: 214 | Batch_idx: 90 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (11466/11648)
Epoch: 214 | Batch_idx: 100 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (12721/12928)
Epoch: 214 | Batch_idx: 110 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (13979/14208)
Epoch: 214 | Batch_idx: 120 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (15234/15488)
Epoch: 214 | Batch_idx: 130 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (16490/16768)
Epoch: 214 | Batch_idx: 140 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (17744/18048)
Epoch: 214 | Batch_idx: 150 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (18997/19328)
Epoch: 214 | Batch_idx: 160 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (20254/20608)
Epoch: 214 | Batch_idx: 170 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (21521/21888)
Epoch: 214 | Batch_idx: 180 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (22779/23168)
Epoch: 214 | Batch_idx: 190 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (24024/24448)
Epoch: 214 | Batch_idx: 200 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (25283/25728)
Epoch: 214 | Batch_idx: 210 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (26538/27008)
Epoch: 214 | Batch_idx: 220 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (27795/28288)
Epoch: 214 | Batch_idx: 230 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (29044/29568)
Epoch: 214 | Batch_idx: 240 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (30301/30848)
Epoch: 214 | Batch_idx: 250 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (31556/32128)
Epoch: 214 | Batch_idx: 260 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (32812/33408)
Epoch: 214 | Batch_idx: 270 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (34060/34688)
Epoch: 214 | Batch_idx: 280 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (35312/35968)
Epoch: 214 | Batch_idx: 290 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (36568/37248)
Epoch: 214 | Batch_idx: 300 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (37818/38528)
Epoch: 214 | Batch_idx: 310 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (39068/39808)
Epoch: 214 | Batch_idx: 320 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (40323/41088)
Epoch: 214 | Batch_idx: 330 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (41581/42368)
Epoch: 214 | Batch_idx: 340 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (42838/43648)
Epoch: 214 | Batch_idx: 350 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (44100/44928)
Epoch: 214 | Batch_idx: 360 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (45357/46208)
Epoch: 214 | Batch_idx: 370 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (46609/47488)
Epoch: 214 | Batch_idx: 380 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (47869/48768)
Epoch: 214 | Batch_idx: 390 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (49084/50000)
# TEST : Loss: (0.4599) | Acc: (88.00%) (8846/10000)
percent tensor([0.5884, 0.5851, 0.5999, 0.5917, 0.6114, 0.5901, 0.5975, 0.6031, 0.5918,
        0.5875, 0.5838, 0.5970, 0.5870, 0.5773, 0.5888, 0.5849],
       device='cuda:0') torch.Size([16])
percent tensor([0.5432, 0.5432, 0.5326, 0.5400, 0.5340, 0.5452, 0.5400, 0.5337, 0.5406,
        0.5417, 0.5435, 0.5390, 0.5430, 0.5406, 0.5462, 0.5446],
       device='cuda:0') torch.Size([16])
percent tensor([0.5429, 0.5677, 0.5669, 0.5722, 0.6047, 0.6026, 0.5774, 0.5590, 0.5708,
        0.5623, 0.5554, 0.5882, 0.5725, 0.5538, 0.5800, 0.5665],
       device='cuda:0') torch.Size([16])
percent tensor([0.6852, 0.6983, 0.6489, 0.6479, 0.6467, 0.6570, 0.6900, 0.6471, 0.6733,
        0.6893, 0.7088, 0.6704, 0.6915, 0.6890, 0.6950, 0.6770],
       device='cuda:0') torch.Size([16])
percent tensor([0.5860, 0.6063, 0.7270, 0.8136, 0.7318, 0.7518, 0.6305, 0.5872, 0.7779,
        0.6285, 0.7317, 0.7201, 0.6433, 0.8285, 0.5672, 0.6462],
       device='cuda:0') torch.Size([16])
percent tensor([0.7531, 0.7165, 0.7799, 0.7734, 0.7968, 0.7576, 0.7717, 0.7917, 0.7426,
        0.7062, 0.7025, 0.7573, 0.6864, 0.7381, 0.7608, 0.7453],
       device='cuda:0') torch.Size([16])
percent tensor([0.5659, 0.6558, 0.7410, 0.6490, 0.7179, 0.7811, 0.6780, 0.6037, 0.5735,
        0.6157, 0.6324, 0.4755, 0.5511, 0.4953, 0.5486, 0.5650],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9995, 1.0000, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9997, 0.9997, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 215 | Batch_idx: 0 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 215 | Batch_idx: 10 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 215 | Batch_idx: 20 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 215 | Batch_idx: 30 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (3912/3968)
Epoch: 215 | Batch_idx: 40 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (5165/5248)
Epoch: 215 | Batch_idx: 50 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (6420/6528)
Epoch: 215 | Batch_idx: 60 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (7668/7808)
Epoch: 215 | Batch_idx: 70 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (8927/9088)
Epoch: 215 | Batch_idx: 80 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (10187/10368)
Epoch: 215 | Batch_idx: 90 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (11445/11648)
Epoch: 215 | Batch_idx: 100 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (12705/12928)
Epoch: 215 | Batch_idx: 110 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (13965/14208)
Epoch: 215 | Batch_idx: 120 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (15220/15488)
Epoch: 215 | Batch_idx: 130 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (16483/16768)
Epoch: 215 | Batch_idx: 140 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (17735/18048)
Epoch: 215 | Batch_idx: 150 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (18987/19328)
Epoch: 215 | Batch_idx: 160 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (20244/20608)
Epoch: 215 | Batch_idx: 170 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (21503/21888)
Epoch: 215 | Batch_idx: 180 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (22768/23168)
Epoch: 215 | Batch_idx: 190 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (24026/24448)
Epoch: 215 | Batch_idx: 200 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (25289/25728)
Epoch: 215 | Batch_idx: 210 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (26548/27008)
Epoch: 215 | Batch_idx: 220 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (27800/28288)
Epoch: 215 | Batch_idx: 230 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (29054/29568)
Epoch: 215 | Batch_idx: 240 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (30300/30848)
Epoch: 215 | Batch_idx: 250 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (31556/32128)
Epoch: 215 | Batch_idx: 260 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (32807/33408)
Epoch: 215 | Batch_idx: 270 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (34067/34688)
Epoch: 215 | Batch_idx: 280 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (35329/35968)
Epoch: 215 | Batch_idx: 290 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (36593/37248)
Epoch: 215 | Batch_idx: 300 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (37850/38528)
Epoch: 215 | Batch_idx: 310 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (39107/39808)
Epoch: 215 | Batch_idx: 320 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (40368/41088)
Epoch: 215 | Batch_idx: 330 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (41629/42368)
Epoch: 215 | Batch_idx: 340 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (42887/43648)
Epoch: 215 | Batch_idx: 350 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (44136/44928)
Epoch: 215 | Batch_idx: 360 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (45394/46208)
Epoch: 215 | Batch_idx: 370 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (46660/47488)
Epoch: 215 | Batch_idx: 380 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (47908/48768)
Epoch: 215 | Batch_idx: 390 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (49108/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_215.pth.tar'
# TEST : Loss: (0.4387) | Acc: (88.00%) (8858/10000)
percent tensor([0.5864, 0.5839, 0.5951, 0.5883, 0.6091, 0.5897, 0.5959, 0.5990, 0.5908,
        0.5853, 0.5830, 0.5934, 0.5857, 0.5776, 0.5874, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.5427, 0.5424, 0.5306, 0.5396, 0.5334, 0.5454, 0.5389, 0.5323, 0.5401,
        0.5409, 0.5431, 0.5373, 0.5425, 0.5403, 0.5458, 0.5448],
       device='cuda:0') torch.Size([16])
percent tensor([0.5460, 0.5679, 0.5736, 0.5765, 0.6153, 0.6057, 0.5794, 0.5589, 0.5755,
        0.5631, 0.5585, 0.5902, 0.5756, 0.5611, 0.5821, 0.5691],
       device='cuda:0') torch.Size([16])
percent tensor([0.6840, 0.6968, 0.6492, 0.6475, 0.6473, 0.6593, 0.6896, 0.6476, 0.6709,
        0.6867, 0.7062, 0.6696, 0.6894, 0.6857, 0.6942, 0.6766],
       device='cuda:0') torch.Size([16])
percent tensor([0.5860, 0.5989, 0.7142, 0.8190, 0.7500, 0.7555, 0.6343, 0.5729, 0.7684,
        0.6229, 0.7160, 0.7205, 0.6216, 0.8354, 0.5641, 0.6364],
       device='cuda:0') torch.Size([16])
percent tensor([0.7591, 0.7197, 0.7804, 0.7809, 0.7959, 0.7556, 0.7751, 0.7883, 0.7442,
        0.7125, 0.7059, 0.7602, 0.6916, 0.7389, 0.7590, 0.7541],
       device='cuda:0') torch.Size([16])
percent tensor([0.5575, 0.6670, 0.7550, 0.6596, 0.7488, 0.7553, 0.6970, 0.6321, 0.5862,
        0.6286, 0.6523, 0.5559, 0.5907, 0.5009, 0.5963, 0.4983],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9997, 0.9996, 1.0000, 0.9999, 1.0000,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 216 | Batch_idx: 0 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 216 | Batch_idx: 10 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 216 | Batch_idx: 20 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 216 | Batch_idx: 30 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (3889/3968)
Epoch: 216 | Batch_idx: 40 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (5143/5248)
Epoch: 216 | Batch_idx: 50 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (6406/6528)
Epoch: 216 | Batch_idx: 60 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (7667/7808)
Epoch: 216 | Batch_idx: 70 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (8931/9088)
Epoch: 216 | Batch_idx: 80 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (10195/10368)
Epoch: 216 | Batch_idx: 90 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (11461/11648)
Epoch: 216 | Batch_idx: 100 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (12724/12928)
Epoch: 216 | Batch_idx: 110 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (13989/14208)
Epoch: 216 | Batch_idx: 120 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (15232/15488)
Epoch: 216 | Batch_idx: 130 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (16490/16768)
Epoch: 216 | Batch_idx: 140 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (17744/18048)
Epoch: 216 | Batch_idx: 150 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (18998/19328)
Epoch: 216 | Batch_idx: 160 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (20257/20608)
Epoch: 216 | Batch_idx: 170 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (21515/21888)
Epoch: 216 | Batch_idx: 180 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (22770/23168)
Epoch: 216 | Batch_idx: 190 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (24031/24448)
Epoch: 216 | Batch_idx: 200 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (25288/25728)
Epoch: 216 | Batch_idx: 210 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (26552/27008)
Epoch: 216 | Batch_idx: 220 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (27806/28288)
Epoch: 216 | Batch_idx: 230 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (29065/29568)
Epoch: 216 | Batch_idx: 240 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (30324/30848)
Epoch: 216 | Batch_idx: 250 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (31576/32128)
Epoch: 216 | Batch_idx: 260 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (32827/33408)
Epoch: 216 | Batch_idx: 270 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (34078/34688)
Epoch: 216 | Batch_idx: 280 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (35334/35968)
Epoch: 216 | Batch_idx: 290 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (36591/37248)
Epoch: 216 | Batch_idx: 300 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (37850/38528)
Epoch: 216 | Batch_idx: 310 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (39106/39808)
Epoch: 216 | Batch_idx: 320 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (40357/41088)
Epoch: 216 | Batch_idx: 330 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (41618/42368)
Epoch: 216 | Batch_idx: 340 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (42877/43648)
Epoch: 216 | Batch_idx: 350 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (44134/44928)
Epoch: 216 | Batch_idx: 360 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (45395/46208)
Epoch: 216 | Batch_idx: 370 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (46645/47488)
Epoch: 216 | Batch_idx: 380 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (47903/48768)
Epoch: 216 | Batch_idx: 390 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (49105/50000)
# TEST : Loss: (0.4646) | Acc: (88.00%) (8821/10000)
percent tensor([0.5866, 0.5842, 0.5964, 0.5884, 0.6085, 0.5889, 0.5962, 0.6000, 0.5906,
        0.5855, 0.5829, 0.5942, 0.5853, 0.5770, 0.5876, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.5434, 0.5430, 0.5327, 0.5405, 0.5341, 0.5458, 0.5395, 0.5336, 0.5395,
        0.5414, 0.5428, 0.5391, 0.5429, 0.5397, 0.5458, 0.5446],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5733, 0.5712, 0.5737, 0.6122, 0.6094, 0.5819, 0.5650, 0.5729,
        0.5664, 0.5567, 0.5942, 0.5754, 0.5589, 0.5849, 0.5688],
       device='cuda:0') torch.Size([16])
percent tensor([0.6859, 0.6952, 0.6521, 0.6509, 0.6487, 0.6545, 0.6902, 0.6439, 0.6715,
        0.6868, 0.7062, 0.6742, 0.6946, 0.6853, 0.6934, 0.6764],
       device='cuda:0') torch.Size([16])
percent tensor([0.5645, 0.5863, 0.6999, 0.8089, 0.7182, 0.7236, 0.6080, 0.5727, 0.7469,
        0.5985, 0.6815, 0.6968, 0.6058, 0.8069, 0.5532, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.7530, 0.7145, 0.7811, 0.7716, 0.7958, 0.7550, 0.7690, 0.7897, 0.7470,
        0.7125, 0.7041, 0.7582, 0.6880, 0.7391, 0.7619, 0.7534],
       device='cuda:0') torch.Size([16])
percent tensor([0.5781, 0.6567, 0.7395, 0.6648, 0.7397, 0.7746, 0.7062, 0.6445, 0.5807,
        0.6214, 0.6514, 0.5185, 0.5734, 0.4462, 0.6167, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 1.0000, 0.9999, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9997, 0.9997, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 217 | Batch_idx: 0 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 217 | Batch_idx: 10 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 217 | Batch_idx: 20 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 217 | Batch_idx: 30 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (3906/3968)
Epoch: 217 | Batch_idx: 40 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (5167/5248)
Epoch: 217 | Batch_idx: 50 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (6424/6528)
Epoch: 217 | Batch_idx: 60 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (7680/7808)
Epoch: 217 | Batch_idx: 70 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (8936/9088)
Epoch: 217 | Batch_idx: 80 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (10196/10368)
Epoch: 217 | Batch_idx: 90 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (11449/11648)
Epoch: 217 | Batch_idx: 100 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (12708/12928)
Epoch: 217 | Batch_idx: 110 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (13963/14208)
Epoch: 217 | Batch_idx: 120 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (15220/15488)
Epoch: 217 | Batch_idx: 130 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (16482/16768)
Epoch: 217 | Batch_idx: 140 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (17744/18048)
Epoch: 217 | Batch_idx: 150 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (19006/19328)
Epoch: 217 | Batch_idx: 160 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (20268/20608)
Epoch: 217 | Batch_idx: 170 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (21529/21888)
Epoch: 217 | Batch_idx: 180 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (22786/23168)
Epoch: 217 | Batch_idx: 190 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (24030/24448)
Epoch: 217 | Batch_idx: 200 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (25280/25728)
Epoch: 217 | Batch_idx: 210 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (26542/27008)
Epoch: 217 | Batch_idx: 220 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (27802/28288)
Epoch: 217 | Batch_idx: 230 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (29055/29568)
Epoch: 217 | Batch_idx: 240 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (30306/30848)
Epoch: 217 | Batch_idx: 250 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (31571/32128)
Epoch: 217 | Batch_idx: 260 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (32832/33408)
Epoch: 217 | Batch_idx: 270 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (34095/34688)
Epoch: 217 | Batch_idx: 280 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (35357/35968)
Epoch: 217 | Batch_idx: 290 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (36604/37248)
Epoch: 217 | Batch_idx: 300 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (37854/38528)
Epoch: 217 | Batch_idx: 310 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (39105/39808)
Epoch: 217 | Batch_idx: 320 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (40361/41088)
Epoch: 217 | Batch_idx: 330 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (41601/42368)
Epoch: 217 | Batch_idx: 340 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (42850/43648)
Epoch: 217 | Batch_idx: 350 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (44113/44928)
Epoch: 217 | Batch_idx: 360 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (45376/46208)
Epoch: 217 | Batch_idx: 370 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (46638/47488)
Epoch: 217 | Batch_idx: 380 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (47896/48768)
Epoch: 217 | Batch_idx: 390 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (49110/50000)
# TEST : Loss: (0.4338) | Acc: (89.00%) (8924/10000)
percent tensor([0.5842, 0.5811, 0.5956, 0.5869, 0.6077, 0.5875, 0.5938, 0.5968, 0.5884,
        0.5833, 0.5808, 0.5926, 0.5829, 0.5743, 0.5851, 0.5805],
       device='cuda:0') torch.Size([16])
percent tensor([0.5425, 0.5417, 0.5332, 0.5394, 0.5346, 0.5455, 0.5393, 0.5336, 0.5401,
        0.5408, 0.5425, 0.5392, 0.5426, 0.5391, 0.5450, 0.5437],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5710, 0.5712, 0.5774, 0.6141, 0.6137, 0.5840, 0.5649, 0.5737,
        0.5640, 0.5592, 0.5904, 0.5767, 0.5640, 0.5860, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.6832, 0.6965, 0.6492, 0.6454, 0.6473, 0.6501, 0.6882, 0.6452, 0.6694,
        0.6879, 0.7060, 0.6709, 0.6923, 0.6851, 0.6897, 0.6746],
       device='cuda:0') torch.Size([16])
percent tensor([0.5782, 0.5953, 0.7176, 0.8069, 0.7373, 0.7476, 0.6183, 0.5734, 0.7710,
        0.6153, 0.7183, 0.7088, 0.6155, 0.8254, 0.5561, 0.6372],
       device='cuda:0') torch.Size([16])
percent tensor([0.7539, 0.7209, 0.7810, 0.7825, 0.7978, 0.7522, 0.7755, 0.7868, 0.7455,
        0.7138, 0.7069, 0.7635, 0.6866, 0.7486, 0.7628, 0.7562],
       device='cuda:0') torch.Size([16])
percent tensor([0.5909, 0.6670, 0.7519, 0.6471, 0.7312, 0.7786, 0.7125, 0.6656, 0.6526,
        0.6434, 0.6869, 0.5373, 0.5963, 0.4858, 0.6150, 0.5344],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 1.0000, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9996, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 218 | Batch_idx: 0 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 218 | Batch_idx: 10 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 218 | Batch_idx: 20 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 218 | Batch_idx: 30 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (3903/3968)
Epoch: 218 | Batch_idx: 40 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (5164/5248)
Epoch: 218 | Batch_idx: 50 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (6416/6528)
Epoch: 218 | Batch_idx: 60 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (7678/7808)
Epoch: 218 | Batch_idx: 70 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (8934/9088)
Epoch: 218 | Batch_idx: 80 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (10182/10368)
Epoch: 218 | Batch_idx: 90 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (11437/11648)
Epoch: 218 | Batch_idx: 100 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (12683/12928)
Epoch: 218 | Batch_idx: 110 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (13936/14208)
Epoch: 218 | Batch_idx: 120 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (15200/15488)
Epoch: 218 | Batch_idx: 130 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (16460/16768)
Epoch: 218 | Batch_idx: 140 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (17718/18048)
Epoch: 218 | Batch_idx: 150 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (18979/19328)
Epoch: 218 | Batch_idx: 160 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (20240/20608)
Epoch: 218 | Batch_idx: 170 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (21502/21888)
Epoch: 218 | Batch_idx: 180 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (22756/23168)
Epoch: 218 | Batch_idx: 190 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (24016/24448)
Epoch: 218 | Batch_idx: 200 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (25273/25728)
Epoch: 218 | Batch_idx: 210 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (26532/27008)
Epoch: 218 | Batch_idx: 220 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (27794/28288)
Epoch: 218 | Batch_idx: 230 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (29045/29568)
Epoch: 218 | Batch_idx: 240 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (30302/30848)
Epoch: 218 | Batch_idx: 250 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (31563/32128)
Epoch: 218 | Batch_idx: 260 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (32815/33408)
Epoch: 218 | Batch_idx: 270 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (34058/34688)
Epoch: 218 | Batch_idx: 280 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (35304/35968)
Epoch: 218 | Batch_idx: 290 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (36546/37248)
Epoch: 218 | Batch_idx: 300 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (37798/38528)
Epoch: 218 | Batch_idx: 310 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (39050/39808)
Epoch: 218 | Batch_idx: 320 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (40302/41088)
Epoch: 218 | Batch_idx: 330 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (41559/42368)
Epoch: 218 | Batch_idx: 340 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (42824/43648)
Epoch: 218 | Batch_idx: 350 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (44082/44928)
Epoch: 218 | Batch_idx: 360 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (45343/46208)
Epoch: 218 | Batch_idx: 370 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (46598/47488)
Epoch: 218 | Batch_idx: 380 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (47854/48768)
Epoch: 218 | Batch_idx: 390 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (49061/50000)
# TEST : Loss: (0.4475) | Acc: (88.00%) (8859/10000)
percent tensor([0.5870, 0.5858, 0.5932, 0.5874, 0.6071, 0.5884, 0.5967, 0.5989, 0.5934,
        0.5857, 0.5847, 0.5927, 0.5867, 0.5812, 0.5877, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.5434, 0.5304, 0.5386, 0.5326, 0.5438, 0.5395, 0.5327, 0.5393,
        0.5412, 0.5428, 0.5378, 0.5423, 0.5407, 0.5452, 0.5439],
       device='cuda:0') torch.Size([16])
percent tensor([0.5478, 0.5736, 0.5660, 0.5713, 0.6084, 0.6087, 0.5826, 0.5620, 0.5831,
        0.5661, 0.5645, 0.5897, 0.5786, 0.5635, 0.5850, 0.5688],
       device='cuda:0') torch.Size([16])
percent tensor([0.6875, 0.7006, 0.6561, 0.6517, 0.6525, 0.6554, 0.6943, 0.6487, 0.6722,
        0.6941, 0.7071, 0.6765, 0.6962, 0.6877, 0.6949, 0.6783],
       device='cuda:0') torch.Size([16])
percent tensor([0.5890, 0.5929, 0.7054, 0.8117, 0.7245, 0.7747, 0.6143, 0.5759, 0.7557,
        0.6057, 0.7186, 0.6993, 0.6088, 0.8091, 0.5614, 0.6436],
       device='cuda:0') torch.Size([16])
percent tensor([0.7546, 0.7098, 0.7788, 0.7788, 0.7984, 0.7570, 0.7691, 0.7834, 0.7461,
        0.7035, 0.7014, 0.7518, 0.6889, 0.7418, 0.7576, 0.7481],
       device='cuda:0') torch.Size([16])
percent tensor([0.5811, 0.6573, 0.7757, 0.6268, 0.7517, 0.7990, 0.7157, 0.6220, 0.6443,
        0.6644, 0.7018, 0.5084, 0.5657, 0.5103, 0.6086, 0.5314],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 1.0000, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9997, 0.9996, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 219 | Batch_idx: 0 |  Loss: (0.0312) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 219 | Batch_idx: 10 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 219 | Batch_idx: 20 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 219 | Batch_idx: 30 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (3912/3968)
Epoch: 219 | Batch_idx: 40 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 219 | Batch_idx: 50 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (6441/6528)
Epoch: 219 | Batch_idx: 60 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (7701/7808)
Epoch: 219 | Batch_idx: 70 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (8961/9088)
Epoch: 219 | Batch_idx: 80 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (10213/10368)
Epoch: 219 | Batch_idx: 90 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (11471/11648)
Epoch: 219 | Batch_idx: 100 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (12735/12928)
Epoch: 219 | Batch_idx: 110 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (13996/14208)
Epoch: 219 | Batch_idx: 120 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (15244/15488)
Epoch: 219 | Batch_idx: 130 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (16510/16768)
Epoch: 219 | Batch_idx: 140 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (17771/18048)
Epoch: 219 | Batch_idx: 150 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (19028/19328)
Epoch: 219 | Batch_idx: 160 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (20291/20608)
Epoch: 219 | Batch_idx: 170 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (21546/21888)
Epoch: 219 | Batch_idx: 180 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (22810/23168)
Epoch: 219 | Batch_idx: 190 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (24063/24448)
Epoch: 219 | Batch_idx: 200 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (25319/25728)
Epoch: 219 | Batch_idx: 210 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (26570/27008)
Epoch: 219 | Batch_idx: 220 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (27831/28288)
Epoch: 219 | Batch_idx: 230 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (29102/29568)
Epoch: 219 | Batch_idx: 240 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (30364/30848)
Epoch: 219 | Batch_idx: 250 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (31625/32128)
Epoch: 219 | Batch_idx: 260 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (32880/33408)
Epoch: 219 | Batch_idx: 270 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (34147/34688)
Epoch: 219 | Batch_idx: 280 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (35407/35968)
Epoch: 219 | Batch_idx: 290 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (36670/37248)
Epoch: 219 | Batch_idx: 300 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (37932/38528)
Epoch: 219 | Batch_idx: 310 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (39187/39808)
Epoch: 219 | Batch_idx: 320 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (40441/41088)
Epoch: 219 | Batch_idx: 330 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (41700/42368)
Epoch: 219 | Batch_idx: 340 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (42964/43648)
Epoch: 219 | Batch_idx: 350 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (44231/44928)
Epoch: 219 | Batch_idx: 360 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (45493/46208)
Epoch: 219 | Batch_idx: 370 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (46753/47488)
Epoch: 219 | Batch_idx: 380 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (48018/48768)
Epoch: 219 | Batch_idx: 390 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (49230/50000)
# TEST : Loss: (0.4266) | Acc: (88.00%) (8895/10000)
percent tensor([0.5851, 0.5829, 0.5922, 0.5871, 0.6058, 0.5879, 0.5941, 0.5973, 0.5890,
        0.5833, 0.5815, 0.5906, 0.5836, 0.5780, 0.5861, 0.5819],
       device='cuda:0') torch.Size([16])
percent tensor([0.5426, 0.5432, 0.5322, 0.5399, 0.5344, 0.5442, 0.5398, 0.5335, 0.5400,
        0.5414, 0.5428, 0.5389, 0.5430, 0.5404, 0.5458, 0.5442],
       device='cuda:0') torch.Size([16])
percent tensor([0.5483, 0.5745, 0.5713, 0.5771, 0.6168, 0.6114, 0.5847, 0.5633, 0.5786,
        0.5656, 0.5604, 0.5939, 0.5795, 0.5625, 0.5872, 0.5714],
       device='cuda:0') torch.Size([16])
percent tensor([0.6841, 0.6986, 0.6516, 0.6482, 0.6491, 0.6543, 0.6924, 0.6466, 0.6714,
        0.6888, 0.7042, 0.6721, 0.6908, 0.6876, 0.6934, 0.6765],
       device='cuda:0') torch.Size([16])
percent tensor([0.5917, 0.5931, 0.7220, 0.8279, 0.7324, 0.7718, 0.6149, 0.5963, 0.7553,
        0.5979, 0.7016, 0.7055, 0.6147, 0.8069, 0.5616, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.7623, 0.7259, 0.7802, 0.7820, 0.7966, 0.7616, 0.7753, 0.7909, 0.7533,
        0.7161, 0.7126, 0.7647, 0.6999, 0.7461, 0.7669, 0.7582],
       device='cuda:0') torch.Size([16])
percent tensor([0.5958, 0.6719, 0.7526, 0.6640, 0.7346, 0.7752, 0.7054, 0.6058, 0.6442,
        0.6592, 0.6802, 0.5322, 0.5844, 0.4870, 0.6101, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 1.0000, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9997, 0.9996, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 220 | Batch_idx: 0 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 220 | Batch_idx: 10 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 220 | Batch_idx: 20 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (2639/2688)
Epoch: 220 | Batch_idx: 30 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (3890/3968)
Epoch: 220 | Batch_idx: 40 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (5145/5248)
Epoch: 220 | Batch_idx: 50 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (6406/6528)
Epoch: 220 | Batch_idx: 60 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (7671/7808)
Epoch: 220 | Batch_idx: 70 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (8935/9088)
Epoch: 220 | Batch_idx: 80 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (10194/10368)
Epoch: 220 | Batch_idx: 90 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (11454/11648)
Epoch: 220 | Batch_idx: 100 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (12721/12928)
Epoch: 220 | Batch_idx: 110 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (13977/14208)
Epoch: 220 | Batch_idx: 120 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (15242/15488)
Epoch: 220 | Batch_idx: 130 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (16501/16768)
Epoch: 220 | Batch_idx: 140 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (17758/18048)
Epoch: 220 | Batch_idx: 150 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (19020/19328)
Epoch: 220 | Batch_idx: 160 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (20279/20608)
Epoch: 220 | Batch_idx: 170 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (21530/21888)
Epoch: 220 | Batch_idx: 180 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (22781/23168)
Epoch: 220 | Batch_idx: 190 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (24042/24448)
Epoch: 220 | Batch_idx: 200 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (25298/25728)
Epoch: 220 | Batch_idx: 210 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (26550/27008)
Epoch: 220 | Batch_idx: 220 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (27804/28288)
Epoch: 220 | Batch_idx: 230 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (29057/29568)
Epoch: 220 | Batch_idx: 240 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (30314/30848)
Epoch: 220 | Batch_idx: 250 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (31569/32128)
Epoch: 220 | Batch_idx: 260 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (32837/33408)
Epoch: 220 | Batch_idx: 270 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (34087/34688)
Epoch: 220 | Batch_idx: 280 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (35348/35968)
Epoch: 220 | Batch_idx: 290 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (36608/37248)
Epoch: 220 | Batch_idx: 300 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (37865/38528)
Epoch: 220 | Batch_idx: 310 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (39125/39808)
Epoch: 220 | Batch_idx: 320 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (40384/41088)
Epoch: 220 | Batch_idx: 330 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (41642/42368)
Epoch: 220 | Batch_idx: 340 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (42893/43648)
Epoch: 220 | Batch_idx: 350 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (44154/44928)
Epoch: 220 | Batch_idx: 360 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (45414/46208)
Epoch: 220 | Batch_idx: 370 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (46678/47488)
Epoch: 220 | Batch_idx: 380 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (47936/48768)
Epoch: 220 | Batch_idx: 390 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (49146/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_220.pth.tar'
# TEST : Loss: (0.4388) | Acc: (88.00%) (8859/10000)
percent tensor([0.5867, 0.5847, 0.5966, 0.5881, 0.6086, 0.5886, 0.5966, 0.5999, 0.5912,
        0.5859, 0.5834, 0.5940, 0.5855, 0.5794, 0.5872, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.5428, 0.5431, 0.5325, 0.5397, 0.5342, 0.5443, 0.5401, 0.5334, 0.5402,
        0.5414, 0.5430, 0.5383, 0.5431, 0.5407, 0.5458, 0.5440],
       device='cuda:0') torch.Size([16])
percent tensor([0.5483, 0.5760, 0.5745, 0.5685, 0.6120, 0.6033, 0.5868, 0.5632, 0.5773,
        0.5684, 0.5636, 0.5942, 0.5829, 0.5591, 0.5812, 0.5663],
       device='cuda:0') torch.Size([16])
percent tensor([0.6831, 0.6987, 0.6494, 0.6484, 0.6480, 0.6534, 0.6902, 0.6472, 0.6708,
        0.6892, 0.7066, 0.6733, 0.6919, 0.6893, 0.6927, 0.6765],
       device='cuda:0') torch.Size([16])
percent tensor([0.5762, 0.5939, 0.7058, 0.8136, 0.7164, 0.7510, 0.6136, 0.5766, 0.7368,
        0.6008, 0.6885, 0.6773, 0.6006, 0.8064, 0.5526, 0.6331],
       device='cuda:0') torch.Size([16])
percent tensor([0.7586, 0.7231, 0.7786, 0.7729, 0.7877, 0.7559, 0.7727, 0.7863, 0.7516,
        0.7133, 0.7095, 0.7546, 0.6939, 0.7410, 0.7596, 0.7498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5416, 0.6465, 0.7524, 0.6513, 0.7252, 0.7371, 0.6706, 0.6098, 0.6349,
        0.6585, 0.6856, 0.5446, 0.5632, 0.4587, 0.5793, 0.5001],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9997, 0.9997, 1.0000, 1.0000, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(186.2055, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(841.5656, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(849.1439, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1508.1913, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(476.6874, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2303.8887, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4275.8169, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1328.4821, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6324.3564, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11450.3555, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3750.2756, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15865.7246, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 221 | Batch_idx: 0 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 221 | Batch_idx: 10 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 221 | Batch_idx: 20 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 221 | Batch_idx: 30 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (3910/3968)
Epoch: 221 | Batch_idx: 40 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (5176/5248)
Epoch: 221 | Batch_idx: 50 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (6435/6528)
Epoch: 221 | Batch_idx: 60 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (7701/7808)
Epoch: 221 | Batch_idx: 70 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (8967/9088)
Epoch: 221 | Batch_idx: 80 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (10231/10368)
Epoch: 221 | Batch_idx: 90 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (11490/11648)
Epoch: 221 | Batch_idx: 100 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (12751/12928)
Epoch: 221 | Batch_idx: 110 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (14010/14208)
Epoch: 221 | Batch_idx: 120 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (15271/15488)
Epoch: 221 | Batch_idx: 130 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (16532/16768)
Epoch: 221 | Batch_idx: 140 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (17792/18048)
Epoch: 221 | Batch_idx: 150 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (19055/19328)
Epoch: 221 | Batch_idx: 160 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (20311/20608)
Epoch: 221 | Batch_idx: 170 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (21569/21888)
Epoch: 221 | Batch_idx: 180 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (22816/23168)
Epoch: 221 | Batch_idx: 190 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (24074/24448)
Epoch: 221 | Batch_idx: 200 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (25335/25728)
Epoch: 221 | Batch_idx: 210 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (26591/27008)
Epoch: 221 | Batch_idx: 220 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (27848/28288)
Epoch: 221 | Batch_idx: 230 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (29108/29568)
Epoch: 221 | Batch_idx: 240 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (30365/30848)
Epoch: 221 | Batch_idx: 250 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (31621/32128)
Epoch: 221 | Batch_idx: 260 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (32877/33408)
Epoch: 221 | Batch_idx: 270 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (34140/34688)
Epoch: 221 | Batch_idx: 280 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (35400/35968)
Epoch: 221 | Batch_idx: 290 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (36655/37248)
Epoch: 221 | Batch_idx: 300 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (37914/38528)
Epoch: 221 | Batch_idx: 310 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (39168/39808)
Epoch: 221 | Batch_idx: 320 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (40431/41088)
Epoch: 221 | Batch_idx: 330 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (41690/42368)
Epoch: 221 | Batch_idx: 340 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (42956/43648)
Epoch: 221 | Batch_idx: 350 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (44211/44928)
Epoch: 221 | Batch_idx: 360 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (45473/46208)
Epoch: 221 | Batch_idx: 370 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (46731/47488)
Epoch: 221 | Batch_idx: 380 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (47986/48768)
Epoch: 221 | Batch_idx: 390 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (49194/50000)
# TEST : Loss: (0.4265) | Acc: (89.00%) (8907/10000)
percent tensor([0.5869, 0.5840, 0.5986, 0.5889, 0.6099, 0.5895, 0.5972, 0.5998, 0.5903,
        0.5858, 0.5825, 0.5954, 0.5846, 0.5771, 0.5873, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.5427, 0.5439, 0.5330, 0.5396, 0.5344, 0.5445, 0.5406, 0.5339, 0.5407,
        0.5420, 0.5434, 0.5392, 0.5431, 0.5403, 0.5459, 0.5440],
       device='cuda:0') torch.Size([16])
percent tensor([0.5496, 0.5751, 0.5724, 0.5742, 0.6142, 0.6112, 0.5848, 0.5603, 0.5783,
        0.5652, 0.5643, 0.5914, 0.5821, 0.5600, 0.5871, 0.5698],
       device='cuda:0') torch.Size([16])
percent tensor([0.6827, 0.6996, 0.6489, 0.6450, 0.6474, 0.6529, 0.6925, 0.6478, 0.6715,
        0.6896, 0.7066, 0.6699, 0.6902, 0.6893, 0.6945, 0.6749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5823, 0.6020, 0.7336, 0.8275, 0.7290, 0.7538, 0.6202, 0.5815, 0.7598,
        0.6194, 0.7205, 0.7214, 0.6212, 0.8293, 0.5557, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.7615, 0.7252, 0.7849, 0.7712, 0.7992, 0.7579, 0.7788, 0.7910, 0.7542,
        0.7203, 0.7126, 0.7647, 0.7006, 0.7517, 0.7630, 0.7567],
       device='cuda:0') torch.Size([16])
percent tensor([0.5257, 0.6256, 0.7377, 0.6323, 0.7058, 0.7448, 0.6786, 0.6244, 0.5987,
        0.6390, 0.6321, 0.5537, 0.5811, 0.4821, 0.5722, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 1.0000, 0.9999, 1.0000,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 222 | Batch_idx: 0 |  Loss: (0.0297) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 222 | Batch_idx: 10 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 222 | Batch_idx: 20 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (2655/2688)
Epoch: 222 | Batch_idx: 30 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 222 | Batch_idx: 40 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (5178/5248)
Epoch: 222 | Batch_idx: 50 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (6444/6528)
Epoch: 222 | Batch_idx: 60 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (7704/7808)
Epoch: 222 | Batch_idx: 70 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (8970/9088)
Epoch: 222 | Batch_idx: 80 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (10221/10368)
Epoch: 222 | Batch_idx: 90 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (11483/11648)
Epoch: 222 | Batch_idx: 100 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (12749/12928)
Epoch: 222 | Batch_idx: 110 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (14010/14208)
Epoch: 222 | Batch_idx: 120 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (15270/15488)
Epoch: 222 | Batch_idx: 130 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (16536/16768)
Epoch: 222 | Batch_idx: 140 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (17799/18048)
Epoch: 222 | Batch_idx: 150 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (19056/19328)
Epoch: 222 | Batch_idx: 160 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (20313/20608)
Epoch: 222 | Batch_idx: 170 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (21579/21888)
Epoch: 222 | Batch_idx: 180 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (22829/23168)
Epoch: 222 | Batch_idx: 190 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (24092/24448)
Epoch: 222 | Batch_idx: 200 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (25357/25728)
Epoch: 222 | Batch_idx: 210 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (26622/27008)
Epoch: 222 | Batch_idx: 220 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (27877/28288)
Epoch: 222 | Batch_idx: 230 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (29141/29568)
Epoch: 222 | Batch_idx: 240 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (30409/30848)
Epoch: 222 | Batch_idx: 250 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (31663/32128)
Epoch: 222 | Batch_idx: 260 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (32920/33408)
Epoch: 222 | Batch_idx: 270 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (34178/34688)
Epoch: 222 | Batch_idx: 280 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (35430/35968)
Epoch: 222 | Batch_idx: 290 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (36694/37248)
Epoch: 222 | Batch_idx: 300 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (37958/38528)
Epoch: 222 | Batch_idx: 310 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (39223/39808)
Epoch: 222 | Batch_idx: 320 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (40491/41088)
Epoch: 222 | Batch_idx: 330 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (41747/42368)
Epoch: 222 | Batch_idx: 340 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (43008/43648)
Epoch: 222 | Batch_idx: 350 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (44264/44928)
Epoch: 222 | Batch_idx: 360 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (45525/46208)
Epoch: 222 | Batch_idx: 370 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (46782/47488)
Epoch: 222 | Batch_idx: 380 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (48035/48768)
Epoch: 222 | Batch_idx: 390 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (49242/50000)
# TEST : Loss: (0.4584) | Acc: (88.00%) (8853/10000)
percent tensor([0.5874, 0.5853, 0.5962, 0.5892, 0.6093, 0.5897, 0.5971, 0.6007, 0.5907,
        0.5863, 0.5832, 0.5941, 0.5859, 0.5783, 0.5884, 0.5840],
       device='cuda:0') torch.Size([16])
percent tensor([0.5434, 0.5446, 0.5329, 0.5410, 0.5351, 0.5458, 0.5408, 0.5340, 0.5409,
        0.5425, 0.5435, 0.5395, 0.5437, 0.5412, 0.5468, 0.5449],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5789, 0.5742, 0.5754, 0.6137, 0.6098, 0.5846, 0.5635, 0.5774,
        0.5690, 0.5623, 0.5942, 0.5826, 0.5586, 0.5898, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.6868, 0.7026, 0.6557, 0.6543, 0.6519, 0.6561, 0.6958, 0.6501, 0.6732,
        0.6940, 0.7111, 0.6780, 0.6964, 0.6952, 0.6990, 0.6793],
       device='cuda:0') torch.Size([16])
percent tensor([0.5778, 0.5927, 0.7190, 0.8246, 0.7228, 0.7336, 0.6114, 0.5787, 0.7520,
        0.6078, 0.7078, 0.7085, 0.6010, 0.8128, 0.5474, 0.6261],
       device='cuda:0') torch.Size([16])
percent tensor([0.7603, 0.7179, 0.7771, 0.7799, 0.7960, 0.7621, 0.7773, 0.7929, 0.7485,
        0.7076, 0.7066, 0.7547, 0.6929, 0.7418, 0.7627, 0.7576],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.6599, 0.7379, 0.6477, 0.6911, 0.7487, 0.6967, 0.6122, 0.6583,
        0.6634, 0.6667, 0.5299, 0.5865, 0.5056, 0.5722, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 1.0000, 0.9998, 0.9997, 1.0000, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9997, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 223 | Batch_idx: 0 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 223 | Batch_idx: 10 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 223 | Batch_idx: 20 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (2642/2688)
Epoch: 223 | Batch_idx: 30 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (3899/3968)
Epoch: 223 | Batch_idx: 40 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (5158/5248)
Epoch: 223 | Batch_idx: 50 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (6414/6528)
Epoch: 223 | Batch_idx: 60 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (7670/7808)
Epoch: 223 | Batch_idx: 70 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (8938/9088)
Epoch: 223 | Batch_idx: 80 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (10196/10368)
Epoch: 223 | Batch_idx: 90 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (11464/11648)
Epoch: 223 | Batch_idx: 100 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (12718/12928)
Epoch: 223 | Batch_idx: 110 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (13980/14208)
Epoch: 223 | Batch_idx: 120 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (15242/15488)
Epoch: 223 | Batch_idx: 130 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (16506/16768)
Epoch: 223 | Batch_idx: 140 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (17762/18048)
Epoch: 223 | Batch_idx: 150 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (19028/19328)
Epoch: 223 | Batch_idx: 160 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (20295/20608)
Epoch: 223 | Batch_idx: 170 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (21556/21888)
Epoch: 223 | Batch_idx: 180 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (22815/23168)
Epoch: 223 | Batch_idx: 190 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (24085/24448)
Epoch: 223 | Batch_idx: 200 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (25349/25728)
Epoch: 223 | Batch_idx: 210 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (26618/27008)
Epoch: 223 | Batch_idx: 220 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (27883/28288)
Epoch: 223 | Batch_idx: 230 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (29141/29568)
Epoch: 223 | Batch_idx: 240 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (30405/30848)
Epoch: 223 | Batch_idx: 250 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (31673/32128)
Epoch: 223 | Batch_idx: 260 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (32938/33408)
Epoch: 223 | Batch_idx: 270 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (34203/34688)
Epoch: 223 | Batch_idx: 280 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (35469/35968)
Epoch: 223 | Batch_idx: 290 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (36727/37248)
Epoch: 223 | Batch_idx: 300 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (37988/38528)
Epoch: 223 | Batch_idx: 310 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (39251/39808)
Epoch: 223 | Batch_idx: 320 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (40518/41088)
Epoch: 223 | Batch_idx: 330 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (41781/42368)
Epoch: 223 | Batch_idx: 340 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (43046/43648)
Epoch: 223 | Batch_idx: 350 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (44313/44928)
Epoch: 223 | Batch_idx: 360 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (45574/46208)
Epoch: 223 | Batch_idx: 370 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (46835/47488)
Epoch: 223 | Batch_idx: 380 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (48098/48768)
Epoch: 223 | Batch_idx: 390 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (49315/50000)
# TEST : Loss: (0.4515) | Acc: (88.00%) (8880/10000)
percent tensor([0.5889, 0.5866, 0.5995, 0.5898, 0.6120, 0.5900, 0.5990, 0.6025, 0.5931,
        0.5881, 0.5849, 0.5965, 0.5875, 0.5789, 0.5893, 0.5851],
       device='cuda:0') torch.Size([16])
percent tensor([0.5438, 0.5443, 0.5336, 0.5405, 0.5348, 0.5461, 0.5407, 0.5342, 0.5415,
        0.5428, 0.5441, 0.5398, 0.5444, 0.5411, 0.5472, 0.5454],
       device='cuda:0') torch.Size([16])
percent tensor([0.5562, 0.5804, 0.5806, 0.5777, 0.6178, 0.6143, 0.5887, 0.5673, 0.5807,
        0.5751, 0.5663, 0.6009, 0.5863, 0.5598, 0.5942, 0.5751],
       device='cuda:0') torch.Size([16])
percent tensor([0.6863, 0.7007, 0.6568, 0.6557, 0.6521, 0.6587, 0.6960, 0.6515, 0.6742,
        0.6927, 0.7103, 0.6764, 0.6927, 0.6898, 0.6967, 0.6802],
       device='cuda:0') torch.Size([16])
percent tensor([0.5747, 0.5831, 0.7173, 0.8283, 0.7199, 0.7381, 0.6127, 0.5825, 0.7490,
        0.5908, 0.6820, 0.7024, 0.5968, 0.8092, 0.5510, 0.6234],
       device='cuda:0') torch.Size([16])
percent tensor([0.7657, 0.7257, 0.7911, 0.7839, 0.8039, 0.7653, 0.7817, 0.7958, 0.7537,
        0.7207, 0.7114, 0.7673, 0.6998, 0.7494, 0.7648, 0.7621],
       device='cuda:0') torch.Size([16])
percent tensor([0.5658, 0.6779, 0.7294, 0.5898, 0.7012, 0.7579, 0.6992, 0.5801, 0.6590,
        0.6566, 0.6901, 0.5284, 0.6358, 0.5405, 0.5943, 0.4811],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 1.0000, 0.9998, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9998, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 224 | Batch_idx: 0 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 224 | Batch_idx: 10 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 224 | Batch_idx: 20 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (97.00%) (2631/2688)
Epoch: 224 | Batch_idx: 30 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (3891/3968)
Epoch: 224 | Batch_idx: 40 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (5150/5248)
Epoch: 224 | Batch_idx: 50 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (6417/6528)
Epoch: 224 | Batch_idx: 60 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (7681/7808)
Epoch: 224 | Batch_idx: 70 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (8939/9088)
Epoch: 224 | Batch_idx: 80 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (10208/10368)
Epoch: 224 | Batch_idx: 90 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (11469/11648)
Epoch: 224 | Batch_idx: 100 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (12730/12928)
Epoch: 224 | Batch_idx: 110 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (13985/14208)
Epoch: 224 | Batch_idx: 120 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (15245/15488)
Epoch: 224 | Batch_idx: 130 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (16507/16768)
Epoch: 224 | Batch_idx: 140 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (17776/18048)
Epoch: 224 | Batch_idx: 150 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (19032/19328)
Epoch: 224 | Batch_idx: 160 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (20293/20608)
Epoch: 224 | Batch_idx: 170 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (21555/21888)
Epoch: 224 | Batch_idx: 180 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (22824/23168)
Epoch: 224 | Batch_idx: 190 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (24085/24448)
Epoch: 224 | Batch_idx: 200 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (25351/25728)
Epoch: 224 | Batch_idx: 210 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (26614/27008)
Epoch: 224 | Batch_idx: 220 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (27878/28288)
Epoch: 224 | Batch_idx: 230 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (29135/29568)
Epoch: 224 | Batch_idx: 240 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (30397/30848)
Epoch: 224 | Batch_idx: 250 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (31653/32128)
Epoch: 224 | Batch_idx: 260 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (32908/33408)
Epoch: 224 | Batch_idx: 270 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (34163/34688)
Epoch: 224 | Batch_idx: 280 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (35425/35968)
Epoch: 224 | Batch_idx: 290 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (36684/37248)
Epoch: 224 | Batch_idx: 300 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (37941/38528)
Epoch: 224 | Batch_idx: 310 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (39201/39808)
Epoch: 224 | Batch_idx: 320 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (40463/41088)
Epoch: 224 | Batch_idx: 330 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (41726/42368)
Epoch: 224 | Batch_idx: 340 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (42983/43648)
Epoch: 224 | Batch_idx: 350 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (44242/44928)
Epoch: 224 | Batch_idx: 360 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (45513/46208)
Epoch: 224 | Batch_idx: 370 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (46775/47488)
Epoch: 224 | Batch_idx: 380 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (48030/48768)
Epoch: 224 | Batch_idx: 390 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (49241/50000)
# TEST : Loss: (0.4480) | Acc: (88.00%) (8893/10000)
percent tensor([0.5878, 0.5860, 0.5955, 0.5888, 0.6085, 0.5899, 0.5971, 0.5999, 0.5901,
        0.5864, 0.5834, 0.5934, 0.5859, 0.5782, 0.5886, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.5442, 0.5445, 0.5322, 0.5410, 0.5345, 0.5461, 0.5409, 0.5348, 0.5422,
        0.5430, 0.5449, 0.5398, 0.5447, 0.5425, 0.5476, 0.5455],
       device='cuda:0') torch.Size([16])
percent tensor([0.5516, 0.5812, 0.5677, 0.5725, 0.6119, 0.6172, 0.5883, 0.5589, 0.5793,
        0.5703, 0.5661, 0.5920, 0.5827, 0.5651, 0.5941, 0.5711],
       device='cuda:0') torch.Size([16])
percent tensor([0.6875, 0.7008, 0.6568, 0.6524, 0.6521, 0.6577, 0.6953, 0.6528, 0.6782,
        0.6940, 0.7122, 0.6795, 0.6976, 0.6949, 0.6966, 0.6811],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5990, 0.7176, 0.8335, 0.7252, 0.7433, 0.6157, 0.5959, 0.7746,
        0.6100, 0.7126, 0.6962, 0.6222, 0.8180, 0.5584, 0.6418],
       device='cuda:0') torch.Size([16])
percent tensor([0.7686, 0.7313, 0.7924, 0.7892, 0.8083, 0.7672, 0.7809, 0.7991, 0.7615,
        0.7221, 0.7150, 0.7660, 0.7049, 0.7486, 0.7718, 0.7672],
       device='cuda:0') torch.Size([16])
percent tensor([0.5858, 0.6486, 0.7315, 0.6310, 0.7123, 0.7611, 0.6747, 0.5810, 0.6662,
        0.6644, 0.6961, 0.5069, 0.6041, 0.4807, 0.5911, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 1.0000, 0.9999, 0.9999, 0.9995, 0.9999, 0.9999, 1.0000,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 225 | Batch_idx: 0 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 225 | Batch_idx: 10 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 225 | Batch_idx: 20 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 225 | Batch_idx: 30 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (3912/3968)
Epoch: 225 | Batch_idx: 40 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (5169/5248)
Epoch: 225 | Batch_idx: 50 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (6419/6528)
Epoch: 225 | Batch_idx: 60 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (7670/7808)
Epoch: 225 | Batch_idx: 70 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (8928/9088)
Epoch: 225 | Batch_idx: 80 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (10188/10368)
Epoch: 225 | Batch_idx: 90 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (11449/11648)
Epoch: 225 | Batch_idx: 100 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (12710/12928)
Epoch: 225 | Batch_idx: 110 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (13975/14208)
Epoch: 225 | Batch_idx: 120 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (15242/15488)
Epoch: 225 | Batch_idx: 130 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (16507/16768)
Epoch: 225 | Batch_idx: 140 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (17763/18048)
Epoch: 225 | Batch_idx: 150 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (19029/19328)
Epoch: 225 | Batch_idx: 160 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (20286/20608)
Epoch: 225 | Batch_idx: 170 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (21553/21888)
Epoch: 225 | Batch_idx: 180 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (22819/23168)
Epoch: 225 | Batch_idx: 190 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (24081/24448)
Epoch: 225 | Batch_idx: 200 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (25347/25728)
Epoch: 225 | Batch_idx: 210 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (26612/27008)
Epoch: 225 | Batch_idx: 220 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (27875/28288)
Epoch: 225 | Batch_idx: 230 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (29137/29568)
Epoch: 225 | Batch_idx: 240 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (30398/30848)
Epoch: 225 | Batch_idx: 250 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (31650/32128)
Epoch: 225 | Batch_idx: 260 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (32911/33408)
Epoch: 225 | Batch_idx: 270 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (34172/34688)
Epoch: 225 | Batch_idx: 280 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (35442/35968)
Epoch: 225 | Batch_idx: 290 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (36705/37248)
Epoch: 225 | Batch_idx: 300 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (37964/38528)
Epoch: 225 | Batch_idx: 310 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (39225/39808)
Epoch: 225 | Batch_idx: 320 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (40485/41088)
Epoch: 225 | Batch_idx: 330 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (41749/42368)
Epoch: 225 | Batch_idx: 340 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (43010/43648)
Epoch: 225 | Batch_idx: 350 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (44270/44928)
Epoch: 225 | Batch_idx: 360 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (45524/46208)
Epoch: 225 | Batch_idx: 370 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (46789/47488)
Epoch: 225 | Batch_idx: 380 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (48051/48768)
Epoch: 225 | Batch_idx: 390 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (49266/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_225.pth.tar'
# TEST : Loss: (0.4477) | Acc: (88.00%) (8859/10000)
percent tensor([0.5889, 0.5891, 0.5984, 0.5912, 0.6124, 0.5908, 0.6009, 0.6027, 0.5955,
        0.5899, 0.5871, 0.5967, 0.5886, 0.5833, 0.5904, 0.5866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5423, 0.5446, 0.5316, 0.5400, 0.5336, 0.5436, 0.5404, 0.5337, 0.5419,
        0.5421, 0.5441, 0.5381, 0.5438, 0.5425, 0.5462, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.5509, 0.5764, 0.5775, 0.5773, 0.6122, 0.6040, 0.5847, 0.5664, 0.5823,
        0.5724, 0.5641, 0.5975, 0.5836, 0.5615, 0.5875, 0.5690],
       device='cuda:0') torch.Size([16])
percent tensor([0.6844, 0.6990, 0.6543, 0.6500, 0.6476, 0.6566, 0.6932, 0.6500, 0.6714,
        0.6913, 0.7096, 0.6726, 0.6935, 0.6897, 0.6933, 0.6780],
       device='cuda:0') torch.Size([16])
percent tensor([0.5853, 0.5971, 0.7290, 0.8240, 0.7386, 0.7526, 0.6304, 0.5975, 0.7862,
        0.6090, 0.7255, 0.7263, 0.6220, 0.8258, 0.5568, 0.6394],
       device='cuda:0') torch.Size([16])
percent tensor([0.7602, 0.7188, 0.7928, 0.7878, 0.8064, 0.7603, 0.7781, 0.7966, 0.7500,
        0.7114, 0.7150, 0.7723, 0.6958, 0.7431, 0.7662, 0.7621],
       device='cuda:0') torch.Size([16])
percent tensor([0.5951, 0.6786, 0.7482, 0.6818, 0.7343, 0.7758, 0.6894, 0.6152, 0.6323,
        0.6888, 0.7059, 0.5138, 0.6095, 0.5487, 0.6067, 0.5429],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9996, 0.9999, 0.9998, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9998, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 226 | Batch_idx: 0 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 226 | Batch_idx: 10 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 226 | Batch_idx: 20 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 226 | Batch_idx: 30 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (3914/3968)
Epoch: 226 | Batch_idx: 40 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (5181/5248)
Epoch: 226 | Batch_idx: 50 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (6448/6528)
Epoch: 226 | Batch_idx: 60 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (7711/7808)
Epoch: 226 | Batch_idx: 70 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (8968/9088)
Epoch: 226 | Batch_idx: 80 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (10229/10368)
Epoch: 226 | Batch_idx: 90 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (11488/11648)
Epoch: 226 | Batch_idx: 100 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (12751/12928)
Epoch: 226 | Batch_idx: 110 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (14013/14208)
Epoch: 226 | Batch_idx: 120 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (15271/15488)
Epoch: 226 | Batch_idx: 130 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (16539/16768)
Epoch: 226 | Batch_idx: 140 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (17809/18048)
Epoch: 226 | Batch_idx: 150 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (19072/19328)
Epoch: 226 | Batch_idx: 160 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (20328/20608)
Epoch: 226 | Batch_idx: 170 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (21594/21888)
Epoch: 226 | Batch_idx: 180 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (22865/23168)
Epoch: 226 | Batch_idx: 190 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (24130/24448)
Epoch: 226 | Batch_idx: 200 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (25393/25728)
Epoch: 226 | Batch_idx: 210 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (26646/27008)
Epoch: 226 | Batch_idx: 220 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (27909/28288)
Epoch: 226 | Batch_idx: 230 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (29169/29568)
Epoch: 226 | Batch_idx: 240 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (30417/30848)
Epoch: 226 | Batch_idx: 250 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (31679/32128)
Epoch: 226 | Batch_idx: 260 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (32938/33408)
Epoch: 226 | Batch_idx: 270 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (34204/34688)
Epoch: 226 | Batch_idx: 280 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (35465/35968)
Epoch: 226 | Batch_idx: 290 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (36725/37248)
Epoch: 226 | Batch_idx: 300 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (37982/38528)
Epoch: 226 | Batch_idx: 310 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (39231/39808)
Epoch: 226 | Batch_idx: 320 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (40487/41088)
Epoch: 226 | Batch_idx: 330 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (41750/42368)
Epoch: 226 | Batch_idx: 340 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (43015/43648)
Epoch: 226 | Batch_idx: 350 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (44273/44928)
Epoch: 226 | Batch_idx: 360 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (45531/46208)
Epoch: 226 | Batch_idx: 370 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (46792/47488)
Epoch: 226 | Batch_idx: 380 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (48046/48768)
Epoch: 226 | Batch_idx: 390 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (49263/50000)
# TEST : Loss: (0.4623) | Acc: (88.00%) (8866/10000)
percent tensor([0.5890, 0.5867, 0.6005, 0.5910, 0.6126, 0.5905, 0.5999, 0.6033, 0.5946,
        0.5885, 0.5855, 0.5973, 0.5879, 0.5810, 0.5895, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.5429, 0.5436, 0.5338, 0.5402, 0.5349, 0.5442, 0.5406, 0.5356, 0.5416,
        0.5427, 0.5437, 0.5396, 0.5438, 0.5414, 0.5460, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.5512, 0.5758, 0.5782, 0.5792, 0.6103, 0.6090, 0.5846, 0.5667, 0.5778,
        0.5697, 0.5636, 0.5992, 0.5845, 0.5626, 0.5873, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.6884, 0.7027, 0.6540, 0.6497, 0.6525, 0.6588, 0.6935, 0.6521, 0.6740,
        0.6942, 0.7120, 0.6755, 0.6988, 0.6919, 0.6970, 0.6809],
       device='cuda:0') torch.Size([16])
percent tensor([0.5833, 0.5965, 0.7422, 0.8371, 0.7496, 0.7486, 0.6297, 0.5950, 0.7745,
        0.6103, 0.7175, 0.7304, 0.6163, 0.8234, 0.5615, 0.6356],
       device='cuda:0') torch.Size([16])
percent tensor([0.7658, 0.7237, 0.7843, 0.7802, 0.8022, 0.7637, 0.7803, 0.7963, 0.7474,
        0.7108, 0.7200, 0.7619, 0.6932, 0.7552, 0.7657, 0.7674],
       device='cuda:0') torch.Size([16])
percent tensor([0.5866, 0.6702, 0.7330, 0.6486, 0.7079, 0.7477, 0.6974, 0.6076, 0.6313,
        0.6470, 0.7112, 0.4961, 0.5564, 0.5141, 0.6037, 0.5180],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9997, 0.9997, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 227 | Batch_idx: 0 |  Loss: (0.0230) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 227 | Batch_idx: 10 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 227 | Batch_idx: 20 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 227 | Batch_idx: 30 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (3918/3968)
Epoch: 227 | Batch_idx: 40 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (5182/5248)
Epoch: 227 | Batch_idx: 50 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (6443/6528)
Epoch: 227 | Batch_idx: 60 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (7705/7808)
Epoch: 227 | Batch_idx: 70 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (8965/9088)
Epoch: 227 | Batch_idx: 80 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (10229/10368)
Epoch: 227 | Batch_idx: 90 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (11490/11648)
Epoch: 227 | Batch_idx: 100 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (12759/12928)
Epoch: 227 | Batch_idx: 110 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (14018/14208)
Epoch: 227 | Batch_idx: 120 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (15284/15488)
Epoch: 227 | Batch_idx: 130 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (16542/16768)
Epoch: 227 | Batch_idx: 140 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (17812/18048)
Epoch: 227 | Batch_idx: 150 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (19066/19328)
Epoch: 227 | Batch_idx: 160 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (20327/20608)
Epoch: 227 | Batch_idx: 170 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (21592/21888)
Epoch: 227 | Batch_idx: 180 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (22842/23168)
Epoch: 227 | Batch_idx: 190 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (24091/24448)
Epoch: 227 | Batch_idx: 200 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (25351/25728)
Epoch: 227 | Batch_idx: 210 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (26613/27008)
Epoch: 227 | Batch_idx: 220 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (27870/28288)
Epoch: 227 | Batch_idx: 230 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (29124/29568)
Epoch: 227 | Batch_idx: 240 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (30388/30848)
Epoch: 227 | Batch_idx: 250 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (31641/32128)
Epoch: 227 | Batch_idx: 260 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (32902/33408)
Epoch: 227 | Batch_idx: 270 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (34164/34688)
Epoch: 227 | Batch_idx: 280 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (35419/35968)
Epoch: 227 | Batch_idx: 290 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (36676/37248)
Epoch: 227 | Batch_idx: 300 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (37942/38528)
Epoch: 227 | Batch_idx: 310 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (39209/39808)
Epoch: 227 | Batch_idx: 320 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (40467/41088)
Epoch: 227 | Batch_idx: 330 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (41721/42368)
Epoch: 227 | Batch_idx: 340 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (42983/43648)
Epoch: 227 | Batch_idx: 350 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (44248/44928)
Epoch: 227 | Batch_idx: 360 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (45513/46208)
Epoch: 227 | Batch_idx: 370 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (46770/47488)
Epoch: 227 | Batch_idx: 380 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (48029/48768)
Epoch: 227 | Batch_idx: 390 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (49244/50000)
# TEST : Loss: (0.4523) | Acc: (88.00%) (8875/10000)
percent tensor([0.5915, 0.5883, 0.5987, 0.5913, 0.6122, 0.5929, 0.6008, 0.6030, 0.5945,
        0.5891, 0.5866, 0.5970, 0.5896, 0.5811, 0.5916, 0.5863],
       device='cuda:0') torch.Size([16])
percent tensor([0.5429, 0.5441, 0.5321, 0.5409, 0.5346, 0.5448, 0.5407, 0.5342, 0.5414,
        0.5429, 0.5440, 0.5395, 0.5436, 0.5416, 0.5464, 0.5446],
       device='cuda:0') torch.Size([16])
percent tensor([0.5538, 0.5835, 0.5712, 0.5826, 0.6164, 0.6148, 0.5931, 0.5646, 0.5842,
        0.5741, 0.5687, 0.6011, 0.5891, 0.5658, 0.5950, 0.5738],
       device='cuda:0') torch.Size([16])
percent tensor([0.6898, 0.7077, 0.6597, 0.6546, 0.6544, 0.6614, 0.7002, 0.6549, 0.6788,
        0.6989, 0.7144, 0.6807, 0.7009, 0.7001, 0.6995, 0.6847],
       device='cuda:0') torch.Size([16])
percent tensor([0.5807, 0.5944, 0.7387, 0.8320, 0.7404, 0.7589, 0.6132, 0.5822, 0.7508,
        0.6110, 0.6915, 0.7297, 0.6109, 0.7980, 0.5664, 0.6289],
       device='cuda:0') torch.Size([16])
percent tensor([0.7626, 0.7290, 0.7839, 0.7800, 0.8007, 0.7570, 0.7766, 0.7879, 0.7566,
        0.7197, 0.7227, 0.7647, 0.7046, 0.7536, 0.7659, 0.7592],
       device='cuda:0') torch.Size([16])
percent tensor([0.5565, 0.6576, 0.7012, 0.6628, 0.6971, 0.7391, 0.6663, 0.6268, 0.6839,
        0.6272, 0.6848, 0.5019, 0.5981, 0.5137, 0.5998, 0.4866],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9999, 0.9996, 0.9999, 0.9999, 1.0000,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9995, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 228 | Batch_idx: 0 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 228 | Batch_idx: 10 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 228 | Batch_idx: 20 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 228 | Batch_idx: 30 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (3910/3968)
Epoch: 228 | Batch_idx: 40 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (5182/5248)
Epoch: 228 | Batch_idx: 50 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (6439/6528)
Epoch: 228 | Batch_idx: 60 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (7700/7808)
Epoch: 228 | Batch_idx: 70 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (8962/9088)
Epoch: 228 | Batch_idx: 80 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (10224/10368)
Epoch: 228 | Batch_idx: 90 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (11489/11648)
Epoch: 228 | Batch_idx: 100 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (12747/12928)
Epoch: 228 | Batch_idx: 110 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (14009/14208)
Epoch: 228 | Batch_idx: 120 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (15272/15488)
Epoch: 228 | Batch_idx: 130 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (16533/16768)
Epoch: 228 | Batch_idx: 140 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (17798/18048)
Epoch: 228 | Batch_idx: 150 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (19065/19328)
Epoch: 228 | Batch_idx: 160 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (20329/20608)
Epoch: 228 | Batch_idx: 170 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (21588/21888)
Epoch: 228 | Batch_idx: 180 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (22846/23168)
Epoch: 228 | Batch_idx: 190 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (24103/24448)
Epoch: 228 | Batch_idx: 200 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (25364/25728)
Epoch: 228 | Batch_idx: 210 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (26628/27008)
Epoch: 228 | Batch_idx: 220 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (27877/28288)
Epoch: 228 | Batch_idx: 230 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (29136/29568)
Epoch: 228 | Batch_idx: 240 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (30395/30848)
Epoch: 228 | Batch_idx: 250 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (31658/32128)
Epoch: 228 | Batch_idx: 260 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (32922/33408)
Epoch: 228 | Batch_idx: 270 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (34180/34688)
Epoch: 228 | Batch_idx: 280 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (35437/35968)
Epoch: 228 | Batch_idx: 290 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (36692/37248)
Epoch: 228 | Batch_idx: 300 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (37954/38528)
Epoch: 228 | Batch_idx: 310 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (39211/39808)
Epoch: 228 | Batch_idx: 320 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (40477/41088)
Epoch: 228 | Batch_idx: 330 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (41739/42368)
Epoch: 228 | Batch_idx: 340 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (43005/43648)
Epoch: 228 | Batch_idx: 350 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (44258/44928)
Epoch: 228 | Batch_idx: 360 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (45516/46208)
Epoch: 228 | Batch_idx: 370 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (46778/47488)
Epoch: 228 | Batch_idx: 380 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (48037/48768)
Epoch: 228 | Batch_idx: 390 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (49255/50000)
# TEST : Loss: (0.4637) | Acc: (88.00%) (8843/10000)
percent tensor([0.5910, 0.5884, 0.5986, 0.5920, 0.6122, 0.5925, 0.6010, 0.6038, 0.5944,
        0.5894, 0.5870, 0.5970, 0.5897, 0.5813, 0.5918, 0.5872],
       device='cuda:0') torch.Size([16])
percent tensor([0.5438, 0.5437, 0.5328, 0.5414, 0.5353, 0.5462, 0.5409, 0.5344, 0.5416,
        0.5426, 0.5442, 0.5400, 0.5442, 0.5416, 0.5470, 0.5450],
       device='cuda:0') torch.Size([16])
percent tensor([0.5551, 0.5821, 0.5746, 0.5832, 0.6210, 0.6181, 0.5959, 0.5647, 0.5839,
        0.5767, 0.5707, 0.6010, 0.5889, 0.5661, 0.5971, 0.5761],
       device='cuda:0') torch.Size([16])
percent tensor([0.6930, 0.7046, 0.6624, 0.6553, 0.6568, 0.6626, 0.6978, 0.6535, 0.6814,
        0.6978, 0.7138, 0.6842, 0.7035, 0.6946, 0.6991, 0.6838],
       device='cuda:0') torch.Size([16])
percent tensor([0.5777, 0.5920, 0.7403, 0.8184, 0.7172, 0.7453, 0.6186, 0.6052, 0.7524,
        0.6054, 0.6850, 0.7332, 0.6074, 0.8030, 0.5575, 0.6251],
       device='cuda:0') torch.Size([16])
percent tensor([0.7607, 0.7301, 0.7875, 0.7806, 0.7956, 0.7522, 0.7796, 0.7899, 0.7565,
        0.7254, 0.7201, 0.7766, 0.6995, 0.7607, 0.7677, 0.7593],
       device='cuda:0') torch.Size([16])
percent tensor([0.5431, 0.6722, 0.7155, 0.6059, 0.6361, 0.7349, 0.6996, 0.5863, 0.6320,
        0.6393, 0.6730, 0.4843, 0.5799, 0.5367, 0.6061, 0.5057],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 1.0000, 0.9999, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9998, 0.9998, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 229 | Batch_idx: 0 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 229 | Batch_idx: 10 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 229 | Batch_idx: 20 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 229 | Batch_idx: 30 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (3903/3968)
Epoch: 229 | Batch_idx: 40 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (5172/5248)
Epoch: 229 | Batch_idx: 50 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (6424/6528)
Epoch: 229 | Batch_idx: 60 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (7694/7808)
Epoch: 229 | Batch_idx: 70 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (8959/9088)
Epoch: 229 | Batch_idx: 80 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (10219/10368)
Epoch: 229 | Batch_idx: 90 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (11480/11648)
Epoch: 229 | Batch_idx: 100 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (12746/12928)
Epoch: 229 | Batch_idx: 110 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (14008/14208)
Epoch: 229 | Batch_idx: 120 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (15269/15488)
Epoch: 229 | Batch_idx: 130 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (16532/16768)
Epoch: 229 | Batch_idx: 140 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (17793/18048)
Epoch: 229 | Batch_idx: 150 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (19056/19328)
Epoch: 229 | Batch_idx: 160 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (20323/20608)
Epoch: 229 | Batch_idx: 170 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (21581/21888)
Epoch: 229 | Batch_idx: 180 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (22846/23168)
Epoch: 229 | Batch_idx: 190 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (24103/24448)
Epoch: 229 | Batch_idx: 200 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (25365/25728)
Epoch: 229 | Batch_idx: 210 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (26620/27008)
Epoch: 229 | Batch_idx: 220 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (27883/28288)
Epoch: 229 | Batch_idx: 230 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (29148/29568)
Epoch: 229 | Batch_idx: 240 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (30409/30848)
Epoch: 229 | Batch_idx: 250 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (31677/32128)
Epoch: 229 | Batch_idx: 260 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (32934/33408)
Epoch: 229 | Batch_idx: 270 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (34185/34688)
Epoch: 229 | Batch_idx: 280 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (35441/35968)
Epoch: 229 | Batch_idx: 290 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (36702/37248)
Epoch: 229 | Batch_idx: 300 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (37963/38528)
Epoch: 229 | Batch_idx: 310 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (39226/39808)
Epoch: 229 | Batch_idx: 320 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (40485/41088)
Epoch: 229 | Batch_idx: 330 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (41748/42368)
Epoch: 229 | Batch_idx: 340 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (43010/43648)
Epoch: 229 | Batch_idx: 350 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (44272/44928)
Epoch: 229 | Batch_idx: 360 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (45533/46208)
Epoch: 229 | Batch_idx: 370 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (46792/47488)
Epoch: 229 | Batch_idx: 380 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (48053/48768)
Epoch: 229 | Batch_idx: 390 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (49266/50000)
# TEST : Loss: (0.4414) | Acc: (89.00%) (8902/10000)
percent tensor([0.5910, 0.5885, 0.6016, 0.5916, 0.6148, 0.5932, 0.6016, 0.6044, 0.5949,
        0.5901, 0.5872, 0.5988, 0.5895, 0.5808, 0.5919, 0.5872],
       device='cuda:0') torch.Size([16])
percent tensor([0.5440, 0.5442, 0.5339, 0.5419, 0.5359, 0.5460, 0.5412, 0.5349, 0.5423,
        0.5432, 0.5443, 0.5403, 0.5443, 0.5421, 0.5471, 0.5455],
       device='cuda:0') torch.Size([16])
percent tensor([0.5517, 0.5795, 0.5757, 0.5808, 0.6168, 0.6111, 0.5866, 0.5633, 0.5792,
        0.5737, 0.5668, 0.5987, 0.5842, 0.5588, 0.5950, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.6891, 0.7039, 0.6560, 0.6556, 0.6537, 0.6629, 0.6967, 0.6531, 0.6752,
        0.6962, 0.7128, 0.6787, 0.6986, 0.6958, 0.7004, 0.6835],
       device='cuda:0') torch.Size([16])
percent tensor([0.5925, 0.6138, 0.7327, 0.8250, 0.7307, 0.7342, 0.6287, 0.5865, 0.7807,
        0.6246, 0.7198, 0.7350, 0.6437, 0.8288, 0.5598, 0.6424],
       device='cuda:0') torch.Size([16])
percent tensor([0.7649, 0.7386, 0.7845, 0.7776, 0.7967, 0.7547, 0.7872, 0.7944, 0.7638,
        0.7276, 0.7243, 0.7744, 0.7089, 0.7603, 0.7697, 0.7605],
       device='cuda:0') torch.Size([16])
percent tensor([0.5592, 0.6712, 0.7423, 0.6563, 0.7047, 0.7279, 0.7010, 0.6425, 0.6498,
        0.6392, 0.6536, 0.5135, 0.5660, 0.4853, 0.6042, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 1.0000, 0.9999, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9998, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 230 | Batch_idx: 0 |  Loss: (0.0258) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 230 | Batch_idx: 10 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 230 | Batch_idx: 20 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 230 | Batch_idx: 30 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (3910/3968)
Epoch: 230 | Batch_idx: 40 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 230 | Batch_idx: 50 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (6443/6528)
Epoch: 230 | Batch_idx: 60 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (7708/7808)
Epoch: 230 | Batch_idx: 70 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (8973/9088)
Epoch: 230 | Batch_idx: 80 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (10233/10368)
Epoch: 230 | Batch_idx: 90 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (11500/11648)
Epoch: 230 | Batch_idx: 100 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (12764/12928)
Epoch: 230 | Batch_idx: 110 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (14028/14208)
Epoch: 230 | Batch_idx: 120 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (15288/15488)
Epoch: 230 | Batch_idx: 130 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (16551/16768)
Epoch: 230 | Batch_idx: 140 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (17813/18048)
Epoch: 230 | Batch_idx: 150 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (19071/19328)
Epoch: 230 | Batch_idx: 160 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (20337/20608)
Epoch: 230 | Batch_idx: 170 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (21597/21888)
Epoch: 230 | Batch_idx: 180 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (22860/23168)
Epoch: 230 | Batch_idx: 190 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (24121/24448)
Epoch: 230 | Batch_idx: 200 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (25382/25728)
Epoch: 230 | Batch_idx: 210 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (26647/27008)
Epoch: 230 | Batch_idx: 220 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (27901/28288)
Epoch: 230 | Batch_idx: 230 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (29159/29568)
Epoch: 230 | Batch_idx: 240 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (30426/30848)
Epoch: 230 | Batch_idx: 250 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (31687/32128)
Epoch: 230 | Batch_idx: 260 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (32949/33408)
Epoch: 230 | Batch_idx: 270 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (34210/34688)
Epoch: 230 | Batch_idx: 280 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (35473/35968)
Epoch: 230 | Batch_idx: 290 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (36734/37248)
Epoch: 230 | Batch_idx: 300 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (37999/38528)
Epoch: 230 | Batch_idx: 310 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (39255/39808)
Epoch: 230 | Batch_idx: 320 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (40517/41088)
Epoch: 230 | Batch_idx: 330 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (41782/42368)
Epoch: 230 | Batch_idx: 340 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (43045/43648)
Epoch: 230 | Batch_idx: 350 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (44303/44928)
Epoch: 230 | Batch_idx: 360 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (45568/46208)
Epoch: 230 | Batch_idx: 370 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (46833/47488)
Epoch: 230 | Batch_idx: 380 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (48096/48768)
Epoch: 230 | Batch_idx: 390 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (49312/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_230.pth.tar'
# TEST : Loss: (0.4467) | Acc: (89.00%) (8906/10000)
percent tensor([0.5905, 0.5874, 0.5989, 0.5912, 0.6111, 0.5925, 0.5998, 0.6037, 0.5933,
        0.5886, 0.5862, 0.5958, 0.5889, 0.5801, 0.5907, 0.5865],
       device='cuda:0') torch.Size([16])
percent tensor([0.5449, 0.5455, 0.5336, 0.5419, 0.5360, 0.5463, 0.5424, 0.5358, 0.5429,
        0.5441, 0.5453, 0.5407, 0.5456, 0.5434, 0.5479, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.5549, 0.5799, 0.5822, 0.5819, 0.6222, 0.6138, 0.5931, 0.5712, 0.5807,
        0.5749, 0.5685, 0.6042, 0.5882, 0.5663, 0.5934, 0.5757],
       device='cuda:0') torch.Size([16])
percent tensor([0.6851, 0.7012, 0.6579, 0.6546, 0.6529, 0.6543, 0.6931, 0.6527, 0.6753,
        0.6936, 0.7096, 0.6787, 0.6955, 0.6901, 0.6948, 0.6804],
       device='cuda:0') torch.Size([16])
percent tensor([0.5784, 0.5878, 0.7303, 0.8230, 0.7219, 0.7291, 0.6155, 0.5961, 0.7551,
        0.6062, 0.6878, 0.7292, 0.6056, 0.8141, 0.5561, 0.6248],
       device='cuda:0') torch.Size([16])
percent tensor([0.7599, 0.7282, 0.7840, 0.7882, 0.8011, 0.7549, 0.7752, 0.7906, 0.7530,
        0.7150, 0.7163, 0.7722, 0.6998, 0.7545, 0.7641, 0.7544],
       device='cuda:0') torch.Size([16])
percent tensor([0.5856, 0.6800, 0.7208, 0.6252, 0.6986, 0.7502, 0.6834, 0.5823, 0.6154,
        0.6659, 0.6791, 0.4857, 0.6076, 0.5535, 0.5886, 0.5029],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 1.0000, 0.9999, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9997, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(186.6534, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(844.1135, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(852.6266, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1508.3582, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(475.1269, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2312.4500, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4278.4561, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1323.6464, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6351.1226, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11422.4385, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3735.8193, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15802.1221, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 231 | Batch_idx: 0 |  Loss: (0.0273) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 231 | Batch_idx: 10 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 231 | Batch_idx: 20 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 231 | Batch_idx: 30 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (3909/3968)
Epoch: 231 | Batch_idx: 40 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (5170/5248)
Epoch: 231 | Batch_idx: 50 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (6438/6528)
Epoch: 231 | Batch_idx: 60 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (7706/7808)
Epoch: 231 | Batch_idx: 70 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (8955/9088)
Epoch: 231 | Batch_idx: 80 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (10221/10368)
Epoch: 231 | Batch_idx: 90 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (11487/11648)
Epoch: 231 | Batch_idx: 100 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (12755/12928)
Epoch: 231 | Batch_idx: 110 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (14021/14208)
Epoch: 231 | Batch_idx: 120 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (15280/15488)
Epoch: 231 | Batch_idx: 130 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (16544/16768)
Epoch: 231 | Batch_idx: 140 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (17812/18048)
Epoch: 231 | Batch_idx: 150 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (19086/19328)
Epoch: 231 | Batch_idx: 160 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (20339/20608)
Epoch: 231 | Batch_idx: 170 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (21604/21888)
Epoch: 231 | Batch_idx: 180 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (22870/23168)
Epoch: 231 | Batch_idx: 190 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (24130/24448)
Epoch: 231 | Batch_idx: 200 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (25390/25728)
Epoch: 231 | Batch_idx: 210 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (26651/27008)
Epoch: 231 | Batch_idx: 220 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (27920/28288)
Epoch: 231 | Batch_idx: 230 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (29184/29568)
Epoch: 231 | Batch_idx: 240 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (30439/30848)
Epoch: 231 | Batch_idx: 250 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (31708/32128)
Epoch: 231 | Batch_idx: 260 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (32974/33408)
Epoch: 231 | Batch_idx: 270 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (34238/34688)
Epoch: 231 | Batch_idx: 280 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (35503/35968)
Epoch: 231 | Batch_idx: 290 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (36763/37248)
Epoch: 231 | Batch_idx: 300 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (38023/38528)
Epoch: 231 | Batch_idx: 310 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (39286/39808)
Epoch: 231 | Batch_idx: 320 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (40546/41088)
Epoch: 231 | Batch_idx: 330 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (41805/42368)
Epoch: 231 | Batch_idx: 340 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (43067/43648)
Epoch: 231 | Batch_idx: 350 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (44327/44928)
Epoch: 231 | Batch_idx: 360 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (45589/46208)
Epoch: 231 | Batch_idx: 370 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (46858/47488)
Epoch: 231 | Batch_idx: 380 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (48114/48768)
Epoch: 231 | Batch_idx: 390 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (49327/50000)
# TEST : Loss: (0.4357) | Acc: (89.00%) (8934/10000)
percent tensor([0.5923, 0.5895, 0.6064, 0.5952, 0.6180, 0.5948, 0.6038, 0.6087, 0.5963,
        0.5922, 0.5879, 0.6026, 0.5904, 0.5818, 0.5936, 0.5890],
       device='cuda:0') torch.Size([16])
percent tensor([0.5450, 0.5451, 0.5343, 0.5415, 0.5359, 0.5461, 0.5423, 0.5359, 0.5433,
        0.5436, 0.5453, 0.5408, 0.5452, 0.5426, 0.5475, 0.5463],
       device='cuda:0') torch.Size([16])
percent tensor([0.5543, 0.5819, 0.5747, 0.5810, 0.6173, 0.6124, 0.5929, 0.5676, 0.5799,
        0.5733, 0.5701, 0.6004, 0.5843, 0.5683, 0.5961, 0.5745],
       device='cuda:0') torch.Size([16])
percent tensor([0.6884, 0.7023, 0.6524, 0.6529, 0.6502, 0.6559, 0.6953, 0.6515, 0.6804,
        0.6933, 0.7121, 0.6763, 0.6998, 0.6922, 0.6951, 0.6796],
       device='cuda:0') torch.Size([16])
percent tensor([0.5790, 0.6072, 0.7206, 0.8073, 0.7188, 0.7307, 0.6088, 0.5814, 0.7580,
        0.6196, 0.7076, 0.7173, 0.6148, 0.8206, 0.5628, 0.6321],
       device='cuda:0') torch.Size([16])
percent tensor([0.7718, 0.7424, 0.7986, 0.7900, 0.8068, 0.7765, 0.7840, 0.7989, 0.7613,
        0.7293, 0.7285, 0.7772, 0.7063, 0.7625, 0.7768, 0.7690],
       device='cuda:0') torch.Size([16])
percent tensor([0.5698, 0.6938, 0.7182, 0.6297, 0.7123, 0.7847, 0.7048, 0.6346, 0.5868,
        0.6267, 0.6528, 0.5069, 0.5672, 0.5204, 0.6266, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 1.0000, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9996, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 232 | Batch_idx: 0 |  Loss: (0.0112) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 232 | Batch_idx: 10 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 232 | Batch_idx: 20 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 232 | Batch_idx: 30 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (3920/3968)
Epoch: 232 | Batch_idx: 40 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (5178/5248)
Epoch: 232 | Batch_idx: 50 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (6450/6528)
Epoch: 232 | Batch_idx: 60 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (7724/7808)
Epoch: 232 | Batch_idx: 70 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (8986/9088)
Epoch: 232 | Batch_idx: 80 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (10256/10368)
Epoch: 232 | Batch_idx: 90 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (11527/11648)
Epoch: 232 | Batch_idx: 100 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (12794/12928)
Epoch: 232 | Batch_idx: 110 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (14059/14208)
Epoch: 232 | Batch_idx: 120 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (15321/15488)
Epoch: 232 | Batch_idx: 130 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (16585/16768)
Epoch: 232 | Batch_idx: 140 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (17852/18048)
Epoch: 232 | Batch_idx: 150 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (19120/19328)
Epoch: 232 | Batch_idx: 160 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (20383/20608)
Epoch: 232 | Batch_idx: 170 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (21653/21888)
Epoch: 232 | Batch_idx: 180 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (22915/23168)
Epoch: 232 | Batch_idx: 190 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (24169/24448)
Epoch: 232 | Batch_idx: 200 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (25426/25728)
Epoch: 232 | Batch_idx: 210 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (26689/27008)
Epoch: 232 | Batch_idx: 220 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (27958/28288)
Epoch: 232 | Batch_idx: 230 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (29220/29568)
Epoch: 232 | Batch_idx: 240 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (30481/30848)
Epoch: 232 | Batch_idx: 250 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (31747/32128)
Epoch: 232 | Batch_idx: 260 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (33009/33408)
Epoch: 232 | Batch_idx: 270 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (34266/34688)
Epoch: 232 | Batch_idx: 280 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (35525/35968)
Epoch: 232 | Batch_idx: 290 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (36790/37248)
Epoch: 232 | Batch_idx: 300 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (38055/38528)
Epoch: 232 | Batch_idx: 310 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (39322/39808)
Epoch: 232 | Batch_idx: 320 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (40578/41088)
Epoch: 232 | Batch_idx: 330 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (41840/42368)
Epoch: 232 | Batch_idx: 340 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (43106/43648)
Epoch: 232 | Batch_idx: 350 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (44370/44928)
Epoch: 232 | Batch_idx: 360 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (45635/46208)
Epoch: 232 | Batch_idx: 370 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (46899/47488)
Epoch: 232 | Batch_idx: 380 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (48168/48768)
Epoch: 232 | Batch_idx: 390 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (49383/50000)
# TEST : Loss: (0.4663) | Acc: (89.00%) (8915/10000)
percent tensor([0.5913, 0.5894, 0.6019, 0.5935, 0.6147, 0.5938, 0.6023, 0.6059, 0.5959,
        0.5903, 0.5875, 0.5988, 0.5898, 0.5825, 0.5927, 0.5886],
       device='cuda:0') torch.Size([16])
percent tensor([0.5452, 0.5454, 0.5347, 0.5417, 0.5370, 0.5466, 0.5425, 0.5365, 0.5437,
        0.5441, 0.5456, 0.5414, 0.5454, 0.5430, 0.5482, 0.5467],
       device='cuda:0') torch.Size([16])
percent tensor([0.5536, 0.5794, 0.5710, 0.5801, 0.6154, 0.6203, 0.5882, 0.5645, 0.5772,
        0.5707, 0.5690, 0.5950, 0.5832, 0.5658, 0.5988, 0.5762],
       device='cuda:0') torch.Size([16])
percent tensor([0.6932, 0.7026, 0.6607, 0.6566, 0.6569, 0.6633, 0.6968, 0.6559, 0.6789,
        0.6936, 0.7130, 0.6795, 0.7017, 0.6926, 0.7007, 0.6818],
       device='cuda:0') torch.Size([16])
percent tensor([0.5854, 0.5985, 0.7352, 0.8211, 0.7269, 0.7575, 0.6203, 0.5963, 0.7685,
        0.6143, 0.7076, 0.7283, 0.6093, 0.8292, 0.5617, 0.6431],
       device='cuda:0') torch.Size([16])
percent tensor([0.7685, 0.7287, 0.7989, 0.7873, 0.8076, 0.7709, 0.7827, 0.7947, 0.7620,
        0.7188, 0.7159, 0.7738, 0.6990, 0.7594, 0.7712, 0.7644],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.6794, 0.7406, 0.6057, 0.6845, 0.7660, 0.7008, 0.6039, 0.6090,
        0.6720, 0.6756, 0.5129, 0.6144, 0.5415, 0.5928, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9999, 0.9994, 1.0000, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9997, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 233 | Batch_idx: 0 |  Loss: (0.0138) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 233 | Batch_idx: 10 |  Loss: (0.0311) |  Loss2: (0.0000) | Acc: (99.00%) (1396/1408)
Epoch: 233 | Batch_idx: 20 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (2665/2688)
Epoch: 233 | Batch_idx: 30 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (3930/3968)
Epoch: 233 | Batch_idx: 40 |  Loss: (0.0322) |  Loss2: (0.0000) | Acc: (99.00%) (5197/5248)
Epoch: 233 | Batch_idx: 50 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (6462/6528)
Epoch: 233 | Batch_idx: 60 |  Loss: (0.0328) |  Loss2: (0.0000) | Acc: (99.00%) (7734/7808)
Epoch: 233 | Batch_idx: 70 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (9000/9088)
Epoch: 233 | Batch_idx: 80 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (99.00%) (10267/10368)
Epoch: 233 | Batch_idx: 90 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (11528/11648)
Epoch: 233 | Batch_idx: 100 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (12794/12928)
Epoch: 233 | Batch_idx: 110 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (14050/14208)
Epoch: 233 | Batch_idx: 120 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (15321/15488)
Epoch: 233 | Batch_idx: 130 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (16583/16768)
Epoch: 233 | Batch_idx: 140 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (17841/18048)
Epoch: 233 | Batch_idx: 150 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (19102/19328)
Epoch: 233 | Batch_idx: 160 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (20370/20608)
Epoch: 233 | Batch_idx: 170 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (21640/21888)
Epoch: 233 | Batch_idx: 180 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (22905/23168)
Epoch: 233 | Batch_idx: 190 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (24168/24448)
Epoch: 233 | Batch_idx: 200 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (25429/25728)
Epoch: 233 | Batch_idx: 210 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (26695/27008)
Epoch: 233 | Batch_idx: 220 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (27957/28288)
Epoch: 233 | Batch_idx: 230 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (29220/29568)
Epoch: 233 | Batch_idx: 240 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (30486/30848)
Epoch: 233 | Batch_idx: 250 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (31750/32128)
Epoch: 233 | Batch_idx: 260 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (33019/33408)
Epoch: 233 | Batch_idx: 270 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (34289/34688)
Epoch: 233 | Batch_idx: 280 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (35554/35968)
Epoch: 233 | Batch_idx: 290 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (36818/37248)
Epoch: 233 | Batch_idx: 300 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (38083/38528)
Epoch: 233 | Batch_idx: 310 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (39342/39808)
Epoch: 233 | Batch_idx: 320 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (40610/41088)
Epoch: 233 | Batch_idx: 330 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (41876/42368)
Epoch: 233 | Batch_idx: 340 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (43143/43648)
Epoch: 233 | Batch_idx: 350 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (44397/44928)
Epoch: 233 | Batch_idx: 360 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (45660/46208)
Epoch: 233 | Batch_idx: 370 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (46928/47488)
Epoch: 233 | Batch_idx: 380 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (48192/48768)
Epoch: 233 | Batch_idx: 390 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (49409/50000)
# TEST : Loss: (0.4464) | Acc: (89.00%) (8901/10000)
percent tensor([0.5931, 0.5909, 0.6015, 0.5949, 0.6148, 0.5952, 0.6034, 0.6065, 0.5970,
        0.5917, 0.5891, 0.5987, 0.5914, 0.5843, 0.5940, 0.5904],
       device='cuda:0') torch.Size([16])
percent tensor([0.5456, 0.5463, 0.5349, 0.5424, 0.5372, 0.5482, 0.5429, 0.5364, 0.5433,
        0.5443, 0.5461, 0.5414, 0.5458, 0.5435, 0.5494, 0.5476],
       device='cuda:0') torch.Size([16])
percent tensor([0.5570, 0.5827, 0.5825, 0.5827, 0.6238, 0.6196, 0.5948, 0.5718, 0.5854,
        0.5752, 0.5739, 0.6042, 0.5890, 0.5667, 0.5980, 0.5789],
       device='cuda:0') torch.Size([16])
percent tensor([0.6947, 0.7098, 0.6641, 0.6593, 0.6587, 0.6646, 0.7028, 0.6579, 0.6818,
        0.7028, 0.7191, 0.6854, 0.7048, 0.6999, 0.7035, 0.6851],
       device='cuda:0') torch.Size([16])
percent tensor([0.5779, 0.6073, 0.7207, 0.8157, 0.7206, 0.7400, 0.6137, 0.5821, 0.7600,
        0.6087, 0.7041, 0.7305, 0.6198, 0.8121, 0.5564, 0.6310],
       device='cuda:0') torch.Size([16])
percent tensor([0.7706, 0.7346, 0.8017, 0.7907, 0.8058, 0.7695, 0.7849, 0.8013, 0.7599,
        0.7232, 0.7223, 0.7782, 0.7084, 0.7603, 0.7729, 0.7703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5634, 0.6743, 0.7283, 0.6372, 0.7101, 0.7233, 0.7192, 0.6571, 0.6347,
        0.6357, 0.6669, 0.5027, 0.6063, 0.4918, 0.6079, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9995, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9997, 0.9997, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 234 | Batch_idx: 0 |  Loss: (0.0250) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 234 | Batch_idx: 10 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 234 | Batch_idx: 20 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (2660/2688)
Epoch: 234 | Batch_idx: 30 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (3918/3968)
Epoch: 234 | Batch_idx: 40 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (5178/5248)
Epoch: 234 | Batch_idx: 50 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (6446/6528)
Epoch: 234 | Batch_idx: 60 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (7712/7808)
Epoch: 234 | Batch_idx: 70 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (8979/9088)
Epoch: 234 | Batch_idx: 80 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (10245/10368)
Epoch: 234 | Batch_idx: 90 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (11512/11648)
Epoch: 234 | Batch_idx: 100 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (12782/12928)
Epoch: 234 | Batch_idx: 110 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (14048/14208)
Epoch: 234 | Batch_idx: 120 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (15313/15488)
Epoch: 234 | Batch_idx: 130 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (16576/16768)
Epoch: 234 | Batch_idx: 140 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (17838/18048)
Epoch: 234 | Batch_idx: 150 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (19108/19328)
Epoch: 234 | Batch_idx: 160 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (20378/20608)
Epoch: 234 | Batch_idx: 170 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (21645/21888)
Epoch: 234 | Batch_idx: 180 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (22912/23168)
Epoch: 234 | Batch_idx: 190 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (24178/24448)
Epoch: 234 | Batch_idx: 200 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (25444/25728)
Epoch: 234 | Batch_idx: 210 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (26696/27008)
Epoch: 234 | Batch_idx: 220 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (27956/28288)
Epoch: 234 | Batch_idx: 230 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (29218/29568)
Epoch: 234 | Batch_idx: 240 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (30479/30848)
Epoch: 234 | Batch_idx: 250 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (31743/32128)
Epoch: 234 | Batch_idx: 260 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (33003/33408)
Epoch: 234 | Batch_idx: 270 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (34271/34688)
Epoch: 234 | Batch_idx: 280 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (35535/35968)
Epoch: 234 | Batch_idx: 290 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (36804/37248)
Epoch: 234 | Batch_idx: 300 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (38068/38528)
Epoch: 234 | Batch_idx: 310 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (39332/39808)
Epoch: 234 | Batch_idx: 320 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (40594/41088)
Epoch: 234 | Batch_idx: 330 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (41862/42368)
Epoch: 234 | Batch_idx: 340 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (43130/43648)
Epoch: 234 | Batch_idx: 350 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (44392/44928)
Epoch: 234 | Batch_idx: 360 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (45665/46208)
Epoch: 234 | Batch_idx: 370 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (46931/47488)
Epoch: 234 | Batch_idx: 380 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (48197/48768)
Epoch: 234 | Batch_idx: 390 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (49414/50000)
# TEST : Loss: (0.4344) | Acc: (89.00%) (8921/10000)
percent tensor([0.5937, 0.5917, 0.6033, 0.5968, 0.6164, 0.5957, 0.6037, 0.6080, 0.5968,
        0.5928, 0.5891, 0.6000, 0.5922, 0.5838, 0.5950, 0.5908],
       device='cuda:0') torch.Size([16])
percent tensor([0.5454, 0.5458, 0.5336, 0.5421, 0.5365, 0.5477, 0.5423, 0.5364, 0.5430,
        0.5439, 0.5461, 0.5405, 0.5455, 0.5430, 0.5491, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.5547, 0.5815, 0.5801, 0.5838, 0.6219, 0.6214, 0.5923, 0.5700, 0.5823,
        0.5744, 0.5732, 0.6020, 0.5848, 0.5705, 0.5968, 0.5783],
       device='cuda:0') torch.Size([16])
percent tensor([0.6958, 0.7092, 0.6587, 0.6562, 0.6553, 0.6641, 0.6991, 0.6557, 0.6863,
        0.7012, 0.7198, 0.6807, 0.7085, 0.6974, 0.7039, 0.6865],
       device='cuda:0') torch.Size([16])
percent tensor([0.5950, 0.6182, 0.7246, 0.8167, 0.7291, 0.7532, 0.6410, 0.5902, 0.7842,
        0.6308, 0.7210, 0.7489, 0.6420, 0.8319, 0.5720, 0.6434],
       device='cuda:0') torch.Size([16])
percent tensor([0.7617, 0.7318, 0.7937, 0.7887, 0.8047, 0.7637, 0.7784, 0.7953, 0.7528,
        0.7180, 0.7174, 0.7702, 0.6984, 0.7572, 0.7686, 0.7631],
       device='cuda:0') torch.Size([16])
percent tensor([0.5312, 0.6485, 0.7294, 0.6104, 0.7237, 0.7430, 0.7118, 0.5708, 0.5824,
        0.6421, 0.6465, 0.4975, 0.5495, 0.5281, 0.5674, 0.4963],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 0.9999, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9997, 0.9996, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 235 | Batch_idx: 0 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 235 | Batch_idx: 10 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 235 | Batch_idx: 20 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (2659/2688)
Epoch: 235 | Batch_idx: 30 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (3921/3968)
Epoch: 235 | Batch_idx: 40 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (5191/5248)
Epoch: 235 | Batch_idx: 50 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (6461/6528)
Epoch: 235 | Batch_idx: 60 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (7719/7808)
Epoch: 235 | Batch_idx: 70 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (8987/9088)
Epoch: 235 | Batch_idx: 80 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (10250/10368)
Epoch: 235 | Batch_idx: 90 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (11513/11648)
Epoch: 235 | Batch_idx: 100 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (12782/12928)
Epoch: 235 | Batch_idx: 110 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (14052/14208)
Epoch: 235 | Batch_idx: 120 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (15323/15488)
Epoch: 235 | Batch_idx: 130 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (16590/16768)
Epoch: 235 | Batch_idx: 140 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (17857/18048)
Epoch: 235 | Batch_idx: 150 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (19129/19328)
Epoch: 235 | Batch_idx: 160 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (20392/20608)
Epoch: 235 | Batch_idx: 170 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (21657/21888)
Epoch: 235 | Batch_idx: 180 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (22921/23168)
Epoch: 235 | Batch_idx: 190 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (24183/24448)
Epoch: 235 | Batch_idx: 200 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (25449/25728)
Epoch: 235 | Batch_idx: 210 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (26717/27008)
Epoch: 235 | Batch_idx: 220 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (27981/28288)
Epoch: 235 | Batch_idx: 230 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (29248/29568)
Epoch: 235 | Batch_idx: 240 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (30516/30848)
Epoch: 235 | Batch_idx: 250 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (31776/32128)
Epoch: 235 | Batch_idx: 260 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (33040/33408)
Epoch: 235 | Batch_idx: 270 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (34308/34688)
Epoch: 235 | Batch_idx: 280 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (35572/35968)
Epoch: 235 | Batch_idx: 290 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (36834/37248)
Epoch: 235 | Batch_idx: 300 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (38091/38528)
Epoch: 235 | Batch_idx: 310 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (39354/39808)
Epoch: 235 | Batch_idx: 320 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (40618/41088)
Epoch: 235 | Batch_idx: 330 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (41874/42368)
Epoch: 235 | Batch_idx: 340 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (43136/43648)
Epoch: 235 | Batch_idx: 350 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (44400/44928)
Epoch: 235 | Batch_idx: 360 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (45656/46208)
Epoch: 235 | Batch_idx: 370 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (46920/47488)
Epoch: 235 | Batch_idx: 380 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (48182/48768)
Epoch: 235 | Batch_idx: 390 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (49398/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_for_e/checkpoint_235.pth.tar'
# TEST : Loss: (0.4332) | Acc: (89.00%) (8924/10000)
percent tensor([0.5918, 0.5895, 0.6012, 0.5944, 0.6137, 0.5933, 0.6016, 0.6065, 0.5944,
        0.5911, 0.5875, 0.5978, 0.5903, 0.5819, 0.5933, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.5454, 0.5459, 0.5347, 0.5427, 0.5366, 0.5469, 0.5426, 0.5367, 0.5429,
        0.5445, 0.5455, 0.5417, 0.5456, 0.5431, 0.5483, 0.5468],
       device='cuda:0') torch.Size([16])
percent tensor([0.5500, 0.5777, 0.5761, 0.5800, 0.6155, 0.6123, 0.5868, 0.5666, 0.5769,
        0.5713, 0.5654, 0.5987, 0.5800, 0.5632, 0.5908, 0.5722],
       device='cuda:0') torch.Size([16])
percent tensor([0.6927, 0.7051, 0.6604, 0.6608, 0.6573, 0.6634, 0.6983, 0.6572, 0.6795,
        0.6935, 0.7108, 0.6820, 0.7011, 0.6972, 0.7013, 0.6834],
       device='cuda:0') torch.Size([16])
percent tensor([0.5874, 0.6045, 0.7261, 0.8371, 0.7349, 0.7602, 0.6181, 0.5793, 0.7650,
        0.6259, 0.7110, 0.7416, 0.6109, 0.8162, 0.5642, 0.6402],
       device='cuda:0') torch.Size([16])
percent tensor([0.7654, 0.7314, 0.7835, 0.7858, 0.8001, 0.7634, 0.7818, 0.7883, 0.7540,
        0.7244, 0.7250, 0.7643, 0.7007, 0.7615, 0.7690, 0.7644],
       device='cuda:0') torch.Size([16])
percent tensor([0.5716, 0.6715, 0.7185, 0.6207, 0.6952, 0.7486, 0.7098, 0.5891, 0.6374,
        0.6637, 0.6517, 0.4883, 0.6149, 0.5035, 0.6060, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9995, 1.0000, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9998, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 236 | Batch_idx: 0 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 236 | Batch_idx: 10 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 236 | Batch_idx: 20 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 236 | Batch_idx: 30 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (3909/3968)
Epoch: 236 | Batch_idx: 40 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (5172/5248)
Epoch: 236 | Batch_idx: 50 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (6434/6528)
Epoch: 236 | Batch_idx: 60 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (7699/7808)
Epoch: 236 | Batch_idx: 70 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (8963/9088)
Epoch: 236 | Batch_idx: 80 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (10230/10368)
Epoch: 236 | Batch_idx: 90 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (11498/11648)
Epoch: 236 | Batch_idx: 100 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (12761/12928)
Epoch: 236 | Batch_idx: 110 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (14023/14208)
Epoch: 236 | Batch_idx: 120 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (15279/15488)
Epoch: 236 | Batch_idx: 130 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (16546/16768)
Epoch: 236 | Batch_idx: 140 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (17812/18048)
Epoch: 236 | Batch_idx: 150 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (19077/19328)
Epoch: 236 | Batch_idx: 160 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (20337/20608)
Epoch: 236 | Batch_idx: 170 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (21602/21888)
Epoch: 236 | Batch_idx: 180 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (22864/23168)
Epoch: 236 | Batch_idx: 190 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (24122/24448)
Epoch: 236 | Batch_idx: 200 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (25390/25728)
Epoch: 236 | Batch_idx: 210 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (26648/27008)
Epoch: 236 | Batch_idx: 220 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (27912/28288)
Epoch: 236 | Batch_idx: 230 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (29175/29568)
Epoch: 236 | Batch_idx: 240 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (30441/30848)
Epoch: 236 | Batch_idx: 250 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (31705/32128)
Epoch: 236 | Batch_idx: 260 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (32962/33408)
Epoch: 236 | Batch_idx: 270 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (34231/34688)
Epoch: 236 | Batch_idx: 280 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (35494/35968)
Epoch: 236 | Batch_idx: 290 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (36759/37248)
Epoch: 236 | Batch_idx: 300 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (38025/38528)
Epoch: 236 | Batch_idx: 310 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (39283/39808)
Epoch: 236 | Batch_idx: 320 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (40535/41088)
Epoch: 236 | Batch_idx: 330 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (41794/42368)
Epoch: 236 | Batch_idx: 340 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (43055/43648)
Epoch: 236 | Batch_idx: 350 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (44322/44928)
Epoch: 236 | Batch_idx: 360 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (45584/46208)
Epoch: 236 | Batch_idx: 370 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (46845/47488)
Epoch: 236 | Batch_idx: 380 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (48109/48768)
Epoch: 236 | Batch_idx: 390 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (49325/50000)
# TEST : Loss: (0.4522) | Acc: (89.00%) (8930/10000)
percent tensor([0.5945, 0.5923, 0.6049, 0.5961, 0.6180, 0.5956, 0.6054, 0.6094, 0.5985,
        0.5937, 0.5904, 0.6019, 0.5927, 0.5851, 0.5953, 0.5908],
       device='cuda:0') torch.Size([16])
percent tensor([0.5441, 0.5442, 0.5336, 0.5413, 0.5357, 0.5464, 0.5412, 0.5346, 0.5419,
        0.5428, 0.5442, 0.5404, 0.5439, 0.5414, 0.5471, 0.5454],
       device='cuda:0') torch.Size([16])
percent tensor([0.5490, 0.5726, 0.5747, 0.5792, 0.6162, 0.6104, 0.5827, 0.5645, 0.5774,
        0.5648, 0.5634, 0.5991, 0.5776, 0.5623, 0.5890, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.6975, 0.7104, 0.6656, 0.6609, 0.6585, 0.6642, 0.7043, 0.6621, 0.6834,
        0.7018, 0.7187, 0.6869, 0.7070, 0.7000, 0.7063, 0.6873],
       device='cuda:0') torch.Size([16])
percent tensor([0.5840, 0.5899, 0.7342, 0.8369, 0.7416, 0.7774, 0.6152, 0.5836, 0.7605,
        0.6045, 0.6981, 0.7278, 0.6004, 0.8027, 0.5666, 0.6360],
       device='cuda:0') torch.Size([16])
percent tensor([0.7742, 0.7327, 0.8047, 0.7920, 0.8050, 0.7651, 0.7883, 0.8003, 0.7631,
        0.7271, 0.7297, 0.7783, 0.6999, 0.7671, 0.7722, 0.7646],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.6296, 0.7067, 0.5958, 0.6969, 0.7082, 0.6493, 0.6063, 0.6051,
        0.6126, 0.6420, 0.4566, 0.5602, 0.4507, 0.5829, 0.4635],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9997, 0.9996, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 237 | Batch_idx: 0 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 237 | Batch_idx: 10 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 237 | Batch_idx: 20 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (2652/2688)
Epoch: 237 | Batch_idx: 30 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (3903/3968)
Epoch: 237 | Batch_idx: 40 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (5164/5248)
Epoch: 237 | Batch_idx: 50 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (6431/6528)
Epoch: 237 | Batch_idx: 60 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (7698/7808)
Epoch: 237 | Batch_idx: 70 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (8957/9088)
Epoch: 237 | Batch_idx: 80 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (10216/10368)
Epoch: 237 | Batch_idx: 90 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (11481/11648)
Epoch: 237 | Batch_idx: 100 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (12748/12928)
Epoch: 237 | Batch_idx: 110 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (14021/14208)
Epoch: 237 | Batch_idx: 120 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (15284/15488)
Epoch: 237 | Batch_idx: 130 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (16540/16768)
Epoch: 237 | Batch_idx: 140 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (17808/18048)
Epoch: 237 | Batch_idx: 150 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (19068/19328)
Epoch: 237 | Batch_idx: 160 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (20331/20608)
Epoch: 237 | Batch_idx: 170 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (21590/21888)
Epoch: 237 | Batch_idx: 180 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (22851/23168)
Epoch: 237 | Batch_idx: 190 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (24113/24448)
Epoch: 237 | Batch_idx: 200 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (25377/25728)
Epoch: 237 | Batch_idx: 210 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (26639/27008)
Epoch: 237 | Batch_idx: 220 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (27901/28288)
Epoch: 237 | Batch_idx: 230 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (29162/29568)
Epoch: 237 | Batch_idx: 240 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (30421/30848)
Epoch: 237 | Batch_idx: 250 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (31683/32128)
Epoch: 237 | Batch_idx: 260 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (32941/33408)
Epoch: 237 | Batch_idx: 270 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (34202/34688)
Epoch: 237 | Batch_idx: 280 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (35471/35968)
Epoch: 237 | Batch_idx: 290 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (36731/37248)
Epoch: 237 | Batch_idx: 300 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (37994/38528)
Epoch: 237 | Batch_idx: 310 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (39259/39808)
Epoch: 237 | Batch_idx: 320 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (40525/41088)
Epoch: 237 | Batch_idx: 330 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (41791/42368)
Epoch: 237 | Batch_idx: 340 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (43048/43648)
Epoch: 237 | Batch_idx: 350 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (44313/44928)
Epoch: 237 | Batch_idx: 360 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (45578/46208)
Epoch: 237 | Batch_idx: 370 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (46846/47488)
Epoch: 237 | Batch_idx: 380 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (48113/48768)
Epoch: 237 | Batch_idx: 390 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (49331/50000)
# TEST : Loss: (0.4355) | Acc: (89.00%) (8913/10000)
percent tensor([0.5938, 0.5914, 0.6037, 0.5948, 0.6165, 0.5950, 0.6043, 0.6072, 0.5975,
        0.5925, 0.5894, 0.6008, 0.5919, 0.5835, 0.5942, 0.5895],
       device='cuda:0') torch.Size([16])
percent tensor([0.5453, 0.5455, 0.5346, 0.5423, 0.5366, 0.5469, 0.5426, 0.5363, 0.5433,
        0.5443, 0.5453, 0.5414, 0.5453, 0.5431, 0.5484, 0.5465],
       device='cuda:0') torch.Size([16])
percent tensor([0.5518, 0.5787, 0.5805, 0.5813, 0.6173, 0.6128, 0.5876, 0.5673, 0.5796,
        0.5699, 0.5653, 0.6006, 0.5823, 0.5653, 0.5910, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.6919, 0.7066, 0.6575, 0.6593, 0.6547, 0.6649, 0.6990, 0.6559, 0.6775,
        0.6971, 0.7144, 0.6812, 0.7015, 0.6975, 0.7040, 0.6858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5873, 0.6011, 0.7306, 0.8288, 0.7364, 0.7528, 0.6193, 0.5866, 0.7613,
        0.6156, 0.6972, 0.7372, 0.6253, 0.8074, 0.5593, 0.6442],
       device='cuda:0') torch.Size([16])
percent tensor([0.7697, 0.7397, 0.7942, 0.7848, 0.8015, 0.7726, 0.7852, 0.7956, 0.7671,
        0.7280, 0.7276, 0.7770, 0.7109, 0.7681, 0.7710, 0.7646],
       device='cuda:0') torch.Size([16])
percent tensor([0.5441, 0.6831, 0.7027, 0.6032, 0.6889, 0.7335, 0.6551, 0.5609, 0.5927,
        0.6356, 0.6329, 0.4502, 0.5561, 0.4692, 0.5564, 0.4723],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 1.0000, 0.9999, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9996, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 238 | Batch_idx: 0 |  Loss: (0.0230) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 238 | Batch_idx: 10 |  Loss: (0.0282) |  Loss2: (0.0000) | Acc: (99.00%) (1397/1408)
Epoch: 238 | Batch_idx: 20 |  Loss: (0.0264) |  Loss2: (0.0000) | Acc: (99.00%) (2670/2688)
Epoch: 238 | Batch_idx: 30 |  Loss: (0.0299) |  Loss2: (0.0000) | Acc: (99.00%) (3933/3968)
Epoch: 238 | Batch_idx: 40 |  Loss: (0.0287) |  Loss2: (0.0000) | Acc: (99.00%) (5207/5248)
Epoch: 238 | Batch_idx: 50 |  Loss: (0.0316) |  Loss2: (0.0000) | Acc: (99.00%) (6468/6528)
Epoch: 238 | Batch_idx: 60 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (7728/7808)
Epoch: 238 | Batch_idx: 70 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (8993/9088)
Epoch: 238 | Batch_idx: 80 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (10256/10368)
Epoch: 238 | Batch_idx: 90 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (11519/11648)
Epoch: 238 | Batch_idx: 100 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (12787/12928)
Epoch: 238 | Batch_idx: 110 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (14051/14208)
Epoch: 238 | Batch_idx: 120 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (15314/15488)
Epoch: 238 | Batch_idx: 130 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (16569/16768)
Epoch: 238 | Batch_idx: 140 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (17831/18048)
Epoch: 238 | Batch_idx: 150 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (19094/19328)
Epoch: 238 | Batch_idx: 160 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (20363/20608)
Epoch: 238 | Batch_idx: 170 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (21628/21888)
Epoch: 238 | Batch_idx: 180 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (22892/23168)
Epoch: 238 | Batch_idx: 190 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (24158/24448)
Epoch: 238 | Batch_idx: 200 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (25421/25728)
Epoch: 238 | Batch_idx: 210 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (26687/27008)
Epoch: 238 | Batch_idx: 220 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (27949/28288)
Epoch: 238 | Batch_idx: 230 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (29210/29568)
Epoch: 238 | Batch_idx: 240 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (30481/30848)
Epoch: 238 | Batch_idx: 250 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (31750/32128)
Epoch: 238 | Batch_idx: 260 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (33013/33408)
Epoch: 238 | Batch_idx: 270 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (34276/34688)
Epoch: 238 | Batch_idx: 280 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (35541/35968)
Epoch: 238 | Batch_idx: 290 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (36806/37248)
Epoch: 238 | Batch_idx: 300 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (38077/38528)
Epoch: 238 | Batch_idx: 310 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (39341/39808)
Epoch: 238 | Batch_idx: 320 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (40603/41088)
Epoch: 238 | Batch_idx: 330 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (41865/42368)
Epoch: 238 | Batch_idx: 340 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (43122/43648)
Epoch: 238 | Batch_idx: 350 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (44388/44928)
Epoch: 238 | Batch_idx: 360 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (45650/46208)
Epoch: 238 | Batch_idx: 370 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (46913/47488)
Epoch: 238 | Batch_idx: 380 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (48174/48768)
Epoch: 238 | Batch_idx: 390 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (49394/50000)
# TEST : Loss: (0.4653) | Acc: (89.00%) (8903/10000)
percent tensor([0.5938, 0.5923, 0.6021, 0.5950, 0.6163, 0.5959, 0.6048, 0.6067, 0.5975,
        0.5930, 0.5905, 0.6003, 0.5924, 0.5854, 0.5954, 0.5904],
       device='cuda:0') torch.Size([16])
percent tensor([0.5441, 0.5446, 0.5339, 0.5417, 0.5361, 0.5464, 0.5413, 0.5354, 0.5416,
        0.5430, 0.5441, 0.5404, 0.5440, 0.5418, 0.5478, 0.5458],
       device='cuda:0') torch.Size([16])
percent tensor([0.5531, 0.5796, 0.5736, 0.5791, 0.6152, 0.6145, 0.5877, 0.5622, 0.5756,
        0.5708, 0.5666, 0.5996, 0.5838, 0.5653, 0.5939, 0.5739],
       device='cuda:0') torch.Size([16])
percent tensor([0.6921, 0.7093, 0.6638, 0.6634, 0.6590, 0.6628, 0.7004, 0.6578, 0.6792,
        0.6998, 0.7127, 0.6844, 0.7046, 0.6945, 0.7047, 0.6858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5840, 0.7372, 0.8271, 0.7348, 0.7582, 0.6142, 0.5861, 0.7501,
        0.6013, 0.6946, 0.7394, 0.6075, 0.8152, 0.5538, 0.6365],
       device='cuda:0') torch.Size([16])
percent tensor([0.7702, 0.7320, 0.7988, 0.7928, 0.8082, 0.7763, 0.7814, 0.7945, 0.7609,
        0.7228, 0.7294, 0.7763, 0.7062, 0.7656, 0.7719, 0.7663],
       device='cuda:0') torch.Size([16])
percent tensor([0.5293, 0.7033, 0.7419, 0.6192, 0.6824, 0.7334, 0.6702, 0.6057, 0.6289,
        0.6500, 0.6519, 0.5096, 0.5737, 0.4925, 0.6129, 0.4925],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 1.0000, 0.9999, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9997, 0.9997, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 239 | Batch_idx: 0 |  Loss: (0.0324) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 239 | Batch_idx: 10 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 239 | Batch_idx: 20 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 239 | Batch_idx: 30 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 239 | Batch_idx: 40 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (5186/5248)
Epoch: 239 | Batch_idx: 50 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (6454/6528)
Epoch: 239 | Batch_idx: 60 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (7716/7808)
Epoch: 239 | Batch_idx: 70 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (8979/9088)
Epoch: 239 | Batch_idx: 80 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (10240/10368)
Epoch: 239 | Batch_idx: 90 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (11501/11648)
Epoch: 239 | Batch_idx: 100 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (12766/12928)
Epoch: 239 | Batch_idx: 110 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (14034/14208)
Epoch: 239 | Batch_idx: 120 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (15301/15488)
Epoch: 239 | Batch_idx: 130 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (16566/16768)
Epoch: 239 | Batch_idx: 140 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (17831/18048)
Epoch: 239 | Batch_idx: 150 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (19096/19328)
Epoch: 239 | Batch_idx: 160 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (20365/20608)
Epoch: 239 | Batch_idx: 170 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (21633/21888)
Epoch: 239 | Batch_idx: 180 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (22898/23168)
Epoch: 239 | Batch_idx: 190 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (24163/24448)
Epoch: 239 | Batch_idx: 200 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (25430/25728)
Epoch: 239 | Batch_idx: 210 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (26697/27008)
Epoch: 239 | Batch_idx: 220 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (27964/28288)
Epoch: 239 | Batch_idx: 230 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (29219/29568)
Epoch: 239 | Batch_idx: 240 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (30485/30848)
Epoch: 239 | Batch_idx: 250 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (31751/32128)
Epoch: 239 | Batch_idx: 260 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (33019/33408)
Epoch: 239 | Batch_idx: 270 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (34289/34688)
Epoch: 239 | Batch_idx: 280 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (35560/35968)
Epoch: 239 | Batch_idx: 290 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (36822/37248)
Epoch: 239 | Batch_idx: 300 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (38087/38528)
Epoch: 239 | Batch_idx: 310 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (39353/39808)
Epoch: 239 | Batch_idx: 320 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (40616/41088)
Epoch: 239 | Batch_idx: 330 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (41876/42368)
Epoch: 239 | Batch_idx: 340 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (43141/43648)
Epoch: 239 | Batch_idx: 350 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (44407/44928)
Epoch: 239 | Batch_idx: 360 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (45660/46208)
Epoch: 239 | Batch_idx: 370 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (46928/47488)
Epoch: 239 | Batch_idx: 380 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (48195/48768)
Epoch: 239 | Batch_idx: 390 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (49406/50000)
# TEST : Loss: (0.4587) | Acc: (88.00%) (8889/10000)
percent tensor([0.5936, 0.5916, 0.6016, 0.5948, 0.6163, 0.5948, 0.6039, 0.6069, 0.5976,
        0.5929, 0.5895, 0.5998, 0.5924, 0.5841, 0.5945, 0.5900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5427, 0.5431, 0.5317, 0.5404, 0.5339, 0.5450, 0.5396, 0.5339, 0.5408,
        0.5416, 0.5430, 0.5386, 0.5431, 0.5411, 0.5460, 0.5447],
       device='cuda:0') torch.Size([16])
percent tensor([0.5529, 0.5785, 0.5740, 0.5811, 0.6159, 0.6164, 0.5872, 0.5633, 0.5808,
        0.5738, 0.5680, 0.5977, 0.5828, 0.5658, 0.5928, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.6880, 0.7054, 0.6570, 0.6583, 0.6523, 0.6593, 0.6945, 0.6533, 0.6743,
        0.6953, 0.7095, 0.6796, 0.6996, 0.6949, 0.7001, 0.6804],
       device='cuda:0') torch.Size([16])
percent tensor([0.5902, 0.6038, 0.7211, 0.8286, 0.7320, 0.7508, 0.6294, 0.5936, 0.7797,
        0.6266, 0.7267, 0.7350, 0.6251, 0.8231, 0.5718, 0.6379],
       device='cuda:0') torch.Size([16])
percent tensor([0.7690, 0.7330, 0.7982, 0.7911, 0.8102, 0.7668, 0.7861, 0.7987, 0.7674,
        0.7287, 0.7371, 0.7762, 0.7066, 0.7634, 0.7727, 0.7624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5442, 0.6698, 0.7190, 0.6072, 0.6552, 0.6926, 0.6791, 0.5856, 0.6637,
        0.6815, 0.6816, 0.4805, 0.5842, 0.4446, 0.6217, 0.5089],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9995, 1.0000, 0.9999, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9997, 0.9997, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(186.8500, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(845.5541, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(854.8922, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1507.8009, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(473.7741, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2318.4131, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4279.1367, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1319.4403, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6370.5537, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11395.3896, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3722.8367, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15745.2031, device='cuda:0', grad_fn=<NormBackward0>)
2 hours 4 mins 9 secs for training