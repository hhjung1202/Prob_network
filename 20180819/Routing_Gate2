Files already downloaded and verified
USE 1 GPUs!
=> loading checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_000.pth.tar'
Epoch: 1 | Batch_idx: 0 |  Loss: (1.7849) |  Loss2: (0.0000) | Acc: (37.00%) (48/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.8202) |  Loss2: (0.0000) | Acc: (33.00%) (474/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.8278) |  Loss2: (0.0000) | Acc: (33.00%) (898/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8159) |  Loss2: (0.0000) | Acc: (33.00%) (1347/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8149) |  Loss2: (0.0000) | Acc: (33.00%) (1755/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.8057) |  Loss2: (0.0000) | Acc: (34.00%) (2234/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.8002) |  Loss2: (0.0000) | Acc: (34.00%) (2687/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.7976) |  Loss2: (0.0000) | Acc: (34.00%) (3126/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.7939) |  Loss2: (0.0000) | Acc: (34.00%) (3599/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.7911) |  Loss2: (0.0000) | Acc: (34.00%) (4015/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.7859) |  Loss2: (0.0000) | Acc: (34.00%) (4510/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.7805) |  Loss2: (0.0000) | Acc: (35.00%) (4989/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.7769) |  Loss2: (0.0000) | Acc: (35.00%) (5448/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.7715) |  Loss2: (0.0000) | Acc: (35.00%) (5886/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7684) |  Loss2: (0.0000) | Acc: (35.00%) (6340/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7657) |  Loss2: (0.0000) | Acc: (35.00%) (6803/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7611) |  Loss2: (0.0000) | Acc: (35.00%) (7280/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7571) |  Loss2: (0.0000) | Acc: (35.00%) (7777/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7538) |  Loss2: (0.0000) | Acc: (35.00%) (8252/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7510) |  Loss2: (0.0000) | Acc: (35.00%) (8702/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7465) |  Loss2: (0.0000) | Acc: (35.00%) (9187/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7439) |  Loss2: (0.0000) | Acc: (35.00%) (9666/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7411) |  Loss2: (0.0000) | Acc: (35.00%) (10136/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7369) |  Loss2: (0.0000) | Acc: (35.00%) (10613/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7340) |  Loss2: (0.0000) | Acc: (35.00%) (11090/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7316) |  Loss2: (0.0000) | Acc: (35.00%) (11554/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7280) |  Loss2: (0.0000) | Acc: (36.00%) (12055/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7248) |  Loss2: (0.0000) | Acc: (36.00%) (12542/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7220) |  Loss2: (0.0000) | Acc: (36.00%) (13032/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7185) |  Loss2: (0.0000) | Acc: (36.00%) (13545/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7167) |  Loss2: (0.0000) | Acc: (36.00%) (14033/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7138) |  Loss2: (0.0000) | Acc: (36.00%) (14548/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7116) |  Loss2: (0.0000) | Acc: (36.00%) (15059/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7088) |  Loss2: (0.0000) | Acc: (36.00%) (15553/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7054) |  Loss2: (0.0000) | Acc: (36.00%) (16089/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.7022) |  Loss2: (0.0000) | Acc: (36.00%) (16611/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.6998) |  Loss2: (0.0000) | Acc: (37.00%) (17140/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.6973) |  Loss2: (0.0000) | Acc: (37.00%) (17631/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.6948) |  Loss2: (0.0000) | Acc: (37.00%) (18125/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.6923) |  Loss2: (0.0000) | Acc: (37.00%) (18625/50000)
# TEST : Loss: (1.6097) | Acc: (39.00%) (3981/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
Epoch: 2 | Batch_idx: 0 |  Loss: (1.6669) |  Loss2: (0.0000) | Acc: (37.00%) (48/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.6137) |  Loss2: (0.0000) | Acc: (39.00%) (563/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.5926) |  Loss2: (0.0000) | Acc: (40.00%) (1101/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.5896) |  Loss2: (0.0000) | Acc: (41.00%) (1634/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.5828) |  Loss2: (0.0000) | Acc: (41.00%) (2167/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.5781) |  Loss2: (0.0000) | Acc: (41.00%) (2690/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.5802) |  Loss2: (0.0000) | Acc: (41.00%) (3213/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.5728) |  Loss2: (0.0000) | Acc: (41.00%) (3780/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.5769) |  Loss2: (0.0000) | Acc: (41.00%) (4305/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.5728) |  Loss2: (0.0000) | Acc: (41.00%) (4862/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.5714) |  Loss2: (0.0000) | Acc: (41.00%) (5415/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.5667) |  Loss2: (0.0000) | Acc: (41.00%) (5962/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5682) |  Loss2: (0.0000) | Acc: (41.00%) (6464/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5642) |  Loss2: (0.0000) | Acc: (41.00%) (7022/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5604) |  Loss2: (0.0000) | Acc: (42.00%) (7585/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5572) |  Loss2: (0.0000) | Acc: (42.00%) (8162/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5570) |  Loss2: (0.0000) | Acc: (42.00%) (8712/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5538) |  Loss2: (0.0000) | Acc: (42.00%) (9268/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5515) |  Loss2: (0.0000) | Acc: (42.00%) (9875/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5492) |  Loss2: (0.0000) | Acc: (42.00%) (10430/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5466) |  Loss2: (0.0000) | Acc: (42.00%) (11018/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5445) |  Loss2: (0.0000) | Acc: (42.00%) (11602/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5420) |  Loss2: (0.0000) | Acc: (43.00%) (12173/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5381) |  Loss2: (0.0000) | Acc: (43.00%) (12768/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5359) |  Loss2: (0.0000) | Acc: (43.00%) (13337/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5336) |  Loss2: (0.0000) | Acc: (43.00%) (13930/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5328) |  Loss2: (0.0000) | Acc: (43.00%) (14489/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5311) |  Loss2: (0.0000) | Acc: (43.00%) (15066/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5298) |  Loss2: (0.0000) | Acc: (43.00%) (15634/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5276) |  Loss2: (0.0000) | Acc: (43.00%) (16233/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5249) |  Loss2: (0.0000) | Acc: (43.00%) (16854/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5234) |  Loss2: (0.0000) | Acc: (43.00%) (17427/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5198) |  Loss2: (0.0000) | Acc: (43.00%) (18028/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5179) |  Loss2: (0.0000) | Acc: (43.00%) (18605/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.5159) |  Loss2: (0.0000) | Acc: (44.00%) (19225/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.5142) |  Loss2: (0.0000) | Acc: (44.00%) (19798/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.5117) |  Loss2: (0.0000) | Acc: (44.00%) (20415/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.5101) |  Loss2: (0.0000) | Acc: (44.00%) (20999/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.5083) |  Loss2: (0.0000) | Acc: (44.00%) (21597/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.5066) |  Loss2: (0.0000) | Acc: (44.00%) (22181/50000)
# TEST : Loss: (1.4587) | Acc: (46.00%) (4633/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
Epoch: 3 | Batch_idx: 0 |  Loss: (1.5165) |  Loss2: (0.0000) | Acc: (41.00%) (53/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4312) |  Loss2: (0.0000) | Acc: (47.00%) (674/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.4405) |  Loss2: (0.0000) | Acc: (48.00%) (1303/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.4403) |  Loss2: (0.0000) | Acc: (48.00%) (1918/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.4263) |  Loss2: (0.0000) | Acc: (48.00%) (2557/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.4123) |  Loss2: (0.0000) | Acc: (49.00%) (3224/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4047) |  Loss2: (0.0000) | Acc: (49.00%) (3860/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4084) |  Loss2: (0.0000) | Acc: (49.00%) (4466/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4061) |  Loss2: (0.0000) | Acc: (49.00%) (5092/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4039) |  Loss2: (0.0000) | Acc: (49.00%) (5748/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.4031) |  Loss2: (0.0000) | Acc: (49.00%) (6375/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.4019) |  Loss2: (0.0000) | Acc: (49.00%) (7015/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.4041) |  Loss2: (0.0000) | Acc: (49.00%) (7621/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.4062) |  Loss2: (0.0000) | Acc: (49.00%) (8238/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.4051) |  Loss2: (0.0000) | Acc: (49.00%) (8887/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.4040) |  Loss2: (0.0000) | Acc: (49.00%) (9521/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.4005) |  Loss2: (0.0000) | Acc: (49.00%) (10147/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.4019) |  Loss2: (0.0000) | Acc: (49.00%) (10764/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.3994) |  Loss2: (0.0000) | Acc: (49.00%) (11418/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.3974) |  Loss2: (0.0000) | Acc: (49.00%) (12065/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.3956) |  Loss2: (0.0000) | Acc: (49.00%) (12708/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.3944) |  Loss2: (0.0000) | Acc: (49.00%) (13360/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.3932) |  Loss2: (0.0000) | Acc: (49.00%) (14015/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.3908) |  Loss2: (0.0000) | Acc: (49.00%) (14671/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.3903) |  Loss2: (0.0000) | Acc: (49.00%) (15298/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.3897) |  Loss2: (0.0000) | Acc: (49.00%) (15924/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.3888) |  Loss2: (0.0000) | Acc: (49.00%) (16554/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.3862) |  Loss2: (0.0000) | Acc: (49.00%) (17213/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.3830) |  Loss2: (0.0000) | Acc: (49.00%) (17893/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.3826) |  Loss2: (0.0000) | Acc: (49.00%) (18544/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.3807) |  Loss2: (0.0000) | Acc: (49.00%) (19203/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.3799) |  Loss2: (0.0000) | Acc: (49.00%) (19832/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.3779) |  Loss2: (0.0000) | Acc: (49.00%) (20514/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.3763) |  Loss2: (0.0000) | Acc: (50.00%) (21189/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.3742) |  Loss2: (0.0000) | Acc: (50.00%) (21860/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.3733) |  Loss2: (0.0000) | Acc: (50.00%) (22507/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.3708) |  Loss2: (0.0000) | Acc: (50.00%) (23168/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.3693) |  Loss2: (0.0000) | Acc: (50.00%) (23853/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.3679) |  Loss2: (0.0000) | Acc: (50.00%) (24523/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.3662) |  Loss2: (0.0000) | Acc: (50.00%) (25197/50000)
# TEST : Loss: (1.4956) | Acc: (45.00%) (4532/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
Epoch: 4 | Batch_idx: 0 |  Loss: (1.2041) |  Loss2: (0.0000) | Acc: (54.00%) (70/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.3198) |  Loss2: (0.0000) | Acc: (53.00%) (759/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.3155) |  Loss2: (0.0000) | Acc: (53.00%) (1439/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.3217) |  Loss2: (0.0000) | Acc: (53.00%) (2112/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.3076) |  Loss2: (0.0000) | Acc: (53.00%) (2811/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.3019) |  Loss2: (0.0000) | Acc: (53.00%) (3519/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.2975) |  Loss2: (0.0000) | Acc: (54.00%) (4224/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.2927) |  Loss2: (0.0000) | Acc: (54.00%) (4914/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.2865) |  Loss2: (0.0000) | Acc: (54.00%) (5633/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.2865) |  Loss2: (0.0000) | Acc: (54.00%) (6325/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.2875) |  Loss2: (0.0000) | Acc: (54.00%) (7017/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.2872) |  Loss2: (0.0000) | Acc: (54.00%) (7718/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.2860) |  Loss2: (0.0000) | Acc: (54.00%) (8438/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.2853) |  Loss2: (0.0000) | Acc: (54.00%) (9103/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.2846) |  Loss2: (0.0000) | Acc: (54.00%) (9828/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.2829) |  Loss2: (0.0000) | Acc: (54.00%) (10525/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.2811) |  Loss2: (0.0000) | Acc: (54.00%) (11198/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.2804) |  Loss2: (0.0000) | Acc: (54.00%) (11900/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.2805) |  Loss2: (0.0000) | Acc: (54.00%) (12574/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.2807) |  Loss2: (0.0000) | Acc: (54.00%) (13229/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.2782) |  Loss2: (0.0000) | Acc: (54.00%) (13950/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.2791) |  Loss2: (0.0000) | Acc: (54.00%) (14626/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.2775) |  Loss2: (0.0000) | Acc: (54.00%) (15350/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.2764) |  Loss2: (0.0000) | Acc: (54.00%) (16068/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.2751) |  Loss2: (0.0000) | Acc: (54.00%) (16781/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.2743) |  Loss2: (0.0000) | Acc: (54.00%) (17485/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.2741) |  Loss2: (0.0000) | Acc: (54.00%) (18187/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.2707) |  Loss2: (0.0000) | Acc: (54.00%) (18943/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.2682) |  Loss2: (0.0000) | Acc: (54.00%) (19666/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.2662) |  Loss2: (0.0000) | Acc: (54.00%) (20397/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.2649) |  Loss2: (0.0000) | Acc: (54.00%) (21100/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.2641) |  Loss2: (0.0000) | Acc: (54.00%) (21794/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.2624) |  Loss2: (0.0000) | Acc: (54.00%) (22496/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.2600) |  Loss2: (0.0000) | Acc: (54.00%) (23221/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.2596) |  Loss2: (0.0000) | Acc: (54.00%) (23927/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.2589) |  Loss2: (0.0000) | Acc: (54.00%) (24642/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.2574) |  Loss2: (0.0000) | Acc: (54.00%) (25373/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.2568) |  Loss2: (0.0000) | Acc: (54.00%) (26102/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.2560) |  Loss2: (0.0000) | Acc: (54.00%) (26808/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.2555) |  Loss2: (0.0000) | Acc: (55.00%) (27504/50000)
# TEST : Loss: (1.2115) | Acc: (56.00%) (5649/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 5 | Batch_idx: 0 |  Loss: (1.2093) |  Loss2: (0.0000) | Acc: (56.00%) (72/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.3227) |  Loss2: (0.0000) | Acc: (53.00%) (748/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.4284) |  Loss2: (0.0000) | Acc: (49.00%) (1330/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.4844) |  Loss2: (0.0000) | Acc: (47.00%) (1889/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.5126) |  Loss2: (0.0000) | Acc: (46.00%) (2449/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.5305) |  Loss2: (0.0000) | Acc: (45.00%) (3002/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.5460) |  Loss2: (0.0000) | Acc: (45.00%) (3543/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.5537) |  Loss2: (0.0000) | Acc: (44.00%) (4080/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.5524) |  Loss2: (0.0000) | Acc: (44.00%) (4660/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.5464) |  Loss2: (0.0000) | Acc: (45.00%) (5247/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.5492) |  Loss2: (0.0000) | Acc: (44.00%) (5780/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.5484) |  Loss2: (0.0000) | Acc: (44.00%) (6374/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.5427) |  Loss2: (0.0000) | Acc: (44.00%) (6969/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.5391) |  Loss2: (0.0000) | Acc: (45.00%) (7569/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.5340) |  Loss2: (0.0000) | Acc: (45.00%) (8176/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.5287) |  Loss2: (0.0000) | Acc: (45.00%) (8758/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.5226) |  Loss2: (0.0000) | Acc: (45.00%) (9371/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.5184) |  Loss2: (0.0000) | Acc: (45.00%) (10011/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.5106) |  Loss2: (0.0000) | Acc: (45.00%) (10654/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.5059) |  Loss2: (0.0000) | Acc: (46.00%) (11268/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.5011) |  Loss2: (0.0000) | Acc: (46.00%) (11894/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.4980) |  Loss2: (0.0000) | Acc: (46.00%) (12508/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.4922) |  Loss2: (0.0000) | Acc: (46.00%) (13148/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.4898) |  Loss2: (0.0000) | Acc: (46.00%) (13758/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.4844) |  Loss2: (0.0000) | Acc: (46.00%) (14418/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.4789) |  Loss2: (0.0000) | Acc: (46.00%) (15087/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.4761) |  Loss2: (0.0000) | Acc: (47.00%) (15724/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.4718) |  Loss2: (0.0000) | Acc: (47.00%) (16373/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.4688) |  Loss2: (0.0000) | Acc: (47.00%) (17006/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.4632) |  Loss2: (0.0000) | Acc: (47.00%) (17692/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.4604) |  Loss2: (0.0000) | Acc: (47.00%) (18340/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.4564) |  Loss2: (0.0000) | Acc: (47.00%) (19007/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.4514) |  Loss2: (0.0000) | Acc: (47.00%) (19692/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.4486) |  Loss2: (0.0000) | Acc: (47.00%) (20336/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.4454) |  Loss2: (0.0000) | Acc: (48.00%) (20982/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.4432) |  Loss2: (0.0000) | Acc: (48.00%) (21626/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.4409) |  Loss2: (0.0000) | Acc: (48.00%) (22262/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.4376) |  Loss2: (0.0000) | Acc: (48.00%) (22911/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.4363) |  Loss2: (0.0000) | Acc: (48.00%) (23544/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.4335) |  Loss2: (0.0000) | Acc: (48.00%) (24194/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_005.pth.tar'
# TEST : Loss: (1.3027) | Acc: (52.00%) (5213/10000)
percent tensor([0.5026, 0.5009, 0.5038, 0.5032, 0.5041, 0.5002, 0.5025, 0.5037, 0.5029,
        0.5032, 0.5019, 0.5044, 0.5029, 0.5006, 0.5012, 0.5020],
       device='cuda:0')
percent tensor([0.4907, 0.4852, 0.4780, 0.4847, 0.4778, 0.4817, 0.4808, 0.4818, 0.4897,
        0.4862, 0.4921, 0.4794, 0.4938, 0.4893, 0.4841, 0.4855],
       device='cuda:0')
percent tensor([0.5143, 0.5064, 0.5269, 0.5177, 0.5234, 0.5159, 0.5130, 0.5199, 0.5083,
        0.5114, 0.5073, 0.5217, 0.5096, 0.4968, 0.5129, 0.5134],
       device='cuda:0')
percent tensor([0.4533, 0.4615, 0.4192, 0.4440, 0.4221, 0.4500, 0.4448, 0.4293, 0.4545,
        0.4522, 0.4642, 0.4298, 0.4655, 0.4730, 0.4514, 0.4492],
       device='cuda:0')
percent tensor([0.4752, 0.4858, 0.4733, 0.4758, 0.4734, 0.4639, 0.4794, 0.4711, 0.4894,
        0.4818, 0.4857, 0.4755, 0.4860, 0.4915, 0.4713, 0.4684],
       device='cuda:0')
percent tensor([0.4925, 0.4946, 0.4939, 0.4944, 0.4928, 0.4947, 0.4942, 0.4964, 0.4892,
        0.4930, 0.4901, 0.4917, 0.4837, 0.4918, 0.4965, 0.4971],
       device='cuda:0')
percent tensor([0.5024, 0.5066, 0.4866, 0.4907, 0.4865, 0.5111, 0.4972, 0.4847, 0.5048,
        0.5007, 0.5070, 0.4879, 0.5057, 0.5089, 0.4990, 0.4977],
       device='cuda:0')
percent tensor([0.5338, 0.5228, 0.5306, 0.5395, 0.5319, 0.5505, 0.5202, 0.5247, 0.5252,
        0.5272, 0.5223, 0.5224, 0.5334, 0.5281, 0.5242, 0.5403],
       device='cuda:0')
Epoch: 6 | Batch_idx: 0 |  Loss: (1.2360) |  Loss2: (0.0000) | Acc: (57.00%) (73/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.2834) |  Loss2: (0.0000) | Acc: (51.00%) (731/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.2909) |  Loss2: (0.0000) | Acc: (53.00%) (1428/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.2937) |  Loss2: (0.0000) | Acc: (52.00%) (2101/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.3015) |  Loss2: (0.0000) | Acc: (52.00%) (2766/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.3140) |  Loss2: (0.0000) | Acc: (52.00%) (3395/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.3093) |  Loss2: (0.0000) | Acc: (52.00%) (4061/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.3089) |  Loss2: (0.0000) | Acc: (52.00%) (4734/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.3088) |  Loss2: (0.0000) | Acc: (52.00%) (5422/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.3099) |  Loss2: (0.0000) | Acc: (52.00%) (6097/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.3056) |  Loss2: (0.0000) | Acc: (52.00%) (6804/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.3060) |  Loss2: (0.0000) | Acc: (52.00%) (7494/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.3073) |  Loss2: (0.0000) | Acc: (52.00%) (8185/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.3047) |  Loss2: (0.0000) | Acc: (53.00%) (8888/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.3057) |  Loss2: (0.0000) | Acc: (52.00%) (9533/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.3026) |  Loss2: (0.0000) | Acc: (52.00%) (10212/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.3023) |  Loss2: (0.0000) | Acc: (52.00%) (10883/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.3011) |  Loss2: (0.0000) | Acc: (52.00%) (11562/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.3005) |  Loss2: (0.0000) | Acc: (52.00%) (12235/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.3003) |  Loss2: (0.0000) | Acc: (52.00%) (12904/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.3003) |  Loss2: (0.0000) | Acc: (52.00%) (13579/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.2994) |  Loss2: (0.0000) | Acc: (52.00%) (14261/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.2983) |  Loss2: (0.0000) | Acc: (52.00%) (14939/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.2965) |  Loss2: (0.0000) | Acc: (52.00%) (15621/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.2954) |  Loss2: (0.0000) | Acc: (52.00%) (16326/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.2942) |  Loss2: (0.0000) | Acc: (52.00%) (17027/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.2930) |  Loss2: (0.0000) | Acc: (53.00%) (17717/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.2923) |  Loss2: (0.0000) | Acc: (53.00%) (18401/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.2909) |  Loss2: (0.0000) | Acc: (53.00%) (19114/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.2894) |  Loss2: (0.0000) | Acc: (53.00%) (19798/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.2876) |  Loss2: (0.0000) | Acc: (53.00%) (20528/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.2858) |  Loss2: (0.0000) | Acc: (53.00%) (21260/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.2858) |  Loss2: (0.0000) | Acc: (53.00%) (21936/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.2839) |  Loss2: (0.0000) | Acc: (53.00%) (22649/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.2847) |  Loss2: (0.0000) | Acc: (53.00%) (23326/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.2843) |  Loss2: (0.0000) | Acc: (53.00%) (24007/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.2818) |  Loss2: (0.0000) | Acc: (53.00%) (24730/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.2811) |  Loss2: (0.0000) | Acc: (53.00%) (25414/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.2804) |  Loss2: (0.0000) | Acc: (53.00%) (26137/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.2794) |  Loss2: (0.0000) | Acc: (53.00%) (26819/50000)
# TEST : Loss: (1.2254) | Acc: (55.00%) (5536/10000)
percent tensor([0.5053, 0.5019, 0.5075, 0.5050, 0.5082, 0.5026, 0.5052, 0.5057, 0.5054,
        0.5056, 0.5037, 0.5085, 0.5050, 0.5014, 0.5029, 0.5038],
       device='cuda:0')
percent tensor([0.4951, 0.4872, 0.4772, 0.4820, 0.4795, 0.4735, 0.4834, 0.4840, 0.5035,
        0.4908, 0.5019, 0.4809, 0.5033, 0.4967, 0.4817, 0.4838],
       device='cuda:0')
percent tensor([0.5236, 0.5114, 0.5331, 0.5279, 0.5292, 0.5294, 0.5166, 0.5287, 0.5106,
        0.5151, 0.5114, 0.5249, 0.5156, 0.4997, 0.5221, 0.5244],
       device='cuda:0')
percent tensor([0.4392, 0.4480, 0.3982, 0.4279, 0.4022, 0.4340, 0.4284, 0.4095, 0.4413,
        0.4376, 0.4516, 0.4107, 0.4529, 0.4628, 0.4349, 0.4328],
       device='cuda:0')
percent tensor([0.4611, 0.4729, 0.4737, 0.4709, 0.4722, 0.4445, 0.4717, 0.4668, 0.4854,
        0.4723, 0.4735, 0.4737, 0.4755, 0.4795, 0.4545, 0.4508],
       device='cuda:0')
percent tensor([0.4950, 0.4986, 0.5005, 0.4992, 0.4986, 0.4972, 0.4997, 0.5066, 0.4902,
        0.4979, 0.4911, 0.4972, 0.4818, 0.4930, 0.5034, 0.5044],
       device='cuda:0')
percent tensor([0.5116, 0.5151, 0.5036, 0.5102, 0.5033, 0.5279, 0.5080, 0.5054, 0.5126,
        0.5081, 0.5129, 0.5000, 0.5146, 0.5164, 0.5128, 0.5125],
       device='cuda:0')
percent tensor([0.6620, 0.6334, 0.6899, 0.7153, 0.6994, 0.7202, 0.6276, 0.7236, 0.6418,
        0.6546, 0.6396, 0.6475, 0.6784, 0.6493, 0.6662, 0.7268],
       device='cuda:0')
Epoch: 7 | Batch_idx: 0 |  Loss: (1.1975) |  Loss2: (0.0000) | Acc: (53.00%) (69/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.2610) |  Loss2: (0.0000) | Acc: (54.00%) (766/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.2574) |  Loss2: (0.0000) | Acc: (53.00%) (1432/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.2571) |  Loss2: (0.0000) | Acc: (53.00%) (2114/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.2561) |  Loss2: (0.0000) | Acc: (53.00%) (2812/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.2501) |  Loss2: (0.0000) | Acc: (53.00%) (3520/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.2525) |  Loss2: (0.0000) | Acc: (54.00%) (4225/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.2466) |  Loss2: (0.0000) | Acc: (54.00%) (4938/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.2472) |  Loss2: (0.0000) | Acc: (54.00%) (5630/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.2454) |  Loss2: (0.0000) | Acc: (54.00%) (6343/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (1.2387) |  Loss2: (0.0000) | Acc: (54.00%) (7081/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (1.2375) |  Loss2: (0.0000) | Acc: (54.00%) (7787/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (1.2398) |  Loss2: (0.0000) | Acc: (54.00%) (8471/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (1.2431) |  Loss2: (0.0000) | Acc: (54.00%) (9131/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (1.2420) |  Loss2: (0.0000) | Acc: (54.00%) (9839/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (1.2409) |  Loss2: (0.0000) | Acc: (54.00%) (10538/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (1.2392) |  Loss2: (0.0000) | Acc: (54.00%) (11254/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (1.2370) |  Loss2: (0.0000) | Acc: (54.00%) (11996/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (1.2372) |  Loss2: (0.0000) | Acc: (54.00%) (12694/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (1.2361) |  Loss2: (0.0000) | Acc: (54.00%) (13393/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (1.2354) |  Loss2: (0.0000) | Acc: (54.00%) (14109/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (1.2356) |  Loss2: (0.0000) | Acc: (54.00%) (14805/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (1.2359) |  Loss2: (0.0000) | Acc: (54.00%) (15494/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (1.2358) |  Loss2: (0.0000) | Acc: (54.00%) (16192/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (1.2341) |  Loss2: (0.0000) | Acc: (54.00%) (16929/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (1.2320) |  Loss2: (0.0000) | Acc: (54.00%) (17648/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (1.2313) |  Loss2: (0.0000) | Acc: (54.00%) (18338/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (1.2310) |  Loss2: (0.0000) | Acc: (54.00%) (19054/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (1.2306) |  Loss2: (0.0000) | Acc: (54.00%) (19777/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (1.2317) |  Loss2: (0.0000) | Acc: (54.00%) (20463/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (1.2299) |  Loss2: (0.0000) | Acc: (55.00%) (21192/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (1.2284) |  Loss2: (0.0000) | Acc: (55.00%) (21921/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (1.2276) |  Loss2: (0.0000) | Acc: (55.00%) (22659/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (1.2260) |  Loss2: (0.0000) | Acc: (55.00%) (23413/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (1.2262) |  Loss2: (0.0000) | Acc: (55.00%) (24121/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (1.2256) |  Loss2: (0.0000) | Acc: (55.00%) (24826/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (1.2254) |  Loss2: (0.0000) | Acc: (55.00%) (25533/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (1.2255) |  Loss2: (0.0000) | Acc: (55.00%) (26259/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (1.2262) |  Loss2: (0.0000) | Acc: (55.00%) (26941/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (1.2238) |  Loss2: (0.0000) | Acc: (55.00%) (27683/50000)
# TEST : Loss: (1.2040) | Acc: (56.00%) (5659/10000)
percent tensor([0.5051, 0.5017, 0.5058, 0.5031, 0.5071, 0.5040, 0.5048, 0.5036, 0.5050,
        0.5043, 0.5037, 0.5068, 0.5042, 0.5020, 0.5028, 0.5036],
       device='cuda:0')
percent tensor([0.4983, 0.4882, 0.4744, 0.4786, 0.4791, 0.4689, 0.4851, 0.4849, 0.5158,
        0.4937, 0.5109, 0.4807, 0.5106, 0.5027, 0.4804, 0.4829],
       device='cuda:0')
percent tensor([0.5266, 0.5129, 0.5360, 0.5328, 0.5321, 0.5347, 0.5175, 0.5331, 0.5111,
        0.5158, 0.5118, 0.5258, 0.5172, 0.5003, 0.5256, 0.5285],
       device='cuda:0')
percent tensor([0.4430, 0.4521, 0.4015, 0.4300, 0.4060, 0.4368, 0.4326, 0.4142, 0.4468,
        0.4427, 0.4562, 0.4147, 0.4565, 0.4675, 0.4382, 0.4363],
       device='cuda:0')
percent tensor([0.4561, 0.4658, 0.4827, 0.4761, 0.4794, 0.4410, 0.4716, 0.4743, 0.4840,
        0.4687, 0.4661, 0.4801, 0.4697, 0.4724, 0.4503, 0.4470],
       device='cuda:0')
percent tensor([0.4977, 0.5024, 0.5066, 0.5034, 0.5042, 0.4995, 0.5048, 0.5156, 0.4911,
        0.5024, 0.4926, 0.5021, 0.4804, 0.4944, 0.5093, 0.5110],
       device='cuda:0')
percent tensor([0.5125, 0.5158, 0.5187, 0.5275, 0.5184, 0.5380, 0.5144, 0.5246, 0.5128,
        0.5080, 0.5101, 0.5083, 0.5123, 0.5160, 0.5208, 0.5196],
       device='cuda:0')
percent tensor([0.7561, 0.7168, 0.7949, 0.8300, 0.8087, 0.8305, 0.7136, 0.8415, 0.7243,
        0.7497, 0.7218, 0.7328, 0.7721, 0.7362, 0.7680, 0.8451],
       device='cuda:0')
Epoch: 8 | Batch_idx: 0 |  Loss: (1.1484) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (1.1983) |  Loss2: (0.0000) | Acc: (55.00%) (782/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (1.1995) |  Loss2: (0.0000) | Acc: (55.00%) (1499/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (1.2011) |  Loss2: (0.0000) | Acc: (55.00%) (2209/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (1.2105) |  Loss2: (0.0000) | Acc: (55.00%) (2902/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (1.2085) |  Loss2: (0.0000) | Acc: (55.00%) (3628/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (1.2053) |  Loss2: (0.0000) | Acc: (55.00%) (4354/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (1.2034) |  Loss2: (0.0000) | Acc: (55.00%) (5071/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (1.2084) |  Loss2: (0.0000) | Acc: (55.00%) (5770/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (1.2098) |  Loss2: (0.0000) | Acc: (55.00%) (6492/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (1.2114) |  Loss2: (0.0000) | Acc: (55.00%) (7203/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (1.2085) |  Loss2: (0.0000) | Acc: (55.00%) (7888/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (1.2044) |  Loss2: (0.0000) | Acc: (55.00%) (8634/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (1.2007) |  Loss2: (0.0000) | Acc: (55.00%) (9368/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (1.2023) |  Loss2: (0.0000) | Acc: (55.00%) (10059/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (1.1999) |  Loss2: (0.0000) | Acc: (55.00%) (10801/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (1.1997) |  Loss2: (0.0000) | Acc: (55.00%) (11517/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (1.2012) |  Loss2: (0.0000) | Acc: (55.00%) (12230/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (1.2006) |  Loss2: (0.0000) | Acc: (55.00%) (12964/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (1.2005) |  Loss2: (0.0000) | Acc: (55.00%) (13679/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (1.2008) |  Loss2: (0.0000) | Acc: (56.00%) (14409/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (1.2021) |  Loss2: (0.0000) | Acc: (55.00%) (15109/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (1.2043) |  Loss2: (0.0000) | Acc: (55.00%) (15839/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (1.2055) |  Loss2: (0.0000) | Acc: (55.00%) (16554/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (1.2036) |  Loss2: (0.0000) | Acc: (56.00%) (17276/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (1.2042) |  Loss2: (0.0000) | Acc: (55.00%) (17973/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (1.2045) |  Loss2: (0.0000) | Acc: (55.00%) (18686/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (1.2042) |  Loss2: (0.0000) | Acc: (55.00%) (19412/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (1.2024) |  Loss2: (0.0000) | Acc: (56.00%) (20165/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (1.2022) |  Loss2: (0.0000) | Acc: (56.00%) (20884/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (1.2024) |  Loss2: (0.0000) | Acc: (56.00%) (21635/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (1.2029) |  Loss2: (0.0000) | Acc: (56.00%) (22341/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (1.2034) |  Loss2: (0.0000) | Acc: (56.00%) (23055/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (1.2041) |  Loss2: (0.0000) | Acc: (56.00%) (23748/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (1.2041) |  Loss2: (0.0000) | Acc: (56.00%) (24443/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (1.2041) |  Loss2: (0.0000) | Acc: (55.00%) (25152/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (1.2025) |  Loss2: (0.0000) | Acc: (56.00%) (25915/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (1.2035) |  Loss2: (0.0000) | Acc: (56.00%) (26614/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (1.2042) |  Loss2: (0.0000) | Acc: (56.00%) (27336/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (1.2037) |  Loss2: (0.0000) | Acc: (56.00%) (28033/50000)
# TEST : Loss: (1.1905) | Acc: (57.00%) (5716/10000)
percent tensor([0.5049, 0.5014, 0.5039, 0.5012, 0.5058, 0.5051, 0.5043, 0.5016, 0.5045,
        0.5031, 0.5036, 0.5051, 0.5034, 0.5024, 0.5027, 0.5034],
       device='cuda:0')
percent tensor([0.5018, 0.4894, 0.4737, 0.4777, 0.4805, 0.4700, 0.4875, 0.4870, 0.5256,
        0.4961, 0.5184, 0.4821, 0.5164, 0.5067, 0.4820, 0.4842],
       device='cuda:0')
percent tensor([0.5259, 0.5107, 0.5349, 0.5343, 0.5312, 0.5370, 0.5150, 0.5338, 0.5079,
        0.5126, 0.5081, 0.5231, 0.5147, 0.4983, 0.5256, 0.5293],
       device='cuda:0')
percent tensor([0.4490, 0.4577, 0.4068, 0.4350, 0.4120, 0.4435, 0.4384, 0.4208, 0.4536,
        0.4487, 0.4626, 0.4202, 0.4622, 0.4728, 0.4443, 0.4425],
       device='cuda:0')
percent tensor([0.4583, 0.4640, 0.4933, 0.4859, 0.4880, 0.4476, 0.4745, 0.4840, 0.4851,
        0.4688, 0.4642, 0.4884, 0.4698, 0.4699, 0.4536, 0.4509],
       device='cuda:0')
percent tensor([0.5010, 0.5068, 0.5131, 0.5084, 0.5104, 0.5031, 0.5109, 0.5256, 0.4929,
        0.5076, 0.4948, 0.5076, 0.4800, 0.4967, 0.5160, 0.5183],
       device='cuda:0')
percent tensor([0.5076, 0.5115, 0.5305, 0.5422, 0.5312, 0.5439, 0.5170, 0.5403, 0.5069,
        0.5010, 0.5008, 0.5124, 0.5026, 0.5103, 0.5248, 0.5207],
       device='cuda:0')
percent tensor([0.7816, 0.7396, 0.8375, 0.8709, 0.8531, 0.8676, 0.7458, 0.8848, 0.7486,
        0.7720, 0.7402, 0.7633, 0.7948, 0.7549, 0.8102, 0.8809],
       device='cuda:0')
Epoch: 9 | Batch_idx: 0 |  Loss: (1.1068) |  Loss2: (0.0000) | Acc: (57.00%) (73/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (1.1688) |  Loss2: (0.0000) | Acc: (57.00%) (810/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (1.1963) |  Loss2: (0.0000) | Acc: (56.00%) (1514/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (1.1813) |  Loss2: (0.0000) | Acc: (57.00%) (2266/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (1.1921) |  Loss2: (0.0000) | Acc: (56.00%) (2975/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (1.1870) |  Loss2: (0.0000) | Acc: (56.00%) (3712/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (1.1875) |  Loss2: (0.0000) | Acc: (56.00%) (4428/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (1.1843) |  Loss2: (0.0000) | Acc: (56.00%) (5170/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (1.1819) |  Loss2: (0.0000) | Acc: (56.00%) (5904/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (1.1861) |  Loss2: (0.0000) | Acc: (56.00%) (6610/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (1.1831) |  Loss2: (0.0000) | Acc: (56.00%) (7333/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (1.1814) |  Loss2: (0.0000) | Acc: (56.00%) (8079/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (1.1835) |  Loss2: (0.0000) | Acc: (56.00%) (8774/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (1.1844) |  Loss2: (0.0000) | Acc: (56.00%) (9498/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (1.1834) |  Loss2: (0.0000) | Acc: (56.00%) (10223/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (1.1833) |  Loss2: (0.0000) | Acc: (56.00%) (10970/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (1.1870) |  Loss2: (0.0000) | Acc: (56.00%) (11671/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (1.1862) |  Loss2: (0.0000) | Acc: (56.00%) (12422/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (1.1865) |  Loss2: (0.0000) | Acc: (56.00%) (13149/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (1.1853) |  Loss2: (0.0000) | Acc: (56.00%) (13903/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (1.1867) |  Loss2: (0.0000) | Acc: (56.00%) (14630/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (1.1884) |  Loss2: (0.0000) | Acc: (56.00%) (15342/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (1.1867) |  Loss2: (0.0000) | Acc: (56.00%) (16088/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (1.1863) |  Loss2: (0.0000) | Acc: (56.00%) (16810/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (1.1875) |  Loss2: (0.0000) | Acc: (56.00%) (17531/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (1.1879) |  Loss2: (0.0000) | Acc: (56.00%) (18253/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (1.1879) |  Loss2: (0.0000) | Acc: (56.00%) (18988/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (1.1874) |  Loss2: (0.0000) | Acc: (56.00%) (19712/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (1.1874) |  Loss2: (0.0000) | Acc: (56.00%) (20448/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (1.1873) |  Loss2: (0.0000) | Acc: (56.00%) (21164/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (1.1863) |  Loss2: (0.0000) | Acc: (56.00%) (21892/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (1.1854) |  Loss2: (0.0000) | Acc: (56.00%) (22626/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (1.1861) |  Loss2: (0.0000) | Acc: (56.00%) (23331/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (1.1858) |  Loss2: (0.0000) | Acc: (56.00%) (24066/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (1.1866) |  Loss2: (0.0000) | Acc: (56.00%) (24774/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (1.1869) |  Loss2: (0.0000) | Acc: (56.00%) (25507/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (1.1869) |  Loss2: (0.0000) | Acc: (56.00%) (26236/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (1.1875) |  Loss2: (0.0000) | Acc: (56.00%) (26937/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (1.1883) |  Loss2: (0.0000) | Acc: (56.00%) (27673/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (1.1893) |  Loss2: (0.0000) | Acc: (56.00%) (28336/50000)
# TEST : Loss: (1.1837) | Acc: (57.00%) (5763/10000)
percent tensor([0.5039, 0.4995, 0.5008, 0.4983, 0.5031, 0.5055, 0.5021, 0.4983, 0.5026,
        0.5005, 0.5025, 0.5019, 0.5017, 0.5008, 0.5014, 0.5023],
       device='cuda:0')
percent tensor([0.5061, 0.4919, 0.4753, 0.4797, 0.4840, 0.4749, 0.4913, 0.4911, 0.5335,
        0.4994, 0.5249, 0.4852, 0.5215, 0.5110, 0.4860, 0.4878],
       device='cuda:0')
percent tensor([0.5251, 0.5103, 0.5372, 0.5362, 0.5338, 0.5374, 0.5154, 0.5365, 0.5077,
        0.5119, 0.5060, 0.5241, 0.5129, 0.4979, 0.5256, 0.5293],
       device='cuda:0')
percent tensor([0.4571, 0.4662, 0.4151, 0.4418, 0.4209, 0.4518, 0.4473, 0.4298, 0.4628,
        0.4577, 0.4716, 0.4288, 0.4703, 0.4808, 0.4528, 0.4509],
       device='cuda:0')
percent tensor([0.4605, 0.4617, 0.5026, 0.4952, 0.4958, 0.4555, 0.4766, 0.4929, 0.4846,
        0.4681, 0.4616, 0.4955, 0.4687, 0.4667, 0.4574, 0.4556],
       device='cuda:0')
percent tensor([0.5038, 0.5110, 0.5183, 0.5128, 0.5147, 0.5064, 0.5155, 0.5333, 0.4946,
        0.5125, 0.4963, 0.5112, 0.4791, 0.4993, 0.5212, 0.5248],
       device='cuda:0')
percent tensor([0.5041, 0.5082, 0.5416, 0.5554, 0.5427, 0.5520, 0.5187, 0.5539, 0.5018,
        0.4947, 0.4923, 0.5157, 0.4942, 0.5060, 0.5291, 0.5220],
       device='cuda:0')
percent tensor([0.7984, 0.7495, 0.8643, 0.8945, 0.8802, 0.8896, 0.7653, 0.9072, 0.7593,
        0.7806, 0.7427, 0.7803, 0.8084, 0.7605, 0.8344, 0.9042],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 10 | Batch_idx: 0 |  Loss: (1.1550) |  Loss2: (0.0000) | Acc: (60.00%) (78/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (1.1587) |  Loss2: (0.0000) | Acc: (56.00%) (801/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (1.1673) |  Loss2: (0.0000) | Acc: (56.00%) (1528/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (1.1809) |  Loss2: (0.0000) | Acc: (56.00%) (2245/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (1.1927) |  Loss2: (0.0000) | Acc: (56.00%) (2969/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (1.1783) |  Loss2: (0.0000) | Acc: (57.00%) (3730/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (1.1721) |  Loss2: (0.0000) | Acc: (57.00%) (4491/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (1.1753) |  Loss2: (0.0000) | Acc: (57.00%) (5221/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (1.1715) |  Loss2: (0.0000) | Acc: (57.00%) (5967/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (1.1715) |  Loss2: (0.0000) | Acc: (57.00%) (6718/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (1.1651) |  Loss2: (0.0000) | Acc: (57.00%) (7487/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (1.1670) |  Loss2: (0.0000) | Acc: (57.00%) (8230/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (1.1682) |  Loss2: (0.0000) | Acc: (57.00%) (8974/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (1.1684) |  Loss2: (0.0000) | Acc: (57.00%) (9700/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (1.1660) |  Loss2: (0.0000) | Acc: (57.00%) (10461/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (1.1652) |  Loss2: (0.0000) | Acc: (57.00%) (11210/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (1.1670) |  Loss2: (0.0000) | Acc: (57.00%) (11926/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (1.1644) |  Loss2: (0.0000) | Acc: (57.00%) (12692/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (1.1632) |  Loss2: (0.0000) | Acc: (58.00%) (13449/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (1.1613) |  Loss2: (0.0000) | Acc: (58.00%) (14212/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (1.1584) |  Loss2: (0.0000) | Acc: (58.00%) (14990/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (1.1586) |  Loss2: (0.0000) | Acc: (58.00%) (15699/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (1.1548) |  Loss2: (0.0000) | Acc: (58.00%) (16477/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (1.1519) |  Loss2: (0.0000) | Acc: (58.00%) (17262/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (1.1488) |  Loss2: (0.0000) | Acc: (58.00%) (18046/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (1.1475) |  Loss2: (0.0000) | Acc: (58.00%) (18806/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (1.1472) |  Loss2: (0.0000) | Acc: (58.00%) (19563/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (1.1457) |  Loss2: (0.0000) | Acc: (58.00%) (20326/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (1.1440) |  Loss2: (0.0000) | Acc: (58.00%) (21076/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (1.1419) |  Loss2: (0.0000) | Acc: (58.00%) (21867/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (1.1415) |  Loss2: (0.0000) | Acc: (58.00%) (22618/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (1.1402) |  Loss2: (0.0000) | Acc: (58.00%) (23384/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (1.1393) |  Loss2: (0.0000) | Acc: (58.00%) (24151/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (1.1395) |  Loss2: (0.0000) | Acc: (58.00%) (24900/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (1.1382) |  Loss2: (0.0000) | Acc: (58.00%) (25691/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (1.1365) |  Loss2: (0.0000) | Acc: (58.00%) (26497/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (1.1358) |  Loss2: (0.0000) | Acc: (58.00%) (27244/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (1.1354) |  Loss2: (0.0000) | Acc: (58.00%) (28016/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (1.1346) |  Loss2: (0.0000) | Acc: (59.00%) (28804/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (1.1326) |  Loss2: (0.0000) | Acc: (59.00%) (29559/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_010.pth.tar'
# TEST : Loss: (1.1127) | Acc: (60.00%) (6047/10000)
percent tensor([0.5032, 0.4990, 0.5005, 0.4981, 0.5029, 0.5049, 0.5017, 0.4980, 0.5021,
        0.5001, 0.5018, 0.5018, 0.5009, 0.5006, 0.5009, 0.5017],
       device='cuda:0')
percent tensor([0.5042, 0.4902, 0.4871, 0.4842, 0.4906, 0.4747, 0.4910, 0.4968, 0.5362,
        0.4965, 0.5239, 0.4906, 0.5188, 0.5094, 0.4847, 0.4871],
       device='cuda:0')
percent tensor([0.5284, 0.5133, 0.5367, 0.5389, 0.5364, 0.5395, 0.5184, 0.5384, 0.5098,
        0.5152, 0.5073, 0.5272, 0.5151, 0.5021, 0.5286, 0.5317],
       device='cuda:0')
percent tensor([0.4555, 0.4600, 0.4245, 0.4398, 0.4282, 0.4503, 0.4449, 0.4281, 0.4654,
        0.4545, 0.4678, 0.4314, 0.4689, 0.4716, 0.4467, 0.4472],
       device='cuda:0')
percent tensor([0.4617, 0.4591, 0.5039, 0.4976, 0.4973, 0.4634, 0.4733, 0.4890, 0.4860,
        0.4633, 0.4610, 0.4945, 0.4663, 0.4679, 0.4580, 0.4566],
       device='cuda:0')
percent tensor([0.5088, 0.5131, 0.5212, 0.5179, 0.5177, 0.5037, 0.5199, 0.5325, 0.4960,
        0.5120, 0.4990, 0.5164, 0.4855, 0.5005, 0.5217, 0.5235],
       device='cuda:0')
percent tensor([0.5106, 0.5139, 0.5429, 0.5488, 0.5440, 0.5438, 0.5215, 0.5551, 0.5033,
        0.4970, 0.4982, 0.5263, 0.4960, 0.5162, 0.5372, 0.5219],
       device='cuda:0')
percent tensor([0.7985, 0.7602, 0.8751, 0.8843, 0.8862, 0.8509, 0.8221, 0.9214, 0.7576,
        0.7911, 0.7468, 0.8253, 0.7900, 0.7620, 0.8613, 0.8927],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(164.4261, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(774.3166, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(773.8102, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1525.4279, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(509.4059, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2167.2681, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4328.7798, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1443.9620, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6106.0654, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12246.6084, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4072.5911, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17275.3145, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 11 | Batch_idx: 0 |  Loss: (0.9188) |  Loss2: (0.0000) | Acc: (68.00%) (88/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (1.0324) |  Loss2: (0.0000) | Acc: (63.00%) (896/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (1.0373) |  Loss2: (0.0000) | Acc: (62.00%) (1693/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (1.0481) |  Loss2: (0.0000) | Acc: (63.00%) (2504/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (1.0417) |  Loss2: (0.0000) | Acc: (63.00%) (3331/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (1.0384) |  Loss2: (0.0000) | Acc: (63.00%) (4151/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (1.0386) |  Loss2: (0.0000) | Acc: (63.00%) (4958/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (1.0419) |  Loss2: (0.0000) | Acc: (63.00%) (5736/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (1.0368) |  Loss2: (0.0000) | Acc: (63.00%) (6569/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (1.0382) |  Loss2: (0.0000) | Acc: (63.00%) (7365/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (1.0379) |  Loss2: (0.0000) | Acc: (63.00%) (8160/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (1.0365) |  Loss2: (0.0000) | Acc: (63.00%) (8952/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (1.0373) |  Loss2: (0.0000) | Acc: (63.00%) (9769/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (1.0394) |  Loss2: (0.0000) | Acc: (63.00%) (10567/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (1.0400) |  Loss2: (0.0000) | Acc: (62.00%) (11365/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (1.0416) |  Loss2: (0.0000) | Acc: (62.00%) (12137/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (1.0417) |  Loss2: (0.0000) | Acc: (62.00%) (12944/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (1.0407) |  Loss2: (0.0000) | Acc: (62.00%) (13759/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (1.0403) |  Loss2: (0.0000) | Acc: (62.00%) (14577/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (1.0397) |  Loss2: (0.0000) | Acc: (62.00%) (15389/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (1.0370) |  Loss2: (0.0000) | Acc: (63.00%) (16232/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (1.0366) |  Loss2: (0.0000) | Acc: (63.00%) (17024/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (1.0350) |  Loss2: (0.0000) | Acc: (63.00%) (17842/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (1.0351) |  Loss2: (0.0000) | Acc: (63.00%) (18639/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (1.0351) |  Loss2: (0.0000) | Acc: (63.00%) (19455/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (1.0346) |  Loss2: (0.0000) | Acc: (63.00%) (20261/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (1.0343) |  Loss2: (0.0000) | Acc: (63.00%) (21072/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (1.0336) |  Loss2: (0.0000) | Acc: (63.00%) (21897/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (1.0341) |  Loss2: (0.0000) | Acc: (63.00%) (22684/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (1.0326) |  Loss2: (0.0000) | Acc: (63.00%) (23511/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (1.0333) |  Loss2: (0.0000) | Acc: (63.00%) (24327/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (1.0328) |  Loss2: (0.0000) | Acc: (63.00%) (25149/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (1.0329) |  Loss2: (0.0000) | Acc: (63.00%) (25943/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (1.0331) |  Loss2: (0.0000) | Acc: (63.00%) (26733/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (1.0318) |  Loss2: (0.0000) | Acc: (63.00%) (27575/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (1.0307) |  Loss2: (0.0000) | Acc: (63.00%) (28400/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (1.0297) |  Loss2: (0.0000) | Acc: (63.00%) (29213/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (1.0297) |  Loss2: (0.0000) | Acc: (63.00%) (30018/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (1.0301) |  Loss2: (0.0000) | Acc: (63.00%) (30813/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (1.0310) |  Loss2: (0.0000) | Acc: (63.00%) (31588/50000)
# TEST : Loss: (1.0780) | Acc: (61.00%) (6128/10000)
percent tensor([0.5032, 0.4987, 0.5014, 0.4989, 0.5034, 0.5051, 0.5016, 0.4986, 0.5023,
        0.5003, 0.5017, 0.5024, 0.5009, 0.4999, 0.5008, 0.5019],
       device='cuda:0')
percent tensor([0.4999, 0.4896, 0.4852, 0.4822, 0.4855, 0.4730, 0.4893, 0.4974, 0.5321,
        0.4952, 0.5215, 0.4887, 0.5140, 0.5106, 0.4845, 0.4868],
       device='cuda:0')
percent tensor([0.5271, 0.5103, 0.5358, 0.5394, 0.5355, 0.5374, 0.5164, 0.5373, 0.5116,
        0.5129, 0.5068, 0.5250, 0.5151, 0.4976, 0.5269, 0.5301],
       device='cuda:0')
percent tensor([0.4547, 0.4589, 0.4304, 0.4425, 0.4312, 0.4506, 0.4462, 0.4315, 0.4603,
        0.4552, 0.4645, 0.4368, 0.4664, 0.4730, 0.4474, 0.4495],
       device='cuda:0')
percent tensor([0.4594, 0.4557, 0.5052, 0.5035, 0.4956, 0.4617, 0.4683, 0.4909, 0.4846,
        0.4649, 0.4633, 0.4941, 0.4677, 0.4602, 0.4581, 0.4572],
       device='cuda:0')
percent tensor([0.5055, 0.5095, 0.5156, 0.5142, 0.5165, 0.5029, 0.5177, 0.5292, 0.4946,
        0.5043, 0.4941, 0.5050, 0.4817, 0.4948, 0.5152, 0.5176],
       device='cuda:0')
percent tensor([0.5090, 0.5149, 0.5389, 0.5462, 0.5397, 0.5378, 0.5191, 0.5467, 0.5026,
        0.5005, 0.4976, 0.5240, 0.4960, 0.5108, 0.5322, 0.5169],
       device='cuda:0')
percent tensor([0.8205, 0.7650, 0.8621, 0.8728, 0.8708, 0.8622, 0.8193, 0.8955, 0.7537,
        0.7977, 0.7492, 0.8386, 0.7910, 0.7500, 0.8480, 0.8894],
       device='cuda:0')
Epoch: 12 | Batch_idx: 0 |  Loss: (1.0024) |  Loss2: (0.0000) | Acc: (67.00%) (86/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.9760) |  Loss2: (0.0000) | Acc: (64.00%) (912/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.9763) |  Loss2: (0.0000) | Acc: (65.00%) (1754/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.9735) |  Loss2: (0.0000) | Acc: (65.00%) (2591/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.9768) |  Loss2: (0.0000) | Acc: (65.00%) (3438/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.9725) |  Loss2: (0.0000) | Acc: (65.00%) (4281/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.9734) |  Loss2: (0.0000) | Acc: (65.00%) (5138/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.9700) |  Loss2: (0.0000) | Acc: (65.00%) (5994/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.9705) |  Loss2: (0.0000) | Acc: (65.00%) (6810/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.9705) |  Loss2: (0.0000) | Acc: (65.00%) (7632/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.9729) |  Loss2: (0.0000) | Acc: (65.00%) (8463/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.9714) |  Loss2: (0.0000) | Acc: (65.00%) (9287/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.9712) |  Loss2: (0.0000) | Acc: (65.00%) (10131/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.9739) |  Loss2: (0.0000) | Acc: (65.00%) (10943/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.9742) |  Loss2: (0.0000) | Acc: (65.00%) (11754/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.9746) |  Loss2: (0.0000) | Acc: (65.00%) (12607/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.9737) |  Loss2: (0.0000) | Acc: (65.00%) (13426/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.9719) |  Loss2: (0.0000) | Acc: (65.00%) (14272/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.9737) |  Loss2: (0.0000) | Acc: (65.00%) (15089/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.9754) |  Loss2: (0.0000) | Acc: (65.00%) (15923/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.9753) |  Loss2: (0.0000) | Acc: (65.00%) (16758/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.9715) |  Loss2: (0.0000) | Acc: (65.00%) (17642/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.9702) |  Loss2: (0.0000) | Acc: (65.00%) (18484/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.9705) |  Loss2: (0.0000) | Acc: (65.00%) (19326/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.9704) |  Loss2: (0.0000) | Acc: (65.00%) (20171/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.9694) |  Loss2: (0.0000) | Acc: (65.00%) (21021/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.9712) |  Loss2: (0.0000) | Acc: (65.00%) (21813/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.9694) |  Loss2: (0.0000) | Acc: (65.00%) (22691/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.9679) |  Loss2: (0.0000) | Acc: (65.00%) (23559/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.9671) |  Loss2: (0.0000) | Acc: (65.00%) (24408/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.9660) |  Loss2: (0.0000) | Acc: (65.00%) (25274/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.9655) |  Loss2: (0.0000) | Acc: (65.00%) (26106/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.9655) |  Loss2: (0.0000) | Acc: (65.00%) (26951/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.9651) |  Loss2: (0.0000) | Acc: (65.00%) (27799/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.9642) |  Loss2: (0.0000) | Acc: (65.00%) (28654/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.9630) |  Loss2: (0.0000) | Acc: (65.00%) (29521/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.9613) |  Loss2: (0.0000) | Acc: (65.00%) (30393/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.9604) |  Loss2: (0.0000) | Acc: (65.00%) (31253/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.9590) |  Loss2: (0.0000) | Acc: (65.00%) (32120/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.9580) |  Loss2: (0.0000) | Acc: (65.00%) (32955/50000)
# TEST : Loss: (0.9877) | Acc: (64.00%) (6495/10000)
percent tensor([0.5028, 0.4993, 0.5001, 0.4991, 0.5024, 0.5042, 0.5017, 0.4986, 0.5020,
        0.5002, 0.5018, 0.5013, 0.5008, 0.5016, 0.5007, 0.5020],
       device='cuda:0')
percent tensor([0.4993, 0.4926, 0.4901, 0.4861, 0.4883, 0.4727, 0.4928, 0.5011, 0.5347,
        0.4981, 0.5210, 0.4941, 0.5142, 0.5180, 0.4855, 0.4862],
       device='cuda:0')
percent tensor([0.5277, 0.5094, 0.5338, 0.5387, 0.5343, 0.5374, 0.5161, 0.5354, 0.5108,
        0.5121, 0.5074, 0.5237, 0.5143, 0.4982, 0.5267, 0.5300],
       device='cuda:0')
percent tensor([0.4546, 0.4624, 0.4327, 0.4422, 0.4326, 0.4522, 0.4490, 0.4335, 0.4626,
        0.4596, 0.4659, 0.4404, 0.4683, 0.4784, 0.4471, 0.4492],
       device='cuda:0')
percent tensor([0.4608, 0.4607, 0.5064, 0.5023, 0.4988, 0.4635, 0.4749, 0.4899, 0.4900,
        0.4700, 0.4712, 0.4974, 0.4693, 0.4731, 0.4598, 0.4596],
       device='cuda:0')
percent tensor([0.5080, 0.5095, 0.5154, 0.5150, 0.5172, 0.5016, 0.5185, 0.5291, 0.4992,
        0.5055, 0.4975, 0.5083, 0.4890, 0.5001, 0.5150, 0.5206],
       device='cuda:0')
percent tensor([0.5099, 0.5148, 0.5295, 0.5414, 0.5293, 0.5410, 0.5194, 0.5405, 0.5008,
        0.5009, 0.5046, 0.5192, 0.4962, 0.5141, 0.5309, 0.5195],
       device='cuda:0')
percent tensor([0.8508, 0.7889, 0.8301, 0.8572, 0.8425, 0.8682, 0.8445, 0.8874, 0.7561,
        0.7954, 0.7688, 0.8087, 0.8060, 0.7866, 0.8609, 0.9054],
       device='cuda:0')
Epoch: 13 | Batch_idx: 0 |  Loss: (0.7899) |  Loss2: (0.0000) | Acc: (71.00%) (92/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.9020) |  Loss2: (0.0000) | Acc: (67.00%) (946/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.9187) |  Loss2: (0.0000) | Acc: (66.00%) (1791/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.9020) |  Loss2: (0.0000) | Acc: (67.00%) (2693/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.9066) |  Loss2: (0.0000) | Acc: (67.00%) (3567/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.9015) |  Loss2: (0.0000) | Acc: (68.00%) (4443/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.9068) |  Loss2: (0.0000) | Acc: (67.00%) (5282/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.9038) |  Loss2: (0.0000) | Acc: (67.00%) (6146/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.9077) |  Loss2: (0.0000) | Acc: (67.00%) (7013/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.9060) |  Loss2: (0.0000) | Acc: (67.00%) (7893/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.9083) |  Loss2: (0.0000) | Acc: (67.00%) (8768/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.9136) |  Loss2: (0.0000) | Acc: (67.00%) (9615/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.9104) |  Loss2: (0.0000) | Acc: (67.00%) (10504/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.9082) |  Loss2: (0.0000) | Acc: (67.00%) (11372/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.9121) |  Loss2: (0.0000) | Acc: (67.00%) (12203/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.9100) |  Loss2: (0.0000) | Acc: (67.00%) (13084/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.9088) |  Loss2: (0.0000) | Acc: (67.00%) (13944/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.9106) |  Loss2: (0.0000) | Acc: (67.00%) (14796/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.9100) |  Loss2: (0.0000) | Acc: (67.00%) (15645/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.9089) |  Loss2: (0.0000) | Acc: (67.00%) (16495/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.9120) |  Loss2: (0.0000) | Acc: (67.00%) (17335/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.9107) |  Loss2: (0.0000) | Acc: (67.00%) (18235/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.9122) |  Loss2: (0.0000) | Acc: (67.00%) (19098/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.9102) |  Loss2: (0.0000) | Acc: (67.00%) (19994/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.9122) |  Loss2: (0.0000) | Acc: (67.00%) (20845/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.9129) |  Loss2: (0.0000) | Acc: (67.00%) (21708/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.9111) |  Loss2: (0.0000) | Acc: (67.00%) (22588/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.9113) |  Loss2: (0.0000) | Acc: (67.00%) (23465/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.9131) |  Loss2: (0.0000) | Acc: (67.00%) (24291/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.9120) |  Loss2: (0.0000) | Acc: (67.00%) (25191/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.9115) |  Loss2: (0.0000) | Acc: (67.00%) (26049/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.9108) |  Loss2: (0.0000) | Acc: (67.00%) (26922/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.9094) |  Loss2: (0.0000) | Acc: (67.00%) (27817/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.9080) |  Loss2: (0.0000) | Acc: (67.00%) (28710/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.9079) |  Loss2: (0.0000) | Acc: (67.00%) (29573/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.9070) |  Loss2: (0.0000) | Acc: (67.00%) (30451/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.9069) |  Loss2: (0.0000) | Acc: (67.00%) (31302/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.9066) |  Loss2: (0.0000) | Acc: (67.00%) (32169/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.9050) |  Loss2: (0.0000) | Acc: (67.00%) (33069/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.9047) |  Loss2: (0.0000) | Acc: (67.00%) (33916/50000)
# TEST : Loss: (0.9349) | Acc: (65.00%) (6591/10000)
percent tensor([0.5031, 0.4990, 0.5013, 0.4993, 0.5032, 0.5042, 0.5019, 0.4993, 0.5025,
        0.5006, 0.5019, 0.5025, 0.5011, 0.5010, 0.5005, 0.5021],
       device='cuda:0')
percent tensor([0.5039, 0.4964, 0.4797, 0.4856, 0.4831, 0.4796, 0.4933, 0.4958, 0.5335,
        0.4981, 0.5279, 0.4860, 0.5178, 0.5210, 0.4892, 0.4910],
       device='cuda:0')
percent tensor([0.5254, 0.5072, 0.5329, 0.5365, 0.5346, 0.5371, 0.5153, 0.5341, 0.5105,
        0.5109, 0.5060, 0.5234, 0.5122, 0.4981, 0.5249, 0.5280],
       device='cuda:0')
percent tensor([0.4576, 0.4657, 0.4381, 0.4458, 0.4369, 0.4536, 0.4527, 0.4372, 0.4649,
        0.4620, 0.4696, 0.4448, 0.4715, 0.4796, 0.4483, 0.4518],
       device='cuda:0')
percent tensor([0.4585, 0.4599, 0.4997, 0.4946, 0.4900, 0.4660, 0.4727, 0.4840, 0.4892,
        0.4654, 0.4717, 0.4911, 0.4665, 0.4738, 0.4582, 0.4580],
       device='cuda:0')
percent tensor([0.5093, 0.5065, 0.5133, 0.5146, 0.5161, 0.5071, 0.5164, 0.5310, 0.4981,
        0.5022, 0.4965, 0.5007, 0.4843, 0.5005, 0.5156, 0.5206],
       device='cuda:0')
percent tensor([0.5095, 0.5123, 0.5208, 0.5398, 0.5312, 0.5410, 0.5174, 0.5363, 0.5036,
        0.4996, 0.5016, 0.5141, 0.4968, 0.5159, 0.5268, 0.5198],
       device='cuda:0')
percent tensor([0.8559, 0.7688, 0.8367, 0.8664, 0.8697, 0.8571, 0.8285, 0.8884, 0.7526,
        0.7878, 0.7603, 0.7933, 0.7985, 0.7911, 0.8324, 0.8930],
       device='cuda:0')
Epoch: 14 | Batch_idx: 0 |  Loss: (0.7715) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.8528) |  Loss2: (0.0000) | Acc: (70.00%) (993/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.8632) |  Loss2: (0.0000) | Acc: (69.00%) (1868/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.8720) |  Loss2: (0.0000) | Acc: (68.00%) (2736/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.8712) |  Loss2: (0.0000) | Acc: (68.00%) (3612/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.8657) |  Loss2: (0.0000) | Acc: (69.00%) (4510/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.8659) |  Loss2: (0.0000) | Acc: (69.00%) (5394/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.8615) |  Loss2: (0.0000) | Acc: (69.00%) (6279/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.8634) |  Loss2: (0.0000) | Acc: (68.00%) (7152/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.8622) |  Loss2: (0.0000) | Acc: (69.00%) (8050/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.8673) |  Loss2: (0.0000) | Acc: (68.00%) (8901/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.8631) |  Loss2: (0.0000) | Acc: (68.00%) (9802/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.8619) |  Loss2: (0.0000) | Acc: (69.00%) (10700/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.8619) |  Loss2: (0.0000) | Acc: (69.00%) (11576/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.8575) |  Loss2: (0.0000) | Acc: (69.00%) (12492/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.8589) |  Loss2: (0.0000) | Acc: (69.00%) (13388/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.8555) |  Loss2: (0.0000) | Acc: (69.00%) (14294/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.8515) |  Loss2: (0.0000) | Acc: (69.00%) (15226/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.8545) |  Loss2: (0.0000) | Acc: (69.00%) (16087/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.8526) |  Loss2: (0.0000) | Acc: (69.00%) (17007/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.8528) |  Loss2: (0.0000) | Acc: (69.00%) (17884/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.8543) |  Loss2: (0.0000) | Acc: (69.00%) (18769/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.8537) |  Loss2: (0.0000) | Acc: (69.00%) (19672/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.8537) |  Loss2: (0.0000) | Acc: (69.00%) (20559/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.8531) |  Loss2: (0.0000) | Acc: (69.00%) (21449/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.8537) |  Loss2: (0.0000) | Acc: (69.00%) (22334/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.8534) |  Loss2: (0.0000) | Acc: (69.00%) (23221/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.8523) |  Loss2: (0.0000) | Acc: (69.00%) (24127/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.8512) |  Loss2: (0.0000) | Acc: (69.00%) (25032/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.8511) |  Loss2: (0.0000) | Acc: (69.00%) (25924/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.8513) |  Loss2: (0.0000) | Acc: (69.00%) (26802/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.8519) |  Loss2: (0.0000) | Acc: (69.00%) (27691/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.8520) |  Loss2: (0.0000) | Acc: (69.00%) (28582/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.8515) |  Loss2: (0.0000) | Acc: (69.00%) (29481/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.8523) |  Loss2: (0.0000) | Acc: (69.00%) (30357/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.8530) |  Loss2: (0.0000) | Acc: (69.00%) (31217/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.8536) |  Loss2: (0.0000) | Acc: (69.00%) (32097/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.8525) |  Loss2: (0.0000) | Acc: (69.00%) (33012/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.8523) |  Loss2: (0.0000) | Acc: (69.00%) (33908/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.8526) |  Loss2: (0.0000) | Acc: (69.00%) (34774/50000)
# TEST : Loss: (0.8644) | Acc: (69.00%) (6933/10000)
percent tensor([0.5027, 0.4986, 0.5018, 0.4992, 0.5033, 0.5037, 0.5017, 0.4994, 0.5024,
        0.5004, 0.5015, 0.5026, 0.5008, 0.5008, 0.5001, 0.5017],
       device='cuda:0')
percent tensor([0.5013, 0.4936, 0.4779, 0.4900, 0.4829, 0.4790, 0.4911, 0.4943, 0.5288,
        0.4974, 0.5229, 0.4848, 0.5146, 0.5165, 0.4882, 0.4895],
       device='cuda:0')
percent tensor([0.5280, 0.5106, 0.5344, 0.5376, 0.5342, 0.5377, 0.5173, 0.5364, 0.5126,
        0.5128, 0.5093, 0.5242, 0.5146, 0.4998, 0.5263, 0.5302],
       device='cuda:0')
percent tensor([0.4531, 0.4633, 0.4330, 0.4480, 0.4346, 0.4542, 0.4515, 0.4340, 0.4622,
        0.4578, 0.4653, 0.4377, 0.4673, 0.4830, 0.4460, 0.4503],
       device='cuda:0')
percent tensor([0.4617, 0.4600, 0.4930, 0.4988, 0.4849, 0.4744, 0.4651, 0.4811, 0.4853,
        0.4634, 0.4719, 0.4802, 0.4669, 0.4701, 0.4584, 0.4624],
       device='cuda:0')
percent tensor([0.5146, 0.5061, 0.5207, 0.5180, 0.5192, 0.5040, 0.5169, 0.5290, 0.5016,
        0.5088, 0.4996, 0.5071, 0.4911, 0.4975, 0.5167, 0.5194],
       device='cuda:0')
percent tensor([0.5105, 0.5109, 0.5246, 0.5386, 0.5279, 0.5411, 0.5156, 0.5371, 0.5028,
        0.5019, 0.5048, 0.5155, 0.4986, 0.5141, 0.5228, 0.5174],
       device='cuda:0')
percent tensor([0.8516, 0.7688, 0.8522, 0.8607, 0.8785, 0.8594, 0.8373, 0.8962, 0.7652,
        0.8120, 0.7725, 0.8507, 0.7964, 0.7810, 0.8309, 0.8821],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 15 | Batch_idx: 0 |  Loss: (0.7775) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.8385) |  Loss2: (0.0000) | Acc: (70.00%) (992/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.8935) |  Loss2: (0.0000) | Acc: (68.00%) (1840/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.9285) |  Loss2: (0.0000) | Acc: (68.00%) (2702/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.9634) |  Loss2: (0.0000) | Acc: (66.00%) (3489/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.9809) |  Loss2: (0.0000) | Acc: (65.00%) (4280/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.9856) |  Loss2: (0.0000) | Acc: (65.00%) (5112/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.9936) |  Loss2: (0.0000) | Acc: (65.00%) (5927/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.9974) |  Loss2: (0.0000) | Acc: (65.00%) (6746/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.9970) |  Loss2: (0.0000) | Acc: (65.00%) (7575/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (1.0042) |  Loss2: (0.0000) | Acc: (64.00%) (8374/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.9995) |  Loss2: (0.0000) | Acc: (64.00%) (9209/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.9966) |  Loss2: (0.0000) | Acc: (64.00%) (10062/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (1.0000) |  Loss2: (0.0000) | Acc: (64.00%) (10863/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.9966) |  Loss2: (0.0000) | Acc: (64.00%) (11687/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.9913) |  Loss2: (0.0000) | Acc: (64.00%) (12547/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.9891) |  Loss2: (0.0000) | Acc: (64.00%) (13378/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.9868) |  Loss2: (0.0000) | Acc: (65.00%) (14238/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.9828) |  Loss2: (0.0000) | Acc: (65.00%) (15099/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.9795) |  Loss2: (0.0000) | Acc: (65.00%) (15963/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.9752) |  Loss2: (0.0000) | Acc: (65.00%) (16831/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.9719) |  Loss2: (0.0000) | Acc: (65.00%) (17705/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.9702) |  Loss2: (0.0000) | Acc: (65.00%) (18553/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.9674) |  Loss2: (0.0000) | Acc: (65.00%) (19414/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.9637) |  Loss2: (0.0000) | Acc: (65.00%) (20290/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.9611) |  Loss2: (0.0000) | Acc: (65.00%) (21147/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.9590) |  Loss2: (0.0000) | Acc: (65.00%) (22007/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.9563) |  Loss2: (0.0000) | Acc: (65.00%) (22877/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.9536) |  Loss2: (0.0000) | Acc: (66.00%) (23747/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.9501) |  Loss2: (0.0000) | Acc: (66.00%) (24639/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.9468) |  Loss2: (0.0000) | Acc: (66.00%) (25527/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.9445) |  Loss2: (0.0000) | Acc: (66.00%) (26401/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.9456) |  Loss2: (0.0000) | Acc: (66.00%) (27259/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.9437) |  Loss2: (0.0000) | Acc: (66.00%) (28141/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.9420) |  Loss2: (0.0000) | Acc: (66.00%) (29017/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.9402) |  Loss2: (0.0000) | Acc: (66.00%) (29908/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.9406) |  Loss2: (0.0000) | Acc: (66.00%) (30749/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.9405) |  Loss2: (0.0000) | Acc: (66.00%) (31621/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.9388) |  Loss2: (0.0000) | Acc: (66.00%) (32500/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.9382) |  Loss2: (0.0000) | Acc: (66.00%) (33326/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_015.pth.tar'
# TEST : Loss: (0.8930) | Acc: (68.00%) (6837/10000)
percent tensor([0.5091, 0.5059, 0.5143, 0.5065, 0.5157, 0.5084, 0.5117, 0.5080, 0.5097,
        0.5096, 0.5076, 0.5159, 0.5073, 0.5058, 0.5068, 0.5068],
       device='cuda:0')
percent tensor([0.4910, 0.4816, 0.4274, 0.4685, 0.4345, 0.4693, 0.4612, 0.4638, 0.5179,
        0.4770, 0.5249, 0.4343, 0.5129, 0.5227, 0.4742, 0.4816],
       device='cuda:0')
percent tensor([0.5573, 0.5372, 0.5734, 0.5677, 0.5685, 0.5582, 0.5481, 0.5702, 0.5473,
        0.5464, 0.5425, 0.5618, 0.5466, 0.5199, 0.5505, 0.5566],
       device='cuda:0')
percent tensor([0.4191, 0.4321, 0.4031, 0.4152, 0.4014, 0.4196, 0.4166, 0.3950, 0.4318,
        0.4296, 0.4376, 0.4082, 0.4400, 0.4567, 0.4098, 0.4191],
       device='cuda:0')
percent tensor([0.4619, 0.4545, 0.4973, 0.4975, 0.4894, 0.4724, 0.4593, 0.4772, 0.4851,
        0.4626, 0.4719, 0.4835, 0.4724, 0.4584, 0.4533, 0.4595],
       device='cuda:0')
percent tensor([0.5471, 0.5406, 0.5543, 0.5469, 0.5565, 0.5362, 0.5559, 0.5748, 0.5344,
        0.5446, 0.5284, 0.5413, 0.5189, 0.5200, 0.5592, 0.5570],
       device='cuda:0')
percent tensor([0.5537, 0.5478, 0.5637, 0.5791, 0.5679, 0.5750, 0.5575, 0.5867, 0.5366,
        0.5420, 0.5385, 0.5515, 0.5401, 0.5495, 0.5671, 0.5640],
       device='cuda:0')
percent tensor([0.8974, 0.8201, 0.8825, 0.9095, 0.9100, 0.8875, 0.8830, 0.9410, 0.8020,
        0.8480, 0.8114, 0.8635, 0.8481, 0.8326, 0.8897, 0.9378],
       device='cuda:0')
Epoch: 16 | Batch_idx: 0 |  Loss: (0.9053) |  Loss2: (0.0000) | Acc: (68.00%) (88/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.8825) |  Loss2: (0.0000) | Acc: (68.00%) (960/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.8970) |  Loss2: (0.0000) | Acc: (67.00%) (1824/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.9030) |  Loss2: (0.0000) | Acc: (67.00%) (2679/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.8993) |  Loss2: (0.0000) | Acc: (67.00%) (3549/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.8900) |  Loss2: (0.0000) | Acc: (67.00%) (4438/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.8827) |  Loss2: (0.0000) | Acc: (68.00%) (5330/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.8791) |  Loss2: (0.0000) | Acc: (68.00%) (6221/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.8770) |  Loss2: (0.0000) | Acc: (68.00%) (7121/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.8756) |  Loss2: (0.0000) | Acc: (68.00%) (8016/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.8776) |  Loss2: (0.0000) | Acc: (68.00%) (8889/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.8771) |  Loss2: (0.0000) | Acc: (68.00%) (9769/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.8761) |  Loss2: (0.0000) | Acc: (68.00%) (10657/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.8745) |  Loss2: (0.0000) | Acc: (68.00%) (11542/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.8715) |  Loss2: (0.0000) | Acc: (68.00%) (12445/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.8741) |  Loss2: (0.0000) | Acc: (68.00%) (13313/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.8724) |  Loss2: (0.0000) | Acc: (68.00%) (14199/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.8711) |  Loss2: (0.0000) | Acc: (68.00%) (15099/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.8693) |  Loss2: (0.0000) | Acc: (68.00%) (15977/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.8696) |  Loss2: (0.0000) | Acc: (68.00%) (16862/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.8713) |  Loss2: (0.0000) | Acc: (68.00%) (17718/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.8711) |  Loss2: (0.0000) | Acc: (68.00%) (18608/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.8690) |  Loss2: (0.0000) | Acc: (69.00%) (19523/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.8693) |  Loss2: (0.0000) | Acc: (69.00%) (20402/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.8692) |  Loss2: (0.0000) | Acc: (69.00%) (21288/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.8687) |  Loss2: (0.0000) | Acc: (68.00%) (22161/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.8685) |  Loss2: (0.0000) | Acc: (68.00%) (23050/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.8693) |  Loss2: (0.0000) | Acc: (68.00%) (23914/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.8691) |  Loss2: (0.0000) | Acc: (68.00%) (24796/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.8701) |  Loss2: (0.0000) | Acc: (68.00%) (25682/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.8701) |  Loss2: (0.0000) | Acc: (68.00%) (26560/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.8696) |  Loss2: (0.0000) | Acc: (68.00%) (27440/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.8694) |  Loss2: (0.0000) | Acc: (68.00%) (28350/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.8688) |  Loss2: (0.0000) | Acc: (69.00%) (29246/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.8671) |  Loss2: (0.0000) | Acc: (69.00%) (30158/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.8664) |  Loss2: (0.0000) | Acc: (69.00%) (31041/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.8671) |  Loss2: (0.0000) | Acc: (69.00%) (31911/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.8666) |  Loss2: (0.0000) | Acc: (69.00%) (32784/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.8659) |  Loss2: (0.0000) | Acc: (69.00%) (33675/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.8656) |  Loss2: (0.0000) | Acc: (69.00%) (34526/50000)
# TEST : Loss: (0.8695) | Acc: (69.00%) (6917/10000)
percent tensor([0.5089, 0.5060, 0.5151, 0.5060, 0.5165, 0.5081, 0.5123, 0.5078, 0.5100,
        0.5098, 0.5078, 0.5169, 0.5072, 0.5056, 0.5065, 0.5062],
       device='cuda:0')
percent tensor([0.5057, 0.4892, 0.4202, 0.4772, 0.4302, 0.4891, 0.4627, 0.4667, 0.5305,
        0.4810, 0.5411, 0.4267, 0.5289, 0.5398, 0.4858, 0.4957],
       device='cuda:0')
percent tensor([0.5620, 0.5322, 0.5822, 0.5759, 0.5765, 0.5673, 0.5481, 0.5767, 0.5490,
        0.5444, 0.5422, 0.5663, 0.5474, 0.5107, 0.5528, 0.5608],
       device='cuda:0')
percent tensor([0.4188, 0.4317, 0.4059, 0.4166, 0.4029, 0.4180, 0.4164, 0.3955, 0.4330,
        0.4315, 0.4386, 0.4113, 0.4411, 0.4543, 0.4089, 0.4192],
       device='cuda:0')
percent tensor([0.4641, 0.4567, 0.5049, 0.5056, 0.4962, 0.4781, 0.4620, 0.4819, 0.4899,
        0.4686, 0.4782, 0.4890, 0.4755, 0.4627, 0.4549, 0.4641],
       device='cuda:0')
percent tensor([0.5629, 0.5571, 0.5714, 0.5614, 0.5730, 0.5500, 0.5736, 0.5979, 0.5484,
        0.5628, 0.5434, 0.5560, 0.5331, 0.5303, 0.5788, 0.5761],
       device='cuda:0')
percent tensor([0.5727, 0.5664, 0.5949, 0.6110, 0.6050, 0.5972, 0.5809, 0.6272, 0.5550,
        0.5649, 0.5561, 0.5766, 0.5575, 0.5689, 0.5908, 0.5874],
       device='cuda:0')
percent tensor([0.9374, 0.8752, 0.9252, 0.9438, 0.9462, 0.9276, 0.9282, 0.9669, 0.8609,
        0.9025, 0.8729, 0.9150, 0.8997, 0.8908, 0.9292, 0.9656],
       device='cuda:0')
Epoch: 17 | Batch_idx: 0 |  Loss: (0.8860) |  Loss2: (0.0000) | Acc: (67.00%) (86/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.8543) |  Loss2: (0.0000) | Acc: (70.00%) (986/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.8655) |  Loss2: (0.0000) | Acc: (70.00%) (1882/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.8610) |  Loss2: (0.0000) | Acc: (69.00%) (2768/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.8607) |  Loss2: (0.0000) | Acc: (69.00%) (3658/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.8498) |  Loss2: (0.0000) | Acc: (69.00%) (4561/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.8529) |  Loss2: (0.0000) | Acc: (69.00%) (5448/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.8496) |  Loss2: (0.0000) | Acc: (69.00%) (6327/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.8493) |  Loss2: (0.0000) | Acc: (69.00%) (7212/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.8480) |  Loss2: (0.0000) | Acc: (69.00%) (8128/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.8531) |  Loss2: (0.0000) | Acc: (69.00%) (9003/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.8542) |  Loss2: (0.0000) | Acc: (69.00%) (9892/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.8550) |  Loss2: (0.0000) | Acc: (69.00%) (10783/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.8562) |  Loss2: (0.0000) | Acc: (69.00%) (11657/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.8556) |  Loss2: (0.0000) | Acc: (69.00%) (12557/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.8560) |  Loss2: (0.0000) | Acc: (69.00%) (13442/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.8538) |  Loss2: (0.0000) | Acc: (69.00%) (14343/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.8503) |  Loss2: (0.0000) | Acc: (69.00%) (15267/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.8506) |  Loss2: (0.0000) | Acc: (69.00%) (16163/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.8518) |  Loss2: (0.0000) | Acc: (69.00%) (17048/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.8516) |  Loss2: (0.0000) | Acc: (69.00%) (17949/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.8536) |  Loss2: (0.0000) | Acc: (69.00%) (18812/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.8539) |  Loss2: (0.0000) | Acc: (69.00%) (19688/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.8530) |  Loss2: (0.0000) | Acc: (69.00%) (20581/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.8506) |  Loss2: (0.0000) | Acc: (69.00%) (21502/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.8498) |  Loss2: (0.0000) | Acc: (69.00%) (22405/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.8512) |  Loss2: (0.0000) | Acc: (69.00%) (23291/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.8512) |  Loss2: (0.0000) | Acc: (69.00%) (24178/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.8523) |  Loss2: (0.0000) | Acc: (69.00%) (25058/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.8512) |  Loss2: (0.0000) | Acc: (69.00%) (25970/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.8510) |  Loss2: (0.0000) | Acc: (69.00%) (26866/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.8523) |  Loss2: (0.0000) | Acc: (69.00%) (27725/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.8511) |  Loss2: (0.0000) | Acc: (69.00%) (28638/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.8506) |  Loss2: (0.0000) | Acc: (69.00%) (29533/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.8490) |  Loss2: (0.0000) | Acc: (69.00%) (30451/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.8489) |  Loss2: (0.0000) | Acc: (69.00%) (31352/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.8471) |  Loss2: (0.0000) | Acc: (69.00%) (32276/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.8471) |  Loss2: (0.0000) | Acc: (69.00%) (33181/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.8474) |  Loss2: (0.0000) | Acc: (69.00%) (34064/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.8472) |  Loss2: (0.0000) | Acc: (69.00%) (34940/50000)
# TEST : Loss: (0.8549) | Acc: (69.00%) (6987/10000)
percent tensor([0.5084, 0.5063, 0.5148, 0.5052, 0.5165, 0.5075, 0.5126, 0.5073, 0.5101,
        0.5098, 0.5078, 0.5169, 0.5069, 0.5061, 0.5063, 0.5056],
       device='cuda:0')
percent tensor([0.5163, 0.4936, 0.4240, 0.4849, 0.4348, 0.5043, 0.4664, 0.4718, 0.5382,
        0.4851, 0.5494, 0.4292, 0.5382, 0.5449, 0.4951, 0.5051],
       device='cuda:0')
percent tensor([0.5625, 0.5255, 0.5837, 0.5783, 0.5783, 0.5721, 0.5447, 0.5773, 0.5463,
        0.5387, 0.5382, 0.5650, 0.5444, 0.5018, 0.5521, 0.5609],
       device='cuda:0')
percent tensor([0.4237, 0.4360, 0.4147, 0.4230, 0.4105, 0.4218, 0.4218, 0.4035, 0.4385,
        0.4375, 0.4437, 0.4194, 0.4456, 0.4557, 0.4139, 0.4241],
       device='cuda:0')
percent tensor([0.4691, 0.4619, 0.5122, 0.5140, 0.5028, 0.4862, 0.4668, 0.4877, 0.4964,
        0.4763, 0.4862, 0.4942, 0.4808, 0.4708, 0.4583, 0.4701],
       device='cuda:0')
percent tensor([0.5709, 0.5644, 0.5812, 0.5686, 0.5827, 0.5557, 0.5824, 0.6113, 0.5550,
        0.5719, 0.5499, 0.5635, 0.5389, 0.5318, 0.5883, 0.5862],
       device='cuda:0')
percent tensor([0.5827, 0.5783, 0.6172, 0.6336, 0.6300, 0.6119, 0.5966, 0.6540, 0.5673,
        0.5799, 0.5679, 0.5930, 0.5669, 0.5817, 0.6042, 0.6016],
       device='cuda:0')
percent tensor([0.9570, 0.9030, 0.9480, 0.9617, 0.9638, 0.9471, 0.9500, 0.9792, 0.8936,
        0.9301, 0.9041, 0.9413, 0.9273, 0.9160, 0.9520, 0.9787],
       device='cuda:0')
Epoch: 18 | Batch_idx: 0 |  Loss: (0.7864) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.8517) |  Loss2: (0.0000) | Acc: (70.00%) (990/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.8495) |  Loss2: (0.0000) | Acc: (70.00%) (1890/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.8576) |  Loss2: (0.0000) | Acc: (69.00%) (2769/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.8593) |  Loss2: (0.0000) | Acc: (69.00%) (3646/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.8482) |  Loss2: (0.0000) | Acc: (69.00%) (4561/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.8384) |  Loss2: (0.0000) | Acc: (70.00%) (5494/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.8412) |  Loss2: (0.0000) | Acc: (70.00%) (6381/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.8383) |  Loss2: (0.0000) | Acc: (70.00%) (7291/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.8403) |  Loss2: (0.0000) | Acc: (70.00%) (8175/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.8410) |  Loss2: (0.0000) | Acc: (70.00%) (9061/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.8431) |  Loss2: (0.0000) | Acc: (70.00%) (9949/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.8451) |  Loss2: (0.0000) | Acc: (69.00%) (10836/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.8427) |  Loss2: (0.0000) | Acc: (69.00%) (11731/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.8462) |  Loss2: (0.0000) | Acc: (69.00%) (12604/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.8436) |  Loss2: (0.0000) | Acc: (69.00%) (13521/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.8469) |  Loss2: (0.0000) | Acc: (69.00%) (14398/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.8438) |  Loss2: (0.0000) | Acc: (69.00%) (15303/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.8448) |  Loss2: (0.0000) | Acc: (69.00%) (16179/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.8425) |  Loss2: (0.0000) | Acc: (69.00%) (17095/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.8386) |  Loss2: (0.0000) | Acc: (70.00%) (18027/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.8372) |  Loss2: (0.0000) | Acc: (70.00%) (18934/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.8373) |  Loss2: (0.0000) | Acc: (70.00%) (19849/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.8359) |  Loss2: (0.0000) | Acc: (70.00%) (20767/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.8376) |  Loss2: (0.0000) | Acc: (70.00%) (21640/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.8373) |  Loss2: (0.0000) | Acc: (70.00%) (22531/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.8362) |  Loss2: (0.0000) | Acc: (70.00%) (23424/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.8377) |  Loss2: (0.0000) | Acc: (70.00%) (24320/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.8374) |  Loss2: (0.0000) | Acc: (70.00%) (25222/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.8356) |  Loss2: (0.0000) | Acc: (70.00%) (26125/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.8380) |  Loss2: (0.0000) | Acc: (70.00%) (26991/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.8390) |  Loss2: (0.0000) | Acc: (69.00%) (27861/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.8387) |  Loss2: (0.0000) | Acc: (70.00%) (28763/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.8389) |  Loss2: (0.0000) | Acc: (70.00%) (29670/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.8383) |  Loss2: (0.0000) | Acc: (70.00%) (30576/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.8380) |  Loss2: (0.0000) | Acc: (70.00%) (31490/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.8373) |  Loss2: (0.0000) | Acc: (70.00%) (32417/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.8372) |  Loss2: (0.0000) | Acc: (70.00%) (33312/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.8367) |  Loss2: (0.0000) | Acc: (70.00%) (34220/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.8355) |  Loss2: (0.0000) | Acc: (70.00%) (35107/50000)
# TEST : Loss: (0.8501) | Acc: (70.00%) (7011/10000)
percent tensor([0.5086, 0.5073, 0.5155, 0.5049, 0.5175, 0.5077, 0.5139, 0.5074, 0.5109,
        0.5105, 0.5086, 0.5180, 0.5072, 0.5070, 0.5068, 0.5055],
       device='cuda:0')
percent tensor([0.5186, 0.4935, 0.4259, 0.4869, 0.4371, 0.5102, 0.4670, 0.4725, 0.5385,
        0.4851, 0.5496, 0.4309, 0.5391, 0.5432, 0.4980, 0.5070],
       device='cuda:0')
percent tensor([0.5642, 0.5247, 0.5856, 0.5803, 0.5806, 0.5764, 0.5451, 0.5785, 0.5465,
        0.5379, 0.5388, 0.5656, 0.5446, 0.5000, 0.5537, 0.5627],
       device='cuda:0')
percent tensor([0.4311, 0.4440, 0.4225, 0.4297, 0.4177, 0.4281, 0.4299, 0.4114, 0.4461,
        0.4464, 0.4520, 0.4280, 0.4532, 0.4626, 0.4223, 0.4317],
       device='cuda:0')
percent tensor([0.4759, 0.4704, 0.5185, 0.5210, 0.5090, 0.4933, 0.4739, 0.4938, 0.5034,
        0.4862, 0.4962, 0.5005, 0.4882, 0.4814, 0.4651, 0.4774],
       device='cuda:0')
percent tensor([0.5715, 0.5657, 0.5841, 0.5698, 0.5854, 0.5560, 0.5845, 0.6164, 0.5555,
        0.5741, 0.5504, 0.5651, 0.5380, 0.5290, 0.5901, 0.5886],
       device='cuda:0')
percent tensor([0.5815, 0.5793, 0.6265, 0.6429, 0.6401, 0.6188, 0.5987, 0.6632, 0.5678,
        0.5808, 0.5677, 0.5984, 0.5647, 0.5839, 0.6036, 0.6019],
       device='cuda:0')
percent tensor([0.9688, 0.9215, 0.9612, 0.9722, 0.9732, 0.9606, 0.9628, 0.9851, 0.9153,
        0.9471, 0.9239, 0.9571, 0.9445, 0.9337, 0.9629, 0.9846],
       device='cuda:0')
Epoch: 19 | Batch_idx: 0 |  Loss: (0.6876) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.8187) |  Loss2: (0.0000) | Acc: (70.00%) (996/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.8050) |  Loss2: (0.0000) | Acc: (70.00%) (1896/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.8045) |  Loss2: (0.0000) | Acc: (70.00%) (2815/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.8132) |  Loss2: (0.0000) | Acc: (70.00%) (3719/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.8156) |  Loss2: (0.0000) | Acc: (70.00%) (4630/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.8139) |  Loss2: (0.0000) | Acc: (70.00%) (5534/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.8259) |  Loss2: (0.0000) | Acc: (70.00%) (6399/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.8278) |  Loss2: (0.0000) | Acc: (70.00%) (7295/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.8289) |  Loss2: (0.0000) | Acc: (70.00%) (8185/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.8295) |  Loss2: (0.0000) | Acc: (70.00%) (9082/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.8260) |  Loss2: (0.0000) | Acc: (70.00%) (10001/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.8239) |  Loss2: (0.0000) | Acc: (70.00%) (10909/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.8234) |  Loss2: (0.0000) | Acc: (70.00%) (11793/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.8263) |  Loss2: (0.0000) | Acc: (70.00%) (12687/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.8248) |  Loss2: (0.0000) | Acc: (70.00%) (13594/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.8246) |  Loss2: (0.0000) | Acc: (70.00%) (14513/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.8253) |  Loss2: (0.0000) | Acc: (70.00%) (15420/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.8258) |  Loss2: (0.0000) | Acc: (70.00%) (16327/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.8261) |  Loss2: (0.0000) | Acc: (70.00%) (17212/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.8275) |  Loss2: (0.0000) | Acc: (70.00%) (18115/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.8270) |  Loss2: (0.0000) | Acc: (70.00%) (19025/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.8290) |  Loss2: (0.0000) | Acc: (70.00%) (19910/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.8286) |  Loss2: (0.0000) | Acc: (70.00%) (20805/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.8273) |  Loss2: (0.0000) | Acc: (70.00%) (21732/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.8283) |  Loss2: (0.0000) | Acc: (70.00%) (22627/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.8287) |  Loss2: (0.0000) | Acc: (70.00%) (23521/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.8300) |  Loss2: (0.0000) | Acc: (70.00%) (24386/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.8297) |  Loss2: (0.0000) | Acc: (70.00%) (25298/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.8282) |  Loss2: (0.0000) | Acc: (70.00%) (26218/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.8267) |  Loss2: (0.0000) | Acc: (70.00%) (27137/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.8276) |  Loss2: (0.0000) | Acc: (70.00%) (28021/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.8273) |  Loss2: (0.0000) | Acc: (70.00%) (28930/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.8264) |  Loss2: (0.0000) | Acc: (70.00%) (29842/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.8262) |  Loss2: (0.0000) | Acc: (70.00%) (30744/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.8246) |  Loss2: (0.0000) | Acc: (70.00%) (31675/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.8257) |  Loss2: (0.0000) | Acc: (70.00%) (32546/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.8262) |  Loss2: (0.0000) | Acc: (70.00%) (33431/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.8277) |  Loss2: (0.0000) | Acc: (70.00%) (34300/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.8291) |  Loss2: (0.0000) | Acc: (70.00%) (35145/50000)
# TEST : Loss: (0.8444) | Acc: (70.00%) (7040/10000)
percent tensor([0.5095, 0.5092, 0.5169, 0.5053, 0.5193, 0.5085, 0.5160, 0.5083, 0.5125,
        0.5121, 0.5101, 0.5199, 0.5082, 0.5088, 0.5080, 0.5060],
       device='cuda:0')
percent tensor([0.5200, 0.4923, 0.4280, 0.4882, 0.4394, 0.5146, 0.4669, 0.4730, 0.5371,
        0.4842, 0.5482, 0.4326, 0.5387, 0.5402, 0.4998, 0.5076],
       device='cuda:0')
percent tensor([0.5628, 0.5225, 0.5833, 0.5783, 0.5782, 0.5756, 0.5430, 0.5756, 0.5452,
        0.5357, 0.5378, 0.5634, 0.5431, 0.4983, 0.5523, 0.5613],
       device='cuda:0')
percent tensor([0.4345, 0.4472, 0.4275, 0.4336, 0.4223, 0.4313, 0.4338, 0.4165, 0.4498,
        0.4500, 0.4552, 0.4330, 0.4565, 0.4647, 0.4259, 0.4347],
       device='cuda:0')
percent tensor([0.4768, 0.4721, 0.5173, 0.5213, 0.5082, 0.4973, 0.4741, 0.4916, 0.5044,
        0.4885, 0.4989, 0.4993, 0.4892, 0.4855, 0.4653, 0.4785],
       device='cuda:0')
percent tensor([0.5728, 0.5666, 0.5872, 0.5719, 0.5897, 0.5588, 0.5863, 0.6215, 0.5564,
        0.5758, 0.5499, 0.5656, 0.5366, 0.5268, 0.5932, 0.5922],
       device='cuda:0')
percent tensor([0.5807, 0.5792, 0.6298, 0.6499, 0.6460, 0.6292, 0.5984, 0.6646, 0.5678,
        0.5791, 0.5681, 0.5985, 0.5645, 0.5889, 0.6021, 0.6025],
       device='cuda:0')
percent tensor([0.9746, 0.9325, 0.9671, 0.9765, 0.9784, 0.9675, 0.9689, 0.9881, 0.9283,
        0.9560, 0.9363, 0.9637, 0.9541, 0.9435, 0.9704, 0.9879],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 20 | Batch_idx: 0 |  Loss: (0.7325) |  Loss2: (0.0000) | Acc: (71.00%) (92/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7932) |  Loss2: (0.0000) | Acc: (70.00%) (999/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.8028) |  Loss2: (0.0000) | Acc: (70.00%) (1906/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.8021) |  Loss2: (0.0000) | Acc: (71.00%) (2830/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.8232) |  Loss2: (0.0000) | Acc: (70.00%) (3710/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.8176) |  Loss2: (0.0000) | Acc: (70.00%) (4627/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.8208) |  Loss2: (0.0000) | Acc: (70.00%) (5522/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.8162) |  Loss2: (0.0000) | Acc: (70.00%) (6446/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.8196) |  Loss2: (0.0000) | Acc: (70.00%) (7345/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.8153) |  Loss2: (0.0000) | Acc: (70.00%) (8270/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.8163) |  Loss2: (0.0000) | Acc: (71.00%) (9179/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.8169) |  Loss2: (0.0000) | Acc: (70.00%) (10084/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.8152) |  Loss2: (0.0000) | Acc: (71.00%) (11013/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.8114) |  Loss2: (0.0000) | Acc: (71.00%) (11933/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.8162) |  Loss2: (0.0000) | Acc: (70.00%) (12808/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.8179) |  Loss2: (0.0000) | Acc: (70.00%) (13700/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.8172) |  Loss2: (0.0000) | Acc: (70.00%) (14609/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.8200) |  Loss2: (0.0000) | Acc: (70.00%) (15490/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.8204) |  Loss2: (0.0000) | Acc: (70.00%) (16390/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.8169) |  Loss2: (0.0000) | Acc: (70.00%) (17316/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.8181) |  Loss2: (0.0000) | Acc: (70.00%) (18214/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.8181) |  Loss2: (0.0000) | Acc: (70.00%) (19126/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.8174) |  Loss2: (0.0000) | Acc: (70.00%) (20032/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.8170) |  Loss2: (0.0000) | Acc: (70.00%) (20929/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.8170) |  Loss2: (0.0000) | Acc: (70.00%) (21827/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.8144) |  Loss2: (0.0000) | Acc: (70.00%) (22769/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.8145) |  Loss2: (0.0000) | Acc: (70.00%) (23688/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.8138) |  Loss2: (0.0000) | Acc: (70.00%) (24607/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.8135) |  Loss2: (0.0000) | Acc: (70.00%) (25505/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.8120) |  Loss2: (0.0000) | Acc: (70.00%) (26434/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.8122) |  Loss2: (0.0000) | Acc: (70.00%) (27347/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.8100) |  Loss2: (0.0000) | Acc: (71.00%) (28307/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.8094) |  Loss2: (0.0000) | Acc: (71.00%) (29223/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.8081) |  Loss2: (0.0000) | Acc: (71.00%) (30165/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.8078) |  Loss2: (0.0000) | Acc: (71.00%) (31084/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.8077) |  Loss2: (0.0000) | Acc: (71.00%) (31995/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.8077) |  Loss2: (0.0000) | Acc: (71.00%) (32927/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.8087) |  Loss2: (0.0000) | Acc: (71.00%) (33837/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.8085) |  Loss2: (0.0000) | Acc: (71.00%) (34746/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.8085) |  Loss2: (0.0000) | Acc: (71.00%) (35628/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_020.pth.tar'
# TEST : Loss: (0.8800) | Acc: (69.00%) (6963/10000)
percent tensor([0.5089, 0.5101, 0.5147, 0.5046, 0.5171, 0.5078, 0.5158, 0.5076, 0.5113,
        0.5115, 0.5099, 0.5178, 0.5075, 0.5104, 0.5083, 0.5058],
       device='cuda:0')
percent tensor([0.5183, 0.4847, 0.4696, 0.4900, 0.4698, 0.5071, 0.4790, 0.4811, 0.5435,
        0.4866, 0.5348, 0.4704, 0.5326, 0.5252, 0.4934, 0.4967],
       device='cuda:0')
percent tensor([0.5574, 0.5215, 0.5758, 0.5752, 0.5757, 0.5734, 0.5433, 0.5713, 0.5426,
        0.5375, 0.5366, 0.5587, 0.5352, 0.5078, 0.5509, 0.5593],
       device='cuda:0')
percent tensor([0.4409, 0.4492, 0.4300, 0.4311, 0.4215, 0.4394, 0.4352, 0.4169, 0.4524,
        0.4494, 0.4590, 0.4342, 0.4620, 0.4610, 0.4312, 0.4368],
       device='cuda:0')
percent tensor([0.4791, 0.4767, 0.5152, 0.5174, 0.5028, 0.4949, 0.4783, 0.4925, 0.5108,
        0.4964, 0.5134, 0.4969, 0.4902, 0.5003, 0.4678, 0.4810],
       device='cuda:0')
percent tensor([0.5823, 0.5646, 0.5764, 0.5754, 0.5810, 0.5657, 0.5800, 0.6152, 0.5496,
        0.5669, 0.5452, 0.5643, 0.5355, 0.5427, 0.5953, 0.5950],
       device='cuda:0')
percent tensor([0.5784, 0.5775, 0.6324, 0.6549, 0.6460, 0.6284, 0.6009, 0.6635, 0.5679,
        0.5719, 0.5752, 0.5991, 0.5615, 0.6021, 0.6032, 0.6069],
       device='cuda:0')
percent tensor([0.9823, 0.9280, 0.9761, 0.9778, 0.9822, 0.9713, 0.9672, 0.9868, 0.9255,
        0.9486, 0.9502, 0.9686, 0.9444, 0.9399, 0.9722, 0.9817],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(167.1229, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(782.6270, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(781.0521, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.7543, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(507.4586, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2171.2380, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4316.2803, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1438.6094, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6090.3716, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12197.0322, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4056.3909, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17194.9863, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 21 | Batch_idx: 0 |  Loss: (0.6861) |  Loss2: (0.0000) | Acc: (71.00%) (92/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.7642) |  Loss2: (0.0000) | Acc: (72.00%) (1023/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.7422) |  Loss2: (0.0000) | Acc: (73.00%) (1988/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.7708) |  Loss2: (0.0000) | Acc: (73.00%) (2899/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.7749) |  Loss2: (0.0000) | Acc: (72.00%) (3825/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.7779) |  Loss2: (0.0000) | Acc: (72.00%) (4745/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.7753) |  Loss2: (0.0000) | Acc: (72.00%) (5688/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.7755) |  Loss2: (0.0000) | Acc: (72.00%) (6611/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.7759) |  Loss2: (0.0000) | Acc: (72.00%) (7538/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.7699) |  Loss2: (0.0000) | Acc: (72.00%) (8502/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.7703) |  Loss2: (0.0000) | Acc: (72.00%) (9432/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.7707) |  Loss2: (0.0000) | Acc: (72.00%) (10367/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.7686) |  Loss2: (0.0000) | Acc: (72.00%) (11302/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.7698) |  Loss2: (0.0000) | Acc: (72.00%) (12233/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.7724) |  Loss2: (0.0000) | Acc: (72.00%) (13136/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.7720) |  Loss2: (0.0000) | Acc: (72.00%) (14076/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.7708) |  Loss2: (0.0000) | Acc: (72.00%) (15024/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.7715) |  Loss2: (0.0000) | Acc: (72.00%) (15946/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.7691) |  Loss2: (0.0000) | Acc: (72.00%) (16898/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.7677) |  Loss2: (0.0000) | Acc: (73.00%) (17853/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.7697) |  Loss2: (0.0000) | Acc: (72.00%) (18775/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.7697) |  Loss2: (0.0000) | Acc: (72.00%) (19701/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.7715) |  Loss2: (0.0000) | Acc: (72.00%) (20608/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.7709) |  Loss2: (0.0000) | Acc: (72.00%) (21552/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.7715) |  Loss2: (0.0000) | Acc: (72.00%) (22456/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.7732) |  Loss2: (0.0000) | Acc: (72.00%) (23355/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.7703) |  Loss2: (0.0000) | Acc: (72.00%) (24335/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.7700) |  Loss2: (0.0000) | Acc: (72.00%) (25288/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.7703) |  Loss2: (0.0000) | Acc: (72.00%) (26200/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.7709) |  Loss2: (0.0000) | Acc: (72.00%) (27102/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.7701) |  Loss2: (0.0000) | Acc: (72.00%) (28038/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.7695) |  Loss2: (0.0000) | Acc: (72.00%) (28973/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.7689) |  Loss2: (0.0000) | Acc: (72.00%) (29908/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.7674) |  Loss2: (0.0000) | Acc: (72.00%) (30845/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.7673) |  Loss2: (0.0000) | Acc: (72.00%) (31765/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.7667) |  Loss2: (0.0000) | Acc: (72.00%) (32710/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.7658) |  Loss2: (0.0000) | Acc: (72.00%) (33648/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.7654) |  Loss2: (0.0000) | Acc: (72.00%) (34597/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.7645) |  Loss2: (0.0000) | Acc: (72.00%) (35532/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.7648) |  Loss2: (0.0000) | Acc: (72.00%) (36427/50000)
# TEST : Loss: (0.7759) | Acc: (73.00%) (7300/10000)
percent tensor([0.5089, 0.5102, 0.5152, 0.5048, 0.5177, 0.5078, 0.5159, 0.5077, 0.5114,
        0.5119, 0.5102, 0.5184, 0.5076, 0.5098, 0.5085, 0.5060],
       device='cuda:0')
percent tensor([0.5114, 0.4835, 0.4684, 0.4900, 0.4680, 0.5026, 0.4744, 0.4892, 0.5333,
        0.4834, 0.5264, 0.4666, 0.5233, 0.5234, 0.4931, 0.4932],
       device='cuda:0')
percent tensor([0.5612, 0.5246, 0.5762, 0.5761, 0.5755, 0.5761, 0.5430, 0.5720, 0.5428,
        0.5353, 0.5374, 0.5579, 0.5382, 0.5137, 0.5511, 0.5608],
       device='cuda:0')
percent tensor([0.4380, 0.4463, 0.4272, 0.4316, 0.4213, 0.4399, 0.4312, 0.4167, 0.4479,
        0.4482, 0.4542, 0.4312, 0.4584, 0.4550, 0.4308, 0.4374],
       device='cuda:0')
percent tensor([0.4773, 0.4776, 0.5179, 0.5167, 0.5079, 0.5004, 0.4754, 0.4961, 0.5012,
        0.4889, 0.4978, 0.4987, 0.4823, 0.5005, 0.4724, 0.4831],
       device='cuda:0')
percent tensor([0.5823, 0.5755, 0.5823, 0.5721, 0.5863, 0.5568, 0.5907, 0.6114, 0.5553,
        0.5773, 0.5519, 0.5698, 0.5387, 0.5518, 0.5880, 0.5903],
       device='cuda:0')
percent tensor([0.5804, 0.5752, 0.6337, 0.6502, 0.6494, 0.6191, 0.5995, 0.6588, 0.5740,
        0.5691, 0.5701, 0.5971, 0.5686, 0.6086, 0.6046, 0.5994],
       device='cuda:0')
percent tensor([0.9826, 0.9347, 0.9722, 0.9745, 0.9779, 0.9646, 0.9674, 0.9840, 0.9335,
        0.9570, 0.9510, 0.9682, 0.9622, 0.9536, 0.9718, 0.9805],
       device='cuda:0')
Epoch: 22 | Batch_idx: 0 |  Loss: (0.7907) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.7386) |  Loss2: (0.0000) | Acc: (74.00%) (1051/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.7264) |  Loss2: (0.0000) | Acc: (75.00%) (2023/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.7299) |  Loss2: (0.0000) | Acc: (74.00%) (2953/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.7324) |  Loss2: (0.0000) | Acc: (74.00%) (3905/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.7261) |  Loss2: (0.0000) | Acc: (74.00%) (4876/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.7331) |  Loss2: (0.0000) | Acc: (74.00%) (5808/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.7364) |  Loss2: (0.0000) | Acc: (74.00%) (6735/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.7367) |  Loss2: (0.0000) | Acc: (74.00%) (7695/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.7405) |  Loss2: (0.0000) | Acc: (73.00%) (8616/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.7351) |  Loss2: (0.0000) | Acc: (74.00%) (9597/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.7387) |  Loss2: (0.0000) | Acc: (74.00%) (10534/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.7380) |  Loss2: (0.0000) | Acc: (74.00%) (11488/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.7411) |  Loss2: (0.0000) | Acc: (74.00%) (12412/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.7402) |  Loss2: (0.0000) | Acc: (74.00%) (13367/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.7387) |  Loss2: (0.0000) | Acc: (74.00%) (14322/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.7391) |  Loss2: (0.0000) | Acc: (74.00%) (15259/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.7365) |  Loss2: (0.0000) | Acc: (74.00%) (16228/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.7367) |  Loss2: (0.0000) | Acc: (74.00%) (17170/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.7376) |  Loss2: (0.0000) | Acc: (74.00%) (18117/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.7358) |  Loss2: (0.0000) | Acc: (74.00%) (19064/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.7346) |  Loss2: (0.0000) | Acc: (74.00%) (20024/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.7352) |  Loss2: (0.0000) | Acc: (74.00%) (20962/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.7307) |  Loss2: (0.0000) | Acc: (74.00%) (21951/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.7287) |  Loss2: (0.0000) | Acc: (74.00%) (22939/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.7284) |  Loss2: (0.0000) | Acc: (74.00%) (23902/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.7262) |  Loss2: (0.0000) | Acc: (74.00%) (24889/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.7260) |  Loss2: (0.0000) | Acc: (74.00%) (25844/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.7261) |  Loss2: (0.0000) | Acc: (74.00%) (26795/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.7257) |  Loss2: (0.0000) | Acc: (74.00%) (27754/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.7269) |  Loss2: (0.0000) | Acc: (74.00%) (28694/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.7259) |  Loss2: (0.0000) | Acc: (74.00%) (29669/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.7262) |  Loss2: (0.0000) | Acc: (74.00%) (30604/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.7247) |  Loss2: (0.0000) | Acc: (74.00%) (31590/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.7244) |  Loss2: (0.0000) | Acc: (74.00%) (32548/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.7244) |  Loss2: (0.0000) | Acc: (74.00%) (33516/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.7231) |  Loss2: (0.0000) | Acc: (74.00%) (34491/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.7228) |  Loss2: (0.0000) | Acc: (74.00%) (35448/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.7222) |  Loss2: (0.0000) | Acc: (74.00%) (36395/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.7218) |  Loss2: (0.0000) | Acc: (74.00%) (37319/50000)
# TEST : Loss: (0.7774) | Acc: (73.00%) (7319/10000)
percent tensor([0.5092, 0.5103, 0.5143, 0.5041, 0.5171, 0.5084, 0.5160, 0.5069, 0.5114,
        0.5116, 0.5104, 0.5178, 0.5078, 0.5101, 0.5086, 0.5060],
       device='cuda:0')
percent tensor([0.5076, 0.4836, 0.4549, 0.4827, 0.4595, 0.4991, 0.4743, 0.4791, 0.5329,
        0.4790, 0.5254, 0.4576, 0.5217, 0.5266, 0.4893, 0.4924],
       device='cuda:0')
percent tensor([0.5579, 0.5207, 0.5821, 0.5756, 0.5799, 0.5719, 0.5420, 0.5735, 0.5432,
        0.5395, 0.5372, 0.5641, 0.5362, 0.5036, 0.5485, 0.5579],
       device='cuda:0')
percent tensor([0.4412, 0.4495, 0.4251, 0.4314, 0.4194, 0.4423, 0.4336, 0.4163, 0.4472,
        0.4465, 0.4556, 0.4300, 0.4597, 0.4633, 0.4319, 0.4393],
       device='cuda:0')
percent tensor([0.4734, 0.4745, 0.5151, 0.5077, 0.5056, 0.4900, 0.4749, 0.4897, 0.5011,
        0.4919, 0.5081, 0.4967, 0.4821, 0.4953, 0.4640, 0.4798],
       device='cuda:0')
percent tensor([0.5789, 0.5741, 0.5792, 0.5725, 0.5854, 0.5606, 0.5901, 0.6072, 0.5571,
        0.5739, 0.5540, 0.5673, 0.5421, 0.5484, 0.5910, 0.5883],
       device='cuda:0')
percent tensor([0.5797, 0.5808, 0.6268, 0.6477, 0.6477, 0.6232, 0.6006, 0.6528, 0.5728,
        0.5713, 0.5805, 0.6058, 0.5690, 0.6030, 0.5991, 0.5985],
       device='cuda:0')
percent tensor([0.9817, 0.9429, 0.9745, 0.9770, 0.9770, 0.9675, 0.9710, 0.9859, 0.9358,
        0.9580, 0.9406, 0.9743, 0.9554, 0.9500, 0.9718, 0.9791],
       device='cuda:0')
Epoch: 23 | Batch_idx: 0 |  Loss: (0.6638) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.6594) |  Loss2: (0.0000) | Acc: (76.00%) (1080/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.6882) |  Loss2: (0.0000) | Acc: (75.00%) (2034/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.6811) |  Loss2: (0.0000) | Acc: (76.00%) (3022/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.6728) |  Loss2: (0.0000) | Acc: (76.00%) (4007/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.6809) |  Loss2: (0.0000) | Acc: (76.00%) (4966/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.6803) |  Loss2: (0.0000) | Acc: (75.00%) (5927/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.6803) |  Loss2: (0.0000) | Acc: (75.00%) (6891/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.6850) |  Loss2: (0.0000) | Acc: (75.00%) (7850/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.6868) |  Loss2: (0.0000) | Acc: (75.00%) (8815/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.6856) |  Loss2: (0.0000) | Acc: (75.00%) (9777/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.6892) |  Loss2: (0.0000) | Acc: (75.00%) (10741/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.6856) |  Loss2: (0.0000) | Acc: (75.00%) (11723/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.6854) |  Loss2: (0.0000) | Acc: (75.00%) (12708/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.6834) |  Loss2: (0.0000) | Acc: (75.00%) (13688/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.6846) |  Loss2: (0.0000) | Acc: (75.00%) (14651/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.6835) |  Loss2: (0.0000) | Acc: (75.00%) (15629/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.6829) |  Loss2: (0.0000) | Acc: (75.00%) (16600/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.6840) |  Loss2: (0.0000) | Acc: (75.00%) (17554/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.6841) |  Loss2: (0.0000) | Acc: (75.00%) (18515/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.6844) |  Loss2: (0.0000) | Acc: (75.00%) (19487/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.6843) |  Loss2: (0.0000) | Acc: (75.00%) (20467/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.6844) |  Loss2: (0.0000) | Acc: (75.00%) (21439/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.6844) |  Loss2: (0.0000) | Acc: (75.00%) (22421/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.6869) |  Loss2: (0.0000) | Acc: (75.00%) (23381/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.6856) |  Loss2: (0.0000) | Acc: (75.00%) (24378/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.6824) |  Loss2: (0.0000) | Acc: (75.00%) (25388/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.6829) |  Loss2: (0.0000) | Acc: (75.00%) (26354/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.6831) |  Loss2: (0.0000) | Acc: (75.00%) (27322/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.6844) |  Loss2: (0.0000) | Acc: (75.00%) (28274/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.6851) |  Loss2: (0.0000) | Acc: (75.00%) (29237/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.6830) |  Loss2: (0.0000) | Acc: (75.00%) (30232/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.6828) |  Loss2: (0.0000) | Acc: (75.00%) (31208/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.6820) |  Loss2: (0.0000) | Acc: (75.00%) (32191/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.6829) |  Loss2: (0.0000) | Acc: (75.00%) (33158/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.6837) |  Loss2: (0.0000) | Acc: (75.00%) (34124/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.6824) |  Loss2: (0.0000) | Acc: (76.00%) (35122/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.6834) |  Loss2: (0.0000) | Acc: (76.00%) (36093/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.6838) |  Loss2: (0.0000) | Acc: (75.00%) (37051/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.6843) |  Loss2: (0.0000) | Acc: (75.00%) (37985/50000)
# TEST : Loss: (0.7111) | Acc: (74.00%) (7469/10000)
percent tensor([0.5091, 0.5100, 0.5142, 0.5038, 0.5169, 0.5079, 0.5157, 0.5066, 0.5110,
        0.5116, 0.5102, 0.5179, 0.5076, 0.5095, 0.5083, 0.5058],
       device='cuda:0')
percent tensor([0.5119, 0.4872, 0.4562, 0.4967, 0.4604, 0.5012, 0.4764, 0.4872, 0.5362,
        0.4823, 0.5274, 0.4598, 0.5264, 0.5376, 0.4928, 0.4992],
       device='cuda:0')
percent tensor([0.5606, 0.5214, 0.5811, 0.5745, 0.5791, 0.5718, 0.5422, 0.5725, 0.5427,
        0.5384, 0.5382, 0.5610, 0.5372, 0.5029, 0.5478, 0.5575],
       device='cuda:0')
percent tensor([0.4380, 0.4494, 0.4265, 0.4361, 0.4217, 0.4427, 0.4329, 0.4180, 0.4473,
        0.4466, 0.4526, 0.4324, 0.4582, 0.4626, 0.4321, 0.4402],
       device='cuda:0')
percent tensor([0.4757, 0.4741, 0.5073, 0.5112, 0.5000, 0.4956, 0.4712, 0.4864, 0.5036,
        0.4917, 0.5040, 0.4947, 0.4834, 0.4998, 0.4661, 0.4830],
       device='cuda:0')
percent tensor([0.5797, 0.5706, 0.5763, 0.5676, 0.5819, 0.5614, 0.5888, 0.6034, 0.5584,
        0.5732, 0.5562, 0.5685, 0.5438, 0.5473, 0.5874, 0.5872],
       device='cuda:0')
percent tensor([0.5820, 0.5798, 0.6302, 0.6471, 0.6512, 0.6123, 0.6028, 0.6458, 0.5822,
        0.5754, 0.5840, 0.6078, 0.5764, 0.6081, 0.5972, 0.5914],
       device='cuda:0')
percent tensor([0.9775, 0.9398, 0.9740, 0.9778, 0.9763, 0.9671, 0.9670, 0.9836, 0.9404,
        0.9501, 0.9417, 0.9748, 0.9517, 0.9417, 0.9672, 0.9744],
       device='cuda:0')
Epoch: 24 | Batch_idx: 0 |  Loss: (0.6564) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.6685) |  Loss2: (0.0000) | Acc: (76.00%) (1072/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.6606) |  Loss2: (0.0000) | Acc: (76.00%) (2065/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.6646) |  Loss2: (0.0000) | Acc: (76.00%) (3021/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.6660) |  Loss2: (0.0000) | Acc: (76.00%) (3995/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.6645) |  Loss2: (0.0000) | Acc: (76.00%) (4977/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.6673) |  Loss2: (0.0000) | Acc: (76.00%) (5951/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.6598) |  Loss2: (0.0000) | Acc: (76.00%) (6957/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.6564) |  Loss2: (0.0000) | Acc: (76.00%) (7943/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.6530) |  Loss2: (0.0000) | Acc: (76.00%) (8947/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.6517) |  Loss2: (0.0000) | Acc: (76.00%) (9937/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.6526) |  Loss2: (0.0000) | Acc: (76.00%) (10929/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.6525) |  Loss2: (0.0000) | Acc: (76.00%) (11924/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.6520) |  Loss2: (0.0000) | Acc: (77.00%) (12929/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.6525) |  Loss2: (0.0000) | Acc: (77.00%) (13907/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.6538) |  Loss2: (0.0000) | Acc: (77.00%) (14890/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.6541) |  Loss2: (0.0000) | Acc: (76.00%) (15851/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.6569) |  Loss2: (0.0000) | Acc: (76.00%) (16817/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.6574) |  Loss2: (0.0000) | Acc: (76.00%) (17788/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.6559) |  Loss2: (0.0000) | Acc: (76.00%) (18791/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.6571) |  Loss2: (0.0000) | Acc: (76.00%) (19777/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.6572) |  Loss2: (0.0000) | Acc: (76.00%) (20772/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.6550) |  Loss2: (0.0000) | Acc: (76.00%) (21768/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.6546) |  Loss2: (0.0000) | Acc: (77.00%) (22778/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.6532) |  Loss2: (0.0000) | Acc: (77.00%) (23796/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.6534) |  Loss2: (0.0000) | Acc: (77.00%) (24782/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.6526) |  Loss2: (0.0000) | Acc: (77.00%) (25786/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.6525) |  Loss2: (0.0000) | Acc: (77.00%) (26783/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.6530) |  Loss2: (0.0000) | Acc: (77.00%) (27769/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.6536) |  Loss2: (0.0000) | Acc: (77.00%) (28755/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.6524) |  Loss2: (0.0000) | Acc: (77.00%) (29754/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.6524) |  Loss2: (0.0000) | Acc: (77.00%) (30753/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.6517) |  Loss2: (0.0000) | Acc: (77.00%) (31755/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.6510) |  Loss2: (0.0000) | Acc: (77.00%) (32751/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.6510) |  Loss2: (0.0000) | Acc: (77.00%) (33745/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.6519) |  Loss2: (0.0000) | Acc: (77.00%) (34736/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.6512) |  Loss2: (0.0000) | Acc: (77.00%) (35742/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.6501) |  Loss2: (0.0000) | Acc: (77.00%) (36752/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.6496) |  Loss2: (0.0000) | Acc: (77.00%) (37746/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.6497) |  Loss2: (0.0000) | Acc: (77.00%) (38690/50000)
# TEST : Loss: (0.6996) | Acc: (75.00%) (7527/10000)
percent tensor([0.5089, 0.5102, 0.5121, 0.5033, 0.5150, 0.5079, 0.5151, 0.5060, 0.5105,
        0.5109, 0.5102, 0.5159, 0.5072, 0.5102, 0.5084, 0.5060],
       device='cuda:0')
percent tensor([0.5093, 0.4905, 0.4593, 0.4926, 0.4652, 0.5032, 0.4822, 0.4870, 0.5346,
        0.4842, 0.5287, 0.4661, 0.5231, 0.5338, 0.4938, 0.4970],
       device='cuda:0')
percent tensor([0.5572, 0.5184, 0.5809, 0.5752, 0.5802, 0.5706, 0.5411, 0.5732, 0.5402,
        0.5369, 0.5332, 0.5609, 0.5323, 0.5069, 0.5471, 0.5560],
       device='cuda:0')
percent tensor([0.4387, 0.4526, 0.4290, 0.4356, 0.4213, 0.4456, 0.4356, 0.4178, 0.4488,
        0.4474, 0.4554, 0.4351, 0.4597, 0.4648, 0.4342, 0.4408],
       device='cuda:0')
percent tensor([0.4719, 0.4738, 0.5139, 0.5132, 0.5034, 0.5017, 0.4723, 0.4909, 0.5045,
        0.4911, 0.5064, 0.4970, 0.4776, 0.5061, 0.4674, 0.4819],
       device='cuda:0')
percent tensor([0.5825, 0.5664, 0.5760, 0.5690, 0.5799, 0.5607, 0.5834, 0.6007, 0.5569,
        0.5690, 0.5579, 0.5641, 0.5417, 0.5496, 0.5864, 0.5853],
       device='cuda:0')
percent tensor([0.5821, 0.5713, 0.6267, 0.6473, 0.6460, 0.6143, 0.6050, 0.6447, 0.5830,
        0.5728, 0.5903, 0.6095, 0.5714, 0.6104, 0.5938, 0.5909],
       device='cuda:0')
percent tensor([0.9764, 0.9369, 0.9698, 0.9744, 0.9754, 0.9555, 0.9726, 0.9829, 0.9403,
        0.9487, 0.9466, 0.9731, 0.9487, 0.9502, 0.9615, 0.9720],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 25 | Batch_idx: 0 |  Loss: (0.5951) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.6603) |  Loss2: (0.0000) | Acc: (77.00%) (1098/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.6989) |  Loss2: (0.0000) | Acc: (75.00%) (2035/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.7268) |  Loss2: (0.0000) | Acc: (74.00%) (2972/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.7350) |  Loss2: (0.0000) | Acc: (74.00%) (3914/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.7525) |  Loss2: (0.0000) | Acc: (74.00%) (4842/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.7602) |  Loss2: (0.0000) | Acc: (73.00%) (5754/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.7615) |  Loss2: (0.0000) | Acc: (73.00%) (6682/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.7682) |  Loss2: (0.0000) | Acc: (73.00%) (7594/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.7682) |  Loss2: (0.0000) | Acc: (73.00%) (8552/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.7658) |  Loss2: (0.0000) | Acc: (73.00%) (9497/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.7655) |  Loss2: (0.0000) | Acc: (73.00%) (10447/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.7637) |  Loss2: (0.0000) | Acc: (73.00%) (11392/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.7619) |  Loss2: (0.0000) | Acc: (73.00%) (12329/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.7598) |  Loss2: (0.0000) | Acc: (73.00%) (13279/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.7575) |  Loss2: (0.0000) | Acc: (73.00%) (14232/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.7522) |  Loss2: (0.0000) | Acc: (73.00%) (15211/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.7521) |  Loss2: (0.0000) | Acc: (73.00%) (16146/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.7491) |  Loss2: (0.0000) | Acc: (73.00%) (17110/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.7476) |  Loss2: (0.0000) | Acc: (73.00%) (18066/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.7462) |  Loss2: (0.0000) | Acc: (73.00%) (19021/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.7469) |  Loss2: (0.0000) | Acc: (73.00%) (19959/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.7440) |  Loss2: (0.0000) | Acc: (73.00%) (20926/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.7410) |  Loss2: (0.0000) | Acc: (74.00%) (21902/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.7372) |  Loss2: (0.0000) | Acc: (74.00%) (22891/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.7355) |  Loss2: (0.0000) | Acc: (74.00%) (23870/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.7327) |  Loss2: (0.0000) | Acc: (74.00%) (24851/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.7324) |  Loss2: (0.0000) | Acc: (74.00%) (25817/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.7320) |  Loss2: (0.0000) | Acc: (74.00%) (26773/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.7310) |  Loss2: (0.0000) | Acc: (74.00%) (27749/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.7300) |  Loss2: (0.0000) | Acc: (74.00%) (28729/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.7292) |  Loss2: (0.0000) | Acc: (74.00%) (29694/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.7291) |  Loss2: (0.0000) | Acc: (74.00%) (30637/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.7271) |  Loss2: (0.0000) | Acc: (74.00%) (31607/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.7264) |  Loss2: (0.0000) | Acc: (74.00%) (32573/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.7259) |  Loss2: (0.0000) | Acc: (74.00%) (33533/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.7246) |  Loss2: (0.0000) | Acc: (74.00%) (34515/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.7220) |  Loss2: (0.0000) | Acc: (74.00%) (35505/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.7221) |  Loss2: (0.0000) | Acc: (74.00%) (36453/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.7214) |  Loss2: (0.0000) | Acc: (74.00%) (37390/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_025.pth.tar'
# TEST : Loss: (0.7070) | Acc: (75.00%) (7520/10000)
percent tensor([0.5129, 0.5147, 0.5232, 0.5066, 0.5254, 0.5112, 0.5226, 0.5108, 0.5150,
        0.5174, 0.5145, 0.5274, 0.5115, 0.5102, 0.5129, 0.5079],
       device='cuda:0')
percent tensor([0.5022, 0.4793, 0.4666, 0.4871, 0.4615, 0.4769, 0.4729, 0.4808, 0.5353,
        0.4821, 0.5220, 0.4698, 0.5195, 0.5318, 0.4734, 0.4834],
       device='cuda:0')
percent tensor([0.5659, 0.5051, 0.6264, 0.6059, 0.6220, 0.5644, 0.5513, 0.6146, 0.5695,
        0.5419, 0.5362, 0.5922, 0.5329, 0.4957, 0.5393, 0.5564],
       device='cuda:0')
percent tensor([0.4574, 0.4773, 0.4454, 0.4472, 0.4368, 0.4553, 0.4583, 0.4343, 0.4680,
        0.4770, 0.4804, 0.4588, 0.4849, 0.4870, 0.4538, 0.4567],
       device='cuda:0')
percent tensor([0.4581, 0.4780, 0.5210, 0.5317, 0.4976, 0.5216, 0.4599, 0.4791, 0.5380,
        0.5048, 0.5397, 0.4881, 0.4766, 0.5672, 0.4407, 0.4697],
       device='cuda:0')
percent tensor([0.5482, 0.5388, 0.5376, 0.5382, 0.5449, 0.5435, 0.5473, 0.5575, 0.5316,
        0.5358, 0.5320, 0.5267, 0.5106, 0.5284, 0.5494, 0.5566],
       device='cuda:0')
percent tensor([0.5602, 0.5535, 0.6617, 0.6941, 0.6868, 0.6349, 0.6002, 0.6756, 0.5995,
        0.5616, 0.5846, 0.6191, 0.5357, 0.6227, 0.5789, 0.5845],
       device='cuda:0')
percent tensor([0.9789, 0.9489, 0.9752, 0.9774, 0.9791, 0.9647, 0.9764, 0.9842, 0.9535,
        0.9611, 0.9562, 0.9772, 0.9595, 0.9627, 0.9682, 0.9766],
       device='cuda:0')
Epoch: 26 | Batch_idx: 0 |  Loss: (0.6703) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.6414) |  Loss2: (0.0000) | Acc: (77.00%) (1093/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.6430) |  Loss2: (0.0000) | Acc: (77.00%) (2084/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.6658) |  Loss2: (0.0000) | Acc: (76.00%) (3046/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.6719) |  Loss2: (0.0000) | Acc: (76.00%) (4017/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.6690) |  Loss2: (0.0000) | Acc: (76.00%) (4999/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.6749) |  Loss2: (0.0000) | Acc: (76.00%) (5967/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.6735) |  Loss2: (0.0000) | Acc: (76.00%) (6966/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.6763) |  Loss2: (0.0000) | Acc: (76.00%) (7938/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.6758) |  Loss2: (0.0000) | Acc: (76.00%) (8908/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.6735) |  Loss2: (0.0000) | Acc: (76.00%) (9894/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.6739) |  Loss2: (0.0000) | Acc: (76.00%) (10861/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.6777) |  Loss2: (0.0000) | Acc: (76.00%) (11819/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.6718) |  Loss2: (0.0000) | Acc: (76.00%) (12829/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.6683) |  Loss2: (0.0000) | Acc: (76.00%) (13832/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.6656) |  Loss2: (0.0000) | Acc: (76.00%) (14845/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.6628) |  Loss2: (0.0000) | Acc: (76.00%) (15832/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.6630) |  Loss2: (0.0000) | Acc: (76.00%) (16825/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.6621) |  Loss2: (0.0000) | Acc: (76.00%) (17826/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.6630) |  Loss2: (0.0000) | Acc: (76.00%) (18800/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.6615) |  Loss2: (0.0000) | Acc: (76.00%) (19788/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.6617) |  Loss2: (0.0000) | Acc: (76.00%) (20771/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.6625) |  Loss2: (0.0000) | Acc: (76.00%) (21746/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.6626) |  Loss2: (0.0000) | Acc: (76.00%) (22726/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.6627) |  Loss2: (0.0000) | Acc: (76.00%) (23715/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.6619) |  Loss2: (0.0000) | Acc: (76.00%) (24705/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.6608) |  Loss2: (0.0000) | Acc: (76.00%) (25709/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.6608) |  Loss2: (0.0000) | Acc: (76.00%) (26690/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.6592) |  Loss2: (0.0000) | Acc: (77.00%) (27696/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.6591) |  Loss2: (0.0000) | Acc: (77.00%) (28697/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.6584) |  Loss2: (0.0000) | Acc: (77.00%) (29687/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.6580) |  Loss2: (0.0000) | Acc: (77.00%) (30681/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.6558) |  Loss2: (0.0000) | Acc: (77.00%) (31702/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.6549) |  Loss2: (0.0000) | Acc: (77.00%) (32700/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.6559) |  Loss2: (0.0000) | Acc: (77.00%) (33670/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.6559) |  Loss2: (0.0000) | Acc: (77.00%) (34646/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.6574) |  Loss2: (0.0000) | Acc: (77.00%) (35608/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.6553) |  Loss2: (0.0000) | Acc: (77.00%) (36645/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.6553) |  Loss2: (0.0000) | Acc: (77.00%) (37627/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.6552) |  Loss2: (0.0000) | Acc: (77.00%) (38571/50000)
# TEST : Loss: (0.6690) | Acc: (76.00%) (7664/10000)
percent tensor([0.5117, 0.5160, 0.5238, 0.5048, 0.5262, 0.5101, 0.5241, 0.5099, 0.5147,
        0.5182, 0.5144, 0.5289, 0.5107, 0.5107, 0.5131, 0.5067],
       device='cuda:0')
percent tensor([0.5077, 0.4889, 0.4694, 0.4887, 0.4642, 0.4744, 0.4806, 0.4856, 0.5488,
        0.4920, 0.5335, 0.4769, 0.5296, 0.5467, 0.4758, 0.4871],
       device='cuda:0')
percent tensor([0.5680, 0.4986, 0.6360, 0.6127, 0.6279, 0.5601, 0.5493, 0.6211, 0.5718,
        0.5412, 0.5344, 0.5979, 0.5336, 0.4896, 0.5335, 0.5561],
       device='cuda:0')
percent tensor([0.4633, 0.4877, 0.4470, 0.4475, 0.4381, 0.4581, 0.4659, 0.4374, 0.4756,
        0.4879, 0.4914, 0.4649, 0.4955, 0.4976, 0.4604, 0.4618],
       device='cuda:0')
percent tensor([0.4460, 0.4775, 0.5230, 0.5346, 0.4936, 0.5190, 0.4488, 0.4685, 0.5468,
        0.5082, 0.5540, 0.4766, 0.4732, 0.5891, 0.4223, 0.4573],
       device='cuda:0')
percent tensor([0.5562, 0.5473, 0.5467, 0.5472, 0.5524, 0.5525, 0.5549, 0.5631, 0.5412,
        0.5458, 0.5417, 0.5359, 0.5216, 0.5401, 0.5547, 0.5628],
       device='cuda:0')
percent tensor([0.5569, 0.5534, 0.6924, 0.7214, 0.7164, 0.6417, 0.6063, 0.6978, 0.6099,
        0.5677, 0.5893, 0.6339, 0.5254, 0.6311, 0.5762, 0.5857],
       device='cuda:0')
percent tensor([0.9864, 0.9632, 0.9839, 0.9849, 0.9859, 0.9755, 0.9840, 0.9892, 0.9685,
        0.9738, 0.9694, 0.9854, 0.9719, 0.9745, 0.9776, 0.9839],
       device='cuda:0')
Epoch: 27 | Batch_idx: 0 |  Loss: (0.5562) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.6751) |  Loss2: (0.0000) | Acc: (76.00%) (1080/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.6569) |  Loss2: (0.0000) | Acc: (77.00%) (2086/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.6512) |  Loss2: (0.0000) | Acc: (77.00%) (3091/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.6427) |  Loss2: (0.0000) | Acc: (78.00%) (4098/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.6457) |  Loss2: (0.0000) | Acc: (77.00%) (5082/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.6450) |  Loss2: (0.0000) | Acc: (77.00%) (6082/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.6435) |  Loss2: (0.0000) | Acc: (77.00%) (7079/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.6400) |  Loss2: (0.0000) | Acc: (78.00%) (8097/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.6411) |  Loss2: (0.0000) | Acc: (78.00%) (9091/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.6442) |  Loss2: (0.0000) | Acc: (77.00%) (10063/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.6439) |  Loss2: (0.0000) | Acc: (77.00%) (11061/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.6436) |  Loss2: (0.0000) | Acc: (77.00%) (12051/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.6430) |  Loss2: (0.0000) | Acc: (77.00%) (13043/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.6430) |  Loss2: (0.0000) | Acc: (77.00%) (14029/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.6436) |  Loss2: (0.0000) | Acc: (77.00%) (15025/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.6430) |  Loss2: (0.0000) | Acc: (77.00%) (16011/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.6431) |  Loss2: (0.0000) | Acc: (77.00%) (17000/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.6429) |  Loss2: (0.0000) | Acc: (77.00%) (17985/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.6422) |  Loss2: (0.0000) | Acc: (77.00%) (18996/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.6433) |  Loss2: (0.0000) | Acc: (77.00%) (19985/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.6408) |  Loss2: (0.0000) | Acc: (77.00%) (21009/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.6407) |  Loss2: (0.0000) | Acc: (77.00%) (21996/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.6422) |  Loss2: (0.0000) | Acc: (77.00%) (22977/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.6415) |  Loss2: (0.0000) | Acc: (77.00%) (23980/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.6404) |  Loss2: (0.0000) | Acc: (77.00%) (24992/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.6408) |  Loss2: (0.0000) | Acc: (77.00%) (25979/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.6398) |  Loss2: (0.0000) | Acc: (77.00%) (26995/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.6381) |  Loss2: (0.0000) | Acc: (77.00%) (28018/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.6373) |  Loss2: (0.0000) | Acc: (77.00%) (29031/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.6370) |  Loss2: (0.0000) | Acc: (77.00%) (30033/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.6364) |  Loss2: (0.0000) | Acc: (77.00%) (31034/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.6359) |  Loss2: (0.0000) | Acc: (77.00%) (32023/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.6357) |  Loss2: (0.0000) | Acc: (77.00%) (33014/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.6355) |  Loss2: (0.0000) | Acc: (77.00%) (34007/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.6352) |  Loss2: (0.0000) | Acc: (77.00%) (35002/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.6349) |  Loss2: (0.0000) | Acc: (77.00%) (35996/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.6346) |  Loss2: (0.0000) | Acc: (77.00%) (37002/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.6338) |  Loss2: (0.0000) | Acc: (77.00%) (38023/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.6333) |  Loss2: (0.0000) | Acc: (77.00%) (38995/50000)
# TEST : Loss: (0.6533) | Acc: (77.00%) (7723/10000)
percent tensor([0.5124, 0.5185, 0.5261, 0.5052, 0.5288, 0.5108, 0.5270, 0.5110, 0.5161,
        0.5205, 0.5158, 0.5320, 0.5116, 0.5125, 0.5149, 0.5073],
       device='cuda:0')
percent tensor([0.5055, 0.4889, 0.4628, 0.4834, 0.4590, 0.4692, 0.4791, 0.4820, 0.5500,
        0.4911, 0.5342, 0.4738, 0.5298, 0.5486, 0.4734, 0.4839],
       device='cuda:0')
percent tensor([0.5701, 0.5000, 0.6369, 0.6146, 0.6283, 0.5587, 0.5504, 0.6232, 0.5726,
        0.5437, 0.5360, 0.5991, 0.5360, 0.4908, 0.5335, 0.5582],
       device='cuda:0')
percent tensor([0.4662, 0.4924, 0.4476, 0.4475, 0.4384, 0.4591, 0.4693, 0.4382, 0.4794,
        0.4928, 0.4969, 0.4680, 0.5010, 0.5025, 0.4636, 0.4638],
       device='cuda:0')
percent tensor([0.4415, 0.4800, 0.5172, 0.5301, 0.4910, 0.5108, 0.4476, 0.4639, 0.5451,
        0.5102, 0.5578, 0.4710, 0.4719, 0.5900, 0.4209, 0.4511],
       device='cuda:0')
percent tensor([0.5706, 0.5618, 0.5589, 0.5596, 0.5640, 0.5659, 0.5683, 0.5748, 0.5549,
        0.5611, 0.5572, 0.5503, 0.5386, 0.5566, 0.5683, 0.5753],
       device='cuda:0')
percent tensor([0.5565, 0.5564, 0.7054, 0.7329, 0.7264, 0.6481, 0.6111, 0.7001, 0.6193,
        0.5758, 0.5968, 0.6432, 0.5324, 0.6422, 0.5720, 0.5851],
       device='cuda:0')
percent tensor([0.9904, 0.9723, 0.9878, 0.9888, 0.9892, 0.9815, 0.9880, 0.9921, 0.9770,
        0.9809, 0.9781, 0.9895, 0.9796, 0.9819, 0.9839, 0.9881],
       device='cuda:0')
Epoch: 28 | Batch_idx: 0 |  Loss: (0.5487) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.6341) |  Loss2: (0.0000) | Acc: (77.00%) (1098/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.6239) |  Loss2: (0.0000) | Acc: (77.00%) (2095/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.6186) |  Loss2: (0.0000) | Acc: (77.00%) (3091/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.6117) |  Loss2: (0.0000) | Acc: (78.00%) (4122/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.6175) |  Loss2: (0.0000) | Acc: (78.00%) (5105/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.6245) |  Loss2: (0.0000) | Acc: (77.00%) (6089/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.6204) |  Loss2: (0.0000) | Acc: (78.00%) (7111/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.6174) |  Loss2: (0.0000) | Acc: (78.00%) (8128/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.6156) |  Loss2: (0.0000) | Acc: (78.00%) (9144/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.6141) |  Loss2: (0.0000) | Acc: (78.00%) (10155/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.6162) |  Loss2: (0.0000) | Acc: (78.00%) (11164/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.6197) |  Loss2: (0.0000) | Acc: (78.00%) (12160/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.6198) |  Loss2: (0.0000) | Acc: (78.00%) (13159/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.6230) |  Loss2: (0.0000) | Acc: (78.00%) (14143/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.6233) |  Loss2: (0.0000) | Acc: (78.00%) (15139/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.6247) |  Loss2: (0.0000) | Acc: (78.00%) (16118/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.6227) |  Loss2: (0.0000) | Acc: (78.00%) (17147/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.6217) |  Loss2: (0.0000) | Acc: (78.00%) (18145/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.6213) |  Loss2: (0.0000) | Acc: (78.00%) (19142/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.6222) |  Loss2: (0.0000) | Acc: (78.00%) (20140/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.6227) |  Loss2: (0.0000) | Acc: (78.00%) (21150/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.6235) |  Loss2: (0.0000) | Acc: (78.00%) (22124/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (23102/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.6241) |  Loss2: (0.0000) | Acc: (78.00%) (24106/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.6228) |  Loss2: (0.0000) | Acc: (78.00%) (25126/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.6233) |  Loss2: (0.0000) | Acc: (78.00%) (26123/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.6237) |  Loss2: (0.0000) | Acc: (78.00%) (27110/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.6229) |  Loss2: (0.0000) | Acc: (78.00%) (28120/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.6245) |  Loss2: (0.0000) | Acc: (78.00%) (29092/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.6241) |  Loss2: (0.0000) | Acc: (78.00%) (30086/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.6239) |  Loss2: (0.0000) | Acc: (78.00%) (31097/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (32084/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.6270) |  Loss2: (0.0000) | Acc: (78.00%) (33049/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.6262) |  Loss2: (0.0000) | Acc: (78.00%) (34057/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.6253) |  Loss2: (0.0000) | Acc: (78.00%) (35075/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.6249) |  Loss2: (0.0000) | Acc: (78.00%) (36073/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.6250) |  Loss2: (0.0000) | Acc: (78.00%) (37061/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.6245) |  Loss2: (0.0000) | Acc: (78.00%) (38070/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.6241) |  Loss2: (0.0000) | Acc: (78.00%) (39025/50000)
# TEST : Loss: (0.6472) | Acc: (77.00%) (7729/10000)
percent tensor([0.5126, 0.5200, 0.5272, 0.5050, 0.5301, 0.5107, 0.5287, 0.5114, 0.5166,
        0.5218, 0.5165, 0.5336, 0.5120, 0.5136, 0.5156, 0.5075],
       device='cuda:0')
percent tensor([0.5053, 0.4899, 0.4594, 0.4820, 0.4568, 0.4681, 0.4793, 0.4809, 0.5502,
        0.4919, 0.5355, 0.4727, 0.5302, 0.5499, 0.4737, 0.4844],
       device='cuda:0')
percent tensor([0.5690, 0.5008, 0.6324, 0.6120, 0.6242, 0.5562, 0.5493, 0.6197, 0.5705,
        0.5433, 0.5355, 0.5953, 0.5358, 0.4928, 0.5322, 0.5583],
       device='cuda:0')
percent tensor([0.4694, 0.4968, 0.4486, 0.4484, 0.4391, 0.4609, 0.4726, 0.4395, 0.4823,
        0.4973, 0.5017, 0.4710, 0.5057, 0.5065, 0.4669, 0.4665],
       device='cuda:0')
percent tensor([0.4404, 0.4787, 0.5134, 0.5274, 0.4907, 0.5085, 0.4460, 0.4604, 0.5425,
        0.5099, 0.5581, 0.4655, 0.4698, 0.5844, 0.4203, 0.4513],
       device='cuda:0')
percent tensor([0.5840, 0.5754, 0.5704, 0.5714, 0.5755, 0.5798, 0.5812, 0.5855, 0.5683,
        0.5748, 0.5713, 0.5631, 0.5543, 0.5720, 0.5813, 0.5882],
       device='cuda:0')
percent tensor([0.5644, 0.5655, 0.7157, 0.7396, 0.7353, 0.6506, 0.6200, 0.7067, 0.6321,
        0.5891, 0.6073, 0.6549, 0.5440, 0.6507, 0.5759, 0.5896],
       device='cuda:0')
percent tensor([0.9932, 0.9792, 0.9909, 0.9914, 0.9917, 0.9861, 0.9912, 0.9938, 0.9834,
        0.9860, 0.9839, 0.9925, 0.9851, 0.9870, 0.9873, 0.9913],
       device='cuda:0')
Epoch: 29 | Batch_idx: 0 |  Loss: (0.6280) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.6281) |  Loss2: (0.0000) | Acc: (77.00%) (1089/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.6243) |  Loss2: (0.0000) | Acc: (77.00%) (2075/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.6389) |  Loss2: (0.0000) | Acc: (76.00%) (3053/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.6326) |  Loss2: (0.0000) | Acc: (77.00%) (4068/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.6264) |  Loss2: (0.0000) | Acc: (77.00%) (5082/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.6242) |  Loss2: (0.0000) | Acc: (78.00%) (6107/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.6279) |  Loss2: (0.0000) | Acc: (77.00%) (7079/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.6294) |  Loss2: (0.0000) | Acc: (77.00%) (8078/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.6284) |  Loss2: (0.0000) | Acc: (77.00%) (9075/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.6300) |  Loss2: (0.0000) | Acc: (78.00%) (10086/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.6285) |  Loss2: (0.0000) | Acc: (77.00%) (11078/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.6272) |  Loss2: (0.0000) | Acc: (78.00%) (12091/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.6229) |  Loss2: (0.0000) | Acc: (78.00%) (13125/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.6258) |  Loss2: (0.0000) | Acc: (78.00%) (14109/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.6260) |  Loss2: (0.0000) | Acc: (78.00%) (15102/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.6263) |  Loss2: (0.0000) | Acc: (78.00%) (16087/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.6252) |  Loss2: (0.0000) | Acc: (78.00%) (17083/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.6240) |  Loss2: (0.0000) | Acc: (78.00%) (18102/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.6233) |  Loss2: (0.0000) | Acc: (78.00%) (19112/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.6236) |  Loss2: (0.0000) | Acc: (78.00%) (20123/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.6245) |  Loss2: (0.0000) | Acc: (78.00%) (21125/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.6237) |  Loss2: (0.0000) | Acc: (78.00%) (22141/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.6242) |  Loss2: (0.0000) | Acc: (78.00%) (23139/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.6237) |  Loss2: (0.0000) | Acc: (78.00%) (24144/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.6226) |  Loss2: (0.0000) | Acc: (78.00%) (25167/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.6214) |  Loss2: (0.0000) | Acc: (78.00%) (26195/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.6220) |  Loss2: (0.0000) | Acc: (78.00%) (27202/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.6217) |  Loss2: (0.0000) | Acc: (78.00%) (28203/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.6228) |  Loss2: (0.0000) | Acc: (78.00%) (29192/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.6224) |  Loss2: (0.0000) | Acc: (78.00%) (30196/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.6225) |  Loss2: (0.0000) | Acc: (78.00%) (31195/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.6212) |  Loss2: (0.0000) | Acc: (78.00%) (32208/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.6213) |  Loss2: (0.0000) | Acc: (78.00%) (33192/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.6195) |  Loss2: (0.0000) | Acc: (78.00%) (34230/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.6193) |  Loss2: (0.0000) | Acc: (78.00%) (35252/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.6199) |  Loss2: (0.0000) | Acc: (78.00%) (36246/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.6187) |  Loss2: (0.0000) | Acc: (78.00%) (37284/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.6190) |  Loss2: (0.0000) | Acc: (78.00%) (38272/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.6188) |  Loss2: (0.0000) | Acc: (78.00%) (39238/50000)
# TEST : Loss: (0.6448) | Acc: (77.00%) (7739/10000)
percent tensor([0.5144, 0.5230, 0.5309, 0.5066, 0.5339, 0.5122, 0.5325, 0.5137, 0.5191,
        0.5250, 0.5188, 0.5381, 0.5140, 0.5157, 0.5180, 0.5090],
       device='cuda:0')
percent tensor([0.5074, 0.4936, 0.4606, 0.4822, 0.4588, 0.4687, 0.4827, 0.4827, 0.5531,
        0.4955, 0.5390, 0.4756, 0.5332, 0.5530, 0.4761, 0.4864],
       device='cuda:0')
percent tensor([0.5696, 0.5011, 0.6317, 0.6113, 0.6237, 0.5543, 0.5495, 0.6196, 0.5708,
        0.5443, 0.5362, 0.5947, 0.5367, 0.4928, 0.5311, 0.5590],
       device='cuda:0')
percent tensor([0.4670, 0.4948, 0.4465, 0.4458, 0.4367, 0.4581, 0.4702, 0.4367, 0.4805,
        0.4952, 0.5000, 0.4691, 0.5040, 0.5041, 0.4645, 0.4639],
       device='cuda:0')
percent tensor([0.4428, 0.4800, 0.5192, 0.5322, 0.4986, 0.5092, 0.4487, 0.4669, 0.5422,
        0.5088, 0.5551, 0.4686, 0.4705, 0.5766, 0.4258, 0.4523],
       device='cuda:0')
percent tensor([0.5832, 0.5749, 0.5720, 0.5733, 0.5767, 0.5826, 0.5803, 0.5847, 0.5695,
        0.5743, 0.5718, 0.5641, 0.5556, 0.5734, 0.5807, 0.5879],
       device='cuda:0')
percent tensor([0.5665, 0.5705, 0.7218, 0.7427, 0.7394, 0.6527, 0.6247, 0.7066, 0.6388,
        0.5950, 0.6130, 0.6628, 0.5543, 0.6548, 0.5757, 0.5903],
       device='cuda:0')
percent tensor([0.9950, 0.9832, 0.9930, 0.9934, 0.9935, 0.9892, 0.9932, 0.9952, 0.9870,
        0.9891, 0.9876, 0.9945, 0.9887, 0.9900, 0.9901, 0.9934],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 30 | Batch_idx: 0 |  Loss: (0.6778) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.6475) |  Loss2: (0.0000) | Acc: (77.00%) (1089/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.6545) |  Loss2: (0.0000) | Acc: (77.00%) (2080/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.6442) |  Loss2: (0.0000) | Acc: (77.00%) (3073/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.6378) |  Loss2: (0.0000) | Acc: (77.00%) (4071/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.6326) |  Loss2: (0.0000) | Acc: (77.00%) (5089/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.6321) |  Loss2: (0.0000) | Acc: (78.00%) (6092/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.6376) |  Loss2: (0.0000) | Acc: (77.00%) (7077/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.6343) |  Loss2: (0.0000) | Acc: (77.00%) (8078/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.6340) |  Loss2: (0.0000) | Acc: (77.00%) (9070/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.6367) |  Loss2: (0.0000) | Acc: (77.00%) (10064/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.6317) |  Loss2: (0.0000) | Acc: (77.00%) (11081/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.6317) |  Loss2: (0.0000) | Acc: (77.00%) (12061/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.6309) |  Loss2: (0.0000) | Acc: (77.00%) (13065/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.6330) |  Loss2: (0.0000) | Acc: (77.00%) (14043/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (77.00%) (15069/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.6268) |  Loss2: (0.0000) | Acc: (77.00%) (16070/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.6253) |  Loss2: (0.0000) | Acc: (78.00%) (17095/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.6269) |  Loss2: (0.0000) | Acc: (78.00%) (18083/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.6273) |  Loss2: (0.0000) | Acc: (78.00%) (19072/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.6268) |  Loss2: (0.0000) | Acc: (77.00%) (20059/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.6263) |  Loss2: (0.0000) | Acc: (77.00%) (21062/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.6256) |  Loss2: (0.0000) | Acc: (78.00%) (22069/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.6265) |  Loss2: (0.0000) | Acc: (78.00%) (23064/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (24075/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.6242) |  Loss2: (0.0000) | Acc: (78.00%) (25067/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.6231) |  Loss2: (0.0000) | Acc: (78.00%) (26103/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.6227) |  Loss2: (0.0000) | Acc: (78.00%) (27106/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.6230) |  Loss2: (0.0000) | Acc: (78.00%) (28104/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.6226) |  Loss2: (0.0000) | Acc: (78.00%) (29110/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.6241) |  Loss2: (0.0000) | Acc: (78.00%) (30101/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.6239) |  Loss2: (0.0000) | Acc: (78.00%) (31095/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.6239) |  Loss2: (0.0000) | Acc: (78.00%) (32086/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.6225) |  Loss2: (0.0000) | Acc: (78.00%) (33124/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.6236) |  Loss2: (0.0000) | Acc: (78.00%) (34112/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.6244) |  Loss2: (0.0000) | Acc: (78.00%) (35100/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (36092/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.6235) |  Loss2: (0.0000) | Acc: (78.00%) (37113/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.6233) |  Loss2: (0.0000) | Acc: (78.00%) (38108/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.6232) |  Loss2: (0.0000) | Acc: (78.00%) (39057/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_030.pth.tar'
# TEST : Loss: (0.6697) | Acc: (76.00%) (7660/10000)
percent tensor([0.5130, 0.5220, 0.5270, 0.5050, 0.5305, 0.5116, 0.5305, 0.5115, 0.5173,
        0.5230, 0.5178, 0.5349, 0.5125, 0.5153, 0.5172, 0.5081],
       device='cuda:0')
percent tensor([0.5088, 0.5002, 0.4650, 0.4849, 0.4652, 0.4721, 0.4892, 0.4863, 0.5605,
        0.5000, 0.5421, 0.4848, 0.5372, 0.5596, 0.4817, 0.4872],
       device='cuda:0')
percent tensor([0.5695, 0.5003, 0.6300, 0.6115, 0.6239, 0.5651, 0.5496, 0.6163, 0.5706,
        0.5419, 0.5375, 0.5912, 0.5323, 0.4945, 0.5353, 0.5605],
       device='cuda:0')
percent tensor([0.4639, 0.4972, 0.4452, 0.4468, 0.4342, 0.4509, 0.4711, 0.4372, 0.4778,
        0.4948, 0.4967, 0.4682, 0.5019, 0.5085, 0.4626, 0.4642],
       device='cuda:0')
percent tensor([0.4557, 0.5022, 0.5262, 0.5223, 0.5110, 0.5110, 0.4717, 0.4751, 0.5434,
        0.5246, 0.5563, 0.4985, 0.4848, 0.5798, 0.4454, 0.4712],
       device='cuda:0')
percent tensor([0.5828, 0.5742, 0.5733, 0.5705, 0.5798, 0.5849, 0.5833, 0.5852, 0.5710,
        0.5792, 0.5685, 0.5672, 0.5616, 0.5683, 0.5811, 0.5903],
       device='cuda:0')
percent tensor([0.5809, 0.5984, 0.7312, 0.7383, 0.7504, 0.6630, 0.6380, 0.7037, 0.6323,
        0.6105, 0.6198, 0.6699, 0.5842, 0.6546, 0.5921, 0.6082],
       device='cuda:0')
percent tensor([0.9936, 0.9840, 0.9924, 0.9932, 0.9923, 0.9912, 0.9928, 0.9956, 0.9845,
        0.9871, 0.9884, 0.9906, 0.9899, 0.9855, 0.9911, 0.9913],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.5975, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(789.7018, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(787.1700, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.2532, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(505.5839, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2177.0791, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4307.9629, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1433.4316, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6086.0190, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12152.4893, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4040.6255, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17120.0156, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 31 | Batch_idx: 0 |  Loss: (0.7348) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.6110) |  Loss2: (0.0000) | Acc: (78.00%) (1103/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.6164) |  Loss2: (0.0000) | Acc: (78.00%) (2111/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.6095) |  Loss2: (0.0000) | Acc: (78.00%) (3109/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.6043) |  Loss2: (0.0000) | Acc: (78.00%) (4130/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.5970) |  Loss2: (0.0000) | Acc: (79.00%) (5158/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.5953) |  Loss2: (0.0000) | Acc: (79.00%) (6172/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.5982) |  Loss2: (0.0000) | Acc: (78.00%) (7163/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.5958) |  Loss2: (0.0000) | Acc: (78.00%) (8183/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.5942) |  Loss2: (0.0000) | Acc: (79.00%) (9217/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.5926) |  Loss2: (0.0000) | Acc: (79.00%) (10249/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.5925) |  Loss2: (0.0000) | Acc: (79.00%) (11268/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.5936) |  Loss2: (0.0000) | Acc: (79.00%) (12282/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.5955) |  Loss2: (0.0000) | Acc: (79.00%) (13279/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.5947) |  Loss2: (0.0000) | Acc: (79.00%) (14307/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.5949) |  Loss2: (0.0000) | Acc: (79.00%) (15312/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.5936) |  Loss2: (0.0000) | Acc: (79.00%) (16340/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.5915) |  Loss2: (0.0000) | Acc: (79.00%) (17376/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.5913) |  Loss2: (0.0000) | Acc: (79.00%) (18391/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.5920) |  Loss2: (0.0000) | Acc: (79.00%) (19399/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.5941) |  Loss2: (0.0000) | Acc: (79.00%) (20400/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.5948) |  Loss2: (0.0000) | Acc: (79.00%) (21410/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.5934) |  Loss2: (0.0000) | Acc: (79.00%) (22435/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.5947) |  Loss2: (0.0000) | Acc: (79.00%) (23441/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.5926) |  Loss2: (0.0000) | Acc: (79.00%) (24474/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.5917) |  Loss2: (0.0000) | Acc: (79.00%) (25497/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.5911) |  Loss2: (0.0000) | Acc: (79.00%) (26528/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.5916) |  Loss2: (0.0000) | Acc: (79.00%) (27545/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.5904) |  Loss2: (0.0000) | Acc: (79.00%) (28579/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.5910) |  Loss2: (0.0000) | Acc: (79.00%) (29598/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.5918) |  Loss2: (0.0000) | Acc: (79.00%) (30588/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.5919) |  Loss2: (0.0000) | Acc: (79.00%) (31595/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.5910) |  Loss2: (0.0000) | Acc: (79.00%) (32624/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.5894) |  Loss2: (0.0000) | Acc: (79.00%) (33660/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.5899) |  Loss2: (0.0000) | Acc: (79.00%) (34663/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.5898) |  Loss2: (0.0000) | Acc: (79.00%) (35688/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.5890) |  Loss2: (0.0000) | Acc: (79.00%) (36719/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.5898) |  Loss2: (0.0000) | Acc: (79.00%) (37725/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.5898) |  Loss2: (0.0000) | Acc: (79.00%) (38757/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.5897) |  Loss2: (0.0000) | Acc: (79.00%) (39734/50000)
# TEST : Loss: (0.6408) | Acc: (77.00%) (7772/10000)
percent tensor([0.5140, 0.5223, 0.5272, 0.5034, 0.5308, 0.5135, 0.5313, 0.5104, 0.5189,
        0.5233, 0.5194, 0.5353, 0.5138, 0.5156, 0.5177, 0.5082],
       device='cuda:0')
percent tensor([0.5130, 0.4921, 0.4685, 0.4904, 0.4686, 0.4753, 0.4815, 0.4951, 0.5595,
        0.4989, 0.5408, 0.4804, 0.5360, 0.5479, 0.4803, 0.4912],
       device='cuda:0')
percent tensor([0.5727, 0.5089, 0.6330, 0.6136, 0.6276, 0.5697, 0.5583, 0.6191, 0.5724,
        0.5464, 0.5411, 0.5988, 0.5367, 0.5108, 0.5404, 0.5659],
       device='cuda:0')
percent tensor([0.4701, 0.4925, 0.4438, 0.4444, 0.4355, 0.4578, 0.4672, 0.4362, 0.4793,
        0.4945, 0.5016, 0.4660, 0.5073, 0.4974, 0.4661, 0.4652],
       device='cuda:0')
percent tensor([0.4327, 0.4661, 0.5017, 0.5075, 0.4994, 0.4784, 0.4500, 0.4566, 0.5271,
        0.5078, 0.5436, 0.4984, 0.4773, 0.5504, 0.4170, 0.4408],
       device='cuda:0')
percent tensor([0.5854, 0.5770, 0.5716, 0.5742, 0.5801, 0.5803, 0.5880, 0.5881, 0.5701,
        0.5778, 0.5710, 0.5681, 0.5613, 0.5731, 0.5827, 0.5896],
       device='cuda:0')
percent tensor([0.5537, 0.5783, 0.7127, 0.7340, 0.7361, 0.6386, 0.6280, 0.7006, 0.6106,
        0.5963, 0.5984, 0.6694, 0.5580, 0.6602, 0.5866, 0.5913],
       device='cuda:0')
percent tensor([0.9950, 0.9834, 0.9945, 0.9948, 0.9939, 0.9848, 0.9924, 0.9969, 0.9860,
        0.9887, 0.9899, 0.9932, 0.9885, 0.9903, 0.9926, 0.9938],
       device='cuda:0')
Epoch: 32 | Batch_idx: 0 |  Loss: (0.6856) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.5713) |  Loss2: (0.0000) | Acc: (80.00%) (1135/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.5413) |  Loss2: (0.0000) | Acc: (80.00%) (2171/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5441) |  Loss2: (0.0000) | Acc: (81.00%) (3215/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5596) |  Loss2: (0.0000) | Acc: (80.00%) (4229/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.5487) |  Loss2: (0.0000) | Acc: (81.00%) (5290/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.5521) |  Loss2: (0.0000) | Acc: (80.00%) (6308/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.5574) |  Loss2: (0.0000) | Acc: (80.00%) (7328/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.5632) |  Loss2: (0.0000) | Acc: (80.00%) (8342/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.5581) |  Loss2: (0.0000) | Acc: (80.00%) (9390/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.5572) |  Loss2: (0.0000) | Acc: (80.00%) (10421/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.5523) |  Loss2: (0.0000) | Acc: (80.00%) (11483/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.5547) |  Loss2: (0.0000) | Acc: (80.00%) (12498/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.5550) |  Loss2: (0.0000) | Acc: (80.00%) (13534/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.5532) |  Loss2: (0.0000) | Acc: (80.00%) (14575/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.5530) |  Loss2: (0.0000) | Acc: (80.00%) (15597/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.5544) |  Loss2: (0.0000) | Acc: (80.00%) (16636/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.5559) |  Loss2: (0.0000) | Acc: (80.00%) (17657/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.5546) |  Loss2: (0.0000) | Acc: (80.00%) (18703/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.5557) |  Loss2: (0.0000) | Acc: (80.00%) (19738/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.5557) |  Loss2: (0.0000) | Acc: (80.00%) (20771/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.5581) |  Loss2: (0.0000) | Acc: (80.00%) (21782/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.5577) |  Loss2: (0.0000) | Acc: (80.00%) (22813/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.5589) |  Loss2: (0.0000) | Acc: (80.00%) (23832/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.5589) |  Loss2: (0.0000) | Acc: (80.00%) (24860/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.5578) |  Loss2: (0.0000) | Acc: (80.00%) (25905/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.5589) |  Loss2: (0.0000) | Acc: (80.00%) (26920/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.5587) |  Loss2: (0.0000) | Acc: (80.00%) (27951/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.5604) |  Loss2: (0.0000) | Acc: (80.00%) (28968/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.5606) |  Loss2: (0.0000) | Acc: (80.00%) (29994/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.5602) |  Loss2: (0.0000) | Acc: (80.00%) (31024/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.5611) |  Loss2: (0.0000) | Acc: (80.00%) (32036/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.5610) |  Loss2: (0.0000) | Acc: (80.00%) (33071/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.5605) |  Loss2: (0.0000) | Acc: (80.00%) (34111/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.5597) |  Loss2: (0.0000) | Acc: (80.00%) (35161/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.5601) |  Loss2: (0.0000) | Acc: (80.00%) (36182/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.5618) |  Loss2: (0.0000) | Acc: (80.00%) (37189/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.5620) |  Loss2: (0.0000) | Acc: (80.00%) (38218/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.5621) |  Loss2: (0.0000) | Acc: (80.00%) (39251/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.5630) |  Loss2: (0.0000) | Acc: (80.00%) (40226/50000)
# TEST : Loss: (0.6766) | Acc: (76.00%) (7670/10000)
percent tensor([0.5132, 0.5217, 0.5278, 0.5038, 0.5311, 0.5124, 0.5309, 0.5110, 0.5173,
        0.5231, 0.5181, 0.5355, 0.5130, 0.5145, 0.5174, 0.5080],
       device='cuda:0')
percent tensor([0.5054, 0.5009, 0.4379, 0.4822, 0.4437, 0.4730, 0.4803, 0.4873, 0.5554,
        0.4950, 0.5465, 0.4550, 0.5326, 0.5628, 0.4846, 0.4951],
       device='cuda:0')
percent tensor([0.5720, 0.5071, 0.6276, 0.6122, 0.6245, 0.5760, 0.5555, 0.6152, 0.5724,
        0.5432, 0.5389, 0.5935, 0.5356, 0.5116, 0.5397, 0.5647],
       device='cuda:0')
percent tensor([0.4669, 0.4897, 0.4397, 0.4435, 0.4337, 0.4565, 0.4640, 0.4357, 0.4737,
        0.4896, 0.4968, 0.4623, 0.4997, 0.4942, 0.4644, 0.4649],
       device='cuda:0')
percent tensor([0.4328, 0.4709, 0.4863, 0.4967, 0.4896, 0.5061, 0.4505, 0.4539, 0.5209,
        0.4921, 0.5489, 0.4597, 0.4729, 0.5484, 0.4274, 0.4572],
       device='cuda:0')
percent tensor([0.5827, 0.5783, 0.5705, 0.5721, 0.5783, 0.5810, 0.5850, 0.5844, 0.5724,
        0.5761, 0.5741, 0.5693, 0.5610, 0.5758, 0.5824, 0.5860],
       device='cuda:0')
percent tensor([0.5619, 0.5950, 0.7171, 0.7298, 0.7351, 0.6667, 0.6454, 0.6951, 0.6213,
        0.6122, 0.6260, 0.6762, 0.5832, 0.6681, 0.5894, 0.5984],
       device='cuda:0')
percent tensor([0.9939, 0.9860, 0.9940, 0.9939, 0.9919, 0.9868, 0.9928, 0.9962, 0.9856,
        0.9905, 0.9914, 0.9961, 0.9881, 0.9904, 0.9907, 0.9925],
       device='cuda:0')
Epoch: 33 | Batch_idx: 0 |  Loss: (0.4097) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.5033) |  Loss2: (0.0000) | Acc: (83.00%) (1174/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.5336) |  Loss2: (0.0000) | Acc: (81.00%) (2204/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5290) |  Loss2: (0.0000) | Acc: (82.00%) (3264/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5247) |  Loss2: (0.0000) | Acc: (81.00%) (4301/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5280) |  Loss2: (0.0000) | Acc: (81.00%) (5349/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5273) |  Loss2: (0.0000) | Acc: (81.00%) (6392/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5324) |  Loss2: (0.0000) | Acc: (81.00%) (7403/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5376) |  Loss2: (0.0000) | Acc: (81.00%) (8427/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5370) |  Loss2: (0.0000) | Acc: (81.00%) (9464/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5410) |  Loss2: (0.0000) | Acc: (81.00%) (10497/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5406) |  Loss2: (0.0000) | Acc: (81.00%) (11553/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5431) |  Loss2: (0.0000) | Acc: (81.00%) (12577/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5429) |  Loss2: (0.0000) | Acc: (81.00%) (13605/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5448) |  Loss2: (0.0000) | Acc: (81.00%) (14631/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5423) |  Loss2: (0.0000) | Acc: (81.00%) (15698/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5424) |  Loss2: (0.0000) | Acc: (81.00%) (16734/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5404) |  Loss2: (0.0000) | Acc: (81.00%) (17786/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5406) |  Loss2: (0.0000) | Acc: (81.00%) (18819/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5400) |  Loss2: (0.0000) | Acc: (81.00%) (19869/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5403) |  Loss2: (0.0000) | Acc: (81.00%) (20908/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5402) |  Loss2: (0.0000) | Acc: (81.00%) (21955/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5395) |  Loss2: (0.0000) | Acc: (81.00%) (23010/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5410) |  Loss2: (0.0000) | Acc: (81.00%) (24042/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5408) |  Loss2: (0.0000) | Acc: (81.00%) (25072/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5403) |  Loss2: (0.0000) | Acc: (81.00%) (26106/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5404) |  Loss2: (0.0000) | Acc: (81.00%) (27153/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5393) |  Loss2: (0.0000) | Acc: (81.00%) (28206/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5390) |  Loss2: (0.0000) | Acc: (81.00%) (29238/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5393) |  Loss2: (0.0000) | Acc: (81.00%) (30263/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5391) |  Loss2: (0.0000) | Acc: (81.00%) (31325/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5398) |  Loss2: (0.0000) | Acc: (81.00%) (32361/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5397) |  Loss2: (0.0000) | Acc: (81.00%) (33413/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5384) |  Loss2: (0.0000) | Acc: (81.00%) (34480/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5388) |  Loss2: (0.0000) | Acc: (81.00%) (35505/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5388) |  Loss2: (0.0000) | Acc: (81.00%) (36551/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5389) |  Loss2: (0.0000) | Acc: (81.00%) (37575/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5391) |  Loss2: (0.0000) | Acc: (81.00%) (38602/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5377) |  Loss2: (0.0000) | Acc: (81.00%) (39662/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5381) |  Loss2: (0.0000) | Acc: (81.00%) (40646/50000)
# TEST : Loss: (0.7236) | Acc: (75.00%) (7572/10000)
percent tensor([0.5134, 0.5233, 0.5252, 0.5044, 0.5293, 0.5129, 0.5309, 0.5110, 0.5176,
        0.5227, 0.5186, 0.5333, 0.5129, 0.5171, 0.5182, 0.5088],
       device='cuda:0')
percent tensor([0.5089, 0.5013, 0.4529, 0.4858, 0.4566, 0.4698, 0.4860, 0.4937, 0.5561,
        0.4975, 0.5429, 0.4687, 0.5345, 0.5643, 0.4831, 0.4919],
       device='cuda:0')
percent tensor([0.5707, 0.5072, 0.6251, 0.6074, 0.6212, 0.5750, 0.5532, 0.6136, 0.5670,
        0.5443, 0.5394, 0.5910, 0.5347, 0.5071, 0.5399, 0.5646],
       device='cuda:0')
percent tensor([0.4705, 0.4966, 0.4512, 0.4510, 0.4415, 0.4612, 0.4715, 0.4407, 0.4809,
        0.4981, 0.5013, 0.4712, 0.5048, 0.4992, 0.4683, 0.4701],
       device='cuda:0')
percent tensor([0.4586, 0.4812, 0.5227, 0.5393, 0.5239, 0.5156, 0.4615, 0.4779, 0.5274,
        0.5277, 0.5443, 0.5210, 0.4958, 0.5477, 0.4507, 0.4709],
       device='cuda:0')
percent tensor([0.5757, 0.5684, 0.5711, 0.5722, 0.5774, 0.5787, 0.5759, 0.5800, 0.5653,
        0.5729, 0.5657, 0.5661, 0.5560, 0.5698, 0.5775, 0.5839],
       device='cuda:0')
percent tensor([0.5738, 0.5799, 0.7094, 0.7259, 0.7359, 0.6582, 0.6315, 0.6851, 0.5969,
        0.5907, 0.6014, 0.6715, 0.5723, 0.6423, 0.5942, 0.6004],
       device='cuda:0')
percent tensor([0.9940, 0.9834, 0.9923, 0.9923, 0.9912, 0.9864, 0.9870, 0.9951, 0.9838,
        0.9836, 0.9901, 0.9922, 0.9906, 0.9879, 0.9923, 0.9925],
       device='cuda:0')
Epoch: 34 | Batch_idx: 0 |  Loss: (0.4998) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.4911) |  Loss2: (0.0000) | Acc: (83.00%) (1170/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.5010) |  Loss2: (0.0000) | Acc: (82.00%) (2221/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.5135) |  Loss2: (0.0000) | Acc: (82.00%) (3254/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.5174) |  Loss2: (0.0000) | Acc: (81.00%) (4293/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.5205) |  Loss2: (0.0000) | Acc: (81.00%) (5326/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.5218) |  Loss2: (0.0000) | Acc: (81.00%) (6388/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.5180) |  Loss2: (0.0000) | Acc: (81.00%) (7440/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.5179) |  Loss2: (0.0000) | Acc: (81.00%) (8488/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.5174) |  Loss2: (0.0000) | Acc: (81.00%) (9540/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.5171) |  Loss2: (0.0000) | Acc: (81.00%) (10579/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.5175) |  Loss2: (0.0000) | Acc: (81.00%) (11638/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.5182) |  Loss2: (0.0000) | Acc: (81.00%) (12693/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.5174) |  Loss2: (0.0000) | Acc: (82.00%) (13750/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.5165) |  Loss2: (0.0000) | Acc: (82.00%) (14805/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.5148) |  Loss2: (0.0000) | Acc: (82.00%) (15863/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.5132) |  Loss2: (0.0000) | Acc: (82.00%) (16934/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.5134) |  Loss2: (0.0000) | Acc: (82.00%) (17985/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.5103) |  Loss2: (0.0000) | Acc: (82.00%) (19065/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.5100) |  Loss2: (0.0000) | Acc: (82.00%) (20117/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.5088) |  Loss2: (0.0000) | Acc: (82.00%) (21186/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.5100) |  Loss2: (0.0000) | Acc: (82.00%) (22225/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.5111) |  Loss2: (0.0000) | Acc: (82.00%) (23268/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.5109) |  Loss2: (0.0000) | Acc: (82.00%) (24323/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.5135) |  Loss2: (0.0000) | Acc: (82.00%) (25343/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.5142) |  Loss2: (0.0000) | Acc: (82.00%) (26396/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.5137) |  Loss2: (0.0000) | Acc: (82.00%) (27454/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (82.00%) (28500/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (82.00%) (29564/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (30605/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.5152) |  Loss2: (0.0000) | Acc: (82.00%) (31655/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.5162) |  Loss2: (0.0000) | Acc: (82.00%) (32660/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.5168) |  Loss2: (0.0000) | Acc: (82.00%) (33697/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (82.00%) (34749/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.5152) |  Loss2: (0.0000) | Acc: (82.00%) (35814/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (82.00%) (36852/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (82.00%) (37900/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (82.00%) (38947/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.5156) |  Loss2: (0.0000) | Acc: (82.00%) (39990/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.5157) |  Loss2: (0.0000) | Acc: (82.00%) (41011/50000)
# TEST : Loss: (0.6025) | Acc: (79.00%) (7951/10000)
percent tensor([0.5127, 0.5231, 0.5238, 0.5035, 0.5278, 0.5127, 0.5303, 0.5099, 0.5165,
        0.5223, 0.5183, 0.5321, 0.5125, 0.5162, 0.5182, 0.5085],
       device='cuda:0')
percent tensor([0.5146, 0.5013, 0.4718, 0.4917, 0.4737, 0.4809, 0.4914, 0.4956, 0.5613,
        0.5004, 0.5434, 0.4840, 0.5346, 0.5571, 0.4887, 0.4930],
       device='cuda:0')
percent tensor([0.5662, 0.5103, 0.6196, 0.6037, 0.6158, 0.5700, 0.5532, 0.6106, 0.5646,
        0.5453, 0.5389, 0.5866, 0.5297, 0.5220, 0.5396, 0.5638],
       device='cuda:0')
percent tensor([0.4690, 0.4937, 0.4471, 0.4523, 0.4389, 0.4622, 0.4672, 0.4404, 0.4784,
        0.4926, 0.5000, 0.4680, 0.5031, 0.4921, 0.4662, 0.4695],
       device='cuda:0')
percent tensor([0.4484, 0.4763, 0.5116, 0.5142, 0.5231, 0.5214, 0.4616, 0.4690, 0.5282,
        0.5067, 0.5434, 0.4961, 0.4791, 0.5449, 0.4411, 0.4677],
       device='cuda:0')
percent tensor([0.5812, 0.5733, 0.5725, 0.5697, 0.5772, 0.5816, 0.5835, 0.5807, 0.5712,
        0.5751, 0.5706, 0.5668, 0.5582, 0.5740, 0.5802, 0.5864],
       device='cuda:0')
percent tensor([0.5660, 0.5766, 0.7042, 0.7183, 0.7297, 0.6468, 0.6254, 0.6912, 0.6092,
        0.5951, 0.6050, 0.6630, 0.5647, 0.6571, 0.5794, 0.5958],
       device='cuda:0')
percent tensor([0.9960, 0.9842, 0.9930, 0.9944, 0.9900, 0.9892, 0.9913, 0.9954, 0.9837,
        0.9868, 0.9902, 0.9932, 0.9900, 0.9900, 0.9906, 0.9935],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 35 | Batch_idx: 0 |  Loss: (0.5647) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.5540) |  Loss2: (0.0000) | Acc: (80.00%) (1127/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.5537) |  Loss2: (0.0000) | Acc: (80.00%) (2155/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.5701) |  Loss2: (0.0000) | Acc: (80.00%) (3180/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.5855) |  Loss2: (0.0000) | Acc: (79.00%) (4173/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.5893) |  Loss2: (0.0000) | Acc: (79.00%) (5178/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.5896) |  Loss2: (0.0000) | Acc: (79.00%) (6196/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.5959) |  Loss2: (0.0000) | Acc: (79.00%) (7192/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.5983) |  Loss2: (0.0000) | Acc: (79.00%) (8193/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.6000) |  Loss2: (0.0000) | Acc: (79.00%) (9206/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.5984) |  Loss2: (0.0000) | Acc: (79.00%) (10235/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.5943) |  Loss2: (0.0000) | Acc: (79.00%) (11278/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.5931) |  Loss2: (0.0000) | Acc: (79.00%) (12309/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.5927) |  Loss2: (0.0000) | Acc: (79.00%) (13337/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.5932) |  Loss2: (0.0000) | Acc: (79.00%) (14360/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.5924) |  Loss2: (0.0000) | Acc: (79.00%) (15366/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.5896) |  Loss2: (0.0000) | Acc: (79.00%) (16412/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.5866) |  Loss2: (0.0000) | Acc: (79.00%) (17455/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.5848) |  Loss2: (0.0000) | Acc: (79.00%) (18491/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.5860) |  Loss2: (0.0000) | Acc: (79.00%) (19495/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.5864) |  Loss2: (0.0000) | Acc: (79.00%) (20501/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.5847) |  Loss2: (0.0000) | Acc: (79.00%) (21527/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.5838) |  Loss2: (0.0000) | Acc: (79.00%) (22555/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.5815) |  Loss2: (0.0000) | Acc: (79.00%) (23607/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.5796) |  Loss2: (0.0000) | Acc: (79.00%) (24651/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.5791) |  Loss2: (0.0000) | Acc: (79.00%) (25661/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.5769) |  Loss2: (0.0000) | Acc: (79.00%) (26705/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.5761) |  Loss2: (0.0000) | Acc: (79.00%) (27742/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.5766) |  Loss2: (0.0000) | Acc: (79.00%) (28756/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.5759) |  Loss2: (0.0000) | Acc: (79.00%) (29775/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.5740) |  Loss2: (0.0000) | Acc: (79.00%) (30811/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.5735) |  Loss2: (0.0000) | Acc: (79.00%) (31833/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.5719) |  Loss2: (0.0000) | Acc: (80.00%) (32883/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.5715) |  Loss2: (0.0000) | Acc: (80.00%) (33918/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.5710) |  Loss2: (0.0000) | Acc: (80.00%) (34971/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.5699) |  Loss2: (0.0000) | Acc: (80.00%) (36033/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.5697) |  Loss2: (0.0000) | Acc: (80.00%) (37060/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.5687) |  Loss2: (0.0000) | Acc: (80.00%) (38103/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.5679) |  Loss2: (0.0000) | Acc: (80.00%) (39154/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.5664) |  Loss2: (0.0000) | Acc: (80.00%) (40173/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_035.pth.tar'
# TEST : Loss: (0.5966) | Acc: (79.00%) (7925/10000)
percent tensor([0.5024, 0.5119, 0.5139, 0.4942, 0.5170, 0.5038, 0.5186, 0.4992, 0.5058,
        0.5114, 0.5073, 0.5210, 0.5019, 0.5059, 0.5078, 0.4985],
       device='cuda:0')
percent tensor([0.4876, 0.4774, 0.4341, 0.4619, 0.4339, 0.4439, 0.4616, 0.4622, 0.5407,
        0.4750, 0.5209, 0.4517, 0.5135, 0.5495, 0.4570, 0.4677],
       device='cuda:0')
percent tensor([0.5978, 0.5402, 0.6273, 0.6229, 0.6212, 0.5994, 0.5752, 0.6257, 0.5877,
        0.5718, 0.5698, 0.6033, 0.5655, 0.5597, 0.5675, 0.5947],
       device='cuda:0')
percent tensor([0.4809, 0.5044, 0.4606, 0.4622, 0.4558, 0.4753, 0.4822, 0.4539, 0.4891,
        0.5034, 0.5080, 0.4793, 0.5096, 0.5038, 0.4800, 0.4820],
       device='cuda:0')
percent tensor([0.4806, 0.5187, 0.5310, 0.5219, 0.5325, 0.5243, 0.4957, 0.4685, 0.5650,
        0.5638, 0.6063, 0.5520, 0.5483, 0.5753, 0.4724, 0.4922],
       device='cuda:0')
percent tensor([0.6141, 0.6082, 0.6033, 0.5967, 0.6014, 0.6034, 0.6145, 0.6099, 0.6021,
        0.6098, 0.6088, 0.6044, 0.6001, 0.6084, 0.6146, 0.6176],
       device='cuda:0')
percent tensor([0.6083, 0.5976, 0.7258, 0.7373, 0.7538, 0.6721, 0.6488, 0.7142, 0.6250,
        0.6118, 0.6339, 0.6972, 0.6000, 0.6730, 0.6172, 0.6232],
       device='cuda:0')
percent tensor([0.9952, 0.9867, 0.9925, 0.9927, 0.9915, 0.9820, 0.9881, 0.9949, 0.9841,
        0.9871, 0.9904, 0.9931, 0.9920, 0.9897, 0.9906, 0.9918],
       device='cuda:0')
Epoch: 36 | Batch_idx: 0 |  Loss: (0.4968) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.5016) |  Loss2: (0.0000) | Acc: (84.00%) (1183/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (83.00%) (2239/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.5212) |  Loss2: (0.0000) | Acc: (82.00%) (3266/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.5257) |  Loss2: (0.0000) | Acc: (82.00%) (4308/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.5377) |  Loss2: (0.0000) | Acc: (81.00%) (5325/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.5334) |  Loss2: (0.0000) | Acc: (81.00%) (6382/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.5369) |  Loss2: (0.0000) | Acc: (81.00%) (7403/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.5381) |  Loss2: (0.0000) | Acc: (81.00%) (8441/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.5407) |  Loss2: (0.0000) | Acc: (81.00%) (9466/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.5432) |  Loss2: (0.0000) | Acc: (81.00%) (10498/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.5467) |  Loss2: (0.0000) | Acc: (81.00%) (11521/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.5451) |  Loss2: (0.0000) | Acc: (81.00%) (12556/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.5492) |  Loss2: (0.0000) | Acc: (80.00%) (13578/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.5527) |  Loss2: (0.0000) | Acc: (80.00%) (14593/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.5508) |  Loss2: (0.0000) | Acc: (80.00%) (15643/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.5492) |  Loss2: (0.0000) | Acc: (80.00%) (16690/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.5472) |  Loss2: (0.0000) | Acc: (81.00%) (17745/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.5445) |  Loss2: (0.0000) | Acc: (81.00%) (18808/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.5397) |  Loss2: (0.0000) | Acc: (81.00%) (19897/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.5384) |  Loss2: (0.0000) | Acc: (81.00%) (20956/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.5358) |  Loss2: (0.0000) | Acc: (81.00%) (22030/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.5353) |  Loss2: (0.0000) | Acc: (81.00%) (23060/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.5350) |  Loss2: (0.0000) | Acc: (81.00%) (24102/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.5336) |  Loss2: (0.0000) | Acc: (81.00%) (25157/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.5328) |  Loss2: (0.0000) | Acc: (81.00%) (26189/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.5317) |  Loss2: (0.0000) | Acc: (81.00%) (27249/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.5294) |  Loss2: (0.0000) | Acc: (81.00%) (28312/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.5299) |  Loss2: (0.0000) | Acc: (81.00%) (29335/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.5295) |  Loss2: (0.0000) | Acc: (81.00%) (30387/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.5280) |  Loss2: (0.0000) | Acc: (81.00%) (31458/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.5279) |  Loss2: (0.0000) | Acc: (81.00%) (32501/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.5271) |  Loss2: (0.0000) | Acc: (81.00%) (33555/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.5275) |  Loss2: (0.0000) | Acc: (81.00%) (34591/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.5262) |  Loss2: (0.0000) | Acc: (81.00%) (35667/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.5264) |  Loss2: (0.0000) | Acc: (81.00%) (36709/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.5254) |  Loss2: (0.0000) | Acc: (81.00%) (37782/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.5253) |  Loss2: (0.0000) | Acc: (81.00%) (38827/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5253) |  Loss2: (0.0000) | Acc: (81.00%) (39877/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5258) |  Loss2: (0.0000) | Acc: (81.00%) (40877/50000)
# TEST : Loss: (0.5694) | Acc: (80.00%) (8019/10000)
percent tensor([0.5039, 0.5133, 0.5181, 0.4968, 0.5207, 0.5059, 0.5209, 0.5018, 0.5076,
        0.5134, 0.5086, 0.5245, 0.5034, 0.5063, 0.5096, 0.4999],
       device='cuda:0')
percent tensor([0.4861, 0.4798, 0.4318, 0.4613, 0.4308, 0.4389, 0.4627, 0.4623, 0.5415,
        0.4775, 0.5226, 0.4517, 0.5140, 0.5558, 0.4559, 0.4685],
       device='cuda:0')
percent tensor([0.5993, 0.5379, 0.6256, 0.6223, 0.6199, 0.6058, 0.5731, 0.6230, 0.5857,
        0.5699, 0.5684, 0.5993, 0.5632, 0.5583, 0.5675, 0.5966],
       device='cuda:0')
percent tensor([0.4824, 0.5050, 0.4609, 0.4644, 0.4576, 0.4775, 0.4840, 0.4576, 0.4895,
        0.5035, 0.5077, 0.4788, 0.5085, 0.5051, 0.4821, 0.4841],
       device='cuda:0')
percent tensor([0.4699, 0.5181, 0.5236, 0.5213, 0.5247, 0.5141, 0.4943, 0.4631, 0.5636,
        0.5629, 0.6115, 0.5494, 0.5421, 0.5818, 0.4681, 0.4863],
       device='cuda:0')
percent tensor([0.6241, 0.6209, 0.6152, 0.6086, 0.6113, 0.6106, 0.6277, 0.6228, 0.6140,
        0.6228, 0.6238, 0.6194, 0.6120, 0.6198, 0.6283, 0.6284],
       device='cuda:0')
percent tensor([0.6063, 0.5933, 0.7287, 0.7408, 0.7605, 0.6770, 0.6501, 0.7239, 0.6154,
        0.6058, 0.6268, 0.6960, 0.5915, 0.6653, 0.6240, 0.6292],
       device='cuda:0')
percent tensor([0.9956, 0.9874, 0.9931, 0.9935, 0.9921, 0.9833, 0.9896, 0.9953, 0.9858,
        0.9883, 0.9916, 0.9938, 0.9926, 0.9906, 0.9916, 0.9928],
       device='cuda:0')
Epoch: 37 | Batch_idx: 0 |  Loss: (0.5114) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.5358) |  Loss2: (0.0000) | Acc: (80.00%) (1135/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.5277) |  Loss2: (0.0000) | Acc: (81.00%) (2200/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.5194) |  Loss2: (0.0000) | Acc: (81.00%) (3252/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.5162) |  Loss2: (0.0000) | Acc: (82.00%) (4306/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.5113) |  Loss2: (0.0000) | Acc: (82.00%) (5369/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.5076) |  Loss2: (0.0000) | Acc: (82.00%) (6429/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.5112) |  Loss2: (0.0000) | Acc: (82.00%) (7470/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.5122) |  Loss2: (0.0000) | Acc: (82.00%) (8528/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.5160) |  Loss2: (0.0000) | Acc: (82.00%) (9577/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.5152) |  Loss2: (0.0000) | Acc: (82.00%) (10634/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.5192) |  Loss2: (0.0000) | Acc: (82.00%) (11676/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.5157) |  Loss2: (0.0000) | Acc: (82.00%) (12735/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.5156) |  Loss2: (0.0000) | Acc: (82.00%) (13793/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.5159) |  Loss2: (0.0000) | Acc: (82.00%) (14841/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.5141) |  Loss2: (0.0000) | Acc: (82.00%) (15888/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.5170) |  Loss2: (0.0000) | Acc: (82.00%) (16921/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.5152) |  Loss2: (0.0000) | Acc: (82.00%) (17975/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.5133) |  Loss2: (0.0000) | Acc: (82.00%) (19050/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.5133) |  Loss2: (0.0000) | Acc: (82.00%) (20109/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.5131) |  Loss2: (0.0000) | Acc: (82.00%) (21162/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.5124) |  Loss2: (0.0000) | Acc: (82.00%) (22221/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.5131) |  Loss2: (0.0000) | Acc: (82.00%) (23259/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.5118) |  Loss2: (0.0000) | Acc: (82.00%) (24337/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.5108) |  Loss2: (0.0000) | Acc: (82.00%) (25396/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.5110) |  Loss2: (0.0000) | Acc: (82.00%) (26439/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.5108) |  Loss2: (0.0000) | Acc: (82.00%) (27497/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.5095) |  Loss2: (0.0000) | Acc: (82.00%) (28554/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.5086) |  Loss2: (0.0000) | Acc: (82.00%) (29619/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.5082) |  Loss2: (0.0000) | Acc: (82.00%) (30676/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.5089) |  Loss2: (0.0000) | Acc: (82.00%) (31726/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.5099) |  Loss2: (0.0000) | Acc: (82.00%) (32772/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.5102) |  Loss2: (0.0000) | Acc: (82.00%) (33823/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.5104) |  Loss2: (0.0000) | Acc: (82.00%) (34866/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.5098) |  Loss2: (0.0000) | Acc: (82.00%) (35924/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.5092) |  Loss2: (0.0000) | Acc: (82.00%) (36990/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.5093) |  Loss2: (0.0000) | Acc: (82.00%) (38044/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.5083) |  Loss2: (0.0000) | Acc: (82.00%) (39115/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.5070) |  Loss2: (0.0000) | Acc: (82.00%) (40200/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.5070) |  Loss2: (0.0000) | Acc: (82.00%) (41211/50000)
# TEST : Loss: (0.5554) | Acc: (80.00%) (8065/10000)
percent tensor([0.5073, 0.5166, 0.5240, 0.5011, 0.5264, 0.5097, 0.5251, 0.5061, 0.5111,
        0.5173, 0.5116, 0.5300, 0.5066, 0.5084, 0.5133, 0.5031],
       device='cuda:0')
percent tensor([0.4925, 0.4880, 0.4374, 0.4671, 0.4367, 0.4418, 0.4704, 0.4698, 0.5493,
        0.4859, 0.5313, 0.4592, 0.5215, 0.5649, 0.4618, 0.4752],
       device='cuda:0')
percent tensor([0.5952, 0.5296, 0.6222, 0.6192, 0.6179, 0.6074, 0.5670, 0.6185, 0.5779,
        0.5625, 0.5608, 0.5925, 0.5540, 0.5499, 0.5623, 0.5939],
       device='cuda:0')
percent tensor([0.4841, 0.5051, 0.4623, 0.4667, 0.4598, 0.4797, 0.4853, 0.4600, 0.4904,
        0.5037, 0.5078, 0.4793, 0.5081, 0.5057, 0.4834, 0.4857],
       device='cuda:0')
percent tensor([0.4582, 0.5114, 0.5196, 0.5218, 0.5206, 0.5096, 0.4874, 0.4556, 0.5600,
        0.5560, 0.6119, 0.5449, 0.5318, 0.5811, 0.4605, 0.4787],
       device='cuda:0')
percent tensor([0.6225, 0.6216, 0.6158, 0.6091, 0.6108, 0.6089, 0.6282, 0.6224, 0.6150,
        0.6236, 0.6268, 0.6223, 0.6125, 0.6209, 0.6292, 0.6271],
       device='cuda:0')
percent tensor([0.6148, 0.5994, 0.7384, 0.7525, 0.7706, 0.6891, 0.6614, 0.7362, 0.6179,
        0.6109, 0.6316, 0.7052, 0.5934, 0.6739, 0.6342, 0.6436],
       device='cuda:0')
percent tensor([0.9963, 0.9884, 0.9943, 0.9948, 0.9932, 0.9856, 0.9913, 0.9961, 0.9876,
        0.9898, 0.9929, 0.9948, 0.9934, 0.9919, 0.9931, 0.9942],
       device='cuda:0')
Epoch: 38 | Batch_idx: 0 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.5318) |  Loss2: (0.0000) | Acc: (82.00%) (1159/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.5156) |  Loss2: (0.0000) | Acc: (82.00%) (2216/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.5179) |  Loss2: (0.0000) | Acc: (82.00%) (3257/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.5196) |  Loss2: (0.0000) | Acc: (81.00%) (4293/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.5175) |  Loss2: (0.0000) | Acc: (82.00%) (5371/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.5083) |  Loss2: (0.0000) | Acc: (82.00%) (6450/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.5092) |  Loss2: (0.0000) | Acc: (82.00%) (7504/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.5132) |  Loss2: (0.0000) | Acc: (82.00%) (8555/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.5159) |  Loss2: (0.0000) | Acc: (82.00%) (9603/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.5169) |  Loss2: (0.0000) | Acc: (82.00%) (10644/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.5152) |  Loss2: (0.0000) | Acc: (82.00%) (11697/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.5141) |  Loss2: (0.0000) | Acc: (82.00%) (12767/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.5159) |  Loss2: (0.0000) | Acc: (82.00%) (13804/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.5168) |  Loss2: (0.0000) | Acc: (82.00%) (14845/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.5152) |  Loss2: (0.0000) | Acc: (82.00%) (15914/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.5145) |  Loss2: (0.0000) | Acc: (82.00%) (16969/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.5126) |  Loss2: (0.0000) | Acc: (82.00%) (18049/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.5111) |  Loss2: (0.0000) | Acc: (82.00%) (19115/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.5102) |  Loss2: (0.0000) | Acc: (82.00%) (20177/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.5096) |  Loss2: (0.0000) | Acc: (82.00%) (21224/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.5090) |  Loss2: (0.0000) | Acc: (82.00%) (22277/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.5105) |  Loss2: (0.0000) | Acc: (82.00%) (23325/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.5122) |  Loss2: (0.0000) | Acc: (82.00%) (24363/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.5130) |  Loss2: (0.0000) | Acc: (82.00%) (25410/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.5117) |  Loss2: (0.0000) | Acc: (82.00%) (26473/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.5109) |  Loss2: (0.0000) | Acc: (82.00%) (27518/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.5104) |  Loss2: (0.0000) | Acc: (82.00%) (28576/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.5086) |  Loss2: (0.0000) | Acc: (82.00%) (29662/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.5081) |  Loss2: (0.0000) | Acc: (82.00%) (30713/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.5079) |  Loss2: (0.0000) | Acc: (82.00%) (31775/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.5081) |  Loss2: (0.0000) | Acc: (82.00%) (32845/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.5068) |  Loss2: (0.0000) | Acc: (82.00%) (33916/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.5060) |  Loss2: (0.0000) | Acc: (82.00%) (34976/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.5060) |  Loss2: (0.0000) | Acc: (82.00%) (36028/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.5065) |  Loss2: (0.0000) | Acc: (82.00%) (37092/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.5061) |  Loss2: (0.0000) | Acc: (82.00%) (38154/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.5052) |  Loss2: (0.0000) | Acc: (82.00%) (39235/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.5045) |  Loss2: (0.0000) | Acc: (82.00%) (40309/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.5042) |  Loss2: (0.0000) | Acc: (82.00%) (41339/50000)
# TEST : Loss: (0.5487) | Acc: (80.00%) (8085/10000)
percent tensor([0.5116, 0.5211, 0.5306, 0.5057, 0.5329, 0.5142, 0.5305, 0.5111, 0.5157,
        0.5222, 0.5158, 0.5363, 0.5108, 0.5119, 0.5177, 0.5069],
       device='cuda:0')
percent tensor([0.4861, 0.4827, 0.4316, 0.4617, 0.4307, 0.4339, 0.4651, 0.4637, 0.5420,
        0.4808, 0.5250, 0.4543, 0.5151, 0.5599, 0.4559, 0.4692],
       device='cuda:0')
percent tensor([0.5963, 0.5303, 0.6223, 0.6202, 0.6189, 0.6116, 0.5674, 0.6180, 0.5777,
        0.5630, 0.5618, 0.5917, 0.5532, 0.5502, 0.5636, 0.5961],
       device='cuda:0')
percent tensor([0.4839, 0.5039, 0.4627, 0.4674, 0.4609, 0.4804, 0.4855, 0.4608, 0.4903,
        0.5026, 0.5066, 0.4787, 0.5065, 0.5056, 0.4832, 0.4856],
       device='cuda:0')
percent tensor([0.4491, 0.5044, 0.5168, 0.5226, 0.5215, 0.5093, 0.4837, 0.4531, 0.5540,
        0.5480, 0.6046, 0.5385, 0.5186, 0.5760, 0.4543, 0.4755],
       device='cuda:0')
percent tensor([0.6252, 0.6261, 0.6211, 0.6153, 0.6159, 0.6124, 0.6330, 0.6275, 0.6201,
        0.6281, 0.6325, 0.6291, 0.6151, 0.6267, 0.6342, 0.6306],
       device='cuda:0')
percent tensor([0.6120, 0.5950, 0.7382, 0.7543, 0.7725, 0.6957, 0.6600, 0.7375, 0.6104,
        0.6047, 0.6228, 0.7029, 0.5851, 0.6669, 0.6324, 0.6466],
       device='cuda:0')
percent tensor([0.9966, 0.9893, 0.9948, 0.9954, 0.9940, 0.9879, 0.9921, 0.9965, 0.9886,
        0.9905, 0.9937, 0.9954, 0.9939, 0.9928, 0.9936, 0.9948],
       device='cuda:0')
Epoch: 39 | Batch_idx: 0 |  Loss: (0.4652) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.5199) |  Loss2: (0.0000) | Acc: (81.00%) (1148/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.4985) |  Loss2: (0.0000) | Acc: (82.00%) (2225/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.4887) |  Loss2: (0.0000) | Acc: (83.00%) (3297/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (82.00%) (4355/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.4936) |  Loss2: (0.0000) | Acc: (82.00%) (5415/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.4979) |  Loss2: (0.0000) | Acc: (82.00%) (6460/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.4972) |  Loss2: (0.0000) | Acc: (82.00%) (7524/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.4968) |  Loss2: (0.0000) | Acc: (82.00%) (8581/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.5012) |  Loss2: (0.0000) | Acc: (82.00%) (9628/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.4982) |  Loss2: (0.0000) | Acc: (82.00%) (10701/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.5031) |  Loss2: (0.0000) | Acc: (82.00%) (11752/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.4965) |  Loss2: (0.0000) | Acc: (82.00%) (12843/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.4956) |  Loss2: (0.0000) | Acc: (83.00%) (13918/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (14966/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (16020/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.4971) |  Loss2: (0.0000) | Acc: (83.00%) (17108/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (83.00%) (18176/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.4944) |  Loss2: (0.0000) | Acc: (83.00%) (19258/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.4933) |  Loss2: (0.0000) | Acc: (83.00%) (20325/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.4955) |  Loss2: (0.0000) | Acc: (83.00%) (21356/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.4960) |  Loss2: (0.0000) | Acc: (82.00%) (22409/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.4972) |  Loss2: (0.0000) | Acc: (82.00%) (23445/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.4971) |  Loss2: (0.0000) | Acc: (82.00%) (24530/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (25588/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.4964) |  Loss2: (0.0000) | Acc: (82.00%) (26654/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.4963) |  Loss2: (0.0000) | Acc: (82.00%) (27713/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.4971) |  Loss2: (0.0000) | Acc: (82.00%) (28751/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.4980) |  Loss2: (0.0000) | Acc: (82.00%) (29792/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (30861/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.4960) |  Loss2: (0.0000) | Acc: (82.00%) (31943/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.4960) |  Loss2: (0.0000) | Acc: (82.00%) (32997/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.4944) |  Loss2: (0.0000) | Acc: (82.00%) (34085/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (82.00%) (35138/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.4966) |  Loss2: (0.0000) | Acc: (82.00%) (36174/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.4963) |  Loss2: (0.0000) | Acc: (82.00%) (37246/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.4958) |  Loss2: (0.0000) | Acc: (82.00%) (38319/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.4959) |  Loss2: (0.0000) | Acc: (82.00%) (39384/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (82.00%) (40452/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.4943) |  Loss2: (0.0000) | Acc: (82.00%) (41493/50000)
# TEST : Loss: (0.5437) | Acc: (80.00%) (8095/10000)
percent tensor([0.5115, 0.5213, 0.5313, 0.5063, 0.5337, 0.5145, 0.5308, 0.5116, 0.5160,
        0.5225, 0.5159, 0.5371, 0.5108, 0.5118, 0.5181, 0.5071],
       device='cuda:0')
percent tensor([0.4911, 0.4881, 0.4356, 0.4652, 0.4348, 0.4373, 0.4702, 0.4684, 0.5468,
        0.4857, 0.5305, 0.4590, 0.5203, 0.5648, 0.4603, 0.4742],
       device='cuda:0')
percent tensor([0.5890, 0.5238, 0.6181, 0.6136, 0.6166, 0.6050, 0.5627, 0.6133, 0.5721,
        0.5571, 0.5551, 0.5865, 0.5458, 0.5414, 0.5570, 0.5891],
       device='cuda:0')
percent tensor([0.4829, 0.5020, 0.4620, 0.4673, 0.4602, 0.4801, 0.4841, 0.4601, 0.4894,
        0.5009, 0.5050, 0.4775, 0.5045, 0.5050, 0.4814, 0.4847],
       device='cuda:0')
percent tensor([0.4534, 0.5083, 0.5198, 0.5284, 0.5267, 0.5126, 0.4895, 0.4581, 0.5568,
        0.5503, 0.6087, 0.5400, 0.5199, 0.5781, 0.4600, 0.4820],
       device='cuda:0')
percent tensor([0.6260, 0.6286, 0.6241, 0.6180, 0.6182, 0.6141, 0.6357, 0.6285, 0.6232,
        0.6306, 0.6364, 0.6335, 0.6178, 0.6300, 0.6369, 0.6323],
       device='cuda:0')
percent tensor([0.6086, 0.5891, 0.7406, 0.7589, 0.7786, 0.6997, 0.6568, 0.7429, 0.6015,
        0.5965, 0.6129, 0.7015, 0.5701, 0.6581, 0.6311, 0.6487],
       device='cuda:0')
percent tensor([0.9971, 0.9903, 0.9956, 0.9962, 0.9949, 0.9901, 0.9932, 0.9969, 0.9903,
        0.9917, 0.9946, 0.9959, 0.9944, 0.9935, 0.9944, 0.9955],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 40 | Batch_idx: 0 |  Loss: (0.4610) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.4994) |  Loss2: (0.0000) | Acc: (82.00%) (1167/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (82.00%) (2219/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.5078) |  Loss2: (0.0000) | Acc: (82.00%) (3265/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (4308/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.5011) |  Loss2: (0.0000) | Acc: (82.00%) (5396/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.4994) |  Loss2: (0.0000) | Acc: (82.00%) (6457/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.5014) |  Loss2: (0.0000) | Acc: (82.00%) (7505/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.4979) |  Loss2: (0.0000) | Acc: (82.00%) (8582/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.5039) |  Loss2: (0.0000) | Acc: (82.00%) (9615/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.5056) |  Loss2: (0.0000) | Acc: (82.00%) (10657/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.5099) |  Loss2: (0.0000) | Acc: (82.00%) (11702/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.5126) |  Loss2: (0.0000) | Acc: (82.00%) (12735/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.5123) |  Loss2: (0.0000) | Acc: (82.00%) (13781/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.5075) |  Loss2: (0.0000) | Acc: (82.00%) (14859/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.5075) |  Loss2: (0.0000) | Acc: (82.00%) (15917/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (16984/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.5062) |  Loss2: (0.0000) | Acc: (82.00%) (18037/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.5047) |  Loss2: (0.0000) | Acc: (82.00%) (19120/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.5014) |  Loss2: (0.0000) | Acc: (82.00%) (20209/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.5017) |  Loss2: (0.0000) | Acc: (82.00%) (21266/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.4996) |  Loss2: (0.0000) | Acc: (82.00%) (22347/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (23409/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.5001) |  Loss2: (0.0000) | Acc: (82.00%) (24457/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.5001) |  Loss2: (0.0000) | Acc: (82.00%) (25525/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.5002) |  Loss2: (0.0000) | Acc: (82.00%) (26571/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.5008) |  Loss2: (0.0000) | Acc: (82.00%) (27616/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.5021) |  Loss2: (0.0000) | Acc: (82.00%) (28663/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.5023) |  Loss2: (0.0000) | Acc: (82.00%) (29726/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.5037) |  Loss2: (0.0000) | Acc: (82.00%) (30764/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.5034) |  Loss2: (0.0000) | Acc: (82.00%) (31823/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (32877/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.5038) |  Loss2: (0.0000) | Acc: (82.00%) (33935/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (34994/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.5043) |  Loss2: (0.0000) | Acc: (82.00%) (36051/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (37091/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.5049) |  Loss2: (0.0000) | Acc: (82.00%) (38159/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (82.00%) (39199/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.5038) |  Loss2: (0.0000) | Acc: (82.00%) (40273/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.5033) |  Loss2: (0.0000) | Acc: (82.00%) (41295/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_040.pth.tar'
# TEST : Loss: (0.6186) | Acc: (79.00%) (7947/10000)
percent tensor([0.5124, 0.5212, 0.5338, 0.5063, 0.5351, 0.5143, 0.5315, 0.5124, 0.5173,
        0.5234, 0.5166, 0.5395, 0.5115, 0.5111, 0.5183, 0.5073],
       device='cuda:0')
percent tensor([0.4962, 0.4888, 0.4393, 0.4654, 0.4405, 0.4401, 0.4744, 0.4706, 0.5482,
        0.4859, 0.5323, 0.4678, 0.5215, 0.5549, 0.4633, 0.4738],
       device='cuda:0')
percent tensor([0.5900, 0.5150, 0.6247, 0.6190, 0.6222, 0.6107, 0.5536, 0.6144, 0.5705,
        0.5556, 0.5575, 0.5777, 0.5432, 0.5170, 0.5560, 0.5905],
       device='cuda:0')
percent tensor([0.4842, 0.5006, 0.4611, 0.4668, 0.4583, 0.4811, 0.4846, 0.4609, 0.4865,
        0.4986, 0.5019, 0.4782, 0.5051, 0.5053, 0.4819, 0.4842],
       device='cuda:0')
percent tensor([0.4736, 0.5233, 0.5438, 0.5442, 0.5367, 0.5239, 0.5057, 0.4745, 0.5628,
        0.5543, 0.6139, 0.5464, 0.5238, 0.5859, 0.4750, 0.4958],
       device='cuda:0')
percent tensor([0.6262, 0.6283, 0.6210, 0.6191, 0.6170, 0.6130, 0.6355, 0.6325, 0.6204,
        0.6275, 0.6339, 0.6291, 0.6151, 0.6215, 0.6340, 0.6298],
       device='cuda:0')
percent tensor([0.6043, 0.6072, 0.7605, 0.7625, 0.7913, 0.7147, 0.6691, 0.7377, 0.6249,
        0.6230, 0.6364, 0.7134, 0.5910, 0.6638, 0.6264, 0.6617],
       device='cuda:0')
percent tensor([0.9969, 0.9902, 0.9952, 0.9942, 0.9953, 0.9917, 0.9936, 0.9970, 0.9887,
        0.9909, 0.9943, 0.9955, 0.9944, 0.9910, 0.9936, 0.9944],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(171.6467, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(795.0969, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(792.0118, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1523.6105, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(503.6988, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2184.0090, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4300.4561, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1428.2991, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6088.4688, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12111.8477, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4024.9270, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17047.5664, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 41 | Batch_idx: 0 |  Loss: (0.5663) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.4989) |  Loss2: (0.0000) | Acc: (83.00%) (1182/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.4751) |  Loss2: (0.0000) | Acc: (84.00%) (2275/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.4694) |  Loss2: (0.0000) | Acc: (84.00%) (3339/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.4720) |  Loss2: (0.0000) | Acc: (84.00%) (4415/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.4811) |  Loss2: (0.0000) | Acc: (83.00%) (5449/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.4845) |  Loss2: (0.0000) | Acc: (83.00%) (6527/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.4818) |  Loss2: (0.0000) | Acc: (83.00%) (7600/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.4811) |  Loss2: (0.0000) | Acc: (83.00%) (8676/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.4791) |  Loss2: (0.0000) | Acc: (83.00%) (9758/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.4821) |  Loss2: (0.0000) | Acc: (83.00%) (10822/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.4818) |  Loss2: (0.0000) | Acc: (83.00%) (11889/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.4784) |  Loss2: (0.0000) | Acc: (83.00%) (12980/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.4794) |  Loss2: (0.0000) | Acc: (83.00%) (14042/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.4786) |  Loss2: (0.0000) | Acc: (83.00%) (15103/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (16165/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.4805) |  Loss2: (0.0000) | Acc: (83.00%) (17230/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.4803) |  Loss2: (0.0000) | Acc: (83.00%) (18314/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.4796) |  Loss2: (0.0000) | Acc: (83.00%) (19386/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.4789) |  Loss2: (0.0000) | Acc: (83.00%) (20460/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.4791) |  Loss2: (0.0000) | Acc: (83.00%) (21538/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.4802) |  Loss2: (0.0000) | Acc: (83.00%) (22592/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.4799) |  Loss2: (0.0000) | Acc: (83.00%) (23658/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.4797) |  Loss2: (0.0000) | Acc: (83.00%) (24733/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.4803) |  Loss2: (0.0000) | Acc: (83.00%) (25799/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.4803) |  Loss2: (0.0000) | Acc: (83.00%) (26877/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.4805) |  Loss2: (0.0000) | Acc: (83.00%) (27942/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.4808) |  Loss2: (0.0000) | Acc: (83.00%) (28997/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (30055/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (31128/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.4813) |  Loss2: (0.0000) | Acc: (83.00%) (32199/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (83.00%) (33274/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.4811) |  Loss2: (0.0000) | Acc: (83.00%) (34342/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (35419/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (36481/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.4821) |  Loss2: (0.0000) | Acc: (83.00%) (37533/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.4826) |  Loss2: (0.0000) | Acc: (83.00%) (38587/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.4822) |  Loss2: (0.0000) | Acc: (83.00%) (39653/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (40714/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.4833) |  Loss2: (0.0000) | Acc: (83.00%) (41730/50000)
# TEST : Loss: (0.6611) | Acc: (77.00%) (7771/10000)
percent tensor([0.5121, 0.5219, 0.5326, 0.5062, 0.5345, 0.5140, 0.5315, 0.5125, 0.5170,
        0.5234, 0.5165, 0.5383, 0.5112, 0.5123, 0.5182, 0.5074],
       device='cuda:0')
percent tensor([0.4906, 0.4845, 0.4286, 0.4624, 0.4274, 0.4317, 0.4667, 0.4664, 0.5347,
        0.4826, 0.5246, 0.4565, 0.5166, 0.5561, 0.4575, 0.4703],
       device='cuda:0')
percent tensor([0.5910, 0.5149, 0.6302, 0.6208, 0.6285, 0.6078, 0.5604, 0.6158, 0.5741,
        0.5584, 0.5549, 0.5922, 0.5439, 0.5200, 0.5565, 0.5888],
       device='cuda:0')
percent tensor([0.4804, 0.4997, 0.4595, 0.4650, 0.4570, 0.4769, 0.4830, 0.4608, 0.4841,
        0.4984, 0.4999, 0.4738, 0.4989, 0.5073, 0.4790, 0.4825],
       device='cuda:0')
percent tensor([0.4552, 0.5082, 0.5405, 0.5411, 0.5271, 0.5038, 0.4891, 0.4724, 0.5442,
        0.5410, 0.5824, 0.5344, 0.5081, 0.5802, 0.4613, 0.4777],
       device='cuda:0')
percent tensor([0.6199, 0.6277, 0.6180, 0.6136, 0.6147, 0.6124, 0.6326, 0.6242, 0.6167,
        0.6299, 0.6309, 0.6311, 0.6147, 0.6226, 0.6340, 0.6255],
       device='cuda:0')
percent tensor([0.6185, 0.6101, 0.7687, 0.7708, 0.7797, 0.6838, 0.6655, 0.7502, 0.6302,
        0.6416, 0.6331, 0.7280, 0.6088, 0.6811, 0.6330, 0.6644],
       device='cuda:0')
percent tensor([0.9962, 0.9904, 0.9967, 0.9956, 0.9945, 0.9903, 0.9939, 0.9974, 0.9898,
        0.9932, 0.9942, 0.9973, 0.9955, 0.9929, 0.9932, 0.9956],
       device='cuda:0')
Epoch: 42 | Batch_idx: 0 |  Loss: (0.4538) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4861) |  Loss2: (0.0000) | Acc: (83.00%) (1176/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.4685) |  Loss2: (0.0000) | Acc: (84.00%) (2268/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.4725) |  Loss2: (0.0000) | Acc: (83.00%) (3323/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.4539) |  Loss2: (0.0000) | Acc: (84.00%) (4442/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.4518) |  Loss2: (0.0000) | Acc: (84.00%) (5529/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.4533) |  Loss2: (0.0000) | Acc: (84.00%) (6629/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.4566) |  Loss2: (0.0000) | Acc: (84.00%) (7707/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.4642) |  Loss2: (0.0000) | Acc: (84.00%) (8771/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.4604) |  Loss2: (0.0000) | Acc: (84.00%) (9861/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.4612) |  Loss2: (0.0000) | Acc: (84.00%) (10951/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4621) |  Loss2: (0.0000) | Acc: (84.00%) (12009/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4615) |  Loss2: (0.0000) | Acc: (84.00%) (13085/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4627) |  Loss2: (0.0000) | Acc: (84.00%) (14158/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4623) |  Loss2: (0.0000) | Acc: (84.00%) (15246/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4628) |  Loss2: (0.0000) | Acc: (84.00%) (16301/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4631) |  Loss2: (0.0000) | Acc: (84.00%) (17385/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4666) |  Loss2: (0.0000) | Acc: (84.00%) (18428/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4666) |  Loss2: (0.0000) | Acc: (84.00%) (19508/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.4654) |  Loss2: (0.0000) | Acc: (84.00%) (20587/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.4667) |  Loss2: (0.0000) | Acc: (84.00%) (21652/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.4682) |  Loss2: (0.0000) | Acc: (84.00%) (22703/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.4682) |  Loss2: (0.0000) | Acc: (84.00%) (23777/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.4690) |  Loss2: (0.0000) | Acc: (84.00%) (24846/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.4701) |  Loss2: (0.0000) | Acc: (83.00%) (25900/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.4696) |  Loss2: (0.0000) | Acc: (83.00%) (26985/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.4689) |  Loss2: (0.0000) | Acc: (84.00%) (28068/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4702) |  Loss2: (0.0000) | Acc: (83.00%) (29122/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4700) |  Loss2: (0.0000) | Acc: (83.00%) (30188/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4692) |  Loss2: (0.0000) | Acc: (83.00%) (31261/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4691) |  Loss2: (0.0000) | Acc: (83.00%) (32341/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4695) |  Loss2: (0.0000) | Acc: (83.00%) (33413/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4686) |  Loss2: (0.0000) | Acc: (83.00%) (34499/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4692) |  Loss2: (0.0000) | Acc: (83.00%) (35555/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4693) |  Loss2: (0.0000) | Acc: (83.00%) (36624/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4690) |  Loss2: (0.0000) | Acc: (83.00%) (37696/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4680) |  Loss2: (0.0000) | Acc: (83.00%) (38784/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4686) |  Loss2: (0.0000) | Acc: (83.00%) (39827/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4688) |  Loss2: (0.0000) | Acc: (83.00%) (40902/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4691) |  Loss2: (0.0000) | Acc: (83.00%) (41932/50000)
# TEST : Loss: (0.7290) | Acc: (76.00%) (7695/10000)
percent tensor([0.5122, 0.5216, 0.5327, 0.5067, 0.5345, 0.5156, 0.5310, 0.5122, 0.5160,
        0.5230, 0.5169, 0.5378, 0.5114, 0.5107, 0.5191, 0.5078],
       device='cuda:0')
percent tensor([0.4957, 0.4824, 0.4464, 0.4710, 0.4429, 0.4342, 0.4710, 0.4730, 0.5425,
        0.4850, 0.5265, 0.4669, 0.5204, 0.5462, 0.4581, 0.4716],
       device='cuda:0')
percent tensor([0.5969, 0.5178, 0.6262, 0.6168, 0.6266, 0.6143, 0.5623, 0.6169, 0.5864,
        0.5597, 0.5678, 0.5808, 0.5488, 0.5261, 0.5584, 0.5948],
       device='cuda:0')
percent tensor([0.4798, 0.5011, 0.4585, 0.4685, 0.4560, 0.4760, 0.4840, 0.4603, 0.4833,
        0.4997, 0.5002, 0.4771, 0.5015, 0.5081, 0.4808, 0.4826],
       device='cuda:0')
percent tensor([0.4546, 0.5101, 0.5208, 0.5436, 0.5180, 0.5164, 0.4890, 0.4607, 0.5521,
        0.5406, 0.5988, 0.5330, 0.5115, 0.5845, 0.4644, 0.4862],
       device='cuda:0')
percent tensor([0.6307, 0.6353, 0.6196, 0.6201, 0.6235, 0.6201, 0.6379, 0.6272, 0.6248,
        0.6352, 0.6353, 0.6358, 0.6194, 0.6334, 0.6384, 0.6333],
       device='cuda:0')
percent tensor([0.6106, 0.6043, 0.7504, 0.7620, 0.7716, 0.7059, 0.6714, 0.7344, 0.6152,
        0.6097, 0.6325, 0.6890, 0.5864, 0.6850, 0.6173, 0.6528],
       device='cuda:0')
percent tensor([0.9981, 0.9896, 0.9967, 0.9962, 0.9956, 0.9917, 0.9952, 0.9983, 0.9922,
        0.9929, 0.9951, 0.9951, 0.9933, 0.9935, 0.9961, 0.9973],
       device='cuda:0')
Epoch: 43 | Batch_idx: 0 |  Loss: (0.4368) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4277) |  Loss2: (0.0000) | Acc: (85.00%) (1202/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4457) |  Loss2: (0.0000) | Acc: (84.00%) (2268/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4515) |  Loss2: (0.0000) | Acc: (84.00%) (3338/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4509) |  Loss2: (0.0000) | Acc: (84.00%) (4412/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4472) |  Loss2: (0.0000) | Acc: (84.00%) (5518/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4506) |  Loss2: (0.0000) | Acc: (84.00%) (6596/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4495) |  Loss2: (0.0000) | Acc: (84.00%) (7673/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4531) |  Loss2: (0.0000) | Acc: (84.00%) (8741/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4546) |  Loss2: (0.0000) | Acc: (84.00%) (9812/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4568) |  Loss2: (0.0000) | Acc: (84.00%) (10888/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4575) |  Loss2: (0.0000) | Acc: (84.00%) (11958/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4542) |  Loss2: (0.0000) | Acc: (84.00%) (13049/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4515) |  Loss2: (0.0000) | Acc: (84.00%) (14151/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4532) |  Loss2: (0.0000) | Acc: (84.00%) (15222/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4559) |  Loss2: (0.0000) | Acc: (84.00%) (16270/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4574) |  Loss2: (0.0000) | Acc: (84.00%) (17333/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4569) |  Loss2: (0.0000) | Acc: (84.00%) (18410/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4542) |  Loss2: (0.0000) | Acc: (84.00%) (19504/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4537) |  Loss2: (0.0000) | Acc: (84.00%) (20580/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4535) |  Loss2: (0.0000) | Acc: (84.00%) (21654/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4512) |  Loss2: (0.0000) | Acc: (84.00%) (22771/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4518) |  Loss2: (0.0000) | Acc: (84.00%) (23848/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4515) |  Loss2: (0.0000) | Acc: (84.00%) (24926/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4507) |  Loss2: (0.0000) | Acc: (84.00%) (25992/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4492) |  Loss2: (0.0000) | Acc: (84.00%) (27086/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4480) |  Loss2: (0.0000) | Acc: (84.00%) (28190/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4480) |  Loss2: (0.0000) | Acc: (84.00%) (29265/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4481) |  Loss2: (0.0000) | Acc: (84.00%) (30341/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4490) |  Loss2: (0.0000) | Acc: (84.00%) (31412/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4497) |  Loss2: (0.0000) | Acc: (84.00%) (32475/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4511) |  Loss2: (0.0000) | Acc: (84.00%) (33537/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4517) |  Loss2: (0.0000) | Acc: (84.00%) (34594/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4518) |  Loss2: (0.0000) | Acc: (84.00%) (35668/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4519) |  Loss2: (0.0000) | Acc: (84.00%) (36750/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4509) |  Loss2: (0.0000) | Acc: (84.00%) (37851/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4506) |  Loss2: (0.0000) | Acc: (84.00%) (38952/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4510) |  Loss2: (0.0000) | Acc: (84.00%) (40022/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4507) |  Loss2: (0.0000) | Acc: (84.00%) (41106/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4512) |  Loss2: (0.0000) | Acc: (84.00%) (42121/50000)
# TEST : Loss: (0.5308) | Acc: (81.00%) (8177/10000)
percent tensor([0.5112, 0.5214, 0.5295, 0.5057, 0.5318, 0.5134, 0.5296, 0.5116, 0.5155,
        0.5222, 0.5160, 0.5352, 0.5108, 0.5106, 0.5180, 0.5070],
       device='cuda:0')
percent tensor([0.4957, 0.4844, 0.4475, 0.4735, 0.4508, 0.4427, 0.4731, 0.4728, 0.5413,
        0.4850, 0.5249, 0.4674, 0.5184, 0.5476, 0.4627, 0.4732],
       device='cuda:0')
percent tensor([0.5856, 0.5189, 0.6211, 0.6150, 0.6186, 0.6053, 0.5588, 0.6123, 0.5752,
        0.5563, 0.5604, 0.5770, 0.5412, 0.5353, 0.5558, 0.5890],
       device='cuda:0')
percent tensor([0.4826, 0.5019, 0.4622, 0.4688, 0.4598, 0.4788, 0.4854, 0.4637, 0.4844,
        0.5021, 0.5024, 0.4782, 0.5029, 0.5047, 0.4808, 0.4845],
       device='cuda:0')
percent tensor([0.4511, 0.4932, 0.5209, 0.5452, 0.5294, 0.5208, 0.4799, 0.4682, 0.5264,
        0.5290, 0.5802, 0.5261, 0.4907, 0.5654, 0.4607, 0.4860],
       device='cuda:0')
percent tensor([0.6222, 0.6295, 0.6152, 0.6137, 0.6191, 0.6162, 0.6314, 0.6228, 0.6192,
        0.6318, 0.6327, 0.6282, 0.6163, 0.6282, 0.6337, 0.6278],
       device='cuda:0')
percent tensor([0.6173, 0.5989, 0.7379, 0.7624, 0.7591, 0.7028, 0.6623, 0.7249, 0.5973,
        0.5966, 0.6098, 0.7002, 0.5810, 0.6776, 0.6163, 0.6590],
       device='cuda:0')
percent tensor([0.9972, 0.9898, 0.9961, 0.9954, 0.9949, 0.9908, 0.9943, 0.9969, 0.9935,
        0.9926, 0.9955, 0.9963, 0.9944, 0.9937, 0.9941, 0.9958],
       device='cuda:0')
Epoch: 44 | Batch_idx: 0 |  Loss: (0.4095) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.4193) |  Loss2: (0.0000) | Acc: (86.00%) (1213/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.4225) |  Loss2: (0.0000) | Acc: (86.00%) (2316/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.4335) |  Loss2: (0.0000) | Acc: (85.00%) (3397/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.4358) |  Loss2: (0.0000) | Acc: (85.00%) (4479/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.4312) |  Loss2: (0.0000) | Acc: (85.00%) (5567/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.4341) |  Loss2: (0.0000) | Acc: (85.00%) (6643/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.4354) |  Loss2: (0.0000) | Acc: (84.00%) (7722/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.4339) |  Loss2: (0.0000) | Acc: (84.00%) (8806/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.4392) |  Loss2: (0.0000) | Acc: (84.00%) (9881/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.4370) |  Loss2: (0.0000) | Acc: (84.00%) (10976/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.4345) |  Loss2: (0.0000) | Acc: (85.00%) (12087/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (85.00%) (13166/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.4341) |  Loss2: (0.0000) | Acc: (85.00%) (14264/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.4368) |  Loss2: (0.0000) | Acc: (84.00%) (15329/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.4401) |  Loss2: (0.0000) | Acc: (84.00%) (16400/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.4385) |  Loss2: (0.0000) | Acc: (84.00%) (17497/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.4382) |  Loss2: (0.0000) | Acc: (84.00%) (18583/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.4387) |  Loss2: (0.0000) | Acc: (84.00%) (19663/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.4393) |  Loss2: (0.0000) | Acc: (84.00%) (20756/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.4393) |  Loss2: (0.0000) | Acc: (84.00%) (21839/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.4415) |  Loss2: (0.0000) | Acc: (84.00%) (22899/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.4411) |  Loss2: (0.0000) | Acc: (84.00%) (23996/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.4416) |  Loss2: (0.0000) | Acc: (84.00%) (25086/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.4411) |  Loss2: (0.0000) | Acc: (84.00%) (26177/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.4408) |  Loss2: (0.0000) | Acc: (84.00%) (27256/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.4417) |  Loss2: (0.0000) | Acc: (84.00%) (28347/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.4420) |  Loss2: (0.0000) | Acc: (84.00%) (29422/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.4415) |  Loss2: (0.0000) | Acc: (84.00%) (30517/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.4415) |  Loss2: (0.0000) | Acc: (84.00%) (31584/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.4411) |  Loss2: (0.0000) | Acc: (84.00%) (32683/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.4398) |  Loss2: (0.0000) | Acc: (84.00%) (33781/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.4404) |  Loss2: (0.0000) | Acc: (84.00%) (34845/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.4399) |  Loss2: (0.0000) | Acc: (84.00%) (35927/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.4388) |  Loss2: (0.0000) | Acc: (84.00%) (37041/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.4392) |  Loss2: (0.0000) | Acc: (84.00%) (38124/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.4387) |  Loss2: (0.0000) | Acc: (84.00%) (39218/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.4379) |  Loss2: (0.0000) | Acc: (84.00%) (40331/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.4392) |  Loss2: (0.0000) | Acc: (84.00%) (41402/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (84.00%) (42461/50000)
# TEST : Loss: (0.6439) | Acc: (79.00%) (7973/10000)
percent tensor([0.5111, 0.5207, 0.5297, 0.5049, 0.5323, 0.5146, 0.5298, 0.5109, 0.5156,
        0.5218, 0.5161, 0.5357, 0.5105, 0.5102, 0.5183, 0.5068],
       device='cuda:0')
percent tensor([0.4927, 0.4922, 0.4343, 0.4697, 0.4404, 0.4453, 0.4757, 0.4706, 0.5409,
        0.4837, 0.5279, 0.4599, 0.5176, 0.5581, 0.4662, 0.4751],
       device='cuda:0')
percent tensor([0.5872, 0.5143, 0.6294, 0.6205, 0.6237, 0.6055, 0.5571, 0.6167, 0.5782,
        0.5584, 0.5563, 0.5867, 0.5417, 0.5271, 0.5533, 0.5881],
       device='cuda:0')
percent tensor([0.4829, 0.5034, 0.4580, 0.4678, 0.4579, 0.4811, 0.4853, 0.4619, 0.4856,
        0.5002, 0.5027, 0.4737, 0.5018, 0.5092, 0.4817, 0.4844],
       device='cuda:0')
percent tensor([0.4600, 0.5196, 0.5327, 0.5626, 0.5435, 0.5404, 0.4981, 0.4816, 0.5364,
        0.5280, 0.5924, 0.5303, 0.5066, 0.5848, 0.4766, 0.4916],
       device='cuda:0')
percent tensor([0.6299, 0.6403, 0.6187, 0.6198, 0.6231, 0.6227, 0.6420, 0.6313, 0.6274,
        0.6390, 0.6339, 0.6410, 0.6202, 0.6346, 0.6437, 0.6328],
       device='cuda:0')
percent tensor([0.6120, 0.6176, 0.7450, 0.7612, 0.7613, 0.6865, 0.6683, 0.7234, 0.5997,
        0.6072, 0.6300, 0.6986, 0.6014, 0.6802, 0.6147, 0.6542],
       device='cuda:0')
percent tensor([0.9968, 0.9929, 0.9948, 0.9933, 0.9950, 0.9863, 0.9940, 0.9966, 0.9928,
        0.9939, 0.9945, 0.9960, 0.9935, 0.9934, 0.9949, 0.9950],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 45 | Batch_idx: 0 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.4354) |  Loss2: (0.0000) | Acc: (84.00%) (1195/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4661) |  Loss2: (0.0000) | Acc: (83.00%) (2250/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4853) |  Loss2: (0.0000) | Acc: (83.00%) (3301/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.5042) |  Loss2: (0.0000) | Acc: (82.00%) (4316/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.5088) |  Loss2: (0.0000) | Acc: (82.00%) (5377/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.5156) |  Loss2: (0.0000) | Acc: (82.00%) (6424/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.5160) |  Loss2: (0.0000) | Acc: (82.00%) (7477/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.5151) |  Loss2: (0.0000) | Acc: (82.00%) (8526/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.5116) |  Loss2: (0.0000) | Acc: (82.00%) (9579/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.5149) |  Loss2: (0.0000) | Acc: (81.00%) (10599/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.5162) |  Loss2: (0.0000) | Acc: (81.00%) (11650/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.5163) |  Loss2: (0.0000) | Acc: (81.00%) (12698/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.5186) |  Loss2: (0.0000) | Acc: (81.00%) (13726/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.5154) |  Loss2: (0.0000) | Acc: (82.00%) (14800/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.5129) |  Loss2: (0.0000) | Acc: (82.00%) (15868/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.5118) |  Loss2: (0.0000) | Acc: (82.00%) (16942/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.5099) |  Loss2: (0.0000) | Acc: (82.00%) (18007/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.5115) |  Loss2: (0.0000) | Acc: (82.00%) (19066/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.5091) |  Loss2: (0.0000) | Acc: (82.00%) (20145/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.5084) |  Loss2: (0.0000) | Acc: (82.00%) (21208/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.5053) |  Loss2: (0.0000) | Acc: (82.00%) (22294/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.5063) |  Loss2: (0.0000) | Acc: (82.00%) (23340/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.5031) |  Loss2: (0.0000) | Acc: (82.00%) (24429/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.5030) |  Loss2: (0.0000) | Acc: (82.00%) (25495/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.5028) |  Loss2: (0.0000) | Acc: (82.00%) (26544/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.5025) |  Loss2: (0.0000) | Acc: (82.00%) (27610/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.5020) |  Loss2: (0.0000) | Acc: (82.00%) (28666/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.5019) |  Loss2: (0.0000) | Acc: (82.00%) (29720/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4995) |  Loss2: (0.0000) | Acc: (82.00%) (30805/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4985) |  Loss2: (0.0000) | Acc: (82.00%) (31874/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4975) |  Loss2: (0.0000) | Acc: (82.00%) (32947/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (33992/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4975) |  Loss2: (0.0000) | Acc: (82.00%) (35065/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4972) |  Loss2: (0.0000) | Acc: (82.00%) (36134/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4958) |  Loss2: (0.0000) | Acc: (82.00%) (37216/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4947) |  Loss2: (0.0000) | Acc: (82.00%) (38295/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4927) |  Loss2: (0.0000) | Acc: (82.00%) (39374/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4919) |  Loss2: (0.0000) | Acc: (82.00%) (40445/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4912) |  Loss2: (0.0000) | Acc: (82.00%) (41482/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_045.pth.tar'
# TEST : Loss: (0.5492) | Acc: (81.00%) (8153/10000)
percent tensor([0.5043, 0.5109, 0.5277, 0.4987, 0.5284, 0.5082, 0.5224, 0.5050, 0.5079,
        0.5141, 0.5067, 0.5319, 0.5023, 0.5005, 0.5098, 0.4988],
       device='cuda:0')
percent tensor([0.4873, 0.4873, 0.4275, 0.4677, 0.4323, 0.4388, 0.4693, 0.4718, 0.5314,
        0.4777, 0.5159, 0.4504, 0.5099, 0.5526, 0.4637, 0.4726],
       device='cuda:0')
percent tensor([0.5731, 0.5039, 0.5947, 0.5969, 0.5933, 0.5931, 0.5396, 0.5921, 0.5497,
        0.5414, 0.5379, 0.5559, 0.5305, 0.5055, 0.5465, 0.5740],
       device='cuda:0')
percent tensor([0.5015, 0.5188, 0.4758, 0.4868, 0.4776, 0.4974, 0.5045, 0.4850, 0.5014,
        0.5138, 0.5153, 0.4906, 0.5148, 0.5250, 0.5018, 0.5033],
       device='cuda:0')
percent tensor([0.4363, 0.4979, 0.5632, 0.6104, 0.5717, 0.5686, 0.4991, 0.4819, 0.5599,
        0.5012, 0.5896, 0.5382, 0.4637, 0.6162, 0.4553, 0.4873],
       device='cuda:0')
percent tensor([0.6085, 0.6177, 0.6035, 0.6104, 0.6092, 0.6095, 0.6238, 0.6114, 0.6151,
        0.6183, 0.6210, 0.6302, 0.6040, 0.6215, 0.6241, 0.6170],
       device='cuda:0')
percent tensor([0.6447, 0.6405, 0.7957, 0.8145, 0.8088, 0.7338, 0.7153, 0.7702, 0.6310,
        0.6341, 0.6635, 0.7426, 0.6190, 0.7102, 0.6452, 0.6857],
       device='cuda:0')
percent tensor([0.9964, 0.9905, 0.9955, 0.9959, 0.9951, 0.9902, 0.9943, 0.9959, 0.9929,
        0.9924, 0.9948, 0.9964, 0.9924, 0.9943, 0.9935, 0.9951],
       device='cuda:0')
Epoch: 46 | Batch_idx: 0 |  Loss: (0.5249) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.4801) |  Loss2: (0.0000) | Acc: (83.00%) (1175/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.4765) |  Loss2: (0.0000) | Acc: (83.00%) (2237/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.4843) |  Loss2: (0.0000) | Acc: (83.00%) (3299/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4828) |  Loss2: (0.0000) | Acc: (83.00%) (4378/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4749) |  Loss2: (0.0000) | Acc: (83.00%) (5462/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4718) |  Loss2: (0.0000) | Acc: (83.00%) (6543/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4730) |  Loss2: (0.0000) | Acc: (83.00%) (7612/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4725) |  Loss2: (0.0000) | Acc: (83.00%) (8670/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4743) |  Loss2: (0.0000) | Acc: (83.00%) (9741/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4703) |  Loss2: (0.0000) | Acc: (83.00%) (10820/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4687) |  Loss2: (0.0000) | Acc: (83.00%) (11913/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4688) |  Loss2: (0.0000) | Acc: (83.00%) (12993/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4692) |  Loss2: (0.0000) | Acc: (83.00%) (14067/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4674) |  Loss2: (0.0000) | Acc: (83.00%) (15155/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4673) |  Loss2: (0.0000) | Acc: (83.00%) (16231/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4662) |  Loss2: (0.0000) | Acc: (84.00%) (17319/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4649) |  Loss2: (0.0000) | Acc: (84.00%) (18401/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4629) |  Loss2: (0.0000) | Acc: (84.00%) (19477/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4604) |  Loss2: (0.0000) | Acc: (84.00%) (20576/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4602) |  Loss2: (0.0000) | Acc: (84.00%) (21648/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4597) |  Loss2: (0.0000) | Acc: (84.00%) (22732/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4608) |  Loss2: (0.0000) | Acc: (84.00%) (23808/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4603) |  Loss2: (0.0000) | Acc: (84.00%) (24883/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4598) |  Loss2: (0.0000) | Acc: (84.00%) (25969/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4581) |  Loss2: (0.0000) | Acc: (84.00%) (27062/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4576) |  Loss2: (0.0000) | Acc: (84.00%) (28139/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4593) |  Loss2: (0.0000) | Acc: (84.00%) (29196/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4598) |  Loss2: (0.0000) | Acc: (84.00%) (30256/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4599) |  Loss2: (0.0000) | Acc: (84.00%) (31332/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4594) |  Loss2: (0.0000) | Acc: (84.00%) (32420/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4592) |  Loss2: (0.0000) | Acc: (84.00%) (33502/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4599) |  Loss2: (0.0000) | Acc: (84.00%) (34571/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4605) |  Loss2: (0.0000) | Acc: (84.00%) (35626/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4606) |  Loss2: (0.0000) | Acc: (84.00%) (36713/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4606) |  Loss2: (0.0000) | Acc: (84.00%) (37793/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4592) |  Loss2: (0.0000) | Acc: (84.00%) (38888/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4577) |  Loss2: (0.0000) | Acc: (84.00%) (39992/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4574) |  Loss2: (0.0000) | Acc: (84.00%) (41063/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4569) |  Loss2: (0.0000) | Acc: (84.00%) (42122/50000)
# TEST : Loss: (0.5217) | Acc: (82.00%) (8240/10000)
percent tensor([0.5084, 0.5140, 0.5326, 0.5036, 0.5332, 0.5112, 0.5263, 0.5099, 0.5111,
        0.5181, 0.5095, 0.5368, 0.5061, 0.5031, 0.5132, 0.5027],
       device='cuda:0')
percent tensor([0.4848, 0.4814, 0.4304, 0.4696, 0.4353, 0.4385, 0.4667, 0.4745, 0.5248,
        0.4736, 0.5078, 0.4486, 0.5042, 0.5453, 0.4611, 0.4693],
       device='cuda:0')
percent tensor([0.5785, 0.5120, 0.5935, 0.5983, 0.5935, 0.5984, 0.5457, 0.5948, 0.5520,
        0.5466, 0.5430, 0.5573, 0.5368, 0.5121, 0.5551, 0.5800],
       device='cuda:0')
percent tensor([0.5081, 0.5214, 0.4854, 0.4948, 0.4869, 0.5038, 0.5103, 0.4943, 0.5057,
        0.5177, 0.5181, 0.4976, 0.5184, 0.5262, 0.5083, 0.5090],
       device='cuda:0')
percent tensor([0.4450, 0.5129, 0.5685, 0.6111, 0.5763, 0.5652, 0.5102, 0.4797, 0.5660,
        0.5156, 0.5953, 0.5532, 0.4754, 0.6171, 0.4631, 0.4884],
       device='cuda:0')
percent tensor([0.6210, 0.6293, 0.6185, 0.6242, 0.6226, 0.6196, 0.6361, 0.6235, 0.6283,
        0.6295, 0.6349, 0.6466, 0.6179, 0.6344, 0.6376, 0.6275],
       device='cuda:0')
percent tensor([0.6570, 0.6518, 0.8090, 0.8228, 0.8225, 0.7461, 0.7282, 0.7877, 0.6367,
        0.6444, 0.6738, 0.7538, 0.6180, 0.7167, 0.6604, 0.6951],
       device='cuda:0')
percent tensor([0.9969, 0.9915, 0.9957, 0.9958, 0.9956, 0.9907, 0.9949, 0.9964, 0.9931,
        0.9929, 0.9953, 0.9966, 0.9930, 0.9948, 0.9938, 0.9956],
       device='cuda:0')
Epoch: 47 | Batch_idx: 0 |  Loss: (0.4284) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.4837) |  Loss2: (0.0000) | Acc: (83.00%) (1180/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.4638) |  Loss2: (0.0000) | Acc: (83.00%) (2246/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.4508) |  Loss2: (0.0000) | Acc: (84.00%) (3352/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4542) |  Loss2: (0.0000) | Acc: (84.00%) (4429/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4497) |  Loss2: (0.0000) | Acc: (84.00%) (5523/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4476) |  Loss2: (0.0000) | Acc: (84.00%) (6621/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4470) |  Loss2: (0.0000) | Acc: (84.00%) (7717/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4444) |  Loss2: (0.0000) | Acc: (85.00%) (8821/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4440) |  Loss2: (0.0000) | Acc: (85.00%) (9903/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4447) |  Loss2: (0.0000) | Acc: (84.00%) (10983/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4448) |  Loss2: (0.0000) | Acc: (84.00%) (12055/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4410) |  Loss2: (0.0000) | Acc: (84.00%) (13163/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4390) |  Loss2: (0.0000) | Acc: (85.00%) (14265/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4397) |  Loss2: (0.0000) | Acc: (85.00%) (15344/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4380) |  Loss2: (0.0000) | Acc: (85.00%) (16448/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4383) |  Loss2: (0.0000) | Acc: (85.00%) (17537/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4370) |  Loss2: (0.0000) | Acc: (85.00%) (18630/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4369) |  Loss2: (0.0000) | Acc: (85.00%) (19725/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4373) |  Loss2: (0.0000) | Acc: (85.00%) (20808/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4368) |  Loss2: (0.0000) | Acc: (85.00%) (21910/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (85.00%) (22992/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4366) |  Loss2: (0.0000) | Acc: (85.00%) (24074/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4365) |  Loss2: (0.0000) | Acc: (85.00%) (25158/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4353) |  Loss2: (0.0000) | Acc: (85.00%) (26256/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4360) |  Loss2: (0.0000) | Acc: (85.00%) (27349/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4362) |  Loss2: (0.0000) | Acc: (85.00%) (28422/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4365) |  Loss2: (0.0000) | Acc: (85.00%) (29506/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4378) |  Loss2: (0.0000) | Acc: (85.00%) (30575/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4383) |  Loss2: (0.0000) | Acc: (84.00%) (31656/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4379) |  Loss2: (0.0000) | Acc: (84.00%) (32743/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4375) |  Loss2: (0.0000) | Acc: (84.00%) (33821/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4370) |  Loss2: (0.0000) | Acc: (84.00%) (34908/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4367) |  Loss2: (0.0000) | Acc: (84.00%) (36008/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4374) |  Loss2: (0.0000) | Acc: (84.00%) (37084/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4370) |  Loss2: (0.0000) | Acc: (84.00%) (38167/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4368) |  Loss2: (0.0000) | Acc: (84.00%) (39266/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4368) |  Loss2: (0.0000) | Acc: (84.00%) (40346/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4367) |  Loss2: (0.0000) | Acc: (84.00%) (41430/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4375) |  Loss2: (0.0000) | Acc: (84.00%) (42467/50000)
# TEST : Loss: (0.5083) | Acc: (82.00%) (8250/10000)
percent tensor([0.5121, 0.5177, 0.5363, 0.5080, 0.5369, 0.5142, 0.5300, 0.5145, 0.5145,
        0.5221, 0.5128, 0.5406, 0.5098, 0.5068, 0.5168, 0.5067],
       device='cuda:0')
percent tensor([0.4827, 0.4775, 0.4325, 0.4703, 0.4370, 0.4367, 0.4647, 0.4764, 0.5215,
        0.4710, 0.5020, 0.4477, 0.5006, 0.5410, 0.4585, 0.4661],
       device='cuda:0')
percent tensor([0.5799, 0.5158, 0.5901, 0.5971, 0.5909, 0.5995, 0.5477, 0.5947, 0.5521,
        0.5487, 0.5455, 0.5551, 0.5387, 0.5164, 0.5579, 0.5819],
       device='cuda:0')
percent tensor([0.5076, 0.5188, 0.4869, 0.4960, 0.4882, 0.5044, 0.5092, 0.4951, 0.5045,
        0.5155, 0.5157, 0.4972, 0.5162, 0.5232, 0.5075, 0.5083],
       device='cuda:0')
percent tensor([0.4387, 0.5152, 0.5642, 0.6081, 0.5712, 0.5586, 0.5093, 0.4706, 0.5655,
        0.5145, 0.5927, 0.5532, 0.4702, 0.6198, 0.4602, 0.4806],
       device='cuda:0')
percent tensor([0.6265, 0.6347, 0.6269, 0.6320, 0.6299, 0.6251, 0.6422, 0.6285, 0.6359,
        0.6350, 0.6434, 0.6567, 0.6250, 0.6425, 0.6444, 0.6320],
       device='cuda:0')
percent tensor([0.6573, 0.6551, 0.8105, 0.8238, 0.8246, 0.7515, 0.7266, 0.7874, 0.6355,
        0.6422, 0.6742, 0.7483, 0.6117, 0.7166, 0.6577, 0.6962],
       device='cuda:0')
percent tensor([0.9972, 0.9925, 0.9961, 0.9960, 0.9959, 0.9914, 0.9954, 0.9968, 0.9938,
        0.9936, 0.9959, 0.9969, 0.9934, 0.9955, 0.9947, 0.9960],
       device='cuda:0')
Epoch: 48 | Batch_idx: 0 |  Loss: (0.3464) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.4303) |  Loss2: (0.0000) | Acc: (84.00%) (1195/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (2298/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.4345) |  Loss2: (0.0000) | Acc: (84.00%) (3369/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.4295) |  Loss2: (0.0000) | Acc: (85.00%) (4461/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.4372) |  Loss2: (0.0000) | Acc: (84.00%) (5524/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.4391) |  Loss2: (0.0000) | Acc: (84.00%) (6606/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.4345) |  Loss2: (0.0000) | Acc: (84.00%) (7709/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.4375) |  Loss2: (0.0000) | Acc: (84.00%) (8785/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.4422) |  Loss2: (0.0000) | Acc: (84.00%) (9855/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.4421) |  Loss2: (0.0000) | Acc: (84.00%) (10941/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.4410) |  Loss2: (0.0000) | Acc: (84.00%) (12028/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.4427) |  Loss2: (0.0000) | Acc: (84.00%) (13108/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.4434) |  Loss2: (0.0000) | Acc: (84.00%) (14189/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.4419) |  Loss2: (0.0000) | Acc: (84.00%) (15284/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.4412) |  Loss2: (0.0000) | Acc: (84.00%) (16380/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.4397) |  Loss2: (0.0000) | Acc: (84.00%) (17463/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.4399) |  Loss2: (0.0000) | Acc: (84.00%) (18550/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.4395) |  Loss2: (0.0000) | Acc: (84.00%) (19644/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.4395) |  Loss2: (0.0000) | Acc: (84.00%) (20726/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.4402) |  Loss2: (0.0000) | Acc: (84.00%) (21808/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.4379) |  Loss2: (0.0000) | Acc: (84.00%) (22913/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.4385) |  Loss2: (0.0000) | Acc: (84.00%) (23986/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.4379) |  Loss2: (0.0000) | Acc: (84.00%) (25086/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.4372) |  Loss2: (0.0000) | Acc: (84.00%) (26172/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.4359) |  Loss2: (0.0000) | Acc: (84.00%) (27271/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.4349) |  Loss2: (0.0000) | Acc: (84.00%) (28370/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.4340) |  Loss2: (0.0000) | Acc: (84.00%) (29474/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (85.00%) (30594/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.4310) |  Loss2: (0.0000) | Acc: (85.00%) (31691/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.4307) |  Loss2: (0.0000) | Acc: (85.00%) (32783/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.4313) |  Loss2: (0.0000) | Acc: (85.00%) (33873/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.4316) |  Loss2: (0.0000) | Acc: (85.00%) (34960/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.4324) |  Loss2: (0.0000) | Acc: (85.00%) (36034/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (85.00%) (37141/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.4313) |  Loss2: (0.0000) | Acc: (85.00%) (38240/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.4308) |  Loss2: (0.0000) | Acc: (85.00%) (39341/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.4300) |  Loss2: (0.0000) | Acc: (85.00%) (40443/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.4303) |  Loss2: (0.0000) | Acc: (85.00%) (41532/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.4303) |  Loss2: (0.0000) | Acc: (85.00%) (42565/50000)
# TEST : Loss: (0.4995) | Acc: (82.00%) (8295/10000)
percent tensor([0.5131, 0.5181, 0.5381, 0.5094, 0.5383, 0.5150, 0.5309, 0.5159, 0.5149,
        0.5230, 0.5130, 0.5419, 0.5104, 0.5072, 0.5172, 0.5075],
       device='cuda:0')
percent tensor([0.4823, 0.4763, 0.4342, 0.4719, 0.4385, 0.4374, 0.4646, 0.4781, 0.5194,
        0.4705, 0.4996, 0.4475, 0.4989, 0.5392, 0.4585, 0.4660],
       device='cuda:0')
percent tensor([0.5817, 0.5160, 0.5900, 0.6000, 0.5918, 0.6042, 0.5487, 0.5968, 0.5521,
        0.5493, 0.5461, 0.5535, 0.5382, 0.5182, 0.5604, 0.5851],
       device='cuda:0')
percent tensor([0.5082, 0.5182, 0.4885, 0.4973, 0.4897, 0.5057, 0.5095, 0.4966, 0.5043,
        0.5150, 0.5152, 0.4976, 0.5154, 0.5222, 0.5083, 0.5089],
       device='cuda:0')
percent tensor([0.4379, 0.5195, 0.5637, 0.6069, 0.5696, 0.5608, 0.5086, 0.4625, 0.5666,
        0.5147, 0.5904, 0.5521, 0.4726, 0.6194, 0.4579, 0.4796],
       device='cuda:0')
percent tensor([0.6303, 0.6378, 0.6332, 0.6379, 0.6349, 0.6291, 0.6459, 0.6323, 0.6413,
        0.6373, 0.6482, 0.6630, 0.6295, 0.6473, 0.6486, 0.6345],
       device='cuda:0')
percent tensor([0.6680, 0.6676, 0.8125, 0.8238, 0.8262, 0.7630, 0.7332, 0.7881, 0.6454,
        0.6502, 0.6823, 0.7489, 0.6250, 0.7257, 0.6625, 0.7047],
       device='cuda:0')
percent tensor([0.9975, 0.9932, 0.9963, 0.9961, 0.9962, 0.9925, 0.9958, 0.9971, 0.9942,
        0.9941, 0.9964, 0.9970, 0.9943, 0.9960, 0.9951, 0.9964],
       device='cuda:0')
Epoch: 49 | Batch_idx: 0 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.4061) |  Loss2: (0.0000) | Acc: (86.00%) (1218/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.4328) |  Loss2: (0.0000) | Acc: (85.00%) (2293/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.4460) |  Loss2: (0.0000) | Acc: (84.00%) (3358/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.4459) |  Loss2: (0.0000) | Acc: (84.00%) (4429/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.4382) |  Loss2: (0.0000) | Acc: (84.00%) (5524/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.4346) |  Loss2: (0.0000) | Acc: (84.00%) (6628/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.4347) |  Loss2: (0.0000) | Acc: (84.00%) (7721/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.4300) |  Loss2: (0.0000) | Acc: (85.00%) (8831/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.4343) |  Loss2: (0.0000) | Acc: (85.00%) (9910/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.4317) |  Loss2: (0.0000) | Acc: (85.00%) (11018/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.4297) |  Loss2: (0.0000) | Acc: (85.00%) (12105/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.4306) |  Loss2: (0.0000) | Acc: (85.00%) (13201/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.4339) |  Loss2: (0.0000) | Acc: (85.00%) (14271/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.4281) |  Loss2: (0.0000) | Acc: (85.00%) (15400/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.4275) |  Loss2: (0.0000) | Acc: (85.00%) (16504/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (85.00%) (17585/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.4273) |  Loss2: (0.0000) | Acc: (85.00%) (18672/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.4284) |  Loss2: (0.0000) | Acc: (85.00%) (19766/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.4274) |  Loss2: (0.0000) | Acc: (85.00%) (20870/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.4284) |  Loss2: (0.0000) | Acc: (85.00%) (21942/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (23057/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.4271) |  Loss2: (0.0000) | Acc: (85.00%) (24144/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.4279) |  Loss2: (0.0000) | Acc: (85.00%) (25221/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (85.00%) (26320/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.4283) |  Loss2: (0.0000) | Acc: (85.00%) (27405/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.4263) |  Loss2: (0.0000) | Acc: (85.00%) (28535/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.4265) |  Loss2: (0.0000) | Acc: (85.00%) (29626/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.4254) |  Loss2: (0.0000) | Acc: (85.00%) (30723/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.4243) |  Loss2: (0.0000) | Acc: (85.00%) (31830/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.4249) |  Loss2: (0.0000) | Acc: (85.00%) (32892/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.4242) |  Loss2: (0.0000) | Acc: (85.00%) (33983/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.4244) |  Loss2: (0.0000) | Acc: (85.00%) (35080/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.4242) |  Loss2: (0.0000) | Acc: (85.00%) (36180/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.4240) |  Loss2: (0.0000) | Acc: (85.00%) (37282/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.4251) |  Loss2: (0.0000) | Acc: (85.00%) (38353/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.4243) |  Loss2: (0.0000) | Acc: (85.00%) (39455/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.4247) |  Loss2: (0.0000) | Acc: (85.00%) (40539/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.4244) |  Loss2: (0.0000) | Acc: (85.00%) (41644/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.4256) |  Loss2: (0.0000) | Acc: (85.00%) (42672/50000)
# TEST : Loss: (0.4935) | Acc: (83.00%) (8315/10000)
percent tensor([0.5169, 0.5224, 0.5419, 0.5136, 0.5421, 0.5182, 0.5351, 0.5204, 0.5185,
        0.5273, 0.5167, 0.5458, 0.5142, 0.5115, 0.5212, 0.5116],
       device='cuda:0')
percent tensor([0.4876, 0.4822, 0.4425, 0.4781, 0.4460, 0.4421, 0.4711, 0.4860, 0.5248,
        0.4778, 0.5047, 0.4547, 0.5043, 0.5449, 0.4636, 0.4709],
       device='cuda:0')
percent tensor([0.5851, 0.5198, 0.5919, 0.6027, 0.5933, 0.6070, 0.5519, 0.5992, 0.5558,
        0.5537, 0.5515, 0.5554, 0.5417, 0.5226, 0.5632, 0.5892],
       device='cuda:0')
percent tensor([0.5081, 0.5171, 0.4891, 0.4980, 0.4902, 0.5062, 0.5091, 0.4967, 0.5037,
        0.5143, 0.5143, 0.4975, 0.5147, 0.5209, 0.5080, 0.5088],
       device='cuda:0')
percent tensor([0.4427, 0.5258, 0.5640, 0.6033, 0.5708, 0.5569, 0.5144, 0.4670, 0.5690,
        0.5208, 0.5938, 0.5565, 0.4766, 0.6190, 0.4645, 0.4825],
       device='cuda:0')
percent tensor([0.6307, 0.6381, 0.6355, 0.6397, 0.6369, 0.6305, 0.6469, 0.6317, 0.6435,
        0.6375, 0.6509, 0.6667, 0.6306, 0.6496, 0.6497, 0.6344],
       device='cuda:0')
percent tensor([0.6653, 0.6657, 0.8076, 0.8182, 0.8226, 0.7593, 0.7260, 0.7843, 0.6413,
        0.6451, 0.6769, 0.7374, 0.6142, 0.7182, 0.6543, 0.7012],
       device='cuda:0')
percent tensor([0.9979, 0.9938, 0.9967, 0.9964, 0.9965, 0.9928, 0.9963, 0.9974, 0.9950,
        0.9947, 0.9967, 0.9974, 0.9948, 0.9965, 0.9955, 0.9968],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 50 | Batch_idx: 0 |  Loss: (0.3904) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.4362) |  Loss2: (0.0000) | Acc: (85.00%) (1205/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.4195) |  Loss2: (0.0000) | Acc: (85.00%) (2306/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (86.00%) (3429/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (86.00%) (4516/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.4163) |  Loss2: (0.0000) | Acc: (85.00%) (5609/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.4167) |  Loss2: (0.0000) | Acc: (85.00%) (6712/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.4152) |  Loss2: (0.0000) | Acc: (86.00%) (7827/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (8913/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (10002/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.4193) |  Loss2: (0.0000) | Acc: (85.00%) (11104/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.4196) |  Loss2: (0.0000) | Acc: (85.00%) (12202/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (13296/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (14391/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.4250) |  Loss2: (0.0000) | Acc: (85.00%) (15464/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.4245) |  Loss2: (0.0000) | Acc: (85.00%) (16563/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.4240) |  Loss2: (0.0000) | Acc: (85.00%) (17660/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.4242) |  Loss2: (0.0000) | Acc: (85.00%) (18748/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (19832/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.4252) |  Loss2: (0.0000) | Acc: (85.00%) (20950/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (22021/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.4277) |  Loss2: (0.0000) | Acc: (85.00%) (23090/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (85.00%) (24172/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.4303) |  Loss2: (0.0000) | Acc: (85.00%) (25256/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.4300) |  Loss2: (0.0000) | Acc: (85.00%) (26344/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.4284) |  Loss2: (0.0000) | Acc: (85.00%) (27455/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.4287) |  Loss2: (0.0000) | Acc: (85.00%) (28551/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4288) |  Loss2: (0.0000) | Acc: (85.00%) (29647/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4281) |  Loss2: (0.0000) | Acc: (85.00%) (30751/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4273) |  Loss2: (0.0000) | Acc: (85.00%) (31863/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4272) |  Loss2: (0.0000) | Acc: (85.00%) (32961/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (34060/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (35160/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4264) |  Loss2: (0.0000) | Acc: (85.00%) (36252/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4273) |  Loss2: (0.0000) | Acc: (85.00%) (37335/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.4279) |  Loss2: (0.0000) | Acc: (85.00%) (38430/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4283) |  Loss2: (0.0000) | Acc: (85.00%) (39510/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4282) |  Loss2: (0.0000) | Acc: (85.00%) (40611/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4277) |  Loss2: (0.0000) | Acc: (85.00%) (41719/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4275) |  Loss2: (0.0000) | Acc: (85.00%) (42770/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_050.pth.tar'
# TEST : Loss: (0.5793) | Acc: (80.00%) (8087/10000)
percent tensor([0.5156, 0.5246, 0.5354, 0.5128, 0.5365, 0.5157, 0.5339, 0.5183, 0.5164,
        0.5271, 0.5170, 0.5410, 0.5141, 0.5147, 0.5217, 0.5116],
       device='cuda:0')
percent tensor([0.4965, 0.4822, 0.4634, 0.4798, 0.4648, 0.4459, 0.4775, 0.4948, 0.5361,
        0.4847, 0.5077, 0.4674, 0.5099, 0.5467, 0.4605, 0.4715],
       device='cuda:0')
percent tensor([0.5816, 0.5238, 0.5921, 0.5965, 0.5966, 0.6049, 0.5599, 0.6002, 0.5628,
        0.5512, 0.5537, 0.5559, 0.5350, 0.5448, 0.5616, 0.5903],
       device='cuda:0')
percent tensor([0.5081, 0.5163, 0.4920, 0.4976, 0.4914, 0.5067, 0.5083, 0.4978, 0.5033,
        0.5157, 0.5150, 0.5005, 0.5163, 0.5175, 0.5083, 0.5092],
       device='cuda:0')
percent tensor([0.4446, 0.5223, 0.5458, 0.5920, 0.5623, 0.5479, 0.4985, 0.4622, 0.5667,
        0.5299, 0.5913, 0.5503, 0.4776, 0.6029, 0.4596, 0.4762],
       device='cuda:0')
percent tensor([0.6303, 0.6418, 0.6338, 0.6390, 0.6346, 0.6315, 0.6430, 0.6267, 0.6384,
        0.6369, 0.6517, 0.6546, 0.6256, 0.6491, 0.6516, 0.6353],
       device='cuda:0')
percent tensor([0.6531, 0.6564, 0.7725, 0.8073, 0.8104, 0.7501, 0.7223, 0.7725, 0.6324,
        0.6368, 0.6486, 0.7039, 0.6011, 0.7386, 0.6490, 0.6994],
       device='cuda:0')
percent tensor([0.9975, 0.9954, 0.9968, 0.9969, 0.9972, 0.9940, 0.9949, 0.9975, 0.9931,
        0.9947, 0.9964, 0.9968, 0.9965, 0.9971, 0.9970, 0.9969],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(173.6440, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(799.8545, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(796.6434, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1523.3041, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.7816, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2190.7273, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4294.8623, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1423.3081, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6094.1401, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12073.3789, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4009.3403, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16977.2539, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 51 | Batch_idx: 0 |  Loss: (0.4041) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.4051) |  Loss2: (0.0000) | Acc: (86.00%) (1212/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.4107) |  Loss2: (0.0000) | Acc: (85.00%) (2303/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (3421/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.4027) |  Loss2: (0.0000) | Acc: (86.00%) (4527/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.4026) |  Loss2: (0.0000) | Acc: (86.00%) (5621/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.4078) |  Loss2: (0.0000) | Acc: (85.00%) (6698/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.4188) |  Loss2: (0.0000) | Acc: (85.00%) (7777/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.4173) |  Loss2: (0.0000) | Acc: (85.00%) (8866/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.4152) |  Loss2: (0.0000) | Acc: (85.00%) (9983/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.4107) |  Loss2: (0.0000) | Acc: (85.00%) (11107/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (86.00%) (12224/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (86.00%) (13321/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (86.00%) (14426/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (15516/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.4069) |  Loss2: (0.0000) | Acc: (85.00%) (16619/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.4067) |  Loss2: (0.0000) | Acc: (85.00%) (17716/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (18817/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (85.00%) (19908/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (21010/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (22125/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (23217/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (24310/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.4071) |  Loss2: (0.0000) | Acc: (85.00%) (25428/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (86.00%) (26537/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (85.00%) (27621/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.4061) |  Loss2: (0.0000) | Acc: (86.00%) (28756/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.4069) |  Loss2: (0.0000) | Acc: (86.00%) (29839/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.4071) |  Loss2: (0.0000) | Acc: (86.00%) (30939/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.4078) |  Loss2: (0.0000) | Acc: (85.00%) (32025/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (33112/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (34210/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (35312/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (36408/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.4069) |  Loss2: (0.0000) | Acc: (85.00%) (37524/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (38631/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (39712/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (40790/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.4087) |  Loss2: (0.0000) | Acc: (85.00%) (41876/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.4094) |  Loss2: (0.0000) | Acc: (85.00%) (42918/50000)
# TEST : Loss: (0.5265) | Acc: (82.00%) (8233/10000)
percent tensor([0.5147, 0.5229, 0.5354, 0.5122, 0.5367, 0.5155, 0.5325, 0.5176, 0.5153,
        0.5261, 0.5159, 0.5408, 0.5129, 0.5114, 0.5210, 0.5108],
       device='cuda:0')
percent tensor([0.4934, 0.4827, 0.4472, 0.4767, 0.4527, 0.4407, 0.4727, 0.4873, 0.5238,
        0.4818, 0.5047, 0.4554, 0.5074, 0.5483, 0.4614, 0.4716],
       device='cuda:0')
percent tensor([0.5798, 0.5202, 0.5911, 0.5930, 0.5940, 0.6029, 0.5543, 0.5939, 0.5616,
        0.5489, 0.5545, 0.5518, 0.5352, 0.5354, 0.5564, 0.5839],
       device='cuda:0')
percent tensor([0.5077, 0.5156, 0.4914, 0.4985, 0.4900, 0.5056, 0.5084, 0.4970, 0.5026,
        0.5141, 0.5140, 0.4999, 0.5157, 0.5170, 0.5065, 0.5084],
       device='cuda:0')
percent tensor([0.4384, 0.5194, 0.5603, 0.6041, 0.5629, 0.5484, 0.4991, 0.4714, 0.5510,
        0.5369, 0.5830, 0.5585, 0.4747, 0.6128, 0.4709, 0.4856],
       device='cuda:0')
percent tensor([0.6283, 0.6368, 0.6358, 0.6414, 0.6384, 0.6335, 0.6429, 0.6259, 0.6372,
        0.6353, 0.6473, 0.6543, 0.6247, 0.6467, 0.6479, 0.6355],
       device='cuda:0')
percent tensor([0.6860, 0.6669, 0.7985, 0.8255, 0.8328, 0.7659, 0.7288, 0.7999, 0.6659,
        0.6721, 0.6739, 0.7506, 0.6251, 0.7526, 0.6666, 0.7265],
       device='cuda:0')
percent tensor([0.9984, 0.9924, 0.9977, 0.9974, 0.9976, 0.9956, 0.9946, 0.9982, 0.9930,
        0.9943, 0.9968, 0.9976, 0.9952, 0.9956, 0.9954, 0.9969],
       device='cuda:0')
Epoch: 52 | Batch_idx: 0 |  Loss: (0.3798) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (86.00%) (1220/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.3917) |  Loss2: (0.0000) | Acc: (86.00%) (2333/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.3903) |  Loss2: (0.0000) | Acc: (86.00%) (3439/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.3878) |  Loss2: (0.0000) | Acc: (86.00%) (4558/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.3903) |  Loss2: (0.0000) | Acc: (86.00%) (5659/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3894) |  Loss2: (0.0000) | Acc: (86.00%) (6761/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3856) |  Loss2: (0.0000) | Acc: (86.00%) (7875/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3865) |  Loss2: (0.0000) | Acc: (86.00%) (8983/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3872) |  Loss2: (0.0000) | Acc: (86.00%) (10086/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3865) |  Loss2: (0.0000) | Acc: (86.00%) (11198/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3904) |  Loss2: (0.0000) | Acc: (86.00%) (12285/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3888) |  Loss2: (0.0000) | Acc: (86.00%) (13407/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3937) |  Loss2: (0.0000) | Acc: (86.00%) (14488/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3950) |  Loss2: (0.0000) | Acc: (86.00%) (15582/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3948) |  Loss2: (0.0000) | Acc: (86.00%) (16692/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3949) |  Loss2: (0.0000) | Acc: (86.00%) (17800/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3912) |  Loss2: (0.0000) | Acc: (86.00%) (18923/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3888) |  Loss2: (0.0000) | Acc: (86.00%) (20054/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (21167/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (22274/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3896) |  Loss2: (0.0000) | Acc: (86.00%) (23371/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3893) |  Loss2: (0.0000) | Acc: (86.00%) (24468/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3904) |  Loss2: (0.0000) | Acc: (86.00%) (25569/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3911) |  Loss2: (0.0000) | Acc: (86.00%) (26660/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (27777/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3917) |  Loss2: (0.0000) | Acc: (86.00%) (28878/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (29997/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3901) |  Loss2: (0.0000) | Acc: (86.00%) (31116/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3900) |  Loss2: (0.0000) | Acc: (86.00%) (32238/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (33327/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3924) |  Loss2: (0.0000) | Acc: (86.00%) (34416/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3921) |  Loss2: (0.0000) | Acc: (86.00%) (35532/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3925) |  Loss2: (0.0000) | Acc: (86.00%) (36632/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3937) |  Loss2: (0.0000) | Acc: (86.00%) (37711/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3936) |  Loss2: (0.0000) | Acc: (86.00%) (38822/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3939) |  Loss2: (0.0000) | Acc: (86.00%) (39927/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3946) |  Loss2: (0.0000) | Acc: (86.00%) (41021/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3950) |  Loss2: (0.0000) | Acc: (86.00%) (42114/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (43186/50000)
# TEST : Loss: (0.5416) | Acc: (81.00%) (8194/10000)
percent tensor([0.5141, 0.5235, 0.5338, 0.5121, 0.5355, 0.5149, 0.5329, 0.5171, 0.5152,
        0.5260, 0.5158, 0.5398, 0.5127, 0.5131, 0.5209, 0.5111],
       device='cuda:0')
percent tensor([0.4922, 0.4820, 0.4488, 0.4812, 0.4545, 0.4354, 0.4738, 0.4932, 0.5288,
        0.4839, 0.5056, 0.4587, 0.5096, 0.5463, 0.4606, 0.4716],
       device='cuda:0')
percent tensor([0.5825, 0.5183, 0.6042, 0.6021, 0.6053, 0.6018, 0.5583, 0.6035, 0.5613,
        0.5520, 0.5531, 0.5652, 0.5380, 0.5299, 0.5570, 0.5855],
       device='cuda:0')
percent tensor([0.5082, 0.5152, 0.4911, 0.4982, 0.4906, 0.5081, 0.5074, 0.4965, 0.5023,
        0.5146, 0.5141, 0.4979, 0.5147, 0.5150, 0.5071, 0.5090],
       device='cuda:0')
percent tensor([0.4385, 0.5214, 0.5431, 0.5787, 0.5436, 0.5388, 0.4905, 0.4521, 0.5609,
        0.5273, 0.5776, 0.5365, 0.4957, 0.6133, 0.4561, 0.4877],
       device='cuda:0')
percent tensor([0.6334, 0.6376, 0.6381, 0.6442, 0.6350, 0.6329, 0.6379, 0.6297, 0.6388,
        0.6354, 0.6465, 0.6534, 0.6314, 0.6433, 0.6474, 0.6384],
       device='cuda:0')
percent tensor([0.6427, 0.6488, 0.7876, 0.8144, 0.8135, 0.7439, 0.7137, 0.7758, 0.6406,
        0.6374, 0.6577, 0.7288, 0.6163, 0.7403, 0.6385, 0.6821],
       device='cuda:0')
percent tensor([0.9978, 0.9931, 0.9973, 0.9975, 0.9968, 0.9941, 0.9953, 0.9984, 0.9947,
        0.9946, 0.9970, 0.9974, 0.9943, 0.9969, 0.9962, 0.9969],
       device='cuda:0')
Epoch: 53 | Batch_idx: 0 |  Loss: (0.4414) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (1237/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.3759) |  Loss2: (0.0000) | Acc: (87.00%) (2340/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.3848) |  Loss2: (0.0000) | Acc: (86.00%) (3449/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.3875) |  Loss2: (0.0000) | Acc: (86.00%) (4543/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.3839) |  Loss2: (0.0000) | Acc: (86.00%) (5654/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.3831) |  Loss2: (0.0000) | Acc: (86.00%) (6763/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.3791) |  Loss2: (0.0000) | Acc: (86.00%) (7889/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.3798) |  Loss2: (0.0000) | Acc: (86.00%) (8998/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.3775) |  Loss2: (0.0000) | Acc: (86.00%) (10126/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (11209/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.3850) |  Loss2: (0.0000) | Acc: (86.00%) (12308/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.3848) |  Loss2: (0.0000) | Acc: (86.00%) (13418/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.3846) |  Loss2: (0.0000) | Acc: (86.00%) (14533/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.3840) |  Loss2: (0.0000) | Acc: (86.00%) (15661/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.3846) |  Loss2: (0.0000) | Acc: (86.00%) (16766/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.3839) |  Loss2: (0.0000) | Acc: (86.00%) (17870/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.3858) |  Loss2: (0.0000) | Acc: (86.00%) (18976/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.3852) |  Loss2: (0.0000) | Acc: (86.00%) (20095/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.3847) |  Loss2: (0.0000) | Acc: (86.00%) (21217/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (22339/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (23469/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (86.00%) (24602/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (25696/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (26790/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.3832) |  Loss2: (0.0000) | Acc: (86.00%) (27893/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (86.00%) (28999/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.3829) |  Loss2: (0.0000) | Acc: (86.00%) (30115/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.3836) |  Loss2: (0.0000) | Acc: (86.00%) (31205/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.3843) |  Loss2: (0.0000) | Acc: (86.00%) (32300/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.3848) |  Loss2: (0.0000) | Acc: (86.00%) (33392/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.3846) |  Loss2: (0.0000) | Acc: (86.00%) (34500/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.3851) |  Loss2: (0.0000) | Acc: (86.00%) (35589/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.3861) |  Loss2: (0.0000) | Acc: (86.00%) (36677/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.3852) |  Loss2: (0.0000) | Acc: (86.00%) (37801/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.3854) |  Loss2: (0.0000) | Acc: (86.00%) (38904/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.3868) |  Loss2: (0.0000) | Acc: (86.00%) (39989/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.3877) |  Loss2: (0.0000) | Acc: (86.00%) (41080/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (42179/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.3876) |  Loss2: (0.0000) | Acc: (86.00%) (43247/50000)
# TEST : Loss: (0.5456) | Acc: (81.00%) (8179/10000)
percent tensor([0.5139, 0.5234, 0.5343, 0.5107, 0.5364, 0.5151, 0.5330, 0.5168, 0.5151,
        0.5259, 0.5155, 0.5406, 0.5123, 0.5125, 0.5205, 0.5105],
       device='cuda:0')
percent tensor([0.4885, 0.4902, 0.4538, 0.4828, 0.4604, 0.4382, 0.4861, 0.4956, 0.5353,
        0.4858, 0.5086, 0.4657, 0.5050, 0.5722, 0.4624, 0.4725],
       device='cuda:0')
percent tensor([0.5820, 0.5136, 0.5980, 0.5980, 0.5983, 0.5996, 0.5503, 0.6007, 0.5634,
        0.5488, 0.5524, 0.5581, 0.5372, 0.5311, 0.5550, 0.5851],
       device='cuda:0')
percent tensor([0.5089, 0.5178, 0.4912, 0.4986, 0.4908, 0.5087, 0.5082, 0.4973, 0.5035,
        0.5167, 0.5159, 0.4992, 0.5161, 0.5177, 0.5077, 0.5100],
       device='cuda:0')
percent tensor([0.4444, 0.5286, 0.5701, 0.5902, 0.5852, 0.5587, 0.5225, 0.4683, 0.5651,
        0.5373, 0.5904, 0.5669, 0.4845, 0.6202, 0.4772, 0.4871],
       device='cuda:0')
percent tensor([0.6328, 0.6406, 0.6377, 0.6382, 0.6398, 0.6409, 0.6417, 0.6290, 0.6421,
        0.6371, 0.6506, 0.6572, 0.6332, 0.6489, 0.6507, 0.6407],
       device='cuda:0')
percent tensor([0.6537, 0.6388, 0.7734, 0.8125, 0.8084, 0.7417, 0.7154, 0.7626, 0.6324,
        0.6288, 0.6606, 0.7215, 0.5992, 0.7369, 0.6364, 0.6854],
       device='cuda:0')
percent tensor([0.9981, 0.9941, 0.9965, 0.9976, 0.9968, 0.9940, 0.9940, 0.9978, 0.9945,
        0.9953, 0.9966, 0.9971, 0.9944, 0.9963, 0.9961, 0.9970],
       device='cuda:0')
Epoch: 54 | Batch_idx: 0 |  Loss: (0.4512) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (87.00%) (1227/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.3765) |  Loss2: (0.0000) | Acc: (87.00%) (2345/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3776) |  Loss2: (0.0000) | Acc: (87.00%) (3464/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3793) |  Loss2: (0.0000) | Acc: (87.00%) (4572/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.3805) |  Loss2: (0.0000) | Acc: (87.00%) (5688/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (87.00%) (6797/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (87.00%) (7921/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (87.00%) (9022/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (86.00%) (10132/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (87.00%) (11251/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.3762) |  Loss2: (0.0000) | Acc: (87.00%) (12371/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.3759) |  Loss2: (0.0000) | Acc: (87.00%) (13483/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.3767) |  Loss2: (0.0000) | Acc: (86.00%) (14586/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (86.00%) (15684/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (86.00%) (16792/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (86.00%) (17900/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.3805) |  Loss2: (0.0000) | Acc: (86.00%) (18998/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.3817) |  Loss2: (0.0000) | Acc: (86.00%) (20090/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.3812) |  Loss2: (0.0000) | Acc: (86.00%) (21200/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (86.00%) (22322/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (86.00%) (23424/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.3797) |  Loss2: (0.0000) | Acc: (86.00%) (24550/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (86.00%) (25659/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (86.00%) (26766/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (86.00%) (27859/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (28961/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (86.00%) (30083/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (86.00%) (31213/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (32337/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (86.00%) (33424/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (86.00%) (34522/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (86.00%) (35630/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (86.00%) (36765/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.3785) |  Loss2: (0.0000) | Acc: (86.00%) (37870/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (38975/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (86.00%) (40080/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.3797) |  Loss2: (0.0000) | Acc: (86.00%) (41187/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (86.00%) (42305/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (86.00%) (43364/50000)
# TEST : Loss: (0.4997) | Acc: (83.00%) (8311/10000)
percent tensor([0.5149, 0.5223, 0.5381, 0.5115, 0.5389, 0.5165, 0.5334, 0.5180, 0.5152,
        0.5263, 0.5154, 0.5426, 0.5125, 0.5108, 0.5206, 0.5104],
       device='cuda:0')
percent tensor([0.4920, 0.4836, 0.4454, 0.4769, 0.4496, 0.4381, 0.4757, 0.4889, 0.5258,
        0.4816, 0.5081, 0.4599, 0.5051, 0.5534, 0.4604, 0.4704],
       device='cuda:0')
percent tensor([0.5766, 0.5109, 0.5942, 0.5987, 0.5956, 0.5978, 0.5496, 0.5985, 0.5582,
        0.5472, 0.5503, 0.5530, 0.5322, 0.5234, 0.5528, 0.5834],
       device='cuda:0')
percent tensor([0.5082, 0.5172, 0.4916, 0.4988, 0.4905, 0.5066, 0.5094, 0.4985, 0.5047,
        0.5156, 0.5153, 0.5002, 0.5150, 0.5192, 0.5077, 0.5087],
       device='cuda:0')
percent tensor([0.4463, 0.5275, 0.5857, 0.5952, 0.5776, 0.5489, 0.5252, 0.4796, 0.5745,
        0.5403, 0.5913, 0.5672, 0.4795, 0.6363, 0.4749, 0.4967],
       device='cuda:0')
percent tensor([0.6301, 0.6376, 0.6438, 0.6395, 0.6434, 0.6347, 0.6455, 0.6275, 0.6396,
        0.6353, 0.6513, 0.6587, 0.6276, 0.6466, 0.6479, 0.6383],
       device='cuda:0')
percent tensor([0.6511, 0.6665, 0.7947, 0.8112, 0.8156, 0.7436, 0.7151, 0.7748, 0.6579,
        0.6645, 0.6680, 0.7465, 0.6041, 0.7386, 0.6557, 0.7064],
       device='cuda:0')
percent tensor([0.9983, 0.9935, 0.9974, 0.9971, 0.9971, 0.9949, 0.9956, 0.9983, 0.9948,
        0.9957, 0.9967, 0.9977, 0.9961, 0.9957, 0.9954, 0.9978],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 55 | Batch_idx: 0 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.3919) |  Loss2: (0.0000) | Acc: (86.00%) (1224/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.4155) |  Loss2: (0.0000) | Acc: (85.00%) (2297/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.4475) |  Loss2: (0.0000) | Acc: (84.00%) (3349/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.4571) |  Loss2: (0.0000) | Acc: (84.00%) (4424/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.4580) |  Loss2: (0.0000) | Acc: (84.00%) (5502/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (84.00%) (6568/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (83.00%) (7631/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.4628) |  Loss2: (0.0000) | Acc: (84.00%) (8711/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.4658) |  Loss2: (0.0000) | Acc: (83.00%) (9773/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.4655) |  Loss2: (0.0000) | Acc: (83.00%) (10845/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.4658) |  Loss2: (0.0000) | Acc: (83.00%) (11906/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.4647) |  Loss2: (0.0000) | Acc: (83.00%) (12976/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.4644) |  Loss2: (0.0000) | Acc: (83.00%) (14058/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.4662) |  Loss2: (0.0000) | Acc: (83.00%) (15121/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.4637) |  Loss2: (0.0000) | Acc: (83.00%) (16206/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.4647) |  Loss2: (0.0000) | Acc: (83.00%) (17279/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.4622) |  Loss2: (0.0000) | Acc: (84.00%) (18386/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.4605) |  Loss2: (0.0000) | Acc: (84.00%) (19493/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.4585) |  Loss2: (0.0000) | Acc: (84.00%) (20582/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.4561) |  Loss2: (0.0000) | Acc: (84.00%) (21678/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.4563) |  Loss2: (0.0000) | Acc: (84.00%) (22750/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.4573) |  Loss2: (0.0000) | Acc: (84.00%) (23816/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.4564) |  Loss2: (0.0000) | Acc: (84.00%) (24913/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.4565) |  Loss2: (0.0000) | Acc: (84.00%) (25991/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.4544) |  Loss2: (0.0000) | Acc: (84.00%) (27094/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.4560) |  Loss2: (0.0000) | Acc: (84.00%) (28153/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.4556) |  Loss2: (0.0000) | Acc: (84.00%) (29233/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.4541) |  Loss2: (0.0000) | Acc: (84.00%) (30325/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.4532) |  Loss2: (0.0000) | Acc: (84.00%) (31415/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.4515) |  Loss2: (0.0000) | Acc: (84.00%) (32520/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.4510) |  Loss2: (0.0000) | Acc: (84.00%) (33619/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.4510) |  Loss2: (0.0000) | Acc: (84.00%) (34698/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.4508) |  Loss2: (0.0000) | Acc: (84.00%) (35770/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.4497) |  Loss2: (0.0000) | Acc: (84.00%) (36870/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.4500) |  Loss2: (0.0000) | Acc: (84.00%) (37951/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.4499) |  Loss2: (0.0000) | Acc: (84.00%) (39023/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.4496) |  Loss2: (0.0000) | Acc: (84.00%) (40100/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.4483) |  Loss2: (0.0000) | Acc: (84.00%) (41206/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.4481) |  Loss2: (0.0000) | Acc: (84.00%) (42234/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_055.pth.tar'
# TEST : Loss: (0.5122) | Acc: (82.00%) (8296/10000)
percent tensor([0.4962, 0.5050, 0.5243, 0.4935, 0.5236, 0.5019, 0.5167, 0.4988, 0.4961,
        0.5094, 0.4965, 0.5285, 0.4930, 0.4931, 0.5045, 0.4921],
       device='cuda:0')
percent tensor([0.5006, 0.4907, 0.4456, 0.4768, 0.4472, 0.4472, 0.4774, 0.4871, 0.5321,
        0.4910, 0.5190, 0.4662, 0.5163, 0.5609, 0.4662, 0.4780],
       device='cuda:0')
percent tensor([0.5825, 0.5117, 0.6051, 0.6169, 0.6132, 0.6155, 0.5524, 0.6114, 0.5726,
        0.5513, 0.5566, 0.5524, 0.5306, 0.5301, 0.5578, 0.5925],
       device='cuda:0')
percent tensor([0.5075, 0.5178, 0.4904, 0.4973, 0.4889, 0.5105, 0.5091, 0.4939, 0.5044,
        0.5165, 0.5161, 0.5015, 0.5149, 0.5242, 0.5070, 0.5088],
       device='cuda:0')
percent tensor([0.4224, 0.5322, 0.5811, 0.5843, 0.5492, 0.5410, 0.5147, 0.4367, 0.5675,
        0.5425, 0.5945, 0.5627, 0.4733, 0.6806, 0.4402, 0.4817],
       device='cuda:0')
percent tensor([0.6240, 0.6334, 0.6503, 0.6456, 0.6512, 0.6322, 0.6468, 0.6344, 0.6445,
        0.6318, 0.6475, 0.6629, 0.6143, 0.6482, 0.6455, 0.6374],
       device='cuda:0')
percent tensor([0.5899, 0.5980, 0.7803, 0.8028, 0.8062, 0.7175, 0.6625, 0.7729, 0.5968,
        0.5788, 0.5776, 0.6900, 0.5058, 0.6577, 0.6106, 0.6784],
       device='cuda:0')
percent tensor([0.9976, 0.9937, 0.9979, 0.9978, 0.9976, 0.9939, 0.9952, 0.9988, 0.9934,
        0.9956, 0.9959, 0.9976, 0.9950, 0.9955, 0.9942, 0.9977],
       device='cuda:0')
Epoch: 56 | Batch_idx: 0 |  Loss: (0.4259) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.3973) |  Loss2: (0.0000) | Acc: (86.00%) (1213/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.4054) |  Loss2: (0.0000) | Acc: (85.00%) (2296/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.4038) |  Loss2: (0.0000) | Acc: (85.00%) (3395/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.3996) |  Loss2: (0.0000) | Acc: (85.00%) (4501/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.3950) |  Loss2: (0.0000) | Acc: (85.00%) (5609/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.4006) |  Loss2: (0.0000) | Acc: (85.00%) (6697/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (85.00%) (7792/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.4048) |  Loss2: (0.0000) | Acc: (85.00%) (8876/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.4118) |  Loss2: (0.0000) | Acc: (85.00%) (9952/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.4151) |  Loss2: (0.0000) | Acc: (85.00%) (11030/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (85.00%) (12129/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.4124) |  Loss2: (0.0000) | Acc: (85.00%) (13227/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (85.00%) (14340/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.4101) |  Loss2: (0.0000) | Acc: (85.00%) (15431/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.4115) |  Loss2: (0.0000) | Acc: (85.00%) (16518/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.4105) |  Loss2: (0.0000) | Acc: (85.00%) (17629/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.4089) |  Loss2: (0.0000) | Acc: (85.00%) (18728/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.4103) |  Loss2: (0.0000) | Acc: (85.00%) (19820/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (20925/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (85.00%) (22019/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (23133/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.4077) |  Loss2: (0.0000) | Acc: (85.00%) (24221/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (25327/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.4070) |  Loss2: (0.0000) | Acc: (85.00%) (26414/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (85.00%) (27522/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (85.00%) (28638/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.4022) |  Loss2: (0.0000) | Acc: (85.00%) (29764/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (85.00%) (30850/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.4039) |  Loss2: (0.0000) | Acc: (85.00%) (31936/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.4040) |  Loss2: (0.0000) | Acc: (85.00%) (33046/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.4034) |  Loss2: (0.0000) | Acc: (85.00%) (34154/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.4027) |  Loss2: (0.0000) | Acc: (85.00%) (35261/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (85.00%) (36362/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.4027) |  Loss2: (0.0000) | Acc: (85.00%) (37469/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.4015) |  Loss2: (0.0000) | Acc: (85.00%) (38595/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.4017) |  Loss2: (0.0000) | Acc: (85.00%) (39693/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.4016) |  Loss2: (0.0000) | Acc: (85.00%) (40802/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.4003) |  Loss2: (0.0000) | Acc: (85.00%) (41920/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.4000) |  Loss2: (0.0000) | Acc: (85.00%) (42984/50000)
# TEST : Loss: (0.4827) | Acc: (83.00%) (8384/10000)
percent tensor([0.4926, 0.5038, 0.5233, 0.4899, 0.5226, 0.4995, 0.5158, 0.4955, 0.4931,
        0.5077, 0.4938, 0.5280, 0.4892, 0.4912, 0.5027, 0.4885],
       device='cuda:0')
percent tensor([0.5026, 0.4963, 0.4445, 0.4759, 0.4453, 0.4502, 0.4805, 0.4857, 0.5361,
        0.4948, 0.5244, 0.4680, 0.5206, 0.5678, 0.4698, 0.4811],
       device='cuda:0')
percent tensor([0.5822, 0.5115, 0.6110, 0.6194, 0.6203, 0.6202, 0.5537, 0.6135, 0.5763,
        0.5513, 0.5556, 0.5551, 0.5287, 0.5326, 0.5579, 0.5921],
       device='cuda:0')
percent tensor([0.5111, 0.5237, 0.4903, 0.4995, 0.4890, 0.5171, 0.5127, 0.4940, 0.5072,
        0.5218, 0.5218, 0.5040, 0.5197, 0.5316, 0.5114, 0.5141],
       device='cuda:0')
percent tensor([0.4214, 0.5447, 0.5810, 0.5848, 0.5431, 0.5318, 0.5186, 0.4316, 0.5682,
        0.5529, 0.6025, 0.5642, 0.4807, 0.6957, 0.4328, 0.4846],
       device='cuda:0')
percent tensor([0.6455, 0.6543, 0.6738, 0.6698, 0.6735, 0.6503, 0.6697, 0.6600, 0.6662,
        0.6528, 0.6694, 0.6883, 0.6345, 0.6707, 0.6690, 0.6590],
       device='cuda:0')
percent tensor([0.5967, 0.5995, 0.7831, 0.8007, 0.8104, 0.7146, 0.6642, 0.7789, 0.5917,
        0.5789, 0.5738, 0.6907, 0.5079, 0.6406, 0.6175, 0.6829],
       device='cuda:0')
percent tensor([0.9977, 0.9942, 0.9980, 0.9979, 0.9976, 0.9937, 0.9954, 0.9989, 0.9936,
        0.9959, 0.9963, 0.9978, 0.9952, 0.9958, 0.9945, 0.9978],
       device='cuda:0')
Epoch: 57 | Batch_idx: 0 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.3675) |  Loss2: (0.0000) | Acc: (87.00%) (1228/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.3684) |  Loss2: (0.0000) | Acc: (87.00%) (2346/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (3469/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.3731) |  Loss2: (0.0000) | Acc: (87.00%) (4566/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (87.00%) (5680/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (86.00%) (6773/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.3771) |  Loss2: (0.0000) | Acc: (86.00%) (7900/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.3785) |  Loss2: (0.0000) | Acc: (86.00%) (9017/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.3801) |  Loss2: (0.0000) | Acc: (86.00%) (10123/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (86.00%) (11226/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (12337/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.3798) |  Loss2: (0.0000) | Acc: (86.00%) (13451/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.3829) |  Loss2: (0.0000) | Acc: (86.00%) (14545/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.3847) |  Loss2: (0.0000) | Acc: (86.00%) (15649/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.3836) |  Loss2: (0.0000) | Acc: (86.00%) (16778/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (17896/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.3856) |  Loss2: (0.0000) | Acc: (86.00%) (18977/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.3862) |  Loss2: (0.0000) | Acc: (86.00%) (20083/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.3843) |  Loss2: (0.0000) | Acc: (86.00%) (21211/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.3848) |  Loss2: (0.0000) | Acc: (86.00%) (22311/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.3856) |  Loss2: (0.0000) | Acc: (86.00%) (23407/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.3842) |  Loss2: (0.0000) | Acc: (86.00%) (24533/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.3839) |  Loss2: (0.0000) | Acc: (86.00%) (25640/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.3839) |  Loss2: (0.0000) | Acc: (86.00%) (26745/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.3835) |  Loss2: (0.0000) | Acc: (86.00%) (27861/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.3825) |  Loss2: (0.0000) | Acc: (86.00%) (28986/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.3823) |  Loss2: (0.0000) | Acc: (86.00%) (30102/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (86.00%) (31213/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.3832) |  Loss2: (0.0000) | Acc: (86.00%) (32306/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (33403/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (34532/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (86.00%) (35631/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (36724/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.3817) |  Loss2: (0.0000) | Acc: (86.00%) (37853/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (86.00%) (38971/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.3816) |  Loss2: (0.0000) | Acc: (86.00%) (40090/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.3812) |  Loss2: (0.0000) | Acc: (86.00%) (41202/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (86.00%) (42330/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (43394/50000)
# TEST : Loss: (0.4665) | Acc: (84.00%) (8440/10000)
percent tensor([0.4963, 0.5091, 0.5286, 0.4936, 0.5282, 0.5030, 0.5215, 0.4999, 0.4974,
        0.5127, 0.4980, 0.5336, 0.4928, 0.4962, 0.5071, 0.4920],
       device='cuda:0')
percent tensor([0.5038, 0.4988, 0.4447, 0.4751, 0.4456, 0.4513, 0.4823, 0.4853, 0.5377,
        0.4969, 0.5267, 0.4707, 0.5232, 0.5698, 0.4718, 0.4826],
       device='cuda:0')
percent tensor([0.5783, 0.5076, 0.6105, 0.6177, 0.6207, 0.6202, 0.5504, 0.6107, 0.5731,
        0.5474, 0.5510, 0.5526, 0.5237, 0.5285, 0.5547, 0.5894],
       device='cuda:0')
percent tensor([0.5167, 0.5311, 0.4923, 0.5031, 0.4905, 0.5242, 0.5182, 0.4958, 0.5116,
        0.5290, 0.5292, 0.5090, 0.5264, 0.5400, 0.5176, 0.5206],
       device='cuda:0')
percent tensor([0.4247, 0.5493, 0.5889, 0.5921, 0.5470, 0.5314, 0.5238, 0.4396, 0.5686,
        0.5551, 0.6024, 0.5675, 0.4830, 0.6984, 0.4343, 0.4896],
       device='cuda:0')
percent tensor([0.6510, 0.6598, 0.6817, 0.6779, 0.6800, 0.6548, 0.6766, 0.6675, 0.6727,
        0.6586, 0.6758, 0.6977, 0.6395, 0.6785, 0.6761, 0.6647],
       device='cuda:0')
percent tensor([0.5997, 0.5996, 0.7795, 0.7971, 0.8090, 0.7168, 0.6610, 0.7787, 0.5885,
        0.5789, 0.5681, 0.6858, 0.5095, 0.6308, 0.6187, 0.6868],
       device='cuda:0')
percent tensor([0.9978, 0.9947, 0.9980, 0.9979, 0.9977, 0.9941, 0.9956, 0.9989, 0.9939,
        0.9963, 0.9965, 0.9979, 0.9954, 0.9961, 0.9950, 0.9979],
       device='cuda:0')
Epoch: 58 | Batch_idx: 0 |  Loss: (0.4154) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3948) |  Loss2: (0.0000) | Acc: (86.00%) (1223/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3749) |  Loss2: (0.0000) | Acc: (87.00%) (2345/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3763) |  Loss2: (0.0000) | Acc: (86.00%) (3451/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (87.00%) (4574/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (5700/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3748) |  Loss2: (0.0000) | Acc: (87.00%) (6802/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (86.00%) (7903/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (9027/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3752) |  Loss2: (0.0000) | Acc: (87.00%) (10140/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3775) |  Loss2: (0.0000) | Acc: (86.00%) (11236/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3785) |  Loss2: (0.0000) | Acc: (86.00%) (12337/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (86.00%) (13471/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (14597/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3754) |  Loss2: (0.0000) | Acc: (86.00%) (15690/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3735) |  Loss2: (0.0000) | Acc: (87.00%) (16817/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3741) |  Loss2: (0.0000) | Acc: (86.00%) (17928/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (86.00%) (19040/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3741) |  Loss2: (0.0000) | Acc: (86.00%) (20145/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (21271/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3711) |  Loss2: (0.0000) | Acc: (87.00%) (22401/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (87.00%) (23504/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3717) |  Loss2: (0.0000) | Acc: (87.00%) (24625/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (25733/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3746) |  Loss2: (0.0000) | Acc: (87.00%) (26840/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3746) |  Loss2: (0.0000) | Acc: (86.00%) (27949/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (29075/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3741) |  Loss2: (0.0000) | Acc: (87.00%) (30188/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3744) |  Loss2: (0.0000) | Acc: (87.00%) (31303/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3739) |  Loss2: (0.0000) | Acc: (87.00%) (32423/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (33544/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3744) |  Loss2: (0.0000) | Acc: (87.00%) (34648/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (87.00%) (35779/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3731) |  Loss2: (0.0000) | Acc: (87.00%) (36889/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (37999/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3748) |  Loss2: (0.0000) | Acc: (87.00%) (39091/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3752) |  Loss2: (0.0000) | Acc: (86.00%) (40196/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3758) |  Loss2: (0.0000) | Acc: (86.00%) (41303/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3754) |  Loss2: (0.0000) | Acc: (87.00%) (42433/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3748) |  Loss2: (0.0000) | Acc: (87.00%) (43507/50000)
# TEST : Loss: (0.4577) | Acc: (84.00%) (8456/10000)
percent tensor([0.4953, 0.5094, 0.5293, 0.4927, 0.5288, 0.5025, 0.5220, 0.4993, 0.4966,
        0.5129, 0.4972, 0.5344, 0.4917, 0.4960, 0.5069, 0.4909],
       device='cuda:0')
percent tensor([0.5060, 0.5024, 0.4448, 0.4752, 0.4452, 0.4532, 0.4846, 0.4849, 0.5402,
        0.4998, 0.5300, 0.4732, 0.5266, 0.5745, 0.4744, 0.4847],
       device='cuda:0')
percent tensor([0.5806, 0.5109, 0.6119, 0.6195, 0.6218, 0.6236, 0.5523, 0.6125, 0.5741,
        0.5491, 0.5509, 0.5542, 0.5254, 0.5340, 0.5581, 0.5915],
       device='cuda:0')
percent tensor([0.5181, 0.5339, 0.4913, 0.5031, 0.4889, 0.5271, 0.5192, 0.4940, 0.5125,
        0.5315, 0.5321, 0.5102, 0.5289, 0.5437, 0.5193, 0.5227],
       device='cuda:0')
percent tensor([0.4247, 0.5473, 0.5903, 0.5936, 0.5487, 0.5279, 0.5250, 0.4426, 0.5660,
        0.5516, 0.5998, 0.5679, 0.4801, 0.6953, 0.4350, 0.4873],
       device='cuda:0')
percent tensor([0.6538, 0.6625, 0.6857, 0.6823, 0.6831, 0.6572, 0.6804, 0.6705, 0.6764,
        0.6616, 0.6802, 0.7046, 0.6420, 0.6832, 0.6807, 0.6668],
       device='cuda:0')
percent tensor([0.6122, 0.6121, 0.7880, 0.8051, 0.8171, 0.7297, 0.6752, 0.7834, 0.6007,
        0.5956, 0.5838, 0.7000, 0.5254, 0.6465, 0.6255, 0.6989],
       device='cuda:0')
percent tensor([0.9981, 0.9950, 0.9981, 0.9980, 0.9979, 0.9945, 0.9960, 0.9989, 0.9945,
        0.9966, 0.9968, 0.9982, 0.9958, 0.9967, 0.9952, 0.9982],
       device='cuda:0')
Epoch: 59 | Batch_idx: 0 |  Loss: (0.3420) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3668) |  Loss2: (0.0000) | Acc: (87.00%) (1231/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3727) |  Loss2: (0.0000) | Acc: (87.00%) (2346/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3652) |  Loss2: (0.0000) | Acc: (87.00%) (3473/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (4581/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3716) |  Loss2: (0.0000) | Acc: (87.00%) (5698/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (86.00%) (6780/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3798) |  Loss2: (0.0000) | Acc: (86.00%) (7883/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3784) |  Loss2: (0.0000) | Acc: (86.00%) (9003/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3761) |  Loss2: (0.0000) | Acc: (87.00%) (10140/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3721) |  Loss2: (0.0000) | Acc: (87.00%) (11273/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (87.00%) (12386/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3718) |  Loss2: (0.0000) | Acc: (87.00%) (13500/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (87.00%) (14643/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (15756/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3708) |  Loss2: (0.0000) | Acc: (87.00%) (16871/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (18004/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3711) |  Loss2: (0.0000) | Acc: (87.00%) (19097/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3729) |  Loss2: (0.0000) | Acc: (87.00%) (20207/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3740) |  Loss2: (0.0000) | Acc: (87.00%) (21320/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (22444/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (23566/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3730) |  Loss2: (0.0000) | Acc: (87.00%) (24679/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (25803/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3717) |  Loss2: (0.0000) | Acc: (87.00%) (26929/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3713) |  Loss2: (0.0000) | Acc: (87.00%) (28050/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3717) |  Loss2: (0.0000) | Acc: (87.00%) (29167/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3716) |  Loss2: (0.0000) | Acc: (87.00%) (30277/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3711) |  Loss2: (0.0000) | Acc: (87.00%) (31397/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3713) |  Loss2: (0.0000) | Acc: (87.00%) (32504/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (87.00%) (33643/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3695) |  Loss2: (0.0000) | Acc: (87.00%) (34772/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3688) |  Loss2: (0.0000) | Acc: (87.00%) (35914/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3688) |  Loss2: (0.0000) | Acc: (87.00%) (37029/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (38142/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (39258/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3688) |  Loss2: (0.0000) | Acc: (87.00%) (40380/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (87.00%) (41494/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3687) |  Loss2: (0.0000) | Acc: (87.00%) (42629/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (87.00%) (43701/50000)
# TEST : Loss: (0.4516) | Acc: (84.00%) (8485/10000)
percent tensor([0.4971, 0.5127, 0.5326, 0.4950, 0.5323, 0.5043, 0.5257, 0.5021, 0.4989,
        0.5161, 0.4994, 0.5383, 0.4936, 0.4992, 0.5097, 0.4931],
       device='cuda:0')
percent tensor([0.5111, 0.5083, 0.4494, 0.4792, 0.4502, 0.4577, 0.4903, 0.4896, 0.5456,
        0.5051, 0.5355, 0.4795, 0.5323, 0.5796, 0.4799, 0.4894],
       device='cuda:0')
percent tensor([0.5792, 0.5074, 0.6152, 0.6203, 0.6261, 0.6230, 0.5514, 0.6147, 0.5739,
        0.5470, 0.5478, 0.5552, 0.5235, 0.5281, 0.5558, 0.5902],
       device='cuda:0')
percent tensor([0.5214, 0.5381, 0.4925, 0.5049, 0.4895, 0.5314, 0.5222, 0.4946, 0.5150,
        0.5358, 0.5367, 0.5136, 0.5330, 0.5484, 0.5230, 0.5264],
       device='cuda:0')
percent tensor([0.4316, 0.5493, 0.5987, 0.6007, 0.5579, 0.5254, 0.5322, 0.4560, 0.5688,
        0.5555, 0.6025, 0.5758, 0.4828, 0.6918, 0.4441, 0.4930],
       device='cuda:0')
percent tensor([0.6631, 0.6718, 0.6953, 0.6915, 0.6913, 0.6651, 0.6903, 0.6794, 0.6859,
        0.6711, 0.6909, 0.7165, 0.6518, 0.6941, 0.6915, 0.6754],
       device='cuda:0')
percent tensor([0.6167, 0.6192, 0.7856, 0.8005, 0.8144, 0.7323, 0.6781, 0.7773, 0.6092,
        0.6058, 0.5950, 0.7042, 0.5383, 0.6550, 0.6249, 0.6994],
       device='cuda:0')
percent tensor([0.9983, 0.9952, 0.9983, 0.9982, 0.9981, 0.9948, 0.9964, 0.9991, 0.9950,
        0.9968, 0.9971, 0.9984, 0.9960, 0.9968, 0.9957, 0.9983],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.3502) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (1239/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3523) |  Loss2: (0.0000) | Acc: (88.00%) (2371/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (3483/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3625) |  Loss2: (0.0000) | Acc: (87.00%) (4608/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3597) |  Loss2: (0.0000) | Acc: (87.00%) (5740/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (6867/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (87.00%) (7983/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (9087/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (10197/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3628) |  Loss2: (0.0000) | Acc: (87.00%) (11328/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3616) |  Loss2: (0.0000) | Acc: (87.00%) (12446/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (13556/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (14679/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3627) |  Loss2: (0.0000) | Acc: (87.00%) (15801/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (16903/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (18017/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3652) |  Loss2: (0.0000) | Acc: (87.00%) (19136/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (20248/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3680) |  Loss2: (0.0000) | Acc: (87.00%) (21347/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (22455/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (87.00%) (23573/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3680) |  Loss2: (0.0000) | Acc: (87.00%) (24688/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (25825/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3659) |  Loss2: (0.0000) | Acc: (87.00%) (26955/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (28072/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3684) |  Loss2: (0.0000) | Acc: (87.00%) (29172/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3686) |  Loss2: (0.0000) | Acc: (87.00%) (30291/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (31422/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3680) |  Loss2: (0.0000) | Acc: (87.00%) (32521/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3683) |  Loss2: (0.0000) | Acc: (87.00%) (33643/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (34766/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3668) |  Loss2: (0.0000) | Acc: (87.00%) (35890/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (37004/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3668) |  Loss2: (0.0000) | Acc: (87.00%) (38115/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (87.00%) (39221/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (87.00%) (40338/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3684) |  Loss2: (0.0000) | Acc: (87.00%) (41446/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (87.00%) (42571/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3675) |  Loss2: (0.0000) | Acc: (87.00%) (43654/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_060.pth.tar'
# TEST : Loss: (0.5652) | Acc: (81.00%) (8118/10000)
percent tensor([0.4971, 0.5134, 0.5245, 0.4933, 0.5272, 0.5039, 0.5249, 0.4993, 0.5001,
        0.5156, 0.5014, 0.5340, 0.4944, 0.5014, 0.5098, 0.4938],
       device='cuda:0')
percent tensor([0.5101, 0.5110, 0.4530, 0.4955, 0.4559, 0.4612, 0.4909, 0.5003, 0.5532,
        0.5065, 0.5374, 0.4731, 0.5345, 0.5861, 0.4814, 0.4990],
       device='cuda:0')
percent tensor([0.5799, 0.5031, 0.6214, 0.6083, 0.6270, 0.6193, 0.5538, 0.6113, 0.5709,
        0.5456, 0.5480, 0.5681, 0.5232, 0.5223, 0.5530, 0.5847],
       device='cuda:0')
percent tensor([0.5239, 0.5422, 0.4902, 0.5082, 0.4887, 0.5314, 0.5234, 0.4951, 0.5167,
        0.5387, 0.5404, 0.5098, 0.5382, 0.5498, 0.5251, 0.5302],
       device='cuda:0')
percent tensor([0.4361, 0.5544, 0.5780, 0.6099, 0.5635, 0.5487, 0.5184, 0.4471, 0.5806,
        0.5525, 0.6040, 0.5637, 0.5005, 0.6696, 0.4527, 0.5072],
       device='cuda:0')
percent tensor([0.6690, 0.6682, 0.6940, 0.7006, 0.6900, 0.6735, 0.6804, 0.6762, 0.6882,
        0.6681, 0.6874, 0.7138, 0.6600, 0.6929, 0.6926, 0.6788],
       device='cuda:0')
percent tensor([0.6000, 0.6149, 0.7591, 0.7717, 0.7982, 0.7177, 0.6691, 0.7565, 0.5616,
        0.6026, 0.5774, 0.6835, 0.5167, 0.6387, 0.6008, 0.6743],
       device='cuda:0')
percent tensor([0.9985, 0.9955, 0.9977, 0.9978, 0.9977, 0.9959, 0.9968, 0.9988, 0.9961,
        0.9971, 0.9975, 0.9981, 0.9963, 0.9973, 0.9974, 0.9984],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.3230, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(803.5354, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(801.1785, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1522.5890, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(499.9149, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2197.6577, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4289.8218, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1418.1250, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6102.1523, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12036.3145, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3993.7783, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16907.9961, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 61 | Batch_idx: 0 |  Loss: (0.4358) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (1234/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (2352/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3691) |  Loss2: (0.0000) | Acc: (87.00%) (3468/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (4602/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (5730/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3603) |  Loss2: (0.0000) | Acc: (87.00%) (6843/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (7974/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (9082/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (10197/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3616) |  Loss2: (0.0000) | Acc: (87.00%) (11317/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (12455/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (13594/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3546) |  Loss2: (0.0000) | Acc: (87.00%) (14723/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3571) |  Loss2: (0.0000) | Acc: (87.00%) (15842/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (16966/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (18077/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (19211/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (20319/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (21426/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (22552/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3611) |  Loss2: (0.0000) | Acc: (87.00%) (23679/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (24791/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3614) |  Loss2: (0.0000) | Acc: (87.00%) (25928/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3600) |  Loss2: (0.0000) | Acc: (87.00%) (27062/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (87.00%) (28171/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3597) |  Loss2: (0.0000) | Acc: (87.00%) (29308/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3590) |  Loss2: (0.0000) | Acc: (87.00%) (30433/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (31564/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (32679/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (33790/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (34922/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3600) |  Loss2: (0.0000) | Acc: (87.00%) (36024/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3594) |  Loss2: (0.0000) | Acc: (87.00%) (37172/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (38290/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3584) |  Loss2: (0.0000) | Acc: (87.00%) (39415/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (40533/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (41664/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3600) |  Loss2: (0.0000) | Acc: (87.00%) (42784/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3599) |  Loss2: (0.0000) | Acc: (87.00%) (43875/50000)
# TEST : Loss: (0.4735) | Acc: (84.00%) (8413/10000)
percent tensor([0.4969, 0.5151, 0.5233, 0.4951, 0.5260, 0.5028, 0.5247, 0.5010, 0.4988,
        0.5160, 0.5013, 0.5314, 0.4950, 0.5018, 0.5107, 0.4942],
       device='cuda:0')
percent tensor([0.5130, 0.5077, 0.4659, 0.4887, 0.4667, 0.4556, 0.4936, 0.5003, 0.5538,
        0.5087, 0.5359, 0.4862, 0.5350, 0.5752, 0.4772, 0.4922],
       device='cuda:0')
percent tensor([0.5762, 0.5019, 0.6167, 0.6056, 0.6206, 0.6186, 0.5498, 0.6096, 0.5698,
        0.5409, 0.5452, 0.5592, 0.5217, 0.5317, 0.5522, 0.5846],
       device='cuda:0')
percent tensor([0.5240, 0.5404, 0.4918, 0.5088, 0.4893, 0.5334, 0.5223, 0.4964, 0.5151,
        0.5392, 0.5395, 0.5110, 0.5363, 0.5486, 0.5241, 0.5300],
       device='cuda:0')
percent tensor([0.4392, 0.5524, 0.5646, 0.6030, 0.5462, 0.5253, 0.5247, 0.4579, 0.5763,
        0.5737, 0.6085, 0.5744, 0.5052, 0.6816, 0.4544, 0.4846],
       device='cuda:0')
percent tensor([0.6618, 0.6663, 0.6779, 0.6911, 0.6843, 0.6730, 0.6835, 0.6722, 0.6801,
        0.6692, 0.6852, 0.7043, 0.6551, 0.6950, 0.6927, 0.6727],
       device='cuda:0')
percent tensor([0.6425, 0.6122, 0.7636, 0.7883, 0.7931, 0.7256, 0.6740, 0.7546, 0.6003,
        0.6296, 0.6108, 0.6916, 0.5656, 0.6393, 0.6074, 0.6691],
       device='cuda:0')
percent tensor([0.9983, 0.9950, 0.9980, 0.9985, 0.9973, 0.9965, 0.9965, 0.9983, 0.9955,
        0.9963, 0.9976, 0.9982, 0.9960, 0.9975, 0.9976, 0.9982],
       device='cuda:0')
Epoch: 62 | Batch_idx: 0 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (1229/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3537) |  Loss2: (0.0000) | Acc: (87.00%) (2362/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3525) |  Loss2: (0.0000) | Acc: (87.00%) (3489/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3523) |  Loss2: (0.0000) | Acc: (87.00%) (4611/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (5733/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3423) |  Loss2: (0.0000) | Acc: (88.00%) (6878/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3427) |  Loss2: (0.0000) | Acc: (88.00%) (8004/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3419) |  Loss2: (0.0000) | Acc: (88.00%) (9136/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3463) |  Loss2: (0.0000) | Acc: (87.00%) (10244/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (87.00%) (11363/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (87.00%) (12495/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (88.00%) (13634/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3442) |  Loss2: (0.0000) | Acc: (88.00%) (14780/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3407) |  Loss2: (0.0000) | Acc: (88.00%) (15932/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3393) |  Loss2: (0.0000) | Acc: (88.00%) (17080/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3422) |  Loss2: (0.0000) | Acc: (88.00%) (18192/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3410) |  Loss2: (0.0000) | Acc: (88.00%) (19335/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3423) |  Loss2: (0.0000) | Acc: (88.00%) (20441/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3413) |  Loss2: (0.0000) | Acc: (88.00%) (21574/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (22700/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3410) |  Loss2: (0.0000) | Acc: (88.00%) (23832/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (24971/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (26095/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3416) |  Loss2: (0.0000) | Acc: (88.00%) (27216/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3409) |  Loss2: (0.0000) | Acc: (88.00%) (28352/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3427) |  Loss2: (0.0000) | Acc: (88.00%) (29453/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3423) |  Loss2: (0.0000) | Acc: (88.00%) (30594/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3421) |  Loss2: (0.0000) | Acc: (88.00%) (31724/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3414) |  Loss2: (0.0000) | Acc: (88.00%) (32866/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3418) |  Loss2: (0.0000) | Acc: (88.00%) (33976/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (88.00%) (35086/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3438) |  Loss2: (0.0000) | Acc: (88.00%) (36199/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (37335/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3445) |  Loss2: (0.0000) | Acc: (88.00%) (38450/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (39588/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3445) |  Loss2: (0.0000) | Acc: (88.00%) (40704/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3446) |  Loss2: (0.0000) | Acc: (88.00%) (41835/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3452) |  Loss2: (0.0000) | Acc: (88.00%) (42956/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3461) |  Loss2: (0.0000) | Acc: (88.00%) (44020/50000)
# TEST : Loss: (0.5176) | Acc: (82.00%) (8282/10000)
percent tensor([0.4977, 0.5147, 0.5253, 0.4943, 0.5285, 0.5055, 0.5256, 0.5006, 0.5005,
        0.5159, 0.5030, 0.5335, 0.4955, 0.5013, 0.5111, 0.4948],
       device='cuda:0')
percent tensor([0.5162, 0.5073, 0.4696, 0.4882, 0.4671, 0.4629, 0.4962, 0.5036, 0.5550,
        0.5087, 0.5338, 0.4884, 0.5361, 0.5777, 0.4799, 0.4915],
       device='cuda:0')
percent tensor([0.5770, 0.5001, 0.6181, 0.6119, 0.6199, 0.6162, 0.5477, 0.6137, 0.5722,
        0.5435, 0.5442, 0.5615, 0.5197, 0.5308, 0.5505, 0.5865],
       device='cuda:0')
percent tensor([0.5254, 0.5407, 0.4901, 0.5061, 0.4889, 0.5347, 0.5234, 0.4975, 0.5165,
        0.5379, 0.5422, 0.5092, 0.5383, 0.5479, 0.5256, 0.5320],
       device='cuda:0')
percent tensor([0.4227, 0.5284, 0.5393, 0.5902, 0.5258, 0.5448, 0.4973, 0.4239, 0.5418,
        0.5384, 0.5929, 0.5476, 0.4782, 0.6429, 0.4428, 0.4861],
       device='cuda:0')
percent tensor([0.6606, 0.6637, 0.6725, 0.6879, 0.6845, 0.6733, 0.6746, 0.6652, 0.6758,
        0.6631, 0.6846, 0.7002, 0.6522, 0.6913, 0.6884, 0.6747],
       device='cuda:0')
percent tensor([0.6063, 0.6079, 0.7648, 0.7848, 0.7874, 0.7005, 0.6508, 0.7405, 0.5537,
        0.6122, 0.5988, 0.6973, 0.5448, 0.6432, 0.5908, 0.6720],
       device='cuda:0')
percent tensor([0.9987, 0.9956, 0.9979, 0.9984, 0.9980, 0.9961, 0.9956, 0.9983, 0.9954,
        0.9970, 0.9981, 0.9984, 0.9965, 0.9980, 0.9973, 0.9983],
       device='cuda:0')
Epoch: 63 | Batch_idx: 0 |  Loss: (0.4709) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (88.00%) (1250/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (2383/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3415) |  Loss2: (0.0000) | Acc: (88.00%) (3503/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3376) |  Loss2: (0.0000) | Acc: (88.00%) (4641/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (5783/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.3343) |  Loss2: (0.0000) | Acc: (88.00%) (6913/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (8043/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.3397) |  Loss2: (0.0000) | Acc: (88.00%) (9154/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.3406) |  Loss2: (0.0000) | Acc: (88.00%) (10279/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.3430) |  Loss2: (0.0000) | Acc: (88.00%) (11392/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.3396) |  Loss2: (0.0000) | Acc: (88.00%) (12536/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (88.00%) (13663/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (88.00%) (14793/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (15954/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (17082/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (18224/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (19359/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (20494/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (21652/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.3326) |  Loss2: (0.0000) | Acc: (88.00%) (22785/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.3312) |  Loss2: (0.0000) | Acc: (88.00%) (23922/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (25052/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (26194/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (27311/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.3337) |  Loss2: (0.0000) | Acc: (88.00%) (28432/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (29561/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.3367) |  Loss2: (0.0000) | Acc: (88.00%) (30666/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (88.00%) (31801/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (32955/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (34094/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (35231/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3368) |  Loss2: (0.0000) | Acc: (88.00%) (36329/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3379) |  Loss2: (0.0000) | Acc: (88.00%) (37438/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (88.00%) (38579/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3377) |  Loss2: (0.0000) | Acc: (88.00%) (39712/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3374) |  Loss2: (0.0000) | Acc: (88.00%) (40852/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3377) |  Loss2: (0.0000) | Acc: (88.00%) (41982/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (43114/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (44186/50000)
# TEST : Loss: (0.4948) | Acc: (83.00%) (8351/10000)
percent tensor([0.4966, 0.5146, 0.5253, 0.4958, 0.5274, 0.5030, 0.5247, 0.5012, 0.4983,
        0.5152, 0.4999, 0.5329, 0.4940, 0.5008, 0.5104, 0.4938],
       device='cuda:0')
percent tensor([0.5138, 0.5120, 0.4638, 0.4904, 0.4689, 0.4675, 0.4977, 0.4996, 0.5501,
        0.5063, 0.5350, 0.4813, 0.5346, 0.5779, 0.4846, 0.4958],
       device='cuda:0')
percent tensor([0.5806, 0.4986, 0.6205, 0.6074, 0.6275, 0.6203, 0.5518, 0.6118, 0.5726,
        0.5434, 0.5455, 0.5652, 0.5208, 0.5182, 0.5508, 0.5837],
       device='cuda:0')
percent tensor([0.5249, 0.5414, 0.4912, 0.5096, 0.4891, 0.5358, 0.5224, 0.4961, 0.5147,
        0.5381, 0.5393, 0.5097, 0.5360, 0.5478, 0.5247, 0.5336],
       device='cuda:0')
percent tensor([0.4203, 0.5180, 0.5444, 0.6026, 0.5464, 0.5466, 0.5100, 0.4355, 0.5347,
        0.5198, 0.5796, 0.5465, 0.4474, 0.6329, 0.4430, 0.4817],
       device='cuda:0')
percent tensor([0.6626, 0.6660, 0.6722, 0.6935, 0.6811, 0.6647, 0.6835, 0.6684, 0.6775,
        0.6656, 0.6885, 0.7012, 0.6435, 0.6943, 0.6951, 0.6772],
       device='cuda:0')
percent tensor([0.6217, 0.6217, 0.7679, 0.7811, 0.7959, 0.7199, 0.6729, 0.7371, 0.5931,
        0.6350, 0.6182, 0.7102, 0.5866, 0.6382, 0.6033, 0.6718],
       device='cuda:0')
percent tensor([0.9987, 0.9956, 0.9984, 0.9984, 0.9980, 0.9958, 0.9956, 0.9986, 0.9956,
        0.9966, 0.9977, 0.9988, 0.9969, 0.9960, 0.9974, 0.9980],
       device='cuda:0')
Epoch: 64 | Batch_idx: 0 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.3312) |  Loss2: (0.0000) | Acc: (88.00%) (1245/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (88.00%) (2381/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3168) |  Loss2: (0.0000) | Acc: (89.00%) (3535/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (88.00%) (4663/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3176) |  Loss2: (0.0000) | Acc: (88.00%) (5802/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3210) |  Loss2: (0.0000) | Acc: (88.00%) (6927/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3249) |  Loss2: (0.0000) | Acc: (88.00%) (8057/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3245) |  Loss2: (0.0000) | Acc: (88.00%) (9216/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3221) |  Loss2: (0.0000) | Acc: (88.00%) (10357/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3275) |  Loss2: (0.0000) | Acc: (88.00%) (11463/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (88.00%) (12596/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3275) |  Loss2: (0.0000) | Acc: (88.00%) (13724/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (14857/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (15995/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3287) |  Loss2: (0.0000) | Acc: (88.00%) (17126/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3293) |  Loss2: (0.0000) | Acc: (88.00%) (18252/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3294) |  Loss2: (0.0000) | Acc: (88.00%) (19383/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3290) |  Loss2: (0.0000) | Acc: (88.00%) (20524/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (21649/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (22782/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (23933/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3296) |  Loss2: (0.0000) | Acc: (88.00%) (25074/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3290) |  Loss2: (0.0000) | Acc: (88.00%) (26204/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3289) |  Loss2: (0.0000) | Acc: (88.00%) (27352/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3290) |  Loss2: (0.0000) | Acc: (88.00%) (28486/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3290) |  Loss2: (0.0000) | Acc: (88.00%) (29613/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3297) |  Loss2: (0.0000) | Acc: (88.00%) (30735/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3300) |  Loss2: (0.0000) | Acc: (88.00%) (31863/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3309) |  Loss2: (0.0000) | Acc: (88.00%) (32981/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (34122/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (35250/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3305) |  Loss2: (0.0000) | Acc: (88.00%) (36375/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3311) |  Loss2: (0.0000) | Acc: (88.00%) (37500/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3305) |  Loss2: (0.0000) | Acc: (88.00%) (38648/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (39774/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (40918/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3288) |  Loss2: (0.0000) | Acc: (88.00%) (42071/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (43213/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3289) |  Loss2: (0.0000) | Acc: (88.00%) (44311/50000)
# TEST : Loss: (0.4324) | Acc: (85.00%) (8545/10000)
percent tensor([0.4978, 0.5153, 0.5240, 0.4949, 0.5273, 0.5050, 0.5254, 0.5005, 0.5000,
        0.5164, 0.5026, 0.5330, 0.4960, 0.5018, 0.5112, 0.4949],
       device='cuda:0')
percent tensor([0.5104, 0.5109, 0.4590, 0.4854, 0.4643, 0.4640, 0.4934, 0.4947, 0.5461,
        0.5027, 0.5325, 0.4788, 0.5305, 0.5823, 0.4811, 0.4929],
       device='cuda:0')
percent tensor([0.5726, 0.4988, 0.6244, 0.6104, 0.6247, 0.6073, 0.5505, 0.6165, 0.5691,
        0.5429, 0.5384, 0.5685, 0.5175, 0.5281, 0.5465, 0.5789],
       device='cuda:0')
percent tensor([0.5274, 0.5419, 0.4955, 0.5119, 0.4910, 0.5352, 0.5234, 0.4976, 0.5156,
        0.5405, 0.5414, 0.5110, 0.5390, 0.5443, 0.5257, 0.5344],
       device='cuda:0')
percent tensor([0.4413, 0.5319, 0.5923, 0.6224, 0.5799, 0.5582, 0.5253, 0.4565, 0.5458,
        0.5434, 0.5837, 0.5796, 0.4828, 0.6359, 0.4629, 0.4888],
       device='cuda:0')
percent tensor([0.6646, 0.6671, 0.6792, 0.6978, 0.6860, 0.6715, 0.6845, 0.6718, 0.6782,
        0.6654, 0.6861, 0.7049, 0.6508, 0.6929, 0.6946, 0.6794],
       device='cuda:0')
percent tensor([0.6347, 0.6218, 0.7667, 0.7714, 0.7935, 0.7054, 0.6684, 0.7473, 0.5693,
        0.6351, 0.5890, 0.6979, 0.5507, 0.6380, 0.6168, 0.6677],
       device='cuda:0')
percent tensor([0.9986, 0.9953, 0.9979, 0.9980, 0.9982, 0.9971, 0.9957, 0.9986, 0.9943,
        0.9965, 0.9978, 0.9981, 0.9961, 0.9961, 0.9965, 0.9984],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 65 | Batch_idx: 0 |  Loss: (0.3619) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (1256/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (86.00%) (2336/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (86.00%) (3451/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (87.00%) (4573/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3668) |  Loss2: (0.0000) | Acc: (87.00%) (5685/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3668) |  Loss2: (0.0000) | Acc: (87.00%) (6798/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3692) |  Loss2: (0.0000) | Acc: (87.00%) (7913/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (87.00%) (9067/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (10202/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (11325/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (12459/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3581) |  Loss2: (0.0000) | Acc: (87.00%) (13569/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (14670/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (15790/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3597) |  Loss2: (0.0000) | Acc: (87.00%) (16907/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (18046/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (19182/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (20297/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (21417/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (22537/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (87.00%) (23668/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3542) |  Loss2: (0.0000) | Acc: (87.00%) (24809/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (25949/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (87.00%) (27066/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (87.00%) (28219/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (29328/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (30445/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (31559/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3506) |  Loss2: (0.0000) | Acc: (87.00%) (32723/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (33846/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (87.00%) (34983/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (36126/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3478) |  Loss2: (0.0000) | Acc: (87.00%) (37275/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3481) |  Loss2: (0.0000) | Acc: (87.00%) (38398/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3470) |  Loss2: (0.0000) | Acc: (87.00%) (39532/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3458) |  Loss2: (0.0000) | Acc: (88.00%) (40680/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3455) |  Loss2: (0.0000) | Acc: (88.00%) (41831/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3452) |  Loss2: (0.0000) | Acc: (88.00%) (42961/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (88.00%) (44066/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_065.pth.tar'
# TEST : Loss: (0.4377) | Acc: (85.00%) (8536/10000)
percent tensor([0.4943, 0.5150, 0.5195, 0.4918, 0.5236, 0.5019, 0.5233, 0.4987, 0.4975,
        0.5144, 0.5006, 0.5293, 0.4933, 0.5008, 0.5097, 0.4922],
       device='cuda:0')
percent tensor([0.5102, 0.5072, 0.4688, 0.4919, 0.4687, 0.4633, 0.4931, 0.5010, 0.5486,
        0.5054, 0.5318, 0.4860, 0.5306, 0.5779, 0.4798, 0.4944],
       device='cuda:0')
percent tensor([0.5681, 0.4849, 0.6197, 0.6037, 0.6182, 0.6046, 0.5418, 0.6085, 0.5594,
        0.5322, 0.5267, 0.5590, 0.5079, 0.5129, 0.5364, 0.5740],
       device='cuda:0')
percent tensor([0.5487, 0.5651, 0.5102, 0.5286, 0.5059, 0.5525, 0.5448, 0.5192, 0.5349,
        0.5608, 0.5616, 0.5280, 0.5597, 0.5665, 0.5495, 0.5560],
       device='cuda:0')
percent tensor([0.4302, 0.5163, 0.6071, 0.6422, 0.5924, 0.5478, 0.5223, 0.4674, 0.5593,
        0.5465, 0.5840, 0.6024, 0.4810, 0.6318, 0.4530, 0.4858],
       device='cuda:0')
percent tensor([0.7082, 0.7153, 0.7073, 0.7301, 0.7143, 0.7052, 0.7286, 0.7074, 0.7217,
        0.7122, 0.7334, 0.7422, 0.7059, 0.7371, 0.7367, 0.7213],
       device='cuda:0')
percent tensor([0.6323, 0.6268, 0.7951, 0.7922, 0.8185, 0.7183, 0.6830, 0.7677, 0.5767,
        0.6571, 0.6076, 0.7211, 0.5614, 0.6537, 0.6149, 0.6751],
       device='cuda:0')
percent tensor([0.9986, 0.9955, 0.9977, 0.9977, 0.9978, 0.9969, 0.9962, 0.9987, 0.9942,
        0.9972, 0.9978, 0.9982, 0.9964, 0.9962, 0.9970, 0.9984],
       device='cuda:0')
Epoch: 66 | Batch_idx: 0 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (2357/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3461) |  Loss2: (0.0000) | Acc: (88.00%) (3496/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3437) |  Loss2: (0.0000) | Acc: (88.00%) (4629/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (88.00%) (5766/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3407) |  Loss2: (0.0000) | Acc: (88.00%) (6887/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3420) |  Loss2: (0.0000) | Acc: (88.00%) (8013/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3426) |  Loss2: (0.0000) | Acc: (88.00%) (9137/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3408) |  Loss2: (0.0000) | Acc: (88.00%) (10267/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3367) |  Loss2: (0.0000) | Acc: (88.00%) (11407/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (12550/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (88.00%) (13691/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (14818/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (15952/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3339) |  Loss2: (0.0000) | Acc: (88.00%) (17096/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (18230/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (19360/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (20501/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (21634/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (22773/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3305) |  Loss2: (0.0000) | Acc: (88.00%) (23920/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3297) |  Loss2: (0.0000) | Acc: (88.00%) (25067/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3303) |  Loss2: (0.0000) | Acc: (88.00%) (26194/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (27312/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (28434/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (29555/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (30693/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3304) |  Loss2: (0.0000) | Acc: (88.00%) (31838/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3310) |  Loss2: (0.0000) | Acc: (88.00%) (32958/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (34092/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3297) |  Loss2: (0.0000) | Acc: (88.00%) (35251/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3296) |  Loss2: (0.0000) | Acc: (88.00%) (36398/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (37528/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (88.00%) (38670/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3293) |  Loss2: (0.0000) | Acc: (88.00%) (39796/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (40936/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (42085/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3279) |  Loss2: (0.0000) | Acc: (88.00%) (43236/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (44340/50000)
# TEST : Loss: (0.4238) | Acc: (85.00%) (8590/10000)
percent tensor([0.4932, 0.5152, 0.5170, 0.4909, 0.5219, 0.5012, 0.5225, 0.4980, 0.4969,
        0.5136, 0.5003, 0.5273, 0.4926, 0.5009, 0.5097, 0.4917],
       device='cuda:0')
percent tensor([0.5122, 0.5087, 0.4768, 0.4986, 0.4746, 0.4637, 0.4965, 0.5079, 0.5516,
        0.5093, 0.5335, 0.4917, 0.5319, 0.5809, 0.4806, 0.4972],
       device='cuda:0')
percent tensor([0.5674, 0.4797, 0.6209, 0.6034, 0.6195, 0.6033, 0.5401, 0.6102, 0.5577,
        0.5297, 0.5235, 0.5557, 0.5027, 0.5100, 0.5325, 0.5735],
       device='cuda:0')
percent tensor([0.5616, 0.5774, 0.5194, 0.5386, 0.5148, 0.5638, 0.5565, 0.5311, 0.5447,
        0.5720, 0.5723, 0.5387, 0.5725, 0.5780, 0.5629, 0.5681],
       device='cuda:0')
percent tensor([0.4253, 0.5172, 0.6071, 0.6478, 0.5937, 0.5453, 0.5216, 0.4674, 0.5644,
        0.5468, 0.5901, 0.6105, 0.4815, 0.6319, 0.4535, 0.4876],
       device='cuda:0')
percent tensor([0.7093, 0.7188, 0.7075, 0.7294, 0.7119, 0.7046, 0.7281, 0.7042, 0.7238,
        0.7149, 0.7368, 0.7455, 0.7125, 0.7394, 0.7378, 0.7205],
       device='cuda:0')
percent tensor([0.6289, 0.6365, 0.7998, 0.7986, 0.8247, 0.7272, 0.6945, 0.7645, 0.5923,
        0.6667, 0.6190, 0.7290, 0.5637, 0.6768, 0.6116, 0.6797],
       device='cuda:0')
percent tensor([0.9987, 0.9956, 0.9979, 0.9979, 0.9979, 0.9971, 0.9964, 0.9988, 0.9947,
        0.9973, 0.9980, 0.9984, 0.9966, 0.9964, 0.9970, 0.9985],
       device='cuda:0')
Epoch: 67 | Batch_idx: 0 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.3697) |  Loss2: (0.0000) | Acc: (87.00%) (1237/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (88.00%) (2375/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3528) |  Loss2: (0.0000) | Acc: (88.00%) (3497/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (4651/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.3283) |  Loss2: (0.0000) | Acc: (88.00%) (5788/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.3287) |  Loss2: (0.0000) | Acc: (88.00%) (6926/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (88.00%) (8073/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3263) |  Loss2: (0.0000) | Acc: (88.00%) (9215/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3278) |  Loss2: (0.0000) | Acc: (88.00%) (10346/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (11487/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3258) |  Loss2: (0.0000) | Acc: (88.00%) (12627/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (13778/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (89.00%) (14934/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (89.00%) (16075/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3223) |  Loss2: (0.0000) | Acc: (89.00%) (17239/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (89.00%) (18380/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (89.00%) (19513/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3218) |  Loss2: (0.0000) | Acc: (89.00%) (20640/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (89.00%) (21765/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (89.00%) (22916/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3213) |  Loss2: (0.0000) | Acc: (89.00%) (24058/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (89.00%) (25204/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (89.00%) (26341/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (89.00%) (27493/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3199) |  Loss2: (0.0000) | Acc: (89.00%) (28634/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (89.00%) (29782/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (89.00%) (30922/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (89.00%) (32072/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (89.00%) (33208/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3189) |  Loss2: (0.0000) | Acc: (89.00%) (34355/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3186) |  Loss2: (0.0000) | Acc: (89.00%) (35502/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (89.00%) (36656/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (89.00%) (37794/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3181) |  Loss2: (0.0000) | Acc: (89.00%) (38921/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (89.00%) (40072/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3173) |  Loss2: (0.0000) | Acc: (89.00%) (41222/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3171) |  Loss2: (0.0000) | Acc: (89.00%) (42365/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3170) |  Loss2: (0.0000) | Acc: (89.00%) (43500/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (89.00%) (44597/50000)
# TEST : Loss: (0.4172) | Acc: (86.00%) (8603/10000)
percent tensor([0.4936, 0.5167, 0.5168, 0.4911, 0.5224, 0.5021, 0.5234, 0.4984, 0.4978,
        0.5141, 0.5013, 0.5272, 0.4932, 0.5025, 0.5108, 0.4920],
       device='cuda:0')
percent tensor([0.5133, 0.5092, 0.4826, 0.5019, 0.4787, 0.4637, 0.4986, 0.5118, 0.5531,
        0.5114, 0.5338, 0.4956, 0.5323, 0.5817, 0.4809, 0.4982],
       device='cuda:0')
percent tensor([0.5672, 0.4834, 0.6186, 0.6009, 0.6172, 0.6004, 0.5422, 0.6080, 0.5595,
        0.5339, 0.5283, 0.5551, 0.5048, 0.5160, 0.5321, 0.5741],
       device='cuda:0')
percent tensor([0.5651, 0.5810, 0.5211, 0.5406, 0.5163, 0.5669, 0.5595, 0.5342, 0.5468,
        0.5744, 0.5744, 0.5411, 0.5761, 0.5807, 0.5668, 0.5712],
       device='cuda:0')
percent tensor([0.4271, 0.5236, 0.6067, 0.6504, 0.5941, 0.5453, 0.5256, 0.4659, 0.5725,
        0.5532, 0.6033, 0.6188, 0.4871, 0.6418, 0.4573, 0.4934],
       device='cuda:0')
percent tensor([0.6998, 0.7118, 0.6988, 0.7198, 0.7012, 0.6958, 0.7189, 0.6921, 0.7158,
        0.7066, 0.7301, 0.7378, 0.7057, 0.7328, 0.7288, 0.7102],
       device='cuda:0')
percent tensor([0.6111, 0.6280, 0.7922, 0.7912, 0.8177, 0.7245, 0.6856, 0.7487, 0.5890,
        0.6582, 0.6103, 0.7177, 0.5541, 0.6715, 0.5936, 0.6672],
       device='cuda:0')
percent tensor([0.9988, 0.9959, 0.9980, 0.9981, 0.9979, 0.9973, 0.9965, 0.9989, 0.9953,
        0.9974, 0.9982, 0.9984, 0.9969, 0.9969, 0.9972, 0.9986],
       device='cuda:0')
Epoch: 68 | Batch_idx: 0 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (90.00%) (1268/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (2404/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (3549/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (4697/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (89.00%) (5839/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (6974/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (8131/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (9279/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.3067) |  Loss2: (0.0000) | Acc: (89.00%) (10427/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (11566/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (89.00%) (12713/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (13866/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (15027/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (16173/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (17324/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.3072) |  Loss2: (0.0000) | Acc: (89.00%) (18458/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.3069) |  Loss2: (0.0000) | Acc: (89.00%) (19588/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (20736/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (21851/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.3101) |  Loss2: (0.0000) | Acc: (89.00%) (22997/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (24155/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (25286/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.3101) |  Loss2: (0.0000) | Acc: (89.00%) (26436/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.3101) |  Loss2: (0.0000) | Acc: (89.00%) (27574/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.3096) |  Loss2: (0.0000) | Acc: (89.00%) (28729/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (29897/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (31040/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (32162/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (33295/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (34448/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (35599/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (36737/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3116) |  Loss2: (0.0000) | Acc: (89.00%) (37871/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (39027/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (40153/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (41313/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (42455/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (43593/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (44679/50000)
# TEST : Loss: (0.4133) | Acc: (86.00%) (8609/10000)
percent tensor([0.4915, 0.5152, 0.5149, 0.4897, 0.5205, 0.5006, 0.5216, 0.4966, 0.4961,
        0.5122, 0.4996, 0.5250, 0.4914, 0.5012, 0.5093, 0.4901],
       device='cuda:0')
percent tensor([0.5141, 0.5086, 0.4854, 0.5034, 0.4807, 0.4632, 0.4989, 0.5135, 0.5539,
        0.5117, 0.5334, 0.4969, 0.5322, 0.5809, 0.4803, 0.4982],
       device='cuda:0')
percent tensor([0.5685, 0.4862, 0.6193, 0.6013, 0.6175, 0.6011, 0.5445, 0.6084, 0.5604,
        0.5380, 0.5310, 0.5560, 0.5057, 0.5210, 0.5328, 0.5764],
       device='cuda:0')
percent tensor([0.5609, 0.5766, 0.5169, 0.5360, 0.5119, 0.5637, 0.5550, 0.5304, 0.5431,
        0.5690, 0.5696, 0.5360, 0.5726, 0.5765, 0.5627, 0.5668],
       device='cuda:0')
percent tensor([0.4221, 0.5193, 0.6064, 0.6529, 0.5969, 0.5495, 0.5228, 0.4642, 0.5722,
        0.5477, 0.5998, 0.6182, 0.4800, 0.6402, 0.4562, 0.4933],
       device='cuda:0')
percent tensor([0.6985, 0.7125, 0.6973, 0.7174, 0.6986, 0.6954, 0.7175, 0.6883, 0.7161,
        0.7059, 0.7310, 0.7374, 0.7073, 0.7334, 0.7278, 0.7077],
       device='cuda:0')
percent tensor([0.6105, 0.6378, 0.7937, 0.7939, 0.8201, 0.7326, 0.6917, 0.7457, 0.5943,
        0.6658, 0.6154, 0.7199, 0.5586, 0.6804, 0.5951, 0.6718],
       device='cuda:0')
percent tensor([0.9988, 0.9960, 0.9981, 0.9982, 0.9981, 0.9974, 0.9966, 0.9989, 0.9956,
        0.9975, 0.9983, 0.9985, 0.9970, 0.9970, 0.9973, 0.9986],
       device='cuda:0')
Epoch: 69 | Batch_idx: 0 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (1274/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.3099) |  Loss2: (0.0000) | Acc: (89.00%) (2410/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.2993) |  Loss2: (0.0000) | Acc: (90.00%) (3575/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (4710/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (5858/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (7006/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.2977) |  Loss2: (0.0000) | Acc: (89.00%) (8163/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (9282/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (10429/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (11581/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (12725/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (13894/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (15028/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (16183/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3011) |  Loss2: (0.0000) | Acc: (89.00%) (17340/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (18473/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (19626/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (20795/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (21925/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (23065/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (24217/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (25366/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (26512/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (27666/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (28800/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (29929/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (31074/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (32216/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (33367/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (34517/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (35677/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (36804/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (37956/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (39103/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (40246/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3062) |  Loss2: (0.0000) | Acc: (89.00%) (41410/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3062) |  Loss2: (0.0000) | Acc: (89.00%) (42549/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3067) |  Loss2: (0.0000) | Acc: (89.00%) (43682/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3066) |  Loss2: (0.0000) | Acc: (89.00%) (44788/50000)
# TEST : Loss: (0.4091) | Acc: (86.00%) (8631/10000)
percent tensor([0.4915, 0.5161, 0.5141, 0.4896, 0.5203, 0.5010, 0.5219, 0.4967, 0.4966,
        0.5123, 0.5002, 0.5245, 0.4917, 0.5021, 0.5100, 0.4903],
       device='cuda:0')
percent tensor([0.5129, 0.5074, 0.4884, 0.5045, 0.4819, 0.4619, 0.4987, 0.5149, 0.5535,
        0.5124, 0.5327, 0.4989, 0.5310, 0.5800, 0.4790, 0.4973],
       device='cuda:0')
percent tensor([0.5672, 0.4848, 0.6189, 0.5994, 0.6178, 0.5990, 0.5446, 0.6078, 0.5607,
        0.5379, 0.5319, 0.5541, 0.5037, 0.5202, 0.5308, 0.5755],
       device='cuda:0')
percent tensor([0.5622, 0.5781, 0.5180, 0.5373, 0.5126, 0.5652, 0.5561, 0.5318, 0.5434,
        0.5698, 0.5699, 0.5370, 0.5740, 0.5772, 0.5644, 0.5681],
       device='cuda:0')
percent tensor([0.4171, 0.5127, 0.6000, 0.6463, 0.5913, 0.5447, 0.5153, 0.4600, 0.5675,
        0.5375, 0.5918, 0.6113, 0.4735, 0.6337, 0.4494, 0.4870],
       device='cuda:0')
percent tensor([0.6917, 0.7063, 0.6914, 0.7111, 0.6921, 0.6899, 0.7102, 0.6804, 0.7099,
        0.6994, 0.7248, 0.7313, 0.7019, 0.7267, 0.7206, 0.6998],
       device='cuda:0')
percent tensor([0.6194, 0.6525, 0.7932, 0.7947, 0.8196, 0.7380, 0.6997, 0.7424, 0.6065,
        0.6765, 0.6284, 0.7193, 0.5736, 0.6897, 0.5997, 0.6763],
       device='cuda:0')
percent tensor([0.9989, 0.9963, 0.9983, 0.9984, 0.9981, 0.9977, 0.9969, 0.9990, 0.9960,
        0.9977, 0.9984, 0.9986, 0.9974, 0.9973, 0.9975, 0.9988],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 70 | Batch_idx: 0 |  Loss: (0.3745) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (1267/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.3149) |  Loss2: (0.0000) | Acc: (89.00%) (2410/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (3553/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (4702/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.3127) |  Loss2: (0.0000) | Acc: (89.00%) (5841/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (89.00%) (6969/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (8111/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (9262/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (10412/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (11567/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (89.00%) (12704/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (13836/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (89.00%) (14993/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (16153/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (17289/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.3168) |  Loss2: (0.0000) | Acc: (89.00%) (18420/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (89.00%) (19532/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.3220) |  Loss2: (0.0000) | Acc: (89.00%) (20656/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.3220) |  Loss2: (0.0000) | Acc: (89.00%) (21785/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (89.00%) (22929/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.3212) |  Loss2: (0.0000) | Acc: (89.00%) (24080/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.3213) |  Loss2: (0.0000) | Acc: (89.00%) (25210/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (89.00%) (26353/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (89.00%) (27497/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (89.00%) (28632/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (89.00%) (29777/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (89.00%) (30914/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3214) |  Loss2: (0.0000) | Acc: (89.00%) (32033/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3209) |  Loss2: (0.0000) | Acc: (89.00%) (33169/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (89.00%) (34300/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (89.00%) (35438/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3201) |  Loss2: (0.0000) | Acc: (89.00%) (36578/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (88.00%) (37696/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (88.00%) (38838/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3215) |  Loss2: (0.0000) | Acc: (88.00%) (39965/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (88.00%) (41095/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3220) |  Loss2: (0.0000) | Acc: (88.00%) (42227/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3221) |  Loss2: (0.0000) | Acc: (88.00%) (43358/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (88.00%) (44450/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_070.pth.tar'
# TEST : Loss: (0.4697) | Acc: (84.00%) (8466/10000)
percent tensor([0.4932, 0.5155, 0.5181, 0.4880, 0.5231, 0.5032, 0.5234, 0.4960, 0.4971,
        0.5129, 0.5015, 0.5275, 0.4930, 0.5006, 0.5103, 0.4903],
       device='cuda:0')
percent tensor([0.5158, 0.5060, 0.4797, 0.4999, 0.4763, 0.4568, 0.4966, 0.5101, 0.5576,
        0.5101, 0.5356, 0.4904, 0.5324, 0.5721, 0.4782, 0.4943],
       device='cuda:0')
percent tensor([0.5744, 0.5011, 0.6150, 0.6040, 0.6161, 0.6097, 0.5577, 0.6109, 0.5713,
        0.5455, 0.5472, 0.5513, 0.5107, 0.5448, 0.5423, 0.5852],
       device='cuda:0')
percent tensor([0.5599, 0.5729, 0.5144, 0.5323, 0.5109, 0.5661, 0.5542, 0.5281, 0.5399,
        0.5657, 0.5680, 0.5377, 0.5717, 0.5756, 0.5643, 0.5641],
       device='cuda:0')
percent tensor([0.4039, 0.5141, 0.5613, 0.6163, 0.5736, 0.5383, 0.5091, 0.4462, 0.5838,
        0.5375, 0.6208, 0.5948, 0.4656, 0.6513, 0.4486, 0.4779],
       device='cuda:0')
percent tensor([0.6836, 0.6970, 0.6943, 0.7004, 0.6971, 0.6911, 0.7062, 0.6748, 0.7058,
        0.6970, 0.7181, 0.7340, 0.6919, 0.7192, 0.7135, 0.6943],
       device='cuda:0')
percent tensor([0.6313, 0.6726, 0.7864, 0.8080, 0.8259, 0.7556, 0.7074, 0.7461, 0.6357,
        0.6756, 0.6530, 0.6907, 0.5696, 0.6897, 0.6323, 0.7074],
       device='cuda:0')
percent tensor([0.9990, 0.9964, 0.9986, 0.9987, 0.9984, 0.9974, 0.9974, 0.9991, 0.9960,
        0.9972, 0.9981, 0.9987, 0.9967, 0.9974, 0.9973, 0.9986],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(176.6755, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(806.8722, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(805.3985, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1522.4771, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(498.0739, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2204.1570, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4285.1899, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1413.1404, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6111.6465, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11999.7129, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3978.2634, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16839.5059, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 71 | Batch_idx: 0 |  Loss: (0.3551) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (1270/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (89.00%) (2419/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.2986) |  Loss2: (0.0000) | Acc: (89.00%) (3558/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.2975) |  Loss2: (0.0000) | Acc: (89.00%) (4710/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (5850/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (6979/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (8114/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (9256/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (10404/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (11556/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (12715/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.3030) |  Loss2: (0.0000) | Acc: (89.00%) (13865/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.3036) |  Loss2: (0.0000) | Acc: (89.00%) (15007/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (89.00%) (16147/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (17287/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (18443/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (19580/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (20721/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (21849/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.3092) |  Loss2: (0.0000) | Acc: (89.00%) (22986/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.3099) |  Loss2: (0.0000) | Acc: (89.00%) (24113/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (25252/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.3106) |  Loss2: (0.0000) | Acc: (89.00%) (26390/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (27519/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (28662/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (29804/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (30951/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (32097/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (33227/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (34364/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (35503/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (36648/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (37784/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.3123) |  Loss2: (0.0000) | Acc: (89.00%) (38922/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (89.00%) (40058/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (89.00%) (41173/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (42310/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (43465/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (44556/50000)
# TEST : Loss: (0.4437) | Acc: (84.00%) (8493/10000)
percent tensor([0.4941, 0.5157, 0.5194, 0.4898, 0.5246, 0.5050, 0.5237, 0.4973, 0.4979,
        0.5130, 0.5018, 0.5277, 0.4933, 0.5005, 0.5113, 0.4913],
       device='cuda:0')
percent tensor([0.5103, 0.5057, 0.4804, 0.5027, 0.4802, 0.4602, 0.4978, 0.5132, 0.5531,
        0.5098, 0.5312, 0.4938, 0.5274, 0.5795, 0.4773, 0.4937],
       device='cuda:0')
percent tensor([0.5683, 0.4863, 0.6086, 0.6000, 0.6126, 0.6044, 0.5433, 0.6020, 0.5593,
        0.5363, 0.5372, 0.5412, 0.5003, 0.5224, 0.5334, 0.5784],
       device='cuda:0')
percent tensor([0.5611, 0.5787, 0.5191, 0.5342, 0.5123, 0.5639, 0.5578, 0.5318, 0.5444,
        0.5694, 0.5704, 0.5434, 0.5746, 0.5783, 0.5657, 0.5647],
       device='cuda:0')
percent tensor([0.4442, 0.5465, 0.5902, 0.6319, 0.5833, 0.5665, 0.5320, 0.4739, 0.5817,
        0.5577, 0.6220, 0.6136, 0.4866, 0.6717, 0.4831, 0.5193],
       device='cuda:0')
percent tensor([0.6947, 0.7089, 0.6992, 0.7061, 0.7002, 0.6928, 0.7162, 0.6860, 0.7123,
        0.7019, 0.7247, 0.7354, 0.7024, 0.7253, 0.7268, 0.7016],
       device='cuda:0')
percent tensor([0.6403, 0.6572, 0.7812, 0.8033, 0.8204, 0.7588, 0.7151, 0.7437, 0.6125,
        0.6914, 0.6275, 0.6967, 0.5719, 0.6977, 0.6292, 0.7063],
       device='cuda:0')
percent tensor([0.9989, 0.9968, 0.9983, 0.9980, 0.9983, 0.9970, 0.9977, 0.9990, 0.9968,
        0.9981, 0.9988, 0.9988, 0.9973, 0.9964, 0.9971, 0.9984],
       device='cuda:0')
Epoch: 72 | Batch_idx: 0 |  Loss: (0.3270) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (89.00%) (1260/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.2885) |  Loss2: (0.0000) | Acc: (89.00%) (2411/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.2994) |  Loss2: (0.0000) | Acc: (89.00%) (3561/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (4697/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (5851/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (6990/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (8141/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (9280/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (10427/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (11562/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (12715/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (13869/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (15015/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (89.00%) (16149/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (17297/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (18451/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (19614/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (20751/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (21894/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (23033/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.3062) |  Loss2: (0.0000) | Acc: (89.00%) (24162/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (25320/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (26453/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (27596/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (28742/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (29869/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (30990/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (32125/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (33267/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (34410/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (35548/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.3079) |  Loss2: (0.0000) | Acc: (89.00%) (36693/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.3073) |  Loss2: (0.0000) | Acc: (89.00%) (37852/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (39008/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (40175/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (41319/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (42470/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (43624/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (44712/50000)
# TEST : Loss: (0.4671) | Acc: (84.00%) (8446/10000)
percent tensor([0.4937, 0.5158, 0.5228, 0.4905, 0.5269, 0.5034, 0.5249, 0.4995, 0.4977,
        0.5134, 0.5001, 0.5295, 0.4925, 0.5026, 0.5104, 0.4903],
       device='cuda:0')
percent tensor([0.5090, 0.5040, 0.4826, 0.5050, 0.4793, 0.4555, 0.4947, 0.5131, 0.5470,
        0.5105, 0.5237, 0.4970, 0.5244, 0.5723, 0.4747, 0.4923],
       device='cuda:0')
percent tensor([0.5751, 0.4935, 0.6115, 0.6048, 0.6113, 0.6161, 0.5454, 0.6043, 0.5618,
        0.5353, 0.5419, 0.5434, 0.5112, 0.5172, 0.5439, 0.5835],
       device='cuda:0')
percent tensor([0.5624, 0.5782, 0.5159, 0.5332, 0.5133, 0.5649, 0.5578, 0.5317, 0.5423,
        0.5693, 0.5699, 0.5412, 0.5754, 0.5824, 0.5656, 0.5660],
       device='cuda:0')
percent tensor([0.4272, 0.5413, 0.5745, 0.6193, 0.5821, 0.5670, 0.5454, 0.4563, 0.5672,
        0.5500, 0.6138, 0.5984, 0.4737, 0.6801, 0.4740, 0.5052],
       device='cuda:0')
percent tensor([0.6920, 0.7043, 0.6959, 0.7025, 0.6980, 0.6907, 0.7121, 0.6791, 0.7078,
        0.7056, 0.7187, 0.7312, 0.6995, 0.7256, 0.7224, 0.7007],
       device='cuda:0')
percent tensor([0.6491, 0.6942, 0.7793, 0.7997, 0.8126, 0.7512, 0.7230, 0.7379, 0.6404,
        0.6871, 0.6623, 0.7026, 0.6032, 0.7012, 0.6217, 0.7046],
       device='cuda:0')
percent tensor([0.9987, 0.9965, 0.9976, 0.9983, 0.9984, 0.9971, 0.9972, 0.9987, 0.9959,
        0.9981, 0.9980, 0.9989, 0.9969, 0.9970, 0.9980, 0.9985],
       device='cuda:0')
Epoch: 73 | Batch_idx: 0 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.2924) |  Loss2: (0.0000) | Acc: (89.00%) (1262/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (88.00%) (2392/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.3030) |  Loss2: (0.0000) | Acc: (89.00%) (3540/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (4685/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (89.00%) (5847/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.2959) |  Loss2: (0.0000) | Acc: (89.00%) (7003/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (8153/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.2957) |  Loss2: (0.0000) | Acc: (89.00%) (9295/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.2937) |  Loss2: (0.0000) | Acc: (89.00%) (10453/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (11601/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (12747/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.2924) |  Loss2: (0.0000) | Acc: (89.00%) (13903/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (89.00%) (15045/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.2931) |  Loss2: (0.0000) | Acc: (89.00%) (16202/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (89.00%) (17365/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (89.00%) (18517/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.2916) |  Loss2: (0.0000) | Acc: (89.00%) (19666/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (89.00%) (20792/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (21942/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (89.00%) (23106/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.2957) |  Loss2: (0.0000) | Acc: (89.00%) (24248/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.2954) |  Loss2: (0.0000) | Acc: (89.00%) (25390/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.2967) |  Loss2: (0.0000) | Acc: (89.00%) (26528/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (27688/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (28844/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (29990/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (31147/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (32278/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.2945) |  Loss2: (0.0000) | Acc: (89.00%) (33425/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (89.00%) (34579/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (35726/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (36862/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.2945) |  Loss2: (0.0000) | Acc: (89.00%) (38013/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (89.00%) (39171/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (40314/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (89.00%) (41461/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (42612/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (43747/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (89.00%) (44850/50000)
# TEST : Loss: (0.4533) | Acc: (85.00%) (8535/10000)
percent tensor([0.4944, 0.5158, 0.5198, 0.4911, 0.5251, 0.5043, 0.5236, 0.4988, 0.4978,
        0.5131, 0.5012, 0.5271, 0.4936, 0.4998, 0.5115, 0.4912],
       device='cuda:0')
percent tensor([0.5105, 0.5047, 0.4812, 0.5000, 0.4769, 0.4588, 0.4965, 0.5117, 0.5538,
        0.5102, 0.5311, 0.4930, 0.5265, 0.5769, 0.4762, 0.4936],
       device='cuda:0')
percent tensor([0.5717, 0.4886, 0.6099, 0.6002, 0.6122, 0.6057, 0.5408, 0.6052, 0.5590,
        0.5291, 0.5345, 0.5381, 0.5049, 0.5166, 0.5370, 0.5785],
       device='cuda:0')
percent tensor([0.5615, 0.5776, 0.5123, 0.5307, 0.5109, 0.5629, 0.5567, 0.5290, 0.5421,
        0.5700, 0.5728, 0.5387, 0.5735, 0.5778, 0.5646, 0.5669],
       device='cuda:0')
percent tensor([0.4425, 0.5510, 0.5888, 0.6312, 0.5899, 0.5749, 0.5423, 0.4663, 0.5990,
        0.5665, 0.6427, 0.5972, 0.5084, 0.6682, 0.4793, 0.5181],
       device='cuda:0')
percent tensor([0.6873, 0.7013, 0.6952, 0.7012, 0.6992, 0.6916, 0.7115, 0.6775, 0.7091,
        0.7006, 0.7163, 0.7312, 0.6954, 0.7198, 0.7207, 0.6969],
       device='cuda:0')
percent tensor([0.6421, 0.6745, 0.7838, 0.8016, 0.8171, 0.7476, 0.7028, 0.7392, 0.6376,
        0.6707, 0.6534, 0.7067, 0.5933, 0.6910, 0.6200, 0.7006],
       device='cuda:0')
percent tensor([0.9990, 0.9972, 0.9985, 0.9988, 0.9982, 0.9975, 0.9971, 0.9992, 0.9967,
        0.9981, 0.9988, 0.9990, 0.9979, 0.9974, 0.9980, 0.9985],
       device='cuda:0')
Epoch: 74 | Batch_idx: 0 |  Loss: (0.3284) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.2888) |  Loss2: (0.0000) | Acc: (90.00%) (1269/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (2444/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (3609/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (4766/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (5907/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (7070/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (8227/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (9375/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (10519/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (11674/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (12821/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (90.00%) (13979/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (15135/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (16289/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (17440/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (18589/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (90.00%) (19718/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2889) |  Loss2: (0.0000) | Acc: (90.00%) (20873/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2885) |  Loss2: (0.0000) | Acc: (90.00%) (22029/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2893) |  Loss2: (0.0000) | Acc: (90.00%) (23178/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2916) |  Loss2: (0.0000) | Acc: (89.00%) (24306/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (90.00%) (25466/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (89.00%) (26604/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2917) |  Loss2: (0.0000) | Acc: (90.00%) (27768/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2917) |  Loss2: (0.0000) | Acc: (90.00%) (28929/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (90.00%) (30077/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2918) |  Loss2: (0.0000) | Acc: (90.00%) (31235/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (90.00%) (32376/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2931) |  Loss2: (0.0000) | Acc: (90.00%) (33528/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2927) |  Loss2: (0.0000) | Acc: (90.00%) (34689/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2927) |  Loss2: (0.0000) | Acc: (90.00%) (35839/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (90.00%) (36988/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2920) |  Loss2: (0.0000) | Acc: (90.00%) (38140/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (90.00%) (39286/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (90.00%) (40448/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2919) |  Loss2: (0.0000) | Acc: (90.00%) (41604/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (90.00%) (42767/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2904) |  Loss2: (0.0000) | Acc: (90.00%) (43922/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2909) |  Loss2: (0.0000) | Acc: (90.00%) (45032/50000)
# TEST : Loss: (0.4067) | Acc: (86.00%) (8604/10000)
percent tensor([0.4934, 0.5172, 0.5172, 0.4923, 0.5219, 0.5019, 0.5231, 0.4986, 0.4982,
        0.5127, 0.5017, 0.5253, 0.4937, 0.5028, 0.5115, 0.4921],
       device='cuda:0')
percent tensor([0.5159, 0.5062, 0.4804, 0.5009, 0.4785, 0.4670, 0.5003, 0.5105, 0.5524,
        0.5097, 0.5323, 0.4944, 0.5272, 0.5789, 0.4804, 0.4972],
       device='cuda:0')
percent tensor([0.5707, 0.4931, 0.6089, 0.6019, 0.6177, 0.6125, 0.5478, 0.6033, 0.5621,
        0.5336, 0.5398, 0.5421, 0.5053, 0.5328, 0.5419, 0.5822],
       device='cuda:0')
percent tensor([0.5607, 0.5758, 0.5170, 0.5343, 0.5127, 0.5637, 0.5559, 0.5286, 0.5411,
        0.5680, 0.5686, 0.5396, 0.5717, 0.5726, 0.5644, 0.5648],
       device='cuda:0')
percent tensor([0.3983, 0.5006, 0.5737, 0.6183, 0.5682, 0.5414, 0.5089, 0.4438, 0.5608,
        0.5212, 0.6027, 0.5848, 0.4617, 0.6207, 0.4366, 0.4793],
       device='cuda:0')
percent tensor([0.6862, 0.6952, 0.6889, 0.7024, 0.6901, 0.6841, 0.7069, 0.6801, 0.7003,
        0.6910, 0.7114, 0.7238, 0.6918, 0.7178, 0.7123, 0.6905],
       device='cuda:0')
percent tensor([0.6323, 0.6645, 0.7869, 0.8114, 0.8180, 0.7650, 0.6949, 0.7324, 0.6141,
        0.6619, 0.6422, 0.7098, 0.5889, 0.6889, 0.6137, 0.7042],
       device='cuda:0')
percent tensor([0.9988, 0.9963, 0.9986, 0.9987, 0.9982, 0.9973, 0.9970, 0.9992, 0.9964,
        0.9969, 0.9985, 0.9987, 0.9974, 0.9968, 0.9977, 0.9982],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 75 | Batch_idx: 0 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (1281/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (90.00%) (2427/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (3557/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (4684/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (88.00%) (5808/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (88.00%) (6944/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.3199) |  Loss2: (0.0000) | Acc: (88.00%) (8067/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.3176) |  Loss2: (0.0000) | Acc: (88.00%) (9207/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.3174) |  Loss2: (0.0000) | Acc: (88.00%) (10343/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (88.00%) (11494/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (88.00%) (12622/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (13762/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.3172) |  Loss2: (0.0000) | Acc: (88.00%) (14901/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (88.00%) (16039/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (88.00%) (17183/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.3193) |  Loss2: (0.0000) | Acc: (88.00%) (18302/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.3183) |  Loss2: (0.0000) | Acc: (88.00%) (19447/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (20606/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (88.00%) (21746/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (88.00%) (22883/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (88.00%) (24020/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (88.00%) (25163/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.3134) |  Loss2: (0.0000) | Acc: (88.00%) (26314/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (27468/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (28604/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.3134) |  Loss2: (0.0000) | Acc: (89.00%) (29747/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (89.00%) (30873/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (32016/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (89.00%) (33181/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (34319/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.3129) |  Loss2: (0.0000) | Acc: (89.00%) (35448/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (36590/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (37753/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (38923/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (40056/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (41173/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (42338/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.3098) |  Loss2: (0.0000) | Acc: (89.00%) (43510/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (44621/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_075.pth.tar'
# TEST : Loss: (0.4202) | Acc: (85.00%) (8578/10000)
percent tensor([0.4970, 0.5239, 0.5208, 0.4972, 0.5264, 0.5053, 0.5290, 0.5037, 0.5019,
        0.5181, 0.5057, 0.5295, 0.4973, 0.5093, 0.5170, 0.4967],
       device='cuda:0')
percent tensor([0.4871, 0.4763, 0.4611, 0.4738, 0.4524, 0.4418, 0.4701, 0.4832, 0.5196,
        0.4824, 0.5020, 0.4715, 0.4985, 0.5399, 0.4543, 0.4694],
       device='cuda:0')
percent tensor([0.5859, 0.4979, 0.6242, 0.6146, 0.6363, 0.6314, 0.5573, 0.6148, 0.5800,
        0.5443, 0.5605, 0.5524, 0.5187, 0.5259, 0.5533, 0.5992],
       device='cuda:0')
percent tensor([0.5711, 0.5887, 0.5309, 0.5476, 0.5269, 0.5744, 0.5698, 0.5428, 0.5519,
        0.5835, 0.5810, 0.5550, 0.5817, 0.5849, 0.5772, 0.5765],
       device='cuda:0')
percent tensor([0.4511, 0.5410, 0.6033, 0.6545, 0.5992, 0.5841, 0.5505, 0.4741, 0.6061,
        0.5682, 0.6419, 0.6169, 0.5177, 0.6719, 0.4771, 0.5235],
       device='cuda:0')
percent tensor([0.6185, 0.6270, 0.6430, 0.6565, 0.6418, 0.6316, 0.6406, 0.6184, 0.6419,
        0.6249, 0.6448, 0.6649, 0.6186, 0.6543, 0.6474, 0.6259],
       device='cuda:0')
percent tensor([0.6521, 0.6893, 0.7800, 0.8131, 0.8149, 0.7672, 0.6949, 0.7224, 0.6680,
        0.6901, 0.6792, 0.7115, 0.6369, 0.7087, 0.6157, 0.7007],
       device='cuda:0')
percent tensor([0.9991, 0.9968, 0.9983, 0.9988, 0.9980, 0.9978, 0.9974, 0.9993, 0.9969,
        0.9976, 0.9987, 0.9986, 0.9981, 0.9970, 0.9977, 0.9983],
       device='cuda:0')
Epoch: 76 | Batch_idx: 0 |  Loss: (0.3868) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (1255/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.3023) |  Loss2: (0.0000) | Acc: (89.00%) (2400/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (3554/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (4711/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.2877) |  Loss2: (0.0000) | Acc: (90.00%) (5883/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (7051/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (8223/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (9382/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (10533/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (11672/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (12845/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (13979/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (15149/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (16302/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (90.00%) (17457/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (18613/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (19759/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (90.00%) (20912/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (22089/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (23242/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (24390/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (25532/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (26713/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (27875/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (29025/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (30178/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (31348/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (90.00%) (32509/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (33666/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (34806/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (35964/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (37116/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (38272/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (39432/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (40596/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (41755/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (42914/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (44082/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (45226/50000)
# TEST : Loss: (0.4054) | Acc: (86.00%) (8630/10000)
percent tensor([0.5012, 0.5289, 0.5273, 0.5022, 0.5329, 0.5098, 0.5347, 0.5090, 0.5060,
        0.5230, 0.5095, 0.5354, 0.5012, 0.5135, 0.5218, 0.5007],
       device='cuda:0')
percent tensor([0.4952, 0.4871, 0.4692, 0.4813, 0.4613, 0.4507, 0.4798, 0.4914, 0.5277,
        0.4928, 0.5113, 0.4812, 0.5080, 0.5481, 0.4645, 0.4780],
       device='cuda:0')
percent tensor([0.5883, 0.5026, 0.6272, 0.6158, 0.6376, 0.6351, 0.5594, 0.6132, 0.5808,
        0.5512, 0.5673, 0.5561, 0.5229, 0.5261, 0.5552, 0.6049],
       device='cuda:0')
percent tensor([0.5709, 0.5894, 0.5303, 0.5470, 0.5274, 0.5737, 0.5709, 0.5427, 0.5528,
        0.5849, 0.5823, 0.5561, 0.5829, 0.5854, 0.5775, 0.5766],
       device='cuda:0')
percent tensor([0.4355, 0.5275, 0.5947, 0.6481, 0.5924, 0.5793, 0.5375, 0.4676, 0.5960,
        0.5540, 0.6289, 0.6039, 0.4962, 0.6672, 0.4665, 0.5064],
       device='cuda:0')
percent tensor([0.6223, 0.6312, 0.6536, 0.6681, 0.6556, 0.6437, 0.6466, 0.6288, 0.6495,
        0.6288, 0.6493, 0.6709, 0.6192, 0.6610, 0.6538, 0.6305],
       device='cuda:0')
percent tensor([0.6458, 0.6916, 0.7741, 0.8069, 0.8088, 0.7623, 0.6919, 0.7180, 0.6649,
        0.6911, 0.6775, 0.7037, 0.6402, 0.7045, 0.6102, 0.6940],
       device='cuda:0')
percent tensor([0.9990, 0.9968, 0.9985, 0.9989, 0.9982, 0.9979, 0.9974, 0.9993, 0.9970,
        0.9976, 0.9987, 0.9988, 0.9980, 0.9971, 0.9978, 0.9983],
       device='cuda:0')
Epoch: 77 | Batch_idx: 0 |  Loss: (0.2977) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (1275/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (2416/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.2917) |  Loss2: (0.0000) | Acc: (90.00%) (3576/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (4740/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (5907/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (7048/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (8221/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (9382/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (10547/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (11703/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (12878/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (14038/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (15202/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (16376/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.2747) |  Loss2: (0.0000) | Acc: (90.00%) (17539/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (18714/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (19888/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (21056/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (22204/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (23349/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (24516/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (25683/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (26851/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (27996/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (29170/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (30327/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.2737) |  Loss2: (0.0000) | Acc: (90.00%) (31483/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (32651/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (33819/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (34989/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (36136/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (37319/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (38486/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (39656/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (40814/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (41962/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (43119/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (44275/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (45387/50000)
# TEST : Loss: (0.3977) | Acc: (86.00%) (8630/10000)
percent tensor([0.5022, 0.5307, 0.5296, 0.5041, 0.5352, 0.5110, 0.5368, 0.5111, 0.5073,
        0.5248, 0.5106, 0.5376, 0.5023, 0.5155, 0.5235, 0.5021],
       device='cuda:0')
percent tensor([0.4944, 0.4872, 0.4688, 0.4811, 0.4612, 0.4514, 0.4796, 0.4909, 0.5269,
        0.4927, 0.5106, 0.4809, 0.5073, 0.5477, 0.4648, 0.4777],
       device='cuda:0')
percent tensor([0.5891, 0.4999, 0.6290, 0.6167, 0.6369, 0.6378, 0.5566, 0.6115, 0.5791,
        0.5510, 0.5665, 0.5553, 0.5206, 0.5248, 0.5539, 0.6065],
       device='cuda:0')
percent tensor([0.5696, 0.5890, 0.5287, 0.5457, 0.5266, 0.5728, 0.5702, 0.5415, 0.5523,
        0.5845, 0.5815, 0.5553, 0.5823, 0.5849, 0.5765, 0.5756],
       device='cuda:0')
percent tensor([0.4249, 0.5236, 0.5898, 0.6438, 0.5867, 0.5728, 0.5309, 0.4612, 0.5921,
        0.5502, 0.6272, 0.5994, 0.4904, 0.6669, 0.4592, 0.4958],
       device='cuda:0')
percent tensor([0.6275, 0.6378, 0.6627, 0.6775, 0.6662, 0.6543, 0.6529, 0.6374, 0.6564,
        0.6337, 0.6548, 0.6777, 0.6242, 0.6683, 0.6608, 0.6361],
       device='cuda:0')
percent tensor([0.6502, 0.7021, 0.7795, 0.8127, 0.8139, 0.7690, 0.6996, 0.7222, 0.6701,
        0.6995, 0.6870, 0.7105, 0.6524, 0.7136, 0.6122, 0.6967],
       device='cuda:0')
percent tensor([0.9991, 0.9970, 0.9986, 0.9991, 0.9984, 0.9980, 0.9975, 0.9993, 0.9974,
        0.9978, 0.9988, 0.9989, 0.9980, 0.9974, 0.9979, 0.9983],
       device='cuda:0')
Epoch: 78 | Batch_idx: 0 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (1283/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (2456/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (90.00%) (3609/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (4781/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (5955/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (7119/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2608) |  Loss2: (0.0000) | Acc: (91.00%) (8291/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (91.00%) (9440/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.2656) |  Loss2: (0.0000) | Acc: (90.00%) (10598/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (90.00%) (11750/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (12912/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (14078/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.2682) |  Loss2: (0.0000) | Acc: (90.00%) (15236/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.2671) |  Loss2: (0.0000) | Acc: (90.00%) (16406/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (90.00%) (17555/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (18711/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (19866/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.2694) |  Loss2: (0.0000) | Acc: (90.00%) (21023/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (22205/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (23353/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (24508/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.2705) |  Loss2: (0.0000) | Acc: (90.00%) (25658/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (26824/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.2705) |  Loss2: (0.0000) | Acc: (90.00%) (27996/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (29142/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (30295/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (31464/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (32635/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (33798/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (34949/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (36118/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (37289/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (38464/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (39628/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2711) |  Loss2: (0.0000) | Acc: (90.00%) (40807/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (41977/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2705) |  Loss2: (0.0000) | Acc: (90.00%) (43142/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (44324/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (45442/50000)
# TEST : Loss: (0.3898) | Acc: (86.00%) (8657/10000)
percent tensor([0.5006, 0.5299, 0.5287, 0.5028, 0.5343, 0.5100, 0.5359, 0.5099, 0.5057,
        0.5238, 0.5091, 0.5367, 0.5006, 0.5146, 0.5226, 0.5007],
       device='cuda:0')
percent tensor([0.4964, 0.4906, 0.4726, 0.4844, 0.4650, 0.4546, 0.4830, 0.4945, 0.5297,
        0.4964, 0.5132, 0.4846, 0.5098, 0.5506, 0.4683, 0.4805],
       device='cuda:0')
percent tensor([0.5880, 0.4989, 0.6281, 0.6148, 0.6357, 0.6362, 0.5550, 0.6099, 0.5766,
        0.5500, 0.5641, 0.5536, 0.5192, 0.5231, 0.5520, 0.6053],
       device='cuda:0')
percent tensor([0.5690, 0.5891, 0.5282, 0.5453, 0.5269, 0.5726, 0.5705, 0.5412, 0.5523,
        0.5846, 0.5813, 0.5551, 0.5821, 0.5854, 0.5763, 0.5755],
       device='cuda:0')
percent tensor([0.4212, 0.5225, 0.5888, 0.6450, 0.5865, 0.5743, 0.5286, 0.4599, 0.5928,
        0.5500, 0.6297, 0.5982, 0.4863, 0.6727, 0.4554, 0.4924],
       device='cuda:0')
percent tensor([0.6330, 0.6440, 0.6710, 0.6867, 0.6762, 0.6647, 0.6588, 0.6463, 0.6631,
        0.6384, 0.6606, 0.6836, 0.6287, 0.6752, 0.6671, 0.6420],
       device='cuda:0')
percent tensor([0.6457, 0.7015, 0.7791, 0.8124, 0.8144, 0.7682, 0.6967, 0.7207, 0.6665,
        0.6980, 0.6855, 0.7044, 0.6521, 0.7068, 0.6058, 0.6928],
       device='cuda:0')
percent tensor([0.9991, 0.9971, 0.9987, 0.9991, 0.9984, 0.9981, 0.9977, 0.9994, 0.9975,
        0.9978, 0.9989, 0.9989, 0.9981, 0.9976, 0.9980, 0.9984],
       device='cuda:0')
Epoch: 79 | Batch_idx: 0 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2671) |  Loss2: (0.0000) | Acc: (90.00%) (1275/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (90.00%) (2443/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (90.00%) (3610/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (91.00%) (4784/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (90.00%) (5940/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (7099/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (8260/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2673) |  Loss2: (0.0000) | Acc: (90.00%) (9434/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (10586/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (91.00%) (11767/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (12926/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (90.00%) (14094/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (91.00%) (15278/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2622) |  Loss2: (0.0000) | Acc: (91.00%) (16448/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (91.00%) (17594/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (91.00%) (18759/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (90.00%) (19918/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (91.00%) (21088/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (91.00%) (22253/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (23410/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (91.00%) (24585/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (91.00%) (25751/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (26905/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (91.00%) (28093/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (91.00%) (29255/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (91.00%) (30422/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (91.00%) (31587/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (91.00%) (32755/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (91.00%) (33927/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (91.00%) (35092/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (91.00%) (36265/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (91.00%) (37441/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2629) |  Loss2: (0.0000) | Acc: (91.00%) (38590/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (91.00%) (39747/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (91.00%) (40905/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (91.00%) (42074/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (91.00%) (43249/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (91.00%) (44419/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (91.00%) (45543/50000)
# TEST : Loss: (0.3859) | Acc: (86.00%) (8672/10000)
percent tensor([0.4992, 0.5289, 0.5282, 0.5015, 0.5337, 0.5091, 0.5351, 0.5086, 0.5043,
        0.5228, 0.5076, 0.5361, 0.4991, 0.5132, 0.5217, 0.4993],
       device='cuda:0')
percent tensor([0.4901, 0.4847, 0.4660, 0.4789, 0.4584, 0.4491, 0.4766, 0.4880, 0.5229,
        0.4901, 0.5066, 0.4779, 0.5031, 0.5452, 0.4624, 0.4746],
       device='cuda:0')
percent tensor([0.5889, 0.4995, 0.6277, 0.6141, 0.6334, 0.6355, 0.5548, 0.6089, 0.5766,
        0.5510, 0.5641, 0.5539, 0.5201, 0.5258, 0.5520, 0.6057],
       device='cuda:0')
percent tensor([0.5637, 0.5845, 0.5236, 0.5409, 0.5231, 0.5685, 0.5654, 0.5365, 0.5479,
        0.5799, 0.5765, 0.5502, 0.5767, 0.5812, 0.5713, 0.5707],
       device='cuda:0')
percent tensor([0.4261, 0.5282, 0.5924, 0.6462, 0.5926, 0.5750, 0.5356, 0.4654, 0.5979,
        0.5563, 0.6348, 0.6025, 0.4915, 0.6763, 0.4616, 0.4947],
       device='cuda:0')
percent tensor([0.6330, 0.6447, 0.6739, 0.6892, 0.6801, 0.6681, 0.6595, 0.6489, 0.6646,
        0.6375, 0.6601, 0.6838, 0.6281, 0.6749, 0.6680, 0.6421],
       device='cuda:0')
percent tensor([0.6468, 0.7038, 0.7785, 0.8114, 0.8149, 0.7714, 0.6987, 0.7186, 0.6700,
        0.7000, 0.6879, 0.7016, 0.6553, 0.7090, 0.6023, 0.6935],
       device='cuda:0')
percent tensor([0.9991, 0.9973, 0.9987, 0.9992, 0.9985, 0.9982, 0.9978, 0.9994, 0.9977,
        0.9980, 0.9990, 0.9990, 0.9982, 0.9978, 0.9980, 0.9985],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 80 | Batch_idx: 0 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (1275/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (2438/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (3599/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (4762/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (5911/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (7068/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (8248/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (9398/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (10542/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (11681/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2846) |  Loss2: (0.0000) | Acc: (90.00%) (12832/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (13999/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (15170/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (16345/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (17492/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (18639/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (19794/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (20959/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (22096/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (23238/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (24379/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (25534/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (26690/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (27836/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (28991/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (30151/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (31313/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (32483/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (33655/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (34808/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (35960/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (37106/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (38248/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (39399/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (40550/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (41710/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (42856/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (43981/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (45088/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_080.pth.tar'
# TEST : Loss: (0.4574) | Acc: (85.00%) (8507/10000)
percent tensor([0.5024, 0.5271, 0.5306, 0.4993, 0.5372, 0.5134, 0.5355, 0.5079, 0.5060,
        0.5234, 0.5089, 0.5398, 0.5008, 0.5092, 0.5220, 0.4994],
       device='cuda:0')
percent tensor([0.4870, 0.4867, 0.4554, 0.4791, 0.4532, 0.4433, 0.4757, 0.4847, 0.5231,
        0.4888, 0.5069, 0.4681, 0.5036, 0.5528, 0.4600, 0.4740],
       device='cuda:0')
percent tensor([0.5874, 0.4976, 0.6403, 0.6196, 0.6403, 0.6272, 0.5546, 0.6131, 0.5692,
        0.5577, 0.5603, 0.5652, 0.5154, 0.5120, 0.5494, 0.6010],
       device='cuda:0')
percent tensor([0.5634, 0.5826, 0.5165, 0.5360, 0.5175, 0.5648, 0.5649, 0.5336, 0.5509,
        0.5761, 0.5775, 0.5462, 0.5774, 0.5865, 0.5686, 0.5691],
       device='cuda:0')
percent tensor([0.4095, 0.5402, 0.5846, 0.6444, 0.5892, 0.5789, 0.5353, 0.4607, 0.5716,
        0.5427, 0.6216, 0.5929, 0.4775, 0.6786, 0.4744, 0.4847],
       device='cuda:0')
percent tensor([0.6300, 0.6465, 0.6748, 0.6847, 0.6812, 0.6688, 0.6572, 0.6432, 0.6637,
        0.6346, 0.6596, 0.6864, 0.6268, 0.6761, 0.6701, 0.6420],
       device='cuda:0')
percent tensor([0.6532, 0.7174, 0.7943, 0.8167, 0.8216, 0.7794, 0.7212, 0.7125, 0.6511,
        0.6903, 0.6840, 0.7099, 0.6550, 0.7317, 0.6091, 0.7084],
       device='cuda:0')
percent tensor([0.9990, 0.9978, 0.9990, 0.9991, 0.9988, 0.9978, 0.9978, 0.9991, 0.9967,
        0.9979, 0.9987, 0.9992, 0.9980, 0.9973, 0.9982, 0.9988],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(177.8710, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(809.8076, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(809.2571, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.8726, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(496.2201, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2210.6963, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4281.1021, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1408.0098, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6120.8335, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11964.3125, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3962.7651, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16771.5586, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 81 | Batch_idx: 0 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (1277/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2711) |  Loss2: (0.0000) | Acc: (90.00%) (2435/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (3582/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (4737/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (5885/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (7059/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (8233/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (9400/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (10562/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (11714/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (12876/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (14055/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (15206/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (16368/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2711) |  Loss2: (0.0000) | Acc: (90.00%) (17521/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (18653/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (19813/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (20971/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (22125/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2747) |  Loss2: (0.0000) | Acc: (90.00%) (23282/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (24455/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (25593/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (26739/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (27901/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (29054/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (30185/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2776) |  Loss2: (0.0000) | Acc: (90.00%) (31348/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (32498/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (33656/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (34819/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (35990/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (37163/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (38326/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (39481/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (40632/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (41807/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (42940/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (44088/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (45194/50000)
# TEST : Loss: (0.4515) | Acc: (85.00%) (8546/10000)
percent tensor([0.5003, 0.5274, 0.5291, 0.4993, 0.5344, 0.5112, 0.5354, 0.5081, 0.5046,
        0.5231, 0.5084, 0.5378, 0.4993, 0.5118, 0.5214, 0.4993],
       device='cuda:0')
percent tensor([0.4888, 0.4822, 0.4651, 0.4768, 0.4582, 0.4444, 0.4742, 0.4869, 0.5224,
        0.4894, 0.5053, 0.4764, 0.5010, 0.5410, 0.4567, 0.4702],
       device='cuda:0')
percent tensor([0.5881, 0.5035, 0.6302, 0.6171, 0.6276, 0.6273, 0.5548, 0.6156, 0.5793,
        0.5568, 0.5643, 0.5542, 0.5241, 0.5335, 0.5518, 0.6053],
       device='cuda:0')
percent tensor([0.5651, 0.5811, 0.5247, 0.5389, 0.5242, 0.5668, 0.5645, 0.5376, 0.5475,
        0.5773, 0.5748, 0.5508, 0.5762, 0.5791, 0.5681, 0.5704],
       device='cuda:0')
percent tensor([0.4553, 0.5720, 0.6209, 0.6620, 0.6249, 0.5948, 0.5667, 0.4825, 0.5980,
        0.6023, 0.6568, 0.6373, 0.5137, 0.7005, 0.5007, 0.5179],
       device='cuda:0')
percent tensor([0.6398, 0.6571, 0.6776, 0.6889, 0.6856, 0.6739, 0.6696, 0.6486, 0.6650,
        0.6501, 0.6716, 0.6904, 0.6329, 0.6760, 0.6788, 0.6539],
       device='cuda:0')
percent tensor([0.6537, 0.7206, 0.7914, 0.7885, 0.8059, 0.7678, 0.7034, 0.7313, 0.6501,
        0.6955, 0.6725, 0.6694, 0.6484, 0.6973, 0.6233, 0.7051],
       device='cuda:0')
percent tensor([0.9990, 0.9979, 0.9989, 0.9991, 0.9986, 0.9984, 0.9977, 0.9994, 0.9969,
        0.9982, 0.9989, 0.9986, 0.9981, 0.9980, 0.9988, 0.9989],
       device='cuda:0')
Epoch: 82 | Batch_idx: 0 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (91.00%) (2447/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (3608/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (91.00%) (4787/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (91.00%) (5956/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (7132/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (8301/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (9466/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (10633/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (11800/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (12961/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (14122/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (15290/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2574) |  Loss2: (0.0000) | Acc: (91.00%) (16448/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (91.00%) (17612/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (18785/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (91.00%) (19940/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2607) |  Loss2: (0.0000) | Acc: (91.00%) (21091/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (91.00%) (22263/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (90.00%) (23404/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (24564/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (25706/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (26867/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (28026/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (29192/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (30353/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2668) |  Loss2: (0.0000) | Acc: (90.00%) (31519/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (32686/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (33866/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (35026/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (36206/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (90.00%) (37360/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (90.00%) (38526/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (39701/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (40870/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (42033/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (90.00%) (43186/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (44343/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (90.00%) (45453/50000)
# TEST : Loss: (0.4930) | Acc: (84.00%) (8440/10000)
percent tensor([0.5004, 0.5277, 0.5282, 0.5010, 0.5354, 0.5107, 0.5356, 0.5087, 0.5052,
        0.5231, 0.5084, 0.5383, 0.4999, 0.5131, 0.5216, 0.5001],
       device='cuda:0')
percent tensor([0.4872, 0.4837, 0.4462, 0.4727, 0.4480, 0.4422, 0.4738, 0.4794, 0.5244,
        0.4852, 0.5077, 0.4627, 0.5034, 0.5519, 0.4564, 0.4718],
       device='cuda:0')
percent tensor([0.5882, 0.5010, 0.6393, 0.6139, 0.6375, 0.6265, 0.5544, 0.6182, 0.5796,
        0.5615, 0.5656, 0.5642, 0.5202, 0.5187, 0.5499, 0.6023],
       device='cuda:0')
percent tensor([0.5682, 0.5851, 0.5252, 0.5441, 0.5240, 0.5721, 0.5686, 0.5381, 0.5509,
        0.5771, 0.5771, 0.5497, 0.5782, 0.5851, 0.5726, 0.5718],
       device='cuda:0')
percent tensor([0.4385, 0.5394, 0.5868, 0.6393, 0.6117, 0.5886, 0.5426, 0.4713, 0.6027,
        0.5502, 0.6524, 0.6163, 0.5145, 0.6714, 0.4881, 0.5003],
       device='cuda:0')
percent tensor([0.6350, 0.6443, 0.6674, 0.6796, 0.6778, 0.6711, 0.6598, 0.6405, 0.6652,
        0.6345, 0.6616, 0.6844, 0.6295, 0.6682, 0.6736, 0.6431],
       device='cuda:0')
percent tensor([0.6570, 0.7149, 0.7863, 0.8122, 0.8181, 0.7717, 0.7346, 0.7291, 0.6672,
        0.6924, 0.7008, 0.7122, 0.6605, 0.7110, 0.6131, 0.7039],
       device='cuda:0')
percent tensor([0.9991, 0.9977, 0.9990, 0.9993, 0.9988, 0.9983, 0.9981, 0.9992, 0.9969,
        0.9974, 0.9992, 0.9991, 0.9981, 0.9974, 0.9981, 0.9990],
       device='cuda:0')
Epoch: 83 | Batch_idx: 0 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (1276/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (2446/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (91.00%) (3616/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (91.00%) (4783/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2616) |  Loss2: (0.0000) | Acc: (91.00%) (5965/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (91.00%) (7123/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (91.00%) (8290/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (91.00%) (9466/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (91.00%) (10624/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2629) |  Loss2: (0.0000) | Acc: (91.00%) (11784/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (91.00%) (12939/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (91.00%) (14107/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (91.00%) (15266/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (91.00%) (16425/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (91.00%) (17599/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (91.00%) (18768/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (91.00%) (19928/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2622) |  Loss2: (0.0000) | Acc: (91.00%) (21101/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (91.00%) (22258/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (91.00%) (23425/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (24572/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (91.00%) (25754/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (91.00%) (26916/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2617) |  Loss2: (0.0000) | Acc: (91.00%) (28095/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (91.00%) (29252/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (91.00%) (30402/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (90.00%) (31543/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2622) |  Loss2: (0.0000) | Acc: (90.00%) (32717/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (90.00%) (33860/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (90.00%) (35038/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (90.00%) (36189/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (37349/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (90.00%) (38508/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (39667/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2646) |  Loss2: (0.0000) | Acc: (90.00%) (40832/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (41994/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (43150/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (44303/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (45420/50000)
# TEST : Loss: (0.4818) | Acc: (84.00%) (8451/10000)
percent tensor([0.4998, 0.5275, 0.5264, 0.4992, 0.5334, 0.5120, 0.5343, 0.5067, 0.5039,
        0.5228, 0.5083, 0.5364, 0.4991, 0.5112, 0.5218, 0.4995],
       device='cuda:0')
percent tensor([0.4913, 0.4903, 0.4627, 0.4859, 0.4602, 0.4502, 0.4788, 0.4878, 0.5246,
        0.4960, 0.5091, 0.4757, 0.5077, 0.5540, 0.4644, 0.4767],
       device='cuda:0')
percent tensor([0.5900, 0.5043, 0.6385, 0.6146, 0.6359, 0.6295, 0.5623, 0.6171, 0.5837,
        0.5599, 0.5659, 0.5676, 0.5219, 0.5404, 0.5516, 0.6052],
       device='cuda:0')
percent tensor([0.5659, 0.5834, 0.5244, 0.5430, 0.5234, 0.5679, 0.5643, 0.5388, 0.5490,
        0.5816, 0.5777, 0.5496, 0.5788, 0.5798, 0.5699, 0.5715],
       device='cuda:0')
percent tensor([0.4470, 0.5533, 0.5986, 0.6395, 0.6046, 0.5930, 0.5558, 0.4762, 0.5932,
        0.5723, 0.6627, 0.6314, 0.5155, 0.6791, 0.5018, 0.5140],
       device='cuda:0')
percent tensor([0.6352, 0.6496, 0.6626, 0.6781, 0.6731, 0.6727, 0.6611, 0.6390, 0.6650,
        0.6391, 0.6697, 0.6798, 0.6318, 0.6758, 0.6751, 0.6445],
       device='cuda:0')
percent tensor([0.6591, 0.7092, 0.7864, 0.7988, 0.8062, 0.7559, 0.7124, 0.7214, 0.6480,
        0.6970, 0.6717, 0.7072, 0.6571, 0.7173, 0.6067, 0.6855],
       device='cuda:0')
percent tensor([0.9993, 0.9977, 0.9988, 0.9991, 0.9984, 0.9982, 0.9981, 0.9992, 0.9976,
        0.9981, 0.9991, 0.9988, 0.9984, 0.9974, 0.9979, 0.9989],
       device='cuda:0')
Epoch: 84 | Batch_idx: 0 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2324) |  Loss2: (0.0000) | Acc: (91.00%) (2471/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (3638/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (4804/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (5952/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (7147/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (8325/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (9470/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (10632/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (11807/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (12988/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (14172/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (15338/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (16506/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (17654/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (18843/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (19993/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (21150/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (22328/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (23475/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (24634/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (25782/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (26940/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (28115/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (29277/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (30439/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (31606/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (32764/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (33946/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (35105/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (36263/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (37433/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (38606/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (39799/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (40939/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (42089/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (43258/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (44422/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (45550/50000)
# TEST : Loss: (0.4352) | Acc: (86.00%) (8600/10000)
percent tensor([0.5009, 0.5280, 0.5323, 0.5021, 0.5373, 0.5114, 0.5361, 0.5103, 0.5047,
        0.5247, 0.5079, 0.5405, 0.4999, 0.5109, 0.5220, 0.5002],
       device='cuda:0')
percent tensor([0.4908, 0.4872, 0.4549, 0.4791, 0.4538, 0.4428, 0.4760, 0.4837, 0.5235,
        0.4899, 0.5077, 0.4701, 0.5063, 0.5525, 0.4595, 0.4727],
       device='cuda:0')
percent tensor([0.5854, 0.4961, 0.6342, 0.6123, 0.6353, 0.6324, 0.5553, 0.6152, 0.5789,
        0.5510, 0.5603, 0.5584, 0.5170, 0.5327, 0.5518, 0.6030],
       device='cuda:0')
percent tensor([0.5672, 0.5845, 0.5199, 0.5418, 0.5206, 0.5696, 0.5642, 0.5365, 0.5492,
        0.5791, 0.5764, 0.5474, 0.5796, 0.5827, 0.5706, 0.5712],
       device='cuda:0')
percent tensor([0.4298, 0.5419, 0.5906, 0.6485, 0.5941, 0.5794, 0.5366, 0.4820, 0.5747,
        0.5600, 0.6236, 0.5978, 0.4906, 0.6671, 0.4815, 0.5132],
       device='cuda:0')
percent tensor([0.6350, 0.6472, 0.6686, 0.6771, 0.6779, 0.6666, 0.6586, 0.6471, 0.6647,
        0.6365, 0.6598, 0.6768, 0.6282, 0.6706, 0.6717, 0.6472],
       device='cuda:0')
percent tensor([0.6441, 0.6771, 0.7886, 0.7879, 0.8094, 0.7610, 0.7051, 0.7155, 0.6251,
        0.6748, 0.6500, 0.6852, 0.6217, 0.6914, 0.6105, 0.6893],
       device='cuda:0')
percent tensor([0.9992, 0.9975, 0.9988, 0.9988, 0.9987, 0.9977, 0.9981, 0.9989, 0.9977,
        0.9983, 0.9990, 0.9990, 0.9982, 0.9981, 0.9983, 0.9991],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 85 | Batch_idx: 0 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (90.00%) (1276/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (89.00%) (2415/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (3559/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2896) |  Loss2: (0.0000) | Acc: (89.00%) (4712/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2881) |  Loss2: (0.0000) | Acc: (89.00%) (5870/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (7037/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (8192/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (9337/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (90.00%) (10484/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (11643/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2877) |  Loss2: (0.0000) | Acc: (89.00%) (12782/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2897) |  Loss2: (0.0000) | Acc: (89.00%) (13922/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2905) |  Loss2: (0.0000) | Acc: (89.00%) (15062/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2883) |  Loss2: (0.0000) | Acc: (89.00%) (16227/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (89.00%) (17387/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (18562/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (19736/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (20883/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (22052/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (23201/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (24347/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (25507/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (26671/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (27835/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (28995/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (30140/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (31289/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (32439/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (33573/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (34710/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (35873/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (37032/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (38205/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (39351/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (40514/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (41663/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (42822/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (43988/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (45120/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_085.pth.tar'
# TEST : Loss: (0.4207) | Acc: (86.00%) (8620/10000)
percent tensor([0.4985, 0.5239, 0.5327, 0.4974, 0.5366, 0.5096, 0.5335, 0.5059, 0.5025,
        0.5213, 0.5052, 0.5390, 0.4968, 0.5065, 0.5184, 0.4961],
       device='cuda:0')
percent tensor([0.5020, 0.4985, 0.4648, 0.4862, 0.4643, 0.4596, 0.4870, 0.4929, 0.5310,
        0.5014, 0.5170, 0.4806, 0.5173, 0.5566, 0.4746, 0.4848],
       device='cuda:0')
percent tensor([0.6136, 0.5201, 0.6541, 0.6390, 0.6568, 0.6566, 0.5763, 0.6458, 0.6027,
        0.5747, 0.5816, 0.5774, 0.5454, 0.5542, 0.5759, 0.6296],
       device='cuda:0')
percent tensor([0.6007, 0.6182, 0.5433, 0.5672, 0.5471, 0.5989, 0.5989, 0.5660, 0.5761,
        0.6121, 0.6087, 0.5756, 0.6127, 0.6152, 0.6065, 0.6042],
       device='cuda:0')
percent tensor([0.4057, 0.5439, 0.5769, 0.6219, 0.5791, 0.5518, 0.5253, 0.4656, 0.5751,
        0.5552, 0.6140, 0.5901, 0.4782, 0.6766, 0.4576, 0.4927],
       device='cuda:0')
percent tensor([0.6624, 0.6817, 0.6920, 0.6980, 0.6997, 0.6915, 0.6886, 0.6637, 0.6959,
        0.6684, 0.6923, 0.7076, 0.6611, 0.7051, 0.7021, 0.6723],
       device='cuda:0')
percent tensor([0.6520, 0.6873, 0.8027, 0.8093, 0.8265, 0.7746, 0.7167, 0.7225, 0.6530,
        0.6874, 0.6616, 0.7095, 0.6424, 0.7160, 0.6164, 0.7005],
       device='cuda:0')
percent tensor([0.9988, 0.9972, 0.9988, 0.9989, 0.9989, 0.9975, 0.9981, 0.9990, 0.9974,
        0.9985, 0.9989, 0.9991, 0.9983, 0.9979, 0.9981, 0.9988],
       device='cuda:0')
Epoch: 86 | Batch_idx: 0 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (1267/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (2423/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (3598/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (90.00%) (4773/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (91.00%) (5956/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (7137/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (8286/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (91.00%) (9446/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (91.00%) (10612/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (91.00%) (11786/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2573) |  Loss2: (0.0000) | Acc: (91.00%) (12949/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (14124/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (91.00%) (15278/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (91.00%) (16431/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (17601/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (91.00%) (18761/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (19920/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (90.00%) (21078/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (22231/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (90.00%) (23407/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (90.00%) (24570/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (25719/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2593) |  Loss2: (0.0000) | Acc: (90.00%) (26885/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (90.00%) (28061/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (90.00%) (29230/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2569) |  Loss2: (0.0000) | Acc: (91.00%) (30421/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2565) |  Loss2: (0.0000) | Acc: (91.00%) (31599/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2566) |  Loss2: (0.0000) | Acc: (91.00%) (32759/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (33926/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (91.00%) (35101/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (36294/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (37458/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (38624/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (39783/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (40939/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (42092/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2565) |  Loss2: (0.0000) | Acc: (91.00%) (43262/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (91.00%) (44417/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (91.00%) (45540/50000)
# TEST : Loss: (0.4046) | Acc: (86.00%) (8672/10000)
percent tensor([0.4976, 0.5238, 0.5305, 0.4959, 0.5350, 0.5087, 0.5331, 0.5043, 0.5024,
        0.5208, 0.5055, 0.5379, 0.4963, 0.5067, 0.5181, 0.4956],
       device='cuda:0')
percent tensor([0.5082, 0.5048, 0.4687, 0.4901, 0.4688, 0.4671, 0.4924, 0.4971, 0.5354,
        0.5068, 0.5224, 0.4850, 0.5233, 0.5612, 0.4814, 0.4908],
       device='cuda:0')
percent tensor([0.6148, 0.5199, 0.6577, 0.6410, 0.6599, 0.6576, 0.5761, 0.6498, 0.6026,
        0.5737, 0.5774, 0.5767, 0.5454, 0.5539, 0.5752, 0.6313],
       device='cuda:0')
percent tensor([0.6066, 0.6249, 0.5462, 0.5709, 0.5500, 0.6042, 0.6046, 0.5699, 0.5797,
        0.6175, 0.6133, 0.5795, 0.6192, 0.6201, 0.6132, 0.6099],
       device='cuda:0')
percent tensor([0.4096, 0.5540, 0.5883, 0.6276, 0.5845, 0.5598, 0.5303, 0.4658, 0.5807,
        0.5637, 0.6230, 0.6002, 0.4913, 0.6811, 0.4589, 0.4941],
       device='cuda:0')
percent tensor([0.6673, 0.6906, 0.6923, 0.6989, 0.6981, 0.6963, 0.6939, 0.6620, 0.7011,
        0.6747, 0.7012, 0.7145, 0.6717, 0.7143, 0.7089, 0.6746],
       device='cuda:0')
percent tensor([0.6444, 0.6933, 0.8157, 0.8189, 0.8353, 0.7862, 0.7179, 0.7239, 0.6544,
        0.6896, 0.6663, 0.7178, 0.6426, 0.7224, 0.6151, 0.6966],
       device='cuda:0')
percent tensor([0.9988, 0.9974, 0.9988, 0.9989, 0.9988, 0.9977, 0.9982, 0.9990, 0.9975,
        0.9985, 0.9989, 0.9991, 0.9984, 0.9980, 0.9982, 0.9989],
       device='cuda:0')
Epoch: 87 | Batch_idx: 0 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (90.00%) (2444/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2611) |  Loss2: (0.0000) | Acc: (90.00%) (3610/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2605) |  Loss2: (0.0000) | Acc: (90.00%) (4772/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (5947/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (7118/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (91.00%) (8274/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (9451/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (10620/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (11796/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (12975/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (14135/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (15312/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (16476/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (91.00%) (17662/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (18838/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (19986/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (21151/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (22319/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (23508/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (91.00%) (24682/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (25840/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2505) |  Loss2: (0.0000) | Acc: (91.00%) (27024/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (28191/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (29358/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (30530/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (31716/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (32872/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (34052/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (35231/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (36412/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (37568/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (38745/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (39928/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (41105/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (42275/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (43441/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (44619/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (45751/50000)
# TEST : Loss: (0.4008) | Acc: (86.00%) (8681/10000)
percent tensor([0.4959, 0.5220, 0.5295, 0.4942, 0.5338, 0.5076, 0.5315, 0.5022, 0.5005,
        0.5190, 0.5037, 0.5366, 0.4946, 0.5045, 0.5162, 0.4937],
       device='cuda:0')
percent tensor([0.5068, 0.5032, 0.4639, 0.4861, 0.4645, 0.4650, 0.4900, 0.4930, 0.5334,
        0.5045, 0.5208, 0.4815, 0.5221, 0.5604, 0.4791, 0.4887],
       device='cuda:0')
percent tensor([0.6131, 0.5154, 0.6594, 0.6414, 0.6612, 0.6559, 0.5728, 0.6537, 0.6010,
        0.5698, 0.5705, 0.5743, 0.5412, 0.5528, 0.5714, 0.6294],
       device='cuda:0')
percent tensor([0.6058, 0.6247, 0.5426, 0.5685, 0.5468, 0.6044, 0.6036, 0.5673, 0.5768,
        0.6160, 0.6111, 0.5755, 0.6179, 0.6195, 0.6130, 0.6095],
       device='cuda:0')
percent tensor([0.4082, 0.5543, 0.5955, 0.6307, 0.5916, 0.5620, 0.5340, 0.4669, 0.5810,
        0.5647, 0.6224, 0.6073, 0.4955, 0.6803, 0.4620, 0.4897],
       device='cuda:0')
percent tensor([0.6718, 0.6971, 0.6950, 0.7011, 0.6984, 0.7013, 0.6992, 0.6609, 0.7048,
        0.6799, 0.7077, 0.7202, 0.6795, 0.7214, 0.7148, 0.6770],
       device='cuda:0')
percent tensor([0.6370, 0.6958, 0.8230, 0.8251, 0.8419, 0.7904, 0.7185, 0.7267, 0.6520,
        0.6875, 0.6639, 0.7227, 0.6407, 0.7212, 0.6152, 0.6919],
       device='cuda:0')
percent tensor([0.9988, 0.9976, 0.9989, 0.9989, 0.9989, 0.9978, 0.9982, 0.9990, 0.9976,
        0.9985, 0.9989, 0.9991, 0.9985, 0.9981, 0.9984, 0.9989],
       device='cuda:0')
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2927) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (1291/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (91.00%) (2469/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (3619/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (4789/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (5972/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (7154/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (8342/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (9507/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (10670/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (11830/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (12987/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (14163/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (15319/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (16494/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (17662/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (18833/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (20001/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (21165/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (22340/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (23500/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (24685/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (25857/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (27028/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (28209/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (29382/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (30554/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (31716/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (32902/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (34081/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (35254/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (36423/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (37611/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (38793/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (39958/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (41129/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (42297/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (43464/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (44652/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (45772/50000)
# TEST : Loss: (0.3930) | Acc: (87.00%) (8710/10000)
percent tensor([0.4954, 0.5217, 0.5277, 0.4932, 0.5324, 0.5066, 0.5309, 0.5013, 0.5008,
        0.5187, 0.5041, 0.5357, 0.4944, 0.5048, 0.5157, 0.4935],
       device='cuda:0')
percent tensor([0.5051, 0.5013, 0.4616, 0.4842, 0.4617, 0.4636, 0.4873, 0.4907, 0.5312,
        0.5026, 0.5189, 0.4788, 0.5202, 0.5588, 0.4770, 0.4872],
       device='cuda:0')
percent tensor([0.6065, 0.5095, 0.6565, 0.6340, 0.6577, 0.6485, 0.5661, 0.6481, 0.5963,
        0.5642, 0.5640, 0.5691, 0.5367, 0.5448, 0.5628, 0.6226],
       device='cuda:0')
percent tensor([0.6022, 0.6219, 0.5385, 0.5653, 0.5424, 0.6027, 0.5995, 0.5623, 0.5719,
        0.6120, 0.6068, 0.5704, 0.6143, 0.6163, 0.6097, 0.6062],
       device='cuda:0')
percent tensor([0.4212, 0.5689, 0.6055, 0.6415, 0.6043, 0.5722, 0.5484, 0.4794, 0.5909,
        0.5768, 0.6326, 0.6178, 0.5077, 0.6921, 0.4765, 0.5013],
       device='cuda:0')
percent tensor([0.6662, 0.6934, 0.6889, 0.6966, 0.6917, 0.6988, 0.6939, 0.6515, 0.7002,
        0.6747, 0.7037, 0.7167, 0.6752, 0.7192, 0.7113, 0.6709],
       device='cuda:0')
percent tensor([0.6274, 0.6944, 0.8255, 0.8283, 0.8447, 0.7922, 0.7150, 0.7314, 0.6454,
        0.6812, 0.6534, 0.7179, 0.6269, 0.7152, 0.6143, 0.6853],
       device='cuda:0')
percent tensor([0.9989, 0.9977, 0.9989, 0.9989, 0.9988, 0.9981, 0.9983, 0.9991, 0.9976,
        0.9985, 0.9990, 0.9991, 0.9985, 0.9982, 0.9984, 0.9989],
       device='cuda:0')
Epoch: 89 | Batch_idx: 0 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (92.00%) (2485/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (92.00%) (3677/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (92.00%) (4845/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (92.00%) (6010/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (92.00%) (7191/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (92.00%) (8378/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (9531/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (10701/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (11856/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (13035/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (14222/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (15413/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (92.00%) (16605/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (92.00%) (17793/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (92.00%) (18974/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (20135/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (92.00%) (21323/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (92.00%) (22508/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (92.00%) (23701/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (92.00%) (24870/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (92.00%) (26049/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (92.00%) (27228/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (92.00%) (28397/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (92.00%) (29578/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (92.00%) (30767/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (92.00%) (31948/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (92.00%) (33115/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (92.00%) (34297/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (92.00%) (35480/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (92.00%) (36657/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (92.00%) (37832/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (92.00%) (39000/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (92.00%) (40172/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (92.00%) (41340/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (92.00%) (42532/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (92.00%) (43700/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (92.00%) (44886/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2386) |  Loss2: (0.0000) | Acc: (92.00%) (46024/50000)
# TEST : Loss: (0.3905) | Acc: (87.00%) (8731/10000)
percent tensor([0.4959, 0.5220, 0.5283, 0.4936, 0.5329, 0.5074, 0.5313, 0.5015, 0.5012,
        0.5190, 0.5045, 0.5362, 0.4949, 0.5049, 0.5160, 0.4939],
       device='cuda:0')
percent tensor([0.5078, 0.5040, 0.4621, 0.4852, 0.4633, 0.4663, 0.4896, 0.4921, 0.5333,
        0.5046, 0.5211, 0.4802, 0.5229, 0.5614, 0.4796, 0.4893],
       device='cuda:0')
percent tensor([0.6059, 0.5078, 0.6592, 0.6358, 0.6603, 0.6507, 0.5648, 0.6513, 0.5956,
        0.5626, 0.5604, 0.5670, 0.5341, 0.5439, 0.5618, 0.6230],
       device='cuda:0')
percent tensor([0.5968, 0.6168, 0.5329, 0.5598, 0.5373, 0.5996, 0.5941, 0.5561, 0.5653,
        0.6061, 0.6002, 0.5633, 0.6085, 0.6106, 0.6048, 0.6011],
       device='cuda:0')
percent tensor([0.4068, 0.5576, 0.6039, 0.6396, 0.6033, 0.5676, 0.5391, 0.4765, 0.5837,
        0.5660, 0.6215, 0.6122, 0.4953, 0.6875, 0.4670, 0.4872],
       device='cuda:0')
percent tensor([0.6622, 0.6903, 0.6847, 0.6921, 0.6869, 0.6977, 0.6902, 0.6447, 0.6959,
        0.6704, 0.7009, 0.7137, 0.6722, 0.7168, 0.7087, 0.6654],
       device='cuda:0')
percent tensor([0.6181, 0.6915, 0.8237, 0.8270, 0.8411, 0.7897, 0.7097, 0.7252, 0.6399,
        0.6733, 0.6454, 0.7148, 0.6265, 0.7089, 0.6055, 0.6769],
       device='cuda:0')
percent tensor([0.9989, 0.9978, 0.9989, 0.9990, 0.9989, 0.9980, 0.9983, 0.9991, 0.9976,
        0.9985, 0.9989, 0.9992, 0.9984, 0.9982, 0.9985, 0.9990],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (2473/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (3660/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (92.00%) (4838/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (6003/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (7172/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (8330/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (9509/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (10676/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (11853/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (13019/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (14165/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (15345/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (16514/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (17676/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (18840/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (20026/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (21197/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (22365/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (23511/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (24663/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (25832/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (91.00%) (27000/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (28150/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (29314/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (30502/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (31663/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (32827/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (33993/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (35147/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (36323/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (37498/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (38663/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (39824/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (41009/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (42175/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (43343/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (44496/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (45626/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_090.pth.tar'
# TEST : Loss: (0.4424) | Acc: (85.00%) (8539/10000)
percent tensor([0.4946, 0.5223, 0.5228, 0.4922, 0.5293, 0.5076, 0.5301, 0.4991, 0.4997,
        0.5176, 0.5047, 0.5324, 0.4936, 0.5053, 0.5163, 0.4939],
       device='cuda:0')
percent tensor([0.5085, 0.5041, 0.4687, 0.4884, 0.4678, 0.4633, 0.4929, 0.4966, 0.5364,
        0.5061, 0.5231, 0.4864, 0.5237, 0.5652, 0.4777, 0.4887],
       device='cuda:0')
percent tensor([0.6065, 0.5060, 0.6573, 0.6362, 0.6600, 0.6548, 0.5633, 0.6464, 0.5891,
        0.5588, 0.5576, 0.5542, 0.5235, 0.5382, 0.5683, 0.6262],
       device='cuda:0')
percent tensor([0.5967, 0.6174, 0.5422, 0.5626, 0.5389, 0.5956, 0.5956, 0.5612, 0.5674,
        0.6091, 0.6017, 0.5715, 0.6097, 0.6063, 0.6040, 0.5999],
       device='cuda:0')
percent tensor([0.4141, 0.5379, 0.5897, 0.6286, 0.6029, 0.5973, 0.5247, 0.4498, 0.5663,
        0.5323, 0.6141, 0.6092, 0.4917, 0.6732, 0.4599, 0.4871],
       device='cuda:0')
percent tensor([0.6678, 0.6950, 0.6824, 0.6974, 0.6851, 0.7002, 0.6891, 0.6408, 0.6945,
        0.6759, 0.7047, 0.7229, 0.6846, 0.7105, 0.7059, 0.6690],
       device='cuda:0')
percent tensor([0.6022, 0.6728, 0.8120, 0.8139, 0.8281, 0.7914, 0.6879, 0.7164, 0.6205,
        0.6366, 0.6318, 0.6949, 0.6150, 0.6713, 0.5820, 0.6552],
       device='cuda:0')
percent tensor([0.9988, 0.9980, 0.9987, 0.9992, 0.9982, 0.9986, 0.9982, 0.9991, 0.9977,
        0.9984, 0.9988, 0.9992, 0.9981, 0.9983, 0.9986, 0.9988],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.0038, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(812.3044, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(812.6809, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.1292, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(494.2865, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2217.6458, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4277.5298, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1402.8809, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6131.4238, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11929.1484, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3947.3657, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16703.5195, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 91 | Batch_idx: 0 |  Loss: (0.2989) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (92.00%) (1301/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (2469/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (3640/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (92.00%) (4829/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (92.00%) (6010/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (92.00%) (7187/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (8353/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (9531/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (10690/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (11869/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (13035/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (14191/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (15379/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (16549/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (17726/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (18902/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (20082/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (21247/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (22408/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (23575/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (24749/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (25909/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (27082/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (28240/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (29419/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (30597/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (31761/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (32927/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (34101/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (35258/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (36426/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (37595/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (91.00%) (38762/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (91.00%) (39937/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (41106/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (42289/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (43461/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (44620/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (45745/50000)
# TEST : Loss: (0.4428) | Acc: (86.00%) (8600/10000)
percent tensor([0.4969, 0.5227, 0.5209, 0.4908, 0.5288, 0.5102, 0.5305, 0.4982, 0.5024,
        0.5178, 0.5072, 0.5319, 0.4959, 0.5069, 0.5172, 0.4950],
       device='cuda:0')
percent tensor([0.5052, 0.4986, 0.4688, 0.4924, 0.4672, 0.4610, 0.4864, 0.4980, 0.5328,
        0.5041, 0.5170, 0.4856, 0.5206, 0.5575, 0.4751, 0.4875],
       device='cuda:0')
percent tensor([0.6042, 0.5095, 0.6700, 0.6375, 0.6680, 0.6523, 0.5716, 0.6489, 0.5900,
        0.5665, 0.5582, 0.5741, 0.5278, 0.5413, 0.5652, 0.6235],
       device='cuda:0')
percent tensor([0.5959, 0.6141, 0.5351, 0.5591, 0.5367, 0.5960, 0.5934, 0.5595, 0.5713,
        0.6053, 0.6023, 0.5639, 0.6111, 0.6077, 0.6001, 0.6005],
       device='cuda:0')
percent tensor([0.4277, 0.5599, 0.6043, 0.6485, 0.6283, 0.6117, 0.5543, 0.4763, 0.5737,
        0.5784, 0.6405, 0.6231, 0.5027, 0.6864, 0.4853, 0.4993],
       device='cuda:0')
percent tensor([0.6594, 0.6806, 0.6716, 0.6944, 0.6846, 0.7039, 0.6943, 0.6418, 0.6902,
        0.6616, 0.6911, 0.6996, 0.6739, 0.7119, 0.7026, 0.6651],
       device='cuda:0')
percent tensor([0.6251, 0.6781, 0.8424, 0.8485, 0.8535, 0.7891, 0.6950, 0.7505, 0.5962,
        0.6649, 0.6346, 0.7207, 0.5973, 0.7100, 0.6230, 0.6820],
       device='cuda:0')
percent tensor([0.9992, 0.9985, 0.9990, 0.9992, 0.9987, 0.9981, 0.9984, 0.9993, 0.9980,
        0.9982, 0.9991, 0.9991, 0.9984, 0.9984, 0.9990, 0.9991],
       device='cuda:0')
Epoch: 92 | Batch_idx: 0 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (91.00%) (1288/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (2460/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (3634/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (91.00%) (4828/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (91.00%) (6002/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (91.00%) (7182/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (8348/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (9525/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (91.00%) (10703/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (91.00%) (11880/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (13056/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (91.00%) (14235/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (91.00%) (15403/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (16592/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (91.00%) (17778/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (18936/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (91.00%) (20111/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2336) |  Loss2: (0.0000) | Acc: (91.00%) (21275/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (22446/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (23622/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2340) |  Loss2: (0.0000) | Acc: (91.00%) (24801/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (25976/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (27147/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (28320/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (29479/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (30643/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (91.00%) (31817/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (33012/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (34182/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (35349/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (36549/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (37730/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (38918/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (40080/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (41249/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (42419/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (43596/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (91.00%) (44770/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (45911/50000)
# TEST : Loss: (0.3997) | Acc: (86.00%) (8654/10000)
percent tensor([0.4947, 0.5248, 0.5152, 0.4920, 0.5229, 0.5080, 0.5294, 0.4971, 0.4993,
        0.5168, 0.5062, 0.5267, 0.4948, 0.5118, 0.5175, 0.4950],
       device='cuda:0')
percent tensor([0.5092, 0.4996, 0.4806, 0.4924, 0.4755, 0.4687, 0.4911, 0.5013, 0.5385,
        0.5064, 0.5198, 0.4898, 0.5235, 0.5587, 0.4771, 0.4883],
       device='cuda:0')
percent tensor([0.6069, 0.5125, 0.6622, 0.6288, 0.6669, 0.6558, 0.5690, 0.6456, 0.5971,
        0.5650, 0.5630, 0.5681, 0.5310, 0.5414, 0.5679, 0.6252],
       device='cuda:0')
percent tensor([0.5968, 0.6162, 0.5369, 0.5619, 0.5383, 0.5984, 0.5950, 0.5615, 0.5692,
        0.6074, 0.6034, 0.5667, 0.6134, 0.6086, 0.6026, 0.6036],
       device='cuda:0')
percent tensor([0.3986, 0.5415, 0.5823, 0.6496, 0.5950, 0.5747, 0.5336, 0.4642, 0.5775,
        0.5543, 0.6305, 0.5968, 0.4683, 0.6749, 0.4566, 0.4801],
       device='cuda:0')
percent tensor([0.6549, 0.6846, 0.6727, 0.6941, 0.6794, 0.6971, 0.6885, 0.6339, 0.6846,
        0.6685, 0.6946, 0.7020, 0.6702, 0.7080, 0.7016, 0.6665],
       device='cuda:0')
percent tensor([0.6068, 0.6939, 0.8127, 0.8159, 0.8455, 0.7802, 0.7126, 0.7297, 0.6221,
        0.6696, 0.6462, 0.6956, 0.5877, 0.7025, 0.5882, 0.6841],
       device='cuda:0')
percent tensor([0.9988, 0.9979, 0.9991, 0.9992, 0.9988, 0.9983, 0.9980, 0.9991, 0.9977,
        0.9983, 0.9991, 0.9991, 0.9979, 0.9978, 0.9986, 0.9989],
       device='cuda:0')
Epoch: 93 | Batch_idx: 0 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (2481/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (3672/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (4868/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (6058/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (7249/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (8417/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (9604/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (10790/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (11981/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (13174/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (14358/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (15523/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (16685/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (17866/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (19063/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (20245/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (21413/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (22611/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (23805/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (24961/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (26149/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (27338/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (28499/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (29677/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (30855/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (32030/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (33197/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (34370/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (35543/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (36723/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (37906/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (39069/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (40252/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (41428/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (42602/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (43780/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (44949/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (46085/50000)
# TEST : Loss: (0.4005) | Acc: (86.00%) (8678/10000)
percent tensor([0.4944, 0.5219, 0.5211, 0.4927, 0.5278, 0.5071, 0.5284, 0.4988, 0.4992,
        0.5168, 0.5040, 0.5306, 0.4938, 0.5054, 0.5161, 0.4936],
       device='cuda:0')
percent tensor([0.5065, 0.4993, 0.4701, 0.4852, 0.4686, 0.4628, 0.4877, 0.4967, 0.5343,
        0.5051, 0.5195, 0.4839, 0.5216, 0.5556, 0.4767, 0.4866],
       device='cuda:0')
percent tensor([0.6096, 0.5131, 0.6664, 0.6430, 0.6661, 0.6594, 0.5695, 0.6477, 0.5978,
        0.5632, 0.5610, 0.5730, 0.5296, 0.5448, 0.5705, 0.6289],
       device='cuda:0')
percent tensor([0.5939, 0.6157, 0.5344, 0.5568, 0.5369, 0.5936, 0.5928, 0.5563, 0.5689,
        0.6072, 0.6023, 0.5654, 0.6097, 0.6103, 0.5981, 0.5988],
       device='cuda:0')
percent tensor([0.4352, 0.5626, 0.5956, 0.6452, 0.6075, 0.5976, 0.5559, 0.4791, 0.5738,
        0.5711, 0.6392, 0.6279, 0.5022, 0.6731, 0.4939, 0.5050],
       device='cuda:0')
percent tensor([0.6550, 0.6904, 0.6729, 0.6892, 0.6810, 0.6997, 0.6861, 0.6368, 0.6922,
        0.6663, 0.6978, 0.6956, 0.6811, 0.7108, 0.7032, 0.6656],
       device='cuda:0')
percent tensor([0.6507, 0.7089, 0.8284, 0.8407, 0.8296, 0.8117, 0.7307, 0.7449, 0.6335,
        0.6981, 0.6542, 0.7192, 0.6080, 0.7145, 0.6425, 0.7154],
       device='cuda:0')
percent tensor([0.9991, 0.9978, 0.9992, 0.9992, 0.9988, 0.9988, 0.9981, 0.9992, 0.9976,
        0.9983, 0.9992, 0.9992, 0.9981, 0.9980, 0.9988, 0.9987],
       device='cuda:0')
Epoch: 94 | Batch_idx: 0 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.2340) |  Loss2: (0.0000) | Acc: (92.00%) (1303/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (2471/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (92.00%) (3652/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (4823/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (5995/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (7169/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (8340/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (9522/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (10690/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (11882/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (13066/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (14257/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (15443/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (16640/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (17822/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (19027/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (20203/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (21393/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (22558/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (23728/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (24895/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (26073/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (27254/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (28436/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (29604/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (30787/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (31977/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (33150/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (34338/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (35521/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (36690/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (37875/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (39060/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (40247/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (41424/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (42594/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (43764/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (44946/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (46077/50000)
# TEST : Loss: (0.4094) | Acc: (86.00%) (8677/10000)
percent tensor([0.4937, 0.5242, 0.5187, 0.4946, 0.5260, 0.5060, 0.5296, 0.5002, 0.4990,
        0.5175, 0.5041, 0.5297, 0.4941, 0.5093, 0.5169, 0.4949],
       device='cuda:0')
percent tensor([0.5054, 0.5040, 0.4669, 0.4931, 0.4650, 0.4653, 0.4887, 0.4968, 0.5373,
        0.5049, 0.5223, 0.4815, 0.5231, 0.5699, 0.4778, 0.4899],
       device='cuda:0')
percent tensor([0.6044, 0.5146, 0.6656, 0.6314, 0.6642, 0.6483, 0.5732, 0.6429, 0.6006,
        0.5671, 0.5661, 0.5708, 0.5276, 0.5547, 0.5621, 0.6207],
       device='cuda:0')
percent tensor([0.5938, 0.6112, 0.5378, 0.5626, 0.5362, 0.5960, 0.5903, 0.5586, 0.5667,
        0.6013, 0.5974, 0.5660, 0.6071, 0.6075, 0.5973, 0.6003],
       device='cuda:0')
percent tensor([0.4401, 0.5932, 0.5955, 0.6634, 0.6102, 0.5992, 0.5592, 0.5010, 0.5915,
        0.5923, 0.6692, 0.6170, 0.5358, 0.6915, 0.5008, 0.5153],
       device='cuda:0')
percent tensor([0.6656, 0.6964, 0.6767, 0.6993, 0.6874, 0.6995, 0.6908, 0.6420, 0.6956,
        0.6723, 0.7013, 0.7072, 0.6927, 0.7099, 0.7071, 0.6750],
       device='cuda:0')
percent tensor([0.6293, 0.7196, 0.8287, 0.8287, 0.8464, 0.7777, 0.7302, 0.7662, 0.6479,
        0.6906, 0.6744, 0.7180, 0.6230, 0.7070, 0.6182, 0.6777],
       device='cuda:0')
percent tensor([0.9992, 0.9982, 0.9990, 0.9991, 0.9985, 0.9984, 0.9982, 0.9993, 0.9977,
        0.9985, 0.9992, 0.9992, 0.9984, 0.9980, 0.9986, 0.9989],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 95 | Batch_idx: 0 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (1308/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (2469/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2608) |  Loss2: (0.0000) | Acc: (91.00%) (3632/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (4762/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (5910/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (7057/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (90.00%) (8200/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2907) |  Loss2: (0.0000) | Acc: (90.00%) (9349/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2905) |  Loss2: (0.0000) | Acc: (90.00%) (10501/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2909) |  Loss2: (0.0000) | Acc: (90.00%) (11640/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2959) |  Loss2: (0.0000) | Acc: (89.00%) (12767/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2965) |  Loss2: (0.0000) | Acc: (89.00%) (13909/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2937) |  Loss2: (0.0000) | Acc: (89.00%) (15077/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (16211/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (89.00%) (17383/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (89.00%) (18527/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2910) |  Loss2: (0.0000) | Acc: (89.00%) (19682/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2919) |  Loss2: (0.0000) | Acc: (89.00%) (20824/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (89.00%) (21989/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2880) |  Loss2: (0.0000) | Acc: (90.00%) (23168/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2888) |  Loss2: (0.0000) | Acc: (90.00%) (24310/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (89.00%) (25438/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (89.00%) (26595/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2885) |  Loss2: (0.0000) | Acc: (90.00%) (27768/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2889) |  Loss2: (0.0000) | Acc: (89.00%) (28913/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2888) |  Loss2: (0.0000) | Acc: (89.00%) (30057/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (31211/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2880) |  Loss2: (0.0000) | Acc: (89.00%) (32370/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2870) |  Loss2: (0.0000) | Acc: (90.00%) (33531/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (90.00%) (34695/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2876) |  Loss2: (0.0000) | Acc: (90.00%) (35835/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2872) |  Loss2: (0.0000) | Acc: (90.00%) (36995/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (90.00%) (38140/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (90.00%) (39298/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (40448/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (90.00%) (41618/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (42782/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (43949/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (45061/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_095.pth.tar'
# TEST : Loss: (0.4336) | Acc: (86.00%) (8602/10000)
percent tensor([0.4982, 0.5330, 0.5179, 0.4982, 0.5269, 0.5063, 0.5369, 0.5027, 0.5042,
        0.5233, 0.5104, 0.5329, 0.4994, 0.5220, 0.5218, 0.4993],
       device='cuda:0')
percent tensor([0.5211, 0.5218, 0.4825, 0.5073, 0.4840, 0.4680, 0.5075, 0.5182, 0.5571,
        0.5261, 0.5395, 0.5015, 0.5436, 0.5910, 0.4903, 0.5008],
       device='cuda:0')
percent tensor([0.6224, 0.5086, 0.7048, 0.6699, 0.7083, 0.6717, 0.5896, 0.6930, 0.6231,
        0.5664, 0.5556, 0.5854, 0.5276, 0.5499, 0.5813, 0.6367],
       device='cuda:0')
percent tensor([0.6056, 0.6206, 0.5505, 0.5732, 0.5453, 0.5979, 0.6039, 0.5713, 0.5792,
        0.6123, 0.6105, 0.5826, 0.6218, 0.6191, 0.6077, 0.6078],
       device='cuda:0')
percent tensor([0.4155, 0.5509, 0.5473, 0.6328, 0.5861, 0.5893, 0.5167, 0.4737, 0.5550,
        0.5447, 0.6286, 0.5692, 0.4681, 0.6655, 0.4801, 0.4862],
       device='cuda:0')
percent tensor([0.6609, 0.6914, 0.6629, 0.6839, 0.6681, 0.6866, 0.6801, 0.6210, 0.6949,
        0.6723, 0.6999, 0.7056, 0.6923, 0.7131, 0.7002, 0.6631],
       device='cuda:0')
percent tensor([0.5918, 0.7024, 0.8102, 0.8312, 0.8446, 0.7870, 0.7087, 0.7471, 0.6283,
        0.6609, 0.6278, 0.6892, 0.5782, 0.6993, 0.5911, 0.6599],
       device='cuda:0')
percent tensor([0.9990, 0.9980, 0.9991, 0.9992, 0.9989, 0.9982, 0.9980, 0.9993, 0.9973,
        0.9983, 0.9991, 0.9990, 0.9979, 0.9982, 0.9986, 0.9989],
       device='cuda:0')
Epoch: 96 | Batch_idx: 0 |  Loss: (0.3323) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (89.00%) (1267/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (2430/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (3592/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (4751/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (90.00%) (5915/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (90.00%) (7079/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (8229/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (90.00%) (9391/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (90.00%) (10555/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (11712/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (12860/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2671) |  Loss2: (0.0000) | Acc: (90.00%) (14024/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (90.00%) (15196/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (16362/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (90.00%) (17535/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (90.00%) (18714/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2608) |  Loss2: (0.0000) | Acc: (90.00%) (19882/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (90.00%) (21027/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2604) |  Loss2: (0.0000) | Acc: (90.00%) (22212/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2583) |  Loss2: (0.0000) | Acc: (90.00%) (23400/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (24551/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (90.00%) (25728/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (90.00%) (26895/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2579) |  Loss2: (0.0000) | Acc: (90.00%) (28065/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (90.00%) (29220/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (90.00%) (30400/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (91.00%) (31574/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (91.00%) (32748/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2565) |  Loss2: (0.0000) | Acc: (91.00%) (33912/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (35081/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (36256/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (37418/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (38589/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (39744/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (40909/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (42087/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (43248/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (44415/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (45529/50000)
# TEST : Loss: (0.4091) | Acc: (86.00%) (8680/10000)
percent tensor([0.4966, 0.5309, 0.5155, 0.4955, 0.5243, 0.5040, 0.5346, 0.5002, 0.5029,
        0.5212, 0.5091, 0.5305, 0.4981, 0.5202, 0.5193, 0.4971],
       device='cuda:0')
percent tensor([0.5160, 0.5165, 0.4748, 0.5006, 0.4762, 0.4539, 0.5014, 0.5155, 0.5553,
        0.5206, 0.5346, 0.4965, 0.5420, 0.5901, 0.4811, 0.4919],
       device='cuda:0')
percent tensor([0.6207, 0.4931, 0.7084, 0.6721, 0.7119, 0.6692, 0.5844, 0.7007, 0.6220,
        0.5543, 0.5411, 0.5806, 0.5174, 0.5431, 0.5763, 0.6304],
       device='cuda:0')
percent tensor([0.6106, 0.6254, 0.5529, 0.5758, 0.5465, 0.5987, 0.6086, 0.5740, 0.5840,
        0.6166, 0.6162, 0.5871, 0.6290, 0.6243, 0.6121, 0.6106],
       device='cuda:0')
percent tensor([0.4130, 0.5464, 0.5462, 0.6375, 0.5937, 0.5972, 0.5174, 0.4725, 0.5494,
        0.5404, 0.6280, 0.5612, 0.4544, 0.6685, 0.4831, 0.4892],
       device='cuda:0')
percent tensor([0.6679, 0.7004, 0.6607, 0.6849, 0.6649, 0.6918, 0.6854, 0.6181, 0.7007,
        0.6792, 0.7103, 0.7103, 0.7031, 0.7240, 0.7090, 0.6695],
       device='cuda:0')
percent tensor([0.5935, 0.7079, 0.8102, 0.8330, 0.8423, 0.7899, 0.7048, 0.7331, 0.6247,
        0.6636, 0.6312, 0.6879, 0.5872, 0.7019, 0.5889, 0.6633],
       device='cuda:0')
percent tensor([0.9991, 0.9980, 0.9990, 0.9992, 0.9989, 0.9984, 0.9980, 0.9993, 0.9973,
        0.9983, 0.9990, 0.9990, 0.9978, 0.9982, 0.9986, 0.9989],
       device='cuda:0')
Epoch: 97 | Batch_idx: 0 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (1282/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (90.00%) (2438/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (90.00%) (3607/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (4780/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (5952/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (7110/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (8284/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (9457/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (10626/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (11796/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (12959/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (14134/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (15311/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (16475/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (17640/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (18835/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (20005/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (21174/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (22342/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (23530/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (24690/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (25874/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (27040/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (28230/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (29415/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (30596/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (31755/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (32945/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (34119/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (35285/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (36457/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (37629/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (38809/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (39983/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (41161/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (42345/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (43515/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (44694/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (45827/50000)
# TEST : Loss: (0.4019) | Acc: (86.00%) (8696/10000)
percent tensor([0.4950, 0.5293, 0.5143, 0.4932, 0.5231, 0.5023, 0.5331, 0.4979, 0.5017,
        0.5196, 0.5079, 0.5291, 0.4968, 0.5182, 0.5173, 0.4948],
       device='cuda:0')
percent tensor([0.5148, 0.5145, 0.4705, 0.4976, 0.4722, 0.4483, 0.4990, 0.5147, 0.5563,
        0.5180, 0.5333, 0.4942, 0.5427, 0.5908, 0.4777, 0.4879],
       device='cuda:0')
percent tensor([0.6236, 0.4901, 0.7100, 0.6736, 0.7129, 0.6701, 0.5846, 0.7041, 0.6234,
        0.5521, 0.5386, 0.5793, 0.5175, 0.5439, 0.5773, 0.6294],
       device='cuda:0')
percent tensor([0.6179, 0.6330, 0.5562, 0.5798, 0.5490, 0.6018, 0.6158, 0.5786, 0.5914,
        0.6239, 0.6254, 0.5943, 0.6389, 0.6325, 0.6189, 0.6163],
       device='cuda:0')
percent tensor([0.4162, 0.5604, 0.5430, 0.6349, 0.5900, 0.6019, 0.5235, 0.4631, 0.5551,
        0.5542, 0.6426, 0.5636, 0.4630, 0.6853, 0.4852, 0.4970],
       device='cuda:0')
percent tensor([0.6708, 0.7052, 0.6577, 0.6820, 0.6600, 0.6928, 0.6874, 0.6120, 0.7036,
        0.6824, 0.7165, 0.7115, 0.7104, 0.7287, 0.7126, 0.6717],
       device='cuda:0')
percent tensor([0.5974, 0.7134, 0.8115, 0.8331, 0.8411, 0.7911, 0.7057, 0.7274, 0.6275,
        0.6730, 0.6412, 0.6901, 0.5921, 0.7054, 0.5924, 0.6658],
       device='cuda:0')
percent tensor([0.9991, 0.9982, 0.9990, 0.9991, 0.9988, 0.9985, 0.9981, 0.9992, 0.9976,
        0.9984, 0.9992, 0.9990, 0.9981, 0.9984, 0.9986, 0.9989],
       device='cuda:0')
Epoch: 98 | Batch_idx: 0 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (2481/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (3661/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (4835/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (6019/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (7194/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (8366/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (9541/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (10720/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (11900/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (13095/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (14258/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (92.00%) (15439/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (16607/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (91.00%) (17778/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (91.00%) (18943/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (91.00%) (20125/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (91.00%) (21307/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (91.00%) (22481/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (23681/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (24856/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (26052/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (27233/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (28407/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (29574/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (30744/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (31930/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (33098/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (34289/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (35463/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (36650/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (37823/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (39005/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (40182/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (41366/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (42548/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (43723/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (44896/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (46040/50000)
# TEST : Loss: (0.3938) | Acc: (87.00%) (8721/10000)
percent tensor([0.4949, 0.5292, 0.5139, 0.4929, 0.5230, 0.5018, 0.5330, 0.4980, 0.5020,
        0.5197, 0.5083, 0.5291, 0.4971, 0.5177, 0.5171, 0.4946],
       device='cuda:0')
percent tensor([0.5147, 0.5137, 0.4708, 0.4977, 0.4718, 0.4448, 0.4984, 0.5158, 0.5571,
        0.5180, 0.5331, 0.4949, 0.5437, 0.5901, 0.4758, 0.4866],
       device='cuda:0')
percent tensor([0.6299, 0.4914, 0.7140, 0.6772, 0.7156, 0.6731, 0.5881, 0.7075, 0.6279,
        0.5542, 0.5425, 0.5824, 0.5221, 0.5463, 0.5815, 0.6330],
       device='cuda:0')
percent tensor([0.6168, 0.6323, 0.5547, 0.5782, 0.5467, 0.6001, 0.6149, 0.5762, 0.5904,
        0.6230, 0.6249, 0.5934, 0.6397, 0.6316, 0.6178, 0.6151],
       device='cuda:0')
percent tensor([0.4153, 0.5576, 0.5436, 0.6359, 0.5899, 0.5973, 0.5269, 0.4682, 0.5549,
        0.5532, 0.6432, 0.5633, 0.4569, 0.6854, 0.4890, 0.4939],
       device='cuda:0')
percent tensor([0.6727, 0.7082, 0.6551, 0.6806, 0.6564, 0.6940, 0.6893, 0.6096, 0.7062,
        0.6847, 0.7212, 0.7122, 0.7141, 0.7336, 0.7156, 0.6726],
       device='cuda:0')
percent tensor([0.5990, 0.7164, 0.8120, 0.8334, 0.8407, 0.7911, 0.7040, 0.7229, 0.6266,
        0.6727, 0.6415, 0.6886, 0.5938, 0.7039, 0.5889, 0.6688],
       device='cuda:0')
percent tensor([0.9991, 0.9982, 0.9990, 0.9992, 0.9988, 0.9984, 0.9981, 0.9992, 0.9975,
        0.9984, 0.9991, 0.9991, 0.9980, 0.9983, 0.9987, 0.9989],
       device='cuda:0')
Epoch: 99 | Batch_idx: 0 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (1297/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (2484/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (3666/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (4836/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (6028/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (7217/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (8388/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (9583/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (10755/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (11934/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (13116/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (14293/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (15472/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (16636/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (17821/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (19009/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (20202/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (21369/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2244) |  Loss2: (0.0000) | Acc: (92.00%) (22553/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (23734/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (24930/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (26113/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (27295/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (28467/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (29658/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (30841/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (32008/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (33202/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (34405/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (35582/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (36763/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (37931/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (39094/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (40271/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (41445/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (42630/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (43816/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (44994/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (46138/50000)
# TEST : Loss: (0.3877) | Acc: (87.00%) (8745/10000)
percent tensor([0.4949, 0.5283, 0.5139, 0.4921, 0.5228, 0.5016, 0.5323, 0.4972, 0.5021,
        0.5191, 0.5082, 0.5287, 0.4972, 0.5166, 0.5162, 0.4941],
       device='cuda:0')
percent tensor([0.5181, 0.5163, 0.4727, 0.5007, 0.4737, 0.4484, 0.5009, 0.5189, 0.5595,
        0.5198, 0.5362, 0.4969, 0.5468, 0.5923, 0.4791, 0.4899],
       device='cuda:0')
percent tensor([0.6275, 0.4858, 0.7094, 0.6721, 0.7120, 0.6700, 0.5847, 0.7044, 0.6242,
        0.5489, 0.5382, 0.5757, 0.5180, 0.5439, 0.5779, 0.6293],
       device='cuda:0')
percent tensor([0.6138, 0.6304, 0.5499, 0.5741, 0.5414, 0.5969, 0.6118, 0.5713, 0.5869,
        0.6201, 0.6232, 0.5898, 0.6383, 0.6292, 0.6150, 0.6120],
       device='cuda:0')
percent tensor([0.4178, 0.5650, 0.5449, 0.6354, 0.5878, 0.5932, 0.5321, 0.4698, 0.5613,
        0.5611, 0.6517, 0.5693, 0.4668, 0.6916, 0.4933, 0.4955],
       device='cuda:0')
percent tensor([0.6775, 0.7136, 0.6561, 0.6814, 0.6558, 0.6967, 0.6929, 0.6077, 0.7110,
        0.6893, 0.7284, 0.7159, 0.7214, 0.7391, 0.7213, 0.6760],
       device='cuda:0')
percent tensor([0.5970, 0.7195, 0.8130, 0.8316, 0.8409, 0.7865, 0.7053, 0.7238, 0.6290,
        0.6784, 0.6428, 0.6917, 0.5894, 0.6987, 0.5899, 0.6669],
       device='cuda:0')
percent tensor([0.9992, 0.9983, 0.9990, 0.9992, 0.9988, 0.9984, 0.9982, 0.9993, 0.9976,
        0.9985, 0.9992, 0.9991, 0.9981, 0.9984, 0.9987, 0.9989],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 100 | Batch_idx: 0 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2129) |  Loss2: (0.0000) | Acc: (92.00%) (1307/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (2485/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (3661/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (4831/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (6010/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (7201/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (8374/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (9546/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (10720/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (11902/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (13090/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2281) |  Loss2: (0.0000) | Acc: (92.00%) (14274/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (15458/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (16638/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (17797/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (18963/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (92.00%) (20139/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (21307/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (92.00%) (22495/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (91.00%) (23657/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (91.00%) (24828/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (91.00%) (26007/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (91.00%) (27186/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (28371/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (29534/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2336) |  Loss2: (0.0000) | Acc: (91.00%) (30692/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (31851/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (91.00%) (33025/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (34192/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (35353/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (36534/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (37712/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (38900/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (40072/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (91.00%) (41259/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (42444/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (43634/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (44800/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (45925/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_100.pth.tar'
# TEST : Loss: (0.4348) | Acc: (85.00%) (8565/10000)
percent tensor([0.4972, 0.5279, 0.5143, 0.4923, 0.5237, 0.5059, 0.5319, 0.4974, 0.5041,
        0.5191, 0.5111, 0.5277, 0.4997, 0.5143, 0.5176, 0.4961],
       device='cuda:0')
percent tensor([0.5184, 0.5118, 0.4818, 0.5009, 0.4832, 0.4561, 0.5005, 0.5167, 0.5624,
        0.5144, 0.5306, 0.5027, 0.5445, 0.5825, 0.4804, 0.4902],
       device='cuda:0')
percent tensor([0.6273, 0.4902, 0.7037, 0.6667, 0.7021, 0.6657, 0.5858, 0.7003, 0.6162,
        0.5547, 0.5484, 0.5800, 0.5186, 0.5430, 0.5809, 0.6298],
       device='cuda:0')
percent tensor([0.6165, 0.6327, 0.5511, 0.5743, 0.5435, 0.6043, 0.6121, 0.5710, 0.5854,
        0.6232, 0.6281, 0.5908, 0.6394, 0.6312, 0.6189, 0.6146],
       device='cuda:0')
percent tensor([0.4294, 0.5682, 0.5652, 0.6494, 0.5988, 0.6145, 0.5369, 0.4639, 0.5873,
        0.5695, 0.6410, 0.6011, 0.4891, 0.6904, 0.4985, 0.5071],
       device='cuda:0')
percent tensor([0.6717, 0.7087, 0.6560, 0.6914, 0.6585, 0.7155, 0.6993, 0.6170, 0.7020,
        0.6791, 0.7139, 0.7147, 0.7017, 0.7379, 0.7182, 0.6807],
       device='cuda:0')
percent tensor([0.6101, 0.7416, 0.8008, 0.8215, 0.8199, 0.7891, 0.6990, 0.7098, 0.6427,
        0.7014, 0.6772, 0.6881, 0.5935, 0.7080, 0.6065, 0.6606],
       device='cuda:0')
percent tensor([0.9990, 0.9984, 0.9991, 0.9993, 0.9989, 0.9983, 0.9980, 0.9992, 0.9979,
        0.9987, 0.9992, 0.9991, 0.9983, 0.9982, 0.9984, 0.9984],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.0750, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(814.5826, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(815.9401, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1520.4747, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(492.4984, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2224.5547, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4275.0337, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1397.8960, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6142.9141, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11894.6660, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3932.0730, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16636.0176, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 101 | Batch_idx: 0 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (2494/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (93.00%) (3693/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (4876/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (6067/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (7246/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (8428/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (9619/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (10794/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (11968/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (13145/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (14331/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (15516/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (16716/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (17898/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (19091/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (20262/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (21459/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (22644/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (23811/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (24991/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (26161/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (27338/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (28508/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (29691/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (30873/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (32043/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (33242/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (34419/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (35600/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (36788/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (37958/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (39144/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (40327/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (41506/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (42695/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (43870/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (45041/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (46176/50000)
# TEST : Loss: (0.4661) | Acc: (85.00%) (8513/10000)
percent tensor([0.4981, 0.5251, 0.5221, 0.4940, 0.5293, 0.5052, 0.5312, 0.5008, 0.5041,
        0.5196, 0.5093, 0.5319, 0.4993, 0.5082, 0.5167, 0.4953],
       device='cuda:0')
percent tensor([0.5223, 0.5127, 0.4773, 0.4989, 0.4831, 0.4606, 0.5030, 0.5161, 0.5633,
        0.5179, 0.5387, 0.5004, 0.5470, 0.5834, 0.4861, 0.4945],
       device='cuda:0')
percent tensor([0.6359, 0.5000, 0.6988, 0.6665, 0.7002, 0.6754, 0.5879, 0.7000, 0.6284,
        0.5596, 0.5567, 0.5753, 0.5303, 0.5673, 0.5846, 0.6352],
       device='cuda:0')
percent tensor([0.6120, 0.6279, 0.5521, 0.5737, 0.5467, 0.6070, 0.6094, 0.5672, 0.5829,
        0.6171, 0.6217, 0.5884, 0.6345, 0.6151, 0.6170, 0.6137],
       device='cuda:0')
percent tensor([0.4216, 0.5532, 0.5884, 0.6398, 0.6071, 0.5980, 0.5240, 0.4508, 0.5877,
        0.5667, 0.6367, 0.6083, 0.4718, 0.6478, 0.4907, 0.4951],
       device='cuda:0')
percent tensor([0.6695, 0.6966, 0.6690, 0.6887, 0.6649, 0.6974, 0.6888, 0.6120, 0.6966,
        0.6815, 0.7082, 0.7168, 0.6970, 0.7106, 0.7130, 0.6759],
       device='cuda:0')
percent tensor([0.6316, 0.7160, 0.8134, 0.8104, 0.8283, 0.8013, 0.7078, 0.6995, 0.6473,
        0.7049, 0.6936, 0.7104, 0.6114, 0.7011, 0.6037, 0.6770],
       device='cuda:0')
percent tensor([0.9993, 0.9982, 0.9988, 0.9991, 0.9986, 0.9976, 0.9984, 0.9992, 0.9979,
        0.9987, 0.9993, 0.9992, 0.9984, 0.9985, 0.9988, 0.9990],
       device='cuda:0')
Epoch: 102 | Batch_idx: 0 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (1307/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (2491/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (3677/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (93.00%) (4884/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (93.00%) (6076/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (93.00%) (7280/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (93.00%) (8461/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2113) |  Loss2: (0.0000) | Acc: (93.00%) (9654/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (93.00%) (10841/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (93.00%) (12044/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (93.00%) (13232/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (93.00%) (14413/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (15591/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (16762/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (17954/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (19140/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (20332/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (21511/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (22711/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (23901/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (25080/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (26268/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (27453/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (28626/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (29814/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (30993/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (32173/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (33355/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (34527/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (92.00%) (35721/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (36899/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (38085/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (39282/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (92.00%) (40470/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (41648/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (42843/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (44018/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (45217/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (46352/50000)
# TEST : Loss: (0.4327) | Acc: (86.00%) (8602/10000)
percent tensor([0.4984, 0.5261, 0.5198, 0.4917, 0.5289, 0.5089, 0.5316, 0.4987, 0.5044,
        0.5192, 0.5108, 0.5309, 0.4993, 0.5091, 0.5182, 0.4959],
       device='cuda:0')
percent tensor([0.5238, 0.5156, 0.4751, 0.5031, 0.4740, 0.4525, 0.5020, 0.5182, 0.5578,
        0.5176, 0.5340, 0.4960, 0.5466, 0.5847, 0.4834, 0.4938],
       device='cuda:0')
percent tensor([0.6303, 0.4952, 0.6932, 0.6621, 0.6937, 0.6750, 0.5884, 0.6884, 0.6196,
        0.5557, 0.5549, 0.5750, 0.5221, 0.5574, 0.5840, 0.6352],
       device='cuda:0')
percent tensor([0.6120, 0.6325, 0.5517, 0.5710, 0.5441, 0.6046, 0.6095, 0.5688, 0.5851,
        0.6231, 0.6246, 0.5902, 0.6347, 0.6247, 0.6175, 0.6148],
       device='cuda:0')
percent tensor([0.4168, 0.5558, 0.6031, 0.6470, 0.6167, 0.5821, 0.5424, 0.4719, 0.5869,
        0.5807, 0.6363, 0.6372, 0.4850, 0.6843, 0.4678, 0.4835],
       device='cuda:0')
percent tensor([0.6726, 0.7004, 0.6731, 0.6932, 0.6645, 0.7012, 0.6916, 0.6219, 0.7027,
        0.6850, 0.7239, 0.7205, 0.7052, 0.7318, 0.7138, 0.6718],
       device='cuda:0')
percent tensor([0.6127, 0.7109, 0.8048, 0.8003, 0.8196, 0.7780, 0.7087, 0.6861, 0.6340,
        0.6714, 0.6755, 0.6850, 0.5853, 0.6802, 0.5852, 0.6607],
       device='cuda:0')
percent tensor([0.9990, 0.9979, 0.9987, 0.9991, 0.9986, 0.9978, 0.9976, 0.9992, 0.9976,
        0.9985, 0.9991, 0.9993, 0.9981, 0.9982, 0.9987, 0.9985],
       device='cuda:0')
Epoch: 103 | Batch_idx: 0 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (1310/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (2484/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (3668/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (4841/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (6032/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (7234/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.2133) |  Loss2: (0.0000) | Acc: (92.00%) (8407/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (9591/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (10782/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (11967/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (13148/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (14335/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (15522/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (16697/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (17896/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (19082/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (20262/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (21451/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (22626/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2128) |  Loss2: (0.0000) | Acc: (92.00%) (23794/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (24991/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (26202/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (27372/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (28572/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (29751/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (30926/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (32108/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (33281/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (34479/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (35655/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2113) |  Loss2: (0.0000) | Acc: (92.00%) (36871/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (38057/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (39246/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (40427/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (41627/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (42811/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (43990/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (45188/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (46324/50000)
# TEST : Loss: (0.4024) | Acc: (87.00%) (8710/10000)
percent tensor([0.4974, 0.5264, 0.5174, 0.4917, 0.5264, 0.5071, 0.5316, 0.4986, 0.5044,
        0.5190, 0.5104, 0.5294, 0.4996, 0.5107, 0.5175, 0.4959],
       device='cuda:0')
percent tensor([0.5195, 0.5137, 0.4702, 0.4996, 0.4738, 0.4597, 0.4999, 0.5088, 0.5546,
        0.5116, 0.5299, 0.4913, 0.5382, 0.5841, 0.4835, 0.4932],
       device='cuda:0')
percent tensor([0.6306, 0.4878, 0.7026, 0.6655, 0.7032, 0.6782, 0.5838, 0.6900, 0.6135,
        0.5572, 0.5507, 0.5807, 0.5177, 0.5457, 0.5793, 0.6342],
       device='cuda:0')
percent tensor([0.6101, 0.6354, 0.5418, 0.5676, 0.5363, 0.5968, 0.6121, 0.5633, 0.5867,
        0.6228, 0.6250, 0.5843, 0.6376, 0.6327, 0.6135, 0.6133],
       device='cuda:0')
percent tensor([0.4273, 0.5639, 0.5863, 0.6428, 0.6146, 0.6135, 0.5484, 0.4820, 0.5832,
        0.5787, 0.6377, 0.6226, 0.5174, 0.6872, 0.4952, 0.5040],
       device='cuda:0')
percent tensor([0.6792, 0.7061, 0.6675, 0.6894, 0.6641, 0.7015, 0.6950, 0.6253, 0.7045,
        0.6893, 0.7166, 0.7217, 0.7145, 0.7384, 0.7211, 0.6802],
       device='cuda:0')
percent tensor([0.6109, 0.7338, 0.8056, 0.8111, 0.8245, 0.7758, 0.7073, 0.7164, 0.6344,
        0.6753, 0.6873, 0.6679, 0.5917, 0.6944, 0.6034, 0.6651],
       device='cuda:0')
percent tensor([0.9992, 0.9979, 0.9988, 0.9992, 0.9986, 0.9984, 0.9982, 0.9991, 0.9977,
        0.9983, 0.9994, 0.9991, 0.9980, 0.9983, 0.9989, 0.9989],
       device='cuda:0')
Epoch: 104 | Batch_idx: 0 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (93.00%) (3705/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (4911/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (93.00%) (6093/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (93.00%) (7276/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (93.00%) (8466/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (93.00%) (9672/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (93.00%) (10858/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (93.00%) (12047/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (93.00%) (13250/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.2048) |  Loss2: (0.0000) | Acc: (93.00%) (14442/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (93.00%) (15645/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (16833/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (18029/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (19234/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (20435/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.1977) |  Loss2: (0.0000) | Acc: (93.00%) (21634/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (22829/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (24009/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (25200/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (26372/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (27563/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (28741/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (29939/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (31128/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (32308/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (33497/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (93.00%) (34679/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (93.00%) (35857/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (93.00%) (37050/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (93.00%) (38239/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (93.00%) (39417/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (93.00%) (40606/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (92.00%) (41773/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (42956/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.2048) |  Loss2: (0.0000) | Acc: (92.00%) (44127/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (45338/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (46495/50000)
# TEST : Loss: (0.4326) | Acc: (86.00%) (8615/10000)
percent tensor([0.4985, 0.5264, 0.5201, 0.4920, 0.5287, 0.5086, 0.5325, 0.4980, 0.5043,
        0.5196, 0.5105, 0.5314, 0.4999, 0.5104, 0.5177, 0.4958],
       device='cuda:0')
percent tensor([0.5239, 0.5136, 0.4815, 0.4979, 0.4820, 0.4564, 0.5058, 0.5168, 0.5604,
        0.5179, 0.5304, 0.5072, 0.5436, 0.5858, 0.4815, 0.4908],
       device='cuda:0')
percent tensor([0.6321, 0.4976, 0.6920, 0.6679, 0.6983, 0.6728, 0.5859, 0.6959, 0.6270,
        0.5620, 0.5670, 0.5649, 0.5248, 0.5494, 0.5852, 0.6377],
       device='cuda:0')
percent tensor([0.6145, 0.6292, 0.5559, 0.5742, 0.5485, 0.6034, 0.6119, 0.5676, 0.5809,
        0.6221, 0.6213, 0.5969, 0.6392, 0.6217, 0.6164, 0.6157],
       device='cuda:0')
percent tensor([0.4295, 0.5564, 0.5803, 0.6324, 0.5903, 0.6027, 0.5342, 0.4628, 0.5878,
        0.5625, 0.6241, 0.6150, 0.4929, 0.6865, 0.4872, 0.4997],
       device='cuda:0')
percent tensor([0.6834, 0.7044, 0.6790, 0.6906, 0.6706, 0.7033, 0.6956, 0.6244, 0.6988,
        0.6886, 0.7217, 0.7267, 0.7105, 0.7309, 0.7202, 0.6788],
       device='cuda:0')
percent tensor([0.6185, 0.7331, 0.7989, 0.8031, 0.8058, 0.7925, 0.7020, 0.7008, 0.6601,
        0.6883, 0.6949, 0.6635, 0.5989, 0.7105, 0.6097, 0.6844],
       device='cuda:0')
percent tensor([0.9992, 0.9983, 0.9990, 0.9991, 0.9983, 0.9975, 0.9980, 0.9992, 0.9980,
        0.9985, 0.9992, 0.9993, 0.9980, 0.9982, 0.9987, 0.9988],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 105 | Batch_idx: 0 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (91.00%) (1292/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (2474/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (91.00%) (3639/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (4802/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (5961/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (7123/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (91.00%) (8274/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (90.00%) (9434/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (90.00%) (10577/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (90.00%) (11763/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (90.00%) (12923/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (14103/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (15267/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (16438/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (90.00%) (17586/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (18757/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (19940/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (21116/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (22302/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (23476/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (24656/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (25818/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (26997/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (28176/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (29347/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (30518/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (31691/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (32876/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (34047/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (35212/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (36393/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (37566/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (38756/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (39942/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (41118/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (42303/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (43480/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (44665/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (45798/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_105.pth.tar'
# TEST : Loss: (0.4072) | Acc: (86.00%) (8694/10000)
percent tensor([0.5025, 0.5311, 0.5258, 0.4973, 0.5345, 0.5123, 0.5383, 0.5039, 0.5100,
        0.5249, 0.5155, 0.5376, 0.5039, 0.5160, 0.5225, 0.5003],
       device='cuda:0')
percent tensor([0.5307, 0.5194, 0.4899, 0.5046, 0.4863, 0.4625, 0.5107, 0.5232, 0.5628,
        0.5249, 0.5352, 0.5122, 0.5492, 0.5875, 0.4884, 0.4990],
       device='cuda:0')
percent tensor([0.6025, 0.4736, 0.6596, 0.6445, 0.6630, 0.6452, 0.5489, 0.6746, 0.5932,
        0.5291, 0.5323, 0.5237, 0.4920, 0.5277, 0.5542, 0.6095],
       device='cuda:0')
percent tensor([0.6221, 0.6338, 0.5735, 0.5838, 0.5658, 0.6160, 0.6229, 0.5747, 0.5892,
        0.6302, 0.6286, 0.6146, 0.6432, 0.6257, 0.6242, 0.6224],
       device='cuda:0')
percent tensor([0.4315, 0.5466, 0.5537, 0.6147, 0.5610, 0.5832, 0.5183, 0.4511, 0.5863,
        0.5626, 0.6093, 0.5908, 0.5021, 0.6853, 0.4840, 0.4931],
       device='cuda:0')
percent tensor([0.6716, 0.6893, 0.6668, 0.6720, 0.6597, 0.6920, 0.6821, 0.6010, 0.6840,
        0.6787, 0.7054, 0.7205, 0.7002, 0.7160, 0.7044, 0.6630],
       device='cuda:0')
percent tensor([0.5776, 0.7012, 0.7724, 0.7763, 0.7865, 0.7591, 0.6669, 0.6858, 0.6203,
        0.6612, 0.6420, 0.6143, 0.5564, 0.6707, 0.5986, 0.6421],
       device='cuda:0')
percent tensor([0.9993, 0.9983, 0.9991, 0.9992, 0.9986, 0.9977, 0.9979, 0.9993, 0.9981,
        0.9987, 0.9992, 0.9994, 0.9980, 0.9980, 0.9987, 0.9990],
       device='cuda:0')
Epoch: 106 | Batch_idx: 0 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (1305/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (93.00%) (2507/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (3686/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (4859/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (6038/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (92.00%) (7202/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (8388/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (92.00%) (9569/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2264) |  Loss2: (0.0000) | Acc: (92.00%) (10750/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (11936/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (92.00%) (13095/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (14283/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (15466/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (16660/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (17858/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (19041/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (20248/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (21428/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (22600/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (23777/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (24964/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (26139/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (27326/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (28509/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (29690/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (30869/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (32053/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (33240/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (34435/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (35612/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (36787/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (37970/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (39165/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (40345/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (41525/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (42709/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (43903/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (45078/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (46236/50000)
# TEST : Loss: (0.3972) | Acc: (87.00%) (8732/10000)
percent tensor([0.5020, 0.5307, 0.5246, 0.4965, 0.5333, 0.5124, 0.5376, 0.5030, 0.5096,
        0.5242, 0.5152, 0.5363, 0.5032, 0.5161, 0.5221, 0.5000],
       device='cuda:0')
percent tensor([0.5314, 0.5220, 0.4900, 0.5056, 0.4869, 0.4651, 0.5117, 0.5233, 0.5625,
        0.5271, 0.5362, 0.5115, 0.5491, 0.5910, 0.4895, 0.5018],
       device='cuda:0')
percent tensor([0.6061, 0.4813, 0.6626, 0.6480, 0.6646, 0.6444, 0.5545, 0.6747, 0.5982,
        0.5359, 0.5367, 0.5335, 0.4997, 0.5359, 0.5576, 0.6123],
       device='cuda:0')
percent tensor([0.6189, 0.6330, 0.5685, 0.5832, 0.5616, 0.6136, 0.6213, 0.5732, 0.5871,
        0.6297, 0.6271, 0.6115, 0.6396, 0.6268, 0.6227, 0.6214],
       device='cuda:0')
percent tensor([0.4530, 0.5580, 0.5705, 0.6270, 0.5788, 0.6007, 0.5338, 0.4639, 0.6035,
        0.5766, 0.6248, 0.6116, 0.5213, 0.6978, 0.5022, 0.5072],
       device='cuda:0')
percent tensor([0.6849, 0.7055, 0.6718, 0.6771, 0.6681, 0.7015, 0.6971, 0.6107, 0.6966,
        0.6940, 0.7192, 0.7291, 0.7153, 0.7306, 0.7172, 0.6764],
       device='cuda:0')
percent tensor([0.6037, 0.7104, 0.7894, 0.7904, 0.8023, 0.7612, 0.6808, 0.7125, 0.6381,
        0.6703, 0.6614, 0.6498, 0.5734, 0.6785, 0.6312, 0.6504],
       device='cuda:0')
percent tensor([0.9993, 0.9985, 0.9991, 0.9992, 0.9986, 0.9980, 0.9980, 0.9993, 0.9982,
        0.9988, 0.9992, 0.9994, 0.9982, 0.9982, 0.9987, 0.9990],
       device='cuda:0')
Epoch: 107 | Batch_idx: 0 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (2497/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (3689/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (93.00%) (4881/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (6057/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (7243/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (8438/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (9640/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (10829/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (93.00%) (12029/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (93.00%) (13219/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (93.00%) (14418/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (93.00%) (15615/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (16816/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (93.00%) (17995/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (93.00%) (19182/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (93.00%) (20372/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (93.00%) (21550/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (93.00%) (22737/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (23916/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (25081/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (92.00%) (26292/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (93.00%) (27503/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (93.00%) (28698/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (92.00%) (29877/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (92.00%) (31064/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (32244/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (33431/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (92.00%) (34617/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (35802/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (36978/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (38180/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (39368/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (40555/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (41741/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (42936/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (44127/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (92.00%) (45322/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (46453/50000)
# TEST : Loss: (0.3904) | Acc: (87.00%) (8757/10000)
percent tensor([0.5010, 0.5298, 0.5232, 0.4955, 0.5320, 0.5121, 0.5365, 0.5017, 0.5090,
        0.5231, 0.5147, 0.5350, 0.5022, 0.5155, 0.5214, 0.4993],
       device='cuda:0')
percent tensor([0.5282, 0.5209, 0.4874, 0.5040, 0.4841, 0.4634, 0.5096, 0.5207, 0.5595,
        0.5261, 0.5339, 0.5088, 0.5456, 0.5910, 0.4876, 0.5003],
       device='cuda:0')
percent tensor([0.6027, 0.4791, 0.6590, 0.6462, 0.6603, 0.6417, 0.5520, 0.6712, 0.5933,
        0.5324, 0.5320, 0.5313, 0.4965, 0.5329, 0.5557, 0.6090],
       device='cuda:0')
percent tensor([0.6186, 0.6328, 0.5685, 0.5845, 0.5606, 0.6136, 0.6210, 0.5727, 0.5874,
        0.6299, 0.6273, 0.6115, 0.6391, 0.6283, 0.6222, 0.6217],
       device='cuda:0')
percent tensor([0.4537, 0.5517, 0.5766, 0.6309, 0.5845, 0.6050, 0.5286, 0.4642, 0.6051,
        0.5718, 0.6231, 0.6116, 0.5183, 0.6951, 0.4975, 0.5056],
       device='cuda:0')
percent tensor([0.6861, 0.7068, 0.6709, 0.6753, 0.6670, 0.6998, 0.6974, 0.6079, 0.6981,
        0.6958, 0.7199, 0.7286, 0.7173, 0.7330, 0.7161, 0.6758],
       device='cuda:0')
percent tensor([0.6083, 0.7093, 0.7906, 0.7946, 0.8065, 0.7597, 0.6828, 0.7209, 0.6332,
        0.6656, 0.6571, 0.6495, 0.5706, 0.6734, 0.6359, 0.6541],
       device='cuda:0')
percent tensor([0.9994, 0.9984, 0.9991, 0.9993, 0.9987, 0.9981, 0.9981, 0.9994, 0.9983,
        0.9989, 0.9993, 0.9994, 0.9982, 0.9983, 0.9988, 0.9991],
       device='cuda:0')
Epoch: 108 | Batch_idx: 0 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (92.00%) (2498/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (3691/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (92.00%) (4874/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (92.00%) (6065/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (7257/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (8444/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (9648/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (10837/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (92.00%) (12016/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (13207/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (14404/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (93.00%) (15596/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (16778/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (93.00%) (17986/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (93.00%) (19170/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (93.00%) (20369/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (93.00%) (21566/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (22765/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (23948/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (25152/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (93.00%) (26353/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (27560/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (28750/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (29937/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (31139/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (32340/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (33546/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (34749/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (93.00%) (35932/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (37136/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (38324/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (39513/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (40716/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (41903/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (43098/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (44290/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (93.00%) (45497/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (93.00%) (46619/50000)
# TEST : Loss: (0.3869) | Acc: (87.00%) (8769/10000)
percent tensor([0.5008, 0.5290, 0.5231, 0.4951, 0.5318, 0.5126, 0.5359, 0.5010, 0.5088,
        0.5223, 0.5145, 0.5341, 0.5018, 0.5149, 0.5210, 0.4989],
       device='cuda:0')
percent tensor([0.5251, 0.5192, 0.4847, 0.5025, 0.4820, 0.4623, 0.5078, 0.5184, 0.5563,
        0.5241, 0.5315, 0.5050, 0.5417, 0.5893, 0.4860, 0.4993],
       device='cuda:0')
percent tensor([0.6074, 0.4841, 0.6633, 0.6517, 0.6651, 0.6458, 0.5564, 0.6761, 0.5976,
        0.5369, 0.5359, 0.5376, 0.5011, 0.5368, 0.5610, 0.6132],
       device='cuda:0')
percent tensor([0.6171, 0.6318, 0.5666, 0.5836, 0.5592, 0.6129, 0.6200, 0.5714, 0.5855,
        0.6282, 0.6256, 0.6090, 0.6374, 0.6275, 0.6212, 0.6208],
       device='cuda:0')
percent tensor([0.4693, 0.5649, 0.5849, 0.6408, 0.5922, 0.6141, 0.5429, 0.4762, 0.6172,
        0.5842, 0.6331, 0.6241, 0.5340, 0.7055, 0.5124, 0.5205],
       device='cuda:0')
percent tensor([0.6991, 0.7214, 0.6807, 0.6840, 0.6788, 0.7106, 0.7116, 0.6201, 0.7111,
        0.7095, 0.7334, 0.7390, 0.7318, 0.7464, 0.7289, 0.6896],
       device='cuda:0')
percent tensor([0.6260, 0.7165, 0.7993, 0.8023, 0.8132, 0.7639, 0.6938, 0.7318, 0.6396,
        0.6764, 0.6711, 0.6732, 0.5818, 0.6804, 0.6519, 0.6643],
       device='cuda:0')
percent tensor([0.9994, 0.9985, 0.9991, 0.9993, 0.9987, 0.9982, 0.9981, 0.9994, 0.9983,
        0.9989, 0.9993, 0.9995, 0.9983, 0.9983, 0.9989, 0.9991],
       device='cuda:0')
Epoch: 109 | Batch_idx: 0 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (2510/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (3709/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (4897/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (6087/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (7284/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (8476/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (9665/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (10870/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (12054/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (13253/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (14442/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.1977) |  Loss2: (0.0000) | Acc: (93.00%) (15634/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (16824/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (18027/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (19221/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (20427/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (21612/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (22820/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (24005/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (25199/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (26391/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (27576/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (28777/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (29971/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (31168/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.1977) |  Loss2: (0.0000) | Acc: (93.00%) (32356/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (33543/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (34738/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (35921/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (37123/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (38320/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (39510/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (40713/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (41901/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (43100/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (44299/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (45508/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (46644/50000)
# TEST : Loss: (0.3855) | Acc: (87.00%) (8789/10000)
percent tensor([0.5013, 0.5295, 0.5223, 0.4953, 0.5312, 0.5135, 0.5361, 0.5011, 0.5094,
        0.5225, 0.5153, 0.5335, 0.5022, 0.5162, 0.5216, 0.4999],
       device='cuda:0')
percent tensor([0.5242, 0.5204, 0.4830, 0.5020, 0.4803, 0.4612, 0.5080, 0.5180, 0.5562,
        0.5247, 0.5317, 0.5036, 0.5409, 0.5921, 0.4853, 0.4993],
       device='cuda:0')
percent tensor([0.6082, 0.4890, 0.6592, 0.6492, 0.6605, 0.6448, 0.5583, 0.6723, 0.5988,
        0.5400, 0.5398, 0.5382, 0.5051, 0.5443, 0.5631, 0.6133],
       device='cuda:0')
percent tensor([0.6156, 0.6310, 0.5653, 0.5828, 0.5577, 0.6122, 0.6190, 0.5692, 0.5843,
        0.6279, 0.6247, 0.6080, 0.6364, 0.6273, 0.6197, 0.6200],
       device='cuda:0')
percent tensor([0.4645, 0.5576, 0.5837, 0.6372, 0.5895, 0.6145, 0.5366, 0.4739, 0.6146,
        0.5764, 0.6276, 0.6213, 0.5256, 0.7027, 0.5093, 0.5154],
       device='cuda:0')
percent tensor([0.6884, 0.7113, 0.6707, 0.6719, 0.6680, 0.7010, 0.7006, 0.6060, 0.7018,
        0.6998, 0.7240, 0.7293, 0.7217, 0.7378, 0.7178, 0.6785],
       device='cuda:0')
percent tensor([0.6265, 0.7155, 0.7976, 0.8029, 0.8116, 0.7631, 0.6939, 0.7279, 0.6369,
        0.6707, 0.6686, 0.6719, 0.5829, 0.6755, 0.6494, 0.6643],
       device='cuda:0')
percent tensor([0.9995, 0.9986, 0.9991, 0.9993, 0.9987, 0.9983, 0.9982, 0.9994, 0.9984,
        0.9989, 0.9993, 0.9995, 0.9983, 0.9984, 0.9989, 0.9992],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 110 | Batch_idx: 0 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (1296/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (92.00%) (2495/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (3700/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (4888/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (6078/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (7282/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.1946) |  Loss2: (0.0000) | Acc: (93.00%) (8478/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (9672/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (10873/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (12062/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (13257/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (14444/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (15632/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.1946) |  Loss2: (0.0000) | Acc: (93.00%) (16834/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (18027/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (19219/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (20428/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (21615/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (22799/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (23986/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (25169/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (26351/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (27504/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (92.00%) (28682/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (92.00%) (29870/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (92.00%) (31065/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (32266/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (33462/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (34645/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (35856/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (37043/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (38220/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (39414/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (40601/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (41806/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (42987/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (44175/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (45362/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (46497/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_110.pth.tar'
# TEST : Loss: (0.4570) | Acc: (85.00%) (8579/10000)
percent tensor([0.5008, 0.5297, 0.5193, 0.4941, 0.5286, 0.5116, 0.5341, 0.5010, 0.5089,
        0.5223, 0.5149, 0.5307, 0.5022, 0.5156, 0.5208, 0.4998],
       device='cuda:0')
percent tensor([0.5221, 0.5295, 0.4707, 0.5078, 0.4724, 0.4626, 0.5108, 0.5180, 0.5589,
        0.5291, 0.5389, 0.4982, 0.5418, 0.6060, 0.4911, 0.5068],
       device='cuda:0')
percent tensor([0.6031, 0.4776, 0.6795, 0.6451, 0.6719, 0.6438, 0.5648, 0.6652, 0.6018,
        0.5392, 0.5342, 0.5639, 0.5010, 0.5398, 0.5538, 0.6062],
       device='cuda:0')
percent tensor([0.6199, 0.6357, 0.5539, 0.5825, 0.5481, 0.6074, 0.6133, 0.5741, 0.5893,
        0.6296, 0.6278, 0.5936, 0.6394, 0.6336, 0.6205, 0.6221],
       device='cuda:0')
percent tensor([0.4438, 0.5502, 0.5906, 0.6540, 0.6046, 0.6064, 0.5493, 0.4866, 0.6029,
        0.5650, 0.6406, 0.6096, 0.4955, 0.6967, 0.5068, 0.5188],
       device='cuda:0')
percent tensor([0.6870, 0.7144, 0.6517, 0.6775, 0.6589, 0.7014, 0.6919, 0.6053, 0.6986,
        0.7000, 0.7201, 0.7144, 0.7184, 0.7361, 0.7222, 0.6831],
       device='cuda:0')
percent tensor([0.6127, 0.6966, 0.8156, 0.8056, 0.8197, 0.7485, 0.7012, 0.7274, 0.6446,
        0.6532, 0.6926, 0.7163, 0.5704, 0.6905, 0.6264, 0.6569],
       device='cuda:0')
percent tensor([0.9993, 0.9986, 0.9992, 0.9994, 0.9988, 0.9987, 0.9985, 0.9992, 0.9981,
        0.9990, 0.9996, 0.9994, 0.9987, 0.9986, 0.9989, 0.9992],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.9293, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(816.6688, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(819.2939, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1520.0465, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(490.6397, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2231.0176, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4271.8823, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1392.8416, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6154.9829, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11860.4395, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3916.8757, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16568.8926, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 111 | Batch_idx: 0 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (1320/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (2500/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (3699/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (4885/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (92.00%) (6058/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (92.00%) (7238/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (92.00%) (8444/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (92.00%) (9624/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (92.00%) (10815/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (12010/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (13215/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (14408/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (15599/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (16790/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (17997/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (19199/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (20412/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (21608/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (22810/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (23994/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (25195/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (26390/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (27592/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (28797/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (29977/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (31166/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (32374/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (33558/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (34755/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (35954/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (37143/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (38340/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (39527/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (40708/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (41892/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (43073/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (44265/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (45470/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (46603/50000)
# TEST : Loss: (0.4000) | Acc: (87.00%) (8761/10000)
percent tensor([0.4994, 0.5292, 0.5159, 0.4932, 0.5259, 0.5097, 0.5333, 0.4998, 0.5066,
        0.5211, 0.5138, 0.5289, 0.5009, 0.5164, 0.5199, 0.4992],
       device='cuda:0')
percent tensor([0.5178, 0.5214, 0.4778, 0.5067, 0.4794, 0.4637, 0.5062, 0.5160, 0.5503,
        0.5243, 0.5311, 0.5034, 0.5357, 0.5923, 0.4876, 0.5001],
       device='cuda:0')
percent tensor([0.6132, 0.4881, 0.6765, 0.6453, 0.6762, 0.6583, 0.5704, 0.6677, 0.6019,
        0.5445, 0.5395, 0.5639, 0.5113, 0.5443, 0.5665, 0.6148],
       device='cuda:0')
percent tensor([0.6137, 0.6301, 0.5589, 0.5827, 0.5520, 0.6088, 0.6127, 0.5733, 0.5853,
        0.6275, 0.6249, 0.5951, 0.6322, 0.6254, 0.6163, 0.6184],
       device='cuda:0')
percent tensor([0.4337, 0.5461, 0.5830, 0.6402, 0.5933, 0.5759, 0.5300, 0.4741, 0.6041,
        0.5655, 0.6375, 0.6086, 0.5105, 0.6812, 0.4851, 0.5029],
       device='cuda:0')
percent tensor([0.6755, 0.7125, 0.6586, 0.6807, 0.6561, 0.6936, 0.6926, 0.6053, 0.6993,
        0.6900, 0.7166, 0.7171, 0.7124, 0.7260, 0.7103, 0.6706],
       device='cuda:0')
percent tensor([0.6230, 0.7210, 0.8146, 0.8001, 0.8259, 0.7505, 0.7013, 0.7293, 0.6478,
        0.6720, 0.6719, 0.7122, 0.5992, 0.6680, 0.6207, 0.6670],
       device='cuda:0')
percent tensor([0.9992, 0.9986, 0.9994, 0.9995, 0.9985, 0.9983, 0.9983, 0.9994, 0.9981,
        0.9984, 0.9993, 0.9995, 0.9985, 0.9984, 0.9989, 0.9991],
       device='cuda:0')
Epoch: 112 | Batch_idx: 0 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (1323/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (2522/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (3724/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (4922/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (6120/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (7313/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (8507/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (9724/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (10923/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (12128/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (13338/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (14539/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (15729/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (16935/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (18132/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (19313/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (20497/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (21698/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (22899/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (24096/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (25300/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (26487/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (27690/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (28889/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (30083/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (31297/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (32480/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (33668/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (34869/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (36064/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (37235/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (38413/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (39617/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (40812/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (42002/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (43179/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (44372/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (45566/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (46710/50000)
# TEST : Loss: (0.4112) | Acc: (87.00%) (8731/10000)
percent tensor([0.5003, 0.5288, 0.5200, 0.4938, 0.5291, 0.5103, 0.5343, 0.5010, 0.5084,
        0.5220, 0.5144, 0.5318, 0.5017, 0.5151, 0.5202, 0.4992],
       device='cuda:0')
percent tensor([0.5193, 0.5205, 0.4775, 0.5054, 0.4768, 0.4651, 0.5055, 0.5149, 0.5529,
        0.5234, 0.5340, 0.4987, 0.5388, 0.5928, 0.4870, 0.5026],
       device='cuda:0')
percent tensor([0.6063, 0.4803, 0.6685, 0.6473, 0.6626, 0.6398, 0.5571, 0.6715, 0.5938,
        0.5416, 0.5281, 0.5572, 0.5035, 0.5327, 0.5578, 0.6107],
       device='cuda:0')
percent tensor([0.6189, 0.6354, 0.5609, 0.5854, 0.5539, 0.6110, 0.6186, 0.5722, 0.5887,
        0.6306, 0.6306, 0.5977, 0.6361, 0.6346, 0.6217, 0.6218],
       device='cuda:0')
percent tensor([0.4430, 0.5474, 0.5745, 0.6321, 0.5913, 0.5905, 0.5321, 0.4683, 0.5925,
        0.5585, 0.6359, 0.6134, 0.5005, 0.6805, 0.4968, 0.5011],
       device='cuda:0')
percent tensor([0.6812, 0.7054, 0.6666, 0.6810, 0.6690, 0.7058, 0.7003, 0.6081, 0.7089,
        0.6923, 0.7202, 0.7213, 0.7159, 0.7352, 0.7155, 0.6801],
       device='cuda:0')
percent tensor([0.6168, 0.7324, 0.8106, 0.8090, 0.8173, 0.7546, 0.7212, 0.7252, 0.6437,
        0.6631, 0.6849, 0.6998, 0.6088, 0.6932, 0.6454, 0.6615],
       device='cuda:0')
percent tensor([0.9993, 0.9987, 0.9993, 0.9993, 0.9984, 0.9983, 0.9989, 0.9994, 0.9981,
        0.9989, 0.9996, 0.9996, 0.9986, 0.9983, 0.9990, 0.9992],
       device='cuda:0')
Epoch: 113 | Batch_idx: 0 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (2519/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (3704/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (4905/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (6105/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (7303/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (8511/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (9711/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (10917/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (12125/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (13308/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (14503/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (15694/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (16894/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (18088/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (19269/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (20481/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (21667/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (22864/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (24067/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (25258/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (26447/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (27628/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (28828/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (30028/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (31219/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (32423/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (33618/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (34827/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (36030/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (37219/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (38415/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (39614/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (40801/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (42004/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (43186/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (44389/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (45577/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (46735/50000)
# TEST : Loss: (0.4201) | Acc: (86.00%) (8687/10000)
percent tensor([0.5005, 0.5290, 0.5227, 0.4950, 0.5314, 0.5111, 0.5352, 0.5020, 0.5081,
        0.5228, 0.5141, 0.5340, 0.5011, 0.5143, 0.5209, 0.4990],
       device='cuda:0')
percent tensor([0.5234, 0.5267, 0.4777, 0.5082, 0.4793, 0.4628, 0.5070, 0.5183, 0.5564,
        0.5298, 0.5404, 0.5001, 0.5431, 0.5961, 0.4889, 0.5048],
       device='cuda:0')
percent tensor([0.6142, 0.4921, 0.6766, 0.6562, 0.6753, 0.6591, 0.5736, 0.6716, 0.5999,
        0.5494, 0.5414, 0.5652, 0.5135, 0.5526, 0.5718, 0.6176],
       device='cuda:0')
percent tensor([0.6130, 0.6360, 0.5526, 0.5757, 0.5464, 0.6045, 0.6137, 0.5639, 0.5879,
        0.6307, 0.6300, 0.5939, 0.6362, 0.6308, 0.6155, 0.6166],
       device='cuda:0')
percent tensor([0.4572, 0.5708, 0.5895, 0.6380, 0.6148, 0.6108, 0.5484, 0.4959, 0.6033,
        0.5869, 0.6498, 0.6308, 0.5147, 0.7058, 0.5143, 0.5302],
       device='cuda:0')
percent tensor([0.6795, 0.7112, 0.6610, 0.6709, 0.6618, 0.6966, 0.6983, 0.6033, 0.7088,
        0.6992, 0.7197, 0.7301, 0.7148, 0.7314, 0.7166, 0.6785],
       device='cuda:0')
percent tensor([0.6329, 0.7237, 0.8096, 0.8026, 0.8277, 0.7682, 0.7191, 0.7229, 0.6273,
        0.6834, 0.6643, 0.7252, 0.6064, 0.6962, 0.6612, 0.6755],
       device='cuda:0')
percent tensor([0.9991, 0.9984, 0.9991, 0.9993, 0.9985, 0.9986, 0.9989, 0.9993, 0.9986,
        0.9990, 0.9995, 0.9996, 0.9986, 0.9984, 0.9991, 0.9989],
       device='cuda:0')
Epoch: 114 | Batch_idx: 0 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (2525/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (4926/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (6129/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (7333/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (8542/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (9728/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (10928/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (12130/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (13328/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (14516/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (15712/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (16913/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (18104/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (19299/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (20508/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (21721/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (22912/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (24111/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (25315/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (26514/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (27722/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (28928/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (30125/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (31312/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (32506/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (33685/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (34881/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (36067/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (37258/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (38461/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (39669/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (40876/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (42086/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (43280/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (44472/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (45669/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (46826/50000)
# TEST : Loss: (0.3973) | Acc: (87.00%) (8744/10000)
percent tensor([0.5007, 0.5307, 0.5198, 0.4954, 0.5278, 0.5107, 0.5349, 0.5023, 0.5078,
        0.5227, 0.5146, 0.5316, 0.5022, 0.5170, 0.5213, 0.4998],
       device='cuda:0')
percent tensor([0.5226, 0.5197, 0.4754, 0.5099, 0.4821, 0.4646, 0.5045, 0.5181, 0.5553,
        0.5237, 0.5373, 0.4965, 0.5398, 0.5880, 0.4890, 0.5032],
       device='cuda:0')
percent tensor([0.6160, 0.4955, 0.6907, 0.6630, 0.6882, 0.6627, 0.5787, 0.6772, 0.6017,
        0.5579, 0.5444, 0.5807, 0.5131, 0.5508, 0.5760, 0.6199],
       device='cuda:0')
percent tensor([0.6125, 0.6301, 0.5514, 0.5749, 0.5449, 0.6007, 0.6091, 0.5676, 0.5881,
        0.6241, 0.6238, 0.5882, 0.6342, 0.6304, 0.6129, 0.6143],
       device='cuda:0')
percent tensor([0.4547, 0.5648, 0.5834, 0.6355, 0.6053, 0.6111, 0.5454, 0.4796, 0.5891,
        0.5803, 0.6415, 0.6245, 0.5005, 0.7007, 0.5011, 0.5351],
       device='cuda:0')
percent tensor([0.6743, 0.7152, 0.6446, 0.6618, 0.6496, 0.6963, 0.6925, 0.5999, 0.7058,
        0.6914, 0.7194, 0.7067, 0.7175, 0.7386, 0.7080, 0.6810],
       device='cuda:0')
percent tensor([0.6231, 0.7242, 0.8132, 0.8103, 0.8180, 0.7774, 0.6916, 0.7256, 0.6159,
        0.6786, 0.6683, 0.6922, 0.5844, 0.6919, 0.6272, 0.6816],
       device='cuda:0')
percent tensor([0.9993, 0.9988, 0.9991, 0.9993, 0.9986, 0.9986, 0.9982, 0.9992, 0.9985,
        0.9988, 0.9996, 0.9995, 0.9986, 0.9983, 0.9990, 0.9990],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 115 | Batch_idx: 0 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (91.00%) (2469/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (91.00%) (3638/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (91.00%) (4809/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (91.00%) (5989/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (91.00%) (7154/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (91.00%) (8333/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (9505/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (91.00%) (10687/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (91.00%) (11869/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (91.00%) (13051/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (91.00%) (14232/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (91.00%) (15418/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (91.00%) (16598/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (17784/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (18963/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (20148/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (21335/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (22523/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (23718/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (24891/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (26075/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (27269/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (28456/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (29644/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (30850/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (32026/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (33199/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (34392/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (35590/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (36770/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (37966/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (39140/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (40308/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (41488/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (42687/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (43863/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (45050/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (46182/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_115.pth.tar'
# TEST : Loss: (0.4040) | Acc: (87.00%) (8730/10000)
percent tensor([0.4935, 0.5259, 0.5120, 0.4875, 0.5198, 0.5038, 0.5299, 0.4949, 0.5017,
        0.5167, 0.5081, 0.5250, 0.4947, 0.5150, 0.5153, 0.4934],
       device='cuda:0')
percent tensor([0.5368, 0.5296, 0.4901, 0.5219, 0.4962, 0.4741, 0.5142, 0.5332, 0.5756,
        0.5378, 0.5547, 0.5109, 0.5557, 0.6043, 0.4971, 0.5131],
       device='cuda:0')
percent tensor([0.6319, 0.5142, 0.6975, 0.6773, 0.6988, 0.6785, 0.5939, 0.6871, 0.6248,
        0.5808, 0.5732, 0.5905, 0.5281, 0.5852, 0.5917, 0.6361],
       device='cuda:0')
percent tensor([0.6159, 0.6297, 0.5637, 0.5802, 0.5523, 0.6009, 0.6135, 0.5748, 0.5933,
        0.6277, 0.6248, 0.5965, 0.6347, 0.6325, 0.6153, 0.6170],
       device='cuda:0')
percent tensor([0.4467, 0.5698, 0.5783, 0.6233, 0.5833, 0.6179, 0.5437, 0.4591, 0.5907,
        0.5751, 0.6490, 0.6195, 0.4946, 0.7078, 0.5059, 0.5311],
       device='cuda:0')
percent tensor([0.6757, 0.7198, 0.6633, 0.6660, 0.6635, 0.7013, 0.7006, 0.6043, 0.7143,
        0.6984, 0.7222, 0.7231, 0.7188, 0.7407, 0.7099, 0.6869],
       device='cuda:0')
percent tensor([0.6550, 0.7346, 0.8141, 0.8067, 0.8112, 0.7748, 0.7145, 0.7370, 0.6489,
        0.6952, 0.6965, 0.6861, 0.6340, 0.7122, 0.6428, 0.6958],
       device='cuda:0')
percent tensor([0.9994, 0.9988, 0.9993, 0.9994, 0.9988, 0.9983, 0.9983, 0.9993, 0.9980,
        0.9988, 0.9995, 0.9995, 0.9985, 0.9984, 0.9991, 0.9990],
       device='cuda:0')
Epoch: 116 | Batch_idx: 0 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (2511/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (3707/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (4888/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (6082/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (7271/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (8452/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (9645/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (92.00%) (10829/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (92.00%) (12004/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (92.00%) (13181/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (92.00%) (14368/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (92.00%) (15545/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (16734/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (92.00%) (17926/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (92.00%) (19129/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (20302/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (92.00%) (21506/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (92.00%) (22698/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (92.00%) (23893/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (92.00%) (25101/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (92.00%) (26277/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (92.00%) (27475/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (92.00%) (28666/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (92.00%) (29856/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (92.00%) (31050/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (92.00%) (32239/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (92.00%) (33442/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (92.00%) (34625/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (92.00%) (35809/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (92.00%) (37006/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (92.00%) (38189/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (92.00%) (39381/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (92.00%) (40579/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (92.00%) (41767/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (92.00%) (42949/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (92.00%) (44155/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (92.00%) (45338/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (92.00%) (46484/50000)
# TEST : Loss: (0.3929) | Acc: (87.00%) (8766/10000)
percent tensor([0.4879, 0.5208, 0.5050, 0.4814, 0.5129, 0.4993, 0.5242, 0.4882, 0.4960,
        0.5109, 0.5032, 0.5182, 0.4890, 0.5104, 0.5105, 0.4884],
       device='cuda:0')
percent tensor([0.5425, 0.5343, 0.4920, 0.5260, 0.5007, 0.4785, 0.5195, 0.5392, 0.5859,
        0.5420, 0.5621, 0.5139, 0.5616, 0.6137, 0.5016, 0.5172],
       device='cuda:0')
percent tensor([0.6288, 0.5069, 0.6962, 0.6742, 0.6959, 0.6762, 0.5875, 0.6823, 0.6232,
        0.5791, 0.5721, 0.5873, 0.5227, 0.5814, 0.5847, 0.6333],
       device='cuda:0')
percent tensor([0.6144, 0.6265, 0.5619, 0.5779, 0.5511, 0.6001, 0.6113, 0.5731, 0.5922,
        0.6237, 0.6217, 0.5932, 0.6316, 0.6303, 0.6134, 0.6148],
       device='cuda:0')
percent tensor([0.4410, 0.5734, 0.5844, 0.6315, 0.5850, 0.6205, 0.5430, 0.4593, 0.5939,
        0.5775, 0.6530, 0.6237, 0.4931, 0.7125, 0.5108, 0.5290],
       device='cuda:0')
percent tensor([0.6771, 0.7233, 0.6664, 0.6689, 0.6679, 0.7076, 0.7031, 0.6025, 0.7176,
        0.7014, 0.7249, 0.7247, 0.7222, 0.7436, 0.7124, 0.6896],
       device='cuda:0')
percent tensor([0.6575, 0.7357, 0.8066, 0.7971, 0.8054, 0.7687, 0.7178, 0.7290, 0.6500,
        0.6975, 0.6987, 0.6888, 0.6469, 0.7115, 0.6437, 0.6994],
       device='cuda:0')
percent tensor([0.9993, 0.9988, 0.9993, 0.9994, 0.9987, 0.9984, 0.9983, 0.9994, 0.9980,
        0.9988, 0.9996, 0.9995, 0.9986, 0.9984, 0.9992, 0.9990],
       device='cuda:0')
Epoch: 117 | Batch_idx: 0 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (92.00%) (2492/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (3696/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (4897/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (6090/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (7289/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (8498/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (9711/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (10893/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (12086/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (13282/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (14475/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (15659/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (16859/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (18056/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (19253/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (20434/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (21639/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (22841/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (24036/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (25234/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (26427/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (27635/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (28840/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (30035/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (31240/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (32429/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (33639/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (34836/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (36035/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (37243/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (38456/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (39652/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (40851/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (42050/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (43240/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (44412/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (45630/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (46794/50000)
# TEST : Loss: (0.3801) | Acc: (88.00%) (8811/10000)
percent tensor([0.4894, 0.5234, 0.5055, 0.4823, 0.5143, 0.5006, 0.5264, 0.4900, 0.4984,
        0.5127, 0.5056, 0.5194, 0.4907, 0.5131, 0.5128, 0.4902],
       device='cuda:0')
percent tensor([0.5371, 0.5281, 0.4859, 0.5204, 0.4941, 0.4733, 0.5137, 0.5342, 0.5811,
        0.5355, 0.5556, 0.5076, 0.5556, 0.6104, 0.4956, 0.5117],
       device='cuda:0')
percent tensor([0.6310, 0.5082, 0.6965, 0.6732, 0.6966, 0.6768, 0.5891, 0.6820, 0.6255,
        0.5800, 0.5743, 0.5883, 0.5273, 0.5803, 0.5860, 0.6338],
       device='cuda:0')
percent tensor([0.6179, 0.6289, 0.5632, 0.5797, 0.5532, 0.6025, 0.6139, 0.5758, 0.5943,
        0.6249, 0.6238, 0.5944, 0.6341, 0.6322, 0.6167, 0.6168],
       device='cuda:0')
percent tensor([0.4395, 0.5748, 0.5882, 0.6376, 0.5883, 0.6227, 0.5419, 0.4612, 0.5977,
        0.5799, 0.6569, 0.6260, 0.4912, 0.7171, 0.5081, 0.5298],
       device='cuda:0')
percent tensor([0.6781, 0.7256, 0.6678, 0.6720, 0.6715, 0.7115, 0.7040, 0.6011, 0.7195,
        0.7030, 0.7267, 0.7250, 0.7232, 0.7440, 0.7133, 0.6920],
       device='cuda:0')
percent tensor([0.6622, 0.7397, 0.8094, 0.7999, 0.8095, 0.7693, 0.7248, 0.7326, 0.6515,
        0.6994, 0.7008, 0.7017, 0.6511, 0.7086, 0.6490, 0.7057],
       device='cuda:0')
percent tensor([0.9993, 0.9988, 0.9993, 0.9994, 0.9987, 0.9985, 0.9983, 0.9994, 0.9981,
        0.9988, 0.9996, 0.9996, 0.9986, 0.9984, 0.9992, 0.9990],
       device='cuda:0')
Epoch: 118 | Batch_idx: 0 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (2503/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (3705/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (4895/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (6082/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (7279/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (8475/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (9671/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (10866/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (12073/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (13289/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (14498/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (15700/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (16903/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (18111/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (19317/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (20534/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (21738/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (22935/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (24144/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (25346/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (26559/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (93.00%) (27774/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (93.00%) (28970/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (30174/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (31377/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (32570/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (33764/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (34964/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (36153/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (37365/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (38576/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (39771/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (40974/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (42171/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (43373/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (44561/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (45759/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (46930/50000)
# TEST : Loss: (0.3757) | Acc: (88.00%) (8830/10000)
percent tensor([0.4925, 0.5260, 0.5087, 0.4849, 0.5178, 0.5038, 0.5296, 0.4927, 0.5014,
        0.5154, 0.5086, 0.5226, 0.4937, 0.5152, 0.5155, 0.4929],
       device='cuda:0')
percent tensor([0.5413, 0.5310, 0.4877, 0.5225, 0.4972, 0.4768, 0.5169, 0.5378, 0.5851,
        0.5383, 0.5593, 0.5102, 0.5593, 0.6147, 0.4987, 0.5147],
       device='cuda:0')
percent tensor([0.6259, 0.5028, 0.6921, 0.6684, 0.6906, 0.6721, 0.5827, 0.6757, 0.6202,
        0.5771, 0.5710, 0.5834, 0.5230, 0.5761, 0.5797, 0.6298],
       device='cuda:0')
percent tensor([0.6256, 0.6350, 0.5689, 0.5849, 0.5586, 0.6081, 0.6212, 0.5827, 0.6014,
        0.6309, 0.6305, 0.6007, 0.6408, 0.6382, 0.6240, 0.6235],
       device='cuda:0')
percent tensor([0.4478, 0.5806, 0.5947, 0.6418, 0.5934, 0.6272, 0.5478, 0.4684, 0.6017,
        0.5878, 0.6625, 0.6316, 0.4983, 0.7206, 0.5178, 0.5346],
       device='cuda:0')
percent tensor([0.6872, 0.7354, 0.6786, 0.6828, 0.6829, 0.7235, 0.7138, 0.6091, 0.7294,
        0.7124, 0.7360, 0.7342, 0.7326, 0.7520, 0.7234, 0.7024],
       device='cuda:0')
percent tensor([0.6672, 0.7393, 0.8115, 0.7991, 0.8124, 0.7678, 0.7287, 0.7368, 0.6547,
        0.7041, 0.7051, 0.7102, 0.6558, 0.7079, 0.6541, 0.7105],
       device='cuda:0')
percent tensor([0.9993, 0.9989, 0.9993, 0.9994, 0.9988, 0.9985, 0.9984, 0.9994, 0.9982,
        0.9989, 0.9996, 0.9996, 0.9986, 0.9984, 0.9992, 0.9990],
       device='cuda:0')
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (1323/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (2542/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (3741/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (4954/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (6154/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (7343/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (8547/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (9762/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (10955/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (12158/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (13344/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (14546/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (15753/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (93.00%) (16960/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (18174/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (19386/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (94.00%) (20576/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (21775/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (22993/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (24198/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (25410/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (26619/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (27827/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (29028/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (30235/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (31433/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (32646/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (33864/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (35067/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (36276/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (94.00%) (37458/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (94.00%) (38652/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (94.00%) (39853/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (94.00%) (41054/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (42255/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (94.00%) (43443/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (44636/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (45832/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (46988/50000)
# TEST : Loss: (0.3722) | Acc: (88.00%) (8837/10000)
percent tensor([0.4928, 0.5260, 0.5084, 0.4842, 0.5179, 0.5041, 0.5297, 0.4924, 0.5021,
        0.5154, 0.5093, 0.5226, 0.4941, 0.5149, 0.5156, 0.4929],
       device='cuda:0')
percent tensor([0.5380, 0.5264, 0.4839, 0.5187, 0.4934, 0.4749, 0.5130, 0.5341, 0.5818,
        0.5333, 0.5550, 0.5058, 0.5553, 0.6112, 0.4957, 0.5111],
       device='cuda:0')
percent tensor([0.6295, 0.5043, 0.6948, 0.6691, 0.6949, 0.6762, 0.5853, 0.6777, 0.6236,
        0.5799, 0.5752, 0.5852, 0.5271, 0.5745, 0.5829, 0.6326],
       device='cuda:0')
percent tensor([0.6270, 0.6348, 0.5696, 0.5859, 0.5597, 0.6095, 0.6216, 0.5837, 0.6021,
        0.6301, 0.6302, 0.6003, 0.6415, 0.6381, 0.6248, 0.6240],
       device='cuda:0')
percent tensor([0.4315, 0.5659, 0.5853, 0.6331, 0.5837, 0.6137, 0.5331, 0.4572, 0.5896,
        0.5743, 0.6508, 0.6206, 0.4810, 0.7127, 0.5020, 0.5178],
       device='cuda:0')
percent tensor([0.6924, 0.7420, 0.6843, 0.6899, 0.6901, 0.7313, 0.7200, 0.6132, 0.7357,
        0.7187, 0.7419, 0.7384, 0.7384, 0.7585, 0.7282, 0.7090],
       device='cuda:0')
percent tensor([0.6704, 0.7424, 0.8145, 0.8040, 0.8159, 0.7700, 0.7323, 0.7402, 0.6533,
        0.7066, 0.7067, 0.7157, 0.6570, 0.7103, 0.6565, 0.7166],
       device='cuda:0')
percent tensor([0.9993, 0.9988, 0.9993, 0.9995, 0.9988, 0.9986, 0.9983, 0.9994, 0.9982,
        0.9989, 0.9996, 0.9996, 0.9986, 0.9984, 0.9992, 0.9991],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (95.00%) (2558/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (95.00%) (3776/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (95.00%) (4990/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (6176/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (7381/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (8571/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (9775/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (10970/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (12146/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (93.00%) (13342/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (14544/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (15747/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (16942/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (18133/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (19347/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (20545/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (21732/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (22925/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (24132/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (25338/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (26529/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (27722/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (28918/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (30101/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (31307/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (32504/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (33695/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (34893/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (36096/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (37288/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (38470/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (39652/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (40840/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (42042/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (43252/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (44449/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (45651/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (46825/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_120.pth.tar'
# TEST : Loss: (0.4174) | Acc: (87.00%) (8735/10000)
percent tensor([0.4935, 0.5236, 0.5095, 0.4853, 0.5212, 0.5082, 0.5277, 0.4920, 0.5002,
        0.5147, 0.5093, 0.5223, 0.4939, 0.5081, 0.5167, 0.4935],
       device='cuda:0')
percent tensor([0.5409, 0.5268, 0.4984, 0.5224, 0.4993, 0.4815, 0.5155, 0.5385, 0.5805,
        0.5358, 0.5530, 0.5159, 0.5577, 0.6054, 0.4999, 0.5134],
       device='cuda:0')
percent tensor([0.6393, 0.5081, 0.7032, 0.6809, 0.7010, 0.6839, 0.5881, 0.6879, 0.6404,
        0.5836, 0.5776, 0.5953, 0.5412, 0.5718, 0.5853, 0.6411],
       device='cuda:0')
percent tensor([0.6230, 0.6353, 0.5615, 0.5832, 0.5589, 0.6046, 0.6208, 0.5815, 0.5922,
        0.6289, 0.6271, 0.5975, 0.6357, 0.6358, 0.6249, 0.6212],
       device='cuda:0')
percent tensor([0.4405, 0.5723, 0.5892, 0.6529, 0.5963, 0.6250, 0.5504, 0.4710, 0.5999,
        0.5784, 0.6397, 0.6303, 0.4963, 0.7091, 0.5138, 0.5118],
       device='cuda:0')
percent tensor([0.6927, 0.7387, 0.6746, 0.6968, 0.6869, 0.7342, 0.7234, 0.6126, 0.7242,
        0.7152, 0.7357, 0.7376, 0.7291, 0.7613, 0.7409, 0.7043],
       device='cuda:0')
percent tensor([0.6685, 0.7516, 0.8182, 0.7984, 0.8292, 0.7757, 0.7429, 0.7350, 0.6619,
        0.7034, 0.7131, 0.7462, 0.6816, 0.7283, 0.6594, 0.7224],
       device='cuda:0')
percent tensor([0.9993, 0.9986, 0.9993, 0.9995, 0.9990, 0.9990, 0.9988, 0.9995, 0.9982,
        0.9988, 0.9994, 0.9996, 0.9988, 0.9978, 0.9991, 0.9992],
       device='cuda:0')


Files already downloaded and verified
USE 1 GPUs!
=> loading checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_120.pth.tar'
Epoch: 121 | Batch_idx: 0 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (2535/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (3737/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (4938/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (6142/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (7345/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (8543/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (9734/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (10937/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (12154/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (13358/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (14553/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (15750/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (16950/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (18148/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (19346/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (20551/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (21759/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (22971/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (24180/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (94.00%) (25390/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (94.00%) (26592/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (27813/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (94.00%) (29007/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (30194/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (31384/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (32586/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (33800/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (94.00%) (35019/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (94.00%) (36229/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (94.00%) (37431/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (94.00%) (38626/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (94.00%) (39836/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (94.00%) (41030/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (42232/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (94.00%) (43437/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (94.00%) (44642/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (45839/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (94.00%) (47005/50000)
# TEST : Loss: (0.4115) | Acc: (87.00%) (8725/10000)
percent tensor([0.4943, 0.5232, 0.5131, 0.4857, 0.5227, 0.5067, 0.5281, 0.4936, 0.5018,
        0.5154, 0.5097, 0.5238, 0.4948, 0.5073, 0.5158, 0.4931],
       device='cuda:0')
percent tensor([0.5380, 0.5229, 0.4964, 0.5187, 0.4989, 0.4771, 0.5137, 0.5368, 0.5791,
        0.5327, 0.5512, 0.5133, 0.5537, 0.6045, 0.4969, 0.5096],
       device='cuda:0')
percent tensor([0.6380, 0.5091, 0.6986, 0.6749, 0.6993, 0.6744, 0.5923, 0.6909, 0.6452,
        0.5840, 0.5799, 0.5966, 0.5451, 0.5830, 0.5841, 0.6390],
       device='cuda:0')
percent tensor([0.6235, 0.6334, 0.5667, 0.5840, 0.5627, 0.6120, 0.6208, 0.5765, 0.5918,
        0.6272, 0.6264, 0.6010, 0.6376, 0.6342, 0.6246, 0.6211],
       device='cuda:0')
percent tensor([0.4408, 0.5732, 0.5774, 0.6504, 0.6000, 0.5936, 0.5660, 0.4938, 0.6063,
        0.5723, 0.6493, 0.6250, 0.4892, 0.6968, 0.5173, 0.5192],
       device='cuda:0')
percent tensor([0.7041, 0.7446, 0.6878, 0.6992, 0.6998, 0.7342, 0.7318, 0.6245, 0.7285,
        0.7225, 0.7416, 0.7460, 0.7392, 0.7587, 0.7441, 0.7077],
       device='cuda:0')
percent tensor([0.6744, 0.7265, 0.8136, 0.8124, 0.8221, 0.7674, 0.7360, 0.7497, 0.6616,
        0.6792, 0.6962, 0.7236, 0.6421, 0.7055, 0.6648, 0.7187],
       device='cuda:0')
percent tensor([0.9993, 0.9988, 0.9990, 0.9993, 0.9984, 0.9990, 0.9989, 0.9992, 0.9983,
        0.9991, 0.9994, 0.9996, 0.9987, 0.9988, 0.9991, 0.9993],
       device='cuda:0')
Epoch: 122 | Batch_idx: 0 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (2548/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (3754/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (4962/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (6160/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (7367/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (8561/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (9778/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (10982/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (12172/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (13361/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (93.00%) (14551/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (93.00%) (15760/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (93.00%) (16959/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (93.00%) (18160/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (19374/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (20580/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (21797/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (22987/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (93.00%) (24172/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (93.00%) (25367/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (93.00%) (26578/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (93.00%) (27784/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (93.00%) (28987/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (93.00%) (30186/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (93.00%) (31394/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (93.00%) (32598/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (93.00%) (33788/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (93.00%) (34996/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (93.00%) (36206/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (93.00%) (37405/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (93.00%) (38615/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (93.00%) (39813/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (93.00%) (41012/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (42213/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (93.00%) (43417/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (93.00%) (44611/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (93.00%) (45796/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (93.00%) (46945/50000)
# TEST : Loss: (0.4219) | Acc: (87.00%) (8705/10000)
percent tensor([0.4942, 0.5246, 0.5102, 0.4856, 0.5213, 0.5050, 0.5288, 0.4930, 0.5028,
        0.5157, 0.5100, 0.5232, 0.4954, 0.5109, 0.5154, 0.4935],
       device='cuda:0')
percent tensor([0.5367, 0.5357, 0.4724, 0.5129, 0.4791, 0.4745, 0.5187, 0.5241, 0.5803,
        0.5323, 0.5563, 0.4983, 0.5568, 0.6239, 0.4994, 0.5149],
       device='cuda:0')
percent tensor([0.6334, 0.5103, 0.6878, 0.6667, 0.6858, 0.6802, 0.5905, 0.6784, 0.6280,
        0.5776, 0.5823, 0.5837, 0.5379, 0.5816, 0.5859, 0.6391],
       device='cuda:0')
percent tensor([0.6245, 0.6331, 0.5705, 0.5917, 0.5637, 0.6132, 0.6200, 0.5851, 0.5932,
        0.6281, 0.6255, 0.5988, 0.6351, 0.6310, 0.6283, 0.6244],
       device='cuda:0')
percent tensor([0.4530, 0.5637, 0.5938, 0.6481, 0.6141, 0.6113, 0.5546, 0.4579, 0.6281,
        0.5775, 0.6662, 0.6300, 0.5176, 0.7043, 0.4958, 0.5031],
       device='cuda:0')
percent tensor([0.6995, 0.7302, 0.6971, 0.7027, 0.7126, 0.7357, 0.7285, 0.6205, 0.7319,
        0.7174, 0.7359, 0.7484, 0.7411, 0.7468, 0.7364, 0.7047],
       device='cuda:0')
percent tensor([0.6717, 0.7399, 0.7994, 0.7977, 0.8151, 0.7858, 0.7320, 0.7214, 0.6626,
        0.6831, 0.7124, 0.7370, 0.6618, 0.6962, 0.6477, 0.6979],
       device='cuda:0')
percent tensor([0.9993, 0.9987, 0.9992, 0.9992, 0.9989, 0.9989, 0.9987, 0.9994, 0.9986,
        0.9988, 0.9995, 0.9995, 0.9985, 0.9985, 0.9990, 0.9991],
       device='cuda:0')
Epoch: 123 | Batch_idx: 0 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (3749/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (4962/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (6169/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (7377/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (8589/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (9816/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (11045/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (12268/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (13482/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (14672/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (15869/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (17079/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (18279/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (19469/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (20673/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (21878/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (23083/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (24286/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (25495/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (26702/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (27897/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (29103/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (30311/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (31510/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (32705/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (33897/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (35108/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (36310/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (37519/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (38725/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (39912/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (41121/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (42310/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (43522/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (44736/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (45935/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (47088/50000)
# TEST : Loss: (0.3805) | Acc: (88.00%) (8837/10000)
percent tensor([0.4937, 0.5249, 0.5095, 0.4878, 0.5209, 0.5047, 0.5281, 0.4943, 0.5021,
        0.5153, 0.5094, 0.5218, 0.4952, 0.5099, 0.5161, 0.4937],
       device='cuda:0')
percent tensor([0.5390, 0.5311, 0.4895, 0.5177, 0.4939, 0.4798, 0.5203, 0.5328, 0.5809,
        0.5335, 0.5546, 0.5083, 0.5581, 0.6165, 0.5002, 0.5138],
       device='cuda:0')
percent tensor([0.6324, 0.5058, 0.6948, 0.6710, 0.6919, 0.6718, 0.5896, 0.6852, 0.6377,
        0.5819, 0.5821, 0.5863, 0.5389, 0.5759, 0.5807, 0.6410],
       device='cuda:0')
percent tensor([0.6232, 0.6325, 0.5608, 0.5862, 0.5594, 0.6142, 0.6197, 0.5797, 0.5903,
        0.6238, 0.6264, 0.5966, 0.6382, 0.6299, 0.6276, 0.6196],
       device='cuda:0')
percent tensor([0.4609, 0.5797, 0.5726, 0.6365, 0.5924, 0.6366, 0.5489, 0.4759, 0.6056,
        0.5885, 0.6663, 0.6086, 0.5257, 0.7034, 0.5215, 0.5339],
       device='cuda:0')
percent tensor([0.6982, 0.7355, 0.6800, 0.7012, 0.6944, 0.7395, 0.7197, 0.6136, 0.7225,
        0.7150, 0.7342, 0.7408, 0.7329, 0.7506, 0.7390, 0.7057],
       device='cuda:0')
percent tensor([0.6573, 0.7369, 0.8096, 0.7994, 0.8142, 0.7706, 0.7380, 0.7361, 0.6613,
        0.6852, 0.7231, 0.7239, 0.6496, 0.7048, 0.6486, 0.7110],
       device='cuda:0')
percent tensor([0.9994, 0.9988, 0.9992, 0.9994, 0.9987, 0.9989, 0.9987, 0.9991, 0.9983,
        0.9990, 0.9995, 0.9996, 0.9988, 0.9983, 0.9991, 0.9991],
       device='cuda:0')
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (93.00%) (1323/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (2531/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (3744/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (4946/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (6148/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (7366/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (8588/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (9801/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (11009/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (12225/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (13424/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (14645/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (15862/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (17065/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (18287/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (19503/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (20716/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (21923/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (23134/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (24354/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (25562/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (26771/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (27969/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (29166/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (30359/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (31555/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (32766/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (33969/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (35174/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (36377/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (37596/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (38813/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (40037/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (41232/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (42437/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (43623/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (44827/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (46028/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (47191/50000)
# TEST : Loss: (0.4681) | Acc: (86.00%) (8645/10000)
percent tensor([0.4944, 0.5241, 0.5117, 0.4869, 0.5214, 0.5063, 0.5284, 0.4941, 0.5020,
        0.5153, 0.5095, 0.5231, 0.4954, 0.5092, 0.5156, 0.4933],
       device='cuda:0')
percent tensor([0.5387, 0.5298, 0.4953, 0.5271, 0.5004, 0.4804, 0.5187, 0.5387, 0.5764,
        0.5353, 0.5482, 0.5147, 0.5544, 0.6102, 0.5021, 0.5159],
       device='cuda:0')
percent tensor([0.6343, 0.5018, 0.7024, 0.6739, 0.6991, 0.6701, 0.5904, 0.6892, 0.6300,
        0.5781, 0.5728, 0.5956, 0.5404, 0.5602, 0.5795, 0.6363],
       device='cuda:0')
percent tensor([0.6247, 0.6368, 0.5676, 0.5884, 0.5643, 0.6146, 0.6207, 0.5859, 0.5974,
        0.6285, 0.6298, 0.5984, 0.6382, 0.6384, 0.6284, 0.6267],
       device='cuda:0')
percent tensor([0.4303, 0.5456, 0.5905, 0.6534, 0.5964, 0.6148, 0.5452, 0.4732, 0.6024,
        0.5739, 0.6493, 0.6248, 0.5061, 0.6892, 0.4942, 0.5103],
       device='cuda:0')
percent tensor([0.6987, 0.7335, 0.6742, 0.6998, 0.6893, 0.7398, 0.7208, 0.6157, 0.7267,
        0.7110, 0.7400, 0.7306, 0.7305, 0.7566, 0.7379, 0.7088],
       device='cuda:0')
percent tensor([0.6530, 0.7506, 0.8166, 0.8157, 0.8105, 0.7667, 0.7365, 0.7202, 0.6824,
        0.6853, 0.7236, 0.7264, 0.6394, 0.7086, 0.6366, 0.7035],
       device='cuda:0')
percent tensor([0.9994, 0.9993, 0.9995, 0.9997, 0.9986, 0.9989, 0.9987, 0.9993, 0.9986,
        0.9990, 0.9996, 0.9995, 0.9989, 0.9981, 0.9993, 0.9991],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 125 | Batch_idx: 0 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (2535/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (3730/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (4923/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (93.00%) (6118/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (7309/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (8515/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (9702/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (10895/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (12092/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (13306/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (14488/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (15686/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (16897/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (18090/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (19288/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (20491/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (21678/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (22887/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (24097/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (25299/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (26503/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (27704/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (28908/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (30117/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (31310/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (32518/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (33722/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (34909/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (36104/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (37317/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1786) |  Loss2: (0.0000) | Acc: (93.00%) (38528/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (39741/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (40939/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (42155/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (43356/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (44569/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (45771/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (46931/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_125.pth.tar'
# TEST : Loss: (0.4034) | Acc: (87.00%) (8781/10000)
percent tensor([0.4934, 0.5231, 0.5090, 0.4870, 0.5193, 0.5074, 0.5265, 0.4920, 0.5006,
        0.5133, 0.5085, 0.5201, 0.4943, 0.5086, 0.5157, 0.4932],
       device='cuda:0')
percent tensor([0.5352, 0.5260, 0.4929, 0.5224, 0.4964, 0.4743, 0.5143, 0.5369, 0.5745,
        0.5333, 0.5451, 0.5120, 0.5534, 0.6051, 0.4966, 0.5110],
       device='cuda:0')
percent tensor([0.6300, 0.5014, 0.6991, 0.6753, 0.6923, 0.6700, 0.5843, 0.6816, 0.6239,
        0.5793, 0.5720, 0.5959, 0.5370, 0.5612, 0.5758, 0.6351],
       device='cuda:0')
percent tensor([0.6133, 0.6267, 0.5577, 0.5780, 0.5522, 0.6027, 0.6081, 0.5732, 0.5869,
        0.6189, 0.6207, 0.5881, 0.6274, 0.6294, 0.6156, 0.6150],
       device='cuda:0')
percent tensor([0.4505, 0.5636, 0.6043, 0.6722, 0.6207, 0.6480, 0.5678, 0.4984, 0.6213,
        0.5800, 0.6541, 0.6419, 0.5218, 0.7089, 0.5149, 0.5329],
       device='cuda:0')
percent tensor([0.6916, 0.7222, 0.6660, 0.6893, 0.6824, 0.7227, 0.7107, 0.6076, 0.7154,
        0.6974, 0.7272, 0.7210, 0.7175, 0.7418, 0.7293, 0.6977],
       device='cuda:0')
percent tensor([0.6230, 0.7268, 0.7910, 0.7967, 0.7917, 0.7540, 0.7081, 0.7006, 0.6581,
        0.6451, 0.6893, 0.7107, 0.6157, 0.6738, 0.6048, 0.6684],
       device='cuda:0')
percent tensor([0.9993, 0.9992, 0.9995, 0.9997, 0.9988, 0.9988, 0.9987, 0.9993, 0.9986,
        0.9990, 0.9995, 0.9995, 0.9989, 0.9981, 0.9991, 0.9991],
       device='cuda:0')
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (2508/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (3709/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (4904/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (6120/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (93.00%) (7338/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (8544/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (9757/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (10953/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (12163/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (13366/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (14573/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (15795/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (16997/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (18215/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (19434/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (20639/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (21837/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (23031/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (24241/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (25452/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (26651/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (27847/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (29044/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (30249/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (31448/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (32664/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (33879/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (35086/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (36303/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (37517/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (38745/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (39958/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (41171/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (42395/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (43604/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (44838/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (46055/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (47228/50000)
# TEST : Loss: (0.3895) | Acc: (88.00%) (8800/10000)
percent tensor([0.4950, 0.5248, 0.5100, 0.4890, 0.5204, 0.5104, 0.5276, 0.4933, 0.5021,
        0.5143, 0.5103, 0.5205, 0.4961, 0.5098, 0.5180, 0.4951],
       device='cuda:0')
percent tensor([0.5435, 0.5378, 0.5034, 0.5324, 0.5058, 0.4838, 0.5245, 0.5460, 0.5834,
        0.5453, 0.5558, 0.5234, 0.5630, 0.6150, 0.5065, 0.5210],
       device='cuda:0')
percent tensor([0.6268, 0.5034, 0.6985, 0.6768, 0.6881, 0.6711, 0.5820, 0.6785, 0.6187,
        0.5813, 0.5714, 0.5945, 0.5350, 0.5630, 0.5746, 0.6363],
       device='cuda:0')
percent tensor([0.6142, 0.6287, 0.5586, 0.5785, 0.5521, 0.6015, 0.6092, 0.5735, 0.5885,
        0.6208, 0.6224, 0.5904, 0.6299, 0.6307, 0.6160, 0.6157],
       device='cuda:0')
percent tensor([0.4422, 0.5588, 0.5955, 0.6648, 0.6163, 0.6447, 0.5629, 0.4897, 0.6174,
        0.5767, 0.6530, 0.6335, 0.5105, 0.7154, 0.5010, 0.5263],
       device='cuda:0')
percent tensor([0.6928, 0.7220, 0.6671, 0.6886, 0.6838, 0.7186, 0.7120, 0.6125, 0.7169,
        0.6981, 0.7276, 0.7225, 0.7170, 0.7405, 0.7311, 0.6970],
       device='cuda:0')
percent tensor([0.6255, 0.7270, 0.7904, 0.7966, 0.7878, 0.7554, 0.7111, 0.6994, 0.6580,
        0.6481, 0.6905, 0.7165, 0.6219, 0.6702, 0.6040, 0.6722],
       device='cuda:0')
percent tensor([0.9993, 0.9991, 0.9994, 0.9996, 0.9987, 0.9989, 0.9987, 0.9993, 0.9987,
        0.9990, 0.9995, 0.9995, 0.9989, 0.9983, 0.9991, 0.9991],
       device='cuda:0')
Epoch: 127 | Batch_idx: 0 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (1325/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (2532/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (3744/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (4939/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (6149/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (7366/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (8589/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (9791/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (11001/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (12220/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (13422/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (14635/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (15852/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (17068/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (18287/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (19504/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (20713/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (21922/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (23117/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (24337/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (25548/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (26771/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (27992/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (29215/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (30425/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (31631/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (32858/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (34085/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (35300/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (36519/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (37744/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (38957/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (40170/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (41395/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (42611/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (43827/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (45036/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (46255/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (47428/50000)
# TEST : Loss: (0.3804) | Acc: (88.00%) (8818/10000)
percent tensor([0.4950, 0.5250, 0.5095, 0.4894, 0.5200, 0.5115, 0.5274, 0.4928, 0.5019,
        0.5138, 0.5105, 0.5196, 0.4960, 0.5098, 0.5186, 0.4953],
       device='cuda:0')
percent tensor([0.5372, 0.5325, 0.4996, 0.5284, 0.5017, 0.4786, 0.5194, 0.5422, 0.5779,
        0.5398, 0.5493, 0.5187, 0.5571, 0.6091, 0.5011, 0.5154],
       device='cuda:0')
percent tensor([0.6242, 0.5022, 0.6954, 0.6766, 0.6858, 0.6720, 0.5793, 0.6770, 0.6129,
        0.5778, 0.5674, 0.5893, 0.5308, 0.5603, 0.5738, 0.6359],
       device='cuda:0')
percent tensor([0.6149, 0.6294, 0.5588, 0.5788, 0.5524, 0.6017, 0.6095, 0.5738, 0.5889,
        0.6210, 0.6229, 0.5904, 0.6309, 0.6307, 0.6159, 0.6161],
       device='cuda:0')
percent tensor([0.4476, 0.5641, 0.6023, 0.6692, 0.6254, 0.6495, 0.5695, 0.4962, 0.6256,
        0.5848, 0.6589, 0.6416, 0.5187, 0.7225, 0.5042, 0.5307],
       device='cuda:0')
percent tensor([0.7003, 0.7283, 0.6753, 0.6927, 0.6912, 0.7213, 0.7204, 0.6208, 0.7256,
        0.7066, 0.7362, 0.7319, 0.7257, 0.7477, 0.7395, 0.7029],
       device='cuda:0')
percent tensor([0.6345, 0.7293, 0.7906, 0.7990, 0.7871, 0.7597, 0.7156, 0.6995, 0.6592,
        0.6492, 0.6905, 0.7224, 0.6310, 0.6707, 0.6087, 0.6787],
       device='cuda:0')
percent tensor([0.9993, 0.9992, 0.9994, 0.9997, 0.9987, 0.9989, 0.9987, 0.9994, 0.9987,
        0.9990, 0.9995, 0.9995, 0.9989, 0.9984, 0.9992, 0.9992],
       device='cuda:0')
Epoch: 128 | Batch_idx: 0 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (94.00%) (1333/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (2560/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (3764/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (4974/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (6181/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (7393/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (8620/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (9825/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (11036/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (12253/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (13467/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (14683/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (15904/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (17115/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (18336/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (19552/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (20775/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (21990/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (23210/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (24424/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (25631/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (26846/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (28069/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (29289/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (30480/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (31691/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (32905/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (34120/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (35335/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (36554/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (37775/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (38986/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (40218/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (41434/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (42656/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (43878/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (45091/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (46308/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (47484/50000)
# TEST : Loss: (0.3751) | Acc: (88.00%) (8840/10000)
percent tensor([0.4960, 0.5265, 0.5101, 0.4904, 0.5211, 0.5134, 0.5286, 0.4936, 0.5031,
        0.5147, 0.5119, 0.5201, 0.4972, 0.5109, 0.5203, 0.4965],
       device='cuda:0')
percent tensor([0.5364, 0.5321, 0.5004, 0.5282, 0.5009, 0.4769, 0.5184, 0.5417, 0.5773,
        0.5402, 0.5486, 0.5193, 0.5569, 0.6083, 0.4995, 0.5149],
       device='cuda:0')
percent tensor([0.6203, 0.4994, 0.6917, 0.6735, 0.6820, 0.6698, 0.5757, 0.6736, 0.6072,
        0.5720, 0.5622, 0.5835, 0.5273, 0.5548, 0.5709, 0.6328],
       device='cuda:0')
percent tensor([0.6223, 0.6379, 0.5641, 0.5846, 0.5572, 0.6078, 0.6168, 0.5794, 0.5952,
        0.6289, 0.6307, 0.5973, 0.6388, 0.6387, 0.6235, 0.6237],
       device='cuda:0')
percent tensor([0.4377, 0.5561, 0.5919, 0.6597, 0.6176, 0.6444, 0.5614, 0.4858, 0.6214,
        0.5796, 0.6531, 0.6333, 0.5112, 0.7235, 0.4927, 0.5230],
       device='cuda:0')
percent tensor([0.7089, 0.7365, 0.6834, 0.6998, 0.6984, 0.7261, 0.7287, 0.6306, 0.7344,
        0.7173, 0.7460, 0.7416, 0.7343, 0.7567, 0.7495, 0.7119],
       device='cuda:0')
percent tensor([0.6346, 0.7302, 0.7899, 0.7997, 0.7874, 0.7614, 0.7174, 0.7008, 0.6614,
        0.6530, 0.6871, 0.7260, 0.6342, 0.6643, 0.6109, 0.6825],
       device='cuda:0')
percent tensor([0.9993, 0.9992, 0.9994, 0.9997, 0.9987, 0.9990, 0.9988, 0.9993, 0.9988,
        0.9990, 0.9996, 0.9995, 0.9990, 0.9984, 0.9991, 0.9991],
       device='cuda:0')
Epoch: 129 | Batch_idx: 0 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (2554/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (3772/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (4996/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (6222/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (7423/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (8635/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (95.00%) (9853/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (11069/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (12280/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (95.00%) (13498/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (14707/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (15929/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (17138/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (18357/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (19572/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (20790/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (95.00%) (22012/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (23225/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (24439/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (25672/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (95.00%) (26895/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (28116/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (29341/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (30551/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (95.00%) (31760/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (32979/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (34193/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (35417/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (36644/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (37867/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (95.00%) (39080/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (40320/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (95.00%) (41530/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (95.00%) (42748/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (95.00%) (43961/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (45190/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (46399/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (47568/50000)
# TEST : Loss: (0.3704) | Acc: (88.00%) (8859/10000)
percent tensor([0.4956, 0.5259, 0.5095, 0.4904, 0.5203, 0.5134, 0.5278, 0.4931, 0.5025,
        0.5139, 0.5115, 0.5190, 0.4968, 0.5105, 0.5200, 0.4962],
       device='cuda:0')
percent tensor([0.5399, 0.5365, 0.5036, 0.5318, 0.5047, 0.4807, 0.5224, 0.5453, 0.5809,
        0.5440, 0.5526, 0.5229, 0.5606, 0.6120, 0.5034, 0.5186],
       device='cuda:0')
percent tensor([0.6206, 0.5017, 0.6928, 0.6750, 0.6844, 0.6714, 0.5778, 0.6757, 0.6072,
        0.5731, 0.5623, 0.5842, 0.5286, 0.5535, 0.5727, 0.6339],
       device='cuda:0')
percent tensor([0.6208, 0.6361, 0.5634, 0.5837, 0.5564, 0.6061, 0.6152, 0.5790, 0.5947,
        0.6272, 0.6293, 0.5963, 0.6380, 0.6370, 0.6214, 0.6217],
       device='cuda:0')
percent tensor([0.4418, 0.5597, 0.5979, 0.6633, 0.6257, 0.6462, 0.5675, 0.4914, 0.6265,
        0.5838, 0.6541, 0.6363, 0.5123, 0.7267, 0.4957, 0.5274],
       device='cuda:0')
percent tensor([0.7047, 0.7322, 0.6789, 0.6928, 0.6922, 0.7193, 0.7252, 0.6255, 0.7316,
        0.7132, 0.7429, 0.7386, 0.7308, 0.7536, 0.7461, 0.7052],
       device='cuda:0')
percent tensor([0.6414, 0.7348, 0.7928, 0.8011, 0.7872, 0.7671, 0.7210, 0.7026, 0.6638,
        0.6581, 0.6894, 0.7310, 0.6391, 0.6690, 0.6129, 0.6879],
       device='cuda:0')
percent tensor([0.9993, 0.9992, 0.9995, 0.9997, 0.9988, 0.9990, 0.9988, 0.9994, 0.9988,
        0.9990, 0.9996, 0.9995, 0.9990, 0.9985, 0.9992, 0.9992],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 130 | Batch_idx: 0 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (95.00%) (2559/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (3758/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (4977/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (6190/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (7408/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (8613/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (9823/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (11035/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (12242/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (13443/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (14637/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (15839/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (17049/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (18256/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (19476/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (20695/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (21907/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (23103/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (24320/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (25530/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (26746/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (27953/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (29167/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (30368/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (31589/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (32794/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (34024/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (35222/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (36411/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (37608/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (38811/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (40013/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (41233/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (42430/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (43624/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (44844/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (46044/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (47207/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_130.pth.tar'
# TEST : Loss: (0.4039) | Acc: (87.00%) (8796/10000)
percent tensor([0.4945, 0.5272, 0.5067, 0.4886, 0.5186, 0.5120, 0.5285, 0.4926, 0.5025,
        0.5140, 0.5122, 0.5175, 0.4964, 0.5133, 0.5196, 0.4963],
       device='cuda:0')
percent tensor([0.5362, 0.5383, 0.4941, 0.5258, 0.4959, 0.4762, 0.5194, 0.5395, 0.5793,
        0.5445, 0.5544, 0.5196, 0.5603, 0.6154, 0.5022, 0.5168],
       device='cuda:0')
percent tensor([0.6173, 0.4884, 0.6878, 0.6676, 0.6840, 0.6717, 0.5722, 0.6717, 0.6046,
        0.5624, 0.5564, 0.5723, 0.5214, 0.5462, 0.5703, 0.6323],
       device='cuda:0')
percent tensor([0.6253, 0.6390, 0.5652, 0.5878, 0.5592, 0.6129, 0.6195, 0.5818, 0.5953,
        0.6265, 0.6297, 0.5936, 0.6382, 0.6362, 0.6249, 0.6267],
       device='cuda:0')
percent tensor([0.4417, 0.5590, 0.5919, 0.6487, 0.6302, 0.6397, 0.5623, 0.4753, 0.6283,
        0.5739, 0.6485, 0.6393, 0.5175, 0.7217, 0.4875, 0.4980],
       device='cuda:0')
percent tensor([0.6955, 0.7266, 0.6947, 0.6990, 0.7020, 0.7170, 0.7303, 0.6345, 0.7344,
        0.7037, 0.7355, 0.7406, 0.7236, 0.7619, 0.7376, 0.6884],
       device='cuda:0')
percent tensor([0.6662, 0.7374, 0.7789, 0.7862, 0.7836, 0.7664, 0.7307, 0.7079, 0.6616,
        0.6793, 0.6829, 0.7162, 0.6586, 0.6532, 0.6205, 0.7149],
       device='cuda:0')
percent tensor([0.9993, 0.9990, 0.9992, 0.9995, 0.9984, 0.9990, 0.9988, 0.9993, 0.9982,
        0.9991, 0.9996, 0.9994, 0.9989, 0.9987, 0.9991, 0.9992],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.3692, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(820.3758, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(825.2001, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1518.7599, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(486.9931, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2243.5347, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4266.3379, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1382.6235, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6181.1792, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11793.2812, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3886.5417, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16435.8574, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (2535/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (3751/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (4948/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (6165/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (7384/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (8597/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (9805/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (11020/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (12251/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (13444/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (14647/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (15849/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (17047/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (18267/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (19479/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (20700/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (21897/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (23114/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (24322/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (25516/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (26728/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (27941/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (29138/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (30362/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (31579/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (32785/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (33990/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (35214/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (36438/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (37645/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (38848/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (40055/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (41253/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (42466/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (43683/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (44887/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (46102/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (47276/50000)
# TEST : Loss: (0.3962) | Acc: (87.00%) (8778/10000)
percent tensor([0.4942, 0.5281, 0.5038, 0.4892, 0.5169, 0.5129, 0.5281, 0.4911, 0.5004,
        0.5134, 0.5117, 0.5158, 0.4957, 0.5150, 0.5204, 0.4968],
       device='cuda:0')
percent tensor([0.5436, 0.5438, 0.5026, 0.5311, 0.5020, 0.4817, 0.5275, 0.5406, 0.5828,
        0.5485, 0.5567, 0.5226, 0.5622, 0.6189, 0.5065, 0.5199],
       device='cuda:0')
percent tensor([0.6224, 0.4950, 0.6805, 0.6659, 0.6750, 0.6702, 0.5740, 0.6735, 0.6162,
        0.5721, 0.5669, 0.5696, 0.5268, 0.5562, 0.5709, 0.6390],
       device='cuda:0')
percent tensor([0.6213, 0.6362, 0.5641, 0.5848, 0.5559, 0.6087, 0.6183, 0.5787, 0.5942,
        0.6273, 0.6244, 0.5989, 0.6401, 0.6367, 0.6218, 0.6227],
       device='cuda:0')
percent tensor([0.4492, 0.5678, 0.5715, 0.6739, 0.6144, 0.6490, 0.5505, 0.4652, 0.6085,
        0.5714, 0.6455, 0.6129, 0.5024, 0.7194, 0.5016, 0.5313],
       device='cuda:0')
percent tensor([0.6969, 0.7273, 0.6840, 0.7046, 0.6878, 0.7236, 0.7187, 0.6247, 0.7261,
        0.7148, 0.7298, 0.7423, 0.7236, 0.7638, 0.7383, 0.6963],
       device='cuda:0')
percent tensor([0.6291, 0.7237, 0.7691, 0.7831, 0.7722, 0.7673, 0.7086, 0.6805, 0.6203,
        0.6420, 0.6752, 0.7202, 0.6231, 0.6589, 0.5928, 0.6962],
       device='cuda:0')
percent tensor([0.9994, 0.9989, 0.9993, 0.9996, 0.9989, 0.9991, 0.9988, 0.9992, 0.9983,
        0.9992, 0.9995, 0.9996, 0.9989, 0.9987, 0.9991, 0.9991],
       device='cuda:0')
Epoch: 132 | Batch_idx: 0 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (93.00%) (1323/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (2534/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (3746/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (4969/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (6192/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (7400/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (8599/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (9811/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (11031/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (12252/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (13454/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (14676/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (15884/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (17098/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (18310/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (19531/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (20735/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (21955/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (23176/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (24400/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (25612/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (26818/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (28031/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (29250/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (30459/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (31659/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (32882/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (34101/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (35317/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (36539/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (37748/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (38967/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (40178/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (41393/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (42602/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (43813/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (45032/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (46217/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (47388/50000)
# TEST : Loss: (0.4016) | Acc: (87.00%) (8791/10000)
percent tensor([0.4949, 0.5247, 0.5123, 0.4894, 0.5229, 0.5118, 0.5290, 0.4937, 0.5029,
        0.5143, 0.5103, 0.5219, 0.4957, 0.5099, 0.5185, 0.4949],
       device='cuda:0')
percent tensor([0.5417, 0.5439, 0.4972, 0.5279, 0.4986, 0.4832, 0.5255, 0.5438, 0.5820,
        0.5471, 0.5575, 0.5218, 0.5624, 0.6229, 0.5064, 0.5209],
       device='cuda:0')
percent tensor([0.6246, 0.4942, 0.6954, 0.6746, 0.6854, 0.6686, 0.5721, 0.6821, 0.6180,
        0.5723, 0.5696, 0.5788, 0.5276, 0.5488, 0.5696, 0.6372],
       device='cuda:0')
percent tensor([0.6224, 0.6341, 0.5644, 0.5843, 0.5578, 0.6086, 0.6172, 0.5775, 0.5909,
        0.6246, 0.6244, 0.5975, 0.6374, 0.6341, 0.6229, 0.6219],
       device='cuda:0')
percent tensor([0.4439, 0.5735, 0.6029, 0.6601, 0.6305, 0.6468, 0.5644, 0.4845, 0.5988,
        0.5754, 0.6359, 0.6246, 0.5121, 0.7256, 0.5097, 0.5288],
       device='cuda:0')
percent tensor([0.6960, 0.7196, 0.6798, 0.6958, 0.6962, 0.7190, 0.7246, 0.6194, 0.7254,
        0.7069, 0.7325, 0.7399, 0.7271, 0.7503, 0.7405, 0.6886],
       device='cuda:0')
percent tensor([0.6427, 0.7224, 0.7880, 0.7760, 0.7815, 0.7589, 0.7040, 0.6899, 0.6331,
        0.6597, 0.6890, 0.7150, 0.6355, 0.6575, 0.6021, 0.6960],
       device='cuda:0')
percent tensor([0.9994, 0.9990, 0.9993, 0.9995, 0.9989, 0.9991, 0.9987, 0.9991, 0.9985,
        0.9990, 0.9996, 0.9996, 0.9990, 0.9984, 0.9990, 0.9993],
       device='cuda:0')
Epoch: 133 | Batch_idx: 0 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (2572/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (3781/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (4992/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (6203/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (7419/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (94.00%) (8632/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (9843/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (11062/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (12280/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (95.00%) (13505/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (95.00%) (14729/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (95.00%) (15941/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (17162/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (95.00%) (18371/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (19583/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (20782/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (22013/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (23233/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (24441/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (25644/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (26843/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (28063/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (29271/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (30475/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (31690/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (32911/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (34119/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (35318/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (36536/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (37761/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (38968/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (40183/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (41414/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (42633/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (43838/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (45049/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (46263/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (47417/50000)
# TEST : Loss: (0.3793) | Acc: (88.00%) (8839/10000)
percent tensor([0.4942, 0.5261, 0.5074, 0.4901, 0.5192, 0.5118, 0.5278, 0.4932, 0.5007,
        0.5137, 0.5108, 0.5181, 0.4958, 0.5115, 0.5191, 0.4962],
       device='cuda:0')
percent tensor([0.5452, 0.5415, 0.4946, 0.5282, 0.4983, 0.4830, 0.5252, 0.5410, 0.5858,
        0.5453, 0.5602, 0.5184, 0.5647, 0.6213, 0.5062, 0.5242],
       device='cuda:0')
percent tensor([0.6134, 0.4953, 0.6943, 0.6699, 0.6864, 0.6699, 0.5705, 0.6702, 0.6019,
        0.5699, 0.5569, 0.5807, 0.5132, 0.5533, 0.5687, 0.6315],
       device='cuda:0')
percent tensor([0.6263, 0.6366, 0.5651, 0.5857, 0.5574, 0.6098, 0.6207, 0.5812, 0.5985,
        0.6299, 0.6291, 0.5961, 0.6450, 0.6353, 0.6243, 0.6249],
       device='cuda:0')
percent tensor([0.4496, 0.5650, 0.5998, 0.6718, 0.6104, 0.6360, 0.5683, 0.4706, 0.6226,
        0.5913, 0.6704, 0.6362, 0.5191, 0.7390, 0.5038, 0.5245],
       device='cuda:0')
percent tensor([0.6963, 0.7235, 0.6840, 0.7073, 0.6918, 0.7164, 0.7251, 0.6344, 0.7325,
        0.7026, 0.7328, 0.7418, 0.7334, 0.7511, 0.7402, 0.6988],
       device='cuda:0')
percent tensor([0.6329, 0.7121, 0.7885, 0.7689, 0.7785, 0.7480, 0.7003, 0.7023, 0.6279,
        0.6552, 0.6951, 0.7102, 0.6184, 0.6517, 0.6005, 0.6815],
       device='cuda:0')
percent tensor([0.9994, 0.9990, 0.9994, 0.9996, 0.9990, 0.9990, 0.9987, 0.9993, 0.9984,
        0.9989, 0.9996, 0.9996, 0.9986, 0.9984, 0.9993, 0.9993],
       device='cuda:0')
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (2547/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (94.00%) (3766/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (4993/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (6209/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (7432/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (8649/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (9859/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (11071/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (12300/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (13524/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (14748/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (15961/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (17182/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (18386/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (19592/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (20820/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (22036/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (23252/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (24473/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (25694/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (26906/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (28126/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (29351/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (30560/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (31768/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (32985/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (34209/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (35424/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (36640/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (37861/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (39072/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (40297/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (41507/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (42721/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (43939/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (45135/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (46342/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (94.00%) (47495/50000)
# TEST : Loss: (0.3797) | Acc: (88.00%) (8801/10000)
percent tensor([0.4942, 0.5264, 0.5085, 0.4897, 0.5208, 0.5130, 0.5289, 0.4940, 0.5021,
        0.5144, 0.5108, 0.5200, 0.4955, 0.5129, 0.5200, 0.4964],
       device='cuda:0')
percent tensor([0.5414, 0.5355, 0.4961, 0.5340, 0.4995, 0.4805, 0.5193, 0.5429, 0.5793,
        0.5465, 0.5546, 0.5171, 0.5630, 0.6104, 0.5013, 0.5204],
       device='cuda:0')
percent tensor([0.6278, 0.4940, 0.7052, 0.6836, 0.6964, 0.6741, 0.5751, 0.6812, 0.6193,
        0.5740, 0.5691, 0.5928, 0.5294, 0.5433, 0.5742, 0.6361],
       device='cuda:0')
percent tensor([0.6225, 0.6396, 0.5532, 0.5802, 0.5516, 0.6084, 0.6231, 0.5784, 0.5949,
        0.6289, 0.6271, 0.5935, 0.6401, 0.6436, 0.6256, 0.6239],
       device='cuda:0')
percent tensor([0.4542, 0.5671, 0.6036, 0.6590, 0.6258, 0.6478, 0.5666, 0.4868, 0.6132,
        0.5803, 0.6608, 0.6404, 0.5378, 0.7228, 0.4992, 0.5155],
       device='cuda:0')
percent tensor([0.6972, 0.7322, 0.6684, 0.6802, 0.6842, 0.7190, 0.7344, 0.6328, 0.7338,
        0.7069, 0.7371, 0.7353, 0.7351, 0.7733, 0.7429, 0.7021],
       device='cuda:0')
percent tensor([0.6596, 0.7484, 0.7860, 0.7876, 0.7748, 0.7492, 0.6911, 0.7025, 0.6290,
        0.6739, 0.7091, 0.7247, 0.6614, 0.6800, 0.6005, 0.6823],
       device='cuda:0')
percent tensor([0.9994, 0.9990, 0.9993, 0.9995, 0.9990, 0.9991, 0.9988, 0.9994, 0.9983,
        0.9991, 0.9996, 0.9994, 0.9989, 0.9980, 0.9991, 0.9992],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (2542/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (3736/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (4921/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (6118/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (7319/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (8511/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (9713/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (10918/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (12098/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (13286/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (14493/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (15680/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (16895/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (18107/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (19300/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (20504/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (21712/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (22919/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (24117/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (25328/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (26530/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (27732/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (28931/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (30125/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (31340/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (32534/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (33730/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (34924/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1800) |  Loss2: (0.0000) | Acc: (93.00%) (36122/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (37330/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (38539/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (39750/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (40961/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (42171/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (43364/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (44576/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (45781/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (46948/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_135.pth.tar'
# TEST : Loss: (0.4034) | Acc: (87.00%) (8770/10000)
percent tensor([0.4961, 0.5277, 0.5103, 0.4925, 0.5225, 0.5166, 0.5304, 0.4967, 0.5036,
        0.5151, 0.5124, 0.5209, 0.4968, 0.5146, 0.5223, 0.4988],
       device='cuda:0')
percent tensor([0.5570, 0.5605, 0.4987, 0.5449, 0.5028, 0.4944, 0.5385, 0.5504, 0.5974,
        0.5666, 0.5780, 0.5283, 0.5828, 0.6393, 0.5185, 0.5394],
       device='cuda:0')
percent tensor([0.6280, 0.5038, 0.6854, 0.6649, 0.6784, 0.6706, 0.5757, 0.6553, 0.6066,
        0.5796, 0.5788, 0.5856, 0.5412, 0.5397, 0.5785, 0.6348],
       device='cuda:0')
percent tensor([0.6323, 0.6510, 0.5618, 0.5909, 0.5563, 0.6197, 0.6341, 0.5876, 0.6008,
        0.6401, 0.6371, 0.6022, 0.6492, 0.6533, 0.6360, 0.6381],
       device='cuda:0')
percent tensor([0.4773, 0.5606, 0.6227, 0.6746, 0.6461, 0.6424, 0.5782, 0.5167, 0.6380,
        0.5763, 0.6723, 0.6607, 0.5469, 0.7274, 0.5029, 0.5235],
       device='cuda:0')
percent tensor([0.6622, 0.6891, 0.6493, 0.6620, 0.6641, 0.6921, 0.6957, 0.6135, 0.6968,
        0.6620, 0.6954, 0.7029, 0.6853, 0.7307, 0.7032, 0.6695],
       device='cuda:0')
percent tensor([0.7048, 0.7728, 0.7962, 0.7917, 0.7753, 0.7527, 0.7226, 0.7277, 0.6661,
        0.7022, 0.7499, 0.7426, 0.7089, 0.7111, 0.6421, 0.7017],
       device='cuda:0')
percent tensor([0.9995, 0.9990, 0.9995, 0.9995, 0.9989, 0.9989, 0.9990, 0.9995, 0.9986,
        0.9991, 0.9996, 0.9995, 0.9992, 0.9984, 0.9991, 0.9993],
       device='cuda:0')
Epoch: 136 | Batch_idx: 0 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (2547/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (3752/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (4970/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (6192/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (7393/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (8607/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (9816/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (11034/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (12258/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (13467/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (14682/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (15891/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (17103/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (18313/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (19532/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (20739/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (21941/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (23133/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (24334/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (25550/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (26751/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (27964/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (29176/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (30390/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (31600/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (32818/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (34029/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (35252/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (36464/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (37666/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (38882/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (40092/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (41303/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (42508/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (43726/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (44947/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (46158/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (47337/50000)
# TEST : Loss: (0.3869) | Acc: (88.00%) (8809/10000)
percent tensor([0.4961, 0.5264, 0.5126, 0.4938, 0.5240, 0.5171, 0.5300, 0.4977, 0.5029,
        0.5149, 0.5112, 0.5221, 0.4964, 0.5129, 0.5221, 0.4985],
       device='cuda:0')
percent tensor([0.5548, 0.5586, 0.4945, 0.5435, 0.4971, 0.4916, 0.5350, 0.5457, 0.5944,
        0.5646, 0.5759, 0.5250, 0.5808, 0.6394, 0.5149, 0.5376],
       device='cuda:0')
percent tensor([0.6335, 0.5051, 0.6890, 0.6685, 0.6806, 0.6765, 0.5781, 0.6576, 0.6112,
        0.5842, 0.5846, 0.5904, 0.5448, 0.5463, 0.5806, 0.6402],
       device='cuda:0')
percent tensor([0.6287, 0.6490, 0.5585, 0.5867, 0.5516, 0.6176, 0.6301, 0.5828, 0.5952,
        0.6380, 0.6338, 0.5988, 0.6469, 0.6483, 0.6337, 0.6355],
       device='cuda:0')
percent tensor([0.4795, 0.5652, 0.6227, 0.6783, 0.6501, 0.6463, 0.5822, 0.5191, 0.6410,
        0.5806, 0.6750, 0.6593, 0.5478, 0.7308, 0.5088, 0.5275],
       device='cuda:0')
percent tensor([0.6609, 0.6872, 0.6555, 0.6663, 0.6713, 0.6935, 0.6952, 0.6180, 0.6958,
        0.6596, 0.6935, 0.7029, 0.6806, 0.7254, 0.7023, 0.6689],
       device='cuda:0')
percent tensor([0.7086, 0.7753, 0.7894, 0.7853, 0.7720, 0.7561, 0.7279, 0.7188, 0.6722,
        0.7044, 0.7575, 0.7404, 0.7119, 0.7178, 0.6437, 0.7012],
       device='cuda:0')
percent tensor([0.9995, 0.9990, 0.9994, 0.9995, 0.9989, 0.9989, 0.9991, 0.9994, 0.9986,
        0.9991, 0.9996, 0.9995, 0.9991, 0.9984, 0.9991, 0.9993],
       device='cuda:0')
Epoch: 137 | Batch_idx: 0 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (2547/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (3763/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (95.00%) (4996/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (6198/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (7395/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (8617/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (9836/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (11038/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (12251/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (13469/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (14684/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (15900/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (17128/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (18349/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (19563/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (20773/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (21978/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (23203/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (24428/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (25643/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (26862/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (28078/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (29296/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (95.00%) (30522/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (95.00%) (31742/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (32946/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (34151/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (35357/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (36581/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (37792/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (38997/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (40219/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (41434/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (42646/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (43866/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (45079/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (46301/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (47469/50000)
# TEST : Loss: (0.3782) | Acc: (88.00%) (8802/10000)
percent tensor([0.4971, 0.5271, 0.5137, 0.4947, 0.5252, 0.5184, 0.5310, 0.4988, 0.5041,
        0.5158, 0.5121, 0.5232, 0.4972, 0.5137, 0.5232, 0.4996],
       device='cuda:0')
percent tensor([0.5518, 0.5554, 0.4931, 0.5424, 0.4933, 0.4885, 0.5316, 0.5435, 0.5927,
        0.5621, 0.5736, 0.5231, 0.5784, 0.6386, 0.5112, 0.5346],
       device='cuda:0')
percent tensor([0.6359, 0.5029, 0.6939, 0.6724, 0.6851, 0.6801, 0.5788, 0.6603, 0.6149,
        0.5860, 0.5869, 0.5942, 0.5443, 0.5486, 0.5809, 0.6419],
       device='cuda:0')
percent tensor([0.6249, 0.6459, 0.5564, 0.5839, 0.5481, 0.6145, 0.6255, 0.5794, 0.5914,
        0.6345, 0.6297, 0.5957, 0.6446, 0.6431, 0.6304, 0.6318],
       device='cuda:0')
percent tensor([0.4660, 0.5579, 0.6132, 0.6708, 0.6428, 0.6378, 0.5735, 0.5078, 0.6372,
        0.5747, 0.6756, 0.6520, 0.5355, 0.7259, 0.4969, 0.5171],
       device='cuda:0')
percent tensor([0.6613, 0.6861, 0.6617, 0.6716, 0.6777, 0.6946, 0.6960, 0.6238, 0.6962,
        0.6594, 0.6931, 0.7034, 0.6776, 0.7233, 0.7016, 0.6693],
       device='cuda:0')
percent tensor([0.7138, 0.7803, 0.7891, 0.7883, 0.7741, 0.7598, 0.7370, 0.7199, 0.6777,
        0.7077, 0.7634, 0.7433, 0.7146, 0.7296, 0.6486, 0.7091],
       device='cuda:0')
percent tensor([0.9995, 0.9990, 0.9994, 0.9995, 0.9990, 0.9988, 0.9990, 0.9994, 0.9986,
        0.9991, 0.9996, 0.9995, 0.9991, 0.9984, 0.9991, 0.9993],
       device='cuda:0')
Epoch: 138 | Batch_idx: 0 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (2554/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (4989/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (6206/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (7421/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (8642/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (9856/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (11067/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (12288/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (13500/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (14719/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (15938/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (17156/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (18372/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (19600/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (20812/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (22027/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (23236/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (24454/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (25684/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (26898/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (28112/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (29337/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (30554/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (31786/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (33001/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (34219/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (35431/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (36654/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (37876/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (39100/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (40307/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (41535/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (42765/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (43989/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (45204/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (46427/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (47603/50000)
# TEST : Loss: (0.3744) | Acc: (88.00%) (8827/10000)
percent tensor([0.4958, 0.5259, 0.5142, 0.4940, 0.5255, 0.5184, 0.5302, 0.4976, 0.5024,
        0.5145, 0.5105, 0.5228, 0.4956, 0.5118, 0.5224, 0.4981],
       device='cuda:0')
percent tensor([0.5533, 0.5573, 0.4944, 0.5437, 0.4947, 0.4894, 0.5333, 0.5444, 0.5955,
        0.5641, 0.5762, 0.5253, 0.5810, 0.6409, 0.5124, 0.5359],
       device='cuda:0')
percent tensor([0.6328, 0.4970, 0.6963, 0.6730, 0.6888, 0.6801, 0.5775, 0.6627, 0.6130,
        0.5828, 0.5827, 0.5936, 0.5368, 0.5439, 0.5778, 0.6394],
       device='cuda:0')
percent tensor([0.6262, 0.6475, 0.5570, 0.5843, 0.5481, 0.6150, 0.6271, 0.5803, 0.5926,
        0.6362, 0.6314, 0.5974, 0.6467, 0.6442, 0.6318, 0.6335],
       device='cuda:0')
percent tensor([0.4662, 0.5647, 0.6110, 0.6723, 0.6396, 0.6409, 0.5754, 0.5026, 0.6413,
        0.5802, 0.6844, 0.6553, 0.5410, 0.7352, 0.4998, 0.5174],
       device='cuda:0')
percent tensor([0.6630, 0.6876, 0.6657, 0.6749, 0.6816, 0.6966, 0.6980, 0.6275, 0.6978,
        0.6611, 0.6945, 0.7048, 0.6788, 0.7238, 0.7025, 0.6712],
       device='cuda:0')
percent tensor([0.7067, 0.7732, 0.7804, 0.7798, 0.7653, 0.7528, 0.7299, 0.7082, 0.6700,
        0.6996, 0.7573, 0.7324, 0.7051, 0.7234, 0.6388, 0.7009],
       device='cuda:0')
percent tensor([0.9995, 0.9991, 0.9994, 0.9996, 0.9990, 0.9989, 0.9991, 0.9994, 0.9987,
        0.9992, 0.9997, 0.9996, 0.9991, 0.9986, 0.9992, 0.9993],
       device='cuda:0')
Epoch: 139 | Batch_idx: 0 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (2555/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (3782/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (6218/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (7438/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (8656/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (9880/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (11094/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (12313/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (13526/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (14742/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (15963/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (17177/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (18402/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (19608/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (20825/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (22055/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (23261/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (24484/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (25701/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (26923/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (28141/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (29365/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (30589/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (31795/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (33022/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (34238/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (35461/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (36675/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (37896/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (39124/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (40348/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (41569/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (42793/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (44029/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (45259/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (46472/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (47645/50000)
# TEST : Loss: (0.3663) | Acc: (88.00%) (8841/10000)
percent tensor([0.4973, 0.5275, 0.5152, 0.4960, 0.5266, 0.5201, 0.5317, 0.4995, 0.5041,
        0.5158, 0.5121, 0.5237, 0.4971, 0.5138, 0.5243, 0.5000],
       device='cuda:0')
percent tensor([0.5499, 0.5541, 0.4930, 0.5415, 0.4918, 0.4869, 0.5300, 0.5413, 0.5923,
        0.5615, 0.5730, 0.5234, 0.5778, 0.6377, 0.5093, 0.5328],
       device='cuda:0')
percent tensor([0.6400, 0.5037, 0.7015, 0.6784, 0.6936, 0.6862, 0.5846, 0.6690, 0.6206,
        0.5897, 0.5905, 0.5998, 0.5439, 0.5530, 0.5847, 0.6455],
       device='cuda:0')
percent tensor([0.6334, 0.6540, 0.5645, 0.5913, 0.5548, 0.6218, 0.6338, 0.5878, 0.5992,
        0.6433, 0.6377, 0.6047, 0.6548, 0.6489, 0.6390, 0.6406],
       device='cuda:0')
percent tensor([0.4635, 0.5659, 0.6093, 0.6718, 0.6395, 0.6399, 0.5762, 0.5002, 0.6370,
        0.5795, 0.6839, 0.6525, 0.5342, 0.7345, 0.4994, 0.5183],
       device='cuda:0')
percent tensor([0.6669, 0.6922, 0.6718, 0.6816, 0.6880, 0.7016, 0.7020, 0.6332, 0.7011,
        0.6651, 0.6983, 0.7083, 0.6813, 0.7267, 0.7057, 0.6761],
       device='cuda:0')
percent tensor([0.7097, 0.7719, 0.7802, 0.7817, 0.7682, 0.7565, 0.7315, 0.7084, 0.6677,
        0.6962, 0.7573, 0.7298, 0.7012, 0.7251, 0.6353, 0.7053],
       device='cuda:0')
percent tensor([0.9995, 0.9991, 0.9994, 0.9996, 0.9990, 0.9989, 0.9991, 0.9994, 0.9986,
        0.9992, 0.9997, 0.9996, 0.9991, 0.9985, 0.9992, 0.9993],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 140 | Batch_idx: 0 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (2562/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (3780/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (5013/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (6237/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (7458/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (8651/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (9867/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (11086/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (12301/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (13520/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (14732/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (15942/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (17175/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (18391/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (19609/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (20824/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (22039/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (23248/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (24438/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (25653/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (26865/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (28081/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (29293/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (30500/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (31704/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (32921/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (34120/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (35332/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (36558/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (37765/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (38967/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (40186/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (41387/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (42593/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (43813/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (45012/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (46220/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (47382/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_140.pth.tar'
# TEST : Loss: (0.4746) | Acc: (85.00%) (8592/10000)
percent tensor([0.4981, 0.5279, 0.5150, 0.4970, 0.5260, 0.5186, 0.5313, 0.4993, 0.5033,
        0.5161, 0.5121, 0.5232, 0.4980, 0.5133, 0.5239, 0.4997],
       device='cuda:0')
percent tensor([0.5529, 0.5526, 0.4916, 0.5323, 0.4951, 0.4932, 0.5302, 0.5369, 0.5914,
        0.5565, 0.5703, 0.5204, 0.5744, 0.6387, 0.5122, 0.5291],
       device='cuda:0')
percent tensor([0.6299, 0.5084, 0.6976, 0.6751, 0.6883, 0.6822, 0.5909, 0.6719, 0.6224,
        0.5860, 0.5871, 0.5883, 0.5304, 0.5772, 0.5810, 0.6478],
       device='cuda:0')
percent tensor([0.6308, 0.6517, 0.5594, 0.5871, 0.5525, 0.6156, 0.6277, 0.5816, 0.6006,
        0.6423, 0.6396, 0.6026, 0.6614, 0.6465, 0.6354, 0.6350],
       device='cuda:0')
percent tensor([0.4672, 0.5909, 0.6048, 0.6951, 0.6227, 0.6441, 0.5859, 0.5113, 0.6448,
        0.6081, 0.7035, 0.6441, 0.5283, 0.7650, 0.5275, 0.5407],
       device='cuda:0')
percent tensor([0.6664, 0.6974, 0.6731, 0.6909, 0.6881, 0.7052, 0.6998, 0.6349, 0.6921,
        0.6721, 0.7029, 0.7152, 0.6838, 0.7308, 0.7133, 0.6813],
       device='cuda:0')
percent tensor([0.6862, 0.7720, 0.7914, 0.7950, 0.7734, 0.7837, 0.7438, 0.7200, 0.6639,
        0.6866, 0.7285, 0.6963, 0.6699, 0.6949, 0.6312, 0.7163],
       device='cuda:0')
percent tensor([0.9993, 0.9993, 0.9994, 0.9996, 0.9990, 0.9992, 0.9991, 0.9994, 0.9989,
        0.9992, 0.9996, 0.9996, 0.9991, 0.9993, 0.9994, 0.9993],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.9641, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.8253, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.1838, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1517.8481, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(485.3258, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2249.0466, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4264.0835, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1377.6647, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6194.4233, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11760.1572, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3871.4658, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16369.9141, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (2559/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (94.00%) (3768/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (94.00%) (4984/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (6205/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (7427/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (8637/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (94.00%) (9845/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (94.00%) (11062/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (94.00%) (12279/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (13489/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (14710/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (15924/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (94.00%) (17138/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (94.00%) (18361/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (94.00%) (19574/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (20795/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (22014/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (23234/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (24456/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (25681/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (26895/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (28116/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (29337/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (30556/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (31768/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (32984/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (34206/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (35427/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (36651/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (37869/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (39071/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (40294/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (41508/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (42717/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (43946/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (45152/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (46361/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (47537/50000)
# TEST : Loss: (0.3826) | Acc: (88.00%) (8852/10000)
percent tensor([0.4986, 0.5281, 0.5138, 0.4974, 0.5258, 0.5189, 0.5302, 0.4995, 0.5041,
        0.5158, 0.5129, 0.5216, 0.4987, 0.5127, 0.5240, 0.5006],
       device='cuda:0')
percent tensor([0.5502, 0.5506, 0.4978, 0.5312, 0.4921, 0.4885, 0.5276, 0.5400, 0.5867,
        0.5570, 0.5685, 0.5266, 0.5724, 0.6300, 0.5088, 0.5281],
       device='cuda:0')
percent tensor([0.6292, 0.5038, 0.6934, 0.6752, 0.6859, 0.6818, 0.5840, 0.6715, 0.6238,
        0.5825, 0.5842, 0.5878, 0.5326, 0.5697, 0.5784, 0.6462],
       device='cuda:0')
percent tensor([0.6348, 0.6528, 0.5658, 0.5890, 0.5589, 0.6170, 0.6324, 0.5869, 0.6010,
        0.6416, 0.6387, 0.6090, 0.6607, 0.6405, 0.6349, 0.6371],
       device='cuda:0')
percent tensor([0.4872, 0.5849, 0.6143, 0.6907, 0.6361, 0.6564, 0.5729, 0.5017, 0.6274,
        0.6024, 0.6997, 0.6549, 0.5391, 0.7338, 0.5204, 0.5298],
       device='cuda:0')
percent tensor([0.6705, 0.6943, 0.6780, 0.6924, 0.6936, 0.6962, 0.6989, 0.6330, 0.6965,
        0.6746, 0.6949, 0.7033, 0.6846, 0.7158, 0.7095, 0.6774],
       device='cuda:0')
percent tensor([0.7036, 0.7718, 0.7860, 0.7785, 0.7668, 0.7823, 0.7347, 0.7035, 0.6842,
        0.7128, 0.7527, 0.7266, 0.6769, 0.7200, 0.6516, 0.7100],
       device='cuda:0')
percent tensor([0.9996, 0.9993, 0.9992, 0.9996, 0.9989, 0.9990, 0.9991, 0.9995, 0.9989,
        0.9991, 0.9997, 0.9996, 0.9990, 0.9986, 0.9993, 0.9993],
       device='cuda:0')
Epoch: 142 | Batch_idx: 0 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (3809/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (5033/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (6247/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (7449/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (8677/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (9904/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (11123/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (12349/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (13579/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (14805/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (16040/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (17264/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (18476/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (19694/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (20923/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (22131/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (23354/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (24573/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (25797/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (27003/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (28225/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (29455/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (30672/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (31891/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (33109/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (34314/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (35534/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (36763/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (37995/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (39204/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (40435/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (41662/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (42882/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (44095/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (45310/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (46533/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (47701/50000)
# TEST : Loss: (0.4095) | Acc: (87.00%) (8756/10000)
percent tensor([0.4981, 0.5267, 0.5190, 0.4975, 0.5291, 0.5183, 0.5321, 0.5009, 0.5062,
        0.5167, 0.5126, 0.5260, 0.4982, 0.5120, 0.5230, 0.4997],
       device='cuda:0')
percent tensor([0.5458, 0.5466, 0.4973, 0.5333, 0.4934, 0.4878, 0.5258, 0.5402, 0.5898,
        0.5535, 0.5653, 0.5294, 0.5691, 0.6246, 0.5073, 0.5230],
       device='cuda:0')
percent tensor([0.6322, 0.5024, 0.6917, 0.6759, 0.6825, 0.6840, 0.5822, 0.6713, 0.6177,
        0.5855, 0.5859, 0.5849, 0.5371, 0.5637, 0.5800, 0.6519],
       device='cuda:0')
percent tensor([0.6358, 0.6542, 0.5613, 0.5897, 0.5581, 0.6219, 0.6339, 0.5862, 0.6025,
        0.6431, 0.6385, 0.6033, 0.6594, 0.6497, 0.6368, 0.6385],
       device='cuda:0')
percent tensor([0.4679, 0.6017, 0.6108, 0.6765, 0.6308, 0.6516, 0.5913, 0.4993, 0.6208,
        0.5983, 0.6947, 0.6481, 0.5322, 0.7404, 0.5191, 0.5238],
       device='cuda:0')
percent tensor([0.6732, 0.6957, 0.6713, 0.6934, 0.6966, 0.7036, 0.7091, 0.6311, 0.6974,
        0.6725, 0.6963, 0.7104, 0.6838, 0.7252, 0.7099, 0.6800],
       device='cuda:0')
percent tensor([0.6936, 0.7622, 0.7919, 0.7770, 0.7809, 0.7772, 0.7360, 0.7160, 0.6697,
        0.6768, 0.7255, 0.7100, 0.6694, 0.7142, 0.6459, 0.7290],
       device='cuda:0')
percent tensor([0.9993, 0.9992, 0.9992, 0.9995, 0.9988, 0.9985, 0.9989, 0.9995, 0.9986,
        0.9992, 0.9996, 0.9995, 0.9992, 0.9989, 0.9994, 0.9990],
       device='cuda:0')
Epoch: 143 | Batch_idx: 0 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (95.00%) (2558/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (3773/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (94.00%) (4984/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (6210/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (7427/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (8657/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (9880/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (11094/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (12314/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (13529/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (14756/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (15981/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (17213/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (18431/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (19649/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (20856/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (22078/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (23305/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (24519/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (25743/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (26951/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (28176/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (29396/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (30621/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (31834/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (33049/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (34266/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (35483/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (36703/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (37924/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (39146/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (40358/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (41588/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (42790/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (44004/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (45233/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (46449/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (47630/50000)
# TEST : Loss: (0.3999) | Acc: (88.00%) (8816/10000)
percent tensor([0.4993, 0.5279, 0.5129, 0.4972, 0.5238, 0.5175, 0.5300, 0.4986, 0.5039,
        0.5161, 0.5126, 0.5213, 0.4991, 0.5129, 0.5236, 0.5006],
       device='cuda:0')
percent tensor([0.5481, 0.5454, 0.5051, 0.5313, 0.5019, 0.4856, 0.5289, 0.5456, 0.5864,
        0.5539, 0.5635, 0.5342, 0.5689, 0.6240, 0.5057, 0.5241],
       device='cuda:0')
percent tensor([0.6199, 0.4973, 0.6903, 0.6650, 0.6824, 0.6751, 0.5769, 0.6685, 0.6228,
        0.5808, 0.5785, 0.5799, 0.5278, 0.5616, 0.5768, 0.6402],
       device='cuda:0')
percent tensor([0.6396, 0.6525, 0.5604, 0.5865, 0.5540, 0.6245, 0.6288, 0.5838, 0.5977,
        0.6392, 0.6414, 0.6046, 0.6635, 0.6420, 0.6376, 0.6393],
       device='cuda:0')
percent tensor([0.4517, 0.5672, 0.6090, 0.6820, 0.6230, 0.6171, 0.5566, 0.4910, 0.6180,
        0.6080, 0.6690, 0.6547, 0.5036, 0.7311, 0.4982, 0.5178],
       device='cuda:0')
percent tensor([0.6712, 0.6971, 0.6751, 0.6967, 0.6853, 0.6974, 0.6920, 0.6252, 0.6936,
        0.6820, 0.7030, 0.7093, 0.6898, 0.7232, 0.7063, 0.6791],
       device='cuda:0')
percent tensor([0.6740, 0.7499, 0.7957, 0.7812, 0.7877, 0.7701, 0.7425, 0.7057, 0.6911,
        0.6841, 0.7024, 0.7115, 0.6589, 0.7123, 0.6495, 0.7033],
       device='cuda:0')
percent tensor([0.9994, 0.9992, 0.9996, 0.9996, 0.9990, 0.9991, 0.9992, 0.9996, 0.9987,
        0.9993, 0.9996, 0.9996, 0.9991, 0.9987, 0.9991, 0.9992],
       device='cuda:0')
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (3789/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (5012/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (6246/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (7471/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (8703/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (9928/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (11158/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (12397/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (13606/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (14832/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (16059/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (17282/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (18505/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (19719/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (20947/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (22170/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (23381/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (24606/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (25825/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (27045/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (28264/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (29494/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (30709/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (31935/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (33159/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (34377/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (35583/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (36817/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (38048/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (39267/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (40485/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (41709/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (42906/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (44126/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (45340/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (46549/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (47732/50000)
# TEST : Loss: (0.3795) | Acc: (88.00%) (8839/10000)
percent tensor([0.5001, 0.5266, 0.5172, 0.4976, 0.5283, 0.5214, 0.5309, 0.4989, 0.5050,
        0.5160, 0.5131, 0.5249, 0.4996, 0.5101, 0.5242, 0.5008],
       device='cuda:0')
percent tensor([0.5473, 0.5526, 0.5025, 0.5390, 0.4976, 0.4899, 0.5327, 0.5449, 0.5863,
        0.5569, 0.5679, 0.5309, 0.5686, 0.6384, 0.5118, 0.5297],
       device='cuda:0')
percent tensor([0.6382, 0.5038, 0.6966, 0.6661, 0.6874, 0.6852, 0.5855, 0.6704, 0.6272,
        0.5871, 0.5887, 0.5888, 0.5404, 0.5735, 0.5820, 0.6458],
       device='cuda:0')
percent tensor([0.6324, 0.6497, 0.5633, 0.5871, 0.5536, 0.6119, 0.6299, 0.5853, 0.6008,
        0.6415, 0.6389, 0.6038, 0.6578, 0.6491, 0.6317, 0.6353],
       device='cuda:0')
percent tensor([0.4673, 0.5933, 0.6115, 0.6894, 0.6309, 0.6802, 0.5821, 0.4975, 0.6179,
        0.5966, 0.6905, 0.6553, 0.5235, 0.7504, 0.5399, 0.5442],
       device='cuda:0')
percent tensor([0.6670, 0.6998, 0.6624, 0.6893, 0.6870, 0.6932, 0.7030, 0.6264, 0.6957,
        0.6727, 0.6996, 0.7072, 0.6872, 0.7254, 0.7080, 0.6801],
       device='cuda:0')
percent tensor([0.6690, 0.7653, 0.7946, 0.7909, 0.7850, 0.7669, 0.7285, 0.7063, 0.6584,
        0.6653, 0.7105, 0.7067, 0.6431, 0.6912, 0.6359, 0.7067],
       device='cuda:0')
percent tensor([0.9993, 0.9993, 0.9994, 0.9995, 0.9990, 0.9988, 0.9992, 0.9994, 0.9986,
        0.9992, 0.9996, 0.9996, 0.9989, 0.9988, 0.9995, 0.9992],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (2540/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (3747/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (4955/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (6143/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (93.00%) (7339/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (8540/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (9756/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (10967/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (12179/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (13382/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (14583/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (15794/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (17009/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (18216/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (19414/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (20627/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (21830/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (23042/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (24247/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (25452/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (26651/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (27880/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (29099/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (30314/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (31543/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (32743/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (33966/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (35195/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (36401/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (37623/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (38845/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (40062/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (41272/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (42485/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (43696/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (44923/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (46130/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (47297/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_145.pth.tar'
# TEST : Loss: (0.3926) | Acc: (87.00%) (8799/10000)
percent tensor([0.4909, 0.5188, 0.5053, 0.4897, 0.5166, 0.5132, 0.5219, 0.4890, 0.4953,
        0.5070, 0.5040, 0.5141, 0.4904, 0.5035, 0.5163, 0.4926],
       device='cuda:0')
percent tensor([0.5702, 0.5707, 0.5322, 0.5637, 0.5296, 0.5114, 0.5564, 0.5714, 0.6107,
        0.5770, 0.5880, 0.5566, 0.5890, 0.6565, 0.5326, 0.5502],
       device='cuda:0')
percent tensor([0.6126, 0.4844, 0.6752, 0.6414, 0.6684, 0.6578, 0.5656, 0.6487, 0.6109,
        0.5673, 0.5697, 0.5704, 0.5210, 0.5495, 0.5567, 0.6208],
       device='cuda:0')
percent tensor([0.6086, 0.6247, 0.5513, 0.5732, 0.5422, 0.5906, 0.6074, 0.5703, 0.5832,
        0.6159, 0.6143, 0.5843, 0.6290, 0.6244, 0.6082, 0.6098],
       device='cuda:0')
percent tensor([0.4919, 0.6201, 0.6384, 0.7168, 0.6421, 0.7093, 0.6082, 0.5035, 0.6477,
        0.6310, 0.7233, 0.7051, 0.5496, 0.7809, 0.5642, 0.5705],
       device='cuda:0')
percent tensor([0.6434, 0.6741, 0.6354, 0.6622, 0.6558, 0.6719, 0.6764, 0.5939, 0.6681,
        0.6432, 0.6735, 0.6834, 0.6584, 0.7032, 0.6805, 0.6513],
       device='cuda:0')
percent tensor([0.6338, 0.7265, 0.7731, 0.7632, 0.7656, 0.7417, 0.6951, 0.6839, 0.6300,
        0.6379, 0.6477, 0.6611, 0.5825, 0.6411, 0.6120, 0.6816],
       device='cuda:0')
percent tensor([0.9993, 0.9993, 0.9995, 0.9997, 0.9991, 0.9990, 0.9991, 0.9995, 0.9984,
        0.9993, 0.9997, 0.9996, 0.9989, 0.9986, 0.9995, 0.9992],
       device='cuda:0')
Epoch: 146 | Batch_idx: 0 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (2542/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (3753/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (94.00%) (4982/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (94.00%) (6194/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (7418/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (94.00%) (8625/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (9851/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (11069/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (94.00%) (12276/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (13505/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (14727/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (15942/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (17169/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (18391/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (19616/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (20835/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (22053/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (23271/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (24497/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (25714/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (26932/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (28150/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (29355/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (30571/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (31805/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (33008/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (34217/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (35442/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (36670/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (37883/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (39117/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (40334/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (41557/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (42774/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (44000/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (45218/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (46447/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (47620/50000)
# TEST : Loss: (0.3813) | Acc: (88.00%) (8850/10000)
percent tensor([0.4939, 0.5220, 0.5088, 0.4938, 0.5202, 0.5174, 0.5249, 0.4926, 0.4983,
        0.5100, 0.5071, 0.5170, 0.4934, 0.5062, 0.5202, 0.4962],
       device='cuda:0')
percent tensor([0.5641, 0.5615, 0.5280, 0.5593, 0.5254, 0.5054, 0.5488, 0.5664, 0.6051,
        0.5683, 0.5799, 0.5503, 0.5818, 0.6481, 0.5246, 0.5426],
       device='cuda:0')
percent tensor([0.6072, 0.4825, 0.6675, 0.6359, 0.6614, 0.6527, 0.5620, 0.6421, 0.6079,
        0.5652, 0.5692, 0.5652, 0.5156, 0.5526, 0.5521, 0.6169],
       device='cuda:0')
percent tensor([0.6102, 0.6241, 0.5550, 0.5759, 0.5461, 0.5904, 0.6082, 0.5736, 0.5858,
        0.6159, 0.6160, 0.5877, 0.6293, 0.6229, 0.6089, 0.6096],
       device='cuda:0')
percent tensor([0.4919, 0.6207, 0.6399, 0.7204, 0.6421, 0.7100, 0.6098, 0.5064, 0.6500,
        0.6343, 0.7245, 0.7076, 0.5506, 0.7824, 0.5694, 0.5741],
       device='cuda:0')
percent tensor([0.6537, 0.6833, 0.6451, 0.6709, 0.6652, 0.6834, 0.6871, 0.6024, 0.6770,
        0.6525, 0.6837, 0.6909, 0.6686, 0.7128, 0.6913, 0.6640],
       device='cuda:0')
percent tensor([0.6430, 0.7294, 0.7839, 0.7740, 0.7769, 0.7451, 0.7098, 0.7013, 0.6345,
        0.6464, 0.6520, 0.6708, 0.5761, 0.6397, 0.6240, 0.6958],
       device='cuda:0')
percent tensor([0.9994, 0.9993, 0.9995, 0.9997, 0.9991, 0.9991, 0.9992, 0.9996, 0.9984,
        0.9993, 0.9997, 0.9996, 0.9989, 0.9986, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 147 | Batch_idx: 0 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (2576/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (3788/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (5002/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (6217/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (7430/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (8648/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (9878/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (11089/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (12308/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (13522/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (14743/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (15960/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (17185/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (18417/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (19629/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (20856/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (22094/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (23322/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (24543/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (25756/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (26979/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (28198/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (29427/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (30654/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (31873/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (33102/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (34331/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (35569/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (36795/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (38018/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (39240/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (40450/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (41680/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (42897/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (44112/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (45341/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (46547/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (47729/50000)
# TEST : Loss: (0.3734) | Acc: (88.00%) (8867/10000)
percent tensor([0.4926, 0.5202, 0.5076, 0.4926, 0.5188, 0.5171, 0.5232, 0.4908, 0.4966,
        0.5081, 0.5055, 0.5153, 0.4917, 0.5042, 0.5191, 0.4949],
       device='cuda:0')
percent tensor([0.5581, 0.5544, 0.5222, 0.5529, 0.5200, 0.5001, 0.5425, 0.5606, 0.5996,
        0.5608, 0.5734, 0.5441, 0.5757, 0.6411, 0.5186, 0.5358],
       device='cuda:0')
percent tensor([0.6135, 0.4920, 0.6743, 0.6411, 0.6681, 0.6536, 0.5705, 0.6477, 0.6182,
        0.5760, 0.5814, 0.5752, 0.5257, 0.5610, 0.5571, 0.6226],
       device='cuda:0')
percent tensor([0.6158, 0.6290, 0.5604, 0.5805, 0.5509, 0.5931, 0.6133, 0.5790, 0.5919,
        0.6218, 0.6226, 0.5944, 0.6359, 0.6270, 0.6137, 0.6140],
       device='cuda:0')
percent tensor([0.4896, 0.6169, 0.6368, 0.7241, 0.6420, 0.7148, 0.6074, 0.5061, 0.6429,
        0.6282, 0.7183, 0.7040, 0.5420, 0.7778, 0.5711, 0.5741],
       device='cuda:0')
percent tensor([0.6559, 0.6844, 0.6474, 0.6727, 0.6674, 0.6872, 0.6890, 0.6029, 0.6783,
        0.6526, 0.6853, 0.6912, 0.6686, 0.7153, 0.6923, 0.6665],
       device='cuda:0')
percent tensor([0.6465, 0.7274, 0.7886, 0.7827, 0.7820, 0.7485, 0.7157, 0.7080, 0.6300,
        0.6426, 0.6482, 0.6717, 0.5691, 0.6374, 0.6265, 0.7033],
       device='cuda:0')
percent tensor([0.9994, 0.9993, 0.9995, 0.9997, 0.9990, 0.9991, 0.9992, 0.9995, 0.9985,
        0.9992, 0.9997, 0.9996, 0.9989, 0.9987, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 148 | Batch_idx: 0 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (2576/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (3804/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (5036/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (6265/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (7485/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (8717/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (9942/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (11163/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (12390/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (13626/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (14849/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (16073/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (17299/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (18528/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (19758/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (20987/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (22212/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (23441/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (24668/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (25895/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (27111/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (28331/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (29558/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (30787/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (32021/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (33242/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (34474/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (35714/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (36941/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (38176/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (39402/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (40626/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (41868/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (43087/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (44316/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (45555/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (46777/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (47961/50000)
# TEST : Loss: (0.3675) | Acc: (88.00%) (8882/10000)
percent tensor([0.4934, 0.5209, 0.5076, 0.4935, 0.5189, 0.5184, 0.5236, 0.4915, 0.4974,
        0.5086, 0.5065, 0.5152, 0.4926, 0.5050, 0.5202, 0.4961],
       device='cuda:0')
percent tensor([0.5581, 0.5524, 0.5226, 0.5531, 0.5206, 0.5012, 0.5415, 0.5606, 0.5992,
        0.5591, 0.5724, 0.5438, 0.5750, 0.6390, 0.5184, 0.5352],
       device='cuda:0')
percent tensor([0.6145, 0.4927, 0.6742, 0.6422, 0.6684, 0.6549, 0.5713, 0.6481, 0.6198,
        0.5768, 0.5830, 0.5762, 0.5256, 0.5650, 0.5577, 0.6238],
       device='cuda:0')
percent tensor([0.6273, 0.6396, 0.5710, 0.5909, 0.5613, 0.6021, 0.6244, 0.5903, 0.6035,
        0.6335, 0.6346, 0.6070, 0.6475, 0.6371, 0.6245, 0.6247],
       device='cuda:0')
percent tensor([0.4923, 0.6192, 0.6351, 0.7211, 0.6383, 0.7131, 0.6120, 0.5045, 0.6455,
        0.6337, 0.7227, 0.7040, 0.5459, 0.7814, 0.5729, 0.5763],
       device='cuda:0')
percent tensor([0.6575, 0.6846, 0.6481, 0.6740, 0.6677, 0.6884, 0.6899, 0.6030, 0.6789,
        0.6533, 0.6865, 0.6901, 0.6687, 0.7165, 0.6929, 0.6683],
       device='cuda:0')
percent tensor([0.6679, 0.7445, 0.8051, 0.8005, 0.7964, 0.7609, 0.7380, 0.7277, 0.6478,
        0.6633, 0.6734, 0.6954, 0.5864, 0.6593, 0.6478, 0.7215],
       device='cuda:0')
percent tensor([0.9994, 0.9993, 0.9995, 0.9997, 0.9991, 0.9992, 0.9992, 0.9995, 0.9985,
        0.9993, 0.9997, 0.9996, 0.9989, 0.9987, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 149 | Batch_idx: 0 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (2580/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (3803/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (5028/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (6252/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (7480/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (8714/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (9937/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (11172/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (12405/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (96.00%) (13652/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (96.00%) (14876/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (96.00%) (16099/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (96.00%) (17327/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (96.00%) (18561/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (19776/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (20996/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (22233/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (23441/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (24665/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (25906/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (27134/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (28359/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (29581/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (30810/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (32038/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (33258/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (34484/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (35715/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (36943/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (38165/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (39395/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (40612/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (41850/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (43078/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (44313/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (45541/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (46772/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (47946/50000)
# TEST : Loss: (0.3682) | Acc: (88.00%) (8868/10000)
percent tensor([0.4961, 0.5239, 0.5107, 0.4965, 0.5221, 0.5215, 0.5266, 0.4943, 0.5000,
        0.5113, 0.5092, 0.5180, 0.4952, 0.5076, 0.5233, 0.4989],
       device='cuda:0')
percent tensor([0.5633, 0.5566, 0.5260, 0.5572, 0.5256, 0.5077, 0.5457, 0.5646, 0.6028,
        0.5626, 0.5765, 0.5470, 0.5793, 0.6417, 0.5235, 0.5400],
       device='cuda:0')
percent tensor([0.6154, 0.4931, 0.6751, 0.6440, 0.6679, 0.6573, 0.5720, 0.6491, 0.6208,
        0.5790, 0.5848, 0.5777, 0.5247, 0.5701, 0.5584, 0.6259],
       device='cuda:0')
percent tensor([0.6259, 0.6386, 0.5690, 0.5892, 0.5594, 0.6002, 0.6232, 0.5887, 0.6024,
        0.6320, 0.6342, 0.6057, 0.6467, 0.6353, 0.6234, 0.6234],
       device='cuda:0')
percent tensor([0.4820, 0.6097, 0.6330, 0.7173, 0.6356, 0.7064, 0.6054, 0.5010, 0.6381,
        0.6251, 0.7134, 0.6972, 0.5351, 0.7735, 0.5658, 0.5664],
       device='cuda:0')
percent tensor([0.6633, 0.6912, 0.6521, 0.6771, 0.6712, 0.6948, 0.6964, 0.6077, 0.6847,
        0.6593, 0.6935, 0.6929, 0.6749, 0.7227, 0.6988, 0.6750],
       device='cuda:0')
percent tensor([0.6621, 0.7426, 0.8035, 0.7996, 0.7961, 0.7622, 0.7351, 0.7220, 0.6491,
        0.6606, 0.6714, 0.6930, 0.5818, 0.6535, 0.6407, 0.7198],
       device='cuda:0')
percent tensor([0.9994, 0.9994, 0.9995, 0.9997, 0.9991, 0.9992, 0.9992, 0.9996, 0.9986,
        0.9993, 0.9997, 0.9996, 0.9989, 0.9988, 0.9995, 0.9993],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 150 | Batch_idx: 0 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (2573/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (3793/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (5014/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (6241/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (7469/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (8685/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (9920/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (11133/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (12345/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (13569/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (14786/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (16012/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (17239/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (18454/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (19680/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (20905/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (22124/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (23343/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (24562/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (25782/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (27016/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (28234/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (29457/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (30680/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (31907/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (33124/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (34327/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (35560/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (36771/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (38007/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (39234/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (40449/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (41677/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (42910/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (44142/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (45358/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (46576/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (47756/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_150.pth.tar'
# TEST : Loss: (0.4265) | Acc: (87.00%) (8764/10000)
percent tensor([0.4950, 0.5237, 0.5138, 0.4974, 0.5238, 0.5186, 0.5266, 0.4970, 0.5002,
        0.5120, 0.5081, 0.5199, 0.4941, 0.5088, 0.5220, 0.4986],
       device='cuda:0')
percent tensor([0.5607, 0.5629, 0.5203, 0.5520, 0.5196, 0.5009, 0.5476, 0.5693, 0.6023,
        0.5667, 0.5760, 0.5478, 0.5819, 0.6443, 0.5231, 0.5384],
       device='cuda:0')
percent tensor([0.6107, 0.4872, 0.6783, 0.6503, 0.6701, 0.6523, 0.5629, 0.6504, 0.6098,
        0.5742, 0.5758, 0.5708, 0.5139, 0.5625, 0.5510, 0.6258],
       device='cuda:0')
percent tensor([0.6278, 0.6409, 0.5722, 0.5913, 0.5630, 0.6042, 0.6274, 0.5906, 0.6026,
        0.6365, 0.6346, 0.6099, 0.6498, 0.6363, 0.6258, 0.6249],
       device='cuda:0')
percent tensor([0.4706, 0.6173, 0.6212, 0.6919, 0.6409, 0.6692, 0.5909, 0.5116, 0.6672,
        0.6260, 0.7188, 0.6687, 0.5631, 0.7628, 0.5436, 0.5625],
       device='cuda:0')
percent tensor([0.6634, 0.6881, 0.6629, 0.6805, 0.6809, 0.6971, 0.6914, 0.6147, 0.6881,
        0.6611, 0.6949, 0.6900, 0.6738, 0.7146, 0.7030, 0.6690],
       device='cuda:0')
percent tensor([0.6691, 0.7555, 0.7940, 0.7815, 0.7987, 0.7509, 0.7506, 0.7099, 0.6438,
        0.6708, 0.6869, 0.6884, 0.6089, 0.6582, 0.6248, 0.7005],
       device='cuda:0')
percent tensor([0.9994, 0.9994, 0.9995, 0.9997, 0.9990, 0.9992, 0.9992, 0.9996, 0.9990,
        0.9995, 0.9998, 0.9996, 0.9992, 0.9987, 0.9994, 0.9994],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(183.4402, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.1704, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.7321, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1517.3192, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(483.5309, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2254.2705, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4260.9204, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1372.5652, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6205.8291, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11727.0186, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3856.4268, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16304.4043, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 151 | Batch_idx: 0 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (2587/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (3816/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (5052/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (6293/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (7530/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (8761/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (9988/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (11204/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (12428/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (13658/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (96.00%) (14879/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (96.00%) (16113/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (96.00%) (17338/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (96.00%) (18557/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (96.00%) (19784/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (20995/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (22226/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (23457/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (24681/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (25916/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (27150/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (28370/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (29590/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (30817/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (32031/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (33270/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (34488/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (35721/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (36933/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (38150/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (39374/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (40596/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (41816/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (43029/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (44246/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (45478/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (46691/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (47858/50000)
# TEST : Loss: (0.4073) | Acc: (87.00%) (8797/10000)
percent tensor([0.4958, 0.5273, 0.5077, 0.4960, 0.5197, 0.5197, 0.5284, 0.4949, 0.5007,
        0.5127, 0.5109, 0.5166, 0.4954, 0.5146, 0.5236, 0.5006],
       device='cuda:0')
percent tensor([0.5587, 0.5533, 0.5128, 0.5457, 0.5170, 0.4996, 0.5404, 0.5594, 0.6006,
        0.5545, 0.5727, 0.5408, 0.5779, 0.6381, 0.5172, 0.5328],
       device='cuda:0')
percent tensor([0.6163, 0.4915, 0.6866, 0.6550, 0.6789, 0.6626, 0.5684, 0.6551, 0.6146,
        0.5819, 0.5808, 0.5782, 0.5212, 0.5618, 0.5613, 0.6303],
       device='cuda:0')
percent tensor([0.6298, 0.6417, 0.5704, 0.5883, 0.5582, 0.6068, 0.6276, 0.5923, 0.6052,
        0.6369, 0.6376, 0.6067, 0.6507, 0.6385, 0.6260, 0.6283],
       device='cuda:0')
percent tensor([0.4530, 0.5890, 0.6251, 0.7215, 0.6456, 0.6651, 0.5885, 0.4912, 0.6306,
        0.5884, 0.6877, 0.6824, 0.5207, 0.7510, 0.5210, 0.5305],
       device='cuda:0')
percent tensor([0.6551, 0.6814, 0.6484, 0.6777, 0.6710, 0.6895, 0.6875, 0.6030, 0.6930,
        0.6500, 0.6956, 0.6847, 0.6709, 0.7181, 0.6920, 0.6634],
       device='cuda:0')
percent tensor([0.6582, 0.7432, 0.7925, 0.8060, 0.8070, 0.7777, 0.7296, 0.6998, 0.6139,
        0.6237, 0.6612, 0.6736, 0.5985, 0.6164, 0.6420, 0.7113],
       device='cuda:0')
percent tensor([0.9995, 0.9993, 0.9993, 0.9995, 0.9991, 0.9992, 0.9991, 0.9994, 0.9987,
        0.9992, 0.9996, 0.9994, 0.9991, 0.9989, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 152 | Batch_idx: 0 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (2578/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (3814/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (5053/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (6293/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (7521/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (8745/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (9968/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (11197/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (12428/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (96.00%) (13647/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (96.00%) (14870/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (96.00%) (16098/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (17321/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (18545/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (19770/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (21006/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (22229/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (23470/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (96.00%) (24699/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (96.00%) (25934/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (96.00%) (27164/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (96.00%) (28391/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (29612/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (30832/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (32065/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (33287/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (34509/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (35725/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (36945/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (38168/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (39398/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (40617/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (41848/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (43068/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (44302/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (45523/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (46754/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (47936/50000)
# TEST : Loss: (0.4128) | Acc: (87.00%) (8792/10000)
percent tensor([0.4970, 0.5237, 0.5152, 0.4961, 0.5242, 0.5197, 0.5271, 0.4969, 0.5022,
        0.5127, 0.5097, 0.5207, 0.4957, 0.5076, 0.5222, 0.4993],
       device='cuda:0')
percent tensor([0.5558, 0.5550, 0.5196, 0.5511, 0.5175, 0.5023, 0.5374, 0.5625, 0.5933,
        0.5573, 0.5675, 0.5428, 0.5761, 0.6319, 0.5215, 0.5325],
       device='cuda:0')
percent tensor([0.6082, 0.4890, 0.6709, 0.6486, 0.6687, 0.6555, 0.5640, 0.6456, 0.6054,
        0.5718, 0.5724, 0.5607, 0.5142, 0.5634, 0.5535, 0.6274],
       device='cuda:0')
percent tensor([0.6324, 0.6390, 0.5770, 0.5882, 0.5646, 0.6086, 0.6255, 0.5899, 0.6071,
        0.6397, 0.6388, 0.6142, 0.6549, 0.6381, 0.6270, 0.6283],
       device='cuda:0')
percent tensor([0.4487, 0.5960, 0.6141, 0.6864, 0.6086, 0.6687, 0.5874, 0.4852, 0.6344,
        0.5918, 0.6902, 0.6421, 0.5112, 0.7690, 0.5322, 0.5387],
       device='cuda:0')
percent tensor([0.6557, 0.6766, 0.6602, 0.6794, 0.6735, 0.6976, 0.6865, 0.6055, 0.6941,
        0.6579, 0.6982, 0.6954, 0.6678, 0.7216, 0.6938, 0.6625],
       device='cuda:0')
percent tensor([0.6891, 0.7616, 0.7783, 0.7812, 0.8002, 0.7509, 0.7496, 0.6883, 0.6421,
        0.6654, 0.6748, 0.6660, 0.6335, 0.6619, 0.6482, 0.7102],
       device='cuda:0')
percent tensor([0.9994, 0.9994, 0.9995, 0.9997, 0.9989, 0.9994, 0.9994, 0.9996, 0.9990,
        0.9993, 0.9997, 0.9996, 0.9992, 0.9986, 0.9993, 0.9993],
       device='cuda:0')
Epoch: 153 | Batch_idx: 0 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (2583/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (3822/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (5058/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (6300/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (7542/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (8761/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (10000/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (11222/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (12442/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (13665/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (14894/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (16120/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (17356/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (18588/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (19812/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (21042/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (22266/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (23493/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (24718/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (96.00%) (25930/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (27165/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (28376/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (29602/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (30833/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (32057/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (33290/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (34502/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (35728/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (36941/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (38170/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (39405/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (40624/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (41855/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (43074/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (44304/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (45539/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (46756/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (47940/50000)
# TEST : Loss: (0.3855) | Acc: (88.00%) (8851/10000)
percent tensor([0.4951, 0.5238, 0.5128, 0.4946, 0.5230, 0.5176, 0.5270, 0.4958, 0.5015,
        0.5123, 0.5096, 0.5195, 0.4946, 0.5095, 0.5214, 0.4985],
       device='cuda:0')
percent tensor([0.5612, 0.5564, 0.5210, 0.5479, 0.5193, 0.5070, 0.5408, 0.5607, 0.6009,
        0.5603, 0.5736, 0.5446, 0.5794, 0.6346, 0.5220, 0.5364],
       device='cuda:0')
percent tensor([0.6192, 0.4987, 0.6742, 0.6621, 0.6729, 0.6664, 0.5754, 0.6573, 0.6182,
        0.5764, 0.5790, 0.5719, 0.5260, 0.5675, 0.5682, 0.6392],
       device='cuda:0')
percent tensor([0.6270, 0.6351, 0.5742, 0.5891, 0.5628, 0.6007, 0.6192, 0.5860, 0.5989,
        0.6335, 0.6302, 0.6086, 0.6450, 0.6294, 0.6235, 0.6220],
       device='cuda:0')
percent tensor([0.4658, 0.5918, 0.6405, 0.6887, 0.6444, 0.6749, 0.5987, 0.5242, 0.6373,
        0.6093, 0.7001, 0.6809, 0.5379, 0.7366, 0.5328, 0.5402],
       device='cuda:0')
percent tensor([0.6531, 0.6795, 0.6621, 0.6657, 0.6736, 0.6836, 0.6857, 0.5967, 0.6852,
        0.6600, 0.6952, 0.6957, 0.6734, 0.7158, 0.6916, 0.6583],
       device='cuda:0')
percent tensor([0.6747, 0.7226, 0.7889, 0.7836, 0.8013, 0.7584, 0.7423, 0.6954, 0.6392,
        0.6323, 0.6726, 0.6876, 0.6222, 0.6546, 0.6206, 0.6980],
       device='cuda:0')
percent tensor([0.9996, 0.9991, 0.9995, 0.9997, 0.9988, 0.9994, 0.9992, 0.9992, 0.9988,
        0.9993, 0.9997, 0.9995, 0.9990, 0.9987, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 154 | Batch_idx: 0 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (2594/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (3825/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (5062/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (6288/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (7515/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (8743/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (9980/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (11205/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (12436/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (13664/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (14899/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (16119/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (17355/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (18583/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (19828/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (21054/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (22290/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (23529/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (24763/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (25990/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (27226/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (28461/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (29680/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (30916/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (32134/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (33372/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (34580/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (35806/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (37025/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (38253/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (39484/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (40713/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (41943/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (43173/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (44406/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (45633/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (46853/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (48016/50000)
# TEST : Loss: (0.4220) | Acc: (87.00%) (8753/10000)
percent tensor([0.4958, 0.5257, 0.5131, 0.4981, 0.5231, 0.5195, 0.5275, 0.4972, 0.5008,
        0.5128, 0.5096, 0.5189, 0.4953, 0.5104, 0.5232, 0.4995],
       device='cuda:0')
percent tensor([0.5577, 0.5530, 0.5192, 0.5440, 0.5189, 0.5054, 0.5406, 0.5554, 0.5988,
        0.5560, 0.5705, 0.5438, 0.5737, 0.6332, 0.5207, 0.5329],
       device='cuda:0')
percent tensor([0.6154, 0.5038, 0.6756, 0.6625, 0.6726, 0.6672, 0.5753, 0.6600, 0.6267,
        0.5850, 0.5865, 0.5733, 0.5245, 0.5780, 0.5703, 0.6384],
       device='cuda:0')
percent tensor([0.6273, 0.6364, 0.5732, 0.5865, 0.5621, 0.6017, 0.6237, 0.5877, 0.5975,
        0.6328, 0.6311, 0.6058, 0.6457, 0.6333, 0.6225, 0.6226],
       device='cuda:0')
percent tensor([0.4657, 0.6027, 0.6253, 0.7057, 0.6410, 0.6828, 0.5926, 0.5097, 0.6536,
        0.6278, 0.6933, 0.6954, 0.5384, 0.7622, 0.5430, 0.5344],
       device='cuda:0')
percent tensor([0.6515, 0.6762, 0.6614, 0.6726, 0.6728, 0.6900, 0.6867, 0.6070, 0.6701,
        0.6588, 0.6867, 0.6912, 0.6646, 0.7146, 0.6904, 0.6578],
       device='cuda:0')
percent tensor([0.6746, 0.7499, 0.7851, 0.7800, 0.7842, 0.7445, 0.7344, 0.7073, 0.6533,
        0.6746, 0.6829, 0.6922, 0.6175, 0.6659, 0.6166, 0.7053],
       device='cuda:0')
percent tensor([0.9994, 0.9994, 0.9995, 0.9996, 0.9988, 0.9994, 0.9991, 0.9995, 0.9989,
        0.9994, 0.9996, 0.9995, 0.9992, 0.9987, 0.9994, 0.9990],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 155 | Batch_idx: 0 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (2554/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (3750/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (4940/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (93.00%) (6136/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (93.00%) (7326/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (8508/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (9714/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (10922/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (12117/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (13325/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (14526/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (15722/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (16920/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (18136/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (19337/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (20544/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (21741/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (22953/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (93.00%) (24172/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (93.00%) (25382/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (26591/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (27797/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (29001/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (30221/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (31435/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (32638/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (33847/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (35052/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (36264/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (37464/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (38679/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (39877/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (41099/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (42295/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (43515/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (44740/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (45956/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (47126/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_155.pth.tar'
# TEST : Loss: (0.4126) | Acc: (87.00%) (8764/10000)
percent tensor([0.4837, 0.5103, 0.5051, 0.4834, 0.5139, 0.5089, 0.5144, 0.4816, 0.4879,
        0.4994, 0.4967, 0.5094, 0.4821, 0.4926, 0.5094, 0.4849],
       device='cuda:0')
percent tensor([0.5857, 0.5882, 0.5302, 0.5639, 0.5343, 0.5378, 0.5678, 0.5762, 0.6228,
        0.5848, 0.6024, 0.5548, 0.6040, 0.6634, 0.5557, 0.5650],
       device='cuda:0')
percent tensor([0.6261, 0.5130, 0.6905, 0.6843, 0.6859, 0.6718, 0.5812, 0.6841, 0.6304,
        0.5927, 0.5849, 0.5910, 0.5339, 0.5658, 0.5838, 0.6496],
       device='cuda:0')
percent tensor([0.6188, 0.6280, 0.5621, 0.5760, 0.5527, 0.5945, 0.6145, 0.5699, 0.5893,
        0.6237, 0.6273, 0.6004, 0.6415, 0.6273, 0.6117, 0.6154],
       device='cuda:0')
percent tensor([0.4620, 0.6313, 0.6180, 0.6974, 0.6448, 0.6896, 0.6127, 0.5159, 0.6617,
        0.6596, 0.7082, 0.6856, 0.5442, 0.7871, 0.5522, 0.5498],
       device='cuda:0')
percent tensor([0.6827, 0.6962, 0.6854, 0.6891, 0.6985, 0.7099, 0.7117, 0.6304, 0.6931,
        0.6843, 0.7110, 0.7199, 0.6904, 0.7323, 0.7126, 0.6831],
       device='cuda:0')
percent tensor([0.6268, 0.7002, 0.7512, 0.7583, 0.7558, 0.7318, 0.6794, 0.6744, 0.5872,
        0.6296, 0.6038, 0.6228, 0.5286, 0.6003, 0.5706, 0.6776],
       device='cuda:0')
percent tensor([0.9993, 0.9993, 0.9994, 0.9995, 0.9987, 0.9994, 0.9991, 0.9994, 0.9988,
        0.9994, 0.9996, 0.9996, 0.9990, 0.9986, 0.9994, 0.9992],
       device='cuda:0')
Epoch: 156 | Batch_idx: 0 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (3780/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (6230/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (7456/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (8674/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (9887/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (11113/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (12315/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (13533/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (14754/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (15963/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (17178/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (18389/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (19592/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (20817/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (22035/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (23258/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (24476/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (25683/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (26904/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (28114/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (29333/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (30557/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (31764/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (32995/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (34223/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (35443/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (36664/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (37879/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (39094/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (40304/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (41521/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (42752/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (43988/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (45201/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (46423/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (47599/50000)
# TEST : Loss: (0.3986) | Acc: (87.00%) (8796/10000)
percent tensor([0.4861, 0.5137, 0.5072, 0.4848, 0.5168, 0.5118, 0.5180, 0.4834, 0.4902,
        0.5022, 0.4997, 0.5125, 0.4847, 0.4944, 0.5127, 0.4871],
       device='cuda:0')
percent tensor([0.5896, 0.5920, 0.5300, 0.5645, 0.5347, 0.5419, 0.5697, 0.5754, 0.6242,
        0.5880, 0.6061, 0.5573, 0.6074, 0.6666, 0.5590, 0.5683],
       device='cuda:0')
percent tensor([0.6265, 0.5026, 0.6907, 0.6825, 0.6865, 0.6739, 0.5771, 0.6832, 0.6316,
        0.5837, 0.5797, 0.5884, 0.5310, 0.5581, 0.5806, 0.6456],
       device='cuda:0')
percent tensor([0.6155, 0.6266, 0.5571, 0.5723, 0.5477, 0.5923, 0.6112, 0.5648, 0.5843,
        0.6217, 0.6252, 0.5963, 0.6388, 0.6257, 0.6094, 0.6133],
       device='cuda:0')
percent tensor([0.4604, 0.6310, 0.6266, 0.7061, 0.6522, 0.6979, 0.6131, 0.5137, 0.6643,
        0.6579, 0.7104, 0.6866, 0.5474, 0.7881, 0.5491, 0.5522],
       device='cuda:0')
percent tensor([0.6798, 0.6942, 0.6818, 0.6866, 0.6964, 0.7044, 0.7101, 0.6335, 0.6891,
        0.6804, 0.7076, 0.7135, 0.6857, 0.7292, 0.7117, 0.6816],
       device='cuda:0')
percent tensor([0.6360, 0.7087, 0.7614, 0.7713, 0.7661, 0.7435, 0.6862, 0.6923, 0.5995,
        0.6338, 0.6138, 0.6281, 0.5339, 0.6022, 0.5827, 0.6857],
       device='cuda:0')
percent tensor([0.9993, 0.9993, 0.9994, 0.9995, 0.9986, 0.9995, 0.9991, 0.9994, 0.9988,
        0.9994, 0.9996, 0.9996, 0.9990, 0.9987, 0.9994, 0.9992],
       device='cuda:0')
Epoch: 157 | Batch_idx: 0 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (2560/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (4994/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (6215/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (7434/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (8645/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (9879/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (11103/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (12321/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (13541/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (14760/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (15973/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (17190/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (18417/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (19635/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (20863/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (22092/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (23310/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (24533/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (25767/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (26982/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (28195/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (29414/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (30646/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (31879/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (33103/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (34323/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (35548/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (36764/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (37997/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (39219/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (40441/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (41654/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (42884/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (44109/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (45338/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (46569/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (47734/50000)
# TEST : Loss: (0.3912) | Acc: (88.00%) (8804/10000)
percent tensor([0.4865, 0.5150, 0.5074, 0.4851, 0.5175, 0.5133, 0.5190, 0.4834, 0.4906,
        0.5030, 0.5006, 0.5133, 0.4852, 0.4946, 0.5141, 0.4877],
       device='cuda:0')
percent tensor([0.5804, 0.5812, 0.5172, 0.5533, 0.5221, 0.5309, 0.5579, 0.5625, 0.6138,
        0.5770, 0.5961, 0.5464, 0.5982, 0.6572, 0.5477, 0.5576],
       device='cuda:0')
percent tensor([0.6300, 0.5003, 0.6973, 0.6874, 0.6919, 0.6775, 0.5776, 0.6870, 0.6375,
        0.5855, 0.5816, 0.5943, 0.5316, 0.5576, 0.5804, 0.6466],
       device='cuda:0')
percent tensor([0.6167, 0.6280, 0.5580, 0.5731, 0.5479, 0.5928, 0.6121, 0.5652, 0.5853,
        0.6238, 0.6281, 0.5982, 0.6404, 0.6277, 0.6107, 0.6145],
       device='cuda:0')
percent tensor([0.4425, 0.6163, 0.6221, 0.6993, 0.6494, 0.6831, 0.6015, 0.5059, 0.6544,
        0.6461, 0.6980, 0.6747, 0.5322, 0.7798, 0.5327, 0.5386],
       device='cuda:0')
percent tensor([0.6844, 0.6994, 0.6865, 0.6904, 0.7013, 0.7063, 0.7158, 0.6408, 0.6938,
        0.6855, 0.7129, 0.7172, 0.6896, 0.7342, 0.7184, 0.6871],
       device='cuda:0')
percent tensor([0.6412, 0.7205, 0.7646, 0.7756, 0.7716, 0.7519, 0.6940, 0.7067, 0.6066,
        0.6391, 0.6186, 0.6348, 0.5473, 0.6063, 0.5984, 0.6962],
       device='cuda:0')
percent tensor([0.9993, 0.9993, 0.9995, 0.9995, 0.9986, 0.9994, 0.9992, 0.9994, 0.9988,
        0.9994, 0.9996, 0.9996, 0.9990, 0.9987, 0.9995, 0.9992],
       device='cuda:0')
Epoch: 158 | Batch_idx: 0 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (2567/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (3793/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (5021/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (6237/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (7467/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (8687/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (9916/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (11140/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (12370/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (13604/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (14818/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (16036/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (17264/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (18493/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (19705/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (20927/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (22163/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (23397/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (24614/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (25834/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (27059/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (28289/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (29521/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (30753/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (31985/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (33217/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (34446/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (35677/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (36895/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (38122/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (39347/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (40576/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (41809/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (43030/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (44253/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (45471/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (46703/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (47891/50000)
# TEST : Loss: (0.3882) | Acc: (88.00%) (8836/10000)
percent tensor([0.4838, 0.5122, 0.5042, 0.4820, 0.5145, 0.5115, 0.5161, 0.4799, 0.4877,
        0.4999, 0.4980, 0.5102, 0.4823, 0.4916, 0.5116, 0.4848],
       device='cuda:0')
percent tensor([0.5822, 0.5835, 0.5186, 0.5546, 0.5238, 0.5321, 0.5601, 0.5629, 0.6161,
        0.5794, 0.5986, 0.5490, 0.5999, 0.6602, 0.5491, 0.5592],
       device='cuda:0')
percent tensor([0.6329, 0.5000, 0.7022, 0.6903, 0.6961, 0.6768, 0.5790, 0.6908, 0.6439,
        0.5874, 0.5848, 0.6001, 0.5357, 0.5593, 0.5799, 0.6467],
       device='cuda:0')
percent tensor([0.6171, 0.6289, 0.5579, 0.5727, 0.5480, 0.5922, 0.6122, 0.5648, 0.5850,
        0.6255, 0.6290, 0.5991, 0.6415, 0.6276, 0.6112, 0.6153],
       device='cuda:0')
percent tensor([0.4612, 0.6336, 0.6420, 0.7151, 0.6687, 0.6979, 0.6200, 0.5248, 0.6714,
        0.6630, 0.7160, 0.6935, 0.5537, 0.7879, 0.5494, 0.5584],
       device='cuda:0')
percent tensor([0.6868, 0.7012, 0.6869, 0.6901, 0.7019, 0.7062, 0.7177, 0.6416, 0.6935,
        0.6872, 0.7150, 0.7172, 0.6907, 0.7351, 0.7206, 0.6896],
       device='cuda:0')
percent tensor([0.6467, 0.7243, 0.7706, 0.7789, 0.7729, 0.7577, 0.7006, 0.7131, 0.6132,
        0.6398, 0.6237, 0.6348, 0.5473, 0.6155, 0.6012, 0.6954],
       device='cuda:0')
percent tensor([0.9994, 0.9993, 0.9995, 0.9995, 0.9986, 0.9995, 0.9992, 0.9994, 0.9989,
        0.9994, 0.9996, 0.9996, 0.9991, 0.9988, 0.9995, 0.9992],
       device='cuda:0')
Epoch: 159 | Batch_idx: 0 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (96.00%) (2592/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (96.00%) (3820/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (96.00%) (5043/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (6262/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (7478/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (8703/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (9925/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (11152/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (12378/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (13612/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (14825/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (16061/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (17286/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (18508/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (19744/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (20987/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (22211/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (23438/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (24674/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (25897/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (27124/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (28351/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (29573/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (30791/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (32007/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (33225/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (34462/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (35697/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (36922/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (38140/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (39385/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (40603/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (41831/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (43063/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (44282/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (45499/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (46733/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (47914/50000)
# TEST : Loss: (0.3867) | Acc: (88.00%) (8832/10000)
percent tensor([0.4865, 0.5155, 0.5074, 0.4842, 0.5180, 0.5145, 0.5197, 0.4826, 0.4906,
        0.5029, 0.5008, 0.5137, 0.4850, 0.4942, 0.5148, 0.4873],
       device='cuda:0')
percent tensor([0.5791, 0.5800, 0.5159, 0.5512, 0.5208, 0.5281, 0.5566, 0.5597, 0.6116,
        0.5758, 0.5946, 0.5464, 0.5966, 0.6564, 0.5454, 0.5559],
       device='cuda:0')
percent tensor([0.6328, 0.4964, 0.7003, 0.6888, 0.6947, 0.6795, 0.5772, 0.6899, 0.6422,
        0.5830, 0.5826, 0.5971, 0.5338, 0.5568, 0.5807, 0.6453],
       device='cuda:0')
percent tensor([0.6223, 0.6346, 0.5613, 0.5763, 0.5509, 0.5965, 0.6170, 0.5680, 0.5892,
        0.6311, 0.6349, 0.6037, 0.6475, 0.6330, 0.6165, 0.6207],
       device='cuda:0')
percent tensor([0.4356, 0.6171, 0.6262, 0.7031, 0.6546, 0.6851, 0.6037, 0.5008, 0.6544,
        0.6491, 0.7023, 0.6791, 0.5350, 0.7818, 0.5233, 0.5407],
       device='cuda:0')
percent tensor([0.6862, 0.7010, 0.6872, 0.6901, 0.7014, 0.7043, 0.7173, 0.6433, 0.6942,
        0.6871, 0.7155, 0.7170, 0.6901, 0.7354, 0.7202, 0.6894],
       device='cuda:0')
percent tensor([0.6517, 0.7285, 0.7735, 0.7853, 0.7760, 0.7629, 0.7022, 0.7216, 0.6223,
        0.6409, 0.6301, 0.6432, 0.5555, 0.6179, 0.6072, 0.6984],
       device='cuda:0')
percent tensor([0.9993, 0.9993, 0.9995, 0.9995, 0.9986, 0.9995, 0.9992, 0.9994, 0.9989,
        0.9994, 0.9997, 0.9996, 0.9991, 0.9989, 0.9995, 0.9991],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 160 | Batch_idx: 0 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (96.00%) (3814/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (5044/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (6280/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (7504/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (8741/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (9956/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (11178/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (12393/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (13622/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (14854/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (16088/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (17309/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (18541/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (19764/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (20986/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (22223/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (23444/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (24675/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (25905/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (27125/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (28346/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (29569/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (30799/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (32013/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (33230/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (34456/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (35684/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (36908/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (38131/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (39349/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (40569/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (41791/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (43014/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (44243/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (45472/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (46703/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (47892/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_160.pth.tar'
# TEST : Loss: (0.3976) | Acc: (88.00%) (8835/10000)
percent tensor([0.4848, 0.5160, 0.5037, 0.4818, 0.5151, 0.5136, 0.5200, 0.4817, 0.4894,
        0.5027, 0.5003, 0.5108, 0.4838, 0.4961, 0.5140, 0.4875],
       device='cuda:0')
percent tensor([0.5740, 0.5707, 0.5218, 0.5555, 0.5232, 0.5185, 0.5504, 0.5636, 0.6129,
        0.5726, 0.5880, 0.5561, 0.5937, 0.6515, 0.5338, 0.5499],
       device='cuda:0')
percent tensor([0.6362, 0.4934, 0.7029, 0.6859, 0.6989, 0.6806, 0.5837, 0.6809, 0.6409,
        0.5810, 0.5902, 0.5955, 0.5369, 0.5735, 0.5737, 0.6466],
       device='cuda:0')
percent tensor([0.6197, 0.6361, 0.5637, 0.5756, 0.5496, 0.5954, 0.6142, 0.5700, 0.5901,
        0.6334, 0.6318, 0.6012, 0.6435, 0.6311, 0.6183, 0.6200],
       device='cuda:0')
percent tensor([0.4792, 0.6159, 0.6726, 0.7369, 0.6820, 0.6919, 0.6046, 0.5125, 0.6650,
        0.6479, 0.7051, 0.7060, 0.5694, 0.7563, 0.5345, 0.5641],
       device='cuda:0')
percent tensor([0.6869, 0.7070, 0.6854, 0.6916, 0.6997, 0.7017, 0.7195, 0.6437, 0.7059,
        0.6879, 0.7113, 0.7058, 0.6959, 0.7233, 0.7248, 0.7005],
       device='cuda:0')
percent tensor([0.6264, 0.7182, 0.7812, 0.7805, 0.7890, 0.7545, 0.7010, 0.7272, 0.6311,
        0.6307, 0.6360, 0.6383, 0.5833, 0.6476, 0.5996, 0.6599],
       device='cuda:0')
percent tensor([0.9996, 0.9995, 0.9994, 0.9997, 0.9987, 0.9994, 0.9993, 0.9994, 0.9989,
        0.9995, 0.9997, 0.9996, 0.9992, 0.9989, 0.9995, 0.9994],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(183.8351, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(824.1613, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(833.4780, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1516.0465, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(481.8880, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2258.8931, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4258.3169, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1367.5488, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6216.6343, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11694.1475, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3841.4565, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16239.0068, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 161 | Batch_idx: 0 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (96.00%) (2584/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (3824/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (5062/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (6299/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (7527/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (8752/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (9980/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (11220/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (12448/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (13676/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (14906/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (16136/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (17383/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (18621/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (19866/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (21105/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (22334/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (23568/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (24799/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (26027/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (27247/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (28469/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (29682/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (30901/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (32125/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (33357/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (34576/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (35810/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (37037/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (38268/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (39494/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (40728/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (41947/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (43181/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (44413/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (45635/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (46873/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (48059/50000)
# TEST : Loss: (0.4035) | Acc: (88.00%) (8850/10000)
percent tensor([0.4865, 0.5171, 0.5082, 0.4825, 0.5188, 0.5154, 0.5225, 0.4832, 0.4921,
        0.5045, 0.5019, 0.5152, 0.4855, 0.4975, 0.5151, 0.4883],
       device='cuda:0')
percent tensor([0.5743, 0.5744, 0.5187, 0.5533, 0.5203, 0.5154, 0.5533, 0.5662, 0.6149,
        0.5761, 0.5915, 0.5506, 0.5954, 0.6550, 0.5352, 0.5521],
       device='cuda:0')
percent tensor([0.6299, 0.4960, 0.7049, 0.6837, 0.6974, 0.6793, 0.5829, 0.6829, 0.6374,
        0.5855, 0.5851, 0.5963, 0.5278, 0.5770, 0.5720, 0.6416],
       device='cuda:0')
percent tensor([0.6209, 0.6290, 0.5639, 0.5773, 0.5517, 0.5987, 0.6127, 0.5703, 0.5939,
        0.6300, 0.6303, 0.6026, 0.6452, 0.6272, 0.6194, 0.6189],
       device='cuda:0')
percent tensor([0.4201, 0.5957, 0.6330, 0.6955, 0.6533, 0.6545, 0.5746, 0.4871, 0.6209,
        0.5957, 0.6812, 0.6668, 0.5329, 0.7369, 0.5036, 0.5264],
       device='cuda:0')
percent tensor([0.6787, 0.7002, 0.6767, 0.6888, 0.6913, 0.7007, 0.7083, 0.6386, 0.6996,
        0.6806, 0.7065, 0.7129, 0.6924, 0.7243, 0.7232, 0.6917],
       device='cuda:0')
percent tensor([0.6574, 0.7418, 0.7766, 0.7797, 0.7925, 0.7762, 0.7469, 0.6967, 0.6237,
        0.6128, 0.6570, 0.6358, 0.5991, 0.6674, 0.6200, 0.6983],
       device='cuda:0')
percent tensor([0.9994, 0.9993, 0.9995, 0.9997, 0.9991, 0.9992, 0.9994, 0.9996, 0.9988,
        0.9992, 0.9996, 0.9995, 0.9990, 0.9987, 0.9994, 0.9993],
       device='cuda:0')
Epoch: 162 | Batch_idx: 0 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (3847/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (5070/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (6298/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (7521/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (8755/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (9984/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (11222/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (12461/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (13680/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (14916/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (16147/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (17383/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (18612/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (19834/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (21068/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (22300/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (23522/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (24746/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (25978/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (27213/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (28445/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (29673/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (30911/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (32140/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (33384/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (34607/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (35838/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (37073/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (38289/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (39518/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (40736/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (41975/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (43214/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (44457/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (45688/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (46928/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (48106/50000)
# TEST : Loss: (0.4094) | Acc: (87.00%) (8794/10000)
percent tensor([0.4863, 0.5168, 0.5092, 0.4844, 0.5198, 0.5147, 0.5211, 0.4836, 0.4915,
        0.5048, 0.5014, 0.5153, 0.4856, 0.4951, 0.5155, 0.4881],
       device='cuda:0')
percent tensor([0.5688, 0.5689, 0.5100, 0.5476, 0.5108, 0.5056, 0.5466, 0.5603, 0.6081,
        0.5702, 0.5878, 0.5436, 0.5906, 0.6468, 0.5299, 0.5442],
       device='cuda:0')
percent tensor([0.6429, 0.5049, 0.7022, 0.6833, 0.6952, 0.6939, 0.5898, 0.6867, 0.6449,
        0.5921, 0.5985, 0.5968, 0.5410, 0.5843, 0.5848, 0.6541],
       device='cuda:0')
percent tensor([0.6167, 0.6299, 0.5627, 0.5771, 0.5519, 0.5929, 0.6146, 0.5701, 0.5862,
        0.6273, 0.6260, 0.6023, 0.6417, 0.6197, 0.6169, 0.6180],
       device='cuda:0')
percent tensor([0.4493, 0.6098, 0.6446, 0.6973, 0.6504, 0.6532, 0.5900, 0.5033, 0.6578,
        0.6312, 0.6996, 0.6690, 0.5568, 0.7645, 0.5144, 0.5194],
       device='cuda:0')
percent tensor([0.6792, 0.7001, 0.6887, 0.6949, 0.7003, 0.6928, 0.7100, 0.6457, 0.7024,
        0.6878, 0.7075, 0.7044, 0.6858, 0.7260, 0.7147, 0.6910],
       device='cuda:0')
percent tensor([0.6728, 0.7502, 0.7685, 0.7693, 0.7762, 0.7476, 0.7480, 0.7367, 0.6338,
        0.6580, 0.6912, 0.6512, 0.6045, 0.6745, 0.6299, 0.6889],
       device='cuda:0')
percent tensor([0.9994, 0.9993, 0.9993, 0.9995, 0.9985, 0.9989, 0.9993, 0.9996, 0.9985,
        0.9993, 0.9997, 0.9996, 0.9991, 0.9988, 0.9994, 0.9991],
       device='cuda:0')
Epoch: 163 | Batch_idx: 0 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (2620/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (97.00%) (3858/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (97.00%) (5093/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (6328/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (7561/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (8793/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (10014/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (11243/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (12486/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (13727/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (14959/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (16192/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (17419/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (18641/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (19881/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (21112/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (22349/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (23587/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (24817/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (26043/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (27278/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (28510/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (29728/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (30963/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (32199/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (33429/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (34674/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (35902/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (37149/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (38391/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (39621/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (40854/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (42073/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (43304/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (44537/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (45771/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (47010/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (48189/50000)
# TEST : Loss: (0.3978) | Acc: (87.00%) (8786/10000)
percent tensor([0.4875, 0.5183, 0.5057, 0.4821, 0.5170, 0.5159, 0.5218, 0.4830, 0.4923,
        0.5048, 0.5034, 0.5130, 0.4860, 0.4979, 0.5164, 0.4887],
       device='cuda:0')
percent tensor([0.5707, 0.5649, 0.5265, 0.5572, 0.5270, 0.5113, 0.5473, 0.5653, 0.6076,
        0.5689, 0.5827, 0.5563, 0.5892, 0.6400, 0.5306, 0.5440],
       device='cuda:0')
percent tensor([0.6396, 0.4965, 0.7117, 0.6913, 0.7013, 0.6902, 0.5886, 0.6874, 0.6392,
        0.5886, 0.5888, 0.6016, 0.5376, 0.5799, 0.5798, 0.6506],
       device='cuda:0')
percent tensor([0.6197, 0.6343, 0.5540, 0.5724, 0.5465, 0.5972, 0.6142, 0.5698, 0.5924,
        0.6300, 0.6298, 0.5964, 0.6464, 0.6277, 0.6171, 0.6210],
       device='cuda:0')
percent tensor([0.4468, 0.6044, 0.6382, 0.7175, 0.6718, 0.6660, 0.6012, 0.5189, 0.6500,
        0.6128, 0.7060, 0.6840, 0.5445, 0.7320, 0.5195, 0.5348],
       device='cuda:0')
percent tensor([0.6815, 0.7042, 0.6721, 0.6821, 0.6904, 0.6997, 0.7155, 0.6417, 0.7042,
        0.6860, 0.7140, 0.7050, 0.6922, 0.7304, 0.7186, 0.6928],
       device='cuda:0')
percent tensor([0.6503, 0.7588, 0.7882, 0.7722, 0.7853, 0.7649, 0.7320, 0.7132, 0.6207,
        0.6387, 0.6770, 0.6661, 0.5839, 0.6573, 0.6373, 0.6744],
       device='cuda:0')
percent tensor([0.9995, 0.9993, 0.9994, 0.9996, 0.9987, 0.9991, 0.9993, 0.9992, 0.9988,
        0.9992, 0.9997, 0.9996, 0.9991, 0.9992, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 164 | Batch_idx: 0 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (2600/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (3842/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (5081/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (6327/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (7562/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (8807/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (10042/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (11278/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (12502/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (13745/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (14982/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (16223/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (17454/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (18684/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (19920/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (21149/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (22388/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (23624/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (24863/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (26104/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (27340/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (28571/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (29794/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (31031/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (32259/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (33490/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (34725/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (35950/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (37180/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (38415/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (39650/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (40887/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (42113/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (43346/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (44583/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (45820/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (47054/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (48240/50000)
# TEST : Loss: (0.4305) | Acc: (87.00%) (8785/10000)
percent tensor([0.4853, 0.5193, 0.5004, 0.4810, 0.5132, 0.5131, 0.5211, 0.4807, 0.4913,
        0.5038, 0.5021, 0.5103, 0.4853, 0.5010, 0.5161, 0.4882],
       device='cuda:0')
percent tensor([0.5716, 0.5748, 0.5128, 0.5536, 0.5163, 0.5146, 0.5519, 0.5638, 0.6111,
        0.5720, 0.5906, 0.5452, 0.5944, 0.6522, 0.5342, 0.5492],
       device='cuda:0')
percent tensor([0.6314, 0.4882, 0.7012, 0.6872, 0.6917, 0.6943, 0.5746, 0.6836, 0.6321,
        0.5763, 0.5868, 0.5855, 0.5307, 0.5663, 0.5782, 0.6453],
       device='cuda:0')
percent tensor([0.6225, 0.6347, 0.5628, 0.5752, 0.5500, 0.5904, 0.6173, 0.5731, 0.5931,
        0.6344, 0.6333, 0.6087, 0.6476, 0.6262, 0.6182, 0.6206],
       device='cuda:0')
percent tensor([0.4625, 0.5952, 0.6304, 0.6974, 0.6544, 0.6781, 0.5749, 0.4840, 0.6460,
        0.5875, 0.6875, 0.6599, 0.5346, 0.7290, 0.5288, 0.5384],
       device='cuda:0')
percent tensor([0.6844, 0.7045, 0.6907, 0.6907, 0.6982, 0.6976, 0.7106, 0.6418, 0.7060,
        0.6861, 0.7099, 0.7144, 0.6940, 0.7204, 0.7200, 0.6944],
       device='cuda:0')
percent tensor([0.6695, 0.7420, 0.7790, 0.7749, 0.7922, 0.7754, 0.7458, 0.7250, 0.6013,
        0.6459, 0.6610, 0.6465, 0.5938, 0.6809, 0.6247, 0.6745],
       device='cuda:0')
percent tensor([0.9996, 0.9994, 0.9994, 0.9996, 0.9991, 0.9991, 0.9995, 0.9995, 0.9987,
        0.9993, 0.9996, 0.9996, 0.9991, 0.9987, 0.9995, 0.9993],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 165 | Batch_idx: 0 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 165 | Batch_idx: 10 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 165 | Batch_idx: 20 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (94.00%) (2551/2688)
Epoch: 165 | Batch_idx: 30 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (3779/3968)
Epoch: 165 | Batch_idx: 40 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (4995/5248)
Epoch: 165 | Batch_idx: 50 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (94.00%) (6190/6528)
Epoch: 165 | Batch_idx: 60 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (94.00%) (7410/7808)
Epoch: 165 | Batch_idx: 70 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (94.00%) (8623/9088)
Epoch: 165 | Batch_idx: 80 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (94.00%) (9837/10368)
Epoch: 165 | Batch_idx: 90 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (94.00%) (11060/11648)
Epoch: 165 | Batch_idx: 100 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (94.00%) (12278/12928)
Epoch: 165 | Batch_idx: 110 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (13499/14208)
Epoch: 165 | Batch_idx: 120 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (14716/15488)
Epoch: 165 | Batch_idx: 130 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (94.00%) (15928/16768)
Epoch: 165 | Batch_idx: 140 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (94.00%) (17144/18048)
Epoch: 165 | Batch_idx: 150 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (18366/19328)
Epoch: 165 | Batch_idx: 160 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (19589/20608)
Epoch: 165 | Batch_idx: 170 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (20807/21888)
Epoch: 165 | Batch_idx: 180 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (22023/23168)
Epoch: 165 | Batch_idx: 190 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (23245/24448)
Epoch: 165 | Batch_idx: 200 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (24457/25728)
Epoch: 165 | Batch_idx: 210 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (25672/27008)
Epoch: 165 | Batch_idx: 220 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (26888/28288)
Epoch: 165 | Batch_idx: 230 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (28110/29568)
Epoch: 165 | Batch_idx: 240 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (29333/30848)
Epoch: 165 | Batch_idx: 250 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (30570/32128)
Epoch: 165 | Batch_idx: 260 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (31778/33408)
Epoch: 165 | Batch_idx: 270 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (32987/34688)
Epoch: 165 | Batch_idx: 280 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (34208/35968)
Epoch: 165 | Batch_idx: 290 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (35435/37248)
Epoch: 165 | Batch_idx: 300 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (36655/38528)
Epoch: 165 | Batch_idx: 310 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (37881/39808)
Epoch: 165 | Batch_idx: 320 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (39108/41088)
Epoch: 165 | Batch_idx: 330 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (40338/42368)
Epoch: 165 | Batch_idx: 340 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (41547/43648)
Epoch: 165 | Batch_idx: 350 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (42781/44928)
Epoch: 165 | Batch_idx: 360 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (44022/46208)
Epoch: 165 | Batch_idx: 370 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (45256/47488)
Epoch: 165 | Batch_idx: 380 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (46471/48768)
Epoch: 165 | Batch_idx: 390 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (47648/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_165.pth.tar'
# TEST : Loss: (0.4029) | Acc: (88.00%) (8836/10000)
percent tensor([0.4923, 0.5262, 0.5079, 0.4866, 0.5208, 0.5178, 0.5290, 0.4879, 0.4990,
        0.5111, 0.5087, 0.5183, 0.4917, 0.5084, 0.5221, 0.4947],
       device='cuda:0')
percent tensor([0.5848, 0.5863, 0.5337, 0.5676, 0.5371, 0.5226, 0.5680, 0.5848, 0.6250,
        0.5845, 0.5990, 0.5642, 0.6077, 0.6625, 0.5452, 0.5595],
       device='cuda:0')
percent tensor([0.6445, 0.4876, 0.7126, 0.7060, 0.7081, 0.7120, 0.5858, 0.7082, 0.6326,
        0.5753, 0.5846, 0.5847, 0.5263, 0.5707, 0.5929, 0.6576],
       device='cuda:0')
percent tensor([0.6672, 0.6753, 0.6059, 0.6170, 0.5934, 0.6264, 0.6651, 0.6203, 0.6396,
        0.6804, 0.6769, 0.6601, 0.6919, 0.6708, 0.6627, 0.6650],
       device='cuda:0')
percent tensor([0.4903, 0.6361, 0.6428, 0.7082, 0.6559, 0.7018, 0.6002, 0.4791, 0.6676,
        0.6210, 0.7167, 0.6795, 0.5942, 0.7514, 0.5500, 0.5742],
       device='cuda:0')
percent tensor([0.6814, 0.7019, 0.6851, 0.6901, 0.6919, 0.6973, 0.7097, 0.6320, 0.7045,
        0.6847, 0.7093, 0.7166, 0.6969, 0.7233, 0.7154, 0.6975],
       device='cuda:0')
percent tensor([0.6380, 0.7241, 0.7945, 0.7735, 0.8074, 0.7758, 0.7294, 0.7014, 0.5739,
        0.6304, 0.6432, 0.6430, 0.5451, 0.6398, 0.6023, 0.6499],
       device='cuda:0')
percent tensor([0.9995, 0.9993, 0.9993, 0.9996, 0.9992, 0.9993, 0.9995, 0.9994, 0.9986,
        0.9993, 0.9996, 0.9997, 0.9991, 0.9987, 0.9995, 0.9992],
       device='cuda:0')
Epoch: 166 | Batch_idx: 0 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 166 | Batch_idx: 10 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 166 | Batch_idx: 20 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 166 | Batch_idx: 30 |  Loss: (0.1165) |  Loss2: (0.0000) | Acc: (95.00%) (3799/3968)
Epoch: 166 | Batch_idx: 40 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (95.00%) (5030/5248)
Epoch: 166 | Batch_idx: 50 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (6248/6528)
Epoch: 166 | Batch_idx: 60 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (7460/7808)
Epoch: 166 | Batch_idx: 70 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (8680/9088)
Epoch: 166 | Batch_idx: 80 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (9901/10368)
Epoch: 166 | Batch_idx: 90 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (11136/11648)
Epoch: 166 | Batch_idx: 100 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (12363/12928)
Epoch: 166 | Batch_idx: 110 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (13587/14208)
Epoch: 166 | Batch_idx: 120 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (14798/15488)
Epoch: 166 | Batch_idx: 130 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (16036/16768)
Epoch: 166 | Batch_idx: 140 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (17262/18048)
Epoch: 166 | Batch_idx: 150 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (18490/19328)
Epoch: 166 | Batch_idx: 160 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (19726/20608)
Epoch: 166 | Batch_idx: 170 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (20960/21888)
Epoch: 166 | Batch_idx: 180 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (22188/23168)
Epoch: 166 | Batch_idx: 190 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (23410/24448)
Epoch: 166 | Batch_idx: 200 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (24640/25728)
Epoch: 166 | Batch_idx: 210 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (25868/27008)
Epoch: 166 | Batch_idx: 220 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (27105/28288)
Epoch: 166 | Batch_idx: 230 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (28328/29568)
Epoch: 166 | Batch_idx: 240 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (29550/30848)
Epoch: 166 | Batch_idx: 250 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (95.00%) (30787/32128)
Epoch: 166 | Batch_idx: 260 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (95.00%) (32016/33408)
Epoch: 166 | Batch_idx: 270 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (95.00%) (33257/34688)
Epoch: 166 | Batch_idx: 280 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (95.00%) (34496/35968)
Epoch: 166 | Batch_idx: 290 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (95.00%) (35731/37248)
Epoch: 166 | Batch_idx: 300 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (95.00%) (36962/38528)
Epoch: 166 | Batch_idx: 310 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (95.00%) (38194/39808)
Epoch: 166 | Batch_idx: 320 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (95.00%) (39426/41088)
Epoch: 166 | Batch_idx: 330 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (95.00%) (40662/42368)
Epoch: 166 | Batch_idx: 340 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (95.00%) (41901/43648)
Epoch: 166 | Batch_idx: 350 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (43141/44928)
Epoch: 166 | Batch_idx: 360 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (44381/46208)
Epoch: 166 | Batch_idx: 370 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (45613/47488)
Epoch: 166 | Batch_idx: 380 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (46848/48768)
Epoch: 166 | Batch_idx: 390 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (48040/50000)
# TEST : Loss: (0.3855) | Acc: (88.00%) (8865/10000)
percent tensor([0.4908, 0.5251, 0.5047, 0.4843, 0.5179, 0.5154, 0.5277, 0.4862, 0.4976,
        0.5097, 0.5074, 0.5158, 0.4898, 0.5088, 0.5203, 0.4936],
       device='cuda:0')
percent tensor([0.5781, 0.5787, 0.5281, 0.5622, 0.5325, 0.5137, 0.5618, 0.5812, 0.6200,
        0.5774, 0.5910, 0.5582, 0.6010, 0.6572, 0.5374, 0.5523],
       device='cuda:0')
percent tensor([0.6411, 0.4823, 0.7075, 0.7000, 0.7030, 0.7060, 0.5817, 0.7043, 0.6256,
        0.5674, 0.5754, 0.5789, 0.5215, 0.5644, 0.5877, 0.6522],
       device='cuda:0')
percent tensor([0.6655, 0.6747, 0.6034, 0.6151, 0.5901, 0.6222, 0.6636, 0.6199, 0.6392,
        0.6800, 0.6760, 0.6587, 0.6911, 0.6707, 0.6606, 0.6626],
       device='cuda:0')
percent tensor([0.4860, 0.6376, 0.6450, 0.7092, 0.6621, 0.7128, 0.5987, 0.4774, 0.6669,
        0.6141, 0.7085, 0.6776, 0.5942, 0.7499, 0.5514, 0.5712],
       device='cuda:0')
percent tensor([0.6882, 0.7074, 0.6894, 0.6954, 0.6971, 0.7058, 0.7151, 0.6357, 0.7103,
        0.6895, 0.7163, 0.7236, 0.7037, 0.7313, 0.7227, 0.7047],
       device='cuda:0')
percent tensor([0.6335, 0.7287, 0.8074, 0.7870, 0.8241, 0.7912, 0.7379, 0.6979, 0.5724,
        0.6226, 0.6424, 0.6530, 0.5414, 0.6352, 0.6050, 0.6553],
       device='cuda:0')
percent tensor([0.9995, 0.9994, 0.9994, 0.9996, 0.9992, 0.9993, 0.9995, 0.9995, 0.9986,
        0.9993, 0.9996, 0.9997, 0.9991, 0.9986, 0.9995, 0.9992],
       device='cuda:0')
Epoch: 167 | Batch_idx: 0 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 167 | Batch_idx: 10 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 167 | Batch_idx: 20 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (2594/2688)
Epoch: 167 | Batch_idx: 30 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (3823/3968)
Epoch: 167 | Batch_idx: 40 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (5074/5248)
Epoch: 167 | Batch_idx: 50 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (6301/6528)
Epoch: 167 | Batch_idx: 60 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (7531/7808)
Epoch: 167 | Batch_idx: 70 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (8762/9088)
Epoch: 167 | Batch_idx: 80 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (10003/10368)
Epoch: 167 | Batch_idx: 90 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (11226/11648)
Epoch: 167 | Batch_idx: 100 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (12466/12928)
Epoch: 167 | Batch_idx: 110 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (13698/14208)
Epoch: 167 | Batch_idx: 120 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (14921/15488)
Epoch: 167 | Batch_idx: 130 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (16168/16768)
Epoch: 167 | Batch_idx: 140 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (17404/18048)
Epoch: 167 | Batch_idx: 150 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (18637/19328)
Epoch: 167 | Batch_idx: 160 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (19862/20608)
Epoch: 167 | Batch_idx: 170 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (21101/21888)
Epoch: 167 | Batch_idx: 180 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (22338/23168)
Epoch: 167 | Batch_idx: 190 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (23577/24448)
Epoch: 167 | Batch_idx: 200 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (24818/25728)
Epoch: 167 | Batch_idx: 210 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (26047/27008)
Epoch: 167 | Batch_idx: 220 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (27279/28288)
Epoch: 167 | Batch_idx: 230 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (28520/29568)
Epoch: 167 | Batch_idx: 240 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (29762/30848)
Epoch: 167 | Batch_idx: 250 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (31000/32128)
Epoch: 167 | Batch_idx: 260 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (32239/33408)
Epoch: 167 | Batch_idx: 270 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (33480/34688)
Epoch: 167 | Batch_idx: 280 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (34712/35968)
Epoch: 167 | Batch_idx: 290 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (35941/37248)
Epoch: 167 | Batch_idx: 300 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (37187/38528)
Epoch: 167 | Batch_idx: 310 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (38426/39808)
Epoch: 167 | Batch_idx: 320 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (39666/41088)
Epoch: 167 | Batch_idx: 330 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (40901/42368)
Epoch: 167 | Batch_idx: 340 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (42135/43648)
Epoch: 167 | Batch_idx: 350 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (43366/44928)
Epoch: 167 | Batch_idx: 360 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (44602/46208)
Epoch: 167 | Batch_idx: 370 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (45828/47488)
Epoch: 167 | Batch_idx: 380 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (47062/48768)
Epoch: 167 | Batch_idx: 390 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (48247/50000)
# TEST : Loss: (0.3789) | Acc: (88.00%) (8884/10000)
percent tensor([0.4882, 0.5235, 0.5003, 0.4810, 0.5141, 0.5120, 0.5257, 0.4837, 0.4955,
        0.5078, 0.5054, 0.5128, 0.4872, 0.5085, 0.5178, 0.4918],
       device='cuda:0')
percent tensor([0.5834, 0.5833, 0.5337, 0.5665, 0.5385, 0.5162, 0.5669, 0.5876, 0.6253,
        0.5824, 0.5954, 0.5639, 0.6061, 0.6615, 0.5412, 0.5564],
       device='cuda:0')
percent tensor([0.6396, 0.4811, 0.7060, 0.6962, 0.7027, 0.7043, 0.5833, 0.7022, 0.6222,
        0.5639, 0.5706, 0.5764, 0.5183, 0.5631, 0.5866, 0.6508],
       device='cuda:0')
percent tensor([0.6606, 0.6702, 0.5995, 0.6112, 0.5850, 0.6166, 0.6589, 0.6157, 0.6352,
        0.6755, 0.6710, 0.6548, 0.6866, 0.6667, 0.6550, 0.6571],
       device='cuda:0')
percent tensor([0.4805, 0.6388, 0.6463, 0.7104, 0.6591, 0.7104, 0.5973, 0.4784, 0.6708,
        0.6151, 0.7114, 0.6813, 0.5928, 0.7531, 0.5512, 0.5651],
       device='cuda:0')
percent tensor([0.6833, 0.7005, 0.6839, 0.6924, 0.6906, 0.7032, 0.7094, 0.6287, 0.7039,
        0.6823, 0.7109, 0.7187, 0.6966, 0.7279, 0.7185, 0.6999],
       device='cuda:0')
percent tensor([0.6394, 0.7372, 0.8143, 0.7957, 0.8324, 0.8009, 0.7505, 0.7019, 0.5827,
        0.6326, 0.6544, 0.6574, 0.5458, 0.6450, 0.6134, 0.6672],
       device='cuda:0')
percent tensor([0.9995, 0.9994, 0.9994, 0.9996, 0.9993, 0.9993, 0.9995, 0.9995, 0.9987,
        0.9993, 0.9996, 0.9997, 0.9991, 0.9987, 0.9995, 0.9992],
       device='cuda:0')
Epoch: 168 | Batch_idx: 0 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 168 | Batch_idx: 10 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 168 | Batch_idx: 20 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (2601/2688)
Epoch: 168 | Batch_idx: 30 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (3832/3968)
Epoch: 168 | Batch_idx: 40 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (5065/5248)
Epoch: 168 | Batch_idx: 50 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (6295/6528)
Epoch: 168 | Batch_idx: 60 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (7526/7808)
Epoch: 168 | Batch_idx: 70 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (8761/9088)
Epoch: 168 | Batch_idx: 80 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (10003/10368)
Epoch: 168 | Batch_idx: 90 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (11234/11648)
Epoch: 168 | Batch_idx: 100 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (12468/12928)
Epoch: 168 | Batch_idx: 110 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (13712/14208)
Epoch: 168 | Batch_idx: 120 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (14958/15488)
Epoch: 168 | Batch_idx: 130 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (16197/16768)
Epoch: 168 | Batch_idx: 140 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (17424/18048)
Epoch: 168 | Batch_idx: 150 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (18667/19328)
Epoch: 168 | Batch_idx: 160 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (19902/20608)
Epoch: 168 | Batch_idx: 170 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (21131/21888)
Epoch: 168 | Batch_idx: 180 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (22367/23168)
Epoch: 168 | Batch_idx: 190 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (23600/24448)
Epoch: 168 | Batch_idx: 200 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (24827/25728)
Epoch: 168 | Batch_idx: 210 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (26058/27008)
Epoch: 168 | Batch_idx: 220 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (27296/28288)
Epoch: 168 | Batch_idx: 230 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (28539/29568)
Epoch: 168 | Batch_idx: 240 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (29774/30848)
Epoch: 168 | Batch_idx: 250 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (31012/32128)
Epoch: 168 | Batch_idx: 260 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (32260/33408)
Epoch: 168 | Batch_idx: 270 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (33505/34688)
Epoch: 168 | Batch_idx: 280 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (34748/35968)
Epoch: 168 | Batch_idx: 290 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (35981/37248)
Epoch: 168 | Batch_idx: 300 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (37214/38528)
Epoch: 168 | Batch_idx: 310 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (38451/39808)
Epoch: 168 | Batch_idx: 320 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (39693/41088)
Epoch: 168 | Batch_idx: 330 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (40945/42368)
Epoch: 168 | Batch_idx: 340 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (42186/43648)
Epoch: 168 | Batch_idx: 350 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (43431/44928)
Epoch: 168 | Batch_idx: 360 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (44663/46208)
Epoch: 168 | Batch_idx: 370 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (45902/47488)
Epoch: 168 | Batch_idx: 380 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (47141/48768)
Epoch: 168 | Batch_idx: 390 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (48342/50000)
# TEST : Loss: (0.3715) | Acc: (88.00%) (8891/10000)
percent tensor([0.4858, 0.5212, 0.4982, 0.4784, 0.5118, 0.5090, 0.5236, 0.4815, 0.4933,
        0.5058, 0.5030, 0.5108, 0.4848, 0.5070, 0.5150, 0.4895],
       device='cuda:0')
percent tensor([0.5769, 0.5748, 0.5283, 0.5605, 0.5331, 0.5079, 0.5600, 0.5831, 0.6193,
        0.5747, 0.5875, 0.5585, 0.5997, 0.6543, 0.5334, 0.5488],
       device='cuda:0')
percent tensor([0.6402, 0.4848, 0.7047, 0.6937, 0.7011, 0.7015, 0.5846, 0.6992, 0.6215,
        0.5663, 0.5725, 0.5781, 0.5208, 0.5640, 0.5866, 0.6506],
       device='cuda:0')
percent tensor([0.6581, 0.6699, 0.5966, 0.6080, 0.5815, 0.6119, 0.6578, 0.6134, 0.6347,
        0.6748, 0.6703, 0.6540, 0.6865, 0.6670, 0.6521, 0.6545],
       device='cuda:0')
percent tensor([0.4660, 0.6267, 0.6437, 0.7095, 0.6544, 0.7042, 0.5844, 0.4761, 0.6635,
        0.6015, 0.6997, 0.6743, 0.5761, 0.7496, 0.5360, 0.5510],
       device='cuda:0')
percent tensor([0.6873, 0.7034, 0.6862, 0.6969, 0.6935, 0.7077, 0.7141, 0.6324, 0.7075,
        0.6847, 0.7144, 0.7222, 0.6997, 0.7330, 0.7228, 0.7044],
       device='cuda:0')
percent tensor([0.6371, 0.7356, 0.8148, 0.7963, 0.8340, 0.8026, 0.7498, 0.6983, 0.5744,
        0.6298, 0.6593, 0.6601, 0.5500, 0.6338, 0.6152, 0.6686],
       device='cuda:0')
percent tensor([0.9995, 0.9994, 0.9994, 0.9996, 0.9992, 0.9994, 0.9995, 0.9995, 0.9987,
        0.9993, 0.9996, 0.9997, 0.9991, 0.9987, 0.9995, 0.9992],
       device='cuda:0')
Epoch: 169 | Batch_idx: 0 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 169 | Batch_idx: 10 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 169 | Batch_idx: 20 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (2599/2688)
Epoch: 169 | Batch_idx: 30 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (3841/3968)
Epoch: 169 | Batch_idx: 40 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (5075/5248)
Epoch: 169 | Batch_idx: 50 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (6315/6528)
Epoch: 169 | Batch_idx: 60 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (7557/7808)
Epoch: 169 | Batch_idx: 70 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (8794/9088)
Epoch: 169 | Batch_idx: 80 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (10040/10368)
Epoch: 169 | Batch_idx: 90 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (11277/11648)
Epoch: 169 | Batch_idx: 100 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (12516/12928)
Epoch: 169 | Batch_idx: 110 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (13755/14208)
Epoch: 169 | Batch_idx: 120 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (15003/15488)
Epoch: 169 | Batch_idx: 130 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (16250/16768)
Epoch: 169 | Batch_idx: 140 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (17493/18048)
Epoch: 169 | Batch_idx: 150 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (18730/19328)
Epoch: 169 | Batch_idx: 160 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (19975/20608)
Epoch: 169 | Batch_idx: 170 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (21199/21888)
Epoch: 169 | Batch_idx: 180 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (22437/23168)
Epoch: 169 | Batch_idx: 190 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (23686/24448)
Epoch: 169 | Batch_idx: 200 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (24926/25728)
Epoch: 169 | Batch_idx: 210 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (26174/27008)
Epoch: 169 | Batch_idx: 220 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (27414/28288)
Epoch: 169 | Batch_idx: 230 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (28644/29568)
Epoch: 169 | Batch_idx: 240 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (29885/30848)
Epoch: 169 | Batch_idx: 250 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (31125/32128)
Epoch: 169 | Batch_idx: 260 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (32349/33408)
Epoch: 169 | Batch_idx: 270 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (33594/34688)
Epoch: 169 | Batch_idx: 280 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (34842/35968)
Epoch: 169 | Batch_idx: 290 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (36068/37248)
Epoch: 169 | Batch_idx: 300 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (37321/38528)
Epoch: 169 | Batch_idx: 310 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (38554/39808)
Epoch: 169 | Batch_idx: 320 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (39800/41088)
Epoch: 169 | Batch_idx: 330 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (41031/42368)
Epoch: 169 | Batch_idx: 340 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (42279/43648)
Epoch: 169 | Batch_idx: 350 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (43506/44928)
Epoch: 169 | Batch_idx: 360 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (44762/46208)
Epoch: 169 | Batch_idx: 370 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (46004/47488)
Epoch: 169 | Batch_idx: 380 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (47234/48768)
Epoch: 169 | Batch_idx: 390 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (48428/50000)
# TEST : Loss: (0.3704) | Acc: (89.00%) (8901/10000)
percent tensor([0.4887, 0.5252, 0.5004, 0.4810, 0.5146, 0.5117, 0.5275, 0.4847, 0.4966,
        0.5094, 0.5065, 0.5138, 0.4877, 0.5113, 0.5185, 0.4928],
       device='cuda:0')
percent tensor([0.5728, 0.5699, 0.5249, 0.5578, 0.5292, 0.5030, 0.5550, 0.5795, 0.6150,
        0.5704, 0.5825, 0.5549, 0.5951, 0.6501, 0.5285, 0.5446],
       device='cuda:0')
percent tensor([0.6456, 0.4902, 0.7063, 0.6959, 0.7033, 0.7077, 0.5895, 0.7013, 0.6256,
        0.5700, 0.5777, 0.5802, 0.5251, 0.5712, 0.5927, 0.6557],
       device='cuda:0')
percent tensor([0.6547, 0.6672, 0.5938, 0.6052, 0.5783, 0.6092, 0.6542, 0.6104, 0.6317,
        0.6720, 0.6673, 0.6511, 0.6839, 0.6644, 0.6487, 0.6511],
       device='cuda:0')
percent tensor([0.4777, 0.6406, 0.6522, 0.7166, 0.6661, 0.7134, 0.5992, 0.4838, 0.6745,
        0.6132, 0.7077, 0.6852, 0.5886, 0.7593, 0.5497, 0.5635],
       device='cuda:0')
percent tensor([0.6974, 0.7136, 0.6960, 0.7073, 0.7043, 0.7195, 0.7244, 0.6421, 0.7163,
        0.6943, 0.7243, 0.7311, 0.7093, 0.7429, 0.7334, 0.7160],
       device='cuda:0')
percent tensor([0.6406, 0.7432, 0.8156, 0.7953, 0.8354, 0.8032, 0.7590, 0.7019, 0.5870,
        0.6412, 0.6679, 0.6666, 0.5533, 0.6399, 0.6234, 0.6700],
       device='cuda:0')
percent tensor([0.9995, 0.9994, 0.9994, 0.9996, 0.9993, 0.9994, 0.9995, 0.9995, 0.9987,
        0.9993, 0.9996, 0.9997, 0.9991, 0.9987, 0.9995, 0.9992],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 170 | Batch_idx: 0 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 170 | Batch_idx: 10 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 170 | Batch_idx: 20 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (2615/2688)
Epoch: 170 | Batch_idx: 30 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (3845/3968)
Epoch: 170 | Batch_idx: 40 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (5076/5248)
Epoch: 170 | Batch_idx: 50 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (6315/6528)
Epoch: 170 | Batch_idx: 60 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (7549/7808)
Epoch: 170 | Batch_idx: 70 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (8773/9088)
Epoch: 170 | Batch_idx: 80 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (10001/10368)
Epoch: 170 | Batch_idx: 90 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (11243/11648)
Epoch: 170 | Batch_idx: 100 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (12483/12928)
Epoch: 170 | Batch_idx: 110 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (13720/14208)
Epoch: 170 | Batch_idx: 120 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (14946/15488)
Epoch: 170 | Batch_idx: 130 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (16188/16768)
Epoch: 170 | Batch_idx: 140 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (17421/18048)
Epoch: 170 | Batch_idx: 150 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (18665/19328)
Epoch: 170 | Batch_idx: 160 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (19908/20608)
Epoch: 170 | Batch_idx: 170 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (21131/21888)
Epoch: 170 | Batch_idx: 180 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (22365/23168)
Epoch: 170 | Batch_idx: 190 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (23587/24448)
Epoch: 170 | Batch_idx: 200 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (24828/25728)
Epoch: 170 | Batch_idx: 210 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (26061/27008)
Epoch: 170 | Batch_idx: 220 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (27288/28288)
Epoch: 170 | Batch_idx: 230 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (28525/29568)
Epoch: 170 | Batch_idx: 240 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (29756/30848)
Epoch: 170 | Batch_idx: 250 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (30996/32128)
Epoch: 170 | Batch_idx: 260 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (32231/33408)
Epoch: 170 | Batch_idx: 270 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (33454/34688)
Epoch: 170 | Batch_idx: 280 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (34680/35968)
Epoch: 170 | Batch_idx: 290 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (35913/37248)
Epoch: 170 | Batch_idx: 300 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (37141/38528)
Epoch: 170 | Batch_idx: 310 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (38379/39808)
Epoch: 170 | Batch_idx: 320 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (39608/41088)
Epoch: 170 | Batch_idx: 330 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (40832/42368)
Epoch: 170 | Batch_idx: 340 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (42045/43648)
Epoch: 170 | Batch_idx: 350 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (43273/44928)
Epoch: 170 | Batch_idx: 360 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (44503/46208)
Epoch: 170 | Batch_idx: 370 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (45733/47488)
Epoch: 170 | Batch_idx: 380 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (46971/48768)
Epoch: 170 | Batch_idx: 390 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (48160/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_170.pth.tar'
# TEST : Loss: (0.4111) | Acc: (88.00%) (8837/10000)
percent tensor([0.4884, 0.5276, 0.4961, 0.4842, 0.5116, 0.5131, 0.5279, 0.4852, 0.4950,
        0.5096, 0.5072, 0.5108, 0.4881, 0.5143, 0.5202, 0.4946],
       device='cuda:0')
percent tensor([0.5773, 0.5657, 0.5253, 0.5548, 0.5316, 0.5063, 0.5528, 0.5755, 0.6152,
        0.5680, 0.5863, 0.5524, 0.5969, 0.6446, 0.5259, 0.5464],
       device='cuda:0')
percent tensor([0.6402, 0.4831, 0.7130, 0.6863, 0.7136, 0.6956, 0.5913, 0.6907, 0.6338,
        0.5722, 0.5763, 0.5895, 0.5245, 0.5544, 0.5818, 0.6474],
       device='cuda:0')
percent tensor([0.6531, 0.6674, 0.5889, 0.6073, 0.5721, 0.6129, 0.6526, 0.6100, 0.6260,
        0.6680, 0.6625, 0.6446, 0.6846, 0.6626, 0.6501, 0.6502],
       device='cuda:0')
percent tensor([0.4658, 0.6503, 0.6450, 0.7118, 0.6613, 0.7055, 0.6025, 0.5134, 0.6662,
        0.6317, 0.7053, 0.6790, 0.5573, 0.7766, 0.5535, 0.5596],
       device='cuda:0')
percent tensor([0.6984, 0.7175, 0.6911, 0.7072, 0.7017, 0.7170, 0.7256, 0.6478, 0.7146,
        0.6999, 0.7267, 0.7222, 0.7035, 0.7479, 0.7365, 0.7165],
       device='cuda:0')
percent tensor([0.6514, 0.7201, 0.8158, 0.8022, 0.8392, 0.8030, 0.7543, 0.7392, 0.6317,
        0.6265, 0.6458, 0.6627, 0.5558, 0.6322, 0.6248, 0.6956],
       device='cuda:0')
percent tensor([0.9996, 0.9994, 0.9996, 0.9998, 0.9992, 0.9994, 0.9994, 0.9997, 0.9990,
        0.9994, 0.9997, 0.9996, 0.9991, 0.9989, 0.9994, 0.9994],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.2620, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(825.1968, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(835.7538, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1515.2234, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(480.0851, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2263.3643, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4255.6426, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1362.5294, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6227.4502, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11660.7959, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3826.5295, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16173.7754, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 171 | Batch_idx: 0 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 171 | Batch_idx: 10 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 171 | Batch_idx: 20 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (2595/2688)
Epoch: 171 | Batch_idx: 30 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (3823/3968)
Epoch: 171 | Batch_idx: 40 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (5070/5248)
Epoch: 171 | Batch_idx: 50 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (6311/6528)
Epoch: 171 | Batch_idx: 60 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (7550/7808)
Epoch: 171 | Batch_idx: 70 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (8796/9088)
Epoch: 171 | Batch_idx: 80 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (10023/10368)
Epoch: 171 | Batch_idx: 90 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (11246/11648)
Epoch: 171 | Batch_idx: 100 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (12469/12928)
Epoch: 171 | Batch_idx: 110 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (13703/14208)
Epoch: 171 | Batch_idx: 120 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (14932/15488)
Epoch: 171 | Batch_idx: 130 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (16159/16768)
Epoch: 171 | Batch_idx: 140 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (17379/18048)
Epoch: 171 | Batch_idx: 150 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (18610/19328)
Epoch: 171 | Batch_idx: 160 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (19850/20608)
Epoch: 171 | Batch_idx: 170 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (21078/21888)
Epoch: 171 | Batch_idx: 180 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (22321/23168)
Epoch: 171 | Batch_idx: 190 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (23563/24448)
Epoch: 171 | Batch_idx: 200 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (24794/25728)
Epoch: 171 | Batch_idx: 210 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (26030/27008)
Epoch: 171 | Batch_idx: 220 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (27270/28288)
Epoch: 171 | Batch_idx: 230 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (28508/29568)
Epoch: 171 | Batch_idx: 240 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (29740/30848)
Epoch: 171 | Batch_idx: 250 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (30968/32128)
Epoch: 171 | Batch_idx: 260 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (32202/33408)
Epoch: 171 | Batch_idx: 270 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (33438/34688)
Epoch: 171 | Batch_idx: 280 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (34670/35968)
Epoch: 171 | Batch_idx: 290 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (35891/37248)
Epoch: 171 | Batch_idx: 300 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (37129/38528)
Epoch: 171 | Batch_idx: 310 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (38361/39808)
Epoch: 171 | Batch_idx: 320 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (39593/41088)
Epoch: 171 | Batch_idx: 330 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (40823/42368)
Epoch: 171 | Batch_idx: 340 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (42045/43648)
Epoch: 171 | Batch_idx: 350 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (43287/44928)
Epoch: 171 | Batch_idx: 360 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (44520/46208)
Epoch: 171 | Batch_idx: 370 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (45759/47488)
Epoch: 171 | Batch_idx: 380 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (46985/48768)
Epoch: 171 | Batch_idx: 390 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (48181/50000)
# TEST : Loss: (0.4116) | Acc: (87.00%) (8777/10000)
percent tensor([0.4895, 0.5261, 0.5005, 0.4840, 0.5164, 0.5159, 0.5282, 0.4860, 0.4959,
        0.5101, 0.5079, 0.5134, 0.4887, 0.5105, 0.5202, 0.4948],
       device='cuda:0')
percent tensor([0.5741, 0.5627, 0.5228, 0.5543, 0.5280, 0.5051, 0.5497, 0.5742, 0.6162,
        0.5651, 0.5822, 0.5517, 0.5939, 0.6472, 0.5268, 0.5446],
       device='cuda:0')
percent tensor([0.6353, 0.4855, 0.7174, 0.6831, 0.7089, 0.6862, 0.5922, 0.6946, 0.6328,
        0.5783, 0.5713, 0.5944, 0.5182, 0.5713, 0.5762, 0.6463],
       device='cuda:0')
percent tensor([0.6548, 0.6707, 0.5892, 0.6107, 0.5737, 0.6213, 0.6541, 0.6088, 0.6272,
        0.6686, 0.6634, 0.6406, 0.6832, 0.6632, 0.6529, 0.6535],
       device='cuda:0')
percent tensor([0.4507, 0.6186, 0.6247, 0.7043, 0.6486, 0.6960, 0.5892, 0.4734, 0.6689,
        0.6047, 0.7092, 0.6663, 0.5544, 0.7786, 0.5296, 0.5424],
       device='cuda:0')
percent tensor([0.6943, 0.7130, 0.6834, 0.7111, 0.6974, 0.7216, 0.7283, 0.6478, 0.7151,
        0.6941, 0.7212, 0.7199, 0.6994, 0.7463, 0.7377, 0.7159],
       device='cuda:0')
percent tensor([0.6409, 0.7371, 0.8064, 0.8065, 0.8274, 0.7931, 0.7394, 0.7306, 0.6375,
        0.6441, 0.6859, 0.6870, 0.5973, 0.6384, 0.6071, 0.6860],
       device='cuda:0')
percent tensor([0.9994, 0.9995, 0.9995, 0.9998, 0.9992, 0.9993, 0.9993, 0.9997, 0.9988,
        0.9993, 0.9997, 0.9997, 0.9992, 0.9988, 0.9995, 0.9991],
       device='cuda:0')
Epoch: 172 | Batch_idx: 0 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 172 | Batch_idx: 10 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 172 | Batch_idx: 20 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 172 | Batch_idx: 30 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 172 | Batch_idx: 40 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (97.00%) (5098/5248)
Epoch: 172 | Batch_idx: 50 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (6332/6528)
Epoch: 172 | Batch_idx: 60 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (7567/7808)
Epoch: 172 | Batch_idx: 70 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (8790/9088)
Epoch: 172 | Batch_idx: 80 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (10035/10368)
Epoch: 172 | Batch_idx: 90 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (11269/11648)
Epoch: 172 | Batch_idx: 100 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (12515/12928)
Epoch: 172 | Batch_idx: 110 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (13760/14208)
Epoch: 172 | Batch_idx: 120 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (15007/15488)
Epoch: 172 | Batch_idx: 130 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (16248/16768)
Epoch: 172 | Batch_idx: 140 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (17491/18048)
Epoch: 172 | Batch_idx: 150 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (18729/19328)
Epoch: 172 | Batch_idx: 160 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (19965/20608)
Epoch: 172 | Batch_idx: 170 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (21211/21888)
Epoch: 172 | Batch_idx: 180 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (22423/23168)
Epoch: 172 | Batch_idx: 190 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (23662/24448)
Epoch: 172 | Batch_idx: 200 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (24900/25728)
Epoch: 172 | Batch_idx: 210 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (26124/27008)
Epoch: 172 | Batch_idx: 220 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (27363/28288)
Epoch: 172 | Batch_idx: 230 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (28591/29568)
Epoch: 172 | Batch_idx: 240 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (29831/30848)
Epoch: 172 | Batch_idx: 250 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (31071/32128)
Epoch: 172 | Batch_idx: 260 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (32304/33408)
Epoch: 172 | Batch_idx: 270 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (33533/34688)
Epoch: 172 | Batch_idx: 280 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (34756/35968)
Epoch: 172 | Batch_idx: 290 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (35980/37248)
Epoch: 172 | Batch_idx: 300 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (37213/38528)
Epoch: 172 | Batch_idx: 310 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (38436/39808)
Epoch: 172 | Batch_idx: 320 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (39670/41088)
Epoch: 172 | Batch_idx: 330 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (40903/42368)
Epoch: 172 | Batch_idx: 340 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (42146/43648)
Epoch: 172 | Batch_idx: 350 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (43388/44928)
Epoch: 172 | Batch_idx: 360 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (44622/46208)
Epoch: 172 | Batch_idx: 370 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (45851/47488)
Epoch: 172 | Batch_idx: 380 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (47075/48768)
Epoch: 172 | Batch_idx: 390 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (48266/50000)
# TEST : Loss: (0.4146) | Acc: (88.00%) (8822/10000)
percent tensor([0.4896, 0.5262, 0.5009, 0.4834, 0.5168, 0.5138, 0.5283, 0.4858, 0.4957,
        0.5101, 0.5077, 0.5140, 0.4889, 0.5113, 0.5200, 0.4944],
       device='cuda:0')
percent tensor([0.5723, 0.5619, 0.5304, 0.5613, 0.5348, 0.5095, 0.5494, 0.5778, 0.6173,
        0.5653, 0.5821, 0.5569, 0.5918, 0.6465, 0.5281, 0.5425],
       device='cuda:0')
percent tensor([0.6378, 0.4883, 0.7019, 0.6777, 0.6993, 0.6911, 0.5857, 0.6871, 0.6325,
        0.5655, 0.5732, 0.5790, 0.5212, 0.5649, 0.5831, 0.6461],
       device='cuda:0')
percent tensor([0.6612, 0.6739, 0.5943, 0.6103, 0.5784, 0.6218, 0.6547, 0.6097, 0.6305,
        0.6747, 0.6710, 0.6469, 0.6910, 0.6674, 0.6542, 0.6578],
       device='cuda:0')
percent tensor([0.4232, 0.6316, 0.6307, 0.7220, 0.6429, 0.6796, 0.5978, 0.4896, 0.6603,
        0.6306, 0.6971, 0.6936, 0.5404, 0.7722, 0.5317, 0.5387],
       device='cuda:0')
percent tensor([0.6949, 0.7161, 0.6976, 0.7084, 0.7020, 0.7182, 0.7215, 0.6445, 0.7138,
        0.6980, 0.7255, 0.7132, 0.7040, 0.7466, 0.7369, 0.7153],
       device='cuda:0')
percent tensor([0.6302, 0.7330, 0.7830, 0.7705, 0.8111, 0.7879, 0.7525, 0.7137, 0.6102,
        0.6386, 0.6291, 0.6203, 0.5691, 0.6147, 0.5670, 0.6874],
       device='cuda:0')
percent tensor([0.9995, 0.9993, 0.9996, 0.9998, 0.9989, 0.9993, 0.9995, 0.9996, 0.9990,
        0.9994, 0.9996, 0.9996, 0.9992, 0.9990, 0.9995, 0.9991],
       device='cuda:0')
Epoch: 173 | Batch_idx: 0 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 173 | Batch_idx: 10 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 173 | Batch_idx: 20 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 173 | Batch_idx: 30 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (3859/3968)
Epoch: 173 | Batch_idx: 40 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (5110/5248)
Epoch: 173 | Batch_idx: 50 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (6347/6528)
Epoch: 173 | Batch_idx: 60 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (7588/7808)
Epoch: 173 | Batch_idx: 70 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (8833/9088)
Epoch: 173 | Batch_idx: 80 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (10075/10368)
Epoch: 173 | Batch_idx: 90 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (11318/11648)
Epoch: 173 | Batch_idx: 100 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (12554/12928)
Epoch: 173 | Batch_idx: 110 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (13806/14208)
Epoch: 173 | Batch_idx: 120 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (15044/15488)
Epoch: 173 | Batch_idx: 130 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (16287/16768)
Epoch: 173 | Batch_idx: 140 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (17522/18048)
Epoch: 173 | Batch_idx: 150 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (18761/19328)
Epoch: 173 | Batch_idx: 160 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (20003/20608)
Epoch: 173 | Batch_idx: 170 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (21247/21888)
Epoch: 173 | Batch_idx: 180 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (22484/23168)
Epoch: 173 | Batch_idx: 190 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (23712/24448)
Epoch: 173 | Batch_idx: 200 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (24955/25728)
Epoch: 173 | Batch_idx: 210 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (26198/27008)
Epoch: 173 | Batch_idx: 220 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (27444/28288)
Epoch: 173 | Batch_idx: 230 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (28681/29568)
Epoch: 173 | Batch_idx: 240 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (29911/30848)
Epoch: 173 | Batch_idx: 250 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (31145/32128)
Epoch: 173 | Batch_idx: 260 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (32372/33408)
Epoch: 173 | Batch_idx: 270 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (33605/34688)
Epoch: 173 | Batch_idx: 280 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (34833/35968)
Epoch: 173 | Batch_idx: 290 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (36075/37248)
Epoch: 173 | Batch_idx: 300 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (37307/38528)
Epoch: 173 | Batch_idx: 310 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (38538/39808)
Epoch: 173 | Batch_idx: 320 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (39766/41088)
Epoch: 173 | Batch_idx: 330 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (40993/42368)
Epoch: 173 | Batch_idx: 340 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (42221/43648)
Epoch: 173 | Batch_idx: 350 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (43457/44928)
Epoch: 173 | Batch_idx: 360 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (44697/46208)
Epoch: 173 | Batch_idx: 370 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (45931/47488)
Epoch: 173 | Batch_idx: 380 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (47169/48768)
Epoch: 173 | Batch_idx: 390 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (48358/50000)
# TEST : Loss: (0.3969) | Acc: (88.00%) (8867/10000)
percent tensor([0.4913, 0.5259, 0.5000, 0.4810, 0.5156, 0.5141, 0.5283, 0.4841, 0.4964,
        0.5100, 0.5091, 0.5141, 0.4902, 0.5106, 0.5196, 0.4942],
       device='cuda:0')
percent tensor([0.5722, 0.5605, 0.5237, 0.5593, 0.5325, 0.5070, 0.5436, 0.5749, 0.6181,
        0.5639, 0.5845, 0.5522, 0.5933, 0.6396, 0.5257, 0.5432],
       device='cuda:0')
percent tensor([0.6407, 0.4886, 0.7163, 0.6810, 0.7104, 0.6895, 0.5963, 0.6902, 0.6362,
        0.5763, 0.5801, 0.5985, 0.5230, 0.5699, 0.5794, 0.6476],
       device='cuda:0')
percent tensor([0.6557, 0.6747, 0.5838, 0.6091, 0.5719, 0.6201, 0.6542, 0.6085, 0.6310,
        0.6711, 0.6689, 0.6429, 0.6882, 0.6681, 0.6566, 0.6559],
       device='cuda:0')
percent tensor([0.4427, 0.6301, 0.6291, 0.7088, 0.6552, 0.6740, 0.6029, 0.4964, 0.6756,
        0.6181, 0.7108, 0.6715, 0.5549, 0.7735, 0.5193, 0.5435],
       device='cuda:0')
percent tensor([0.6924, 0.7115, 0.6852, 0.7045, 0.6988, 0.7167, 0.7222, 0.6425, 0.7110,
        0.6926, 0.7174, 0.7117, 0.6969, 0.7378, 0.7359, 0.7134],
       device='cuda:0')
percent tensor([0.6499, 0.7436, 0.8080, 0.7991, 0.8242, 0.7971, 0.7497, 0.7103, 0.6410,
        0.6316, 0.6679, 0.6811, 0.5653, 0.6417, 0.6080, 0.7021],
       device='cuda:0')
percent tensor([0.9995, 0.9993, 0.9995, 0.9998, 0.9990, 0.9995, 0.9994, 0.9996, 0.9991,
        0.9994, 0.9997, 0.9997, 0.9991, 0.9989, 0.9995, 0.9991],
       device='cuda:0')
Epoch: 174 | Batch_idx: 0 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 174 | Batch_idx: 10 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 174 | Batch_idx: 20 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 174 | Batch_idx: 30 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (3844/3968)
Epoch: 174 | Batch_idx: 40 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (5088/5248)
Epoch: 174 | Batch_idx: 50 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (6332/6528)
Epoch: 174 | Batch_idx: 60 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (7569/7808)
Epoch: 174 | Batch_idx: 70 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (8811/9088)
Epoch: 174 | Batch_idx: 80 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (10043/10368)
Epoch: 174 | Batch_idx: 90 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (11275/11648)
Epoch: 174 | Batch_idx: 100 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (12519/12928)
Epoch: 174 | Batch_idx: 110 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (13752/14208)
Epoch: 174 | Batch_idx: 120 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (14984/15488)
Epoch: 174 | Batch_idx: 130 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (16220/16768)
Epoch: 174 | Batch_idx: 140 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (17463/18048)
Epoch: 174 | Batch_idx: 150 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (18695/19328)
Epoch: 174 | Batch_idx: 160 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (19936/20608)
Epoch: 174 | Batch_idx: 170 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (21177/21888)
Epoch: 174 | Batch_idx: 180 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (22406/23168)
Epoch: 174 | Batch_idx: 190 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (23647/24448)
Epoch: 174 | Batch_idx: 200 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (24885/25728)
Epoch: 174 | Batch_idx: 210 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (26130/27008)
Epoch: 174 | Batch_idx: 220 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (27360/28288)
Epoch: 174 | Batch_idx: 230 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (28614/29568)
Epoch: 174 | Batch_idx: 240 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (29858/30848)
Epoch: 174 | Batch_idx: 250 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (31091/32128)
Epoch: 174 | Batch_idx: 260 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (32335/33408)
Epoch: 174 | Batch_idx: 270 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (33574/34688)
Epoch: 174 | Batch_idx: 280 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (34797/35968)
Epoch: 174 | Batch_idx: 290 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (36031/37248)
Epoch: 174 | Batch_idx: 300 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (37259/38528)
Epoch: 174 | Batch_idx: 310 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (38500/39808)
Epoch: 174 | Batch_idx: 320 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (39738/41088)
Epoch: 174 | Batch_idx: 330 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (40980/42368)
Epoch: 174 | Batch_idx: 340 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (42222/43648)
Epoch: 174 | Batch_idx: 350 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (43454/44928)
Epoch: 174 | Batch_idx: 360 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (44700/46208)
Epoch: 174 | Batch_idx: 370 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (45949/47488)
Epoch: 174 | Batch_idx: 380 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (47197/48768)
Epoch: 174 | Batch_idx: 390 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (48390/50000)
# TEST : Loss: (0.3971) | Acc: (88.00%) (8890/10000)
percent tensor([0.4926, 0.5254, 0.5059, 0.4845, 0.5190, 0.5160, 0.5283, 0.4873, 0.4973,
        0.5109, 0.5090, 0.5162, 0.4904, 0.5088, 0.5205, 0.4952],
       device='cuda:0')
percent tensor([0.5714, 0.5596, 0.5241, 0.5595, 0.5317, 0.5042, 0.5459, 0.5747, 0.6091,
        0.5663, 0.5804, 0.5548, 0.5896, 0.6382, 0.5279, 0.5402],
       device='cuda:0')
percent tensor([0.6379, 0.4950, 0.7025, 0.6838, 0.7037, 0.6899, 0.5965, 0.6924, 0.6324,
        0.5737, 0.5838, 0.5872, 0.5217, 0.5840, 0.5861, 0.6546],
       device='cuda:0')
percent tensor([0.6541, 0.6662, 0.5903, 0.6070, 0.5775, 0.6164, 0.6485, 0.6068, 0.6270,
        0.6644, 0.6599, 0.6408, 0.6796, 0.6560, 0.6490, 0.6495],
       device='cuda:0')
percent tensor([0.4489, 0.5976, 0.6562, 0.7101, 0.6675, 0.6740, 0.5861, 0.4992, 0.6505,
        0.6084, 0.6912, 0.6956, 0.5419, 0.7452, 0.5269, 0.5288],
       device='cuda:0')
percent tensor([0.6927, 0.7118, 0.6995, 0.7108, 0.7063, 0.7192, 0.7229, 0.6496, 0.7121,
        0.6940, 0.7235, 0.7229, 0.7036, 0.7387, 0.7376, 0.7125],
       device='cuda:0')
percent tensor([0.6776, 0.7460, 0.8103, 0.7943, 0.8134, 0.7938, 0.7544, 0.7152, 0.6137,
        0.6585, 0.6801, 0.6975, 0.6001, 0.6595, 0.6249, 0.7076],
       device='cuda:0')
percent tensor([0.9995, 0.9994, 0.9995, 0.9998, 0.9990, 0.9992, 0.9993, 0.9997, 0.9991,
        0.9995, 0.9997, 0.9997, 0.9991, 0.9991, 0.9995, 0.9993],
       device='cuda:0')
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 175 | Batch_idx: 0 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 175 | Batch_idx: 10 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 175 | Batch_idx: 20 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (2604/2688)
Epoch: 175 | Batch_idx: 30 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (3845/3968)
Epoch: 175 | Batch_idx: 40 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (5061/5248)
Epoch: 175 | Batch_idx: 50 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (6276/6528)
Epoch: 175 | Batch_idx: 60 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (7507/7808)
Epoch: 175 | Batch_idx: 70 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (8734/9088)
Epoch: 175 | Batch_idx: 80 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (9964/10368)
Epoch: 175 | Batch_idx: 90 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (11201/11648)
Epoch: 175 | Batch_idx: 100 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (12437/12928)
Epoch: 175 | Batch_idx: 110 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (13682/14208)
Epoch: 175 | Batch_idx: 120 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (14911/15488)
Epoch: 175 | Batch_idx: 130 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (16147/16768)
Epoch: 175 | Batch_idx: 140 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (17379/18048)
Epoch: 175 | Batch_idx: 150 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (18615/19328)
Epoch: 175 | Batch_idx: 160 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (19849/20608)
Epoch: 175 | Batch_idx: 170 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (21089/21888)
Epoch: 175 | Batch_idx: 180 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (22314/23168)
Epoch: 175 | Batch_idx: 190 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (23541/24448)
Epoch: 175 | Batch_idx: 200 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (24781/25728)
Epoch: 175 | Batch_idx: 210 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (26005/27008)
Epoch: 175 | Batch_idx: 220 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (27239/28288)
Epoch: 175 | Batch_idx: 230 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (28485/29568)
Epoch: 175 | Batch_idx: 240 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (29722/30848)
Epoch: 175 | Batch_idx: 250 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (30963/32128)
Epoch: 175 | Batch_idx: 260 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (32209/33408)
Epoch: 175 | Batch_idx: 270 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (33446/34688)
Epoch: 175 | Batch_idx: 280 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (34694/35968)
Epoch: 175 | Batch_idx: 290 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (35945/37248)
Epoch: 175 | Batch_idx: 300 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (37186/38528)
Epoch: 175 | Batch_idx: 310 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (38437/39808)
Epoch: 175 | Batch_idx: 320 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (39686/41088)
Epoch: 175 | Batch_idx: 330 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (40919/42368)
Epoch: 175 | Batch_idx: 340 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (42152/43648)
Epoch: 175 | Batch_idx: 350 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (43392/44928)
Epoch: 175 | Batch_idx: 360 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (44633/46208)
Epoch: 175 | Batch_idx: 370 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (45866/47488)
Epoch: 175 | Batch_idx: 380 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (47095/48768)
Epoch: 175 | Batch_idx: 390 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (48291/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_175.pth.tar'
# TEST : Loss: (0.3884) | Acc: (88.00%) (8897/10000)
percent tensor([0.5060, 0.5412, 0.5163, 0.4978, 0.5315, 0.5285, 0.5435, 0.5015, 0.5118,
        0.5251, 0.5239, 0.5287, 0.5050, 0.5256, 0.5349, 0.5093],
       device='cuda:0')
percent tensor([0.5816, 0.5775, 0.5311, 0.5698, 0.5411, 0.5133, 0.5625, 0.5866, 0.6216,
        0.5817, 0.5938, 0.5647, 0.6008, 0.6607, 0.5399, 0.5546],
       device='cuda:0')
percent tensor([0.6362, 0.5008, 0.6927, 0.6749, 0.6936, 0.6899, 0.5948, 0.6886, 0.6280,
        0.5736, 0.5852, 0.5732, 0.5216, 0.5873, 0.5890, 0.6553],
       device='cuda:0')
percent tensor([0.6641, 0.6749, 0.6050, 0.6173, 0.5902, 0.6228, 0.6606, 0.6187, 0.6367,
        0.6720, 0.6665, 0.6552, 0.6915, 0.6632, 0.6568, 0.6590],
       device='cuda:0')
percent tensor([0.4514, 0.6045, 0.6609, 0.7173, 0.6673, 0.6880, 0.5906, 0.5081, 0.6620,
        0.6210, 0.6963, 0.7074, 0.5440, 0.7611, 0.5481, 0.5409],
       device='cuda:0')
percent tensor([0.7133, 0.7322, 0.7225, 0.7329, 0.7285, 0.7410, 0.7422, 0.6691, 0.7351,
        0.7166, 0.7445, 0.7483, 0.7300, 0.7562, 0.7605, 0.7345],
       device='cuda:0')
percent tensor([0.6480, 0.7246, 0.8001, 0.7703, 0.8083, 0.7745, 0.7370, 0.6994, 0.5893,
        0.6672, 0.6674, 0.6445, 0.5420, 0.6121, 0.5949, 0.6793],
       device='cuda:0')
percent tensor([0.9994, 0.9994, 0.9996, 0.9998, 0.9991, 0.9991, 0.9993, 0.9996, 0.9990,
        0.9996, 0.9997, 0.9997, 0.9990, 0.9989, 0.9995, 0.9992],
       device='cuda:0')
Epoch: 176 | Batch_idx: 0 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 176 | Batch_idx: 10 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 176 | Batch_idx: 20 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (2605/2688)
Epoch: 176 | Batch_idx: 30 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (3843/3968)
Epoch: 176 | Batch_idx: 40 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (5089/5248)
Epoch: 176 | Batch_idx: 50 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (6318/6528)
Epoch: 176 | Batch_idx: 60 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (7560/7808)
Epoch: 176 | Batch_idx: 70 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (8796/9088)
Epoch: 176 | Batch_idx: 80 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (10032/10368)
Epoch: 176 | Batch_idx: 90 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (11274/11648)
Epoch: 176 | Batch_idx: 100 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (12516/12928)
Epoch: 176 | Batch_idx: 110 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (13749/14208)
Epoch: 176 | Batch_idx: 120 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (14983/15488)
Epoch: 176 | Batch_idx: 130 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (16221/16768)
Epoch: 176 | Batch_idx: 140 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (17461/18048)
Epoch: 176 | Batch_idx: 150 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (18701/19328)
Epoch: 176 | Batch_idx: 160 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (19942/20608)
Epoch: 176 | Batch_idx: 170 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (21183/21888)
Epoch: 176 | Batch_idx: 180 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (22417/23168)
Epoch: 176 | Batch_idx: 190 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (23660/24448)
Epoch: 176 | Batch_idx: 200 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (24894/25728)
Epoch: 176 | Batch_idx: 210 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (26135/27008)
Epoch: 176 | Batch_idx: 220 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (27377/28288)
Epoch: 176 | Batch_idx: 230 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (28633/29568)
Epoch: 176 | Batch_idx: 240 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (29874/30848)
Epoch: 176 | Batch_idx: 250 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (31111/32128)
Epoch: 176 | Batch_idx: 260 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (32352/33408)
Epoch: 176 | Batch_idx: 270 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (33587/34688)
Epoch: 176 | Batch_idx: 280 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (34834/35968)
Epoch: 176 | Batch_idx: 290 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (36083/37248)
Epoch: 176 | Batch_idx: 300 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (37332/38528)
Epoch: 176 | Batch_idx: 310 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (38572/39808)
Epoch: 176 | Batch_idx: 320 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (39812/41088)
Epoch: 176 | Batch_idx: 330 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (41041/42368)
Epoch: 176 | Batch_idx: 340 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (42280/43648)
Epoch: 176 | Batch_idx: 350 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (43521/44928)
Epoch: 176 | Batch_idx: 360 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (44771/46208)
Epoch: 176 | Batch_idx: 370 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (46015/47488)
Epoch: 176 | Batch_idx: 380 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (47245/48768)
Epoch: 176 | Batch_idx: 390 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (48437/50000)
# TEST : Loss: (0.3820) | Acc: (89.00%) (8913/10000)
percent tensor([0.5040, 0.5378, 0.5141, 0.4952, 0.5288, 0.5253, 0.5404, 0.4992, 0.5101,
        0.5226, 0.5215, 0.5267, 0.5030, 0.5227, 0.5316, 0.5068],
       device='cuda:0')
percent tensor([0.5801, 0.5740, 0.5295, 0.5676, 0.5380, 0.5117, 0.5591, 0.5846, 0.6207,
        0.5787, 0.5919, 0.5624, 0.5984, 0.6603, 0.5366, 0.5527],
       device='cuda:0')
percent tensor([0.6358, 0.5000, 0.6949, 0.6757, 0.6961, 0.6885, 0.5953, 0.6899, 0.6282,
        0.5743, 0.5838, 0.5724, 0.5205, 0.5847, 0.5867, 0.6556],
       device='cuda:0')
percent tensor([0.6627, 0.6729, 0.6046, 0.6160, 0.5886, 0.6200, 0.6586, 0.6180, 0.6361,
        0.6705, 0.6650, 0.6537, 0.6900, 0.6626, 0.6548, 0.6569],
       device='cuda:0')
percent tensor([0.4579, 0.6123, 0.6665, 0.7270, 0.6740, 0.6938, 0.5991, 0.5126, 0.6709,
        0.6274, 0.7084, 0.7212, 0.5581, 0.7638, 0.5577, 0.5495],
       device='cuda:0')
percent tensor([0.7160, 0.7376, 0.7260, 0.7366, 0.7308, 0.7440, 0.7457, 0.6696, 0.7402,
        0.7203, 0.7495, 0.7541, 0.7362, 0.7615, 0.7640, 0.7365],
       device='cuda:0')
percent tensor([0.6420, 0.7272, 0.8041, 0.7784, 0.8137, 0.7812, 0.7360, 0.6985, 0.5881,
        0.6671, 0.6618, 0.6407, 0.5277, 0.6196, 0.5902, 0.6698],
       device='cuda:0')
percent tensor([0.9994, 0.9994, 0.9996, 0.9998, 0.9992, 0.9992, 0.9993, 0.9996, 0.9991,
        0.9996, 0.9997, 0.9997, 0.9990, 0.9989, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 177 | Batch_idx: 0 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 177 | Batch_idx: 10 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 177 | Batch_idx: 20 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (96.00%) (2603/2688)
Epoch: 177 | Batch_idx: 30 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (3849/3968)
Epoch: 177 | Batch_idx: 40 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 177 | Batch_idx: 50 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (6336/6528)
Epoch: 177 | Batch_idx: 60 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (7580/7808)
Epoch: 177 | Batch_idx: 70 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (8812/9088)
Epoch: 177 | Batch_idx: 80 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (10064/10368)
Epoch: 177 | Batch_idx: 90 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (11312/11648)
Epoch: 177 | Batch_idx: 100 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (12552/12928)
Epoch: 177 | Batch_idx: 110 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (13802/14208)
Epoch: 177 | Batch_idx: 120 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (15039/15488)
Epoch: 177 | Batch_idx: 130 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (16283/16768)
Epoch: 177 | Batch_idx: 140 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (17525/18048)
Epoch: 177 | Batch_idx: 150 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (18779/19328)
Epoch: 177 | Batch_idx: 160 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (20018/20608)
Epoch: 177 | Batch_idx: 170 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (21260/21888)
Epoch: 177 | Batch_idx: 180 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (22501/23168)
Epoch: 177 | Batch_idx: 190 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (23750/24448)
Epoch: 177 | Batch_idx: 200 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (24999/25728)
Epoch: 177 | Batch_idx: 210 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (26244/27008)
Epoch: 177 | Batch_idx: 220 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (27487/28288)
Epoch: 177 | Batch_idx: 230 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (28729/29568)
Epoch: 177 | Batch_idx: 240 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (29976/30848)
Epoch: 177 | Batch_idx: 250 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (31221/32128)
Epoch: 177 | Batch_idx: 260 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (32467/33408)
Epoch: 177 | Batch_idx: 270 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (33716/34688)
Epoch: 177 | Batch_idx: 280 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (34956/35968)
Epoch: 177 | Batch_idx: 290 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (36200/37248)
Epoch: 177 | Batch_idx: 300 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (37441/38528)
Epoch: 177 | Batch_idx: 310 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (38689/39808)
Epoch: 177 | Batch_idx: 320 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (39934/41088)
Epoch: 177 | Batch_idx: 330 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (41183/42368)
Epoch: 177 | Batch_idx: 340 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (42418/43648)
Epoch: 177 | Batch_idx: 350 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (43667/44928)
Epoch: 177 | Batch_idx: 360 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (44918/46208)
Epoch: 177 | Batch_idx: 370 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (46168/47488)
Epoch: 177 | Batch_idx: 380 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (47414/48768)
Epoch: 177 | Batch_idx: 390 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (48613/50000)
# TEST : Loss: (0.3753) | Acc: (89.00%) (8931/10000)
percent tensor([0.5039, 0.5373, 0.5138, 0.4954, 0.5283, 0.5248, 0.5399, 0.4994, 0.5103,
        0.5223, 0.5215, 0.5263, 0.5030, 0.5230, 0.5312, 0.5068],
       device='cuda:0')
percent tensor([0.5832, 0.5759, 0.5325, 0.5701, 0.5410, 0.5152, 0.5614, 0.5875, 0.6246,
        0.5808, 0.5946, 0.5650, 0.6008, 0.6634, 0.5396, 0.5553],
       device='cuda:0')
percent tensor([0.6402, 0.5020, 0.6993, 0.6806, 0.7011, 0.6922, 0.5991, 0.6952, 0.6328,
        0.5770, 0.5856, 0.5757, 0.5228, 0.5879, 0.5899, 0.6589],
       device='cuda:0')
percent tensor([0.6622, 0.6713, 0.6055, 0.6165, 0.5892, 0.6188, 0.6578, 0.6188, 0.6368,
        0.6693, 0.6637, 0.6532, 0.6888, 0.6619, 0.6537, 0.6561],
       device='cuda:0')
percent tensor([0.4617, 0.6206, 0.6729, 0.7339, 0.6824, 0.6934, 0.6099, 0.5222, 0.6786,
        0.6356, 0.7198, 0.7336, 0.5694, 0.7657, 0.5651, 0.5537],
       device='cuda:0')
percent tensor([0.7232, 0.7467, 0.7319, 0.7432, 0.7366, 0.7504, 0.7538, 0.6752, 0.7484,
        0.7276, 0.7579, 0.7628, 0.7455, 0.7713, 0.7709, 0.7432],
       device='cuda:0')
percent tensor([0.6460, 0.7393, 0.8067, 0.7781, 0.8155, 0.7880, 0.7380, 0.6949, 0.5928,
        0.6799, 0.6674, 0.6450, 0.5320, 0.6343, 0.5918, 0.6719],
       device='cuda:0')
percent tensor([0.9995, 0.9995, 0.9996, 0.9998, 0.9991, 0.9992, 0.9994, 0.9996, 0.9992,
        0.9996, 0.9997, 0.9997, 0.9991, 0.9990, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 178 | Batch_idx: 0 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 178 | Batch_idx: 10 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 178 | Batch_idx: 20 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 178 | Batch_idx: 30 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (96.00%) (3843/3968)
Epoch: 178 | Batch_idx: 40 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (96.00%) (5086/5248)
Epoch: 178 | Batch_idx: 50 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (6333/6528)
Epoch: 178 | Batch_idx: 60 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (7581/7808)
Epoch: 178 | Batch_idx: 70 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (8836/9088)
Epoch: 178 | Batch_idx: 80 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (10075/10368)
Epoch: 178 | Batch_idx: 90 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (11319/11648)
Epoch: 178 | Batch_idx: 100 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (12551/12928)
Epoch: 178 | Batch_idx: 110 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (13795/14208)
Epoch: 178 | Batch_idx: 120 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (15034/15488)
Epoch: 178 | Batch_idx: 130 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (16275/16768)
Epoch: 178 | Batch_idx: 140 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (17513/18048)
Epoch: 178 | Batch_idx: 150 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (18757/19328)
Epoch: 178 | Batch_idx: 160 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (19998/20608)
Epoch: 178 | Batch_idx: 170 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (21244/21888)
Epoch: 178 | Batch_idx: 180 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (22484/23168)
Epoch: 178 | Batch_idx: 190 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (23734/24448)
Epoch: 178 | Batch_idx: 200 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (24980/25728)
Epoch: 178 | Batch_idx: 210 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (26208/27008)
Epoch: 178 | Batch_idx: 220 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (27443/28288)
Epoch: 178 | Batch_idx: 230 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (28683/29568)
Epoch: 178 | Batch_idx: 240 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (96.00%) (29918/30848)
Epoch: 178 | Batch_idx: 250 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (31165/32128)
Epoch: 178 | Batch_idx: 260 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (32407/33408)
Epoch: 178 | Batch_idx: 270 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (33649/34688)
Epoch: 178 | Batch_idx: 280 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (34906/35968)
Epoch: 178 | Batch_idx: 290 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (36146/37248)
Epoch: 178 | Batch_idx: 300 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (37384/38528)
Epoch: 178 | Batch_idx: 310 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (38635/39808)
Epoch: 178 | Batch_idx: 320 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (39873/41088)
Epoch: 178 | Batch_idx: 330 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (41124/42368)
Epoch: 178 | Batch_idx: 340 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (42364/43648)
Epoch: 178 | Batch_idx: 350 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (43607/44928)
Epoch: 178 | Batch_idx: 360 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (44854/46208)
Epoch: 178 | Batch_idx: 370 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (46106/47488)
Epoch: 178 | Batch_idx: 380 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (47358/48768)
Epoch: 178 | Batch_idx: 390 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (48550/50000)
# TEST : Loss: (0.3752) | Acc: (89.00%) (8933/10000)
percent tensor([0.5030, 0.5361, 0.5121, 0.4949, 0.5264, 0.5239, 0.5384, 0.4987, 0.5092,
        0.5213, 0.5204, 0.5248, 0.5022, 0.5220, 0.5304, 0.5062],
       device='cuda:0')
percent tensor([0.5790, 0.5720, 0.5280, 0.5658, 0.5355, 0.5099, 0.5565, 0.5824, 0.6206,
        0.5775, 0.5907, 0.5613, 0.5967, 0.6607, 0.5345, 0.5507],
       device='cuda:0')
percent tensor([0.6407, 0.5042, 0.7012, 0.6807, 0.7029, 0.6908, 0.6015, 0.6964, 0.6356,
        0.5798, 0.5882, 0.5779, 0.5236, 0.5890, 0.5895, 0.6599],
       device='cuda:0')
percent tensor([0.6577, 0.6665, 0.6022, 0.6128, 0.5858, 0.6150, 0.6530, 0.6154, 0.6328,
        0.6651, 0.6586, 0.6488, 0.6834, 0.6580, 0.6489, 0.6511],
       device='cuda:0')
percent tensor([0.4448, 0.6050, 0.6680, 0.7312, 0.6797, 0.6880, 0.5980, 0.5182, 0.6671,
        0.6160, 0.7051, 0.7260, 0.5515, 0.7534, 0.5552, 0.5389],
       device='cuda:0')
percent tensor([0.7124, 0.7378, 0.7224, 0.7340, 0.7280, 0.7420, 0.7443, 0.6634, 0.7403,
        0.7172, 0.7479, 0.7548, 0.7362, 0.7636, 0.7616, 0.7320],
       device='cuda:0')
percent tensor([0.6483, 0.7528, 0.8115, 0.7887, 0.8222, 0.7976, 0.7420, 0.6979, 0.5997,
        0.6858, 0.6758, 0.6497, 0.5471, 0.6380, 0.5915, 0.6802],
       device='cuda:0')
percent tensor([0.9994, 0.9995, 0.9996, 0.9998, 0.9991, 0.9991, 0.9993, 0.9996, 0.9991,
        0.9995, 0.9997, 0.9997, 0.9990, 0.9989, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 179 | Batch_idx: 0 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 179 | Batch_idx: 10 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 179 | Batch_idx: 20 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (2608/2688)
Epoch: 179 | Batch_idx: 30 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (3863/3968)
Epoch: 179 | Batch_idx: 40 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (5099/5248)
Epoch: 179 | Batch_idx: 50 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (6348/6528)
Epoch: 179 | Batch_idx: 60 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (7600/7808)
Epoch: 179 | Batch_idx: 70 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (8847/9088)
Epoch: 179 | Batch_idx: 80 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (10095/10368)
Epoch: 179 | Batch_idx: 90 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (11338/11648)
Epoch: 179 | Batch_idx: 100 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (12588/12928)
Epoch: 179 | Batch_idx: 110 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (13842/14208)
Epoch: 179 | Batch_idx: 120 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (15093/15488)
Epoch: 179 | Batch_idx: 130 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (16338/16768)
Epoch: 179 | Batch_idx: 140 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (17589/18048)
Epoch: 179 | Batch_idx: 150 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (18838/19328)
Epoch: 179 | Batch_idx: 160 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (20089/20608)
Epoch: 179 | Batch_idx: 170 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (21340/21888)
Epoch: 179 | Batch_idx: 180 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (22589/23168)
Epoch: 179 | Batch_idx: 190 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (23848/24448)
Epoch: 179 | Batch_idx: 200 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (25093/25728)
Epoch: 179 | Batch_idx: 210 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (26334/27008)
Epoch: 179 | Batch_idx: 220 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (27580/28288)
Epoch: 179 | Batch_idx: 230 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (28822/29568)
Epoch: 179 | Batch_idx: 240 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (30067/30848)
Epoch: 179 | Batch_idx: 250 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (31306/32128)
Epoch: 179 | Batch_idx: 260 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (32548/33408)
Epoch: 179 | Batch_idx: 270 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (33801/34688)
Epoch: 179 | Batch_idx: 280 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (35045/35968)
Epoch: 179 | Batch_idx: 290 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (36275/37248)
Epoch: 179 | Batch_idx: 300 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (37520/38528)
Epoch: 179 | Batch_idx: 310 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (38756/39808)
Epoch: 179 | Batch_idx: 320 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (40001/41088)
Epoch: 179 | Batch_idx: 330 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (41243/42368)
Epoch: 179 | Batch_idx: 340 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (42502/43648)
Epoch: 179 | Batch_idx: 350 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (43742/44928)
Epoch: 179 | Batch_idx: 360 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (44995/46208)
Epoch: 179 | Batch_idx: 370 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (46239/47488)
Epoch: 179 | Batch_idx: 380 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (47485/48768)
Epoch: 179 | Batch_idx: 390 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (48684/50000)
# TEST : Loss: (0.3682) | Acc: (89.00%) (8943/10000)
percent tensor([0.5069, 0.5404, 0.5170, 0.4990, 0.5314, 0.5276, 0.5430, 0.5033, 0.5139,
        0.5256, 0.5247, 0.5297, 0.5064, 0.5261, 0.5344, 0.5099],
       device='cuda:0')
percent tensor([0.5804, 0.5725, 0.5313, 0.5683, 0.5379, 0.5109, 0.5576, 0.5853, 0.6220,
        0.5785, 0.5910, 0.5634, 0.5975, 0.6617, 0.5355, 0.5520],
       device='cuda:0')
percent tensor([0.6411, 0.5048, 0.7001, 0.6805, 0.7023, 0.6919, 0.6016, 0.6966, 0.6337,
        0.5796, 0.5866, 0.5751, 0.5222, 0.5895, 0.5901, 0.6605],
       device='cuda:0')
percent tensor([0.6611, 0.6696, 0.6054, 0.6160, 0.5889, 0.6182, 0.6565, 0.6188, 0.6364,
        0.6681, 0.6619, 0.6521, 0.6865, 0.6611, 0.6524, 0.6544],
       device='cuda:0')
percent tensor([0.4435, 0.6062, 0.6623, 0.7303, 0.6769, 0.6833, 0.5993, 0.5171, 0.6674,
        0.6186, 0.7097, 0.7270, 0.5530, 0.7570, 0.5535, 0.5390],
       device='cuda:0')
percent tensor([0.7092, 0.7361, 0.7191, 0.7311, 0.7241, 0.7394, 0.7412, 0.6588, 0.7386,
        0.7144, 0.7465, 0.7530, 0.7351, 0.7621, 0.7587, 0.7284],
       device='cuda:0')
percent tensor([0.6432, 0.7572, 0.8122, 0.7868, 0.8221, 0.7975, 0.7386, 0.6954, 0.5992,
        0.6932, 0.6753, 0.6502, 0.5481, 0.6349, 0.5869, 0.6717],
       device='cuda:0')
percent tensor([0.9995, 0.9995, 0.9996, 0.9998, 0.9991, 0.9991, 0.9994, 0.9996, 0.9992,
        0.9996, 0.9997, 0.9997, 0.9991, 0.9990, 0.9995, 0.9993],
       device='cuda:0')
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 180 | Batch_idx: 0 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 180 | Batch_idx: 10 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 180 | Batch_idx: 20 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (2617/2688)
Epoch: 180 | Batch_idx: 30 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (3864/3968)
Epoch: 180 | Batch_idx: 40 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (5109/5248)
Epoch: 180 | Batch_idx: 50 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (6352/6528)
Epoch: 180 | Batch_idx: 60 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (7581/7808)
Epoch: 180 | Batch_idx: 70 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (8821/9088)
Epoch: 180 | Batch_idx: 80 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (10059/10368)
Epoch: 180 | Batch_idx: 90 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (11297/11648)
Epoch: 180 | Batch_idx: 100 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (12547/12928)
Epoch: 180 | Batch_idx: 110 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (13791/14208)
Epoch: 180 | Batch_idx: 120 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (97.00%) (15025/15488)
Epoch: 180 | Batch_idx: 130 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (16261/16768)
Epoch: 180 | Batch_idx: 140 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (97.00%) (17507/18048)
Epoch: 180 | Batch_idx: 150 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (18742/19328)
Epoch: 180 | Batch_idx: 160 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (97.00%) (19991/20608)
Epoch: 180 | Batch_idx: 170 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (21239/21888)
Epoch: 180 | Batch_idx: 180 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (22487/23168)
Epoch: 180 | Batch_idx: 190 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (97.00%) (23721/24448)
Epoch: 180 | Batch_idx: 200 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (97.00%) (24957/25728)
Epoch: 180 | Batch_idx: 210 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (26176/27008)
Epoch: 180 | Batch_idx: 220 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (27413/28288)
Epoch: 180 | Batch_idx: 230 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (28647/29568)
Epoch: 180 | Batch_idx: 240 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (29884/30848)
Epoch: 180 | Batch_idx: 250 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (31128/32128)
Epoch: 180 | Batch_idx: 260 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (32370/33408)
Epoch: 180 | Batch_idx: 270 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (33608/34688)
Epoch: 180 | Batch_idx: 280 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (34858/35968)
Epoch: 180 | Batch_idx: 290 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (36096/37248)
Epoch: 180 | Batch_idx: 300 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (37342/38528)
Epoch: 180 | Batch_idx: 310 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (38581/39808)
Epoch: 180 | Batch_idx: 320 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (39828/41088)
Epoch: 180 | Batch_idx: 330 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (41063/42368)
Epoch: 180 | Batch_idx: 340 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (42313/43648)
Epoch: 180 | Batch_idx: 350 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (43558/44928)
Epoch: 180 | Batch_idx: 360 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (44794/46208)
Epoch: 180 | Batch_idx: 370 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (46018/47488)
Epoch: 180 | Batch_idx: 380 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (47254/48768)
Epoch: 180 | Batch_idx: 390 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (48449/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_180.pth.tar'
# TEST : Loss: (0.4253) | Acc: (88.00%) (8831/10000)
percent tensor([0.5042, 0.5359, 0.5234, 0.4983, 0.5359, 0.5243, 0.5427, 0.5032, 0.5135,
        0.5248, 0.5209, 0.5355, 0.5038, 0.5199, 0.5305, 0.5061],
       device='cuda:0')
percent tensor([0.5798, 0.5747, 0.5210, 0.5623, 0.5243, 0.5064, 0.5520, 0.5795, 0.6231,
        0.5768, 0.5928, 0.5527, 0.6001, 0.6613, 0.5321, 0.5483],
       device='cuda:0')
percent tensor([0.6375, 0.5025, 0.6982, 0.6754, 0.6962, 0.6919, 0.5935, 0.6975, 0.6207,
        0.5759, 0.5783, 0.5700, 0.5213, 0.5769, 0.5860, 0.6527],
       device='cuda:0')
percent tensor([0.6608, 0.6662, 0.6047, 0.6177, 0.5877, 0.6229, 0.6539, 0.6145, 0.6373,
        0.6700, 0.6664, 0.6544, 0.6844, 0.6595, 0.6554, 0.6544],
       device='cuda:0')
percent tensor([0.4432, 0.6098, 0.6249, 0.7017, 0.6651, 0.6803, 0.6021, 0.4730, 0.6741,
        0.6194, 0.7193, 0.7062, 0.5720, 0.7540, 0.5290, 0.5498],
       device='cuda:0')
percent tensor([0.7283, 0.7496, 0.7200, 0.7273, 0.7319, 0.7489, 0.7503, 0.6564, 0.7487,
        0.7344, 0.7596, 0.7671, 0.7469, 0.7690, 0.7657, 0.7398],
       device='cuda:0')
percent tensor([0.6695, 0.7651, 0.7960, 0.7856, 0.7919, 0.7835, 0.7505, 0.6954, 0.6464,
        0.7022, 0.6562, 0.6423, 0.5828, 0.6488, 0.6021, 0.7072],
       device='cuda:0')
percent tensor([0.9996, 0.9994, 0.9996, 0.9998, 0.9992, 0.9992, 0.9994, 0.9997, 0.9993,
        0.9994, 0.9997, 0.9997, 0.9992, 0.9992, 0.9994, 0.9995],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.5417, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(826.1649, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(837.5274, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1514.0725, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(478.3404, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2267.2124, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4252.5508, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1357.5414, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6238.7739, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11627.7393, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3811.6897, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16109.3359, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 181 | Batch_idx: 0 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 181 | Batch_idx: 10 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 181 | Batch_idx: 20 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (2595/2688)
Epoch: 181 | Batch_idx: 30 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (3836/3968)
Epoch: 181 | Batch_idx: 40 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (5082/5248)
Epoch: 181 | Batch_idx: 50 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (6320/6528)
Epoch: 181 | Batch_idx: 60 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (7563/7808)
Epoch: 181 | Batch_idx: 70 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (8796/9088)
Epoch: 181 | Batch_idx: 80 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (10036/10368)
Epoch: 181 | Batch_idx: 90 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (11274/11648)
Epoch: 181 | Batch_idx: 100 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (12520/12928)
Epoch: 181 | Batch_idx: 110 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (13760/14208)
Epoch: 181 | Batch_idx: 120 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (15012/15488)
Epoch: 181 | Batch_idx: 130 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (16261/16768)
Epoch: 181 | Batch_idx: 140 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (17503/18048)
Epoch: 181 | Batch_idx: 150 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (18738/19328)
Epoch: 181 | Batch_idx: 160 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (19981/20608)
Epoch: 181 | Batch_idx: 170 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (21224/21888)
Epoch: 181 | Batch_idx: 180 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (22464/23168)
Epoch: 181 | Batch_idx: 190 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (23705/24448)
Epoch: 181 | Batch_idx: 200 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (24944/25728)
Epoch: 181 | Batch_idx: 210 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (26190/27008)
Epoch: 181 | Batch_idx: 220 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (27429/28288)
Epoch: 181 | Batch_idx: 230 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (28666/29568)
Epoch: 181 | Batch_idx: 240 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (29905/30848)
Epoch: 181 | Batch_idx: 250 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (31146/32128)
Epoch: 181 | Batch_idx: 260 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (32382/33408)
Epoch: 181 | Batch_idx: 270 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (33624/34688)
Epoch: 181 | Batch_idx: 280 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (34858/35968)
Epoch: 181 | Batch_idx: 290 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (36097/37248)
Epoch: 181 | Batch_idx: 300 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (37348/38528)
Epoch: 181 | Batch_idx: 310 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (38583/39808)
Epoch: 181 | Batch_idx: 320 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (39816/41088)
Epoch: 181 | Batch_idx: 330 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (41058/42368)
Epoch: 181 | Batch_idx: 340 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (42302/43648)
Epoch: 181 | Batch_idx: 350 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (43555/44928)
Epoch: 181 | Batch_idx: 360 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (44791/46208)
Epoch: 181 | Batch_idx: 370 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (46025/47488)
Epoch: 181 | Batch_idx: 380 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (47262/48768)
Epoch: 181 | Batch_idx: 390 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (48455/50000)
# TEST : Loss: (0.4720) | Acc: (87.00%) (8722/10000)
percent tensor([0.5059, 0.5385, 0.5250, 0.5017, 0.5370, 0.5268, 0.5434, 0.5069, 0.5135,
        0.5265, 0.5221, 0.5351, 0.5054, 0.5208, 0.5332, 0.5087],
       device='cuda:0')
percent tensor([0.5740, 0.5614, 0.5235, 0.5563, 0.5280, 0.5101, 0.5424, 0.5710, 0.6143,
        0.5668, 0.5829, 0.5558, 0.5899, 0.6461, 0.5281, 0.5420],
       device='cuda:0')
percent tensor([0.6462, 0.5002, 0.7167, 0.6888, 0.7170, 0.6986, 0.6051, 0.6973, 0.6417,
        0.5742, 0.5886, 0.5921, 0.5308, 0.5759, 0.5937, 0.6576],
       device='cuda:0')
percent tensor([0.6614, 0.6691, 0.5951, 0.6206, 0.5824, 0.6198, 0.6532, 0.6182, 0.6329,
        0.6710, 0.6622, 0.6428, 0.6845, 0.6636, 0.6536, 0.6580],
       device='cuda:0')
percent tensor([0.4475, 0.5919, 0.6457, 0.7186, 0.6686, 0.7108, 0.5961, 0.5001, 0.6652,
        0.6095, 0.7146, 0.7030, 0.5509, 0.7602, 0.5273, 0.5417],
       device='cuda:0')
percent tensor([0.7187, 0.7416, 0.7101, 0.7298, 0.7137, 0.7348, 0.7432, 0.6581, 0.7377,
        0.7231, 0.7535, 0.7522, 0.7393, 0.7731, 0.7551, 0.7358],
       device='cuda:0')
percent tensor([0.6716, 0.7850, 0.8233, 0.8081, 0.8227, 0.7871, 0.7363, 0.7001, 0.6929,
        0.7087, 0.6925, 0.6913, 0.6342, 0.6328, 0.5985, 0.6943],
       device='cuda:0')
percent tensor([0.9996, 0.9995, 0.9996, 0.9998, 0.9990, 0.9990, 0.9995, 0.9997, 0.9992,
        0.9996, 0.9997, 0.9997, 0.9993, 0.9991, 0.9995, 0.9991],
       device='cuda:0')
Epoch: 182 | Batch_idx: 0 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 182 | Batch_idx: 10 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 182 | Batch_idx: 20 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 182 | Batch_idx: 30 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (3859/3968)
Epoch: 182 | Batch_idx: 40 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (5107/5248)
Epoch: 182 | Batch_idx: 50 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (6346/6528)
Epoch: 182 | Batch_idx: 60 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (97.00%) (7594/7808)
Epoch: 182 | Batch_idx: 70 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (8839/9088)
Epoch: 182 | Batch_idx: 80 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (10084/10368)
Epoch: 182 | Batch_idx: 90 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (11341/11648)
Epoch: 182 | Batch_idx: 100 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (12578/12928)
Epoch: 182 | Batch_idx: 110 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (13818/14208)
Epoch: 182 | Batch_idx: 120 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (15068/15488)
Epoch: 182 | Batch_idx: 130 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (16312/16768)
Epoch: 182 | Batch_idx: 140 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (17562/18048)
Epoch: 182 | Batch_idx: 150 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (18801/19328)
Epoch: 182 | Batch_idx: 160 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (20038/20608)
Epoch: 182 | Batch_idx: 170 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (21272/21888)
Epoch: 182 | Batch_idx: 180 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (22506/23168)
Epoch: 182 | Batch_idx: 190 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (23742/24448)
Epoch: 182 | Batch_idx: 200 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (24974/25728)
Epoch: 182 | Batch_idx: 210 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (26214/27008)
Epoch: 182 | Batch_idx: 220 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (27464/28288)
Epoch: 182 | Batch_idx: 230 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (28705/29568)
Epoch: 182 | Batch_idx: 240 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (29943/30848)
Epoch: 182 | Batch_idx: 250 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (31175/32128)
Epoch: 182 | Batch_idx: 260 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (32420/33408)
Epoch: 182 | Batch_idx: 270 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (33662/34688)
Epoch: 182 | Batch_idx: 280 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (34901/35968)
Epoch: 182 | Batch_idx: 290 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (36148/37248)
Epoch: 182 | Batch_idx: 300 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (37400/38528)
Epoch: 182 | Batch_idx: 310 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (38658/39808)
Epoch: 182 | Batch_idx: 320 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (39888/41088)
Epoch: 182 | Batch_idx: 330 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (41129/42368)
Epoch: 182 | Batch_idx: 340 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (42373/43648)
Epoch: 182 | Batch_idx: 350 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (43610/44928)
Epoch: 182 | Batch_idx: 360 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (44847/46208)
Epoch: 182 | Batch_idx: 370 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (46086/47488)
Epoch: 182 | Batch_idx: 380 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (47331/48768)
Epoch: 182 | Batch_idx: 390 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (48519/50000)
# TEST : Loss: (0.4133) | Acc: (88.00%) (8822/10000)
percent tensor([0.5058, 0.5380, 0.5238, 0.4999, 0.5371, 0.5272, 0.5434, 0.5052, 0.5138,
        0.5258, 0.5224, 0.5349, 0.5050, 0.5208, 0.5330, 0.5081],
       device='cuda:0')
percent tensor([0.5799, 0.5705, 0.5213, 0.5591, 0.5273, 0.5118, 0.5506, 0.5741, 0.6193,
        0.5721, 0.5875, 0.5546, 0.5973, 0.6549, 0.5336, 0.5482],
       device='cuda:0')
percent tensor([0.6444, 0.5047, 0.7208, 0.6891, 0.7198, 0.6957, 0.6077, 0.7026, 0.6402,
        0.5848, 0.5880, 0.5947, 0.5270, 0.5770, 0.5926, 0.6545],
       device='cuda:0')
percent tensor([0.6610, 0.6727, 0.5995, 0.6149, 0.5835, 0.6211, 0.6567, 0.6189, 0.6379,
        0.6735, 0.6715, 0.6485, 0.6870, 0.6709, 0.6581, 0.6553],
       device='cuda:0')
percent tensor([0.4393, 0.5840, 0.6199, 0.7094, 0.6709, 0.7014, 0.5941, 0.4909, 0.6418,
        0.5869, 0.6903, 0.6646, 0.5442, 0.7219, 0.5126, 0.5452],
       device='cuda:0')
percent tensor([0.7171, 0.7369, 0.7070, 0.7288, 0.7178, 0.7439, 0.7438, 0.6640, 0.7318,
        0.7148, 0.7484, 0.7432, 0.7306, 0.7677, 0.7570, 0.7271],
       device='cuda:0')
percent tensor([0.6591, 0.7804, 0.7926, 0.8046, 0.8245, 0.7923, 0.7415, 0.7011, 0.5922,
        0.6856, 0.6587, 0.6556, 0.5917, 0.6134, 0.5935, 0.6970],
       device='cuda:0')
percent tensor([0.9996, 0.9994, 0.9995, 0.9997, 0.9988, 0.9992, 0.9995, 0.9996, 0.9991,
        0.9995, 0.9997, 0.9997, 0.9991, 0.9991, 0.9993, 0.9992],
       device='cuda:0')
Epoch: 183 | Batch_idx: 0 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 183 | Batch_idx: 10 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 183 | Batch_idx: 20 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (2590/2688)
Epoch: 183 | Batch_idx: 30 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (3843/3968)
Epoch: 183 | Batch_idx: 40 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (5086/5248)
Epoch: 183 | Batch_idx: 50 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (6337/6528)
Epoch: 183 | Batch_idx: 60 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (7584/7808)
Epoch: 183 | Batch_idx: 70 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (8830/9088)
Epoch: 183 | Batch_idx: 80 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (10066/10368)
Epoch: 183 | Batch_idx: 90 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (11301/11648)
Epoch: 183 | Batch_idx: 100 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (12538/12928)
Epoch: 183 | Batch_idx: 110 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (13794/14208)
Epoch: 183 | Batch_idx: 120 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (15031/15488)
Epoch: 183 | Batch_idx: 130 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (16275/16768)
Epoch: 183 | Batch_idx: 140 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (17516/18048)
Epoch: 183 | Batch_idx: 150 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (18761/19328)
Epoch: 183 | Batch_idx: 160 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (20001/20608)
Epoch: 183 | Batch_idx: 170 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (21230/21888)
Epoch: 183 | Batch_idx: 180 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (22472/23168)
Epoch: 183 | Batch_idx: 190 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (23711/24448)
Epoch: 183 | Batch_idx: 200 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (24955/25728)
Epoch: 183 | Batch_idx: 210 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (26199/27008)
Epoch: 183 | Batch_idx: 220 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (27427/28288)
Epoch: 183 | Batch_idx: 230 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (28670/29568)
Epoch: 183 | Batch_idx: 240 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (29912/30848)
Epoch: 183 | Batch_idx: 250 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (31152/32128)
Epoch: 183 | Batch_idx: 260 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (32391/33408)
Epoch: 183 | Batch_idx: 270 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (33632/34688)
Epoch: 183 | Batch_idx: 280 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (34871/35968)
Epoch: 183 | Batch_idx: 290 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (36117/37248)
Epoch: 183 | Batch_idx: 300 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (37353/38528)
Epoch: 183 | Batch_idx: 310 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (38593/39808)
Epoch: 183 | Batch_idx: 320 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (39834/41088)
Epoch: 183 | Batch_idx: 330 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (41074/42368)
Epoch: 183 | Batch_idx: 340 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (42310/43648)
Epoch: 183 | Batch_idx: 350 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (43546/44928)
Epoch: 183 | Batch_idx: 360 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (44785/46208)
Epoch: 183 | Batch_idx: 370 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (46030/47488)
Epoch: 183 | Batch_idx: 380 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (47259/48768)
Epoch: 183 | Batch_idx: 390 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (48450/50000)
# TEST : Loss: (0.4450) | Acc: (87.00%) (8755/10000)
percent tensor([0.5083, 0.5405, 0.5298, 0.5010, 0.5424, 0.5279, 0.5481, 0.5082, 0.5179,
        0.5293, 0.5255, 0.5408, 0.5084, 0.5241, 0.5340, 0.5094],
       device='cuda:0')
percent tensor([0.5704, 0.5604, 0.5151, 0.5543, 0.5162, 0.5076, 0.5408, 0.5712, 0.6128,
        0.5639, 0.5781, 0.5467, 0.5870, 0.6470, 0.5289, 0.5419],
       device='cuda:0')
percent tensor([0.6458, 0.5110, 0.7113, 0.6864, 0.7106, 0.6938, 0.6047, 0.7030, 0.6358,
        0.5836, 0.5827, 0.5931, 0.5357, 0.5864, 0.5924, 0.6543],
       device='cuda:0')
percent tensor([0.6658, 0.6708, 0.6053, 0.6178, 0.5912, 0.6289, 0.6555, 0.6204, 0.6470,
        0.6732, 0.6749, 0.6475, 0.6932, 0.6696, 0.6589, 0.6621],
       device='cuda:0')
percent tensor([0.4402, 0.6228, 0.6095, 0.6858, 0.6410, 0.6944, 0.6178, 0.4591, 0.6537,
        0.6254, 0.7333, 0.6751, 0.5634, 0.7635, 0.5313, 0.5516],
       device='cuda:0')
percent tensor([0.7256, 0.7483, 0.7144, 0.7317, 0.7266, 0.7495, 0.7536, 0.6665, 0.7443,
        0.7305, 0.7611, 0.7583, 0.7510, 0.7755, 0.7645, 0.7441],
       device='cuda:0')
percent tensor([0.6798, 0.7470, 0.8156, 0.7836, 0.8244, 0.7608, 0.7571, 0.7260, 0.6076,
        0.6960, 0.6507, 0.6971, 0.5865, 0.5882, 0.5905, 0.6726],
       device='cuda:0')
percent tensor([0.9996, 0.9994, 0.9995, 0.9996, 0.9989, 0.9990, 0.9995, 0.9996, 0.9993,
        0.9995, 0.9997, 0.9997, 0.9993, 0.9992, 0.9994, 0.9991],
       device='cuda:0')
Epoch: 184 | Batch_idx: 0 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 184 | Batch_idx: 10 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 184 | Batch_idx: 20 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (96.00%) (2604/2688)
Epoch: 184 | Batch_idx: 30 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (3851/3968)
Epoch: 184 | Batch_idx: 40 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (5091/5248)
Epoch: 184 | Batch_idx: 50 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (96.00%) (6331/6528)
Epoch: 184 | Batch_idx: 60 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (7588/7808)
Epoch: 184 | Batch_idx: 70 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (8832/9088)
Epoch: 184 | Batch_idx: 80 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (10068/10368)
Epoch: 184 | Batch_idx: 90 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (11313/11648)
Epoch: 184 | Batch_idx: 100 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (12549/12928)
Epoch: 184 | Batch_idx: 110 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (13798/14208)
Epoch: 184 | Batch_idx: 120 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (15036/15488)
Epoch: 184 | Batch_idx: 130 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (16275/16768)
Epoch: 184 | Batch_idx: 140 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (17529/18048)
Epoch: 184 | Batch_idx: 150 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (18777/19328)
Epoch: 184 | Batch_idx: 160 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (20018/20608)
Epoch: 184 | Batch_idx: 170 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (21252/21888)
Epoch: 184 | Batch_idx: 180 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (22500/23168)
Epoch: 184 | Batch_idx: 190 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (23737/24448)
Epoch: 184 | Batch_idx: 200 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (24987/25728)
Epoch: 184 | Batch_idx: 210 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (26234/27008)
Epoch: 184 | Batch_idx: 220 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (27482/28288)
Epoch: 184 | Batch_idx: 230 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (28733/29568)
Epoch: 184 | Batch_idx: 240 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (29979/30848)
Epoch: 184 | Batch_idx: 250 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (31216/32128)
Epoch: 184 | Batch_idx: 260 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (32460/33408)
Epoch: 184 | Batch_idx: 270 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (33712/34688)
Epoch: 184 | Batch_idx: 280 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (34952/35968)
Epoch: 184 | Batch_idx: 290 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (36190/37248)
Epoch: 184 | Batch_idx: 300 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (37434/38528)
Epoch: 184 | Batch_idx: 310 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (38673/39808)
Epoch: 184 | Batch_idx: 320 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (39924/41088)
Epoch: 184 | Batch_idx: 330 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (41175/42368)
Epoch: 184 | Batch_idx: 340 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (42415/43648)
Epoch: 184 | Batch_idx: 350 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (43662/44928)
Epoch: 184 | Batch_idx: 360 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (44892/46208)
Epoch: 184 | Batch_idx: 370 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (46130/47488)
Epoch: 184 | Batch_idx: 380 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (47381/48768)
Epoch: 184 | Batch_idx: 390 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (48576/50000)
# TEST : Loss: (0.3943) | Acc: (88.00%) (8867/10000)
percent tensor([0.5073, 0.5407, 0.5209, 0.4995, 0.5360, 0.5288, 0.5453, 0.5044, 0.5144,
        0.5273, 0.5251, 0.5345, 0.5074, 0.5241, 0.5352, 0.5098],
       device='cuda:0')
percent tensor([0.5712, 0.5653, 0.5094, 0.5530, 0.5173, 0.5055, 0.5448, 0.5697, 0.6151,
        0.5664, 0.5847, 0.5450, 0.5899, 0.6555, 0.5273, 0.5434],
       device='cuda:0')
percent tensor([0.6451, 0.5108, 0.7162, 0.6925, 0.7173, 0.7009, 0.6081, 0.7017, 0.6397,
        0.5892, 0.5894, 0.5942, 0.5352, 0.5873, 0.5973, 0.6578],
       device='cuda:0')
percent tensor([0.6595, 0.6681, 0.5932, 0.6127, 0.5788, 0.6237, 0.6509, 0.6129, 0.6317,
        0.6697, 0.6671, 0.6424, 0.6852, 0.6598, 0.6552, 0.6535],
       device='cuda:0')
percent tensor([0.4373, 0.5892, 0.6304, 0.6989, 0.6659, 0.6851, 0.5842, 0.4819, 0.6654,
        0.6098, 0.7207, 0.6837, 0.5594, 0.7477, 0.5254, 0.5555],
       device='cuda:0')
percent tensor([0.7324, 0.7530, 0.7137, 0.7318, 0.7262, 0.7532, 0.7522, 0.6653, 0.7495,
        0.7336, 0.7644, 0.7580, 0.7513, 0.7735, 0.7720, 0.7473],
       device='cuda:0')
percent tensor([0.6622, 0.7714, 0.8113, 0.8056, 0.8402, 0.7622, 0.7555, 0.7073, 0.6327,
        0.6879, 0.6992, 0.6700, 0.5995, 0.6431, 0.5842, 0.6750],
       device='cuda:0')
percent tensor([0.9996, 0.9995, 0.9996, 0.9998, 0.9991, 0.9992, 0.9995, 0.9996, 0.9993,
        0.9995, 0.9997, 0.9997, 0.9993, 0.9991, 0.9994, 0.9993],
       device='cuda:0')
Epoch: 185 | Batch_idx: 0 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 185 | Batch_idx: 10 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 185 | Batch_idx: 20 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 185 | Batch_idx: 30 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (3864/3968)
Epoch: 185 | Batch_idx: 40 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (5114/5248)
Epoch: 185 | Batch_idx: 50 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (6356/6528)
Epoch: 185 | Batch_idx: 60 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (7604/7808)
Epoch: 185 | Batch_idx: 70 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (8857/9088)
Epoch: 185 | Batch_idx: 80 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (10109/10368)
Epoch: 185 | Batch_idx: 90 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (11345/11648)
Epoch: 185 | Batch_idx: 100 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (12591/12928)
Epoch: 185 | Batch_idx: 110 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (13842/14208)
Epoch: 185 | Batch_idx: 120 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (15080/15488)
Epoch: 185 | Batch_idx: 130 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (16330/16768)
Epoch: 185 | Batch_idx: 140 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (17584/18048)
Epoch: 185 | Batch_idx: 150 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (18828/19328)
Epoch: 185 | Batch_idx: 160 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (20071/20608)
Epoch: 185 | Batch_idx: 170 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (21317/21888)
Epoch: 185 | Batch_idx: 180 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (22565/23168)
Epoch: 185 | Batch_idx: 190 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (23810/24448)
Epoch: 185 | Batch_idx: 200 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (25057/25728)
Epoch: 185 | Batch_idx: 210 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (26308/27008)
Epoch: 185 | Batch_idx: 220 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (27561/28288)
Epoch: 185 | Batch_idx: 230 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (28808/29568)
Epoch: 185 | Batch_idx: 240 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (30048/30848)
Epoch: 185 | Batch_idx: 250 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (31288/32128)
Epoch: 185 | Batch_idx: 260 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (32537/33408)
Epoch: 185 | Batch_idx: 270 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (33778/34688)
Epoch: 185 | Batch_idx: 280 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (35018/35968)
Epoch: 185 | Batch_idx: 290 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (36264/37248)
Epoch: 185 | Batch_idx: 300 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (37498/38528)
Epoch: 185 | Batch_idx: 310 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (38741/39808)
Epoch: 185 | Batch_idx: 320 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (39981/41088)
Epoch: 185 | Batch_idx: 330 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (41218/42368)
Epoch: 185 | Batch_idx: 340 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (42460/43648)
Epoch: 185 | Batch_idx: 350 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (43715/44928)
Epoch: 185 | Batch_idx: 360 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (44958/46208)
Epoch: 185 | Batch_idx: 370 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (46200/47488)
Epoch: 185 | Batch_idx: 380 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (47441/48768)
Epoch: 185 | Batch_idx: 390 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (48638/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_185.pth.tar'
# TEST : Loss: (0.4587) | Acc: (87.00%) (8717/10000)
percent tensor([0.5090, 0.5438, 0.5238, 0.5033, 0.5378, 0.5288, 0.5480, 0.5076, 0.5174,
        0.5294, 0.5267, 0.5366, 0.5088, 0.5278, 0.5373, 0.5118],
       device='cuda:0')
percent tensor([0.5694, 0.5635, 0.5233, 0.5514, 0.5300, 0.5108, 0.5465, 0.5709, 0.6151,
        0.5670, 0.5838, 0.5525, 0.5862, 0.6443, 0.5285, 0.5409],
       device='cuda:0')
percent tensor([0.6556, 0.5142, 0.7127, 0.6918, 0.7176, 0.7074, 0.6102, 0.7006, 0.6469,
        0.5956, 0.5989, 0.5925, 0.5440, 0.5800, 0.6081, 0.6662],
       device='cuda:0')
percent tensor([0.6569, 0.6686, 0.6012, 0.6189, 0.5876, 0.6209, 0.6527, 0.6158, 0.6322,
        0.6703, 0.6677, 0.6512, 0.6899, 0.6612, 0.6537, 0.6542],
       device='cuda:0')
percent tensor([0.4333, 0.5961, 0.6233, 0.7009, 0.6360, 0.6672, 0.5946, 0.4750, 0.6624,
        0.6250, 0.7271, 0.6805, 0.5378, 0.7721, 0.4993, 0.5439],
       device='cuda:0')
percent tensor([0.7294, 0.7570, 0.7214, 0.7374, 0.7277, 0.7481, 0.7603, 0.6673, 0.7479,
        0.7398, 0.7668, 0.7730, 0.7529, 0.7883, 0.7692, 0.7499],
       device='cuda:0')
percent tensor([0.6692, 0.7876, 0.7988, 0.7734, 0.8146, 0.7670, 0.7477, 0.7007, 0.6532,
        0.7117, 0.7130, 0.6631, 0.5901, 0.6690, 0.5737, 0.6875],
       device='cuda:0')
percent tensor([0.9995, 0.9994, 0.9995, 0.9997, 0.9990, 0.9992, 0.9993, 0.9995, 0.9992,
        0.9995, 0.9997, 0.9997, 0.9991, 0.9991, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 186 | Batch_idx: 0 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 186 | Batch_idx: 10 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 186 | Batch_idx: 20 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (2626/2688)
Epoch: 186 | Batch_idx: 30 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (3887/3968)
Epoch: 186 | Batch_idx: 40 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (5134/5248)
Epoch: 186 | Batch_idx: 50 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (6378/6528)
Epoch: 186 | Batch_idx: 60 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (7628/7808)
Epoch: 186 | Batch_idx: 70 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (8878/9088)
Epoch: 186 | Batch_idx: 80 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (10125/10368)
Epoch: 186 | Batch_idx: 90 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (11359/11648)
Epoch: 186 | Batch_idx: 100 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (12604/12928)
Epoch: 186 | Batch_idx: 110 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (13850/14208)
Epoch: 186 | Batch_idx: 120 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (15097/15488)
Epoch: 186 | Batch_idx: 130 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (16350/16768)
Epoch: 186 | Batch_idx: 140 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (17597/18048)
Epoch: 186 | Batch_idx: 150 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (18845/19328)
Epoch: 186 | Batch_idx: 160 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (20100/20608)
Epoch: 186 | Batch_idx: 170 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (21345/21888)
Epoch: 186 | Batch_idx: 180 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (22585/23168)
Epoch: 186 | Batch_idx: 190 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (23813/24448)
Epoch: 186 | Batch_idx: 200 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (25062/25728)
Epoch: 186 | Batch_idx: 210 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (26317/27008)
Epoch: 186 | Batch_idx: 220 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (27554/28288)
Epoch: 186 | Batch_idx: 230 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (28807/29568)
Epoch: 186 | Batch_idx: 240 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (30047/30848)
Epoch: 186 | Batch_idx: 250 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (31296/32128)
Epoch: 186 | Batch_idx: 260 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (32544/33408)
Epoch: 186 | Batch_idx: 270 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (33788/34688)
Epoch: 186 | Batch_idx: 280 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (35040/35968)
Epoch: 186 | Batch_idx: 290 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (36285/37248)
Epoch: 186 | Batch_idx: 300 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (37534/38528)
Epoch: 186 | Batch_idx: 310 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (38778/39808)
Epoch: 186 | Batch_idx: 320 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (40021/41088)
Epoch: 186 | Batch_idx: 330 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (41259/42368)
Epoch: 186 | Batch_idx: 340 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (42500/43648)
Epoch: 186 | Batch_idx: 350 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (43745/44928)
Epoch: 186 | Batch_idx: 360 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (44986/46208)
Epoch: 186 | Batch_idx: 370 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (46240/47488)
Epoch: 186 | Batch_idx: 380 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (47492/48768)
Epoch: 186 | Batch_idx: 390 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (48691/50000)
# TEST : Loss: (0.4237) | Acc: (88.00%) (8825/10000)
percent tensor([0.5094, 0.5463, 0.5209, 0.5032, 0.5361, 0.5299, 0.5490, 0.5075, 0.5173,
        0.5306, 0.5277, 0.5351, 0.5098, 0.5316, 0.5382, 0.5131],
       device='cuda:0')
percent tensor([0.5699, 0.5639, 0.5151, 0.5587, 0.5231, 0.5086, 0.5475, 0.5662, 0.6092,
        0.5657, 0.5819, 0.5466, 0.5848, 0.6535, 0.5283, 0.5427],
       device='cuda:0')
percent tensor([0.6409, 0.5039, 0.7209, 0.6888, 0.7177, 0.6939, 0.6000, 0.7053, 0.6397,
        0.5882, 0.5842, 0.5964, 0.5332, 0.5835, 0.5913, 0.6561],
       device='cuda:0')
percent tensor([0.6610, 0.6697, 0.5949, 0.6160, 0.5812, 0.6237, 0.6535, 0.6140, 0.6397,
        0.6728, 0.6714, 0.6436, 0.6913, 0.6641, 0.6552, 0.6576],
       device='cuda:0')
percent tensor([0.4627, 0.6152, 0.6383, 0.7337, 0.6709, 0.7024, 0.6242, 0.5016, 0.6832,
        0.6354, 0.7442, 0.7220, 0.5703, 0.7813, 0.5478, 0.5646],
       device='cuda:0')
percent tensor([0.7364, 0.7552, 0.7236, 0.7453, 0.7337, 0.7590, 0.7592, 0.6760, 0.7525,
        0.7350, 0.7676, 0.7694, 0.7534, 0.7796, 0.7734, 0.7523],
       device='cuda:0')
percent tensor([0.6654, 0.8064, 0.8079, 0.7896, 0.8393, 0.7869, 0.7623, 0.7089, 0.6450,
        0.7136, 0.6988, 0.6823, 0.6149, 0.6509, 0.5798, 0.6842],
       device='cuda:0')
percent tensor([0.9996, 0.9995, 0.9996, 0.9997, 0.9992, 0.9992, 0.9994, 0.9996, 0.9993,
        0.9995, 0.9997, 0.9998, 0.9992, 0.9990, 0.9994, 0.9994],
       device='cuda:0')
Epoch: 187 | Batch_idx: 0 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 187 | Batch_idx: 10 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 187 | Batch_idx: 20 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 187 | Batch_idx: 30 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (3876/3968)
Epoch: 187 | Batch_idx: 40 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (5117/5248)
Epoch: 187 | Batch_idx: 50 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (6357/6528)
Epoch: 187 | Batch_idx: 60 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (7607/7808)
Epoch: 187 | Batch_idx: 70 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (8863/9088)
Epoch: 187 | Batch_idx: 80 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (10107/10368)
Epoch: 187 | Batch_idx: 90 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (11355/11648)
Epoch: 187 | Batch_idx: 100 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (12591/12928)
Epoch: 187 | Batch_idx: 110 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (13832/14208)
Epoch: 187 | Batch_idx: 120 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (15087/15488)
Epoch: 187 | Batch_idx: 130 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (16328/16768)
Epoch: 187 | Batch_idx: 140 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (17563/18048)
Epoch: 187 | Batch_idx: 150 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (18810/19328)
Epoch: 187 | Batch_idx: 160 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (20055/20608)
Epoch: 187 | Batch_idx: 170 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (21294/21888)
Epoch: 187 | Batch_idx: 180 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (22542/23168)
Epoch: 187 | Batch_idx: 190 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (23798/24448)
Epoch: 187 | Batch_idx: 200 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (25042/25728)
Epoch: 187 | Batch_idx: 210 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (26288/27008)
Epoch: 187 | Batch_idx: 220 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (27530/28288)
Epoch: 187 | Batch_idx: 230 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (28777/29568)
Epoch: 187 | Batch_idx: 240 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (30020/30848)
Epoch: 187 | Batch_idx: 250 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (31266/32128)
Epoch: 187 | Batch_idx: 260 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (32511/33408)
Epoch: 187 | Batch_idx: 270 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (33760/34688)
Epoch: 187 | Batch_idx: 280 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (35009/35968)
Epoch: 187 | Batch_idx: 290 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (36250/37248)
Epoch: 187 | Batch_idx: 300 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (37488/38528)
Epoch: 187 | Batch_idx: 310 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (38728/39808)
Epoch: 187 | Batch_idx: 320 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (39973/41088)
Epoch: 187 | Batch_idx: 330 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (41210/42368)
Epoch: 187 | Batch_idx: 340 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (42446/43648)
Epoch: 187 | Batch_idx: 350 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (43688/44928)
Epoch: 187 | Batch_idx: 360 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (44929/46208)
Epoch: 187 | Batch_idx: 370 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (46169/47488)
Epoch: 187 | Batch_idx: 380 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (47417/48768)
Epoch: 187 | Batch_idx: 390 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (48616/50000)
# TEST : Loss: (0.4029) | Acc: (89.00%) (8903/10000)
percent tensor([0.5105, 0.5465, 0.5249, 0.5057, 0.5392, 0.5314, 0.5500, 0.5110, 0.5178,
        0.5317, 0.5278, 0.5378, 0.5104, 0.5301, 0.5393, 0.5140],
       device='cuda:0')
percent tensor([0.5742, 0.5589, 0.5185, 0.5570, 0.5231, 0.5087, 0.5423, 0.5697, 0.6139,
        0.5648, 0.5810, 0.5465, 0.5888, 0.6496, 0.5268, 0.5454],
       device='cuda:0')
percent tensor([0.6500, 0.5161, 0.7260, 0.6898, 0.7280, 0.6997, 0.6140, 0.7047, 0.6499,
        0.5961, 0.5951, 0.6093, 0.5445, 0.5836, 0.5991, 0.6599],
       device='cuda:0')
percent tensor([0.6610, 0.6773, 0.5941, 0.6145, 0.5823, 0.6277, 0.6618, 0.6161, 0.6396,
        0.6763, 0.6730, 0.6406, 0.6913, 0.6698, 0.6572, 0.6615],
       device='cuda:0')
percent tensor([0.4295, 0.5942, 0.6043, 0.7031, 0.6506, 0.6803, 0.5682, 0.4635, 0.6586,
        0.6095, 0.7150, 0.6927, 0.5596, 0.7610, 0.5179, 0.5131],
       device='cuda:0')
percent tensor([0.7277, 0.7532, 0.7110, 0.7306, 0.7185, 0.7505, 0.7513, 0.6720, 0.7485,
        0.7310, 0.7547, 0.7576, 0.7523, 0.7714, 0.7691, 0.7388],
       device='cuda:0')
percent tensor([0.6517, 0.8103, 0.7907, 0.8062, 0.8285, 0.7786, 0.7457, 0.6959, 0.6266,
        0.7233, 0.6925, 0.7097, 0.6188, 0.6834, 0.6089, 0.6964],
       device='cuda:0')
percent tensor([0.9996, 0.9994, 0.9996, 0.9998, 0.9992, 0.9992, 0.9994, 0.9997, 0.9993,
        0.9994, 0.9997, 0.9997, 0.9993, 0.9987, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 188 | Batch_idx: 0 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 188 | Batch_idx: 10 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 188 | Batch_idx: 20 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (2617/2688)
Epoch: 188 | Batch_idx: 30 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (3858/3968)
Epoch: 188 | Batch_idx: 40 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (5102/5248)
Epoch: 188 | Batch_idx: 50 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (6347/6528)
Epoch: 188 | Batch_idx: 60 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (7591/7808)
Epoch: 188 | Batch_idx: 70 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (8845/9088)
Epoch: 188 | Batch_idx: 80 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (10092/10368)
Epoch: 188 | Batch_idx: 90 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (11335/11648)
Epoch: 188 | Batch_idx: 100 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (12590/12928)
Epoch: 188 | Batch_idx: 110 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (13839/14208)
Epoch: 188 | Batch_idx: 120 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (15091/15488)
Epoch: 188 | Batch_idx: 130 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (16337/16768)
Epoch: 188 | Batch_idx: 140 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (17593/18048)
Epoch: 188 | Batch_idx: 150 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (18840/19328)
Epoch: 188 | Batch_idx: 160 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (20087/20608)
Epoch: 188 | Batch_idx: 170 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (21327/21888)
Epoch: 188 | Batch_idx: 180 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (22577/23168)
Epoch: 188 | Batch_idx: 190 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (23826/24448)
Epoch: 188 | Batch_idx: 200 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (25072/25728)
Epoch: 188 | Batch_idx: 210 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (26325/27008)
Epoch: 188 | Batch_idx: 220 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (27568/28288)
Epoch: 188 | Batch_idx: 230 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (28813/29568)
Epoch: 188 | Batch_idx: 240 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (30058/30848)
Epoch: 188 | Batch_idx: 250 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (31297/32128)
Epoch: 188 | Batch_idx: 260 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (32541/33408)
Epoch: 188 | Batch_idx: 270 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (33783/34688)
Epoch: 188 | Batch_idx: 280 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (35026/35968)
Epoch: 188 | Batch_idx: 290 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (36282/37248)
Epoch: 188 | Batch_idx: 300 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (37528/38528)
Epoch: 188 | Batch_idx: 310 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (38776/39808)
Epoch: 188 | Batch_idx: 320 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (40028/41088)
Epoch: 188 | Batch_idx: 330 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (41272/42368)
Epoch: 188 | Batch_idx: 340 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (42528/43648)
Epoch: 188 | Batch_idx: 350 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (43770/44928)
Epoch: 188 | Batch_idx: 360 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (45023/46208)
Epoch: 188 | Batch_idx: 370 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (46272/47488)
Epoch: 188 | Batch_idx: 380 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (47517/48768)
Epoch: 188 | Batch_idx: 390 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (48716/50000)
# TEST : Loss: (0.4321) | Acc: (88.00%) (8834/10000)
percent tensor([0.5104, 0.5453, 0.5278, 0.5060, 0.5419, 0.5317, 0.5496, 0.5104, 0.5182,
        0.5318, 0.5270, 0.5405, 0.5103, 0.5284, 0.5391, 0.5136],
       device='cuda:0')
percent tensor([0.5690, 0.5563, 0.5150, 0.5523, 0.5191, 0.5066, 0.5408, 0.5684, 0.6094,
        0.5608, 0.5773, 0.5433, 0.5833, 0.6428, 0.5249, 0.5406],
       device='cuda:0')
percent tensor([0.6501, 0.5197, 0.7191, 0.6930, 0.7239, 0.7011, 0.6108, 0.7051, 0.6484,
        0.5980, 0.6033, 0.6013, 0.5402, 0.5787, 0.6033, 0.6627],
       device='cuda:0')
percent tensor([0.6616, 0.6683, 0.5957, 0.6149, 0.5810, 0.6262, 0.6566, 0.6161, 0.6391,
        0.6753, 0.6699, 0.6507, 0.6905, 0.6690, 0.6554, 0.6587],
       device='cuda:0')
percent tensor([0.4595, 0.6168, 0.6556, 0.7183, 0.6757, 0.7089, 0.5963, 0.4892, 0.6627,
        0.6227, 0.7080, 0.6964, 0.5605, 0.7882, 0.5357, 0.5488],
       device='cuda:0')
percent tensor([0.7310, 0.7484, 0.7282, 0.7460, 0.7330, 0.7530, 0.7609, 0.6735, 0.7531,
        0.7358, 0.7594, 0.7666, 0.7507, 0.7856, 0.7692, 0.7509],
       device='cuda:0')
percent tensor([0.6543, 0.8007, 0.8008, 0.7856, 0.8360, 0.7739, 0.7508, 0.6918, 0.6542,
        0.7169, 0.6801, 0.6703, 0.5893, 0.6788, 0.5792, 0.6829],
       device='cuda:0')
percent tensor([0.9995, 0.9996, 0.9994, 0.9997, 0.9992, 0.9992, 0.9995, 0.9996, 0.9992,
        0.9995, 0.9997, 0.9997, 0.9991, 0.9990, 0.9994, 0.9991],
       device='cuda:0')
Epoch: 189 | Batch_idx: 0 |  Loss: (0.0240) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 189 | Batch_idx: 10 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 189 | Batch_idx: 20 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 189 | Batch_idx: 30 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (3886/3968)
Epoch: 189 | Batch_idx: 40 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (5143/5248)
Epoch: 189 | Batch_idx: 50 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (6394/6528)
Epoch: 189 | Batch_idx: 60 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (7643/7808)
Epoch: 189 | Batch_idx: 70 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (8896/9088)
Epoch: 189 | Batch_idx: 80 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (10155/10368)
Epoch: 189 | Batch_idx: 90 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (11400/11648)
Epoch: 189 | Batch_idx: 100 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (12648/12928)
Epoch: 189 | Batch_idx: 110 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (13897/14208)
Epoch: 189 | Batch_idx: 120 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (15144/15488)
Epoch: 189 | Batch_idx: 130 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (16391/16768)
Epoch: 189 | Batch_idx: 140 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (17635/18048)
Epoch: 189 | Batch_idx: 150 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (18880/19328)
Epoch: 189 | Batch_idx: 160 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (20120/20608)
Epoch: 189 | Batch_idx: 170 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (21372/21888)
Epoch: 189 | Batch_idx: 180 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (22614/23168)
Epoch: 189 | Batch_idx: 190 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (23858/24448)
Epoch: 189 | Batch_idx: 200 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (25109/25728)
Epoch: 189 | Batch_idx: 210 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (26362/27008)
Epoch: 189 | Batch_idx: 220 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (27617/28288)
Epoch: 189 | Batch_idx: 230 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (28860/29568)
Epoch: 189 | Batch_idx: 240 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (30106/30848)
Epoch: 189 | Batch_idx: 250 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (31353/32128)
Epoch: 189 | Batch_idx: 260 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (32601/33408)
Epoch: 189 | Batch_idx: 270 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (33851/34688)
Epoch: 189 | Batch_idx: 280 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (35092/35968)
Epoch: 189 | Batch_idx: 290 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (36337/37248)
Epoch: 189 | Batch_idx: 300 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (37582/38528)
Epoch: 189 | Batch_idx: 310 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (38832/39808)
Epoch: 189 | Batch_idx: 320 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (40074/41088)
Epoch: 189 | Batch_idx: 330 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (41321/42368)
Epoch: 189 | Batch_idx: 340 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (42567/43648)
Epoch: 189 | Batch_idx: 350 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (43809/44928)
Epoch: 189 | Batch_idx: 360 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (45049/46208)
Epoch: 189 | Batch_idx: 370 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (46296/47488)
Epoch: 189 | Batch_idx: 380 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (47535/48768)
Epoch: 189 | Batch_idx: 390 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (48742/50000)
# TEST : Loss: (0.4222) | Acc: (88.00%) (8875/10000)
percent tensor([0.5121, 0.5463, 0.5291, 0.5075, 0.5438, 0.5335, 0.5508, 0.5119, 0.5206,
        0.5331, 0.5291, 0.5417, 0.5123, 0.5281, 0.5410, 0.5151],
       device='cuda:0')
percent tensor([0.5696, 0.5599, 0.5180, 0.5551, 0.5207, 0.5069, 0.5443, 0.5751, 0.6141,
        0.5645, 0.5803, 0.5465, 0.5860, 0.6502, 0.5261, 0.5423],
       device='cuda:0')
percent tensor([0.6503, 0.5177, 0.7203, 0.7001, 0.7219, 0.6968, 0.6100, 0.7063, 0.6447,
        0.5925, 0.5975, 0.6047, 0.5451, 0.5868, 0.5965, 0.6641],
       device='cuda:0')
percent tensor([0.6685, 0.6839, 0.6020, 0.6212, 0.5890, 0.6320, 0.6642, 0.6226, 0.6490,
        0.6841, 0.6788, 0.6554, 0.6977, 0.6780, 0.6691, 0.6657],
       device='cuda:0')
percent tensor([0.4380, 0.6071, 0.6297, 0.7020, 0.6606, 0.7006, 0.6020, 0.4737, 0.6527,
        0.6083, 0.7208, 0.6702, 0.5588, 0.7626, 0.5197, 0.5427],
       device='cuda:0')
percent tensor([0.7316, 0.7575, 0.7187, 0.7340, 0.7285, 0.7549, 0.7628, 0.6752, 0.7511,
        0.7326, 0.7662, 0.7657, 0.7551, 0.7902, 0.7726, 0.7496],
       device='cuda:0')
percent tensor([0.6426, 0.7668, 0.7884, 0.7810, 0.8202, 0.7799, 0.7251, 0.6591, 0.6078,
        0.6926, 0.6774, 0.6796, 0.6049, 0.6261, 0.5617, 0.6504],
       device='cuda:0')
percent tensor([0.9996, 0.9994, 0.9996, 0.9997, 0.9993, 0.9993, 0.9994, 0.9997, 0.9993,
        0.9995, 0.9997, 0.9997, 0.9991, 0.9989, 0.9996, 0.9990],
       device='cuda:0')
Epoch: 190 | Batch_idx: 0 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 190 | Batch_idx: 10 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 190 | Batch_idx: 20 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 190 | Batch_idx: 30 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (98.00%) (3892/3968)
Epoch: 190 | Batch_idx: 40 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (5138/5248)
Epoch: 190 | Batch_idx: 50 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (6393/6528)
Epoch: 190 | Batch_idx: 60 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (7645/7808)
Epoch: 190 | Batch_idx: 70 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (8893/9088)
Epoch: 190 | Batch_idx: 80 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (10149/10368)
Epoch: 190 | Batch_idx: 90 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (11402/11648)
Epoch: 190 | Batch_idx: 100 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (12656/12928)
Epoch: 190 | Batch_idx: 110 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (13910/14208)
Epoch: 190 | Batch_idx: 120 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (15158/15488)
Epoch: 190 | Batch_idx: 130 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (16405/16768)
Epoch: 190 | Batch_idx: 140 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (17659/18048)
Epoch: 190 | Batch_idx: 150 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (18917/19328)
Epoch: 190 | Batch_idx: 160 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (20175/20608)
Epoch: 190 | Batch_idx: 170 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (21428/21888)
Epoch: 190 | Batch_idx: 180 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (22661/23168)
Epoch: 190 | Batch_idx: 190 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (23904/24448)
Epoch: 190 | Batch_idx: 200 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (25161/25728)
Epoch: 190 | Batch_idx: 210 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (26412/27008)
Epoch: 190 | Batch_idx: 220 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (27668/28288)
Epoch: 190 | Batch_idx: 230 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (28906/29568)
Epoch: 190 | Batch_idx: 240 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (30163/30848)
Epoch: 190 | Batch_idx: 250 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (31405/32128)
Epoch: 190 | Batch_idx: 260 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (32649/33408)
Epoch: 190 | Batch_idx: 270 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (33887/34688)
Epoch: 190 | Batch_idx: 280 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (35128/35968)
Epoch: 190 | Batch_idx: 290 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (36366/37248)
Epoch: 190 | Batch_idx: 300 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (37619/38528)
Epoch: 190 | Batch_idx: 310 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (38872/39808)
Epoch: 190 | Batch_idx: 320 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (40119/41088)
Epoch: 190 | Batch_idx: 330 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (41381/42368)
Epoch: 190 | Batch_idx: 340 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (42632/43648)
Epoch: 190 | Batch_idx: 350 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (43884/44928)
Epoch: 190 | Batch_idx: 360 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (45133/46208)
Epoch: 190 | Batch_idx: 370 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (46380/47488)
Epoch: 190 | Batch_idx: 380 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (47621/48768)
Epoch: 190 | Batch_idx: 390 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (48815/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_190.pth.tar'
# TEST : Loss: (0.4202) | Acc: (88.00%) (8852/10000)
percent tensor([0.5128, 0.5498, 0.5257, 0.5080, 0.5415, 0.5335, 0.5528, 0.5121, 0.5206,
        0.5341, 0.5307, 0.5399, 0.5134, 0.5343, 0.5420, 0.5165],
       device='cuda:0')
percent tensor([0.5642, 0.5603, 0.5219, 0.5532, 0.5230, 0.5019, 0.5471, 0.5747, 0.6083,
        0.5651, 0.5739, 0.5477, 0.5792, 0.6533, 0.5240, 0.5383],
       device='cuda:0')
percent tensor([0.6455, 0.5038, 0.7279, 0.6963, 0.7238, 0.6948, 0.6044, 0.7056, 0.6528,
        0.5872, 0.5956, 0.6048, 0.5374, 0.5759, 0.5899, 0.6580],
       device='cuda:0')
percent tensor([0.6668, 0.6856, 0.6010, 0.6245, 0.5856, 0.6344, 0.6644, 0.6216, 0.6446,
        0.6845, 0.6779, 0.6565, 0.6973, 0.6784, 0.6681, 0.6638],
       device='cuda:0')
percent tensor([0.4492, 0.5905, 0.6364, 0.7147, 0.6660, 0.6905, 0.5829, 0.4979, 0.6465,
        0.6152, 0.7003, 0.6852, 0.5712, 0.7717, 0.5318, 0.5374],
       device='cuda:0')
percent tensor([0.7376, 0.7634, 0.7254, 0.7447, 0.7315, 0.7616, 0.7623, 0.6825, 0.7563,
        0.7434, 0.7600, 0.7721, 0.7584, 0.7948, 0.7799, 0.7494],
       device='cuda:0')
percent tensor([0.6182, 0.7741, 0.7842, 0.7813, 0.8142, 0.7614, 0.7323, 0.6874, 0.6202,
        0.6868, 0.6901, 0.6728, 0.6396, 0.6212, 0.5431, 0.6445],
       device='cuda:0')
percent tensor([0.9996, 0.9996, 0.9995, 0.9997, 0.9992, 0.9993, 0.9994, 0.9997, 0.9989,
        0.9996, 0.9998, 0.9997, 0.9994, 0.9990, 0.9995, 0.9991],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(185.5607, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.7943, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(843.5679, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1516.3998, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(476.9167, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2281.6689, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4261.3516, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1352.6786, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6280.5229, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11605.1328, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3797.0288, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16043.5801, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 191 | Batch_idx: 0 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 191 | Batch_idx: 10 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 191 | Batch_idx: 20 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (96.00%) (2605/2688)
Epoch: 191 | Batch_idx: 30 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (3859/3968)
Epoch: 191 | Batch_idx: 40 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (5110/5248)
Epoch: 191 | Batch_idx: 50 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (6358/6528)
Epoch: 191 | Batch_idx: 60 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (7610/7808)
Epoch: 191 | Batch_idx: 70 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (8865/9088)
Epoch: 191 | Batch_idx: 80 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (10119/10368)
Epoch: 191 | Batch_idx: 90 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (11376/11648)
Epoch: 191 | Batch_idx: 100 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (12629/12928)
Epoch: 191 | Batch_idx: 110 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (13876/14208)
Epoch: 191 | Batch_idx: 120 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (15125/15488)
Epoch: 191 | Batch_idx: 130 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (16379/16768)
Epoch: 191 | Batch_idx: 140 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (17626/18048)
Epoch: 191 | Batch_idx: 150 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (18886/19328)
Epoch: 191 | Batch_idx: 160 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (20138/20608)
Epoch: 191 | Batch_idx: 170 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (21379/21888)
Epoch: 191 | Batch_idx: 180 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (22623/23168)
Epoch: 191 | Batch_idx: 190 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (23876/24448)
Epoch: 191 | Batch_idx: 200 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (25128/25728)
Epoch: 191 | Batch_idx: 210 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (26378/27008)
Epoch: 191 | Batch_idx: 220 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (27631/28288)
Epoch: 191 | Batch_idx: 230 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (28875/29568)
Epoch: 191 | Batch_idx: 240 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (30121/30848)
Epoch: 191 | Batch_idx: 250 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (31364/32128)
Epoch: 191 | Batch_idx: 260 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (32612/33408)
Epoch: 191 | Batch_idx: 270 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (33856/34688)
Epoch: 191 | Batch_idx: 280 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (35108/35968)
Epoch: 191 | Batch_idx: 290 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (36356/37248)
Epoch: 191 | Batch_idx: 300 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (37602/38528)
Epoch: 191 | Batch_idx: 310 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (38842/39808)
Epoch: 191 | Batch_idx: 320 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (40096/41088)
Epoch: 191 | Batch_idx: 330 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (41345/42368)
Epoch: 191 | Batch_idx: 340 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (42591/43648)
Epoch: 191 | Batch_idx: 350 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (43826/44928)
Epoch: 191 | Batch_idx: 360 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (45075/46208)
Epoch: 191 | Batch_idx: 370 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (46316/47488)
Epoch: 191 | Batch_idx: 380 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (47561/48768)
Epoch: 191 | Batch_idx: 390 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (48762/50000)
# TEST : Loss: (0.4182) | Acc: (88.00%) (8874/10000)
percent tensor([0.5123, 0.5473, 0.5286, 0.5086, 0.5437, 0.5345, 0.5519, 0.5122, 0.5204,
        0.5334, 0.5299, 0.5416, 0.5123, 0.5306, 0.5413, 0.5155],
       device='cuda:0')
percent tensor([0.5741, 0.5635, 0.5186, 0.5560, 0.5234, 0.5036, 0.5508, 0.5718, 0.6178,
        0.5709, 0.5820, 0.5507, 0.5890, 0.6577, 0.5242, 0.5449],
       device='cuda:0')
percent tensor([0.6508, 0.5220, 0.7321, 0.6971, 0.7288, 0.7043, 0.6154, 0.7102, 0.6584,
        0.5984, 0.6050, 0.6086, 0.5470, 0.5873, 0.6044, 0.6636],
       device='cuda:0')
percent tensor([0.6678, 0.6788, 0.6056, 0.6286, 0.5938, 0.6377, 0.6633, 0.6219, 0.6387,
        0.6787, 0.6763, 0.6568, 0.6958, 0.6735, 0.6658, 0.6696],
       device='cuda:0')
percent tensor([0.4495, 0.5836, 0.6340, 0.7140, 0.6705, 0.6831, 0.5859, 0.4881, 0.6581,
        0.6098, 0.7132, 0.6902, 0.5466, 0.7609, 0.5227, 0.5171],
       device='cuda:0')
percent tensor([0.7427, 0.7606, 0.7270, 0.7476, 0.7395, 0.7617, 0.7708, 0.6817, 0.7534,
        0.7421, 0.7671, 0.7760, 0.7615, 0.7919, 0.7819, 0.7575],
       device='cuda:0')
percent tensor([0.6542, 0.7890, 0.8037, 0.7794, 0.8262, 0.7603, 0.7544, 0.7108, 0.6339,
        0.7168, 0.7018, 0.6503, 0.6211, 0.6042, 0.5831, 0.6732],
       device='cuda:0')
percent tensor([0.9996, 0.9996, 0.9996, 0.9998, 0.9992, 0.9992, 0.9996, 0.9997, 0.9989,
        0.9996, 0.9998, 0.9996, 0.9994, 0.9989, 0.9995, 0.9992],
       device='cuda:0')
Epoch: 192 | Batch_idx: 0 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 192 | Batch_idx: 10 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 192 | Batch_idx: 20 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 192 | Batch_idx: 30 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (3876/3968)
Epoch: 192 | Batch_idx: 40 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (5133/5248)
Epoch: 192 | Batch_idx: 50 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (6388/6528)
Epoch: 192 | Batch_idx: 60 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (7642/7808)
Epoch: 192 | Batch_idx: 70 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (8893/9088)
Epoch: 192 | Batch_idx: 80 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (10149/10368)
Epoch: 192 | Batch_idx: 90 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (11399/11648)
Epoch: 192 | Batch_idx: 100 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (12643/12928)
Epoch: 192 | Batch_idx: 110 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (13884/14208)
Epoch: 192 | Batch_idx: 120 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (15131/15488)
Epoch: 192 | Batch_idx: 130 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (16376/16768)
Epoch: 192 | Batch_idx: 140 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (17615/18048)
Epoch: 192 | Batch_idx: 150 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (18864/19328)
Epoch: 192 | Batch_idx: 160 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (20115/20608)
Epoch: 192 | Batch_idx: 170 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (21377/21888)
Epoch: 192 | Batch_idx: 180 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (22627/23168)
Epoch: 192 | Batch_idx: 190 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (23883/24448)
Epoch: 192 | Batch_idx: 200 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (25132/25728)
Epoch: 192 | Batch_idx: 210 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (26380/27008)
Epoch: 192 | Batch_idx: 220 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (27623/28288)
Epoch: 192 | Batch_idx: 230 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (28871/29568)
Epoch: 192 | Batch_idx: 240 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (30120/30848)
Epoch: 192 | Batch_idx: 250 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (31364/32128)
Epoch: 192 | Batch_idx: 260 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (32615/33408)
Epoch: 192 | Batch_idx: 270 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (33865/34688)
Epoch: 192 | Batch_idx: 280 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (35110/35968)
Epoch: 192 | Batch_idx: 290 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (36353/37248)
Epoch: 192 | Batch_idx: 300 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (37601/38528)
Epoch: 192 | Batch_idx: 310 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (38856/39808)
Epoch: 192 | Batch_idx: 320 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (40099/41088)
Epoch: 192 | Batch_idx: 330 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (41343/42368)
Epoch: 192 | Batch_idx: 340 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (42587/43648)
Epoch: 192 | Batch_idx: 350 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (43835/44928)
Epoch: 192 | Batch_idx: 360 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (45087/46208)
Epoch: 192 | Batch_idx: 370 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (46337/47488)
Epoch: 192 | Batch_idx: 380 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (47589/48768)
Epoch: 192 | Batch_idx: 390 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (48789/50000)
# TEST : Loss: (0.4262) | Acc: (88.00%) (8831/10000)
percent tensor([0.5186, 0.5499, 0.5379, 0.5096, 0.5523, 0.5411, 0.5576, 0.5163, 0.5264,
        0.5378, 0.5352, 0.5491, 0.5173, 0.5315, 0.5453, 0.5190],
       device='cuda:0')
percent tensor([0.5650, 0.5611, 0.5075, 0.5458, 0.5096, 0.5008, 0.5420, 0.5648, 0.6082,
        0.5655, 0.5768, 0.5394, 0.5817, 0.6517, 0.5231, 0.5380],
       device='cuda:0')
percent tensor([0.6405, 0.5031, 0.7180, 0.6942, 0.7108, 0.6949, 0.5993, 0.7047, 0.6375,
        0.5801, 0.5845, 0.5905, 0.5290, 0.5828, 0.5895, 0.6572],
       device='cuda:0')
percent tensor([0.6653, 0.6825, 0.6015, 0.6225, 0.5898, 0.6326, 0.6623, 0.6220, 0.6412,
        0.6803, 0.6751, 0.6499, 0.6921, 0.6757, 0.6638, 0.6661],
       device='cuda:0')
percent tensor([0.4553, 0.6160, 0.6490, 0.7171, 0.6817, 0.7097, 0.6005, 0.4857, 0.6635,
        0.6294, 0.7264, 0.6908, 0.5666, 0.7803, 0.5334, 0.5535],
       device='cuda:0')
percent tensor([0.7428, 0.7655, 0.7311, 0.7472, 0.7421, 0.7649, 0.7655, 0.6830, 0.7625,
        0.7472, 0.7701, 0.7686, 0.7624, 0.7929, 0.7803, 0.7594],
       device='cuda:0')
percent tensor([0.6519, 0.7926, 0.7948, 0.7759, 0.8120, 0.7708, 0.7501, 0.6868, 0.6377,
        0.6826, 0.7032, 0.6980, 0.6182, 0.6523, 0.5901, 0.6589],
       device='cuda:0')
percent tensor([0.9995, 0.9995, 0.9994, 0.9997, 0.9992, 0.9992, 0.9996, 0.9997, 0.9993,
        0.9994, 0.9998, 0.9997, 0.9993, 0.9986, 0.9996, 0.9993],
       device='cuda:0')
Epoch: 193 | Batch_idx: 0 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 193 | Batch_idx: 10 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 193 | Batch_idx: 20 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (2639/2688)
Epoch: 193 | Batch_idx: 30 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (3896/3968)
Epoch: 193 | Batch_idx: 40 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (5146/5248)
Epoch: 193 | Batch_idx: 50 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (6395/6528)
Epoch: 193 | Batch_idx: 60 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (7648/7808)
Epoch: 193 | Batch_idx: 70 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (8904/9088)
Epoch: 193 | Batch_idx: 80 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (10156/10368)
Epoch: 193 | Batch_idx: 90 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (11411/11648)
Epoch: 193 | Batch_idx: 100 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (12659/12928)
Epoch: 193 | Batch_idx: 110 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (13909/14208)
Epoch: 193 | Batch_idx: 120 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (15160/15488)
Epoch: 193 | Batch_idx: 130 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (16405/16768)
Epoch: 193 | Batch_idx: 140 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (17665/18048)
Epoch: 193 | Batch_idx: 150 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (18913/19328)
Epoch: 193 | Batch_idx: 160 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (20172/20608)
Epoch: 193 | Batch_idx: 170 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (21424/21888)
Epoch: 193 | Batch_idx: 180 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (22670/23168)
Epoch: 193 | Batch_idx: 190 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (23907/24448)
Epoch: 193 | Batch_idx: 200 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (25160/25728)
Epoch: 193 | Batch_idx: 210 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (26405/27008)
Epoch: 193 | Batch_idx: 220 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (27662/28288)
Epoch: 193 | Batch_idx: 230 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (28916/29568)
Epoch: 193 | Batch_idx: 240 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (30166/30848)
Epoch: 193 | Batch_idx: 250 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (31418/32128)
Epoch: 193 | Batch_idx: 260 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (32667/33408)
Epoch: 193 | Batch_idx: 270 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (33912/34688)
Epoch: 193 | Batch_idx: 280 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (35156/35968)
Epoch: 193 | Batch_idx: 290 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (36404/37248)
Epoch: 193 | Batch_idx: 300 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (37657/38528)
Epoch: 193 | Batch_idx: 310 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (38910/39808)
Epoch: 193 | Batch_idx: 320 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (40160/41088)
Epoch: 193 | Batch_idx: 330 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (41407/42368)
Epoch: 193 | Batch_idx: 340 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (42650/43648)
Epoch: 193 | Batch_idx: 350 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (43906/44928)
Epoch: 193 | Batch_idx: 360 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (45154/46208)
Epoch: 193 | Batch_idx: 370 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (46409/47488)
Epoch: 193 | Batch_idx: 380 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (47655/48768)
Epoch: 193 | Batch_idx: 390 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (48857/50000)
# TEST : Loss: (0.4046) | Acc: (88.00%) (8881/10000)
percent tensor([0.5154, 0.5519, 0.5280, 0.5093, 0.5438, 0.5364, 0.5552, 0.5148, 0.5239,
        0.5356, 0.5340, 0.5417, 0.5158, 0.5364, 0.5445, 0.5189],
       device='cuda:0')
percent tensor([0.5714, 0.5569, 0.5168, 0.5506, 0.5223, 0.5053, 0.5435, 0.5677, 0.6095,
        0.5666, 0.5768, 0.5469, 0.5838, 0.6440, 0.5231, 0.5400],
       device='cuda:0')
percent tensor([0.6490, 0.5083, 0.7238, 0.6999, 0.7195, 0.7055, 0.6030, 0.7019, 0.6429,
        0.5899, 0.5993, 0.5993, 0.5366, 0.5724, 0.6016, 0.6594],
       device='cuda:0')
percent tensor([0.6654, 0.6808, 0.6009, 0.6180, 0.5867, 0.6315, 0.6627, 0.6195, 0.6440,
        0.6784, 0.6777, 0.6519, 0.6952, 0.6764, 0.6636, 0.6643],
       device='cuda:0')
percent tensor([0.4598, 0.6066, 0.6558, 0.7256, 0.6954, 0.6917, 0.6115, 0.5141, 0.6781,
        0.6427, 0.7219, 0.7278, 0.5847, 0.7698, 0.5359, 0.5637],
       device='cuda:0')
percent tensor([0.7485, 0.7727, 0.7290, 0.7492, 0.7441, 0.7687, 0.7769, 0.6906, 0.7657,
        0.7531, 0.7825, 0.7772, 0.7689, 0.8075, 0.7888, 0.7684],
       device='cuda:0')
percent tensor([0.6601, 0.7876, 0.8145, 0.7807, 0.8255, 0.7773, 0.7518, 0.7179, 0.6329,
        0.6843, 0.6750, 0.6948, 0.6039, 0.6467, 0.6009, 0.6790],
       device='cuda:0')
percent tensor([0.9997, 0.9997, 0.9997, 0.9997, 0.9993, 0.9995, 0.9996, 0.9997, 0.9993,
        0.9996, 0.9998, 0.9998, 0.9994, 0.9991, 0.9995, 0.9994],
       device='cuda:0')
Epoch: 194 | Batch_idx: 0 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 194 | Batch_idx: 10 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 194 | Batch_idx: 20 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 194 | Batch_idx: 30 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (3892/3968)
Epoch: 194 | Batch_idx: 40 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (5151/5248)
Epoch: 194 | Batch_idx: 50 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (6409/6528)
Epoch: 194 | Batch_idx: 60 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (7660/7808)
Epoch: 194 | Batch_idx: 70 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (98.00%) (8910/9088)
Epoch: 194 | Batch_idx: 80 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (98.00%) (10162/10368)
Epoch: 194 | Batch_idx: 90 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (11410/11648)
Epoch: 194 | Batch_idx: 100 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (12667/12928)
Epoch: 194 | Batch_idx: 110 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (13924/14208)
Epoch: 194 | Batch_idx: 120 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (15169/15488)
Epoch: 194 | Batch_idx: 130 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (16420/16768)
Epoch: 194 | Batch_idx: 140 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (17672/18048)
Epoch: 194 | Batch_idx: 150 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (18928/19328)
Epoch: 194 | Batch_idx: 160 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (20174/20608)
Epoch: 194 | Batch_idx: 170 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (21419/21888)
Epoch: 194 | Batch_idx: 180 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (22670/23168)
Epoch: 194 | Batch_idx: 190 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (23921/24448)
Epoch: 194 | Batch_idx: 200 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (25179/25728)
Epoch: 194 | Batch_idx: 210 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (26435/27008)
Epoch: 194 | Batch_idx: 220 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (27690/28288)
Epoch: 194 | Batch_idx: 230 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (28944/29568)
Epoch: 194 | Batch_idx: 240 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (30194/30848)
Epoch: 194 | Batch_idx: 250 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (31444/32128)
Epoch: 194 | Batch_idx: 260 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (32686/33408)
Epoch: 194 | Batch_idx: 270 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (33928/34688)
Epoch: 194 | Batch_idx: 280 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (35180/35968)
Epoch: 194 | Batch_idx: 290 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (36430/37248)
Epoch: 194 | Batch_idx: 300 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (37687/38528)
Epoch: 194 | Batch_idx: 310 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (38946/39808)
Epoch: 194 | Batch_idx: 320 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (40191/41088)
Epoch: 194 | Batch_idx: 330 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (41439/42368)
Epoch: 194 | Batch_idx: 340 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (42682/43648)
Epoch: 194 | Batch_idx: 350 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (43929/44928)
Epoch: 194 | Batch_idx: 360 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (45173/46208)
Epoch: 194 | Batch_idx: 370 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (46426/47488)
Epoch: 194 | Batch_idx: 380 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (47674/48768)
Epoch: 194 | Batch_idx: 390 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (48876/50000)
# TEST : Loss: (0.4301) | Acc: (88.00%) (8891/10000)
percent tensor([0.5184, 0.5582, 0.5299, 0.5149, 0.5469, 0.5407, 0.5605, 0.5186, 0.5267,
        0.5408, 0.5378, 0.5450, 0.5193, 0.5421, 0.5502, 0.5233],
       device='cuda:0')
percent tensor([0.5682, 0.5654, 0.5189, 0.5517, 0.5216, 0.4984, 0.5478, 0.5740, 0.6079,
        0.5702, 0.5749, 0.5531, 0.5852, 0.6509, 0.5232, 0.5402],
       device='cuda:0')
percent tensor([0.6485, 0.5053, 0.7276, 0.6966, 0.7258, 0.7131, 0.6042, 0.7028, 0.6423,
        0.5875, 0.5970, 0.5982, 0.5353, 0.5723, 0.6039, 0.6624],
       device='cuda:0')
percent tensor([0.6648, 0.6823, 0.5932, 0.6165, 0.5842, 0.6326, 0.6655, 0.6184, 0.6397,
        0.6793, 0.6748, 0.6497, 0.6925, 0.6823, 0.6641, 0.6660],
       device='cuda:0')
percent tensor([0.4515, 0.6204, 0.6295, 0.7212, 0.6586, 0.6954, 0.6153, 0.4789, 0.6722,
        0.6310, 0.7284, 0.7043, 0.5562, 0.7893, 0.5274, 0.5618],
       device='cuda:0')
percent tensor([0.7495, 0.7786, 0.7304, 0.7563, 0.7480, 0.7689, 0.7826, 0.6957, 0.7760,
        0.7541, 0.7768, 0.7775, 0.7691, 0.8064, 0.7866, 0.7685],
       device='cuda:0')
percent tensor([0.6558, 0.7887, 0.7935, 0.7871, 0.8101, 0.7862, 0.7220, 0.7005, 0.6423,
        0.6733, 0.6795, 0.6525, 0.6246, 0.6384, 0.5657, 0.6566],
       device='cuda:0')
percent tensor([0.9996, 0.9996, 0.9996, 0.9998, 0.9993, 0.9995, 0.9995, 0.9997, 0.9992,
        0.9996, 0.9998, 0.9997, 0.9993, 0.9988, 0.9996, 0.9993],
       device='cuda:0')
Epoch: 195 | Batch_idx: 0 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 195 | Batch_idx: 10 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 195 | Batch_idx: 20 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (2635/2688)
Epoch: 195 | Batch_idx: 30 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (3890/3968)
Epoch: 195 | Batch_idx: 40 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (5136/5248)
Epoch: 195 | Batch_idx: 50 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (6395/6528)
Epoch: 195 | Batch_idx: 60 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (7652/7808)
Epoch: 195 | Batch_idx: 70 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (8899/9088)
Epoch: 195 | Batch_idx: 80 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (10148/10368)
Epoch: 195 | Batch_idx: 90 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (11400/11648)
Epoch: 195 | Batch_idx: 100 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (12652/12928)
Epoch: 195 | Batch_idx: 110 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (13897/14208)
Epoch: 195 | Batch_idx: 120 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (15147/15488)
Epoch: 195 | Batch_idx: 130 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (16393/16768)
Epoch: 195 | Batch_idx: 140 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (17643/18048)
Epoch: 195 | Batch_idx: 150 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (18891/19328)
Epoch: 195 | Batch_idx: 160 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (20143/20608)
Epoch: 195 | Batch_idx: 170 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (21396/21888)
Epoch: 195 | Batch_idx: 180 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (22640/23168)
Epoch: 195 | Batch_idx: 190 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (23898/24448)
Epoch: 195 | Batch_idx: 200 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (25153/25728)
Epoch: 195 | Batch_idx: 210 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (26410/27008)
Epoch: 195 | Batch_idx: 220 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (27661/28288)
Epoch: 195 | Batch_idx: 230 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (28916/29568)
Epoch: 195 | Batch_idx: 240 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (30168/30848)
Epoch: 195 | Batch_idx: 250 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (31421/32128)
Epoch: 195 | Batch_idx: 260 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (32667/33408)
Epoch: 195 | Batch_idx: 270 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (33911/34688)
Epoch: 195 | Batch_idx: 280 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (35156/35968)
Epoch: 195 | Batch_idx: 290 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (36408/37248)
Epoch: 195 | Batch_idx: 300 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (37656/38528)
Epoch: 195 | Batch_idx: 310 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (38909/39808)
Epoch: 195 | Batch_idx: 320 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (40153/41088)
Epoch: 195 | Batch_idx: 330 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (41397/42368)
Epoch: 195 | Batch_idx: 340 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (42638/43648)
Epoch: 195 | Batch_idx: 350 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (43889/44928)
Epoch: 195 | Batch_idx: 360 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (45141/46208)
Epoch: 195 | Batch_idx: 370 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (46393/47488)
Epoch: 195 | Batch_idx: 380 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (47653/48768)
Epoch: 195 | Batch_idx: 390 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (48855/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate/checkpoint_195.pth.tar'
# TEST : Loss: (0.4210) | Acc: (88.00%) (8869/10000)
percent tensor([0.5143, 0.5512, 0.5265, 0.5098, 0.5431, 0.5382, 0.5535, 0.5144, 0.5219,
        0.5349, 0.5328, 0.5400, 0.5149, 0.5342, 0.5450, 0.5188],
       device='cuda:0')
percent tensor([0.5626, 0.5583, 0.5099, 0.5480, 0.5152, 0.4962, 0.5419, 0.5668, 0.6023,
        0.5623, 0.5709, 0.5447, 0.5780, 0.6470, 0.5199, 0.5360],
       device='cuda:0')
percent tensor([0.6504, 0.5170, 0.7279, 0.6937, 0.7233, 0.7019, 0.6129, 0.7010, 0.6461,
        0.5932, 0.5985, 0.6026, 0.5380, 0.5887, 0.6014, 0.6648],
       device='cuda:0')
percent tensor([0.6682, 0.6815, 0.5947, 0.6170, 0.5859, 0.6344, 0.6652, 0.6189, 0.6452,
        0.6784, 0.6775, 0.6490, 0.6981, 0.6801, 0.6647, 0.6663],
       device='cuda:0')
percent tensor([0.4503, 0.6103, 0.6380, 0.7057, 0.6671, 0.7061, 0.6178, 0.4851, 0.6650,
        0.6321, 0.7195, 0.7134, 0.5446, 0.7805, 0.5288, 0.5553],
       device='cuda:0')
percent tensor([0.7467, 0.7669, 0.7318, 0.7550, 0.7490, 0.7677, 0.7755, 0.6915, 0.7686,
        0.7461, 0.7742, 0.7764, 0.7685, 0.7954, 0.7857, 0.7605],
       device='cuda:0')
percent tensor([0.6400, 0.7961, 0.7990, 0.7802, 0.8278, 0.7826, 0.7470, 0.6861, 0.6269,
        0.6826, 0.6835, 0.6698, 0.6062, 0.6186, 0.5620, 0.6818],
       device='cuda:0')
percent tensor([0.9997, 0.9996, 0.9996, 0.9998, 0.9992, 0.9992, 0.9996, 0.9998, 0.9993,
        0.9995, 0.9997, 0.9997, 0.9994, 0.9988, 0.9996, 0.9994],
       device='cuda:0')
Epoch: 196 | Batch_idx: 0 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 196 | Batch_idx: 10 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 196 | Batch_idx: 20 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (2630/2688)
Epoch: 196 | Batch_idx: 30 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (3881/3968)
Epoch: 196 | Batch_idx: 40 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (5132/5248)
Epoch: 196 | Batch_idx: 50 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (6386/6528)
Epoch: 196 | Batch_idx: 60 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (7635/7808)
Epoch: 196 | Batch_idx: 70 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (8879/9088)
Epoch: 196 | Batch_idx: 80 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (10134/10368)
Epoch: 196 | Batch_idx: 90 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (11385/11648)
Epoch: 196 | Batch_idx: 100 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (12632/12928)
Epoch: 196 | Batch_idx: 110 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (13891/14208)
Epoch: 196 | Batch_idx: 120 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (15141/15488)
Epoch: 196 | Batch_idx: 130 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (16395/16768)
Epoch: 196 | Batch_idx: 140 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (17645/18048)
Epoch: 196 | Batch_idx: 150 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (18888/19328)
Epoch: 196 | Batch_idx: 160 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (20150/20608)
Epoch: 196 | Batch_idx: 170 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (21405/21888)
Epoch: 196 | Batch_idx: 180 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (22665/23168)
Epoch: 196 | Batch_idx: 190 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (23921/24448)
Epoch: 196 | Batch_idx: 200 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (25173/25728)
Epoch: 196 | Batch_idx: 210 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (26424/27008)
Epoch: 196 | Batch_idx: 220 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (27671/28288)
Epoch: 196 | Batch_idx: 230 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (28922/29568)
Epoch: 196 | Batch_idx: 240 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (30177/30848)
Epoch: 196 | Batch_idx: 250 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (31427/32128)
Epoch: 196 | Batch_idx: 260 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (32668/33408)
Epoch: 196 | Batch_idx: 270 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (33918/34688)
Epoch: 196 | Batch_idx: 280 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (35161/35968)
Epoch: 196 | Batch_idx: 290 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (36403/37248)
Epoch: 196 | Batch_idx: 300 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (37652/38528)
Epoch: 196 | Batch_idx: 310 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (38905/39808)
Epoch: 196 | Batch_idx: 320 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (40161/41088)
Epoch: 196 | Batch_idx: 330 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (41420/42368)
Epoch: 196 | Batch_idx: 340 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (42668/43648)
Epoch: 196 | Batch_idx: 350 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (43924/44928)
Epoch: 196 | Batch_idx: 360 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (45174/46208)
Epoch: 196 | Batch_idx: 370 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (46425/47488)
Epoch: 196 | Batch_idx: 380 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (47677/48768)
Epoch: 196 | Batch_idx: 390 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (48892/50000)
# TEST : Loss: (0.4270) | Acc: (88.00%) (8887/10000)
percent tensor([0.5168, 0.5540, 0.5324, 0.5144, 0.5482, 0.5399, 0.5571, 0.5184, 0.5250,
        0.5382, 0.5351, 0.5446, 0.5173, 0.5366, 0.5476, 0.5210],
       device='cuda:0')
percent tensor([0.5584, 0.5503, 0.5051, 0.5467, 0.5118, 0.4920, 0.5346, 0.5598, 0.5992,
        0.5522, 0.5656, 0.5354, 0.5742, 0.6373, 0.5141, 0.5275],
       device='cuda:0')
percent tensor([0.6467, 0.5158, 0.7215, 0.6925, 0.7202, 0.6976, 0.6098, 0.7082, 0.6423,
        0.5937, 0.5919, 0.6032, 0.5344, 0.5872, 0.5995, 0.6629],
       device='cuda:0')
percent tensor([0.6687, 0.6813, 0.6012, 0.6271, 0.5928, 0.6466, 0.6646, 0.6223, 0.6432,
        0.6779, 0.6759, 0.6517, 0.6947, 0.6780, 0.6681, 0.6720],
       device='cuda:0')
percent tensor([0.4788, 0.6255, 0.6112, 0.7187, 0.6496, 0.7036, 0.6133, 0.4854, 0.6656,
        0.6390, 0.7346, 0.6848, 0.6068, 0.7710, 0.5626, 0.5680],
       device='cuda:0')
percent tensor([0.7443, 0.7695, 0.7366, 0.7617, 0.7466, 0.7788, 0.7713, 0.6854, 0.7612,
        0.7467, 0.7728, 0.7710, 0.7718, 0.7942, 0.7903, 0.7654],
       device='cuda:0')
percent tensor([0.6678, 0.7776, 0.7799, 0.7481, 0.7999, 0.7656, 0.7590, 0.6870, 0.6434,
        0.6522, 0.6903, 0.6606, 0.5911, 0.6357, 0.5597, 0.6708],
       device='cuda:0')
percent tensor([0.9997, 0.9995, 0.9995, 0.9998, 0.9992, 0.9994, 0.9995, 0.9997, 0.9993,
        0.9996, 0.9998, 0.9997, 0.9994, 0.9992, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 197 | Batch_idx: 0 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 197 | Batch_idx: 10 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 197 | Batch_idx: 20 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (2630/2688)
Epoch: 197 | Batch_idx: 30 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (3884/3968)
Epoch: 197 | Batch_idx: 40 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (5137/5248)
Epoch: 197 | Batch_idx: 50 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (6397/6528)
Epoch: 197 | Batch_idx: 60 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (98.00%) (7654/7808)
Epoch: 197 | Batch_idx: 70 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (8916/9088)
Epoch: 197 | Batch_idx: 80 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (98.00%) (10171/10368)
Epoch: 197 | Batch_idx: 90 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (98.00%) (11426/11648)
Epoch: 197 | Batch_idx: 100 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (98.00%) (12680/12928)
Epoch: 197 | Batch_idx: 110 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (98.00%) (13927/14208)
Epoch: 197 | Batch_idx: 120 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (98.00%) (15179/15488)
Epoch: 197 | Batch_idx: 130 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (98.00%) (16433/16768)
Epoch: 197 | Batch_idx: 140 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (98.00%) (17689/18048)
Epoch: 197 | Batch_idx: 150 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (18937/19328)
Epoch: 197 | Batch_idx: 160 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (20192/20608)
Epoch: 197 | Batch_idx: 170 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (21446/21888)
Epoch: 197 | Batch_idx: 180 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (98.00%) (22705/23168)
Epoch: 197 | Batch_idx: 190 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (98.00%) (23960/24448)
Epoch: 197 | Batch_idx: 200 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (25212/25728)
Epoch: 197 | Batch_idx: 210 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (98.00%) (26468/27008)
Epoch: 197 | Batch_idx: 220 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (27722/28288)
Epoch: 197 | Batch_idx: 230 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (28974/29568)
Epoch: 197 | Batch_idx: 240 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (98.00%) (30232/30848)
Epoch: 197 | Batch_idx: 250 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (31483/32128)
Epoch: 197 | Batch_idx: 260 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (32739/33408)
Epoch: 197 | Batch_idx: 270 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (33991/34688)
Epoch: 197 | Batch_idx: 280 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (35246/35968)
Epoch: 197 | Batch_idx: 290 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (36493/37248)
Epoch: 197 | Batch_idx: 300 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (37740/38528)
Epoch: 197 | Batch_idx: 310 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (38983/39808)
Epoch: 197 | Batch_idx: 320 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (40227/41088)
Epoch: 197 | Batch_idx: 330 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (41480/42368)
Epoch: 197 | Batch_idx: 340 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (42738/43648)
Epoch: 197 | Batch_idx: 350 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (43993/44928)
Epoch: 197 | Batch_idx: 360 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (45251/46208)
Epoch: 197 | Batch_idx: 370 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (46498/47488)
Epoch: 197 | Batch_idx: 380 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (47742/48768)
Epoch: 197 | Batch_idx: 390 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (48949/50000)
# TEST : Loss: (0.4580) | Acc: (87.00%) (8792/10000)
percent tensor([0.5181, 0.5536, 0.5358, 0.5140, 0.5506, 0.5401, 0.5581, 0.5183, 0.5259,
        0.5395, 0.5350, 0.5476, 0.5179, 0.5350, 0.5473, 0.5213],
       device='cuda:0')
percent tensor([0.5622, 0.5617, 0.5128, 0.5552, 0.5118, 0.4988, 0.5407, 0.5724, 0.6037,
        0.5628, 0.5684, 0.5396, 0.5799, 0.6543, 0.5226, 0.5392],
       device='cuda:0')
percent tensor([0.6454, 0.5192, 0.7132, 0.6904, 0.7184, 0.7030, 0.6079, 0.6981, 0.6402,
        0.5908, 0.5954, 0.5866, 0.5325, 0.5939, 0.6039, 0.6621],
       device='cuda:0')
percent tensor([0.6740, 0.6806, 0.6122, 0.6318, 0.5956, 0.6432, 0.6652, 0.6267, 0.6429,
        0.6814, 0.6768, 0.6630, 0.6974, 0.6734, 0.6715, 0.6713],
       device='cuda:0')
percent tensor([0.4523, 0.6186, 0.6386, 0.7154, 0.6649, 0.7124, 0.6216, 0.5014, 0.6743,
        0.6209, 0.7151, 0.7048, 0.5624, 0.7735, 0.5360, 0.5617],
       device='cuda:0')
percent tensor([0.7491, 0.7714, 0.7529, 0.7645, 0.7542, 0.7746, 0.7754, 0.6940, 0.7722,
        0.7555, 0.7791, 0.7932, 0.7717, 0.7991, 0.7886, 0.7671],
       device='cuda:0')
percent tensor([0.6091, 0.7879, 0.7799, 0.7440, 0.7874, 0.7409, 0.7175, 0.6501, 0.6868,
        0.6629, 0.6819, 0.6147, 0.6097, 0.6206, 0.4974, 0.6195],
       device='cuda:0')
percent tensor([0.9995, 0.9996, 0.9996, 0.9998, 0.9993, 0.9993, 0.9995, 0.9996, 0.9992,
        0.9995, 0.9997, 0.9997, 0.9993, 0.9990, 0.9994, 0.9993],
       device='cuda:0')
Epoch: 198 | Batch_idx: 0 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 198 | Batch_idx: 10 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 198 | Batch_idx: 20 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (2640/2688)
Epoch: 198 | Batch_idx: 30 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (3895/3968)
Epoch: 198 | Batch_idx: 40 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (5154/5248)
Epoch: 198 | Batch_idx: 50 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (6412/6528)
Epoch: 198 | Batch_idx: 60 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (7662/7808)
Epoch: 198 | Batch_idx: 70 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (8920/9088)
Epoch: 198 | Batch_idx: 80 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (10175/10368)
Epoch: 198 | Batch_idx: 90 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (11437/11648)
Epoch: 198 | Batch_idx: 100 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (12693/12928)
Epoch: 198 | Batch_idx: 110 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (13948/14208)
Epoch: 198 | Batch_idx: 120 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (15212/15488)
Epoch: 198 | Batch_idx: 130 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (16465/16768)
Epoch: 198 | Batch_idx: 140 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (17729/18048)
Epoch: 198 | Batch_idx: 150 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (18981/19328)
Epoch: 198 | Batch_idx: 160 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (20231/20608)
Epoch: 198 | Batch_idx: 170 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (21490/21888)
Epoch: 198 | Batch_idx: 180 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (22751/23168)
Epoch: 198 | Batch_idx: 190 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (24003/24448)
Epoch: 198 | Batch_idx: 200 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (25261/25728)
Epoch: 198 | Batch_idx: 210 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (26512/27008)
Epoch: 198 | Batch_idx: 220 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (27762/28288)
Epoch: 198 | Batch_idx: 230 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (29020/29568)
Epoch: 198 | Batch_idx: 240 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (30269/30848)
Epoch: 198 | Batch_idx: 250 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (31521/32128)
Epoch: 198 | Batch_idx: 260 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (32767/33408)
Epoch: 198 | Batch_idx: 270 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (34018/34688)
Epoch: 198 | Batch_idx: 280 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (35267/35968)
Epoch: 198 | Batch_idx: 290 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (36518/37248)
Epoch: 198 | Batch_idx: 300 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (37778/38528)
Epoch: 198 | Batch_idx: 310 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (39032/39808)
Epoch: 198 | Batch_idx: 320 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (40290/41088)
Epoch: 198 | Batch_idx: 330 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (41546/42368)
Epoch: 198 | Batch_idx: 340 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (42796/43648)
Epoch: 198 | Batch_idx: 350 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (44047/44928)
Epoch: 198 | Batch_idx: 360 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (45302/46208)
Epoch: 198 | Batch_idx: 370 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (46557/47488)
Epoch: 198 | Batch_idx: 380 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (47822/48768)
Epoch: 198 | Batch_idx: 390 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (49030/50000)
# TEST : Loss: (0.4187) | Acc: (89.00%) (8905/10000)
percent tensor([0.5165, 0.5545, 0.5301, 0.5133, 0.5455, 0.5399, 0.5571, 0.5167, 0.5242,
        0.5380, 0.5351, 0.5429, 0.5168, 0.5390, 0.5476, 0.5214],
       device='cuda:0')
percent tensor([0.5637, 0.5564, 0.5032, 0.5409, 0.5111, 0.4974, 0.5392, 0.5602, 0.6079,
        0.5572, 0.5729, 0.5379, 0.5786, 0.6476, 0.5174, 0.5342],
       device='cuda:0')
percent tensor([0.6469, 0.5082, 0.7288, 0.7006, 0.7264, 0.7037, 0.6038, 0.7023, 0.6433,
        0.5938, 0.5924, 0.6015, 0.5352, 0.5782, 0.5981, 0.6624],
       device='cuda:0')
percent tensor([0.6738, 0.6856, 0.6019, 0.6285, 0.5896, 0.6439, 0.6693, 0.6253, 0.6488,
        0.6845, 0.6788, 0.6546, 0.7014, 0.6824, 0.6723, 0.6762],
       device='cuda:0')
percent tensor([0.4573, 0.6166, 0.6333, 0.7170, 0.6591, 0.6876, 0.6168, 0.4883, 0.6638,
        0.6332, 0.7325, 0.7059, 0.5610, 0.7871, 0.5345, 0.5537],
       device='cuda:0')
percent tensor([0.7513, 0.7825, 0.7359, 0.7638, 0.7511, 0.7785, 0.7813, 0.6951, 0.7716,
        0.7621, 0.7877, 0.7876, 0.7744, 0.8127, 0.7956, 0.7737],
       device='cuda:0')
percent tensor([0.6380, 0.7731, 0.7951, 0.7762, 0.8037, 0.7733, 0.7328, 0.6837, 0.6411,
        0.6453, 0.6679, 0.6387, 0.6019, 0.6138, 0.5496, 0.6444],
       device='cuda:0')
percent tensor([0.9997, 0.9996, 0.9996, 0.9998, 0.9993, 0.9994, 0.9996, 0.9996, 0.9993,
        0.9995, 0.9997, 0.9998, 0.9993, 0.9989, 0.9995, 0.9993],
       device='cuda:0')
Epoch: 199 | Batch_idx: 0 |  Loss: (0.0325) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 199 | Batch_idx: 10 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 199 | Batch_idx: 20 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (2638/2688)
Epoch: 199 | Batch_idx: 30 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (3895/3968)
Epoch: 199 | Batch_idx: 40 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (5156/5248)
Epoch: 199 | Batch_idx: 50 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (6416/6528)
Epoch: 199 | Batch_idx: 60 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (7674/7808)
Epoch: 199 | Batch_idx: 70 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (8931/9088)
Epoch: 199 | Batch_idx: 80 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (10189/10368)
Epoch: 199 | Batch_idx: 90 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (11444/11648)
Epoch: 199 | Batch_idx: 100 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (12700/12928)
Epoch: 199 | Batch_idx: 110 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (13966/14208)
Epoch: 199 | Batch_idx: 120 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (15220/15488)
Epoch: 199 | Batch_idx: 130 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (16472/16768)
Epoch: 199 | Batch_idx: 140 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (17723/18048)
Epoch: 199 | Batch_idx: 150 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (18981/19328)
Epoch: 199 | Batch_idx: 160 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (20236/20608)
Epoch: 199 | Batch_idx: 170 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (21490/21888)
Epoch: 199 | Batch_idx: 180 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (22748/23168)
Epoch: 199 | Batch_idx: 190 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (24005/24448)
Epoch: 199 | Batch_idx: 200 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (25255/25728)
Epoch: 199 | Batch_idx: 210 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (26517/27008)
Epoch: 199 | Batch_idx: 220 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (27775/28288)
Epoch: 199 | Batch_idx: 230 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (29035/29568)
Epoch: 199 | Batch_idx: 240 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (30302/30848)
Epoch: 199 | Batch_idx: 250 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (31548/32128)
Epoch: 199 | Batch_idx: 260 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (32801/33408)
Epoch: 199 | Batch_idx: 270 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (34054/34688)
Epoch: 199 | Batch_idx: 280 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (35305/35968)
Epoch: 199 | Batch_idx: 290 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (36556/37248)
Epoch: 199 | Batch_idx: 300 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (37806/38528)
Epoch: 199 | Batch_idx: 310 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (39061/39808)
Epoch: 199 | Batch_idx: 320 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (40321/41088)
Epoch: 199 | Batch_idx: 330 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (41582/42368)
Epoch: 199 | Batch_idx: 340 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (42836/43648)
Epoch: 199 | Batch_idx: 350 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (44095/44928)
Epoch: 199 | Batch_idx: 360 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (45351/46208)
Epoch: 199 | Batch_idx: 370 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (46599/47488)
Epoch: 199 | Batch_idx: 380 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (47851/48768)
Epoch: 199 | Batch_idx: 390 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (49059/50000)
# TEST : Loss: (0.4202) | Acc: (89.00%) (8919/10000)
percent tensor([0.5195, 0.5531, 0.5363, 0.5152, 0.5509, 0.5415, 0.5578, 0.5194, 0.5271,
        0.5393, 0.5359, 0.5476, 0.5187, 0.5348, 0.5477, 0.5222],
       device='cuda:0')
percent tensor([0.5659, 0.5578, 0.5097, 0.5506, 0.5155, 0.5037, 0.5400, 0.5632, 0.6035,
        0.5609, 0.5726, 0.5432, 0.5812, 0.6465, 0.5236, 0.5401],
       device='cuda:0')
percent tensor([0.6527, 0.5135, 0.7309, 0.7009, 0.7278, 0.7010, 0.6099, 0.7043, 0.6469,
        0.5926, 0.5936, 0.6110, 0.5420, 0.5867, 0.5997, 0.6641],
       device='cuda:0')
percent tensor([0.6766, 0.6865, 0.6085, 0.6303, 0.5914, 0.6438, 0.6686, 0.6278, 0.6508,
        0.6893, 0.6817, 0.6577, 0.7031, 0.6832, 0.6710, 0.6765],
       device='cuda:0')
percent tensor([0.4445, 0.5843, 0.6407, 0.7014, 0.6828, 0.6789, 0.6186, 0.4931, 0.6498,
        0.5984, 0.7142, 0.6982, 0.5538, 0.7571, 0.5173, 0.5450],
       device='cuda:0')
percent tensor([0.7532, 0.7748, 0.7451, 0.7636, 0.7587, 0.7758, 0.7852, 0.7045, 0.7722,
        0.7509, 0.7743, 0.7867, 0.7736, 0.8033, 0.7905, 0.7715],
       device='cuda:0')
percent tensor([0.6484, 0.7986, 0.8001, 0.7811, 0.8228, 0.7543, 0.7220, 0.6864, 0.6141,
        0.6638, 0.6778, 0.6716, 0.5954, 0.6137, 0.5730, 0.6467],
       device='cuda:0')
percent tensor([0.9997, 0.9994, 0.9996, 0.9998, 0.9993, 0.9991, 0.9995, 0.9997, 0.9992,
        0.9995, 0.9998, 0.9998, 0.9992, 0.9990, 0.9995, 0.9991],
       device='cuda:0')
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(186.3559, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(834.1144, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(848.2548, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1517.7018, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(475.4887, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2292.5330, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4267.5796, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1348.3896, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6312.2759, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11582.8701, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3783.8589, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15984.6484, device='cuda:0', grad_fn=<NormBackward0>)
2 hours 2 mins 34 secs for training