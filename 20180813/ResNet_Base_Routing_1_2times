Files already downloaded and verified
USE 1 GPUs!
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3130) | Acc: (6.00%) (8/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.1567) | Acc: (19.00%) (272/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.0581) | Acc: (23.00%) (620/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.0013) | Acc: (24.00%) (981/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (1.9522) | Acc: (26.00%) (1391/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (1.9221) | Acc: (27.00%) (1806/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (1.8964) | Acc: (28.00%) (2247/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (1.8713) | Acc: (29.00%) (2708/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (1.8525) | Acc: (30.00%) (3129/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (1.8363) | Acc: (30.00%) (3580/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (1.8186) | Acc: (31.00%) (4042/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (1.8032) | Acc: (31.00%) (4538/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (1.7859) | Acc: (32.00%) (5023/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (1.7699) | Acc: (33.00%) (5546/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (1.7553) | Acc: (33.00%) (6066/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (1.7410) | Acc: (34.00%) (6612/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (1.7273) | Acc: (34.00%) (7162/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (1.7167) | Acc: (35.00%) (7724/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (1.7058) | Acc: (35.00%) (8264/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (1.6976) | Acc: (35.00%) (8800/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (1.6890) | Acc: (36.00%) (9348/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (1.6791) | Acc: (36.00%) (9926/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (1.6699) | Acc: (37.00%) (10514/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (1.6605) | Acc: (37.00%) (11109/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (1.6494) | Acc: (37.00%) (11717/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (1.6397) | Acc: (38.00%) (12346/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (1.6297) | Acc: (38.00%) (12978/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (1.6225) | Acc: (39.00%) (13589/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (1.6129) | Acc: (39.00%) (14226/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (1.6041) | Acc: (39.00%) (14872/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (1.5946) | Acc: (40.00%) (15548/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (1.5851) | Acc: (40.00%) (16224/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (1.5746) | Acc: (41.00%) (16897/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (1.5659) | Acc: (41.00%) (17595/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (1.5593) | Acc: (41.00%) (18255/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (1.5531) | Acc: (42.00%) (18934/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (1.5453) | Acc: (42.00%) (19615/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (1.5381) | Acc: (42.00%) (20301/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (1.5314) | Acc: (43.00%) (21005/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (1.5233) | Acc: (43.00%) (21701/50000)
# TEST : Loss: (1.2977) | Acc: (51.00%) (5167/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1095, -0.2030,  0.1186],
          [-0.1002,  0.1745,  0.1185],
          [ 0.0492, -0.0229, -0.1271]],

         [[-0.1967,  0.1987,  0.1600],
          [ 0.0067,  0.1823,  0.0653],
          [ 0.1850, -0.1450,  0.1364]],

         [[-0.1487,  0.0251, -0.0268],
          [-0.1549, -0.0178, -0.0253],
          [-0.1595,  0.0245, -0.1021]]],


        [[[ 0.1236, -0.1538,  0.0934],
          [-0.0565, -0.1724,  0.0012],
          [ 0.1274, -0.0039, -0.1724]],

         [[-0.1076,  0.0923, -0.0201],
          [ 0.1424,  0.0173,  0.0429],
          [ 0.1209,  0.1588, -0.1410]],

         [[ 0.0460, -0.1606,  0.0034],
          [-0.1563,  0.0830,  0.0772],
          [ 0.0183, -0.0696, -0.1062]]],


        [[[ 0.0609,  0.1249, -0.0969],
          [-0.0582,  0.1209, -0.1392],
          [ 0.0037,  0.1850,  0.1099]],

         [[-0.1440,  0.0644, -0.1406],
          [-0.1718, -0.0188, -0.1447],
          [-0.1530, -0.1721,  0.0542]],

         [[ 0.1374, -0.0203,  0.1780],
          [ 0.0992,  0.0187,  0.0033],
          [-0.0742,  0.1100,  0.0669]]],


        ...,


        [[[ 0.2188, -0.0454, -0.0151],
          [ 0.1864, -0.1300,  0.0055],
          [-0.0646, -0.1298, -0.0534]],

         [[-0.0184, -0.0124, -0.1255],
          [-0.1532, -0.1691,  0.1242],
          [-0.0501,  0.1998,  0.1930]],

         [[-0.0657, -0.0976,  0.2298],
          [ 0.0236, -0.1885, -0.0968],
          [ 0.0315, -0.0589, -0.0223]]],


        [[[ 0.0663, -0.0803,  0.1310],
          [ 0.1858,  0.1014,  0.0123],
          [-0.1267, -0.0674,  0.0029]],

         [[ 0.1081,  0.0507, -0.1010],
          [ 0.0186, -0.0652, -0.2152],
          [ 0.0086,  0.1301, -0.0491]],

         [[-0.0558,  0.0399, -0.1946],
          [-0.0780,  0.0496,  0.0747],
          [ 0.1247,  0.0340, -0.0041]]],


        [[[ 0.0176,  0.0731, -0.0019],
          [ 0.1076,  0.0871, -0.0524],
          [ 0.1321,  0.1011,  0.0299]],

         [[ 0.0128,  0.0233, -0.0514],
          [ 0.1234,  0.0065,  0.0211],
          [-0.0877, -0.1275, -0.0364]],

         [[ 0.1577,  0.0947, -0.1215],
          [ 0.0052, -0.1324,  0.0246],
          [ 0.1319,  0.0618, -0.1706]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0446,  0.0408,  0.0415],
          [ 0.0443,  0.0384,  0.0416],
          [ 0.0468,  0.0394,  0.0403]],

         [[ 0.0681,  0.0661,  0.0658],
          [ 0.0691,  0.0666,  0.0695],
          [ 0.0730,  0.0701,  0.0715]],

         [[ 0.0585,  0.0554,  0.0545],
          [ 0.0613,  0.0588,  0.0600],
          [ 0.0666,  0.0646,  0.0641]]],


        [[[ 0.0206,  0.0179,  0.0199],
          [ 0.0221,  0.0183,  0.0190],
          [ 0.0253,  0.0213,  0.0196]],

         [[ 0.0263,  0.0233,  0.0252],
          [ 0.0285,  0.0243,  0.0251],
          [ 0.0326,  0.0283,  0.0265]],

         [[ 0.0221,  0.0198,  0.0215],
          [ 0.0248,  0.0215,  0.0221],
          [ 0.0298,  0.0263,  0.0242]]],


        [[[-0.0306, -0.0161, -0.0128],
          [-0.0432, -0.0286, -0.0272],
          [-0.0333, -0.0318, -0.0376]],

         [[-0.0026,  0.0071,  0.0008],
          [-0.0185, -0.0069, -0.0136],
          [-0.0148, -0.0136, -0.0256]],

         [[ 0.0090,  0.0153,  0.0094],
          [-0.0084,  0.0011, -0.0044],
          [-0.0102, -0.0070, -0.0152]]],


        ...,


        [[[ 0.0028,  0.0056, -0.0037],
          [-0.0016,  0.0037, -0.0064],
          [-0.0101, -0.0042, -0.0149]],

         [[-0.0173, -0.0156, -0.0290],
          [-0.0200, -0.0160, -0.0294],
          [-0.0276, -0.0233, -0.0364]],

         [[-0.0174, -0.0169, -0.0287],
          [-0.0178, -0.0147, -0.0257],
          [-0.0243, -0.0212, -0.0319]]],


        [[[-0.0148, -0.0172, -0.0147],
          [-0.0165, -0.0189, -0.0130],
          [-0.0073, -0.0136, -0.0133]],

         [[-0.0275, -0.0314, -0.0312],
          [-0.0271, -0.0322, -0.0310],
          [-0.0207, -0.0304, -0.0347]],

         [[-0.0140, -0.0172, -0.0187],
          [-0.0163, -0.0210, -0.0216],
          [-0.0125, -0.0201, -0.0248]]],


        [[[-0.0001, -0.0003, -0.0005],
          [-0.0002, -0.0003, -0.0005],
          [ 0.0000, -0.0001, -0.0003]],

         [[-0.0002, -0.0004, -0.0007],
          [-0.0002, -0.0003, -0.0006],
          [ 0.0002,  0.0000, -0.0003]],

         [[ 0.0001,  0.0000, -0.0002],
          [ 0.0002,  0.0001, -0.0000],
          [ 0.0005,  0.0004,  0.0002]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.]], device='cuda:0')

percentage_weight_grad None

Epoch: 1 | Batch_idx: 0 |  Loss: (1.1590) | Acc: (55.00%) (71/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.2115) | Acc: (56.00%) (789/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.1980) | Acc: (56.00%) (1517/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.1916) | Acc: (56.00%) (2233/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.2005) | Acc: (55.00%) (2938/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.2002) | Acc: (56.00%) (3671/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.1990) | Acc: (56.00%) (4400/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.2070) | Acc: (56.00%) (5108/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.1937) | Acc: (56.00%) (5894/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.1899) | Acc: (56.00%) (6618/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.1876) | Acc: (56.00%) (7347/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.1817) | Acc: (57.00%) (8121/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.1792) | Acc: (57.00%) (8861/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.1718) | Acc: (57.00%) (9646/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.1675) | Acc: (57.00%) (10417/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.1620) | Acc: (58.00%) (11216/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.1576) | Acc: (58.00%) (11973/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.1508) | Acc: (58.00%) (12788/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.1443) | Acc: (58.00%) (13584/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.1427) | Acc: (58.00%) (14367/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.1372) | Acc: (58.00%) (15170/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.1324) | Acc: (59.00%) (15974/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.1289) | Acc: (59.00%) (16756/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.1258) | Acc: (59.00%) (17544/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.1247) | Acc: (59.00%) (18324/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.1205) | Acc: (59.00%) (19121/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.1154) | Acc: (59.00%) (19944/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.1122) | Acc: (59.00%) (20742/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.1079) | Acc: (59.00%) (21538/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.1038) | Acc: (60.00%) (22377/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.0983) | Acc: (60.00%) (23230/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.0935) | Acc: (60.00%) (24052/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.0903) | Acc: (60.00%) (24874/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.0873) | Acc: (60.00%) (25688/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.0830) | Acc: (60.00%) (26530/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.0796) | Acc: (60.00%) (27355/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.0750) | Acc: (61.00%) (28223/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.0711) | Acc: (61.00%) (29077/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.0663) | Acc: (61.00%) (29937/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.0634) | Acc: (61.00%) (30758/50000)
# TEST : Loss: (0.9885) | Acc: (66.00%) (6604/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1161, -0.2112,  0.1030],
          [-0.1009,  0.1770,  0.1132],
          [ 0.0599, -0.0233, -0.1352]],

         [[-0.2021,  0.1989,  0.1564],
          [ 0.0037,  0.1892,  0.0653],
          [ 0.1930, -0.1444,  0.1282]],

         [[-0.1506,  0.0253, -0.0284],
          [-0.1592, -0.0151, -0.0261],
          [-0.1496,  0.0256, -0.1055]]],


        [[[ 0.1128, -0.1602,  0.1013],
          [-0.0654, -0.1704,  0.0120],
          [ 0.1233, -0.0008, -0.1753]],

         [[-0.1133,  0.0906, -0.0073],
          [ 0.1375,  0.0238,  0.0561],
          [ 0.1198,  0.1634, -0.1464]],

         [[ 0.0495, -0.1562,  0.0219],
          [-0.1528,  0.0940,  0.0973],
          [ 0.0263, -0.0574, -0.1027]]],


        [[[ 0.0560,  0.1119, -0.1092],
          [-0.0545,  0.1191, -0.1445],
          [ 0.0037,  0.1816,  0.1102]],

         [[-0.1398,  0.0563, -0.1489],
          [-0.1664, -0.0234, -0.1525],
          [-0.1514, -0.1771,  0.0549]],

         [[ 0.1523, -0.0150,  0.1801],
          [ 0.1155,  0.0260,  0.0043],
          [-0.0672,  0.1096,  0.0694]]],


        ...,


        [[[ 0.2180, -0.0437, -0.0067],
          [ 0.1747, -0.1403,  0.0050],
          [-0.0792, -0.1419, -0.0618]],

         [[-0.0174, -0.0113, -0.1163],
          [-0.1584, -0.1734,  0.1324],
          [-0.0527,  0.2002,  0.1963]],

         [[-0.0617, -0.0989,  0.2284],
          [ 0.0241, -0.1976, -0.0976],
          [ 0.0405, -0.0548, -0.0237]]],


        [[[ 0.0568, -0.0873,  0.1205],
          [ 0.1770,  0.0977,  0.0022],
          [-0.1516, -0.0758,  0.0042]],

         [[ 0.0917,  0.0326, -0.1241],
          [ 0.0155, -0.0674, -0.2265],
          [ 0.0000,  0.1333, -0.0395]],

         [[-0.0653,  0.0322, -0.2046],
          [-0.0740,  0.0556,  0.0714],
          [ 0.1245,  0.0444,  0.0118]]],


        [[[ 0.0219,  0.0665, -0.0011],
          [ 0.1193,  0.1023, -0.0295],
          [ 0.1307,  0.1096,  0.0486]],

         [[-0.0050,  0.0051, -0.0631],
          [ 0.1045,  0.0034,  0.0207],
          [-0.0940, -0.1224, -0.0281]],

         [[ 0.1393,  0.0821, -0.1249],
          [-0.0054, -0.1300,  0.0191],
          [ 0.1080,  0.0484, -0.1667]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0255, -0.0283, -0.0320],
          [-0.0272, -0.0277, -0.0335],
          [-0.0316, -0.0330, -0.0367]],

         [[-0.0235, -0.0263, -0.0262],
          [-0.0294, -0.0302, -0.0300],
          [-0.0321, -0.0346, -0.0336]],

         [[-0.0223, -0.0239, -0.0231],
          [-0.0243, -0.0255, -0.0235],
          [-0.0247, -0.0293, -0.0283]]],


        [[[-0.0058, -0.0067, -0.0063],
          [-0.0020, -0.0025, -0.0024],
          [-0.0031, -0.0031, -0.0042]],

         [[-0.0107, -0.0125, -0.0118],
          [-0.0073, -0.0086, -0.0072],
          [-0.0080, -0.0077, -0.0076]],

         [[-0.0111, -0.0123, -0.0110],
          [-0.0073, -0.0088, -0.0078],
          [-0.0078, -0.0082, -0.0090]]],


        [[[ 0.0514,  0.0280,  0.0313],
          [ 0.0690,  0.0487,  0.0488],
          [ 0.0685,  0.0524,  0.0527]],

         [[ 0.1129,  0.0967,  0.0915],
          [ 0.1355,  0.1195,  0.1051],
          [ 0.1326,  0.1128,  0.0959]],

         [[ 0.1581,  0.1458,  0.1330],
          [ 0.1772,  0.1630,  0.1401],
          [ 0.1737,  0.1531,  0.1285]]],


        ...,


        [[[-0.0222, -0.0184, -0.0180],
          [-0.0305, -0.0265, -0.0227],
          [-0.0271, -0.0194, -0.0122]],

         [[ 0.0033,  0.0021, -0.0023],
          [-0.0053, -0.0065, -0.0089],
          [-0.0032, -0.0002,  0.0014]],

         [[ 0.0098,  0.0068, -0.0005],
          [ 0.0041,  0.0011, -0.0039],
          [ 0.0065,  0.0070,  0.0067]]],


        [[[-0.0024, -0.0064, -0.0087],
          [-0.0155, -0.0074,  0.0036],
          [-0.0135,  0.0063,  0.0276]],

         [[-0.0050, -0.0108, -0.0145],
          [-0.0107, -0.0047,  0.0007],
          [-0.0052,  0.0114,  0.0253]],

         [[ 0.0088,  0.0048,  0.0061],
          [-0.0005,  0.0072,  0.0145],
          [-0.0001,  0.0171,  0.0314]]],


        [[[ 0.0005,  0.0002,  0.0002],
          [ 0.0005,  0.0004,  0.0003],
          [ 0.0004,  0.0004,  0.0007]],

         [[ 0.0014,  0.0012,  0.0012],
          [ 0.0014,  0.0013,  0.0012],
          [ 0.0013,  0.0013,  0.0014]],

         [[ 0.0016,  0.0014,  0.0013],
          [ 0.0017,  0.0016,  0.0014],
          [ 0.0016,  0.0016,  0.0016]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.]], device='cuda:0')

percentage_weight_grad None

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 2 | Batch_idx: 0 |  Loss: (0.9316) | Acc: (71.00%) (92/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.0120) | Acc: (63.00%) (898/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.1993) | Acc: (57.00%) (1558/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.2736) | Acc: (56.00%) (2241/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.2955) | Acc: (55.00%) (2931/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.3039) | Acc: (55.00%) (3601/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.2983) | Acc: (55.00%) (4305/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.2934) | Acc: (55.00%) (5018/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.2897) | Acc: (55.00%) (5739/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.2799) | Acc: (55.00%) (6472/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.2665) | Acc: (56.00%) (7240/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.2569) | Acc: (56.00%) (7974/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.2527) | Acc: (56.00%) (8703/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.2433) | Acc: (56.00%) (9456/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.2354) | Acc: (56.00%) (10229/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.2270) | Acc: (56.00%) (11013/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.2198) | Acc: (57.00%) (11797/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.2103) | Acc: (57.00%) (12622/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.2040) | Acc: (57.00%) (13410/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.2000) | Acc: (57.00%) (14167/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.1924) | Acc: (58.00%) (14989/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.1885) | Acc: (58.00%) (15756/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.1843) | Acc: (58.00%) (16538/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.1809) | Acc: (58.00%) (17305/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.1782) | Acc: (58.00%) (18070/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.1729) | Acc: (58.00%) (18887/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.1685) | Acc: (58.00%) (19694/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.1627) | Acc: (59.00%) (20527/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.1582) | Acc: (59.00%) (21341/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.1541) | Acc: (59.00%) (22172/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.1505) | Acc: (59.00%) (22976/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.1466) | Acc: (59.00%) (23807/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.1463) | Acc: (59.00%) (24572/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.1431) | Acc: (59.00%) (25392/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.1401) | Acc: (60.00%) (26222/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.1374) | Acc: (60.00%) (27009/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.1345) | Acc: (60.00%) (27842/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.1320) | Acc: (60.00%) (28631/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.1300) | Acc: (60.00%) (29442/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.1285) | Acc: (60.00%) (30204/50000)
# TEST : Loss: (1.0018) | Acc: (64.00%) (6469/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1142, -0.2082,  0.1061],
          [-0.0996,  0.1789,  0.1159],
          [ 0.0610, -0.0214, -0.1324]],

         [[-0.2009,  0.2008,  0.1589],
          [ 0.0041,  0.1906,  0.0675],
          [ 0.1931, -0.1431,  0.1297]],

         [[-0.1487,  0.0279, -0.0254],
          [-0.1579, -0.0130, -0.0235],
          [-0.1485,  0.0272, -0.1033]]],


        [[[ 0.1121, -0.1597,  0.1018],
          [-0.0654, -0.1698,  0.0127],
          [ 0.1229, -0.0006, -0.1743]],

         [[-0.1125,  0.0912, -0.0055],
          [ 0.1378,  0.0247,  0.0576],
          [ 0.1202,  0.1638, -0.1448]],

         [[ 0.0502, -0.1546,  0.0237],
          [-0.1512,  0.0950,  0.0989],
          [ 0.0273, -0.0559, -0.1009]]],


        [[[ 0.0500,  0.1055, -0.1151],
          [-0.0601,  0.1128, -0.1505],
          [-0.0019,  0.1755,  0.1041]],

         [[-0.1458,  0.0499, -0.1549],
          [-0.1730, -0.0305, -0.1591],
          [-0.1579, -0.1838,  0.0485]],

         [[ 0.1468, -0.0205,  0.1748],
          [ 0.1099,  0.0203, -0.0010],
          [-0.0726,  0.1039,  0.0642]]],


        ...,


        [[[ 0.2170, -0.0447, -0.0068],
          [ 0.1757, -0.1389,  0.0059],
          [-0.0760, -0.1394, -0.0605]],

         [[-0.0176, -0.0122, -0.1153],
          [-0.1565, -0.1715,  0.1336],
          [-0.0500,  0.2014,  0.1973]],

         [[-0.0619, -0.0997,  0.2277],
          [ 0.0249, -0.1958, -0.0962],
          [ 0.0421, -0.0535, -0.0230]]],


        [[[ 0.0559, -0.0872,  0.1208],
          [ 0.1771,  0.0983,  0.0028],
          [-0.1505, -0.0749,  0.0044]],

         [[ 0.0909,  0.0322, -0.1239],
          [ 0.0160, -0.0667, -0.2256],
          [ 0.0009,  0.1338, -0.0391]],

         [[-0.0664,  0.0314, -0.2048],
          [-0.0739,  0.0557,  0.0714],
          [ 0.1246,  0.0447,  0.0119]]],


        [[[ 0.0179,  0.0581, -0.0020],
          [ 0.0993,  0.0902, -0.0282],
          [ 0.1121,  0.0979,  0.0429]],

         [[-0.0033,  0.0055, -0.0587],
          [ 0.0965,  0.0041,  0.0192],
          [-0.0851, -0.1128, -0.0275]],

         [[ 0.1292,  0.0759, -0.1186],
          [-0.0059, -0.1228,  0.0165],
          [ 0.0997,  0.0438, -0.1591]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1460]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0316]], device='cuda:0')

Epoch: 3 | Batch_idx: 0 |  Loss: (1.1245) | Acc: (60.00%) (77/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.0695) | Acc: (62.00%) (874/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.0517) | Acc: (62.00%) (1681/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.0331) | Acc: (63.00%) (2525/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.0232) | Acc: (63.00%) (3356/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.0171) | Acc: (64.00%) (4187/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.0155) | Acc: (64.00%) (5008/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.0121) | Acc: (64.00%) (5837/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.0041) | Acc: (64.00%) (6704/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.0026) | Acc: (64.00%) (7517/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.0049) | Acc: (64.00%) (8335/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.0054) | Acc: (64.00%) (9155/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.0072) | Acc: (64.00%) (9978/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.0080) | Acc: (64.00%) (10795/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.0078) | Acc: (64.00%) (11620/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.0096) | Acc: (64.00%) (12431/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.0083) | Acc: (64.00%) (13259/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.0080) | Acc: (64.00%) (14086/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.0093) | Acc: (64.00%) (14897/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.0097) | Acc: (64.00%) (15717/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.0107) | Acc: (64.00%) (16524/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.0097) | Acc: (64.00%) (17372/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.0090) | Acc: (64.00%) (18213/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.0082) | Acc: (64.00%) (19056/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.0056) | Acc: (64.00%) (19920/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.0059) | Acc: (64.00%) (20747/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.0048) | Acc: (64.00%) (21574/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.0063) | Acc: (64.00%) (22407/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.0079) | Acc: (64.00%) (23210/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.0083) | Acc: (64.00%) (24032/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.0070) | Acc: (64.00%) (24878/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.0055) | Acc: (64.00%) (25731/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.0073) | Acc: (64.00%) (26533/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.0067) | Acc: (64.00%) (27374/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.0060) | Acc: (64.00%) (28204/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.0041) | Acc: (64.00%) (29062/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.0036) | Acc: (64.00%) (29900/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.0033) | Acc: (64.00%) (30739/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.0021) | Acc: (64.00%) (31590/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.0018) | Acc: (64.00%) (32412/50000)
# TEST : Loss: (0.9601) | Acc: (66.00%) (6611/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1140, -0.2079,  0.1059],
          [-0.0994,  0.1786,  0.1157],
          [ 0.0609, -0.0213, -0.1322]],

         [[-0.2005,  0.2004,  0.1586],
          [ 0.0041,  0.1902,  0.0674],
          [ 0.1927, -0.1428,  0.1295]],

         [[-0.1484,  0.0279, -0.0254],
          [-0.1576, -0.0129, -0.0235],
          [-0.1482,  0.0272, -0.1031]]],


        [[[ 0.1117, -0.1591,  0.1015],
          [-0.0652, -0.1692,  0.0127],
          [ 0.1224, -0.0006, -0.1737]],

         [[-0.1120,  0.0908, -0.0055],
          [ 0.1372,  0.0246,  0.0573],
          [ 0.1197,  0.1631, -0.1442]],

         [[ 0.0500, -0.1539,  0.0236],
          [-0.1505,  0.0946,  0.0984],
          [ 0.0272, -0.0556, -0.1004]]],


        [[[ 0.0500,  0.1054, -0.1150],
          [-0.0601,  0.1127, -0.1503],
          [-0.0019,  0.1753,  0.1040]],

         [[-0.1457,  0.0498, -0.1547],
          [-0.1728, -0.0305, -0.1590],
          [-0.1577, -0.1836,  0.0484]],

         [[ 0.1466, -0.0205,  0.1746],
          [ 0.1098,  0.0202, -0.0010],
          [-0.0725,  0.1037,  0.0641]]],


        ...,


        [[[ 0.2161, -0.0445, -0.0068],
          [ 0.1750, -0.1382,  0.0058],
          [-0.0756, -0.1388, -0.0603]],

         [[-0.0176, -0.0121, -0.1148],
          [-0.1557, -0.1705,  0.1329],
          [-0.0498,  0.2004,  0.1965]],

         [[-0.0615, -0.0990,  0.2264],
          [ 0.0247, -0.1939, -0.0956],
          [ 0.0418, -0.0531, -0.0229]]],


        [[[ 0.0558, -0.0870,  0.1205],
          [ 0.1767,  0.0981,  0.0028],
          [-0.1502, -0.0747,  0.0044]],

         [[ 0.0907,  0.0321, -0.1236],
          [ 0.0159, -0.0665, -0.2252],
          [ 0.0009,  0.1335, -0.0390]],

         [[-0.0662,  0.0313, -0.2043],
          [-0.0738,  0.0556,  0.0712],
          [ 0.1243,  0.0446,  0.0119]]],


        [[[ 0.0143,  0.0494, -0.0018],
          [ 0.0779,  0.0768, -0.0253],
          [ 0.0926,  0.0856,  0.0389]],

         [[-0.0029,  0.0049, -0.0532],
          [ 0.0850,  0.0037,  0.0174],
          [-0.0753, -0.1014, -0.0252]],

         [[ 0.1179,  0.0695, -0.1089],
          [-0.0054, -0.1125,  0.0152],
          [ 0.0910,  0.0401, -0.1464]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2199]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0096]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 4 | Batch_idx: 0 |  Loss: (0.9412) | Acc: (70.00%) (90/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.1631) | Acc: (59.00%) (832/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.1944) | Acc: (57.00%) (1549/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.2161) | Acc: (57.00%) (2266/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.2200) | Acc: (56.00%) (2967/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.2212) | Acc: (56.00%) (3677/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.1957) | Acc: (57.00%) (4463/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.1708) | Acc: (57.00%) (5261/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.1526) | Acc: (58.00%) (6078/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.1385) | Acc: (59.00%) (6882/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.1286) | Acc: (59.00%) (7660/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.1191) | Acc: (59.00%) (8465/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.1059) | Acc: (60.00%) (9311/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.0946) | Acc: (60.00%) (10130/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.0818) | Acc: (60.00%) (11007/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.0706) | Acc: (61.00%) (11885/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.0624) | Acc: (61.00%) (12733/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.0572) | Acc: (62.00%) (13577/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.0520) | Acc: (62.00%) (14433/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.0474) | Acc: (62.00%) (15269/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.0422) | Acc: (62.00%) (16115/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.0361) | Acc: (62.00%) (16972/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.0309) | Acc: (63.00%) (17831/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.0227) | Acc: (63.00%) (18730/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.0155) | Acc: (63.00%) (19613/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.0095) | Acc: (63.00%) (20501/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.0016) | Acc: (64.00%) (21413/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (0.9977) | Acc: (64.00%) (22276/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (0.9922) | Acc: (64.00%) (23187/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (0.9880) | Acc: (64.00%) (24086/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (0.9826) | Acc: (64.00%) (25008/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (0.9772) | Acc: (65.00%) (25921/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (0.9731) | Acc: (65.00%) (26830/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (0.9681) | Acc: (65.00%) (27762/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (0.9648) | Acc: (65.00%) (28664/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (0.9595) | Acc: (65.00%) (29602/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (0.9559) | Acc: (66.00%) (30500/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (0.9520) | Acc: (66.00%) (31415/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (0.9473) | Acc: (66.00%) (32365/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (0.9429) | Acc: (66.00%) (33251/50000)
# TEST : Loss: (0.9174) | Acc: (68.00%) (6836/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1121, -0.2057,  0.1030],
          [-0.0961,  0.1871,  0.1212],
          [ 0.0745, -0.0169, -0.1261]],

         [[-0.2031,  0.2075,  0.1656],
          [-0.0003,  0.1987,  0.0758],
          [ 0.1998, -0.1424,  0.1328]],

         [[-0.1492,  0.0287, -0.0260],
          [-0.1677, -0.0176, -0.0268],
          [-0.1458,  0.0181, -0.1046]]],


        [[[ 0.1184, -0.1570,  0.1164],
          [-0.0646, -0.1588,  0.0322],
          [ 0.1215,  0.0073, -0.1774]],

         [[-0.1172,  0.0829,  0.0053],
          [ 0.1272,  0.0293,  0.0718],
          [ 0.1122,  0.1669, -0.1550]],

         [[ 0.0498, -0.1540,  0.0426],
          [-0.1555,  0.1013,  0.1179],
          [ 0.0237, -0.0471, -0.1062]]],


        [[[ 0.0513,  0.1087, -0.1107],
          [-0.0433,  0.1283, -0.1350],
          [ 0.0202,  0.1978,  0.1332]],

         [[-0.1515,  0.0477, -0.1499],
          [-0.1733, -0.0325, -0.1541],
          [-0.1562, -0.1828,  0.0633]],

         [[ 0.1459, -0.0202,  0.1776],
          [ 0.1159,  0.0225,  0.0030],
          [-0.0716,  0.1007,  0.0697]]],


        ...,


        [[[ 0.2363, -0.0287,  0.0083],
          [ 0.1806, -0.1447,  0.0062],
          [-0.0706, -0.1338, -0.0683]],

         [[-0.0041, -0.0032, -0.1002],
          [-0.1543, -0.1778,  0.1390],
          [-0.0490,  0.2107,  0.1962]],

         [[-0.0546, -0.1017,  0.2319],
          [ 0.0135, -0.2267, -0.1001],
          [ 0.0418, -0.0457, -0.0259]]],


        [[[ 0.0603, -0.0775,  0.1241],
          [ 0.1794,  0.0990, -0.0132],
          [-0.1630, -0.0876, -0.0123]],

         [[ 0.0924,  0.0329, -0.1300],
          [ 0.0266, -0.0607, -0.2379],
          [ 0.0093,  0.1423, -0.0345]],

         [[-0.0704,  0.0265, -0.2154],
          [-0.0660,  0.0594,  0.0564],
          [ 0.1391,  0.0606,  0.0218]]],


        [[[-0.0133,  0.0290, -0.0138],
          [ 0.0424,  0.0555, -0.0354],
          [ 0.0636,  0.0678,  0.0245]],

         [[-0.0251, -0.0153, -0.0722],
          [ 0.0526, -0.0205, -0.0147],
          [-0.0814, -0.1060, -0.0456]],

         [[ 0.0942,  0.0519, -0.1144],
          [-0.0180, -0.1150, -0.0054],
          [ 0.0739,  0.0273, -0.1472]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 7.2690e-03,  6.8240e-03,  1.7818e-02],
          [ 5.9475e-03,  6.9994e-03,  1.4469e-02],
          [ 1.2012e-02,  1.1809e-02,  1.4224e-02]],

         [[ 2.7291e-02,  2.9410e-02,  4.2651e-02],
          [ 3.0191e-02,  3.0672e-02,  4.0577e-02],
          [ 3.5182e-02,  3.3519e-02,  3.9874e-02]],

         [[ 4.0381e-02,  4.0460e-02,  4.5572e-02],
          [ 4.1864e-02,  4.0522e-02,  4.4283e-02],
          [ 4.4755e-02,  4.2634e-02,  4.5876e-02]]],


        [[[ 8.2172e-03,  1.1171e-02,  1.1642e-02],
          [ 9.0588e-03,  1.3712e-02,  1.2050e-02],
          [ 1.2478e-02,  1.6408e-02,  1.8255e-02]],

         [[ 1.0330e-02,  1.3958e-02,  1.2917e-02],
          [ 1.1923e-02,  1.6175e-02,  1.2883e-02],
          [ 1.5672e-02,  1.7760e-02,  1.8134e-02]],

         [[ 5.4716e-03,  7.7582e-03,  4.7982e-03],
          [ 5.0361e-03,  7.8579e-03,  3.1599e-03],
          [ 6.2276e-03,  8.8432e-03,  8.9703e-03]]],


        [[[ 3.9773e-02,  4.4649e-02,  5.9786e-02],
          [ 3.7348e-02,  3.9784e-02,  5.4790e-02],
          [ 4.9946e-02,  4.2162e-02,  4.4543e-02]],

         [[ 3.8645e-03,  1.4221e-02,  3.9168e-02],
          [ 7.5414e-03,  1.1975e-02,  3.1906e-02],
          [ 2.7473e-02,  1.9571e-02,  2.1382e-02]],

         [[ 1.5773e-03,  1.1647e-02,  3.4003e-02],
          [ 4.6882e-03,  6.5498e-03,  2.1523e-02],
          [ 1.9991e-02,  9.9223e-03,  1.0945e-02]]],


        ...,


        [[[-1.3122e-02, -1.3363e-02, -1.3371e-02],
          [ 8.4192e-03,  8.9988e-03,  1.2380e-02],
          [-3.7456e-03, -3.4708e-03,  4.9452e-03]],

         [[-3.1139e-02, -3.0633e-02, -2.9885e-02],
          [-1.0499e-02, -8.0534e-03, -3.4924e-03],
          [-2.0931e-02, -1.8238e-02, -8.0620e-03]],

         [[-3.4040e-02, -3.1639e-02, -3.3284e-02],
          [-1.4349e-02, -1.0042e-02, -9.9461e-03],
          [-2.5532e-02, -2.1878e-02, -1.7127e-02]]],


        [[[ 2.9901e-02,  2.9753e-02,  2.5662e-02],
          [ 3.2080e-02,  3.2961e-02,  3.1730e-02],
          [ 2.0242e-02,  1.4914e-02,  1.6129e-02]],

         [[ 3.1689e-02,  2.9614e-02,  2.4591e-02],
          [ 3.1351e-02,  2.9877e-02,  2.8583e-02],
          [ 1.8877e-02,  1.1598e-02,  1.2424e-02]],

         [[ 1.7021e-02,  1.6965e-02,  1.1425e-02],
          [ 1.7319e-02,  1.8695e-02,  1.5852e-02],
          [ 8.4918e-03,  3.9613e-03,  4.1098e-03]]],


        [[[-1.8742e-04, -2.2935e-04, -2.3561e-04],
          [ 1.0432e-05, -3.9514e-05, -1.2641e-04],
          [ 1.7401e-04,  1.2373e-04, -4.2445e-05]],

         [[-3.5162e-05, -6.8789e-05, -9.5373e-05],
          [ 1.3471e-04,  6.2195e-05, -4.0737e-05],
          [ 2.5885e-04,  1.6521e-04, -6.7615e-06]],

         [[ 4.4894e-05,  3.9555e-05,  6.2992e-06],
          [ 1.5089e-04,  1.2095e-04,  3.6417e-05],
          [ 2.1175e-04,  1.7944e-04,  4.4821e-05]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2174]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 5 | Batch_idx: 0 |  Loss: (0.7613) | Acc: (75.00%) (96/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (0.7302) | Acc: (74.00%) (1046/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (0.7376) | Acc: (74.00%) (2004/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (0.7464) | Acc: (74.00%) (2940/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (0.7378) | Acc: (74.00%) (3916/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (0.7505) | Acc: (74.00%) (4840/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (0.7530) | Acc: (73.00%) (5776/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (0.7524) | Acc: (73.00%) (6717/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (0.7442) | Acc: (74.00%) (7703/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (0.7445) | Acc: (74.00%) (8649/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (0.7480) | Acc: (74.00%) (9582/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (0.7488) | Acc: (74.00%) (10520/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (0.7461) | Acc: (74.00%) (11480/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (0.7442) | Acc: (74.00%) (12452/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (0.7411) | Acc: (74.00%) (13414/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (0.7381) | Acc: (74.00%) (14402/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (0.7366) | Acc: (74.00%) (15363/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (0.7353) | Acc: (74.00%) (16330/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (0.7325) | Acc: (74.00%) (17322/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (0.7315) | Acc: (74.00%) (18269/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (0.7295) | Acc: (74.00%) (19239/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (0.7260) | Acc: (74.00%) (20233/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (0.7251) | Acc: (74.00%) (21198/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (0.7235) | Acc: (74.00%) (22167/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (0.7234) | Acc: (74.00%) (23124/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (0.7233) | Acc: (74.00%) (24079/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (0.7201) | Acc: (75.00%) (25073/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (0.7195) | Acc: (75.00%) (26041/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (0.7186) | Acc: (75.00%) (27014/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (0.7187) | Acc: (75.00%) (27977/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (0.7180) | Acc: (75.00%) (28943/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (0.7183) | Acc: (75.00%) (29921/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (0.7167) | Acc: (75.00%) (30903/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (0.7141) | Acc: (75.00%) (31903/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (0.7135) | Acc: (75.00%) (32873/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (0.7116) | Acc: (75.00%) (33851/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (0.7110) | Acc: (75.00%) (34821/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (0.7098) | Acc: (75.00%) (35815/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (0.7099) | Acc: (75.00%) (36780/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (0.7083) | Acc: (75.00%) (37744/50000)
# TEST : Loss: (0.9054) | Acc: (70.00%) (7088/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1147, -0.2098,  0.0963],
          [-0.0982,  0.1902,  0.1194],
          [ 0.0782, -0.0164, -0.1258]],

         [[-0.2043,  0.2082,  0.1660],
          [-0.0053,  0.2027,  0.0774],
          [ 0.2011, -0.1418,  0.1345]],

         [[-0.1505,  0.0245, -0.0308],
          [-0.1762, -0.0209, -0.0307],
          [-0.1466,  0.0160, -0.1025]]],


        [[[ 0.1180, -0.1617,  0.1104],
          [-0.0756, -0.1592,  0.0374],
          [ 0.1191,  0.0073, -0.1896]],

         [[-0.1255,  0.0726, -0.0035],
          [ 0.1043,  0.0238,  0.0742],
          [ 0.0996,  0.1624, -0.1711]],

         [[ 0.0421, -0.1589,  0.0448],
          [-0.1729,  0.1012,  0.1358],
          [ 0.0205, -0.0401, -0.1022]]],


        [[[ 0.0522,  0.1070, -0.1182],
          [-0.0395,  0.1272, -0.1391],
          [ 0.0166,  0.1981,  0.1402]],

         [[-0.1505,  0.0486, -0.1504],
          [-0.1727, -0.0380, -0.1584],
          [-0.1646, -0.1909,  0.0642]],

         [[ 0.1467, -0.0167,  0.1799],
          [ 0.1189,  0.0212,  0.0012],
          [-0.0802,  0.0908,  0.0658]]],


        ...,


        [[[ 0.2410, -0.0207,  0.0118],
          [ 0.1733, -0.1550,  0.0061],
          [-0.0811, -0.1355, -0.0794]],

         [[ 0.0023,  0.0086, -0.0917],
          [-0.1553, -0.1787,  0.1468],
          [-0.0512,  0.2198,  0.1922]],

         [[-0.0409, -0.0801,  0.2469],
          [ 0.0198, -0.2217, -0.0878],
          [ 0.0490, -0.0298, -0.0276]]],


        [[[ 0.0633, -0.0664,  0.1355],
          [ 0.1827,  0.1027, -0.0147],
          [-0.1690, -0.0905, -0.0141]],

         [[ 0.0909,  0.0348, -0.1280],
          [ 0.0324, -0.0569, -0.2414],
          [ 0.0152,  0.1499, -0.0282]],

         [[-0.0772,  0.0227, -0.2174],
          [-0.0647,  0.0596,  0.0488],
          [ 0.1449,  0.0701,  0.0276]]],


        [[[-0.0259,  0.0143, -0.0225],
          [ 0.0246,  0.0401, -0.0411],
          [ 0.0475,  0.0534,  0.0147]],

         [[-0.0295, -0.0208, -0.0716],
          [ 0.0392, -0.0242, -0.0206],
          [-0.0754, -0.0983, -0.0478]],

         [[ 0.0724,  0.0356, -0.1128],
          [-0.0261, -0.1116, -0.0166],
          [ 0.0552,  0.0135, -0.1438]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0055,  0.0129,  0.0168],
          [ 0.0049,  0.0082,  0.0160],
          [ 0.0020, -0.0050,  0.0061]],

         [[ 0.0178,  0.0212,  0.0233],
          [ 0.0093,  0.0036,  0.0108],
          [-0.0022, -0.0182, -0.0043]],

         [[ 0.0215,  0.0220,  0.0186],
          [ 0.0163,  0.0122,  0.0140],
          [ 0.0080, -0.0048,  0.0036]]],


        [[[ 0.0032,  0.0065,  0.0099],
          [-0.0007,  0.0011,  0.0077],
          [-0.0067, -0.0044,  0.0002]],

         [[ 0.0071,  0.0094,  0.0097],
          [ 0.0043,  0.0039,  0.0076],
          [-0.0015, -0.0007,  0.0025]],

         [[ 0.0049,  0.0049,  0.0059],
          [ 0.0016, -0.0013,  0.0030],
          [-0.0035, -0.0053, -0.0024]]],


        [[[-0.0214, -0.0317, -0.0370],
          [-0.0123, -0.0131, -0.0070],
          [-0.0418, -0.0352, -0.0183]],

         [[-0.0257, -0.0391, -0.0390],
          [-0.0200, -0.0234, -0.0201],
          [-0.0436, -0.0360, -0.0292]],

         [[-0.0325, -0.0374, -0.0318],
          [-0.0371, -0.0359, -0.0291],
          [-0.0581, -0.0464, -0.0406]]],


        ...,


        [[[ 0.0396,  0.0341,  0.0298],
          [ 0.0384,  0.0376,  0.0424],
          [ 0.0118,  0.0175,  0.0230]],

         [[ 0.0216,  0.0203,  0.0192],
          [ 0.0238,  0.0279,  0.0335],
          [ 0.0016,  0.0086,  0.0117]],

         [[ 0.0076,  0.0063,  0.0061],
          [ 0.0087,  0.0115,  0.0184],
          [-0.0090, -0.0022,  0.0039]]],


        [[[ 0.0018,  0.0024,  0.0147],
          [-0.0080, -0.0122,  0.0011],
          [-0.0249, -0.0347, -0.0233]],

         [[-0.0224, -0.0197, -0.0039],
          [-0.0251, -0.0241, -0.0052],
          [-0.0289, -0.0327, -0.0171]],

         [[-0.0403, -0.0364, -0.0177],
          [-0.0349, -0.0321, -0.0109],
          [-0.0314, -0.0342, -0.0183]]],


        [[[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2169]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 6 | Batch_idx: 0 |  Loss: (0.6084) | Acc: (81.00%) (104/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (0.6858) | Acc: (77.00%) (1089/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (0.8251) | Acc: (72.00%) (1939/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (0.8598) | Acc: (70.00%) (2806/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (0.8778) | Acc: (70.00%) (3691/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (0.8727) | Acc: (70.00%) (4589/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (0.8720) | Acc: (70.00%) (5493/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (0.8644) | Acc: (70.00%) (6416/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (0.8614) | Acc: (70.00%) (7324/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (0.8524) | Acc: (70.00%) (8249/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (0.8439) | Acc: (71.00%) (9194/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (0.8365) | Acc: (71.00%) (10132/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (0.8311) | Acc: (71.00%) (11075/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (0.8271) | Acc: (71.00%) (12024/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (0.8201) | Acc: (71.00%) (12981/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (0.8119) | Acc: (72.00%) (13945/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (0.8091) | Acc: (72.00%) (14866/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (0.8059) | Acc: (72.00%) (15816/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (0.8035) | Acc: (72.00%) (16767/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (0.7997) | Acc: (72.00%) (17718/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (0.7954) | Acc: (72.00%) (18685/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (0.7900) | Acc: (72.00%) (19660/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (0.7835) | Acc: (72.00%) (20641/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (0.7794) | Acc: (73.00%) (21623/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (0.7776) | Acc: (73.00%) (22575/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (0.7742) | Acc: (73.00%) (23536/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (0.7711) | Acc: (73.00%) (24523/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (0.7665) | Acc: (73.00%) (25520/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (0.7637) | Acc: (73.00%) (26502/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (0.7603) | Acc: (73.00%) (27495/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (0.7578) | Acc: (73.00%) (28487/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (0.7558) | Acc: (74.00%) (29465/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (0.7522) | Acc: (74.00%) (30465/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (0.7495) | Acc: (74.00%) (31439/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (0.7485) | Acc: (74.00%) (32392/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (0.7458) | Acc: (74.00%) (33399/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (0.7443) | Acc: (74.00%) (34379/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (0.7422) | Acc: (74.00%) (35388/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (0.7397) | Acc: (74.00%) (36386/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (0.7373) | Acc: (74.00%) (37345/50000)
# TEST : Loss: (0.6557) | Acc: (77.00%) (7777/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1151, -0.2106,  0.0946],
          [-0.0991,  0.1889,  0.1180],
          [ 0.0768, -0.0177, -0.1270]],

         [[-0.2036,  0.2079,  0.1651],
          [-0.0049,  0.2029,  0.0775],
          [ 0.2010, -0.1412,  0.1344]],

         [[-0.1502,  0.0242, -0.0311],
          [-0.1761, -0.0209, -0.0307],
          [-0.1469,  0.0157, -0.1026]]],


        [[[ 0.1157, -0.1634,  0.1080],
          [-0.0776, -0.1601,  0.0357],
          [ 0.1168,  0.0061, -0.1905]],

         [[-0.1277,  0.0697, -0.0057],
          [ 0.1007,  0.0220,  0.0723],
          [ 0.0965,  0.1603, -0.1720]],

         [[ 0.0399, -0.1598,  0.0436],
          [-0.1742,  0.1004,  0.1351],
          [ 0.0189, -0.0399, -0.1015]]],


        [[[ 0.0543,  0.1094, -0.1157],
          [-0.0376,  0.1292, -0.1375],
          [ 0.0196,  0.2010,  0.1429]],

         [[-0.1471,  0.0526, -0.1462],
          [-0.1694, -0.0343, -0.1551],
          [-0.1601, -0.1865,  0.0681]],

         [[ 0.1502, -0.0124,  0.1836],
          [ 0.1226,  0.0256,  0.0048],
          [-0.0753,  0.0955,  0.0701]]],


        ...,


        [[[ 0.2410, -0.0210,  0.0121],
          [ 0.1737, -0.1543,  0.0066],
          [-0.0779, -0.1318, -0.0763]],

         [[ 0.0033,  0.0085, -0.0905],
          [-0.1531, -0.1773,  0.1474],
          [-0.0477,  0.2227,  0.1950]],

         [[-0.0378, -0.0776,  0.2491],
          [ 0.0238, -0.2167, -0.0842],
          [ 0.0537, -0.0243, -0.0227]]],


        [[[ 0.0613, -0.0678,  0.1333],
          [ 0.1806,  0.1012, -0.0166],
          [-0.1708, -0.0916, -0.0156]],

         [[ 0.0886,  0.0327, -0.1305],
          [ 0.0301, -0.0587, -0.2438],
          [ 0.0125,  0.1478, -0.0305]],

         [[-0.0793,  0.0204, -0.2201],
          [-0.0671,  0.0572,  0.0453],
          [ 0.1417,  0.0676,  0.0247]]],


        [[[-0.0213,  0.0122, -0.0200],
          [ 0.0201,  0.0346, -0.0368],
          [ 0.0391,  0.0462,  0.0131]],

         [[-0.0248, -0.0174, -0.0612],
          [ 0.0329, -0.0204, -0.0178],
          [-0.0633, -0.0829, -0.0413]],

         [[ 0.0626,  0.0306, -0.0974],
          [-0.0226, -0.0961, -0.0144],
          [ 0.0475,  0.0116, -0.1247]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2360]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0093]], device='cuda:0')

Epoch: 7 | Batch_idx: 0 |  Loss: (0.5198) | Acc: (82.00%) (105/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (0.6725) | Acc: (76.00%) (1084/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (0.6569) | Acc: (77.00%) (2080/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (0.6511) | Acc: (77.00%) (3070/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (0.6531) | Acc: (77.00%) (4062/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (0.6574) | Acc: (77.00%) (5048/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (0.6525) | Acc: (77.00%) (6055/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (0.6521) | Acc: (77.00%) (7034/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (0.6512) | Acc: (77.00%) (8034/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (0.6550) | Acc: (77.00%) (9021/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (0.6553) | Acc: (77.00%) (10010/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (0.6537) | Acc: (77.00%) (11019/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (0.6525) | Acc: (77.00%) (12012/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (0.6536) | Acc: (77.00%) (13013/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (0.6561) | Acc: (77.00%) (13982/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (0.6569) | Acc: (77.00%) (14990/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (0.6578) | Acc: (77.00%) (15956/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (0.6596) | Acc: (77.00%) (16945/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (0.6579) | Acc: (77.00%) (17965/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (0.6590) | Acc: (77.00%) (18959/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (0.6597) | Acc: (77.00%) (19956/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (0.6603) | Acc: (77.00%) (20936/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (0.6595) | Acc: (77.00%) (21946/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (0.6577) | Acc: (77.00%) (22934/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (0.6592) | Acc: (77.00%) (23909/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (0.6590) | Acc: (77.00%) (24892/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (0.6589) | Acc: (77.00%) (25869/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (0.6592) | Acc: (77.00%) (26861/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (0.6592) | Acc: (77.00%) (27841/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (0.6590) | Acc: (77.00%) (28834/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (0.6592) | Acc: (77.00%) (29822/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (0.6580) | Acc: (77.00%) (30853/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (0.6582) | Acc: (77.00%) (31836/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (0.6582) | Acc: (77.00%) (32829/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (0.6590) | Acc: (77.00%) (33815/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (0.6589) | Acc: (77.00%) (34797/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (0.6598) | Acc: (77.00%) (35784/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (0.6584) | Acc: (77.00%) (36802/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (0.6585) | Acc: (77.00%) (37794/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (0.6576) | Acc: (77.00%) (38778/50000)
# TEST : Loss: (0.6418) | Acc: (77.00%) (7782/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1149, -0.2102,  0.0944],
          [-0.0989,  0.1886,  0.1178],
          [ 0.0766, -0.0177, -0.1267]],

         [[-0.2032,  0.2075,  0.1648],
          [-0.0049,  0.2025,  0.0774],
          [ 0.2006, -0.1410,  0.1341]],

         [[-0.1499,  0.0242, -0.0311],
          [-0.1758, -0.0208, -0.0307],
          [-0.1466,  0.0157, -0.1024]]],


        [[[ 0.1152, -0.1627,  0.1076],
          [-0.0772, -0.1593,  0.0356],
          [ 0.1162,  0.0060, -0.1896]],

         [[-0.1271,  0.0693, -0.0057],
          [ 0.1002,  0.0219,  0.0720],
          [ 0.0960,  0.1595, -0.1712]],

         [[ 0.0397, -0.1590,  0.0434],
          [-0.1734,  0.0999,  0.1344],
          [ 0.0188, -0.0397, -0.1010]]],


        [[[ 0.0543,  0.1093, -0.1156],
          [-0.0375,  0.1291, -0.1373],
          [ 0.0196,  0.2008,  0.1427]],

         [[-0.1469,  0.0526, -0.1460],
          [-0.1691, -0.0342, -0.1549],
          [-0.1599, -0.1862,  0.0680]],

         [[ 0.1500, -0.0124,  0.1834],
          [ 0.1225,  0.0255,  0.0048],
          [-0.0752,  0.0954,  0.0701]]],


        ...,


        [[[ 0.2402, -0.0209,  0.0121],
          [ 0.1731, -0.1536,  0.0066],
          [-0.0776, -0.1313, -0.0760]],

         [[ 0.0033,  0.0084, -0.0901],
          [-0.1524, -0.1764,  0.1469],
          [-0.0475,  0.2217,  0.1943]],

         [[-0.0376, -0.0771,  0.2480],
          [ 0.0237, -0.2151, -0.0837],
          [ 0.0534, -0.0242, -0.0226]]],


        [[[ 0.0612, -0.0677,  0.1331],
          [ 0.1803,  0.1011, -0.0165],
          [-0.1704, -0.0914, -0.0156]],

         [[ 0.0884,  0.0326, -0.1303],
          [ 0.0301, -0.0585, -0.2433],
          [ 0.0125,  0.1475, -0.0305]],

         [[-0.0792,  0.0203, -0.2197],
          [-0.0670,  0.0571,  0.0452],
          [ 0.1414,  0.0674,  0.0246]]],


        [[[-0.0166,  0.0101, -0.0173],
          [ 0.0157,  0.0288, -0.0320],
          [ 0.0309,  0.0386,  0.0114]],

         [[-0.0199, -0.0140, -0.0505],
          [ 0.0265, -0.0165, -0.0148],
          [-0.0509, -0.0672, -0.0345]],

         [[ 0.0524,  0.0254, -0.0813],
          [-0.0189, -0.0799, -0.0121],
          [ 0.0395,  0.0096, -0.1047]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3082]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0519]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 8 | Batch_idx: 0 |  Loss: (0.5293) | Acc: (82.00%) (105/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (0.7539) | Acc: (73.00%) (1036/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (0.7843) | Acc: (72.00%) (1958/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (0.7848) | Acc: (72.00%) (2889/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (0.7940) | Acc: (72.00%) (3802/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (0.8004) | Acc: (72.00%) (4737/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (0.8011) | Acc: (72.00%) (5667/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (0.8037) | Acc: (72.00%) (6587/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (0.7956) | Acc: (72.00%) (7529/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (0.7911) | Acc: (72.00%) (8489/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (0.7873) | Acc: (72.00%) (9422/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (0.7873) | Acc: (72.00%) (10348/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (0.7819) | Acc: (73.00%) (11309/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (0.7762) | Acc: (73.00%) (12271/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (0.7708) | Acc: (73.00%) (13243/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (0.7655) | Acc: (73.00%) (14234/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (0.7589) | Acc: (73.00%) (15226/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (0.7535) | Acc: (74.00%) (16221/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (0.7520) | Acc: (74.00%) (17187/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (0.7482) | Acc: (74.00%) (18136/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (0.7447) | Acc: (74.00%) (19131/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (0.7401) | Acc: (74.00%) (20125/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (0.7380) | Acc: (74.00%) (21102/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (0.7361) | Acc: (74.00%) (22070/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (0.7327) | Acc: (74.00%) (23060/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (0.7287) | Acc: (74.00%) (24071/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (0.7268) | Acc: (75.00%) (25067/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (0.7215) | Acc: (75.00%) (26103/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (0.7199) | Acc: (75.00%) (27088/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (0.7172) | Acc: (75.00%) (28095/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (0.7141) | Acc: (75.00%) (29101/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (0.7112) | Acc: (75.00%) (30101/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (0.7082) | Acc: (75.00%) (31097/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (0.7055) | Acc: (75.00%) (32092/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (0.7046) | Acc: (75.00%) (33074/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (0.7036) | Acc: (75.00%) (34066/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (0.7016) | Acc: (75.00%) (35065/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (0.6992) | Acc: (75.00%) (36078/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (0.6958) | Acc: (76.00%) (37099/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (0.6942) | Acc: (76.00%) (38066/50000)
# TEST : Loss: (0.8127) | Acc: (73.00%) (7349/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1102, -0.2091,  0.0935],
          [-0.0880,  0.1970,  0.1191],
          [ 0.0924, -0.0152, -0.1244]],

         [[-0.2043,  0.2073,  0.1641],
          [-0.0036,  0.2052,  0.0753],
          [ 0.2062, -0.1473,  0.1305]],

         [[-0.1544,  0.0173, -0.0376],
          [-0.1824, -0.0265, -0.0384],
          [-0.1470,  0.0079, -0.1007]]],


        [[[ 0.1218, -0.1558,  0.1022],
          [-0.0621, -0.1459,  0.0369],
          [ 0.1334,  0.0148, -0.1930]],

         [[-0.1214,  0.0659, -0.0199],
          [ 0.1131,  0.0281,  0.0648],
          [ 0.1102,  0.1623, -0.1815]],

         [[ 0.0383, -0.1663,  0.0312],
          [-0.1584,  0.1084,  0.1378],
          [ 0.0405, -0.0259, -0.0950]]],


        [[[ 0.0437,  0.1012, -0.1185],
          [-0.0385,  0.1237, -0.1402],
          [ 0.0167,  0.2008,  0.1552]],

         [[-0.1514,  0.0448, -0.1487],
          [-0.1733, -0.0487, -0.1635],
          [-0.1709, -0.2016,  0.0696]],

         [[ 0.1517, -0.0134,  0.1807],
          [ 0.1260,  0.0210, -0.0006],
          [-0.0820,  0.0853,  0.0698]]],


        ...,


        [[[ 0.2516, -0.0023,  0.0116],
          [ 0.1802, -0.1597,  0.0002],
          [-0.0852, -0.1388, -0.0954]],

         [[ 0.0082,  0.0197, -0.0919],
          [-0.1482, -0.1803,  0.1474],
          [-0.0542,  0.2255,  0.1898]],

         [[-0.0302, -0.0663,  0.2487],
          [ 0.0270, -0.2272, -0.0812],
          [ 0.0432, -0.0306, -0.0307]]],


        [[[ 0.0721, -0.0544,  0.1462],
          [ 0.1846,  0.1042, -0.0194],
          [-0.1803, -0.0995, -0.0268]],

         [[ 0.0977,  0.0402, -0.1230],
          [ 0.0418, -0.0487, -0.2410],
          [ 0.0204,  0.1587, -0.0248]],

         [[-0.0777,  0.0206, -0.2194],
          [-0.0606,  0.0621,  0.0425],
          [ 0.1498,  0.0791,  0.0287]]],


        [[[-0.0135,  0.0071, -0.0151],
          [ 0.0105,  0.0223, -0.0277],
          [ 0.0219,  0.0303,  0.0091]],

         [[-0.0154, -0.0108, -0.0400],
          [ 0.0202, -0.0129, -0.0121],
          [-0.0391, -0.0521, -0.0278]],

         [[ 0.0419,  0.0201, -0.0653],
          [-0.0153, -0.0640, -0.0099],
          [ 0.0314,  0.0075, -0.0846]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-1.3713e-02,  5.2912e-03,  1.0454e-02],
          [-1.7888e-02, -4.9272e-03,  4.4359e-03],
          [-1.4395e-02, -9.3440e-03, -4.6803e-03]],

         [[-2.4259e-03,  1.4499e-02,  1.8871e-02],
          [-3.8334e-03,  6.9140e-03,  1.4395e-02],
          [ 4.3863e-03,  5.1428e-03,  7.1821e-03]],

         [[ 1.1557e-02,  2.4361e-02,  2.8549e-02],
          [ 1.4568e-02,  2.1462e-02,  2.8222e-02],
          [ 2.2073e-02,  2.1070e-02,  2.2885e-02]]],


        [[[ 6.4702e-03,  5.1428e-03,  6.9476e-03],
          [ 3.9842e-03,  3.3003e-03,  3.9231e-03],
          [ 4.1484e-03,  4.0092e-03,  3.4903e-03]],

         [[ 6.1663e-03,  4.7901e-03,  6.1682e-03],
          [ 3.2435e-03,  3.1834e-03,  3.8072e-03],
          [ 3.9710e-03,  4.6967e-03,  4.0260e-03]],

         [[ 8.3492e-03,  6.5549e-03,  6.4605e-03],
          [ 4.8077e-03,  3.9803e-03,  3.2369e-03],
          [ 4.4548e-03,  4.3233e-03,  2.6339e-03]]],


        [[[-1.0509e-02,  7.7524e-03,  3.3123e-02],
          [-1.1983e-02,  2.9635e-02,  5.2461e-02],
          [-2.2887e-02,  1.5437e-02,  3.6199e-02]],

         [[-5.4990e-02, -4.4224e-02, -2.2370e-02],
          [-6.6084e-02, -2.9712e-02, -1.1437e-02],
          [-8.1737e-02, -4.6865e-02, -2.8866e-02]],

         [[-1.0775e-01, -1.0331e-01, -8.6218e-02],
          [-1.0091e-01, -7.7362e-02, -6.4494e-02],
          [-1.0561e-01, -7.9784e-02, -6.8062e-02]]],


        ...,


        [[[ 4.9455e-03,  1.9038e-02,  2.6099e-02],
          [-8.5860e-05,  1.2889e-02,  1.7980e-02],
          [ 3.0335e-03,  1.1064e-02,  1.1711e-02]],

         [[ 6.3808e-03,  2.3084e-02,  3.0218e-02],
          [ 2.5629e-04,  1.6318e-02,  2.2300e-02],
          [ 3.4406e-03,  1.4746e-02,  1.7444e-02]],

         [[ 7.3872e-03,  2.4204e-02,  3.0767e-02],
          [ 1.5648e-03,  1.7768e-02,  2.3603e-02],
          [ 4.5278e-03,  1.6558e-02,  2.0147e-02]]],


        [[[ 7.2835e-02,  6.3499e-02,  6.7028e-02],
          [ 6.3760e-02,  4.3843e-02,  4.1726e-02],
          [ 5.4662e-02,  4.0600e-02,  3.2402e-02]],

         [[ 8.8008e-02,  8.2686e-02,  8.5363e-02],
          [ 7.5476e-02,  5.7758e-02,  5.5913e-02],
          [ 6.3533e-02,  5.2404e-02,  4.6131e-02]],

         [[ 8.0237e-02,  7.7659e-02,  8.0273e-02],
          [ 6.1973e-02,  4.8711e-02,  4.8288e-02],
          [ 4.7188e-02,  3.8887e-02,  3.4158e-02]]],


        [[[ 1.4849e-06, -3.4869e-08,  3.5574e-08],
          [ 1.5674e-06,  5.6112e-08,  1.2664e-07],
          [ 1.4843e-06, -1.9158e-08,  4.7164e-08]],

         [[ 1.6158e-06,  4.6115e-08,  1.1828e-07],
          [ 1.6959e-06,  1.4141e-07,  2.1287e-07],
          [ 1.6164e-06,  6.3544e-08,  1.3059e-07]],

         [[ 1.5081e-06,  1.2257e-07,  1.9009e-07],
          [ 1.5994e-06,  2.1044e-07,  2.7736e-07],
          [ 1.5430e-06,  1.3842e-07,  2.0174e-07]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3114]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 9 | Batch_idx: 0 |  Loss: (0.3924) | Acc: (85.00%) (109/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (0.5901) | Acc: (79.00%) (1118/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (0.5946) | Acc: (80.00%) (2153/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (0.6019) | Acc: (80.00%) (3183/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (0.5996) | Acc: (80.00%) (4204/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (0.5902) | Acc: (80.00%) (5239/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (0.5898) | Acc: (80.00%) (6262/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (0.5922) | Acc: (79.00%) (7261/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (0.5925) | Acc: (79.00%) (8271/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (0.5947) | Acc: (79.00%) (9274/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (0.5944) | Acc: (79.00%) (10304/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (0.5929) | Acc: (79.00%) (11334/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (0.5916) | Acc: (79.00%) (12349/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (0.5920) | Acc: (79.00%) (13351/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (0.5932) | Acc: (79.00%) (14348/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (0.5906) | Acc: (79.00%) (15394/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (0.5853) | Acc: (79.00%) (16465/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (0.5848) | Acc: (79.00%) (17492/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (0.5840) | Acc: (79.00%) (18523/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (0.5797) | Acc: (80.00%) (19584/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (0.5807) | Acc: (80.00%) (20585/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (0.5822) | Acc: (79.00%) (21598/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (0.5830) | Acc: (79.00%) (22624/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (0.5802) | Acc: (80.00%) (23668/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (0.5792) | Acc: (80.00%) (24717/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (0.5791) | Acc: (80.00%) (25742/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (0.5783) | Acc: (80.00%) (26767/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (0.5766) | Acc: (80.00%) (27808/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (0.5749) | Acc: (80.00%) (28858/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (0.5723) | Acc: (80.00%) (29916/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (0.5715) | Acc: (80.00%) (30960/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (0.5695) | Acc: (80.00%) (32033/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (0.5686) | Acc: (80.00%) (33065/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (0.5669) | Acc: (80.00%) (34136/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (0.5669) | Acc: (80.00%) (35174/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (0.5663) | Acc: (80.00%) (36213/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (0.5650) | Acc: (80.00%) (37274/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (0.5646) | Acc: (80.00%) (38330/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (0.5657) | Acc: (80.00%) (39348/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (0.5652) | Acc: (80.00%) (40358/50000)
# TEST : Loss: (0.6250) | Acc: (79.00%) (7940/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1115, -0.2103,  0.0949],
          [-0.0870,  0.2044,  0.1280],
          [ 0.0960, -0.0078, -0.1149]],

         [[-0.2076,  0.2056,  0.1684],
          [-0.0075,  0.2096,  0.0842],
          [ 0.2028, -0.1470,  0.1353]],

         [[-0.1535,  0.0152, -0.0348],
          [-0.1871, -0.0259, -0.0348],
          [-0.1492,  0.0100, -0.0937]]],


        [[[ 0.1245, -0.1528,  0.1138],
          [-0.0584, -0.1387,  0.0478],
          [ 0.1342,  0.0066, -0.1963]],

         [[-0.1251,  0.0576, -0.0200],
          [ 0.1131,  0.0311,  0.0667],
          [ 0.1065,  0.1500, -0.1912]],

         [[ 0.0328, -0.1743,  0.0358],
          [-0.1605,  0.1098,  0.1450],
          [ 0.0360, -0.0344, -0.0945]]],


        [[[ 0.0406,  0.1043, -0.1130],
          [-0.0371,  0.1232, -0.1438],
          [ 0.0188,  0.2044,  0.1625]],

         [[-0.1637,  0.0395, -0.1465],
          [-0.1824, -0.0602, -0.1737],
          [-0.1768, -0.2077,  0.0686]],

         [[ 0.1451, -0.0109,  0.1862],
          [ 0.1281,  0.0227, -0.0016],
          [-0.0804,  0.0873,  0.0731]]],


        ...,


        [[[ 0.2487, -0.0006,  0.0123],
          [ 0.1789, -0.1678, -0.0008],
          [-0.0791, -0.1325, -0.0894]],

         [[-0.0020,  0.0144, -0.0987],
          [-0.1514, -0.1874,  0.1459],
          [-0.0420,  0.2423,  0.2039]],

         [[-0.0301, -0.0624,  0.2447],
          [ 0.0294, -0.2353, -0.0833],
          [ 0.0535, -0.0217, -0.0252]]],


        [[[ 0.0701, -0.0475,  0.1538],
          [ 0.1885,  0.1100, -0.0217],
          [-0.1911, -0.1085, -0.0388]],

         [[ 0.0848,  0.0328, -0.1273],
          [ 0.0374, -0.0514, -0.2506],
          [ 0.0087,  0.1521, -0.0339]],

         [[-0.0869,  0.0181, -0.2190],
          [-0.0569,  0.0677,  0.0395],
          [ 0.1477,  0.0810,  0.0258]]],


        [[[-0.0116,  0.0031, -0.0140],
          [ 0.0049,  0.0148, -0.0243],
          [ 0.0132,  0.0211,  0.0056]],

         [[-0.0108, -0.0079, -0.0300],
          [ 0.0148, -0.0095, -0.0094],
          [-0.0279, -0.0381, -0.0214]],

         [[ 0.0322,  0.0151, -0.0500],
          [-0.0116, -0.0488, -0.0080],
          [ 0.0239,  0.0055, -0.0652]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0165, -0.0188, -0.0219],
          [-0.0046, -0.0140, -0.0123],
          [-0.0107, -0.0165, -0.0177]],

         [[-0.0194, -0.0272, -0.0275],
          [-0.0106, -0.0207, -0.0212],
          [-0.0153, -0.0210, -0.0247]],

         [[-0.0231, -0.0300, -0.0318],
          [-0.0166, -0.0259, -0.0283],
          [-0.0198, -0.0264, -0.0318]]],


        [[[-0.0030,  0.0008,  0.0003],
          [-0.0028, -0.0023, -0.0061],
          [ 0.0002, -0.0011, -0.0038]],

         [[-0.0051, -0.0018, -0.0024],
          [-0.0055, -0.0050, -0.0061],
          [-0.0026, -0.0022, -0.0036]],

         [[-0.0058, -0.0042, -0.0043],
          [-0.0064, -0.0070, -0.0073],
          [-0.0042, -0.0041, -0.0046]]],


        [[[-0.0533, -0.0264, -0.0285],
          [-0.0496, -0.0263, -0.0115],
          [-0.0299, -0.0181, -0.0153]],

         [[-0.0185,  0.0007, -0.0079],
          [-0.0130,  0.0046,  0.0116],
          [ 0.0033,  0.0124,  0.0122]],

         [[-0.0006,  0.0186,  0.0100],
          [ 0.0055,  0.0256,  0.0264],
          [ 0.0182,  0.0310,  0.0289]]],


        ...,


        [[[-0.0262, -0.0258, -0.0384],
          [-0.0322, -0.0242, -0.0317],
          [-0.0300, -0.0208, -0.0173]],

         [[-0.0193, -0.0218, -0.0309],
          [-0.0279, -0.0227, -0.0248],
          [-0.0299, -0.0198, -0.0138]],

         [[-0.0217, -0.0216, -0.0271],
          [-0.0267, -0.0214, -0.0221],
          [-0.0288, -0.0196, -0.0147]]],


        [[[ 0.0573,  0.0602,  0.0692],
          [ 0.0477,  0.0564,  0.0564],
          [ 0.0275,  0.0463,  0.0405]],

         [[ 0.0559,  0.0610,  0.0647],
          [ 0.0560,  0.0592,  0.0504],
          [ 0.0351,  0.0434,  0.0331]],

         [[ 0.0516,  0.0540,  0.0604],
          [ 0.0489,  0.0547,  0.0511],
          [ 0.0310,  0.0426,  0.0367]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3105]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 10 | Batch_idx: 0 |  Loss: (0.5683) | Acc: (78.00%) (100/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (0.5779) | Acc: (79.00%) (1124/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (0.6456) | Acc: (77.00%) (2089/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (0.6928) | Acc: (76.00%) (3025/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (0.7095) | Acc: (75.00%) (3972/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (0.7154) | Acc: (75.00%) (4923/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (0.7122) | Acc: (75.00%) (5889/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (0.7102) | Acc: (75.00%) (6864/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (0.7001) | Acc: (75.00%) (7874/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (0.6884) | Acc: (76.00%) (8904/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (0.6806) | Acc: (76.00%) (9914/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (0.6781) | Acc: (76.00%) (10896/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (0.6734) | Acc: (76.00%) (11910/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (0.6685) | Acc: (77.00%) (12921/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (0.6657) | Acc: (77.00%) (13941/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (0.6617) | Acc: (77.00%) (14966/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (0.6583) | Acc: (77.00%) (15991/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (0.6549) | Acc: (77.00%) (16999/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (0.6509) | Acc: (77.00%) (18020/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (0.6464) | Acc: (78.00%) (19073/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (0.6450) | Acc: (78.00%) (20084/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (0.6413) | Acc: (78.00%) (21108/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (0.6408) | Acc: (78.00%) (22114/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (0.6403) | Acc: (78.00%) (23127/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (0.6384) | Acc: (78.00%) (24149/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (0.6353) | Acc: (78.00%) (25179/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (0.6337) | Acc: (78.00%) (26201/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (0.6312) | Acc: (78.00%) (27254/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (0.6301) | Acc: (78.00%) (28261/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (0.6270) | Acc: (78.00%) (29315/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (0.6273) | Acc: (78.00%) (30321/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (0.6257) | Acc: (78.00%) (31336/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (0.6237) | Acc: (78.00%) (32378/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (0.6225) | Acc: (78.00%) (33392/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (0.6213) | Acc: (78.00%) (34414/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (0.6198) | Acc: (78.00%) (35463/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (0.6177) | Acc: (79.00%) (36514/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (0.6160) | Acc: (79.00%) (37547/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (0.6136) | Acc: (79.00%) (38600/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (0.6122) | Acc: (79.00%) (39604/50000)
# TEST : Loss: (0.5557) | Acc: (81.00%) (8120/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1085, -0.2066,  0.0977],
          [-0.0852,  0.2064,  0.1298],
          [ 0.0974, -0.0059, -0.1128]],

         [[-0.2044,  0.2089,  0.1710],
          [-0.0057,  0.2117,  0.0862],
          [ 0.2042, -0.1448,  0.1370]],

         [[-0.1500,  0.0188, -0.0320],
          [-0.1848, -0.0234, -0.0326],
          [-0.1471,  0.0117, -0.0914]]],


        [[[ 0.1222, -0.1526,  0.1132],
          [-0.0595, -0.1377,  0.0485],
          [ 0.1319,  0.0067, -0.1947]],

         [[-0.1258,  0.0568, -0.0194],
          [ 0.1111,  0.0314,  0.0673],
          [ 0.1044,  0.1492, -0.1900]],

         [[ 0.0312, -0.1736,  0.0361],
          [-0.1608,  0.1098,  0.1455],
          [ 0.0342, -0.0338, -0.0934]]],


        [[[ 0.0412,  0.1042, -0.1125],
          [-0.0366,  0.1232, -0.1435],
          [ 0.0183,  0.2039,  0.1627]],

         [[-0.1642,  0.0383, -0.1473],
          [-0.1830, -0.0612, -0.1746],
          [-0.1781, -0.2089,  0.0678]],

         [[ 0.1436, -0.0127,  0.1842],
          [ 0.1267,  0.0210, -0.0032],
          [-0.0822,  0.0854,  0.0717]]],


        ...,


        [[[ 0.2477, -0.0004,  0.0137],
          [ 0.1783, -0.1680, -0.0009],
          [-0.0790, -0.1332, -0.0900]],

         [[-0.0025,  0.0145, -0.0972],
          [-0.1511, -0.1875,  0.1449],
          [-0.0419,  0.2402,  0.2018]],

         [[-0.0311, -0.0629,  0.2444],
          [ 0.0283, -0.2362, -0.0844],
          [ 0.0522, -0.0244, -0.0280]]],


        [[[ 0.0684, -0.0485,  0.1518],
          [ 0.1874,  0.1085, -0.0232],
          [-0.1916, -0.1100, -0.0403]],

         [[ 0.0834,  0.0319, -0.1283],
          [ 0.0367, -0.0523, -0.2509],
          [ 0.0083,  0.1510, -0.0345]],

         [[-0.0888,  0.0164, -0.2208],
          [-0.0581,  0.0660,  0.0377],
          [ 0.1463,  0.0795,  0.0244]]],


        [[[-0.0074,  0.0022, -0.0107],
          [ 0.0031,  0.0107, -0.0188],
          [ 0.0085,  0.0152,  0.0044]],

         [[-0.0072, -0.0053, -0.0211],
          [ 0.0100, -0.0065, -0.0067],
          [-0.0187, -0.0259, -0.0154]],

         [[ 0.0232,  0.0108, -0.0359],
          [-0.0083, -0.0348, -0.0058],
          [ 0.0170,  0.0039, -0.0473]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3712]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0102]], device='cuda:0')

Epoch: 11 | Batch_idx: 0 |  Loss: (0.5515) | Acc: (80.00%) (103/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (0.5677) | Acc: (80.00%) (1128/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (0.5775) | Acc: (80.00%) (2168/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (0.5698) | Acc: (80.00%) (3202/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (0.5636) | Acc: (81.00%) (4251/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (0.5606) | Acc: (81.00%) (5296/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (0.5594) | Acc: (81.00%) (6337/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (0.5592) | Acc: (81.00%) (7376/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (0.5535) | Acc: (81.00%) (8420/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (0.5471) | Acc: (81.00%) (9493/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (0.5460) | Acc: (81.00%) (10546/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (0.5465) | Acc: (81.00%) (11589/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (0.5442) | Acc: (81.00%) (12649/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (0.5436) | Acc: (81.00%) (13687/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (0.5413) | Acc: (81.00%) (14739/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (0.5414) | Acc: (81.00%) (15785/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (0.5421) | Acc: (81.00%) (16809/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (0.5410) | Acc: (81.00%) (17873/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (0.5407) | Acc: (81.00%) (18922/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (0.5422) | Acc: (81.00%) (19950/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (0.5424) | Acc: (81.00%) (20983/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (0.5429) | Acc: (81.00%) (22023/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (0.5419) | Acc: (81.00%) (23078/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (0.5408) | Acc: (81.00%) (24129/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (0.5395) | Acc: (81.00%) (25191/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (0.5402) | Acc: (81.00%) (26223/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (0.5399) | Acc: (81.00%) (27266/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (0.5400) | Acc: (81.00%) (28323/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (0.5400) | Acc: (81.00%) (29356/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (0.5399) | Acc: (81.00%) (30404/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (0.5407) | Acc: (81.00%) (31449/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (0.5408) | Acc: (81.00%) (32491/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (0.5411) | Acc: (81.00%) (33538/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (0.5404) | Acc: (81.00%) (34591/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (0.5405) | Acc: (81.00%) (35634/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (0.5419) | Acc: (81.00%) (36655/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (0.5402) | Acc: (81.00%) (37728/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (0.5394) | Acc: (81.00%) (38793/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (0.5388) | Acc: (81.00%) (39864/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (0.5373) | Acc: (81.00%) (40889/50000)
# TEST : Loss: (0.5264) | Acc: (82.00%) (8232/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1083, -0.2061,  0.0975],
          [-0.0850,  0.2059,  0.1295],
          [ 0.0972, -0.0059, -0.1125]],

         [[-0.2040,  0.2084,  0.1706],
          [-0.0057,  0.2112,  0.0860],
          [ 0.2037, -0.1444,  0.1367]],

         [[-0.1496,  0.0187, -0.0319],
          [-0.1843, -0.0234, -0.0325],
          [-0.1467,  0.0117, -0.0912]]],


        [[[ 0.1213, -0.1516,  0.1125],
          [-0.0591, -0.1368,  0.0482],
          [ 0.1310,  0.0067, -0.1933]],

         [[-0.1249,  0.0564, -0.0193],
          [ 0.1103,  0.0312,  0.0668],
          [ 0.1036,  0.1481, -0.1887]],

         [[ 0.0310, -0.1723,  0.0358],
          [-0.1595,  0.1090,  0.1443],
          [ 0.0340, -0.0335, -0.0927]]],


        [[[ 0.0412,  0.1041, -0.1124],
          [-0.0366,  0.1230, -0.1433],
          [ 0.0182,  0.2036,  0.1625]],

         [[-0.1640,  0.0382, -0.1471],
          [-0.1828, -0.0612, -0.1744],
          [-0.1779, -0.2086,  0.0678]],

         [[ 0.1434, -0.0127,  0.1840],
          [ 0.1265,  0.0210, -0.0032],
          [-0.0821,  0.0853,  0.0717]]],


        ...,


        [[[ 0.2468, -0.0004,  0.0136],
          [ 0.1776, -0.1674, -0.0009],
          [-0.0787, -0.1328, -0.0897]],

         [[-0.0025,  0.0144, -0.0968],
          [-0.1505, -0.1867,  0.1444],
          [-0.0417,  0.2392,  0.2011]],

         [[-0.0310, -0.0626,  0.2434],
          [ 0.0282, -0.2350, -0.0840],
          [ 0.0519, -0.0243, -0.0278]]],


        [[[ 0.0683, -0.0484,  0.1515],
          [ 0.1871,  0.1083, -0.0232],
          [-0.1912, -0.1097, -0.0402]],

         [[ 0.0833,  0.0319, -0.1280],
          [ 0.0366, -0.0522, -0.2504],
          [ 0.0083,  0.1507, -0.0344]],

         [[-0.0886,  0.0164, -0.2204],
          [-0.0580,  0.0658,  0.0376],
          [ 0.1460,  0.0793,  0.0244]]],


        [[[-0.0042,  0.0014, -0.0077],
          [ 0.0018,  0.0071, -0.0138],
          [ 0.0050,  0.0102,  0.0032]],

         [[-0.0045, -0.0032, -0.0137],
          [ 0.0061, -0.0040, -0.0045],
          [-0.0115, -0.0162, -0.0103]],

         [[ 0.0155,  0.0071, -0.0239],
          [-0.0056, -0.0230, -0.0039],
          [ 0.0112,  0.0026, -0.0319]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3911]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0296]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 12 | Batch_idx: 0 |  Loss: (0.5959) | Acc: (75.00%) (97/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.6393) | Acc: (77.00%) (1098/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.6412) | Acc: (77.00%) (2094/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.6671) | Acc: (77.00%) (3068/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.6648) | Acc: (77.00%) (4055/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.6662) | Acc: (77.00%) (5045/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.6676) | Acc: (77.00%) (6044/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.6656) | Acc: (77.00%) (7048/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.6558) | Acc: (77.00%) (8070/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.6529) | Acc: (77.00%) (9065/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.6526) | Acc: (77.00%) (10074/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.6447) | Acc: (78.00%) (11110/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.6414) | Acc: (78.00%) (12124/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.6391) | Acc: (78.00%) (13133/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.6333) | Acc: (78.00%) (14162/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.6343) | Acc: (78.00%) (15172/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.6323) | Acc: (78.00%) (16189/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.6331) | Acc: (78.00%) (17185/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.6328) | Acc: (78.00%) (18197/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.6307) | Acc: (78.00%) (19211/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.6286) | Acc: (78.00%) (20237/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.6237) | Acc: (78.00%) (21301/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.6220) | Acc: (78.00%) (22328/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.6193) | Acc: (78.00%) (23346/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.6155) | Acc: (79.00%) (24390/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.6138) | Acc: (79.00%) (25413/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.6108) | Acc: (79.00%) (26444/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.6068) | Acc: (79.00%) (27500/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.6034) | Acc: (79.00%) (28556/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.6021) | Acc: (79.00%) (29587/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.6003) | Acc: (79.00%) (30634/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.5989) | Acc: (79.00%) (31654/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.5979) | Acc: (79.00%) (32698/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.5961) | Acc: (79.00%) (33746/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.5957) | Acc: (79.00%) (34769/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.5938) | Acc: (79.00%) (35817/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.5926) | Acc: (79.00%) (36854/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.5900) | Acc: (79.00%) (37920/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.5871) | Acc: (79.00%) (38980/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.5847) | Acc: (79.00%) (39998/50000)
# TEST : Loss: (0.5221) | Acc: (82.00%) (8239/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1151, -0.2094,  0.0931],
          [-0.0900,  0.2088,  0.1310],
          [ 0.0922, -0.0120, -0.1159]],

         [[-0.2087,  0.2097,  0.1714],
          [-0.0106,  0.2145,  0.0897],
          [ 0.1988, -0.1515,  0.1300]],

         [[-0.1513,  0.0195, -0.0319],
          [-0.1901, -0.0263, -0.0343],
          [-0.1532,  0.0006, -0.1012]]],


        [[[ 0.1093, -0.1687,  0.1045],
          [-0.0642, -0.1359,  0.0520],
          [ 0.1381,  0.0137, -0.1978]],

         [[-0.1427,  0.0373, -0.0320],
          [ 0.1043,  0.0341,  0.0676],
          [ 0.1102,  0.1548, -0.1995]],

         [[ 0.0220, -0.1749,  0.0377],
          [-0.1588,  0.1154,  0.1519],
          [ 0.0384, -0.0277, -0.0970]]],


        [[[ 0.0417,  0.1057, -0.1092],
          [-0.0225,  0.1340, -0.1359],
          [ 0.0290,  0.2152,  0.1750]],

         [[-0.1676,  0.0348, -0.1470],
          [-0.1789, -0.0639, -0.1754],
          [-0.1764, -0.2125,  0.0690]],

         [[ 0.1406, -0.0119,  0.1872],
          [ 0.1331,  0.0259,  0.0022],
          [-0.0781,  0.0881,  0.0774]]],


        ...,


        [[[ 0.2460, -0.0004,  0.0165],
          [ 0.1792, -0.1820, -0.0069],
          [-0.0878, -0.1428, -0.0970]],

         [[-0.0112,  0.0107, -0.0929],
          [-0.1473, -0.1944,  0.1458],
          [-0.0402,  0.2439,  0.2070]],

         [[-0.0386, -0.0626,  0.2491],
          [ 0.0301, -0.2411, -0.0846],
          [ 0.0520, -0.0272, -0.0299]]],


        [[[ 0.0692, -0.0409,  0.1634],
          [ 0.1907,  0.1170, -0.0122],
          [-0.1892, -0.1056, -0.0374]],

         [[ 0.0738,  0.0238, -0.1309],
          [ 0.0395, -0.0490, -0.2475],
          [ 0.0184,  0.1614, -0.0274]],

         [[-0.1026,  0.0038, -0.2243],
          [-0.0594,  0.0695,  0.0454],
          [ 0.1576,  0.0966,  0.0406]]],


        [[[-0.0020,  0.0009, -0.0052],
          [ 0.0011,  0.0044, -0.0095],
          [ 0.0028,  0.0063,  0.0022]],

         [[-0.0023, -0.0017, -0.0080],
          [ 0.0036, -0.0022, -0.0027],
          [-0.0062, -0.0091, -0.0063]],

         [[ 0.0097,  0.0043, -0.0145],
          [-0.0033, -0.0139, -0.0024],
          [ 0.0069,  0.0016, -0.0197]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-1.2977e-02, -9.0027e-03, -1.2780e-02],
          [-2.6307e-02, -2.5348e-02, -2.7625e-02],
          [-2.2037e-02, -2.0390e-02, -2.3292e-02]],

         [[-1.4068e-02, -9.8421e-03, -1.3530e-02],
          [-2.2710e-02, -2.0286e-02, -2.2985e-02],
          [-1.6065e-02, -1.3719e-02, -1.7098e-02]],

         [[-1.6249e-02, -1.4007e-02, -1.6242e-02],
          [-2.7574e-02, -2.6207e-02, -2.4779e-02],
          [-2.1385e-02, -1.7681e-02, -1.6009e-02]]],


        [[[ 8.4313e-04, -7.5022e-04, -4.4427e-04],
          [-2.3693e-03, -4.4798e-03, -4.6901e-03],
          [-5.6547e-03, -7.2763e-03, -6.5658e-03]],

         [[-1.3962e-04, -1.5377e-03, -9.0244e-04],
          [-2.4158e-03, -4.7060e-03, -4.6588e-03],
          [-5.1740e-03, -7.1221e-03, -6.6385e-03]],

         [[-1.5125e-03, -2.6204e-03, -2.2129e-03],
          [-3.4096e-03, -5.5086e-03, -5.1684e-03],
          [-5.6290e-03, -6.4659e-03, -5.4059e-03]]],


        [[[ 3.0642e-02,  1.3977e-02, -9.4425e-04],
          [ 4.6327e-03, -6.4512e-05,  1.1146e-03],
          [ 1.5525e-02,  1.2713e-02,  6.2020e-03]],

         [[ 3.7632e-02,  1.8747e-02,  5.5699e-03],
          [ 1.3772e-02,  7.8314e-03,  7.5166e-03],
          [ 2.6265e-02,  2.4469e-02,  1.3842e-02]],

         [[ 4.1531e-02,  2.9326e-02,  1.9786e-02],
          [ 1.8674e-02,  1.4107e-02,  1.0219e-02],
          [ 3.0505e-02,  2.4730e-02,  1.1212e-02]]],


        ...,


        [[[ 2.9076e-03, -1.4368e-04, -5.7598e-03],
          [-3.1972e-03, -5.4762e-04, -4.8531e-03],
          [-4.0392e-03, -1.8652e-03, -7.6175e-03]],

         [[ 3.2756e-03, -2.3183e-03, -1.1050e-02],
          [-4.4289e-03, -3.7207e-03, -1.0446e-02],
          [-3.5869e-03, -3.4856e-03, -1.1808e-02]],

         [[-2.1054e-03, -7.9688e-03, -1.5734e-02],
          [-5.6455e-03, -9.6109e-03, -1.8072e-02],
          [-4.4704e-03, -8.8175e-03, -1.7774e-02]]],


        [[[ 1.3609e-02,  8.5859e-03,  3.9084e-03],
          [ 1.5385e-02,  1.2805e-02, -1.6101e-04],
          [ 2.6774e-02,  2.5400e-02,  1.3687e-02]],

         [[ 2.6288e-02,  2.0243e-02,  1.5486e-02],
          [ 2.2167e-02,  1.8222e-02,  6.5869e-03],
          [ 2.5523e-02,  2.2447e-02,  1.1901e-02]],

         [[ 2.9906e-02,  2.2684e-02,  1.6860e-02],
          [ 2.6642e-02,  2.2114e-02,  7.5701e-03],
          [ 2.5735e-02,  2.2082e-02,  8.0071e-03]]],


        [[[ 1.5409e-07, -1.4748e-08, -5.4449e-09],
          [ 1.8748e-07, -4.6430e-09,  4.8477e-09],
          [ 1.7558e-07, -1.3709e-08, -4.7502e-09]],

         [[ 1.4374e-07, -3.3332e-09,  6.1519e-09],
          [ 1.7257e-07,  7.1149e-09,  1.6716e-08],
          [ 1.6220e-07, -2.3663e-09,  6.6617e-09]],

         [[ 1.1977e-07,  8.1796e-09,  1.6732e-08],
          [ 1.4718e-07,  1.7936e-08,  2.6564e-08],
          [ 1.1389e-07,  9.3923e-09,  1.7532e-08]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3886]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 13 | Batch_idx: 0 |  Loss: (0.4381) | Acc: (82.00%) (105/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.4945) | Acc: (82.00%) (1168/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.5100) | Acc: (82.00%) (2216/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.5024) | Acc: (82.00%) (3278/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.4890) | Acc: (83.00%) (4375/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.4850) | Acc: (83.00%) (5448/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.4864) | Acc: (83.00%) (6525/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.4864) | Acc: (83.00%) (7595/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.4877) | Acc: (83.00%) (8658/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.4909) | Acc: (83.00%) (9717/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.4928) | Acc: (83.00%) (10769/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.4924) | Acc: (83.00%) (11848/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.4932) | Acc: (83.00%) (12915/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.4934) | Acc: (83.00%) (13972/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.4927) | Acc: (83.00%) (15055/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.4943) | Acc: (83.00%) (16107/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.4931) | Acc: (83.00%) (17174/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.4921) | Acc: (83.00%) (18252/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.4882) | Acc: (83.00%) (19359/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.4880) | Acc: (83.00%) (20421/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.4879) | Acc: (83.00%) (21486/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.4904) | Acc: (83.00%) (22544/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.4902) | Acc: (83.00%) (23620/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.4895) | Acc: (83.00%) (24699/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.4880) | Acc: (83.00%) (25786/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.4875) | Acc: (83.00%) (26872/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.4855) | Acc: (83.00%) (27959/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.4858) | Acc: (83.00%) (29035/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.4839) | Acc: (83.00%) (30127/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.4842) | Acc: (83.00%) (31195/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.4827) | Acc: (83.00%) (32265/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.4830) | Acc: (83.00%) (33341/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.4817) | Acc: (83.00%) (34423/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.4824) | Acc: (83.00%) (35494/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.4830) | Acc: (83.00%) (36541/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.4826) | Acc: (83.00%) (37615/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.4815) | Acc: (83.00%) (38706/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.4802) | Acc: (83.00%) (39799/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.4798) | Acc: (83.00%) (40868/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.4793) | Acc: (83.00%) (41906/50000)
# TEST : Loss: (0.6392) | Acc: (79.00%) (7922/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1199, -0.2153,  0.0900],
          [-0.0931,  0.2064,  0.1283],
          [ 0.0919, -0.0125, -0.1179]],

         [[-0.2167,  0.2060,  0.1707],
          [-0.0185,  0.2144,  0.0893],
          [ 0.1897, -0.1553,  0.1252]],

         [[-0.1538,  0.0177, -0.0318],
          [-0.1999, -0.0313, -0.0383],
          [-0.1631, -0.0048, -0.1040]]],


        [[[ 0.1178, -0.1589,  0.1113],
          [-0.0678, -0.1304,  0.0581],
          [ 0.1362,  0.0131, -0.2026]],

         [[-0.1351,  0.0389, -0.0300],
          [ 0.1005,  0.0393,  0.0755],
          [ 0.1119,  0.1551, -0.2043]],

         [[ 0.0329, -0.1655,  0.0437],
          [-0.1639,  0.1169,  0.1562],
          [ 0.0369, -0.0303, -0.1009]]],


        [[[ 0.0429,  0.1093, -0.1018],
          [-0.0151,  0.1407, -0.1299],
          [ 0.0409,  0.2219,  0.1844]],

         [[-0.1679,  0.0352, -0.1422],
          [-0.1786, -0.0680, -0.1787],
          [-0.1714, -0.2166,  0.0686]],

         [[ 0.1468, -0.0052,  0.1930],
          [ 0.1414,  0.0306,  0.0023],
          [-0.0731,  0.0863,  0.0733]]],


        ...,


        [[[ 0.2478,  0.0040,  0.0157],
          [ 0.1744, -0.1866, -0.0120],
          [-0.0932, -0.1389, -0.0972]],

         [[-0.0160,  0.0067, -0.1004],
          [-0.1588, -0.2033,  0.1412],
          [-0.0451,  0.2508,  0.2103]],

         [[-0.0410, -0.0631,  0.2453],
          [ 0.0206, -0.2505, -0.0887],
          [ 0.0453, -0.0285, -0.0339]]],


        [[[ 0.0715, -0.0350,  0.1701],
          [ 0.1877,  0.1192, -0.0095],
          [-0.1997, -0.1148, -0.0406]],

         [[ 0.0739,  0.0229, -0.1287],
          [ 0.0379, -0.0499, -0.2488],
          [ 0.0125,  0.1555, -0.0281]],

         [[-0.1098, -0.0015, -0.2253],
          [-0.0624,  0.0706,  0.0478],
          [ 0.1583,  0.1020,  0.0503]]],


        [[[-0.0008,  0.0005, -0.0032],
          [ 0.0005,  0.0024, -0.0060],
          [ 0.0013,  0.0035,  0.0014]],

         [[-0.0011, -0.0008, -0.0042],
          [ 0.0017, -0.0011, -0.0015],
          [-0.0030, -0.0045, -0.0034]],

         [[ 0.0053,  0.0023, -0.0079],
          [-0.0018, -0.0075, -0.0013],
          [ 0.0037,  0.0008, -0.0110]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0223, -0.0239, -0.0242],
          [-0.0230, -0.0273, -0.0339],
          [-0.0301, -0.0332, -0.0369]],

         [[-0.0380, -0.0424, -0.0432],
          [-0.0403, -0.0471, -0.0534],
          [-0.0498, -0.0532, -0.0562]],

         [[-0.0360, -0.0459, -0.0500],
          [-0.0348, -0.0463, -0.0548],
          [-0.0451, -0.0526, -0.0558]]],


        [[[ 0.0055,  0.0053,  0.0067],
          [ 0.0051,  0.0061,  0.0069],
          [ 0.0063,  0.0069,  0.0094]],

         [[ 0.0110,  0.0105,  0.0112],
          [ 0.0115,  0.0122,  0.0124],
          [ 0.0122,  0.0123,  0.0148]],

         [[ 0.0096,  0.0091,  0.0104],
          [ 0.0109,  0.0128,  0.0137],
          [ 0.0122,  0.0131,  0.0151]]],


        [[[-0.0663, -0.0608, -0.0596],
          [-0.0655, -0.0619, -0.0775],
          [-0.0571, -0.0717, -0.0862]],

         [[-0.0371, -0.0286, -0.0227],
          [-0.0366, -0.0265, -0.0419],
          [-0.0226, -0.0325, -0.0504]],

         [[ 0.0031,  0.0105,  0.0151],
          [ 0.0103,  0.0154, -0.0013],
          [ 0.0212,  0.0094, -0.0153]]],


        ...,


        [[[-0.0167, -0.0194, -0.0104],
          [-0.0232, -0.0216, -0.0126],
          [-0.0164, -0.0185, -0.0034]],

         [[ 0.0064,  0.0019,  0.0060],
          [-0.0000, -0.0011,  0.0044],
          [ 0.0043, -0.0033,  0.0102]],

         [[ 0.0193,  0.0122,  0.0130],
          [ 0.0139,  0.0095,  0.0123],
          [ 0.0178,  0.0086,  0.0164]]],


        [[[ 0.0096,  0.0066, -0.0078],
          [ 0.0226,  0.0160,  0.0069],
          [ 0.0420,  0.0290,  0.0190]],

         [[ 0.0207,  0.0206,  0.0067],
          [ 0.0278,  0.0257,  0.0202],
          [ 0.0448,  0.0345,  0.0257]],

         [[ 0.0234,  0.0260,  0.0140],
          [ 0.0269,  0.0277,  0.0224],
          [ 0.0373,  0.0330,  0.0270]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3873]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 14 | Batch_idx: 0 |  Loss: (0.4550) | Acc: (82.00%) (106/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.5704) | Acc: (80.00%) (1131/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.5939) | Acc: (79.00%) (2150/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.6154) | Acc: (79.00%) (3143/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.6300) | Acc: (78.00%) (4134/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.6305) | Acc: (78.00%) (5135/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.6349) | Acc: (78.00%) (6127/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.6343) | Acc: (78.00%) (7127/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.6332) | Acc: (78.00%) (8135/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.6258) | Acc: (78.00%) (9166/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.6191) | Acc: (78.00%) (10209/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.6121) | Acc: (79.00%) (11241/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.6051) | Acc: (79.00%) (12301/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.5980) | Acc: (79.00%) (13371/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.5913) | Acc: (79.00%) (14422/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.5885) | Acc: (79.00%) (15460/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.5861) | Acc: (80.00%) (16503/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.5831) | Acc: (80.00%) (17542/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.5796) | Acc: (80.00%) (18598/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.5757) | Acc: (80.00%) (19665/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.5727) | Acc: (80.00%) (20723/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.5696) | Acc: (80.00%) (21796/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.5673) | Acc: (80.00%) (22843/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.5647) | Acc: (80.00%) (23911/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.5614) | Acc: (80.00%) (24979/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.5585) | Acc: (81.00%) (26055/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.5558) | Acc: (81.00%) (27123/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.5529) | Acc: (81.00%) (28204/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.5489) | Acc: (81.00%) (29300/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.5462) | Acc: (81.00%) (30380/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.5436) | Acc: (81.00%) (31455/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.5422) | Acc: (81.00%) (32523/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.5387) | Acc: (81.00%) (33622/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.5369) | Acc: (81.00%) (34697/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.5344) | Acc: (82.00%) (35792/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.5321) | Acc: (82.00%) (36866/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.5299) | Acc: (82.00%) (37949/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.5268) | Acc: (82.00%) (39063/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.5271) | Acc: (82.00%) (40120/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.5256) | Acc: (82.00%) (41164/50000)
# TEST : Loss: (0.4917) | Acc: (83.00%) (8340/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1183, -0.2141,  0.0909],
          [-0.0906,  0.2076,  0.1291],
          [ 0.0950, -0.0095, -0.1165]],

         [[-0.2140,  0.2068,  0.1717],
          [-0.0154,  0.2162,  0.0906],
          [ 0.1933, -0.1515,  0.1262]],

         [[-0.1519,  0.0183, -0.0307],
          [-0.1975, -0.0299, -0.0375],
          [-0.1598, -0.0023, -0.1029]]],


        [[[ 0.1148, -0.1598,  0.1084],
          [-0.0695, -0.1317,  0.0557],
          [ 0.1338,  0.0104, -0.2028]],

         [[-0.1376,  0.0350, -0.0333],
          [ 0.0960,  0.0356,  0.0718],
          [ 0.1085,  0.1505, -0.2055]],

         [[ 0.0290, -0.1676,  0.0397],
          [-0.1663,  0.1121,  0.1510],
          [ 0.0337, -0.0337, -0.1034]]],


        [[[ 0.0443,  0.1100, -0.1019],
          [-0.0133,  0.1413, -0.1293],
          [ 0.0432,  0.2233,  0.1860]],

         [[-0.1655,  0.0365, -0.1421],
          [-0.1760, -0.0670, -0.1779],
          [-0.1687, -0.2149,  0.0705]],

         [[ 0.1484, -0.0042,  0.1925],
          [ 0.1430,  0.0313,  0.0027],
          [-0.0713,  0.0870,  0.0746]]],


        ...,


        [[[ 0.2474,  0.0062,  0.0167],
          [ 0.1738, -0.1842, -0.0108],
          [-0.0926, -0.1370, -0.0973]],

         [[-0.0170,  0.0074, -0.1002],
          [-0.1598, -0.2025,  0.1406],
          [-0.0458,  0.2506,  0.2086]],

         [[-0.0447, -0.0648,  0.2425],
          [ 0.0165, -0.2520, -0.0903],
          [ 0.0416, -0.0306, -0.0370]]],


        [[[ 0.0711, -0.0343,  0.1721],
          [ 0.1859,  0.1188, -0.0083],
          [-0.1996, -0.1138, -0.0389]],

         [[ 0.0720,  0.0221, -0.1274],
          [ 0.0357, -0.0509, -0.2481],
          [ 0.0120,  0.1558, -0.0263]],

         [[-0.1107, -0.0018, -0.2231],
          [-0.0628,  0.0708,  0.0492],
          [ 0.1595,  0.1039,  0.0531]]],


        [[[-0.0003,  0.0002, -0.0018],
          [ 0.0002,  0.0011, -0.0034],
          [ 0.0005,  0.0017,  0.0008]],

         [[-0.0005, -0.0003, -0.0019],
          [ 0.0007, -0.0004, -0.0007],
          [-0.0012, -0.0019, -0.0017]],

         [[ 0.0026,  0.0011, -0.0038],
          [-0.0009, -0.0035, -0.0006],
          [ 0.0018,  0.0004, -0.0054]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5071]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0116]], device='cuda:0')

Epoch: 15 | Batch_idx: 0 |  Loss: (0.3556) | Acc: (89.00%) (114/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.4588) | Acc: (85.00%) (1206/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.4466) | Acc: (85.00%) (2305/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.4407) | Acc: (86.00%) (3413/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.4442) | Acc: (85.00%) (4503/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.4401) | Acc: (85.00%) (5600/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.4480) | Acc: (85.00%) (6662/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.4467) | Acc: (85.00%) (7772/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.4511) | Acc: (85.00%) (8845/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.4527) | Acc: (85.00%) (9924/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.4518) | Acc: (85.00%) (11013/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.4494) | Acc: (85.00%) (12107/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.4488) | Acc: (85.00%) (13203/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.4502) | Acc: (85.00%) (14271/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.4518) | Acc: (85.00%) (15363/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.4512) | Acc: (85.00%) (16439/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.4518) | Acc: (85.00%) (17520/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.4502) | Acc: (85.00%) (18625/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.4535) | Acc: (84.00%) (19680/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.4542) | Acc: (84.00%) (20758/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.4535) | Acc: (84.00%) (21846/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.4527) | Acc: (84.00%) (22942/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.4505) | Acc: (85.00%) (24047/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.4509) | Acc: (84.00%) (25129/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.4517) | Acc: (84.00%) (26215/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.4506) | Acc: (85.00%) (27321/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.4510) | Acc: (84.00%) (28386/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.4530) | Acc: (84.00%) (29447/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.4533) | Acc: (84.00%) (30533/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.4531) | Acc: (84.00%) (31629/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.4523) | Acc: (84.00%) (32724/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.4526) | Acc: (84.00%) (33803/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.4527) | Acc: (84.00%) (34889/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.4524) | Acc: (84.00%) (35972/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.4531) | Acc: (84.00%) (37054/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.4526) | Acc: (84.00%) (38151/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.4531) | Acc: (84.00%) (39212/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.4532) | Acc: (84.00%) (40299/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.4525) | Acc: (84.00%) (41401/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.4527) | Acc: (84.00%) (42449/50000)
# TEST : Loss: (0.4667) | Acc: (84.00%) (8411/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1179, -0.2135,  0.0906],
          [-0.0904,  0.2070,  0.1287],
          [ 0.0947, -0.0095, -0.1161]],

         [[-0.2134,  0.2062,  0.1712],
          [-0.0154,  0.2156,  0.0903],
          [ 0.1928, -0.1511,  0.1258]],

         [[-0.1514,  0.0183, -0.0306],
          [-0.1968, -0.0298, -0.0373],
          [-0.1592, -0.0023, -0.1025]]],


        [[[ 0.1137, -0.1584,  0.1074],
          [-0.0688, -0.1305,  0.0551],
          [ 0.1326,  0.0103, -0.2009]],

         [[-0.1363,  0.0346, -0.0330],
          [ 0.0950,  0.0352,  0.0711],
          [ 0.1074,  0.1490, -0.2035]],

         [[ 0.0287, -0.1659,  0.0393],
          [-0.1646,  0.1109,  0.1495],
          [ 0.0334, -0.0334, -0.1023]]],


        [[[ 0.0443,  0.1098, -0.1017],
          [-0.0133,  0.1411, -0.1291],
          [ 0.0432,  0.2231,  0.1858]],

         [[-0.1653,  0.0364, -0.1419],
          [-0.1757, -0.0669, -0.1777],
          [-0.1685, -0.2146,  0.0704]],

         [[ 0.1482, -0.0042,  0.1923],
          [ 0.1428,  0.0312,  0.0026],
          [-0.0712,  0.0869,  0.0745]]],


        ...,


        [[[ 0.2465,  0.0062,  0.0167],
          [ 0.1732, -0.1836, -0.0108],
          [-0.0922, -0.1364, -0.0969]],

         [[-0.0169,  0.0073, -0.0998],
          [-0.1592, -0.2017,  0.1401],
          [-0.0456,  0.2496,  0.2078]],

         [[-0.0445, -0.0645,  0.2415],
          [ 0.0164, -0.2509, -0.0899],
          [ 0.0414, -0.0305, -0.0369]]],


        [[[ 0.0709, -0.0342,  0.1718],
          [ 0.1855,  0.1185, -0.0083],
          [-0.1992, -0.1136, -0.0388]],

         [[ 0.0718,  0.0220, -0.1271],
          [ 0.0356, -0.0507, -0.2475],
          [ 0.0120,  0.1555, -0.0263]],

         [[-0.1104, -0.0018, -0.2226],
          [-0.0626,  0.0706,  0.0491],
          [ 0.1592,  0.1037,  0.0530]]],


        [[[-0.0001,  0.0001, -0.0008],
          [ 0.0001,  0.0005, -0.0017],
          [ 0.0001,  0.0007,  0.0004]],

         [[-0.0002, -0.0001, -0.0007],
          [ 0.0002, -0.0002, -0.0003],
          [-0.0004, -0.0007, -0.0007]],

         [[ 0.0011,  0.0004, -0.0015],
          [-0.0003, -0.0014, -0.0003],
          [ 0.0007,  0.0002, -0.0022]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5482]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0335]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 16 | Batch_idx: 0 |  Loss: (0.3648) | Acc: (88.00%) (113/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.4410) | Acc: (85.00%) (1204/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.4683) | Acc: (84.00%) (2262/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.5068) | Acc: (82.00%) (3278/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.5343) | Acc: (81.00%) (4292/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.5337) | Acc: (81.00%) (5337/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.5414) | Acc: (81.00%) (6361/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.5440) | Acc: (81.00%) (7402/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.5437) | Acc: (81.00%) (8448/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.5415) | Acc: (81.00%) (9501/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.5417) | Acc: (81.00%) (10535/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.5434) | Acc: (81.00%) (11560/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.5450) | Acc: (81.00%) (12609/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.5438) | Acc: (81.00%) (13656/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.5426) | Acc: (81.00%) (14722/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.5420) | Acc: (81.00%) (15772/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.5426) | Acc: (81.00%) (16813/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.5411) | Acc: (81.00%) (17866/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.5393) | Acc: (81.00%) (18918/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.5363) | Acc: (81.00%) (19983/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.5340) | Acc: (81.00%) (21048/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.5317) | Acc: (81.00%) (22099/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.5320) | Acc: (81.00%) (23131/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.5328) | Acc: (81.00%) (24176/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.5306) | Acc: (81.00%) (25251/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.5303) | Acc: (81.00%) (26291/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.5284) | Acc: (81.00%) (27356/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.5286) | Acc: (81.00%) (28398/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.5259) | Acc: (81.00%) (29490/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.5246) | Acc: (82.00%) (30552/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.5240) | Acc: (82.00%) (31609/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.5215) | Acc: (82.00%) (32695/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.5203) | Acc: (82.00%) (33747/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.5199) | Acc: (82.00%) (34812/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.5186) | Acc: (82.00%) (35877/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.5185) | Acc: (82.00%) (36939/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.5181) | Acc: (82.00%) (38006/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.5163) | Acc: (82.00%) (39098/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.5163) | Acc: (82.00%) (40153/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.5154) | Acc: (82.00%) (41186/50000)
# TEST : Loss: (0.5624) | Acc: (81.00%) (8119/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1158, -0.2086,  0.0963],
          [-0.0890,  0.2208,  0.1365],
          [ 0.0899, -0.0108, -0.1225]],

         [[-0.2206,  0.2056,  0.1774],
          [-0.0179,  0.2281,  0.1036],
          [ 0.1882, -0.1524,  0.1211]],

         [[-0.1472,  0.0251, -0.0209],
          [-0.1937, -0.0201, -0.0272],
          [-0.1636, -0.0048, -0.1040]]],


        [[[ 0.1334, -0.1408,  0.1224],
          [-0.0592, -0.1137,  0.0761],
          [ 0.1463,  0.0199, -0.1987]],

         [[-0.1137,  0.0498, -0.0182],
          [ 0.0998,  0.0523,  0.0924],
          [ 0.1172,  0.1600, -0.1964]],

         [[ 0.0624, -0.1334,  0.0658],
          [-0.1462,  0.1318,  0.1750],
          [ 0.0423, -0.0223, -0.0891]]],


        [[[ 0.0391,  0.1022, -0.1112],
          [-0.0170,  0.1360, -0.1319],
          [ 0.0360,  0.2216,  0.1899]],

         [[-0.1693,  0.0319, -0.1488],
          [-0.1841, -0.0768, -0.1811],
          [-0.1813, -0.2252,  0.0687]],

         [[ 0.1521,  0.0007,  0.1917],
          [ 0.1479,  0.0373,  0.0099],
          [-0.0727,  0.0887,  0.0784]]],


        ...,


        [[[ 0.2567,  0.0111,  0.0138],
          [ 0.1954, -0.1785, -0.0041],
          [-0.0817, -0.1312, -0.0961]],

         [[-0.0104,  0.0038, -0.1061],
          [-0.1409, -0.1995,  0.1471],
          [-0.0351,  0.2627,  0.2201]],

         [[-0.0440, -0.0662,  0.2351],
          [ 0.0232, -0.2556, -0.0957],
          [ 0.0297, -0.0466, -0.0529]]],


        [[[ 0.0740, -0.0263,  0.1758],
          [ 0.1909,  0.1246, -0.0080],
          [-0.2090, -0.1218, -0.0481]],

         [[ 0.0828,  0.0336, -0.1235],
          [ 0.0507, -0.0355, -0.2450],
          [ 0.0162,  0.1645, -0.0232]],

         [[-0.1040,  0.0074, -0.2164],
          [-0.0550,  0.0846,  0.0562],
          [ 0.1613,  0.1145,  0.0578]]],


        [[[-0.0000,  0.0000, -0.0003],
          [ 0.0000,  0.0002, -0.0007],
          [ 0.0000,  0.0002,  0.0002]],

         [[-0.0000, -0.0000, -0.0002],
          [ 0.0001, -0.0000, -0.0001],
          [-0.0001, -0.0002, -0.0002]],

         [[ 0.0004,  0.0001, -0.0005],
          [-0.0001, -0.0005, -0.0001],
          [ 0.0002,  0.0000, -0.0008]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0154,  0.0118,  0.0203],
          [ 0.0116,  0.0120,  0.0178],
          [ 0.0107,  0.0191,  0.0257]],

         [[ 0.0090,  0.0084,  0.0122],
          [ 0.0050,  0.0080,  0.0090],
          [ 0.0076,  0.0148,  0.0182]],

         [[ 0.0089,  0.0108,  0.0102],
          [ 0.0028,  0.0076,  0.0078],
          [ 0.0060,  0.0145,  0.0206]]],


        [[[ 0.0002,  0.0018,  0.0019],
          [ 0.0013,  0.0011,  0.0020],
          [-0.0014, -0.0011,  0.0001]],

         [[ 0.0010,  0.0027,  0.0032],
          [ 0.0025,  0.0016,  0.0018],
          [-0.0005, -0.0015, -0.0002]],

         [[ 0.0005,  0.0015,  0.0022],
          [ 0.0016,  0.0007,  0.0009],
          [-0.0013, -0.0023, -0.0012]]],


        [[[-0.0892, -0.0813, -0.0861],
          [-0.1153, -0.0937, -0.0873],
          [-0.1057, -0.0793, -0.0654]],

         [[-0.0509, -0.0381, -0.0450],
          [-0.0735, -0.0436, -0.0377],
          [-0.0591, -0.0210, -0.0130]],

         [[-0.0359, -0.0242, -0.0278],
          [-0.0527, -0.0241, -0.0181],
          [-0.0429, -0.0053,  0.0036]]],


        ...,


        [[[-0.0103, -0.0045, -0.0117],
          [-0.0159, -0.0151, -0.0155],
          [-0.0087, -0.0097, -0.0083]],

         [[-0.0093, -0.0019, -0.0100],
          [-0.0120, -0.0095, -0.0130],
          [-0.0051, -0.0079, -0.0099]],

         [[-0.0045,  0.0024, -0.0050],
          [-0.0069, -0.0054, -0.0099],
          [ 0.0020, -0.0036, -0.0090]]],


        [[[-0.0183, -0.0065, -0.0066],
          [ 0.0032,  0.0143,  0.0125],
          [ 0.0090,  0.0160,  0.0086]],

         [[-0.0116,  0.0007,  0.0068],
          [ 0.0080,  0.0204,  0.0258],
          [ 0.0103,  0.0210,  0.0193]],

         [[-0.0166, -0.0056,  0.0037],
          [ 0.0039,  0.0166,  0.0261],
          [ 0.0113,  0.0239,  0.0257]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5502]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 17 | Batch_idx: 0 |  Loss: (0.4021) | Acc: (88.00%) (113/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.4198) | Acc: (86.00%) (1211/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.4228) | Acc: (85.00%) (2308/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.4226) | Acc: (85.00%) (3401/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.4268) | Acc: (85.00%) (4499/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.4384) | Acc: (85.00%) (5575/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.4349) | Acc: (85.00%) (6665/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.4355) | Acc: (85.00%) (7767/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.4357) | Acc: (85.00%) (8848/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.4356) | Acc: (85.00%) (9939/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.4372) | Acc: (85.00%) (11008/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.4375) | Acc: (85.00%) (12103/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.4393) | Acc: (85.00%) (13198/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.4365) | Acc: (85.00%) (14300/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.4354) | Acc: (85.00%) (15400/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.4357) | Acc: (85.00%) (16482/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.4363) | Acc: (85.00%) (17573/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.4373) | Acc: (85.00%) (18653/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.4357) | Acc: (85.00%) (19764/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.4368) | Acc: (85.00%) (20842/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.4368) | Acc: (85.00%) (21941/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.4367) | Acc: (85.00%) (23041/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.4375) | Acc: (85.00%) (24138/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.4366) | Acc: (85.00%) (25237/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.4344) | Acc: (85.00%) (26331/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.4348) | Acc: (85.00%) (27416/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.4344) | Acc: (85.00%) (28520/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.4328) | Acc: (85.00%) (29624/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.4333) | Acc: (85.00%) (30705/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.4329) | Acc: (85.00%) (31811/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.4331) | Acc: (85.00%) (32902/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.4327) | Acc: (85.00%) (34014/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.4320) | Acc: (85.00%) (35117/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.4319) | Acc: (85.00%) (36205/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.4318) | Acc: (85.00%) (37299/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.4314) | Acc: (85.00%) (38389/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.4321) | Acc: (85.00%) (39472/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.4309) | Acc: (85.00%) (40579/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.4306) | Acc: (85.00%) (41687/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.4295) | Acc: (85.00%) (42754/50000)
# TEST : Loss: (0.5504) | Acc: (82.00%) (8225/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1607e-01, -2.1131e-01,  9.0078e-02],
          [-8.9260e-02,  2.2263e-01,  1.3471e-01],
          [ 8.7303e-02, -1.0111e-02, -1.1839e-01]],

         [[-2.2318e-01,  2.0349e-01,  1.7766e-01],
          [-1.7640e-02,  2.3258e-01,  1.0859e-01],
          [ 1.8670e-01, -1.4996e-01,  1.2867e-01]],

         [[-1.5336e-01,  1.9232e-02, -2.1781e-02],
          [-2.0175e-01, -2.7564e-02, -3.1051e-02],
          [-1.7113e-01, -1.3449e-02, -1.0491e-01]]],


        [[[ 1.1891e-01, -1.6108e-01,  1.0188e-01],
          [-6.5859e-02, -1.2653e-01,  6.0009e-02],
          [ 1.4876e-01,  1.5494e-02, -2.0969e-01]],

         [[-1.3012e-01,  2.3681e-02, -4.0980e-02],
          [ 8.8681e-02,  4.0189e-02,  7.8217e-02],
          [ 1.2135e-01,  1.6141e-01, -2.0119e-01]],

         [[ 4.0693e-02, -1.5964e-01,  3.9752e-02],
          [-1.5919e-01,  1.1601e-01,  1.5632e-01],
          [ 3.9352e-02, -2.7032e-02, -1.0028e-01]]],


        [[[ 4.7234e-02,  1.0941e-01, -9.9378e-02],
          [-7.7290e-03,  1.4135e-01, -1.2773e-01],
          [ 5.1660e-02,  2.2698e-01,  1.9441e-01]],

         [[-1.7645e-01,  2.1170e-02, -1.5327e-01],
          [-1.8925e-01, -9.1218e-02, -1.9231e-01],
          [-1.7519e-01, -2.3567e-01,  6.0165e-02]],

         [[ 1.4858e-01, -5.5279e-03,  1.8666e-01],
          [ 1.4754e-01,  3.0355e-02,  3.6768e-03],
          [-6.3272e-02,  8.3592e-02,  7.0996e-02]]],


        ...,


        [[[ 2.5125e-01,  1.5998e-02,  2.8913e-03],
          [ 1.8994e-01, -1.8600e-01, -1.5379e-02],
          [-8.9931e-02, -1.3182e-01, -1.0062e-01]],

         [[-1.2626e-02,  1.3647e-02, -1.0203e-01],
          [-1.4356e-01, -1.9878e-01,  1.5284e-01],
          [-4.0313e-02,  2.7490e-01,  2.3151e-01]],

         [[-3.5667e-02, -4.3078e-02,  2.4688e-01],
          [ 3.0419e-02, -2.4101e-01, -8.0726e-02],
          [ 2.4026e-02, -3.5031e-02, -4.5635e-02]]],


        [[[ 6.2976e-02, -3.3971e-02,  1.7215e-01],
          [ 1.8281e-01,  1.1976e-01, -1.2872e-02],
          [-2.2016e-01, -1.3529e-01, -5.9416e-02]],

         [[ 7.2478e-02,  2.1042e-02, -1.3751e-01],
          [ 4.2972e-02, -4.3272e-02, -2.5795e-01],
          [ 4.3119e-03,  1.5072e-01, -3.6662e-02]],

         [[-1.2039e-01, -1.1078e-02, -2.3150e-01],
          [-6.2124e-02,  7.7993e-02,  4.8105e-02],
          [ 1.5338e-01,  1.0862e-01,  5.4909e-02]]],


        [[[-3.0153e-06,  6.4381e-06, -1.1846e-04],
          [ 1.8905e-06,  4.0237e-05, -2.6669e-04],
          [ 5.6989e-06,  6.0810e-05,  6.0692e-05]],

         [[-8.0194e-06, -5.7918e-06, -5.2732e-05],
          [ 1.2841e-05, -8.4407e-06, -2.3860e-05],
          [-2.1329e-05, -3.8175e-05, -5.8956e-05]],

         [[ 9.4031e-05,  3.5394e-05, -1.3278e-04],
          [-3.0353e-05, -1.1592e-04, -2.4669e-05],
          [ 5.6588e-05,  1.2140e-05, -2.0907e-04]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0282, -0.0299, -0.0345],
          [-0.0308, -0.0383, -0.0434],
          [-0.0322, -0.0385, -0.0415]],

         [[-0.0322, -0.0288, -0.0369],
          [-0.0332, -0.0366, -0.0449],
          [-0.0334, -0.0385, -0.0424]],

         [[-0.0323, -0.0302, -0.0376],
          [-0.0365, -0.0409, -0.0448],
          [-0.0380, -0.0427, -0.0408]]],


        [[[-0.0029, -0.0020, -0.0026],
          [-0.0005,  0.0008,  0.0013],
          [-0.0030, -0.0005,  0.0005]],

         [[-0.0020, -0.0008, -0.0004],
          [ 0.0019,  0.0030,  0.0039],
          [ 0.0003,  0.0020,  0.0019]],

         [[ 0.0010,  0.0015,  0.0004],
          [ 0.0039,  0.0046,  0.0047],
          [ 0.0024,  0.0046,  0.0043]]],


        [[[-0.0793, -0.0649, -0.0539],
          [-0.0677, -0.0661, -0.0651],
          [-0.0659, -0.0736, -0.0714]],

         [[-0.0605, -0.0503, -0.0446],
          [-0.0567, -0.0526, -0.0539],
          [-0.0590, -0.0635, -0.0595]],

         [[-0.0446, -0.0378, -0.0339],
          [-0.0416, -0.0377, -0.0432],
          [-0.0382, -0.0419, -0.0441]]],


        ...,


        [[[ 0.0077, -0.0002, -0.0156],
          [-0.0171, -0.0014, -0.0068],
          [-0.0311, -0.0137, -0.0139]],

         [[ 0.0140,  0.0058, -0.0067],
          [-0.0099,  0.0045,  0.0012],
          [-0.0230, -0.0066, -0.0078]],

         [[ 0.0055,  0.0012, -0.0105],
          [-0.0105,  0.0033, -0.0024],
          [-0.0214, -0.0062, -0.0095]]],


        [[[ 0.0377,  0.0270,  0.0211],
          [ 0.0523,  0.0452,  0.0449],
          [ 0.0570,  0.0485,  0.0507]],

         [[ 0.0381,  0.0288,  0.0282],
          [ 0.0642,  0.0547,  0.0532],
          [ 0.0655,  0.0555,  0.0555]],

         [[ 0.0300,  0.0195,  0.0168],
          [ 0.0528,  0.0439,  0.0395],
          [ 0.0541,  0.0448,  0.0395]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5485]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 18 | Batch_idx: 0 |  Loss: (0.4178) | Acc: (85.00%) (110/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.4421) | Acc: (85.00%) (1199/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.4726) | Acc: (84.00%) (2260/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.4906) | Acc: (83.00%) (3305/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.4918) | Acc: (83.00%) (4371/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.5056) | Acc: (82.00%) (5417/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.5053) | Acc: (82.00%) (6466/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.4996) | Acc: (82.00%) (7543/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.4983) | Acc: (83.00%) (8609/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.4962) | Acc: (83.00%) (9685/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.4931) | Acc: (83.00%) (10761/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.4917) | Acc: (83.00%) (11834/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.4893) | Acc: (83.00%) (12911/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.4875) | Acc: (83.00%) (13990/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.4835) | Acc: (83.00%) (15094/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.4779) | Acc: (83.00%) (16192/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.4776) | Acc: (83.00%) (17273/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.4762) | Acc: (83.00%) (18371/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.4740) | Acc: (84.00%) (19462/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.4731) | Acc: (84.00%) (20554/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.4696) | Acc: (84.00%) (21666/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.4662) | Acc: (84.00%) (22773/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.4654) | Acc: (84.00%) (23867/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.4631) | Acc: (84.00%) (24964/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.4619) | Acc: (84.00%) (26067/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.4606) | Acc: (84.00%) (27165/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.4585) | Acc: (84.00%) (28260/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.4567) | Acc: (84.00%) (29364/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.4547) | Acc: (84.00%) (30465/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.4520) | Acc: (84.00%) (31585/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.4513) | Acc: (84.00%) (32673/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.4492) | Acc: (84.00%) (33787/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.4478) | Acc: (84.00%) (34893/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.4460) | Acc: (84.00%) (36009/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.4448) | Acc: (85.00%) (37110/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.4441) | Acc: (85.00%) (38202/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.4417) | Acc: (85.00%) (39339/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.4396) | Acc: (85.00%) (40462/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.4382) | Acc: (85.00%) (41575/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.4378) | Acc: (85.00%) (42641/50000)
# TEST : Loss: (0.4416) | Acc: (85.00%) (8539/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1443e-01, -2.0921e-01,  9.1624e-02],
          [-8.7592e-02,  2.2370e-01,  1.3619e-01],
          [ 8.8642e-02, -8.8650e-03, -1.1608e-01]],

         [[-2.2151e-01,  2.0417e-01,  1.7898e-01],
          [-1.6590e-02,  2.3308e-01,  1.1002e-01],
          [ 1.8707e-01, -1.4892e-01,  1.3034e-01]],

         [[-1.5136e-01,  2.1151e-02, -1.9538e-02],
          [-1.9967e-01, -2.5697e-02, -2.9152e-02],
          [-1.6936e-01, -1.2271e-02, -1.0263e-01]]],


        [[[ 1.1838e-01, -1.5849e-01,  1.0253e-01],
          [-6.4570e-02, -1.2408e-01,  6.0590e-02],
          [ 1.4897e-01,  1.7390e-02, -2.0567e-01]],

         [[-1.2810e-01,  2.4038e-02, -3.9065e-02],
          [ 8.7160e-02,  4.0112e-02,  7.7890e-02],
          [ 1.2068e-01,  1.6106e-01, -1.9732e-01]],

         [[ 3.9084e-02, -1.5895e-01,  3.9228e-02],
          [-1.5913e-01,  1.1303e-01,  1.5340e-01],
          [ 3.8667e-02, -2.6933e-02, -9.8999e-02]]],


        [[[ 4.9188e-02,  1.1043e-01, -9.8311e-02],
          [-5.5560e-03,  1.4233e-01, -1.2725e-01],
          [ 5.4040e-02,  2.2855e-01,  1.9514e-01]],

         [[-1.7378e-01,  2.2928e-02, -1.5113e-01],
          [-1.8599e-01, -8.9156e-02, -1.9078e-01],
          [-1.7180e-01, -2.3297e-01,  6.1671e-02]],

         [[ 1.5160e-01, -2.7579e-03,  1.8950e-01],
          [ 1.5128e-01,  3.3474e-02,  6.2692e-03],
          [-5.9233e-02,  8.7061e-02,  7.3594e-02]]],


        ...,


        [[[ 2.5180e-01,  1.8653e-02,  6.5472e-03],
          [ 1.9265e-01, -1.8223e-01, -9.8651e-03],
          [-8.6577e-02, -1.2894e-01, -9.6332e-02]],

         [[-1.2106e-02,  1.5453e-02, -9.9294e-02],
          [-1.4150e-01, -1.9699e-01,  1.5549e-01],
          [-3.8760e-02,  2.7438e-01,  2.3243e-01]],

         [[-3.6987e-02, -4.3272e-02,  2.4615e-01],
          [ 2.9063e-02, -2.4212e-01, -7.9847e-02],
          [ 2.2849e-02, -3.7051e-02, -4.6233e-02]]],


        [[[ 6.2384e-02, -3.3064e-02,  1.7411e-01],
          [ 1.8137e-01,  1.1944e-01, -1.2801e-02],
          [-2.2177e-01, -1.3594e-01, -6.0291e-02]],

         [[ 7.0645e-02,  2.0216e-02, -1.3706e-01],
          [ 3.9702e-02, -4.5394e-02, -2.5981e-01],
          [ 3.5222e-04,  1.4769e-01, -3.9539e-02]],

         [[-1.2183e-01, -1.2137e-02, -2.3090e-01],
          [-6.4834e-02,  7.5502e-02,  4.5785e-02],
          [ 1.4979e-01,  1.0591e-01,  5.2313e-02]]],


        [[[-3.0368e-07,  1.1333e-06, -3.1492e-05],
          [ 1.9689e-07,  7.7217e-06, -7.6286e-05],
          [ 6.3584e-07,  1.1888e-05,  1.7239e-05]],

         [[-1.0862e-06, -7.6989e-07, -8.9692e-06],
          [ 1.7605e-06, -1.1827e-06, -4.5137e-06],
          [-2.8792e-06, -5.5326e-06, -1.1405e-05]],

         [[ 1.8409e-05,  6.5236e-06, -2.5415e-05],
          [-5.8504e-06, -2.1503e-05, -4.9467e-06],
          [ 1.0415e-05,  2.1957e-06, -4.2212e-05]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5366]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0253]], device='cuda:0')

Epoch: 19 | Batch_idx: 0 |  Loss: (0.4582) | Acc: (85.00%) (110/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.3513) | Acc: (88.00%) (1243/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.3614) | Acc: (88.00%) (2369/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.3700) | Acc: (88.00%) (3494/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.3722) | Acc: (87.00%) (4598/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.3757) | Acc: (87.00%) (5722/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.3826) | Acc: (87.00%) (6811/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.3817) | Acc: (87.00%) (7934/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.3802) | Acc: (87.00%) (9061/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.3843) | Acc: (87.00%) (10170/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.3832) | Acc: (87.00%) (11289/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.3849) | Acc: (87.00%) (12405/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.3847) | Acc: (87.00%) (13514/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.3843) | Acc: (87.00%) (14629/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.3862) | Acc: (87.00%) (15742/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.3881) | Acc: (87.00%) (16838/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.3881) | Acc: (87.00%) (17961/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.3880) | Acc: (87.00%) (19072/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.3880) | Acc: (87.00%) (20186/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.3899) | Acc: (87.00%) (21289/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.3909) | Acc: (87.00%) (22391/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.3927) | Acc: (86.00%) (23495/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.3933) | Acc: (86.00%) (24592/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.3945) | Acc: (86.00%) (25684/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.3935) | Acc: (86.00%) (26811/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.3917) | Acc: (86.00%) (27942/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.3916) | Acc: (86.00%) (29057/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.3927) | Acc: (86.00%) (30161/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.3918) | Acc: (86.00%) (31275/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.3919) | Acc: (86.00%) (32386/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.3911) | Acc: (86.00%) (33503/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.3908) | Acc: (86.00%) (34628/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.3896) | Acc: (87.00%) (35761/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.3887) | Acc: (87.00%) (36891/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.3887) | Acc: (87.00%) (37995/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.3880) | Acc: (87.00%) (39111/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.3880) | Acc: (87.00%) (40222/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.3871) | Acc: (87.00%) (41348/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.3877) | Acc: (87.00%) (42455/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.3873) | Acc: (87.00%) (43545/50000)
# TEST : Loss: (0.4244) | Acc: (86.00%) (8605/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1409e-01, -2.0856e-01,  9.1325e-02],
          [-8.7330e-02,  2.2300e-01,  1.3574e-01],
          [ 8.8378e-02, -8.8374e-03, -1.1572e-01]],

         [[-2.2080e-01,  2.0350e-01,  1.7836e-01],
          [-1.6536e-02,  2.3230e-01,  1.0965e-01],
          [ 1.8647e-01, -1.4842e-01,  1.2991e-01]],

         [[-1.5080e-01,  2.1076e-02, -1.9470e-02],
          [-1.9894e-01, -2.5605e-02, -2.9051e-02],
          [-1.6876e-01, -1.2228e-02, -1.0227e-01]]],


        [[[ 1.1677e-01, -1.5635e-01,  1.0117e-01],
          [-6.3698e-02, -1.2237e-01,  5.9767e-02],
          [ 1.4694e-01,  1.7156e-02, -2.0288e-01]],

         [[-1.2630e-01,  2.3703e-02, -3.8531e-02],
          [ 8.5909e-02,  3.9525e-02,  7.6772e-02],
          [ 1.1888e-01,  1.5873e-01, -1.9451e-01]],

         [[ 3.8507e-02, -1.5663e-01,  3.8673e-02],
          [-1.5672e-01,  1.1130e-01,  1.5111e-01],
          [ 3.8064e-02, -2.6522e-02, -9.7512e-02]]],


        [[[ 4.9128e-02,  1.1029e-01, -9.8189e-02],
          [-5.5494e-03,  1.4216e-01, -1.2710e-01],
          [ 5.3974e-02,  2.2827e-01,  1.9490e-01]],

         [[-1.7355e-01,  2.2898e-02, -1.5093e-01],
          [-1.8573e-01, -8.9037e-02, -1.9053e-01],
          [-1.7156e-01, -2.3266e-01,  6.1591e-02]],

         [[ 1.5139e-01, -2.7540e-03,  1.8924e-01],
          [ 1.5107e-01,  3.3427e-02,  6.2605e-03],
          [-5.9149e-02,  8.6940e-02,  7.3493e-02]]],


        ...,


        [[[ 2.5083e-01,  1.8582e-02,  6.5214e-03],
          [ 1.9189e-01, -1.8148e-01, -9.8262e-03],
          [-8.6232e-02, -1.2842e-01, -9.5968e-02]],

         [[-1.2056e-02,  1.5388e-02, -9.8881e-02],
          [-1.4088e-01, -1.9610e-01,  1.5484e-01],
          [-3.8592e-02,  2.7320e-01,  2.3151e-01]],

         [[-3.6820e-02, -4.3069e-02,  2.4504e-01],
          [ 2.8912e-02, -2.4078e-01, -7.9465e-02],
          [ 2.2732e-02, -3.6865e-02, -4.6026e-02]]],


        [[[ 6.2241e-02, -3.2989e-02,  1.7373e-01],
          [ 1.8093e-01,  1.1916e-01, -1.2772e-02],
          [-2.2125e-01, -1.3564e-01, -6.0159e-02]],

         [[ 7.0478e-02,  2.0167e-02, -1.3672e-01],
          [ 3.9604e-02, -4.5281e-02, -2.5916e-01],
          [ 3.5137e-04,  1.4734e-01, -3.9446e-02]],

         [[-1.2153e-01, -1.2107e-02, -2.3030e-01],
          [-6.4669e-02,  7.5308e-02,  4.5666e-02],
          [ 1.4942e-01,  1.0565e-01,  5.2185e-02]]],


        [[[-1.7916e-08,  1.3417e-07, -6.2115e-06],
          [ 1.2115e-08,  1.0175e-06, -1.6471e-05],
          [ 4.2643e-08,  1.6029e-06,  3.6903e-06]],

         [[-9.2800e-08, -6.4255e-08, -1.0175e-06],
          [ 1.5271e-07, -1.0542e-07, -5.8431e-07],
          [-2.4496e-07, -5.1426e-07, -1.5179e-06]],

         [[ 2.4866e-06,  8.1765e-07, -3.3384e-06],
          [-7.7509e-07, -2.7166e-06, -6.8833e-07],
          [ 1.3029e-06,  2.6880e-07, -5.9240e-06]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5210]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0049]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 20 | Batch_idx: 0 |  Loss: (0.3543) | Acc: (87.00%) (112/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.4113) | Acc: (86.00%) (1219/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.4347) | Acc: (85.00%) (2303/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.4620) | Acc: (84.00%) (3363/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.4707) | Acc: (84.00%) (4430/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.4837) | Acc: (84.00%) (5492/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.4870) | Acc: (83.00%) (6547/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.4896) | Acc: (83.00%) (7611/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.4952) | Acc: (83.00%) (8670/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.4956) | Acc: (83.00%) (9725/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.4930) | Acc: (83.00%) (10805/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.4954) | Acc: (83.00%) (11865/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.4939) | Acc: (83.00%) (12945/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.4949) | Acc: (83.00%) (14005/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.4929) | Acc: (83.00%) (15084/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.4907) | Acc: (83.00%) (16144/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.4891) | Acc: (83.00%) (17223/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.4868) | Acc: (83.00%) (18315/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.4844) | Acc: (83.00%) (19401/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.4832) | Acc: (83.00%) (20483/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.4830) | Acc: (83.00%) (21566/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.4809) | Acc: (83.00%) (22654/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.4792) | Acc: (83.00%) (23747/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.4819) | Acc: (83.00%) (24795/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.4817) | Acc: (83.00%) (25866/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.4796) | Acc: (83.00%) (26964/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.4767) | Acc: (84.00%) (28068/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.4746) | Acc: (84.00%) (29158/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.4724) | Acc: (84.00%) (30239/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.4715) | Acc: (84.00%) (31315/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.4703) | Acc: (84.00%) (32394/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.4697) | Acc: (84.00%) (33463/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.4700) | Acc: (84.00%) (34547/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.4694) | Acc: (84.00%) (35638/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.4688) | Acc: (84.00%) (36725/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.4675) | Acc: (84.00%) (37829/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.4663) | Acc: (84.00%) (38933/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.4650) | Acc: (84.00%) (40039/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.4635) | Acc: (84.00%) (41127/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.4628) | Acc: (84.00%) (42174/50000)
# TEST : Loss: (0.6137) | Acc: (80.00%) (8003/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1223e-01, -2.0541e-01,  9.7877e-02],
          [-8.3127e-02,  2.3337e-01,  1.4272e-01],
          [ 8.8761e-02, -7.5026e-03, -1.1633e-01]],

         [[-2.2428e-01,  2.0551e-01,  1.8809e-01],
          [-2.1603e-02,  2.3718e-01,  1.1768e-01],
          [ 1.7929e-01, -1.5125e-01,  1.2956e-01]],

         [[-1.4720e-01,  2.4745e-02, -1.0638e-02],
          [-2.0063e-01, -2.3855e-02, -2.5999e-02],
          [-1.7759e-01, -1.5879e-02, -1.0337e-01]]],


        [[[ 1.2484e-01, -1.5042e-01,  9.7959e-02],
          [-6.0117e-02, -1.1530e-01,  6.1369e-02],
          [ 1.5151e-01,  2.2761e-02, -2.0176e-01]],

         [[-1.2543e-01,  1.7185e-02, -4.4497e-02],
          [ 8.3468e-02,  4.1624e-02,  7.6622e-02],
          [ 1.2023e-01,  1.5967e-01, -1.9600e-01]],

         [[ 4.0664e-02, -1.5495e-01,  3.4972e-02],
          [-1.4892e-01,  1.1712e-01,  1.5462e-01],
          [ 4.0350e-02, -2.6674e-02, -9.7106e-02]]],


        [[[ 6.6071e-02,  1.2118e-01, -9.4282e-02],
          [ 1.3839e-02,  1.5438e-01, -1.2491e-01],
          [ 6.3314e-02,  2.3495e-01,  1.9298e-01]],

         [[-1.6316e-01,  2.4764e-02, -1.5150e-01],
          [-1.8098e-01, -9.3647e-02, -1.9612e-01],
          [-1.7569e-01, -2.4284e-01,  5.0992e-02]],

         [[ 1.6699e-01,  4.0568e-03,  1.9262e-01],
          [ 1.6480e-01,  3.8276e-02,  9.2560e-03],
          [-5.6324e-02,  8.5367e-02,  6.7814e-02]]],


        ...,


        [[[ 2.4545e-01,  2.1671e-02,  9.1752e-03],
          [ 1.8654e-01, -1.9423e-01, -1.8371e-02],
          [-9.5320e-02, -1.3698e-01, -1.0154e-01]],

         [[-3.9291e-02,  3.0756e-03, -1.0165e-01],
          [-1.5927e-01, -2.1298e-01,  1.5039e-01],
          [-4.8516e-02,  2.6963e-01,  2.3522e-01]],

         [[-5.0723e-02, -4.1134e-02,  2.4924e-01],
          [ 2.1151e-02, -2.4449e-01, -7.6259e-02],
          [ 2.7065e-02, -3.3085e-02, -3.4968e-02]]],


        [[[ 6.6201e-02, -2.6443e-02,  1.7657e-01],
          [ 1.8625e-01,  1.1969e-01, -1.9428e-02],
          [-2.1373e-01, -1.3386e-01, -5.7542e-02]],

         [[ 7.8060e-02,  2.1567e-02, -1.3469e-01],
          [ 5.7156e-02, -4.1946e-02, -2.6409e-01],
          [ 2.4783e-02,  1.6121e-01, -2.8070e-02]],

         [[-1.2947e-01, -2.5786e-02, -2.4010e-01],
          [-6.2127e-02,  6.8073e-02,  3.4600e-02],
          [ 1.6493e-01,  1.1627e-01,  6.3094e-02]]],


        [[[-5.3953e-10,  9.6906e-09, -8.4689e-07],
          [ 3.8472e-10,  8.4010e-08, -2.5122e-06],
          [ 1.5096e-09,  1.3619e-07,  5.5686e-07]],

         [[-4.4551e-09, -2.9953e-09, -6.9673e-08],
          [ 7.4719e-09, -5.3370e-09, -4.7186e-08],
          [-1.1698e-08, -2.7443e-08, -1.2689e-07]],

         [[ 2.1175e-07,  6.3420e-08, -2.7454e-07],
          [-6.4427e-08, -2.1281e-07, -6.0826e-08],
          [ 1.0083e-07,  2.0247e-08, -5.2906e-07]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0168,  0.0225,  0.0245],
          [ 0.0294,  0.0309,  0.0329],
          [ 0.0262,  0.0374,  0.0325]],

         [[ 0.0239,  0.0216,  0.0235],
          [ 0.0369,  0.0294,  0.0314],
          [ 0.0310,  0.0366,  0.0331]],

         [[ 0.0258,  0.0197,  0.0181],
          [ 0.0366,  0.0277,  0.0239],
          [ 0.0337,  0.0356,  0.0266]]],


        [[[ 0.0013,  0.0031,  0.0026],
          [ 0.0050,  0.0039,  0.0037],
          [ 0.0032,  0.0023,  0.0027]],

         [[ 0.0014,  0.0028,  0.0021],
          [ 0.0051,  0.0038,  0.0029],
          [ 0.0023,  0.0014,  0.0021]],

         [[ 0.0002,  0.0028,  0.0026],
          [ 0.0035,  0.0036,  0.0035],
          [ 0.0023,  0.0021,  0.0028]]],


        [[[-0.0340, -0.0101, -0.0110],
          [-0.0252,  0.0056, -0.0171],
          [ 0.0106,  0.0278,  0.0033]],

         [[-0.0519, -0.0262, -0.0272],
          [-0.0472, -0.0154, -0.0371],
          [-0.0129,  0.0029, -0.0244]],

         [[-0.0685, -0.0514, -0.0525],
          [-0.0624, -0.0408, -0.0595],
          [-0.0327, -0.0234, -0.0507]]],


        ...,


        [[[ 0.0045,  0.0079,  0.0133],
          [ 0.0046,  0.0100,  0.0138],
          [ 0.0118,  0.0152,  0.0239]],

         [[ 0.0017,  0.0043,  0.0093],
          [ 0.0005,  0.0037,  0.0075],
          [ 0.0094,  0.0067,  0.0165]],

         [[ 0.0019,  0.0061,  0.0094],
          [-0.0055, -0.0002,  0.0046],
          [ 0.0006,  0.0022,  0.0150]]],


        [[[ 0.0108, -0.0055, -0.0199],
          [-0.0232, -0.0156, -0.0204],
          [-0.0271, -0.0247, -0.0184]],

         [[ 0.0115, -0.0004, -0.0137],
          [-0.0201, -0.0096, -0.0155],
          [-0.0219, -0.0192, -0.0182]],

         [[ 0.0352,  0.0256,  0.0169],
          [ 0.0101,  0.0188,  0.0178],
          [ 0.0078,  0.0100,  0.0145]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5216]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 21 | Batch_idx: 0 |  Loss: (0.3891) | Acc: (85.00%) (110/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.4257) | Acc: (86.00%) (1214/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.4228) | Acc: (85.00%) (2298/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.4119) | Acc: (85.00%) (3407/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.4021) | Acc: (86.00%) (4528/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.3923) | Acc: (86.00%) (5645/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.3911) | Acc: (86.00%) (6766/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.4012) | Acc: (86.00%) (7839/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.3988) | Acc: (86.00%) (8952/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.4004) | Acc: (86.00%) (10045/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.4059) | Acc: (86.00%) (11125/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.4029) | Acc: (86.00%) (12245/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.3990) | Acc: (86.00%) (13362/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.3978) | Acc: (86.00%) (14477/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.3973) | Acc: (86.00%) (15579/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.3950) | Acc: (86.00%) (16695/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.3930) | Acc: (86.00%) (17817/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.3942) | Acc: (86.00%) (18928/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.3941) | Acc: (86.00%) (20028/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.3943) | Acc: (86.00%) (21134/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.3924) | Acc: (86.00%) (22262/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.3916) | Acc: (86.00%) (23379/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.3903) | Acc: (86.00%) (24493/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.3890) | Acc: (86.00%) (25616/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.3901) | Acc: (86.00%) (26709/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.3904) | Acc: (86.00%) (27820/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.3899) | Acc: (86.00%) (28918/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.3906) | Acc: (86.00%) (30017/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.3912) | Acc: (86.00%) (31116/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.3908) | Acc: (86.00%) (32238/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.3895) | Acc: (86.00%) (33368/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.3882) | Acc: (86.00%) (34487/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.3889) | Acc: (86.00%) (35595/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.3886) | Acc: (86.00%) (36715/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.3893) | Acc: (86.00%) (37822/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.3884) | Acc: (86.00%) (38950/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.3879) | Acc: (86.00%) (40065/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.3881) | Acc: (86.00%) (41179/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.3887) | Acc: (86.00%) (42285/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.3898) | Acc: (86.00%) (43321/50000)
# TEST : Loss: (0.5012) | Acc: (83.00%) (8357/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1944e-01, -2.1327e-01,  8.6992e-02],
          [-8.3004e-02,  2.3577e-01,  1.3984e-01],
          [ 9.5859e-02,  8.1736e-04, -1.0891e-01]],

         [[-2.3267e-01,  1.9821e-01,  1.8087e-01],
          [-2.2445e-02,  2.4023e-01,  1.1657e-01],
          [ 1.8551e-01, -1.4167e-01,  1.3382e-01]],

         [[-1.6244e-01,  1.0587e-02, -2.0748e-02],
          [-2.0853e-01, -3.1260e-02, -3.7747e-02],
          [-1.7349e-01, -1.2919e-02, -1.0691e-01]]],


        [[[ 1.3552e-01, -1.3942e-01,  1.0682e-01],
          [-5.8204e-02, -1.0693e-01,  7.3394e-02],
          [ 1.5017e-01,  2.3595e-02, -1.9740e-01]],

         [[-1.1624e-01,  2.4433e-02, -3.6429e-02],
          [ 8.3850e-02,  5.0507e-02,  8.9646e-02],
          [ 1.2075e-01,  1.6256e-01, -1.8931e-01]],

         [[ 4.9040e-02, -1.4546e-01,  4.1476e-02],
          [-1.4470e-01,  1.2567e-01,  1.6486e-01],
          [ 4.3638e-02, -1.8263e-02, -9.0182e-02]]],


        [[[ 6.4087e-02,  1.1805e-01, -9.2594e-02],
          [ 1.6944e-02,  1.5776e-01, -1.1975e-01],
          [ 6.3510e-02,  2.3670e-01,  1.9554e-01]],

         [[-1.7104e-01,  1.5648e-02, -1.5261e-01],
          [-1.8610e-01, -9.9075e-02, -1.9503e-01],
          [-1.8062e-01, -2.4922e-01,  4.9487e-02]],

         [[ 1.6387e-01,  3.5436e-03,  1.9507e-01],
          [ 1.6602e-01,  4.2501e-02,  1.6668e-02],
          [-5.3097e-02,  8.8055e-02,  7.0279e-02]]],


        ...,


        [[[ 2.3717e-01,  1.9495e-02,  4.9130e-03],
          [ 1.8736e-01, -2.0269e-01, -3.2518e-02],
          [-9.5266e-02, -1.4106e-01, -1.1213e-01]],

         [[-5.3831e-02,  4.5132e-05, -9.9096e-02],
          [-1.5910e-01, -2.1357e-01,  1.4930e-01],
          [-4.8848e-02,  2.7590e-01,  2.3742e-01]],

         [[-5.4672e-02, -4.1136e-02,  2.4998e-01],
          [ 2.5672e-02, -2.4991e-01, -8.6972e-02],
          [ 2.4798e-02, -3.3205e-02, -4.4953e-02]]],


        [[[ 6.8977e-02, -1.7106e-02,  1.8603e-01],
          [ 1.8422e-01,  1.2827e-01, -1.1147e-02],
          [-2.2140e-01, -1.3260e-01, -5.2916e-02]],

         [[ 7.4255e-02,  1.5421e-02, -1.4295e-01],
          [ 4.9401e-02, -4.4653e-02, -2.6951e-01],
          [ 1.2949e-02,  1.5703e-01, -2.7251e-02]],

         [[-1.2751e-01, -2.3646e-02, -2.3950e-01],
          [-5.7362e-02,  7.9895e-02,  4.0780e-02],
          [ 1.6713e-01,  1.3047e-01,  7.8995e-02]]],


        [[[-6.9108e-12,  3.7670e-10, -7.2966e-08],
          [ 5.2741e-12,  3.8639e-09, -2.4888e-07],
          [ 2.3776e-11,  6.4935e-09,  5.4438e-08]],

         [[-1.0336e-10, -6.6948e-11, -2.5324e-09],
          [ 1.7758e-10, -1.3244e-10, -2.1107e-09],
          [-2.6960e-10, -7.2801e-10, -5.9276e-09]],

         [[ 1.0124e-08,  2.6966e-09, -1.2564e-08],
          [-2.9884e-09, -9.1619e-09, -3.0466e-09],
          [ 4.2747e-09,  8.2970e-10, -2.6854e-08]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0311, -0.0254, -0.0208],
          [-0.0301, -0.0217, -0.0134],
          [-0.0350, -0.0202, -0.0103]],

         [[-0.0211, -0.0176, -0.0145],
          [-0.0172, -0.0110, -0.0040],
          [-0.0187, -0.0053,  0.0018]],

         [[-0.0143, -0.0113, -0.0102],
          [-0.0124, -0.0046,  0.0018],
          [-0.0106,  0.0034,  0.0110]]],


        [[[-0.0008, -0.0022, -0.0020],
          [ 0.0006, -0.0005, -0.0007],
          [ 0.0009,  0.0014,  0.0017]],

         [[-0.0002, -0.0011, -0.0008],
          [ 0.0015,  0.0003,  0.0000],
          [ 0.0019,  0.0023,  0.0020]],

         [[ 0.0001, -0.0010, -0.0009],
          [ 0.0017,  0.0001,  0.0001],
          [ 0.0024,  0.0025,  0.0017]]],


        [[[ 0.0545,  0.0698,  0.0659],
          [ 0.0593,  0.0614,  0.0586],
          [ 0.0619,  0.0526,  0.0137]],

         [[ 0.0587,  0.0646,  0.0538],
          [ 0.0583,  0.0582,  0.0551],
          [ 0.0561,  0.0515,  0.0157]],

         [[ 0.0627,  0.0592,  0.0498],
          [ 0.0611,  0.0606,  0.0578],
          [ 0.0575,  0.0589,  0.0307]]],


        ...,


        [[[-0.0551, -0.0415, -0.0297],
          [-0.0347, -0.0269, -0.0275],
          [-0.0343, -0.0378, -0.0346]],

         [[-0.0504, -0.0395, -0.0252],
          [-0.0285, -0.0208, -0.0206],
          [-0.0281, -0.0313, -0.0249]],

         [[-0.0359, -0.0279, -0.0132],
          [-0.0148, -0.0100, -0.0094],
          [-0.0160, -0.0201, -0.0134]]],


        [[[-0.0103, -0.0150, -0.0191],
          [-0.0041,  0.0012, -0.0020],
          [ 0.0072,  0.0154,  0.0157]],

         [[ 0.0048,  0.0003, -0.0049],
          [ 0.0107,  0.0182,  0.0127],
          [ 0.0145,  0.0248,  0.0254]],

         [[ 0.0128,  0.0070,  0.0032],
          [ 0.0206,  0.0257,  0.0180],
          [ 0.0204,  0.0288,  0.0265]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5199]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 22 | Batch_idx: 0 |  Loss: (0.3778) | Acc: (88.00%) (113/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.4130) | Acc: (85.00%) (1205/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.4272) | Acc: (85.00%) (2304/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.4299) | Acc: (85.00%) (3394/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.4442) | Acc: (84.00%) (4458/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.4419) | Acc: (84.00%) (5530/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.4500) | Acc: (84.00%) (6605/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.4465) | Acc: (84.00%) (7690/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.4438) | Acc: (84.00%) (8792/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.4393) | Acc: (85.00%) (9903/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.4388) | Acc: (85.00%) (10998/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.4345) | Acc: (85.00%) (12105/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.4333) | Acc: (85.00%) (13210/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.4329) | Acc: (85.00%) (14299/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.4300) | Acc: (85.00%) (15396/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.4254) | Acc: (85.00%) (16524/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.4225) | Acc: (85.00%) (17639/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.4200) | Acc: (85.00%) (18758/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.4180) | Acc: (85.00%) (19867/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.4180) | Acc: (85.00%) (20969/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.4145) | Acc: (85.00%) (22098/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.4130) | Acc: (85.00%) (23203/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.4103) | Acc: (86.00%) (24331/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.4089) | Acc: (86.00%) (25450/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.4072) | Acc: (86.00%) (26580/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.4052) | Acc: (86.00%) (27713/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.4046) | Acc: (86.00%) (28827/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.4053) | Acc: (86.00%) (29926/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.4029) | Acc: (86.00%) (31059/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.4014) | Acc: (86.00%) (32182/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.4010) | Acc: (86.00%) (33294/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.3995) | Acc: (86.00%) (34405/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.3984) | Acc: (86.00%) (35523/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.3970) | Acc: (86.00%) (36645/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.3956) | Acc: (86.00%) (37781/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.3960) | Acc: (86.00%) (38876/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.3955) | Acc: (86.00%) (39987/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.3945) | Acc: (86.00%) (41114/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.3940) | Acc: (86.00%) (42224/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.3937) | Acc: (86.00%) (43300/50000)
# TEST : Loss: (0.4156) | Acc: (85.00%) (8588/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1640e-01, -2.1074e-01,  8.9515e-02],
          [-7.9464e-02,  2.3733e-01,  1.4141e-01],
          [ 1.0002e-01,  4.0819e-03, -1.0572e-01]],

         [[-2.2928e-01,  1.9996e-01,  1.8334e-01],
          [-1.9138e-02,  2.4190e-01,  1.1839e-01],
          [ 1.8921e-01, -1.3789e-01,  1.3658e-01]],

         [[-1.5977e-01,  1.2234e-02, -1.8512e-02],
          [-2.0529e-01, -2.9368e-02, -3.6221e-02],
          [-1.6988e-01, -1.0591e-02, -1.0445e-01]]],


        [[[ 1.3345e-01, -1.3598e-01,  1.0648e-01],
          [-5.6309e-02, -1.0418e-01,  7.2282e-02],
          [ 1.4786e-01,  2.2830e-02, -1.9477e-01]],

         [[-1.1462e-01,  2.4274e-02, -3.5468e-02],
          [ 8.2746e-02,  4.9706e-02,  8.7183e-02],
          [ 1.1812e-01,  1.5844e-01, -1.8720e-01]],

         [[ 4.8835e-02, -1.4205e-01,  4.1508e-02],
          [-1.4083e-01,  1.2421e-01,  1.6162e-01],
          [ 4.3083e-02, -1.8596e-02, -8.9462e-02]]],


        [[[ 6.2068e-02,  1.1587e-01, -9.4317e-02],
          [ 1.4240e-02,  1.5520e-01, -1.2141e-01],
          [ 6.0936e-02,  2.3404e-01,  1.9312e-01]],

         [[-1.7230e-01,  1.4037e-02, -1.5375e-01],
          [-1.8848e-01, -1.0126e-01, -1.9654e-01],
          [-1.8274e-01, -2.5138e-01,  4.7151e-02]],

         [[ 1.6323e-01,  3.0295e-03,  1.9440e-01],
          [ 1.6433e-01,  4.1377e-02,  1.5921e-02],
          [-5.3634e-02,  8.7205e-02,  6.9409e-02]]],


        ...,


        [[[ 2.3718e-01,  1.9150e-02,  4.7750e-03],
          [ 1.8726e-01, -2.0204e-01, -3.1292e-02],
          [-9.3137e-02, -1.3929e-01, -1.0964e-01]],

         [[-5.1367e-02,  1.4252e-03, -9.7357e-02],
          [-1.5620e-01, -2.1075e-01,  1.5183e-01],
          [-4.4899e-02,  2.7835e-01,  2.4068e-01]],

         [[-5.2099e-02, -3.9454e-02,  2.5024e-01],
          [ 2.7431e-02, -2.4746e-01, -8.4475e-02],
          [ 2.6995e-02, -3.0941e-02, -4.2182e-02]]],


        [[[ 6.8224e-02, -1.8191e-02,  1.8392e-01],
          [ 1.8376e-01,  1.2764e-01, -1.1551e-02],
          [-2.2120e-01, -1.3286e-01, -5.4116e-02]],

         [[ 7.2506e-02,  1.3753e-02, -1.4471e-01],
          [ 4.8069e-02, -4.5542e-02, -2.6958e-01],
          [ 1.1821e-02,  1.5569e-01, -2.8616e-02]],

         [[-1.2681e-01, -2.3142e-02, -2.3898e-01],
          [-5.6374e-02,  8.0613e-02,  4.1605e-02],
          [ 1.6732e-01,  1.3080e-01,  7.8691e-02]]],


        [[[-2.9355e-14,  6.6841e-12, -3.5406e-09],
          [ 2.4475e-14,  8.4907e-11, -1.4387e-08],
          [ 1.3214e-13,  1.4935e-10,  3.0950e-09]],

         [[-9.4749e-13, -5.8495e-13, -4.1250e-11],
          [ 1.6792e-12, -1.3239e-12, -4.4769e-11],
          [-2.4504e-12, -7.9275e-12, -1.3285e-10]],

         [[ 2.3369e-10,  5.3630e-11, -2.7433e-10],
          [-6.6375e-11, -1.8512e-10, -7.4593e-11],
          [ 8.4704e-11,  1.5745e-11, -6.6866e-10]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5257]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0215]], device='cuda:0')

Epoch: 23 | Batch_idx: 0 |  Loss: (0.3687) | Acc: (87.00%) (112/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.3450) | Acc: (89.00%) (1255/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.3279) | Acc: (89.00%) (2396/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.3404) | Acc: (88.00%) (3511/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.3434) | Acc: (88.00%) (4636/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.3459) | Acc: (88.00%) (5764/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.3531) | Acc: (87.00%) (6867/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.3498) | Acc: (88.00%) (8002/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.3549) | Acc: (87.00%) (9119/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.3553) | Acc: (87.00%) (10243/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.3566) | Acc: (87.00%) (11364/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.3572) | Acc: (87.00%) (12488/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.3568) | Acc: (87.00%) (13617/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.3580) | Acc: (87.00%) (14738/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.3579) | Acc: (87.00%) (15859/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.3559) | Acc: (88.00%) (17011/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.3552) | Acc: (88.00%) (18137/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.3571) | Acc: (87.00%) (19245/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.3563) | Acc: (87.00%) (20376/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.3557) | Acc: (87.00%) (21499/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.3567) | Acc: (87.00%) (22625/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.3560) | Acc: (87.00%) (23748/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.3555) | Acc: (87.00%) (24881/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.3559) | Acc: (87.00%) (26010/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.3568) | Acc: (87.00%) (27125/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.3568) | Acc: (87.00%) (28248/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.3567) | Acc: (87.00%) (29379/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.3573) | Acc: (87.00%) (30498/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.3572) | Acc: (87.00%) (31631/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.3568) | Acc: (87.00%) (32759/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.3565) | Acc: (87.00%) (33888/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.3567) | Acc: (87.00%) (34999/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.3575) | Acc: (87.00%) (36117/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.3568) | Acc: (87.00%) (37261/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.3566) | Acc: (87.00%) (38391/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.3563) | Acc: (87.00%) (39520/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.3564) | Acc: (87.00%) (40652/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.3561) | Acc: (87.00%) (41776/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.3562) | Acc: (87.00%) (42902/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.3569) | Acc: (87.00%) (43970/50000)
# TEST : Loss: (0.4055) | Acc: (86.00%) (8636/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1605e-01, -2.1005e-01,  8.9203e-02],
          [-7.9218e-02,  2.3654e-01,  1.4091e-01],
          [ 9.9713e-02,  4.0684e-03, -1.0536e-01]],

         [[-2.2853e-01,  1.9927e-01,  1.8268e-01],
          [-1.9075e-02,  2.4105e-01,  1.1796e-01],
          [ 1.8860e-01, -1.3742e-01,  1.3610e-01]],

         [[-1.5918e-01,  1.2190e-02, -1.8446e-02],
          [-2.0455e-01, -2.9263e-02, -3.6092e-02],
          [-1.6928e-01, -1.0553e-02, -1.0408e-01]]],


        [[[ 1.3080e-01, -1.3328e-01,  1.0440e-01],
          [-5.5179e-02, -1.0204e-01,  7.0814e-02],
          [ 1.4477e-01,  2.2365e-02, -1.9072e-01]],

         [[-1.1226e-01,  2.3778e-02, -3.4752e-02],
          [ 8.1000e-02,  4.8628e-02,  8.5303e-02],
          [ 1.1546e-01,  1.5496e-01, -1.8308e-01]],

         [[ 4.7773e-02, -1.3896e-01,  4.0618e-02],
          [-1.3766e-01,  1.2133e-01,  1.5792e-01],
          [ 4.2068e-02, -1.8163e-02, -8.7360e-02]]],


        [[[ 6.1992e-02,  1.1573e-01, -9.4198e-02],
          [ 1.4222e-02,  1.5501e-01, -1.2126e-01],
          [ 6.0858e-02,  2.3375e-01,  1.9287e-01]],

         [[-1.7207e-01,  1.4019e-02, -1.5355e-01],
          [-1.8823e-01, -1.0112e-01, -1.9627e-01],
          [-1.8249e-01, -2.5105e-01,  4.7089e-02]],

         [[ 1.6300e-01,  3.0254e-03,  1.9413e-01],
          [ 1.6410e-01,  4.1318e-02,  1.5898e-02],
          [-5.3557e-02,  8.7081e-02,  6.9310e-02]]],


        ...,


        [[[ 2.3637e-01,  1.9084e-02,  4.7581e-03],
          [ 1.8660e-01, -2.0129e-01, -3.1180e-02],
          [-9.2794e-02, -1.3877e-01, -1.0925e-01]],

         [[-5.1182e-02,  1.4200e-03, -9.6990e-02],
          [-1.5560e-01, -2.0990e-01,  1.5125e-01],
          [-4.4722e-02,  2.7725e-01,  2.3977e-01]],

         [[-5.1894e-02, -3.9294e-02,  2.4922e-01],
          [ 2.7311e-02, -2.4631e-01, -8.4116e-02],
          [ 2.6878e-02, -3.0806e-02, -4.2010e-02]]],


        [[[ 6.8055e-02, -1.8146e-02,  1.8347e-01],
          [ 1.8329e-01,  1.2732e-01, -1.1522e-02],
          [-2.2064e-01, -1.3252e-01, -5.3982e-02]],

         [[ 7.2320e-02,  1.3717e-02, -1.4433e-01],
          [ 4.7942e-02, -4.5420e-02, -2.6886e-01],
          [ 1.1789e-02,  1.5528e-01, -2.8542e-02]],

         [[-1.2647e-01, -2.3077e-02, -2.3828e-01],
          [-5.6218e-02,  8.0385e-02,  4.1485e-02],
          [ 1.6685e-01,  1.3044e-01,  7.8475e-02]]],


        [[[-2.8945e-17,  4.3358e-14, -8.3272e-11],
          [ 2.7177e-17,  7.2586e-13, -4.2235e-10],
          [ 1.8674e-16,  1.3541e-12,  8.8962e-11]],

         [[-2.5974e-15, -1.5054e-15, -2.3951e-13],
          [ 4.7947e-15, -4.0662e-15, -3.6568e-13],
          [-6.6420e-15, -2.7240e-14, -1.1650e-12]],

         [[ 2.1284e-12,  4.0315e-13, -2.3261e-12],
          [-5.7532e-13, -1.4204e-12, -7.3285e-13],
          [ 6.3373e-13,  1.1140e-13, -6.7131e-12]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5552]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0154]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 24 | Batch_idx: 0 |  Loss: (0.4040) | Acc: (85.00%) (110/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.3279) | Acc: (88.00%) (1244/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.3790) | Acc: (86.00%) (2331/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.4056) | Acc: (86.00%) (3413/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.4182) | Acc: (85.00%) (4485/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.4301) | Acc: (85.00%) (5565/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.4373) | Acc: (84.00%) (6624/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.4348) | Acc: (84.00%) (7702/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.4438) | Acc: (84.00%) (8771/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.4464) | Acc: (84.00%) (9848/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.4488) | Acc: (84.00%) (10926/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.4510) | Acc: (84.00%) (11987/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.4499) | Acc: (84.00%) (13061/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.4495) | Acc: (84.00%) (14150/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.4471) | Acc: (84.00%) (15254/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.4437) | Acc: (84.00%) (16367/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.4478) | Acc: (84.00%) (17428/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.4469) | Acc: (84.00%) (18523/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.4467) | Acc: (84.00%) (19614/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.4468) | Acc: (84.00%) (20705/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.4440) | Acc: (84.00%) (21817/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.4427) | Acc: (84.00%) (22895/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.4406) | Acc: (84.00%) (23998/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.4408) | Acc: (84.00%) (25089/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.4419) | Acc: (84.00%) (26166/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.4409) | Acc: (84.00%) (27255/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.4384) | Acc: (84.00%) (28372/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.4375) | Acc: (84.00%) (29467/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.4378) | Acc: (84.00%) (30554/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.4365) | Acc: (84.00%) (31652/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.4363) | Acc: (84.00%) (32736/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.4346) | Acc: (85.00%) (33852/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.4327) | Acc: (85.00%) (34962/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.4326) | Acc: (85.00%) (36056/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.4315) | Acc: (85.00%) (37172/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.4296) | Acc: (85.00%) (38287/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.4294) | Acc: (85.00%) (39387/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.4281) | Acc: (85.00%) (40504/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.4261) | Acc: (85.00%) (41626/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.4254) | Acc: (85.00%) (42685/50000)
# TEST : Loss: (0.5561) | Acc: (81.00%) (8149/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1723e-01, -2.1291e-01,  8.7035e-02],
          [-7.1448e-02,  2.4635e-01,  1.4619e-01],
          [ 1.1186e-01,  8.8570e-03, -1.0572e-01]],

         [[-2.2721e-01,  1.9948e-01,  1.8279e-01],
          [-1.0471e-02,  2.5366e-01,  1.2736e-01],
          [ 2.0302e-01, -1.3167e-01,  1.3711e-01]],

         [[-1.5958e-01,  8.5718e-03, -1.9842e-02],
          [-2.0548e-01, -2.7984e-02, -3.3321e-02],
          [-1.6378e-01, -9.7187e-03, -1.0195e-01]]],


        [[[ 1.3028e-01, -1.4556e-01,  8.7909e-02],
          [-4.4893e-02, -1.0199e-01,  5.9256e-02],
          [ 1.4154e-01,  6.3112e-03, -2.1823e-01]],

         [[-1.1560e-01, -1.0308e-03, -5.4587e-02],
          [ 7.6423e-02,  3.3197e-02,  6.6077e-02],
          [ 1.0387e-01,  1.3313e-01, -2.1210e-01]],

         [[ 3.7712e-02, -1.6073e-01,  1.8871e-02],
          [-1.3974e-01,  1.0109e-01,  1.3125e-01],
          [ 2.8072e-02, -3.8462e-02, -1.1539e-01]]],


        [[[ 5.5713e-02,  1.1608e-01, -9.0619e-02],
          [ 3.8042e-03,  1.5673e-01, -1.2446e-01],
          [ 5.9478e-02,  2.4249e-01,  2.0487e-01]],

         [[-1.7927e-01,  9.5704e-03, -1.5306e-01],
          [-2.0447e-01, -1.0856e-01, -2.0551e-01],
          [-1.9179e-01, -2.5429e-01,  5.2253e-02]],

         [[ 1.5783e-01,  2.8497e-03,  1.9284e-01],
          [ 1.5437e-01,  4.0306e-02,  1.0506e-02],
          [-5.9214e-02,  8.4270e-02,  7.0561e-02]]],


        ...,


        [[[ 2.6036e-01,  2.9016e-02,  9.3290e-03],
          [ 2.0658e-01, -1.9744e-01, -3.0415e-02],
          [-8.3925e-02, -1.3480e-01, -1.0865e-01]],

         [[-3.6103e-02,  6.7445e-03, -9.0413e-02],
          [-1.4644e-01, -2.0883e-01,  1.5029e-01],
          [-4.0644e-02,  2.8393e-01,  2.4267e-01]],

         [[-2.3638e-02, -2.8370e-02,  2.5807e-01],
          [ 4.3973e-02, -2.4425e-01, -8.9475e-02],
          [ 2.9230e-02, -3.4886e-02, -5.4188e-02]]],


        [[[ 8.0376e-02,  1.3948e-03,  1.9501e-01],
          [ 1.8502e-01,  1.3628e-01, -1.1961e-02],
          [-2.2768e-01, -1.4153e-01, -6.4704e-02]],

         [[ 8.1253e-02,  2.3589e-02, -1.3345e-01],
          [ 4.8999e-02, -3.9089e-02, -2.6644e-01],
          [ 1.2993e-02,  1.5907e-01, -2.5498e-02]],

         [[-1.3139e-01, -2.2715e-02, -2.3029e-01],
          [-6.1843e-02,  8.4243e-02,  4.8746e-02],
          [ 1.7450e-01,  1.4331e-01,  9.3381e-02]]],


        [[[-3.7954e-21,  7.5270e-17, -7.7699e-13],
          [ 4.2186e-21,  1.8152e-15, -5.2370e-12],
          [ 4.0714e-20,  3.6587e-15,  1.0738e-12]],

         [[-1.4152e-18, -7.5242e-19, -3.5882e-16],
          [ 2.7618e-18, -2.5865e-18, -8.6120e-16],
          [-3.5636e-18, -2.0177e-17, -3.0127e-15]],

         [[ 5.7857e-15,  8.5084e-16, -5.7546e-15],
          [-1.4652e-15, -3.0797e-15, -2.2006e-15],
          [ 1.3291e-15,  2.1699e-16, -2.0739e-14]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0051,  0.0077,  0.0073],
          [-0.0063,  0.0043,  0.0129],
          [-0.0013,  0.0027,  0.0126]],

         [[-0.0080, -0.0019,  0.0018],
          [-0.0185, -0.0053,  0.0063],
          [-0.0149, -0.0075,  0.0065]],

         [[ 0.0028,  0.0074,  0.0066],
          [-0.0053,  0.0075,  0.0143],
          [-0.0057,  0.0021,  0.0138]]],


        [[[-0.0027, -0.0015, -0.0010],
          [-0.0033, -0.0022, -0.0002],
          [-0.0025, -0.0015, -0.0008]],

         [[-0.0018, -0.0006, -0.0003],
          [-0.0027, -0.0014,  0.0004],
          [-0.0024, -0.0011, -0.0005]],

         [[-0.0020, -0.0014, -0.0009],
          [-0.0027, -0.0019, -0.0002],
          [-0.0021, -0.0012, -0.0006]]],


        [[[ 0.0276,  0.0204,  0.0180],
          [ 0.0204,  0.0193,  0.0002],
          [-0.0002, -0.0006, -0.0060]],

         [[ 0.0310,  0.0400,  0.0377],
          [ 0.0198,  0.0214,  0.0027],
          [ 0.0058, -0.0020, -0.0132]],

         [[ 0.0255,  0.0326,  0.0245],
          [ 0.0273,  0.0331,  0.0099],
          [ 0.0139,  0.0148,  0.0038]]],


        ...,


        [[[ 0.0060,  0.0022, -0.0061],
          [ 0.0057, -0.0003, -0.0027],
          [ 0.0003,  0.0072, -0.0092]],

         [[ 0.0091,  0.0053, -0.0038],
          [ 0.0091,  0.0027, -0.0021],
          [ 0.0048,  0.0099, -0.0076]],

         [[ 0.0128,  0.0102, -0.0003],
          [ 0.0130,  0.0061, -0.0010],
          [ 0.0136,  0.0172, -0.0029]]],


        [[[-0.0735, -0.0853, -0.0857],
          [-0.0430, -0.0521, -0.0710],
          [-0.0289, -0.0367, -0.0487]],

         [[-0.0608, -0.0709, -0.0764],
          [-0.0338, -0.0419, -0.0638],
          [-0.0191, -0.0274, -0.0424]],

         [[-0.0454, -0.0505, -0.0506],
          [-0.0271, -0.0314, -0.0461],
          [-0.0219, -0.0286, -0.0356]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5531]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 25 | Batch_idx: 0 |  Loss: (0.4295) | Acc: (85.00%) (109/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.3713) | Acc: (87.00%) (1230/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.3681) | Acc: (87.00%) (2354/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.3583) | Acc: (87.00%) (3482/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.3530) | Acc: (88.00%) (4622/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.3552) | Acc: (88.00%) (5749/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.3569) | Acc: (88.00%) (6883/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.3592) | Acc: (88.00%) (8003/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.3621) | Acc: (87.00%) (9113/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.3670) | Acc: (87.00%) (10228/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.3692) | Acc: (87.00%) (11340/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.3669) | Acc: (87.00%) (12473/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.3677) | Acc: (87.00%) (13594/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.3661) | Acc: (87.00%) (14735/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.3666) | Acc: (87.00%) (15855/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.3653) | Acc: (87.00%) (16984/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.3647) | Acc: (87.00%) (18109/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.3634) | Acc: (87.00%) (19237/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.3619) | Acc: (87.00%) (20370/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.3642) | Acc: (87.00%) (21484/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.3643) | Acc: (87.00%) (22604/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.3659) | Acc: (87.00%) (23712/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.3655) | Acc: (87.00%) (24831/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.3659) | Acc: (87.00%) (25946/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.3667) | Acc: (87.00%) (27057/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.3673) | Acc: (87.00%) (28173/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.3656) | Acc: (87.00%) (29316/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.3661) | Acc: (87.00%) (30431/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.3667) | Acc: (87.00%) (31535/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.3663) | Acc: (87.00%) (32661/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.3656) | Acc: (87.00%) (33787/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.3648) | Acc: (87.00%) (34915/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.3648) | Acc: (87.00%) (36032/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.3643) | Acc: (87.00%) (37157/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.3633) | Acc: (87.00%) (38283/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.3624) | Acc: (87.00%) (39413/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.3618) | Acc: (87.00%) (40541/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.3622) | Acc: (87.00%) (41651/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.3621) | Acc: (87.00%) (42771/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.3609) | Acc: (87.00%) (43881/50000)
# TEST : Loss: (0.4100) | Acc: (86.00%) (8655/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2526e-01, -2.2647e-01,  7.7121e-02],
          [-8.0695e-02,  2.3736e-01,  1.3682e-01],
          [ 1.0102e-01, -7.1867e-03, -1.1886e-01]],

         [[-2.3278e-01,  1.9419e-01,  1.8242e-01],
          [-1.7645e-02,  2.5194e-01,  1.2576e-01],
          [ 1.9355e-01, -1.4332e-01,  1.2807e-01]],

         [[-1.6786e-01, -4.9770e-03, -2.8403e-02],
          [-2.1654e-01, -3.9157e-02, -4.5365e-02],
          [-1.7132e-01, -2.4114e-02, -1.1556e-01]]],


        [[[ 1.2234e-01, -1.3171e-01,  1.0215e-01],
          [-5.1764e-02, -9.7622e-02,  7.1582e-02],
          [ 1.4753e-01,  1.1994e-02, -2.1414e-01]],

         [[-1.2355e-01,  7.0392e-03, -3.6589e-02],
          [ 6.0846e-02,  3.3329e-02,  7.7727e-02],
          [ 1.0238e-01,  1.3357e-01, -2.0940e-01]],

         [[ 3.3228e-02, -1.4665e-01,  3.5085e-02],
          [-1.4895e-01,  9.8041e-02,  1.4242e-01],
          [ 2.8792e-02, -3.6408e-02, -1.1035e-01]]],


        [[[ 5.1463e-02,  1.1114e-01, -8.9242e-02],
          [-8.7403e-04,  1.4908e-01, -1.2665e-01],
          [ 6.2908e-02,  2.4037e-01,  2.0760e-01]],

         [[-1.8396e-01,  1.7781e-03, -1.5194e-01],
          [-2.0982e-01, -1.2045e-01, -2.0767e-01],
          [-1.8585e-01, -2.5808e-01,  5.5851e-02]],

         [[ 1.6200e-01,  5.0874e-03,  1.9782e-01],
          [ 1.6471e-01,  4.5145e-02,  1.7461e-02],
          [-4.2642e-02,  9.2353e-02,  7.7651e-02]]],


        ...,


        [[[ 2.5987e-01,  2.2265e-02,  2.5841e-03],
          [ 2.1418e-01, -1.9661e-01, -3.2536e-02],
          [-7.9903e-02, -1.2958e-01, -1.0703e-01]],

         [[-4.5843e-02, -1.1444e-02, -1.0246e-01],
          [-1.4549e-01, -2.0943e-01,  1.4977e-01],
          [-3.5237e-02,  2.9619e-01,  2.4738e-01]],

         [[-2.3475e-02, -3.9871e-02,  2.4791e-01],
          [ 4.2195e-02, -2.5179e-01, -9.9134e-02],
          [ 3.0229e-02, -3.7722e-02, -6.5089e-02]]],


        [[[ 7.3400e-02, -2.0030e-03,  1.9018e-01],
          [ 1.7955e-01,  1.3078e-01, -2.0374e-02],
          [-2.3739e-01, -1.5417e-01, -7.6577e-02]],

         [[ 7.7484e-02,  1.6564e-02, -1.4128e-01],
          [ 5.1247e-02, -4.3707e-02, -2.7701e-01],
          [ 1.3899e-02,  1.5465e-01, -3.5940e-02]],

         [[-1.3428e-01, -2.6539e-02, -2.3166e-01],
          [-5.9410e-02,  8.6718e-02,  4.8849e-02],
          [ 1.7371e-01,  1.4623e-01,  9.3128e-02]]],


        [[[-2.3240e-26,  2.1867e-20, -2.1803e-15],
          [ 3.4026e-26,  8.7239e-19, -2.1327e-14],
          [ 5.6425e-25,  1.9546e-18,  4.2214e-15]],

         [[-7.8674e-23, -3.6832e-23, -8.4896e-20],
          [ 1.6660e-22, -1.8039e-22, -3.8118e-19],
          [-1.9368e-22, -1.7551e-21, -1.5158e-18]],

         [[ 3.1163e-18,  3.2388e-19, -2.7250e-18],
          [-7.2192e-19, -1.2167e-18, -1.3575e-18],
          [ 5.0156e-19,  7.3946e-20, -1.3297e-17]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0052,  0.0005,  0.0059],
          [ 0.0015,  0.0056,  0.0047],
          [-0.0005,  0.0054,  0.0016]],

         [[-0.0029,  0.0025,  0.0065],
          [ 0.0032,  0.0065,  0.0056],
          [-0.0010,  0.0040,  0.0012]],

         [[ 0.0070,  0.0127,  0.0177],
          [ 0.0102,  0.0129,  0.0125],
          [ 0.0046,  0.0081,  0.0047]]],


        [[[-0.0039, -0.0048, -0.0050],
          [-0.0033, -0.0045, -0.0054],
          [-0.0049, -0.0049, -0.0043]],

         [[-0.0050, -0.0056, -0.0051],
          [-0.0040, -0.0051, -0.0054],
          [-0.0049, -0.0050, -0.0043]],

         [[-0.0049, -0.0055, -0.0052],
          [-0.0040, -0.0051, -0.0058],
          [-0.0052, -0.0052, -0.0047]]],


        [[[-0.0514, -0.0582, -0.0710],
          [-0.0462, -0.0521, -0.0654],
          [-0.0433, -0.0581, -0.0662]],

         [[-0.0473, -0.0594, -0.0795],
          [-0.0395, -0.0453, -0.0648],
          [-0.0346, -0.0435, -0.0545]],

         [[-0.0373, -0.0506, -0.0692],
          [-0.0206, -0.0288, -0.0431],
          [-0.0134, -0.0270, -0.0346]]],


        ...,


        [[[ 0.0022,  0.0137,  0.0257],
          [-0.0075,  0.0103,  0.0100],
          [ 0.0042,  0.0145,  0.0153]],

         [[-0.0028,  0.0094,  0.0256],
          [-0.0067,  0.0121,  0.0146],
          [ 0.0076,  0.0192,  0.0203]],

         [[-0.0012,  0.0096,  0.0218],
          [-0.0035,  0.0141,  0.0137],
          [ 0.0075,  0.0180,  0.0175]]],


        [[[-0.0680, -0.0607, -0.0684],
          [-0.0781, -0.0706, -0.0599],
          [-0.0670, -0.0622, -0.0522]],

         [[-0.0551, -0.0493, -0.0575],
          [-0.0612, -0.0550, -0.0469],
          [-0.0505, -0.0429, -0.0370]],

         [[-0.0347, -0.0354, -0.0464],
          [-0.0426, -0.0438, -0.0393],
          [-0.0329, -0.0313, -0.0285]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5511]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 26 | Batch_idx: 0 |  Loss: (0.1921) | Acc: (95.00%) (122/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.3206) | Acc: (88.00%) (1246/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.3555) | Acc: (87.00%) (2352/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.3879) | Acc: (86.00%) (3439/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.3885) | Acc: (86.00%) (4560/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.3935) | Acc: (86.00%) (5666/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.3931) | Acc: (86.00%) (6771/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.3919) | Acc: (86.00%) (7884/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.3911) | Acc: (86.00%) (8992/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.3883) | Acc: (86.00%) (10114/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.3844) | Acc: (86.00%) (11243/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.3809) | Acc: (87.00%) (12367/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.3783) | Acc: (87.00%) (13491/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.3757) | Acc: (87.00%) (14630/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.3748) | Acc: (87.00%) (15747/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.3726) | Acc: (87.00%) (16879/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.3696) | Acc: (87.00%) (18016/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.3685) | Acc: (87.00%) (19146/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.3677) | Acc: (87.00%) (20254/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.3645) | Acc: (87.00%) (21401/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.3654) | Acc: (87.00%) (22520/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.3639) | Acc: (87.00%) (23658/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.3642) | Acc: (87.00%) (24772/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.3637) | Acc: (87.00%) (25898/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.3632) | Acc: (87.00%) (27035/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.3609) | Acc: (87.00%) (28189/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.3610) | Acc: (87.00%) (29314/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.3610) | Acc: (87.00%) (30444/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.3602) | Acc: (87.00%) (31579/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.3583) | Acc: (87.00%) (32726/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.3576) | Acc: (87.00%) (33864/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.3576) | Acc: (87.00%) (34995/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.3581) | Acc: (87.00%) (36102/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.3575) | Acc: (87.00%) (37231/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.3569) | Acc: (87.00%) (38369/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.3560) | Acc: (87.00%) (39518/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.3544) | Acc: (88.00%) (40668/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.3544) | Acc: (88.00%) (41793/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.3526) | Acc: (88.00%) (42954/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.3519) | Acc: (88.00%) (44049/50000)
# TEST : Loss: (0.3692) | Acc: (87.00%) (8774/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2472e-01, -2.2560e-01,  7.7038e-02],
          [-8.0647e-02,  2.3700e-01,  1.3724e-01],
          [ 1.0258e-01, -5.5254e-03, -1.1678e-01]],

         [[-2.3131e-01,  1.9477e-01,  1.8288e-01],
          [-1.7205e-02,  2.5209e-01,  1.2688e-01],
          [ 1.9543e-01, -1.4047e-01,  1.3025e-01]],

         [[-1.6622e-01, -3.8104e-03, -2.7655e-02],
          [-2.1544e-01, -3.8479e-02, -4.4447e-02],
          [-1.6860e-01, -2.2104e-02, -1.1351e-01]]],


        [[[ 1.2207e-01, -1.2615e-01,  1.0273e-01],
          [-4.8414e-02, -9.3768e-02,  7.1811e-02],
          [ 1.4630e-01,  1.2902e-02, -2.0802e-01]],

         [[-1.1697e-01,  9.9006e-03, -3.2716e-02],
          [ 6.2632e-02,  3.4446e-02,  7.7485e-02],
          [ 1.0335e-01,  1.3221e-01, -2.0275e-01]],

         [[ 3.6971e-02, -1.3868e-01,  3.8376e-02],
          [-1.4132e-01,  9.8315e-02,  1.4124e-01],
          [ 3.2455e-02, -3.2813e-02, -1.0522e-01]]],


        [[[ 5.2998e-02,  1.1279e-01, -8.6883e-02],
          [-6.6040e-04,  1.4957e-01, -1.2526e-01],
          [ 6.3735e-02,  2.4165e-01,  2.0918e-01]],

         [[-1.8164e-01,  3.9837e-03, -1.4929e-01],
          [-2.0913e-01, -1.1941e-01, -2.0613e-01],
          [-1.8442e-01, -2.5605e-01,  5.7404e-02]],

         [[ 1.6370e-01,  7.3881e-03,  2.0014e-01],
          [ 1.6449e-01,  4.5902e-02,  1.8626e-02],
          [-4.2187e-02,  9.3575e-02,  7.8867e-02]]],


        ...,


        [[[ 2.6228e-01,  2.4660e-02,  4.1298e-03],
          [ 2.1639e-01, -1.9424e-01, -3.0192e-02],
          [-7.8944e-02, -1.2895e-01, -1.0624e-01]],

         [[-4.3660e-02, -1.0629e-02, -1.0276e-01],
          [-1.4285e-01, -2.0794e-01,  1.4996e-01],
          [-3.4893e-02,  2.9447e-01,  2.4558e-01]],

         [[-2.3895e-02, -4.1112e-02,  2.4517e-01],
          [ 4.1993e-02, -2.5202e-01, -9.9552e-02],
          [ 2.8235e-02, -4.0385e-02, -6.7743e-02]]],


        [[[ 8.1163e-02,  5.3472e-03,  1.9756e-01],
          [ 1.8657e-01,  1.3711e-01, -1.4426e-02],
          [-2.3161e-01, -1.4906e-01, -7.1634e-02]],

         [[ 8.4722e-02,  2.3346e-02, -1.3353e-01],
          [ 5.8069e-02, -3.7259e-02, -2.7028e-01],
          [ 1.9312e-02,  1.5928e-01, -3.0566e-02]],

         [[-1.2886e-01, -2.1382e-02, -2.2465e-01],
          [-5.4424e-02,  9.1414e-02,  5.4336e-02],
          [ 1.7747e-01,  1.4986e-01,  9.7955e-02]]],


        [[[ 6.8376e-35,  4.7308e-25, -1.2265e-18],
          [ 1.8307e-34,  4.0299e-23, -1.9871e-17],
          [ 3.4358e-32,  1.0556e-22,  3.7511e-18]],

         [[-1.0838e-28, -3.9989e-29, -1.3371e-24],
          [ 2.6665e-28, -3.7512e-28, -1.5581e-23],
          [-2.5585e-28, -5.3797e-27, -7.4937e-23]],

         [[ 1.7035e-22,  1.0563e-23, -1.2315e-22],
          [-3.4601e-23, -4.1965e-23, -9.0536e-23],
          [ 1.6146e-23,  2.0405e-24, -9.3818e-22]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5643]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0310]], device='cuda:0')

Epoch: 27 | Batch_idx: 0 |  Loss: (0.2799) | Acc: (90.00%) (116/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.3154) | Acc: (89.00%) (1255/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.3367) | Acc: (88.00%) (2373/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.3325) | Acc: (88.00%) (3510/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.3354) | Acc: (88.00%) (4640/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.3387) | Acc: (88.00%) (5756/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.3407) | Acc: (88.00%) (6892/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.3371) | Acc: (88.00%) (8036/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.3338) | Acc: (88.00%) (9169/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.3332) | Acc: (88.00%) (10305/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.3273) | Acc: (88.00%) (11464/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.3305) | Acc: (88.00%) (12583/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.3301) | Acc: (88.00%) (13719/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.3285) | Acc: (88.00%) (14867/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.3261) | Acc: (88.00%) (16022/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.3271) | Acc: (88.00%) (17155/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.3265) | Acc: (88.00%) (18310/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.3238) | Acc: (88.00%) (19466/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.3238) | Acc: (88.00%) (20615/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.3238) | Acc: (88.00%) (21758/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.3232) | Acc: (89.00%) (22910/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.3217) | Acc: (89.00%) (24075/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.3220) | Acc: (89.00%) (25213/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.3224) | Acc: (89.00%) (26364/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.3224) | Acc: (89.00%) (27509/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.3224) | Acc: (89.00%) (28651/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.3215) | Acc: (89.00%) (29803/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.3201) | Acc: (89.00%) (30970/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.3209) | Acc: (89.00%) (32095/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.3209) | Acc: (89.00%) (33245/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.3209) | Acc: (89.00%) (34379/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.3205) | Acc: (89.00%) (35512/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.3206) | Acc: (89.00%) (36649/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.3218) | Acc: (89.00%) (37775/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.3219) | Acc: (89.00%) (38909/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.3218) | Acc: (89.00%) (40051/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.3214) | Acc: (89.00%) (41207/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.3209) | Acc: (89.00%) (42353/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.3205) | Acc: (89.00%) (43497/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.3203) | Acc: (89.00%) (44608/50000)
# TEST : Loss: (0.3589) | Acc: (88.00%) (8812/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2436e-01, -2.2493e-01,  7.6798e-02],
          [-8.0413e-02,  2.3628e-01,  1.3680e-01],
          [ 1.0228e-01, -5.5087e-03, -1.1641e-01]],

         [[-2.3060e-01,  1.9415e-01,  1.8228e-01],
          [-1.7151e-02,  2.5128e-01,  1.2646e-01],
          [ 1.9483e-01, -1.4001e-01,  1.2982e-01]],

         [[-1.6563e-01, -3.7971e-03, -2.7561e-02],
          [-2.1467e-01, -3.8346e-02, -4.4297e-02],
          [-1.6802e-01, -2.2028e-02, -1.1312e-01]]],


        [[[ 1.1857e-01, -1.2255e-01,  9.9815e-02],
          [-4.7030e-02, -9.1035e-02,  6.9733e-02],
          [ 1.4189e-01,  1.2524e-02, -2.0179e-01]],

         [[-1.1358e-01,  9.6121e-03, -3.1763e-02],
          [ 6.0802e-02,  3.3406e-02,  7.5143e-02],
          [ 1.0008e-01,  1.2817e-01, -1.9646e-01]],

         [[ 3.5844e-02, -1.3441e-01,  3.7207e-02],
          [-1.3692e-01,  9.5159e-02,  1.3675e-01],
          [ 3.1389e-02, -3.1765e-02, -1.0178e-01]]],


        [[[ 5.2930e-02,  1.1264e-01, -8.6771e-02],
          [-6.5956e-04,  1.4938e-01, -1.2510e-01],
          [ 6.3649e-02,  2.4133e-01,  2.0890e-01]],

         [[-1.8139e-01,  3.9781e-03, -1.4908e-01],
          [-2.0884e-01, -1.1925e-01, -2.0584e-01],
          [-1.8415e-01, -2.5569e-01,  5.7324e-02]],

         [[ 1.6346e-01,  7.3771e-03,  1.9984e-01],
          [ 1.6425e-01,  4.5833e-02,  1.8598e-02],
          [-4.2122e-02,  9.3433e-02,  7.8747e-02]]],


        ...,


        [[[ 2.6141e-01,  2.4579e-02,  4.1158e-03],
          [ 2.1566e-01, -1.9357e-01, -3.0091e-02],
          [-7.8676e-02, -1.2851e-01, -1.0589e-01]],

         [[-4.3507e-02, -1.0591e-02, -1.0238e-01],
          [-1.4234e-01, -2.0715e-01,  1.4941e-01],
          [-3.4765e-02,  2.9340e-01,  2.4472e-01]],

         [[-2.3806e-02, -4.0956e-02,  2.4426e-01],
          [ 4.1822e-02, -2.5093e-01, -9.9160e-02],
          [ 2.8122e-02, -4.0223e-02, -6.7488e-02]]],


        [[[ 8.0978e-02,  5.3351e-03,  1.9712e-01],
          [ 1.8613e-01,  1.3680e-01, -1.4393e-02],
          [-2.3107e-01, -1.4872e-01, -7.1477e-02]],

         [[ 8.4526e-02,  2.3291e-02, -1.3321e-01],
          [ 5.7930e-02, -3.7170e-02, -2.6964e-01],
          [ 1.9266e-02,  1.5890e-01, -3.0496e-02]],

         [[-1.2854e-01, -2.1328e-02, -2.2407e-01],
          [-5.4288e-02,  9.1184e-02,  5.4198e-02],
          [ 1.7702e-01,  1.4949e-01,  9.7716e-02]]],


        [[[-1.6670e-41,  9.3225e-32, -7.1471e-23],
          [ 5.1352e-41,  3.9184e-29, -2.4038e-21],
          [-3.5572e-41,  1.3783e-28,  4.2400e-22]],

         [[ 5.1940e-38, -1.1328e-38, -1.1767e-31],
          [-2.9549e-37,  9.1841e-37, -1.1952e-29],
          [ 8.2849e-38,  2.4941e-35, -8.2901e-29]],

         [[ 2.2747e-28,  5.1409e-30, -1.1481e-28],
          [-3.6096e-29, -2.2913e-29, -1.7380e-28],
          [ 7.6487e-30,  6.9690e-31, -1.9918e-27]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5161]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0304]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 28 | Batch_idx: 0 |  Loss: (0.2764) | Acc: (91.00%) (117/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.3237) | Acc: (88.00%) (1242/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.3209) | Acc: (88.00%) (2383/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.3572) | Acc: (87.00%) (3480/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.3810) | Acc: (86.00%) (4555/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.4006) | Acc: (86.00%) (5619/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.4059) | Acc: (86.00%) (6722/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.4000) | Acc: (86.00%) (7851/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.4016) | Acc: (86.00%) (8959/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.4048) | Acc: (86.00%) (10053/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.4053) | Acc: (86.00%) (11141/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.4088) | Acc: (86.00%) (12233/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.4106) | Acc: (86.00%) (13327/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.4084) | Acc: (86.00%) (14433/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.4062) | Acc: (86.00%) (15543/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.4093) | Acc: (85.00%) (16619/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.4083) | Acc: (86.00%) (17733/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.4077) | Acc: (86.00%) (18835/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.4068) | Acc: (86.00%) (19942/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.4062) | Acc: (86.00%) (21047/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.4042) | Acc: (86.00%) (22166/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.4019) | Acc: (86.00%) (23287/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.4027) | Acc: (86.00%) (24389/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.4021) | Acc: (86.00%) (25502/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.3994) | Acc: (86.00%) (26636/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.3988) | Acc: (86.00%) (27755/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.3987) | Acc: (86.00%) (28870/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.3981) | Acc: (86.00%) (29982/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.3973) | Acc: (86.00%) (31107/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.3965) | Acc: (86.00%) (32216/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.3972) | Acc: (86.00%) (33315/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.3984) | Acc: (86.00%) (34418/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.3978) | Acc: (86.00%) (35531/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.3978) | Acc: (86.00%) (36634/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.3982) | Acc: (86.00%) (37727/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.3990) | Acc: (86.00%) (38827/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.3990) | Acc: (86.00%) (39943/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.3979) | Acc: (86.00%) (41067/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.3970) | Acc: (86.00%) (42192/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.3970) | Acc: (86.00%) (43267/50000)
# TEST : Loss: (0.4794) | Acc: (84.00%) (8428/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1911e-01, -2.1838e-01,  7.7965e-02],
          [-7.1363e-02,  2.4171e-01,  1.3923e-01],
          [ 1.1731e-01,  2.6858e-03, -1.1104e-01]],

         [[-2.2645e-01,  2.0337e-01,  1.8903e-01],
          [-1.5367e-02,  2.5415e-01,  1.2914e-01],
          [ 2.0274e-01, -1.3424e-01,  1.3552e-01]],

         [[-1.7494e-01, -7.9758e-03, -3.3134e-02],
          [-2.2703e-01, -5.0874e-02, -5.5465e-02],
          [-1.6823e-01, -2.3863e-02, -1.1273e-01]]],


        [[[ 9.5891e-02, -1.3546e-01,  8.9016e-02],
          [-6.5443e-02, -1.1256e-01,  5.1203e-02],
          [ 1.1354e-01, -1.4723e-02, -2.1958e-01]],

         [[-1.1822e-01,  6.8659e-03, -2.5239e-02],
          [ 5.2239e-02,  2.4381e-02,  7.0993e-02],
          [ 9.2139e-02,  1.2059e-01, -1.9360e-01]],

         [[ 2.6322e-02, -1.3448e-01,  4.0633e-02],
          [-1.3871e-01,  8.1782e-02,  1.3038e-01],
          [ 2.8765e-02, -3.2064e-02, -9.9614e-02]]],


        [[[ 6.2667e-02,  1.1054e-01, -8.9324e-02],
          [ 7.2415e-03,  1.4717e-01, -1.3188e-01],
          [ 7.5843e-02,  2.4167e-01,  2.0792e-01]],

         [[-1.7685e-01, -2.8476e-03, -1.5326e-01],
          [-2.0966e-01, -1.3366e-01, -2.1740e-01],
          [-1.7849e-01, -2.7072e-01,  4.5138e-02]],

         [[ 1.7079e-01,  1.0676e-02,  2.0149e-01],
          [ 1.6611e-01,  4.3329e-02,  1.4824e-02],
          [-3.4022e-02,  8.7111e-02,  7.0928e-02]]],


        ...,


        [[[ 2.5608e-01,  2.9984e-02,  1.2569e-02],
          [ 2.0790e-01, -2.0533e-01, -3.8969e-02],
          [-8.6351e-02, -1.3809e-01, -1.0785e-01]],

         [[-4.0330e-02,  1.0333e-02, -6.8260e-02],
          [-1.3314e-01, -1.9005e-01,  1.7766e-01],
          [-2.4113e-02,  3.1070e-01,  2.7530e-01]],

         [[-1.6219e-02, -2.5812e-02,  2.6040e-01],
          [ 5.4537e-02, -2.4113e-01, -8.8659e-02],
          [ 3.9091e-02, -3.1608e-02, -5.1798e-02]]],


        [[[ 6.9745e-02,  8.2446e-04,  1.9686e-01],
          [ 1.7639e-01,  1.3190e-01, -2.2258e-02],
          [-2.3687e-01, -1.5591e-01, -7.8466e-02]],

         [[ 6.7811e-02,  7.2803e-03, -1.4259e-01],
          [ 4.7134e-02, -4.9752e-02, -2.8525e-01],
          [ 1.9224e-02,  1.5434e-01, -3.5580e-02]],

         [[-1.4766e-01, -4.3397e-02, -2.3938e-01],
          [-6.0493e-02,  8.3563e-02,  4.4324e-02],
          [ 1.7970e-01,  1.5201e-01,  1.0067e-01]]],


        [[[-1.7986e-41,  2.3830e-41, -1.0739e-28],
          [ 3.6459e-41,  2.1173e-38, -1.2883e-26],
          [-6.2466e-41, -3.8939e-38,  2.0294e-27]],

         [[-5.2235e-41, -2.0407e-41,  5.7331e-41],
          [ 5.1181e-41, -2.3009e-41, -1.0834e-38],
          [-2.2704e-41,  4.3941e-41, -1.9357e-38]],

         [[-8.2597e-38,  5.4130e-39, -7.1572e-38],
          [-1.3828e-38, -2.4506e-38,  3.4955e-37],
          [ 7.9329e-39,  5.8414e-40,  5.1092e-36]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0537, -0.0480, -0.0480],
          [-0.0550, -0.0494, -0.0432],
          [-0.0537, -0.0532, -0.0372]],

         [[-0.0687, -0.0621, -0.0580],
          [-0.0625, -0.0564, -0.0476],
          [-0.0575, -0.0579, -0.0413]],

         [[-0.0544, -0.0531, -0.0484],
          [-0.0480, -0.0479, -0.0409],
          [-0.0439, -0.0499, -0.0357]]],


        [[[-0.0002, -0.0001, -0.0008],
          [-0.0001, -0.0005, -0.0006],
          [-0.0004, -0.0010, -0.0007]],

         [[-0.0000, -0.0001, -0.0009],
          [-0.0002, -0.0005, -0.0007],
          [-0.0005, -0.0010, -0.0008]],

         [[ 0.0002,  0.0004, -0.0001],
          [ 0.0002,  0.0002,  0.0000],
          [-0.0003, -0.0006, -0.0003]]],


        [[[-0.0371, -0.0098,  0.0253],
          [-0.0686, -0.0178, -0.0129],
          [-0.0838, -0.0449, -0.0426]],

         [[-0.0545, -0.0261,  0.0050],
          [-0.0723, -0.0259, -0.0254],
          [-0.0702, -0.0380, -0.0356]],

         [[-0.0452, -0.0321, -0.0006],
          [-0.0582, -0.0256, -0.0198],
          [-0.0480, -0.0238, -0.0218]]],


        ...,


        [[[-0.0674, -0.0502, -0.0395],
          [-0.0684, -0.0602, -0.0535],
          [-0.0503, -0.0432, -0.0422]],

         [[-0.0480, -0.0299, -0.0166],
          [-0.0465, -0.0368, -0.0264],
          [-0.0291, -0.0204, -0.0185]],

         [[-0.0196, -0.0035,  0.0060],
          [-0.0172, -0.0095, -0.0011],
          [-0.0038,  0.0009,  0.0025]]],


        [[[-0.0626, -0.0669, -0.0692],
          [-0.0822, -0.0721, -0.0782],
          [-0.0837, -0.0742, -0.0791]],

         [[-0.0472, -0.0554, -0.0619],
          [-0.0703, -0.0630, -0.0692],
          [-0.0776, -0.0697, -0.0706]],

         [[-0.0373, -0.0427, -0.0470],
          [-0.0629, -0.0544, -0.0567],
          [-0.0703, -0.0632, -0.0629]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5128]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 29 | Batch_idx: 0 |  Loss: (0.4234) | Acc: (84.00%) (108/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.3401) | Acc: (88.00%) (1243/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.3336) | Acc: (88.00%) (2381/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.3339) | Acc: (88.00%) (3519/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.3282) | Acc: (88.00%) (4664/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.3285) | Acc: (88.00%) (5806/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.3294) | Acc: (88.00%) (6937/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.3304) | Acc: (88.00%) (8070/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.3361) | Acc: (88.00%) (9197/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.3357) | Acc: (88.00%) (10325/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.3369) | Acc: (88.00%) (11454/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.3351) | Acc: (88.00%) (12591/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.3402) | Acc: (88.00%) (13686/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.3376) | Acc: (88.00%) (14824/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.3385) | Acc: (88.00%) (15953/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.3384) | Acc: (88.00%) (17093/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.3376) | Acc: (88.00%) (18227/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.3381) | Acc: (88.00%) (19344/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.3385) | Acc: (88.00%) (20483/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.3369) | Acc: (88.00%) (21635/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.3371) | Acc: (88.00%) (22771/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.3364) | Acc: (88.00%) (23906/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.3359) | Acc: (88.00%) (25041/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.3372) | Acc: (88.00%) (26165/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.3377) | Acc: (88.00%) (27288/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.3363) | Acc: (88.00%) (28423/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.3394) | Acc: (88.00%) (29519/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.3381) | Acc: (88.00%) (30663/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.3370) | Acc: (88.00%) (31802/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.3376) | Acc: (88.00%) (32945/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.3380) | Acc: (88.00%) (34066/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.3376) | Acc: (88.00%) (35205/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.3382) | Acc: (88.00%) (36326/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.3374) | Acc: (88.00%) (37460/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.3374) | Acc: (88.00%) (38578/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.3363) | Acc: (88.00%) (39728/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.3373) | Acc: (88.00%) (40850/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.3373) | Acc: (88.00%) (41983/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.3372) | Acc: (88.00%) (43116/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.3366) | Acc: (88.00%) (44230/50000)
# TEST : Loss: (0.4161) | Acc: (86.00%) (8643/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2210e-01, -2.2386e-01,  7.2856e-02],
          [-6.6985e-02,  2.4617e-01,  1.4764e-01],
          [ 1.2230e-01,  5.5350e-03, -1.0538e-01]],

         [[-2.2574e-01,  2.0018e-01,  1.8564e-01],
          [-9.3041e-03,  2.6115e-01,  1.4025e-01],
          [ 2.0886e-01, -1.2848e-01,  1.4101e-01]],

         [[-1.7803e-01, -1.2814e-02, -3.5954e-02],
          [-2.2333e-01, -4.9978e-02, -5.0428e-02],
          [-1.6648e-01, -2.5624e-02, -1.1334e-01]]],


        [[[ 9.1138e-02, -1.3471e-01,  8.6830e-02],
          [-6.1626e-02, -9.7850e-02,  6.6762e-02],
          [ 1.0394e-01, -1.2230e-02, -2.0658e-01]],

         [[-1.1781e-01, -2.4504e-03, -3.0126e-02],
          [ 5.1775e-02,  3.0440e-02,  8.0027e-02],
          [ 8.2944e-02,  1.1490e-01, -1.8625e-01]],

         [[ 2.5014e-02, -1.3892e-01,  3.1544e-02],
          [-1.2948e-01,  8.4643e-02,  1.3219e-01],
          [ 2.0831e-02, -3.3816e-02, -9.5171e-02]]],


        [[[ 5.4438e-02,  1.1273e-01, -8.4398e-02],
          [ 2.4819e-03,  1.5057e-01, -1.2423e-01],
          [ 7.1820e-02,  2.4470e-01,  2.2246e-01]],

         [[-1.8350e-01, -3.2671e-03, -1.5296e-01],
          [-2.1679e-01, -1.3856e-01, -2.1676e-01],
          [-1.8280e-01, -2.7533e-01,  5.1560e-02]],

         [[ 1.6278e-01,  1.2788e-02,  2.0188e-01],
          [ 1.5860e-01,  4.3118e-02,  1.7086e-02],
          [-3.9650e-02,  8.3928e-02,  7.4145e-02]]],


        ...,


        [[[ 2.5249e-01,  2.1686e-02,  1.7361e-03],
          [ 2.0799e-01, -2.1302e-01, -4.8059e-02],
          [-9.0482e-02, -1.3945e-01, -1.1321e-01]],

         [[-5.7672e-02, -8.6833e-03, -8.2777e-02],
          [-1.4281e-01, -2.0408e-01,  1.6790e-01],
          [-3.2896e-02,  3.0721e-01,  2.7114e-01]],

         [[-2.4972e-02, -4.2272e-02,  2.4018e-01],
          [ 4.4147e-02, -2.5630e-01, -1.0545e-01],
          [ 2.7885e-02, -3.8149e-02, -6.3995e-02]]],


        [[[ 8.0928e-02,  1.3081e-02,  2.0917e-01],
          [ 1.7924e-01,  1.3456e-01, -2.3546e-02],
          [-2.4948e-01, -1.6488e-01, -8.5624e-02]],

         [[ 7.0431e-02,  1.2227e-02, -1.3215e-01],
          [ 4.7204e-02, -4.9611e-02, -2.8689e-01],
          [ 9.8794e-03,  1.5085e-01, -3.7368e-02]],

         [[-1.5257e-01, -4.6369e-02, -2.3519e-01],
          [-6.5619e-02,  7.9886e-02,  4.1275e-02],
          [ 1.7031e-01,  1.5325e-01,  1.0433e-01]]],


        [[[ 6.3591e-42,  6.5214e-41,  8.9100e-38],
          [-3.1822e-41, -9.5639e-42,  6.0245e-35],
          [ 3.6917e-41,  3.5512e-41, -1.0957e-35]],

         [[-9.1827e-42,  2.9572e-41,  4.7299e-41],
          [ 1.3433e-41, -5.5273e-41,  3.5391e-41],
          [ 2.1129e-41,  2.0963e-41,  3.7933e-42]],

         [[ 1.5434e-41, -3.0981e-41,  1.4194e-41],
          [-8.2452e-42,  5.6953e-41, -2.7282e-41],
          [-1.0713e-41,  1.3495e-42,  1.3537e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0147,  0.0139,  0.0179],
          [ 0.0067,  0.0108,  0.0087],
          [ 0.0236,  0.0261,  0.0266]],

         [[ 0.0193,  0.0216,  0.0270],
          [ 0.0137,  0.0198,  0.0191],
          [ 0.0336,  0.0377,  0.0393]],

         [[ 0.0197,  0.0207,  0.0262],
          [ 0.0156,  0.0183,  0.0162],
          [ 0.0346,  0.0348,  0.0335]]],


        [[[-0.0004, -0.0005, -0.0000],
          [ 0.0004, -0.0002,  0.0002],
          [ 0.0012,  0.0009,  0.0010]],

         [[-0.0004, -0.0005, -0.0001],
          [ 0.0003, -0.0002,  0.0001],
          [ 0.0011,  0.0007,  0.0009]],

         [[-0.0008, -0.0008, -0.0004],
          [-0.0001, -0.0005, -0.0003],
          [ 0.0006,  0.0003,  0.0004]]],


        [[[-0.0151, -0.0377, -0.0538],
          [ 0.0042,  0.0023, -0.0243],
          [ 0.0108,  0.0378,  0.0258]],

         [[-0.0246, -0.0412, -0.0524],
          [-0.0094, -0.0031, -0.0219],
          [-0.0074,  0.0207,  0.0112]],

         [[-0.0549, -0.0715, -0.0769],
          [-0.0383, -0.0370, -0.0493],
          [-0.0338, -0.0122, -0.0187]]],


        ...,


        [[[ 0.0031, -0.0002, -0.0025],
          [ 0.0039, -0.0015, -0.0043],
          [-0.0157, -0.0082, -0.0133]],

         [[ 0.0058,  0.0014, -0.0018],
          [ 0.0088,  0.0026, -0.0031],
          [-0.0086, -0.0021, -0.0119]],

         [[-0.0047, -0.0104, -0.0149],
          [ 0.0032, -0.0029, -0.0098],
          [-0.0120, -0.0071, -0.0161]]],


        [[[-0.0424, -0.0603, -0.0499],
          [-0.0787, -0.0890, -0.0823],
          [-0.0921, -0.0995, -0.0910]],

         [[-0.0367, -0.0576, -0.0535],
          [-0.0741, -0.0874, -0.0877],
          [-0.0914, -0.0993, -0.0960]],

         [[-0.0242, -0.0441, -0.0453],
          [-0.0618, -0.0743, -0.0765],
          [-0.0848, -0.0887, -0.0824]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5109]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 30 | Batch_idx: 0 |  Loss: (0.2259) | Acc: (92.00%) (119/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.3552) | Acc: (87.00%) (1235/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.3829) | Acc: (86.00%) (2335/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.3999) | Acc: (86.00%) (3432/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.4055) | Acc: (86.00%) (4539/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.4092) | Acc: (86.00%) (5629/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.4014) | Acc: (86.00%) (6750/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.4060) | Acc: (86.00%) (7834/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.4091) | Acc: (86.00%) (8936/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.4073) | Acc: (86.00%) (10043/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.4007) | Acc: (86.00%) (11174/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.3945) | Acc: (86.00%) (12302/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.3923) | Acc: (86.00%) (13408/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.3888) | Acc: (86.00%) (14536/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.3875) | Acc: (86.00%) (15646/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.3819) | Acc: (86.00%) (16795/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.3809) | Acc: (86.00%) (17914/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.3791) | Acc: (87.00%) (19043/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.3762) | Acc: (87.00%) (20177/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.3754) | Acc: (87.00%) (21303/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.3740) | Acc: (87.00%) (22435/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.3718) | Acc: (87.00%) (23566/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.3708) | Acc: (87.00%) (24702/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.3693) | Acc: (87.00%) (25837/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.3681) | Acc: (87.00%) (26960/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.3670) | Acc: (87.00%) (28094/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.3640) | Acc: (87.00%) (29231/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.3637) | Acc: (87.00%) (30365/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.3638) | Acc: (87.00%) (31485/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.3615) | Acc: (87.00%) (32628/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.3615) | Acc: (87.00%) (33760/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.3605) | Acc: (87.00%) (34897/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.3587) | Acc: (87.00%) (36048/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.3572) | Acc: (87.00%) (37212/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.3563) | Acc: (87.00%) (38362/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.3550) | Acc: (87.00%) (39508/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.3532) | Acc: (87.00%) (40656/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.3525) | Acc: (88.00%) (41804/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.3515) | Acc: (88.00%) (42940/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.3496) | Acc: (88.00%) (44062/50000)
# TEST : Loss: (0.3750) | Acc: (87.00%) (8752/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1675e-01, -2.1787e-01,  7.7132e-02],
          [-6.1917e-02,  2.5084e-01,  1.5187e-01],
          [ 1.2495e-01,  8.5047e-03, -1.0303e-01]],

         [[-2.2164e-01,  2.0344e-01,  1.8755e-01],
          [-5.9395e-03,  2.6410e-01,  1.4256e-01],
          [ 2.0926e-01, -1.2723e-01,  1.4060e-01]],

         [[-1.7487e-01, -1.0107e-02, -3.4349e-02],
          [-2.2007e-01, -4.7095e-02, -4.8055e-02],
          [-1.6566e-01, -2.4997e-02, -1.1272e-01]]],


        [[[ 8.7426e-02, -1.2877e-01,  8.3158e-02],
          [-5.9881e-02, -9.3318e-02,  6.4442e-02],
          [ 9.8219e-02, -1.2492e-02, -1.9824e-01]],

         [[-1.1233e-01, -1.4940e-03, -2.8445e-02],
          [ 4.9324e-02,  2.9729e-02,  7.7316e-02],
          [ 7.8131e-02,  1.0925e-01, -1.7837e-01]],

         [[ 2.4986e-02, -1.3121e-01,  3.1428e-02],
          [-1.2366e-01,  8.1805e-02,  1.2735e-01],
          [ 1.8893e-02, -3.2473e-02, -9.0714e-02]]],


        [[[ 5.6374e-02,  1.1552e-01, -8.0226e-02],
          [ 5.8466e-03,  1.5294e-01, -1.2038e-01],
          [ 7.5530e-02,  2.4706e-01,  2.2592e-01]],

         [[-1.8057e-01,  2.3021e-04, -1.4846e-01],
          [-2.1267e-01, -1.3558e-01, -2.1269e-01],
          [-1.7824e-01, -2.7196e-01,  5.5725e-02]],

         [[ 1.6636e-01,  1.7235e-02,  2.0661e-01],
          [ 1.6311e-01,  4.6869e-02,  2.1815e-02],
          [-3.4679e-02,  8.7508e-02,  7.8858e-02]]],


        ...,


        [[[ 2.5034e-01,  2.1300e-02,  1.9621e-03],
          [ 2.0577e-01, -2.1291e-01, -4.7015e-02],
          [-9.1090e-02, -1.3994e-01, -1.1230e-01]],

         [[-5.9728e-02, -9.6355e-03, -8.2962e-02],
          [-1.4453e-01, -2.0432e-01,  1.6821e-01],
          [-3.3434e-02,  3.0560e-01,  2.7150e-01]],

         [[-2.3811e-02, -4.0143e-02,  2.4175e-01],
          [ 4.4541e-02, -2.5408e-01, -1.0266e-01],
          [ 2.8661e-02, -3.7881e-02, -6.2114e-02]]],


        [[[ 7.6387e-02,  9.0501e-03,  2.0438e-01],
          [ 1.7668e-01,  1.3222e-01, -2.6195e-02],
          [-2.4970e-01, -1.6589e-01, -8.7905e-02]],

         [[ 6.4956e-02,  7.1333e-03, -1.3731e-01],
          [ 4.3973e-02, -5.2502e-02, -2.8975e-01],
          [ 8.7189e-03,  1.4884e-01, -4.0235e-02]],

         [[-1.5707e-01, -5.0728e-02, -2.3911e-01],
          [-6.8425e-02,  7.7242e-02,  3.8491e-02],
          [ 1.6898e-01,  1.5140e-01,  1.0129e-01]]],


        [[[-4.5371e-41, -8.8380e-42, -6.6280e-41],
          [-6.3100e-41, -6.5166e-41, -7.2377e-42],
          [ 4.1134e-41, -1.0958e-41, -8.2004e-42]],

         [[-6.1891e-41, -4.3097e-41, -1.0186e-41],
          [ 4.8318e-41,  4.0462e-41,  4.7557e-41],
          [-5.9138e-41,  1.4346e-41,  5.8497e-41]],

         [[-3.5020e-41,  4.4694e-41,  6.7492e-41],
          [ 4.4116e-41, -1.8615e-41, -6.0515e-41],
          [ 5.8536e-41,  6.0037e-41, -3.0939e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4424]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0065]], device='cuda:0')

Epoch: 31 | Batch_idx: 0 |  Loss: (0.3208) | Acc: (88.00%) (113/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.3288) | Acc: (89.00%) (1260/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.3189) | Acc: (89.00%) (2417/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.3237) | Acc: (89.00%) (3549/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.3171) | Acc: (89.00%) (4700/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.3127) | Acc: (89.00%) (5851/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.3098) | Acc: (89.00%) (7009/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.3073) | Acc: (89.00%) (8158/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.3088) | Acc: (89.00%) (9306/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.3103) | Acc: (89.00%) (10451/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.3089) | Acc: (89.00%) (11601/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.3081) | Acc: (89.00%) (12762/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.3061) | Acc: (89.00%) (13922/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.3044) | Acc: (89.00%) (15079/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.3057) | Acc: (89.00%) (16214/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.3079) | Acc: (89.00%) (17338/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.3081) | Acc: (89.00%) (18491/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.3077) | Acc: (89.00%) (19638/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.3077) | Acc: (89.00%) (20796/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.3079) | Acc: (89.00%) (21943/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.3073) | Acc: (89.00%) (23088/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.3062) | Acc: (89.00%) (24250/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.3054) | Acc: (89.00%) (25404/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.3045) | Acc: (89.00%) (26560/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.3059) | Acc: (89.00%) (27697/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.3047) | Acc: (89.00%) (28857/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.3052) | Acc: (89.00%) (29995/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.3044) | Acc: (89.00%) (31163/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.3037) | Acc: (89.00%) (32316/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.3040) | Acc: (89.00%) (33459/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.3035) | Acc: (89.00%) (34619/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.3019) | Acc: (89.00%) (35781/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.3025) | Acc: (89.00%) (36935/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.3021) | Acc: (89.00%) (38086/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.3018) | Acc: (89.00%) (39234/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.3027) | Acc: (89.00%) (40359/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.3033) | Acc: (89.00%) (41502/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.3035) | Acc: (89.00%) (42652/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.3038) | Acc: (89.00%) (43798/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.3044) | Acc: (89.00%) (44900/50000)
# TEST : Loss: (0.3590) | Acc: (88.00%) (8801/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1643e-01, -2.1722e-01,  7.6892e-02],
          [-6.1737e-02,  2.5008e-01,  1.5139e-01],
          [ 1.2459e-01,  8.4787e-03, -1.0270e-01]],

         [[-2.2098e-01,  2.0281e-01,  1.8696e-01],
          [-5.9214e-03,  2.6326e-01,  1.4210e-01],
          [ 2.0863e-01, -1.2683e-01,  1.4014e-01]],

         [[-1.7428e-01, -1.0073e-02, -3.4236e-02],
          [-2.1932e-01, -4.6937e-02, -4.7897e-02],
          [-1.6511e-01, -2.4913e-02, -1.1235e-01]]],


        [[[ 8.3096e-02, -1.2229e-01,  7.9106e-02],
          [-5.6941e-02, -8.8603e-02,  6.1189e-02],
          [ 9.3311e-02, -1.1860e-02, -1.8739e-01]],

         [[-1.0669e-01, -1.4179e-03, -2.7031e-02],
          [ 4.6862e-02,  2.8188e-02,  7.3285e-02],
          [ 7.4090e-02,  1.0357e-01, -1.6830e-01]],

         [[ 2.3649e-02, -1.2413e-01,  2.9783e-02],
          [-1.1703e-01,  7.7270e-02,  1.2035e-01],
          [ 1.7865e-02, -3.0701e-02, -8.5365e-02]]],


        [[[ 5.6304e-02,  1.1537e-01, -8.0126e-02],
          [ 5.8393e-03,  1.5275e-01, -1.2023e-01],
          [ 7.5431e-02,  2.4673e-01,  2.2563e-01]],

         [[-1.8033e-01,  2.2990e-04, -1.4826e-01],
          [-2.1239e-01, -1.3539e-01, -2.1239e-01],
          [-1.7799e-01, -2.7158e-01,  5.5648e-02]],

         [[ 1.6612e-01,  1.7211e-02,  2.0632e-01],
          [ 1.6287e-01,  4.6800e-02,  2.1783e-02],
          [-3.4628e-02,  8.7377e-02,  7.8740e-02]]],


        ...,


        [[[ 2.4956e-01,  2.1232e-02,  1.9557e-03],
          [ 2.0512e-01, -2.1222e-01, -4.6865e-02],
          [-9.0798e-02, -1.3949e-01, -1.1195e-01]],

         [[-5.9526e-02, -9.6022e-03, -8.2673e-02],
          [-1.4403e-01, -2.0359e-01,  1.6763e-01],
          [-3.3317e-02,  3.0453e-01,  2.7059e-01]],

         [[-2.3725e-02, -3.9993e-02,  2.4086e-01],
          [ 4.4371e-02, -2.5305e-01, -1.0227e-01],
          [ 2.8552e-02, -3.7735e-02, -6.1889e-02]]],


        [[[ 7.6217e-02,  9.0307e-03,  2.0395e-01],
          [ 1.7627e-01,  1.3192e-01, -2.6139e-02],
          [-2.4913e-01, -1.6552e-01, -8.7716e-02]],

         [[ 6.4805e-02,  7.1170e-03, -1.3699e-01],
          [ 4.3868e-02, -5.2379e-02, -2.8908e-01],
          [ 8.6985e-03,  1.4850e-01, -4.0145e-02]],

         [[-1.5668e-01, -5.0604e-02, -2.3851e-01],
          [-6.8254e-02,  7.7052e-02,  3.8397e-02],
          [ 1.6857e-01,  1.5103e-01,  1.0104e-01]]],


        [[[-7.6749e-42,  1.9212e-41, -3.0143e-41],
          [-1.2923e-41, -1.1771e-42, -1.1348e-41],
          [-4.5395e-41,  6.9381e-41, -7.2447e-42]],

         [[ 3.1660e-41,  6.8809e-41, -8.9781e-42],
          [-9.8792e-42, -6.6308e-41,  3.9329e-41],
          [ 6.7758e-41,  6.0673e-41, -1.3822e-41]],

         [[ 4.2119e-41, -6.2498e-43,  7.8529e-42],
          [-3.1491e-41,  3.2476e-41,  3.4325e-41],
          [ 1.6147e-41,  5.3829e-41,  6.8148e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4454]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0106]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 32 | Batch_idx: 0 |  Loss: (0.2653) | Acc: (93.00%) (120/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.3177) | Acc: (89.00%) (1265/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.3415) | Acc: (88.00%) (2373/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.3604) | Acc: (87.00%) (3477/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.3786) | Acc: (86.00%) (4562/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.3966) | Acc: (86.00%) (5630/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.3993) | Acc: (86.00%) (6716/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.3992) | Acc: (86.00%) (7834/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.4011) | Acc: (86.00%) (8927/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.3982) | Acc: (86.00%) (10045/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.3922) | Acc: (86.00%) (11179/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.3885) | Acc: (86.00%) (12320/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.3864) | Acc: (86.00%) (13443/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.3832) | Acc: (86.00%) (14576/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.3865) | Acc: (86.00%) (15673/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.3874) | Acc: (86.00%) (16777/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.3880) | Acc: (86.00%) (17891/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.3890) | Acc: (86.00%) (18987/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.3908) | Acc: (86.00%) (20100/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.3905) | Acc: (86.00%) (21200/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.3879) | Acc: (86.00%) (22341/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.3861) | Acc: (86.00%) (23472/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.3851) | Acc: (86.00%) (24603/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.3838) | Acc: (87.00%) (25728/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.3825) | Acc: (87.00%) (26848/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.3829) | Acc: (87.00%) (27960/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.3822) | Acc: (87.00%) (29078/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.3821) | Acc: (87.00%) (30188/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.3813) | Acc: (87.00%) (31307/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.3814) | Acc: (87.00%) (32412/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.3809) | Acc: (86.00%) (33509/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.3793) | Acc: (87.00%) (34647/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.3783) | Acc: (87.00%) (35768/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.3777) | Acc: (87.00%) (36891/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.3772) | Acc: (87.00%) (38002/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.3762) | Acc: (87.00%) (39125/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.3762) | Acc: (87.00%) (40242/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.3756) | Acc: (87.00%) (41366/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.3749) | Acc: (87.00%) (42491/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.3742) | Acc: (87.00%) (43570/50000)
# TEST : Loss: (0.4424) | Acc: (85.00%) (8545/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2361e-01, -2.2380e-01,  7.9174e-02],
          [-6.7826e-02,  2.4774e-01,  1.6152e-01],
          [ 1.1816e-01,  1.7643e-03, -1.0079e-01]],

         [[-2.2442e-01,  2.0432e-01,  1.9600e-01],
          [-7.5386e-03,  2.6753e-01,  1.5553e-01],
          [ 2.0496e-01, -1.3050e-01,  1.4188e-01]],

         [[-1.6969e-01, -3.6766e-03, -2.2965e-02],
          [-2.1981e-01, -4.5735e-02, -3.8493e-02],
          [-1.6779e-01, -3.0774e-02, -1.1310e-01]]],


        [[[ 7.2847e-02, -1.1932e-01,  8.6529e-02],
          [-5.3041e-02, -8.7871e-02,  6.0651e-02],
          [ 9.4858e-02, -1.5899e-02, -1.8090e-01]],

         [[-1.0873e-01, -7.0269e-03, -1.5811e-02],
          [ 4.0223e-02,  1.9428e-02,  6.8174e-02],
          [ 7.4872e-02,  8.8299e-02, -1.6739e-01]],

         [[ 1.4906e-02, -1.2612e-01,  3.1862e-02],
          [-1.1341e-01,  6.7116e-02,  1.1481e-01],
          [ 2.5690e-02, -3.2358e-02, -7.9253e-02]]],


        [[[ 6.0776e-02,  1.2005e-01, -7.7535e-02],
          [ 1.3275e-02,  1.5839e-01, -1.1724e-01],
          [ 7.6848e-02,  2.5115e-01,  2.3222e-01]],

         [[-1.7866e-01,  2.5955e-03, -1.4564e-01],
          [-2.1734e-01, -1.3924e-01, -2.1003e-01],
          [-1.8966e-01, -2.8218e-01,  5.5203e-02]],

         [[ 1.6406e-01,  1.9858e-02,  2.0631e-01],
          [ 1.6408e-01,  5.3290e-02,  2.5417e-02],
          [-4.3044e-02,  8.1163e-02,  7.3505e-02]]],


        ...,


        [[[ 2.4345e-01,  2.5975e-02,  9.4332e-03],
          [ 2.0816e-01, -2.1733e-01, -4.1458e-02],
          [-8.3002e-02, -1.4655e-01, -1.1677e-01]],

         [[-7.3952e-02, -1.2650e-02, -7.7672e-02],
          [-1.5493e-01, -2.1842e-01,  1.6817e-01],
          [-3.6019e-02,  2.9399e-01,  2.6534e-01]],

         [[-4.3401e-02, -4.8026e-02,  2.3223e-01],
          [ 2.7021e-02, -2.7481e-01, -1.1842e-01],
          [ 1.5571e-02, -6.0350e-02, -8.1883e-02]]],


        [[[ 7.9888e-02,  1.7195e-02,  2.1379e-01],
          [ 1.8260e-01,  1.4344e-01, -7.2098e-03],
          [-2.5976e-01, -1.6965e-01, -8.1526e-02]],

         [[ 6.2473e-02,  3.4614e-03, -1.4190e-01],
          [ 4.7549e-02, -4.6768e-02, -2.7919e-01],
          [-2.5468e-03,  1.4552e-01, -3.3836e-02]],

         [[-1.6048e-01, -5.4304e-02, -2.3707e-01],
          [-6.6734e-02,  8.4442e-02,  5.3822e-02],
          [ 1.6116e-01,  1.5612e-01,  1.1395e-01]]],


        [[[ 7.1147e-41,  1.6126e-41, -3.1242e-41],
          [ 5.7382e-41, -2.3559e-41, -3.1305e-42],
          [ 5.4939e-41, -5.3730e-41,  2.7835e-41]],

         [[ 6.9213e-41, -3.6958e-41,  6.3739e-41],
          [-4.3789e-41, -7.0007e-41, -3.0424e-41],
          [ 5.5535e-41,  6.0319e-41,  4.3583e-41]],

         [[-7.1924e-41, -9.5260e-42,  8.5816e-42],
          [ 6.0863e-41, -3.8183e-41, -7.1201e-41],
          [-2.0648e-41, -7.1969e-41, -2.2792e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0019,  0.0049, -0.0053],
          [-0.0116, -0.0087, -0.0133],
          [-0.0186, -0.0161, -0.0146]],

         [[-0.0103, -0.0020, -0.0093],
          [-0.0204, -0.0148, -0.0173],
          [-0.0262, -0.0219, -0.0180]],

         [[-0.0202, -0.0115, -0.0135],
          [-0.0256, -0.0168, -0.0143],
          [-0.0261, -0.0176, -0.0122]]],


        [[[ 0.0006,  0.0000,  0.0002],
          [ 0.0001, -0.0001,  0.0001],
          [-0.0002, -0.0004, -0.0001]],

         [[ 0.0008,  0.0002,  0.0004],
          [ 0.0004,  0.0001,  0.0004],
          [-0.0001, -0.0003,  0.0001]],

         [[ 0.0006, -0.0000,  0.0002],
          [ 0.0003, -0.0000,  0.0002],
          [-0.0001, -0.0002,  0.0000]]],


        [[[-0.0799, -0.1172, -0.1337],
          [-0.0611, -0.0776, -0.0762],
          [-0.0479, -0.0515, -0.0428]],

         [[-0.0602, -0.1000, -0.1209],
          [-0.0635, -0.0814, -0.0796],
          [-0.0599, -0.0650, -0.0556]],

         [[-0.0485, -0.0946, -0.1208],
          [-0.0555, -0.0828, -0.0879],
          [-0.0554, -0.0713, -0.0680]]],


        ...,


        [[[-0.0052, -0.0100, -0.0116],
          [-0.0064, -0.0006, -0.0018],
          [-0.0145, -0.0053, -0.0088]],

         [[-0.0071, -0.0141, -0.0169],
          [-0.0091, -0.0029, -0.0039],
          [-0.0168, -0.0052, -0.0079]],

         [[-0.0039, -0.0130, -0.0147],
          [-0.0079, -0.0041, -0.0035],
          [-0.0177, -0.0063, -0.0060]]],


        [[[-0.0079, -0.0106, -0.0060],
          [-0.0027, -0.0020,  0.0032],
          [ 0.0185,  0.0211,  0.0191]],

         [[-0.0253, -0.0308, -0.0304],
          [-0.0183, -0.0223, -0.0208],
          [ 0.0043,  0.0043,  0.0005]],

         [[ 0.0088,  0.0052,  0.0058],
          [ 0.0095,  0.0045,  0.0036],
          [ 0.0206,  0.0148,  0.0095]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4428]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 33 | Batch_idx: 0 |  Loss: (0.2129) | Acc: (92.00%) (118/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.3093) | Acc: (90.00%) (1271/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.3219) | Acc: (89.00%) (2397/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.3217) | Acc: (89.00%) (3539/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.3307) | Acc: (88.00%) (4657/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.3271) | Acc: (88.00%) (5796/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.3221) | Acc: (89.00%) (6958/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.3227) | Acc: (89.00%) (8105/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.3219) | Acc: (89.00%) (9249/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.3283) | Acc: (88.00%) (10362/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.3287) | Acc: (88.00%) (11497/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.3300) | Acc: (88.00%) (12629/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.3285) | Acc: (88.00%) (13771/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.3307) | Acc: (88.00%) (14896/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.3278) | Acc: (88.00%) (16044/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.3273) | Acc: (88.00%) (17196/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.3264) | Acc: (88.00%) (18332/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.3256) | Acc: (88.00%) (19478/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.3257) | Acc: (88.00%) (20613/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.3260) | Acc: (88.00%) (21751/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.3244) | Acc: (89.00%) (22898/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.3229) | Acc: (89.00%) (24060/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.3228) | Acc: (89.00%) (25204/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.3214) | Acc: (89.00%) (26360/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.3212) | Acc: (89.00%) (27502/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.3214) | Acc: (89.00%) (28648/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.3226) | Acc: (89.00%) (29772/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.3250) | Acc: (89.00%) (30889/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.3239) | Acc: (89.00%) (32040/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.3229) | Acc: (89.00%) (33198/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.3223) | Acc: (89.00%) (34337/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.3227) | Acc: (89.00%) (35462/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.3224) | Acc: (89.00%) (36604/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.3232) | Acc: (89.00%) (37735/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.3233) | Acc: (89.00%) (38879/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.3233) | Acc: (89.00%) (40021/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.3235) | Acc: (89.00%) (41160/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.3237) | Acc: (89.00%) (42293/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.3223) | Acc: (89.00%) (43461/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.3215) | Acc: (89.00%) (44573/50000)
# TEST : Loss: (0.3817) | Acc: (87.00%) (8742/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2974e-01, -2.2774e-01,  7.8538e-02],
          [-7.2553e-02,  2.4971e-01,  1.6162e-01],
          [ 1.1897e-01,  7.5823e-03, -9.5869e-02]],

         [[-2.2752e-01,  2.0229e-01,  1.9816e-01],
          [-9.4159e-03,  2.7153e-01,  1.5874e-01],
          [ 2.0978e-01, -1.2223e-01,  1.4542e-01]],

         [[-1.7199e-01, -5.9008e-03, -2.1914e-02],
          [-2.2234e-01, -4.5025e-02, -3.8480e-02],
          [-1.6205e-01, -2.3292e-02, -1.0885e-01]]],


        [[[ 6.7188e-02, -1.1574e-01,  7.8888e-02],
          [-5.0195e-02, -8.3585e-02,  5.2077e-02],
          [ 9.1589e-02, -1.0574e-02, -1.7181e-01]],

         [[-1.0169e-01, -8.3110e-03, -1.9056e-02],
          [ 4.4296e-02,  2.2836e-02,  5.9338e-02],
          [ 7.9486e-02,  9.2171e-02, -1.6022e-01]],

         [[ 1.6492e-02, -1.2078e-01,  2.5261e-02],
          [-1.0057e-01,  6.6753e-02,  1.0214e-01],
          [ 3.2630e-02, -2.1922e-02, -7.5995e-02]]],


        [[[ 5.9293e-02,  1.1602e-01, -8.2235e-02],
          [ 1.5533e-02,  1.5807e-01, -1.1480e-01],
          [ 7.4083e-02,  2.4896e-01,  2.3342e-01]],

         [[-1.8234e-01, -2.8534e-03, -1.4809e-01],
          [-2.2180e-01, -1.4718e-01, -2.0790e-01],
          [-1.9551e-01, -2.9154e-01,  5.6059e-02]],

         [[ 1.6707e-01,  2.4232e-02,  2.0693e-01],
          [ 1.6776e-01,  5.5791e-02,  2.8077e-02],
          [-4.0169e-02,  7.9201e-02,  6.9620e-02]]],


        ...,


        [[[ 2.4392e-01,  2.9304e-02,  1.0340e-02],
          [ 2.0907e-01, -2.1777e-01, -4.4666e-02],
          [-8.9704e-02, -1.5034e-01, -1.2298e-01]],

         [[-7.7627e-02, -1.3181e-02, -7.1520e-02],
          [-1.5598e-01, -2.1898e-01,  1.7180e-01],
          [-3.6910e-02,  3.0037e-01,  2.7238e-01]],

         [[-3.4641e-02, -4.0997e-02,  2.4013e-01],
          [ 3.4155e-02, -2.7033e-01, -1.1607e-01],
          [ 2.0039e-02, -5.1425e-02, -7.3551e-02]]],


        [[[ 9.1011e-02,  2.8675e-02,  2.2107e-01],
          [ 1.9418e-01,  1.5039e-01,  1.1099e-03],
          [-2.6078e-01, -1.7280e-01, -8.5329e-02]],

         [[ 7.1977e-02,  1.1956e-02, -1.3661e-01],
          [ 6.5291e-02, -3.7420e-02, -2.7230e-01],
          [ 5.6525e-03,  1.4783e-01, -3.6324e-02]],

         [[-1.5281e-01, -4.7997e-02, -2.3229e-01],
          [-5.2357e-02,  9.2846e-02,  6.0283e-02],
          [ 1.6848e-01,  1.6212e-01,  1.1543e-01]]],


        [[[-7.5941e-41,  3.8527e-41, -6.8243e-42],
          [-4.3925e-41,  3.1905e-41, -5.7022e-41],
          [-7.2006e-41, -6.4844e-41,  6.2020e-41]],

         [[ 5.7532e-41, -2.3721e-41, -6.2698e-41],
          [-2.5261e-41, -5.3632e-41, -6.4635e-41],
          [ 7.1756e-41,  4.1125e-41, -7.5012e-42]],

         [[-3.4008e-41, -4.9128e-41, -5.9367e-41],
          [ 3.9419e-42,  4.3969e-41, -6.2281e-41],
          [-6.2670e-41,  2.2197e-42, -4.1114e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0422,  0.0404,  0.0352],
          [ 0.0405,  0.0414,  0.0333],
          [ 0.0310,  0.0345,  0.0294]],

         [[ 0.0609,  0.0599,  0.0543],
          [ 0.0553,  0.0571,  0.0491],
          [ 0.0418,  0.0459,  0.0419]],

         [[ 0.0640,  0.0626,  0.0581],
          [ 0.0572,  0.0578,  0.0497],
          [ 0.0453,  0.0483,  0.0440]]],


        [[[-0.0011, -0.0009, -0.0005],
          [-0.0012, -0.0007, -0.0004],
          [-0.0014, -0.0008, -0.0003]],

         [[-0.0011, -0.0008, -0.0005],
          [-0.0012, -0.0006, -0.0003],
          [-0.0014, -0.0007, -0.0003]],

         [[-0.0008, -0.0006, -0.0003],
          [-0.0008, -0.0004, -0.0001],
          [-0.0010, -0.0004,  0.0000]]],


        [[[ 0.0773,  0.1137,  0.1041],
          [ 0.0813,  0.0875,  0.0958],
          [ 0.0803,  0.0724,  0.0861]],

         [[ 0.0718,  0.1022,  0.1013],
          [ 0.0866,  0.0906,  0.1039],
          [ 0.0877,  0.0779,  0.0963]],

         [[ 0.0621,  0.0889,  0.0970],
          [ 0.0680,  0.0722,  0.0958],
          [ 0.0624,  0.0533,  0.0803]]],


        ...,


        [[[ 0.0338,  0.0338,  0.0306],
          [ 0.0207,  0.0197,  0.0164],
          [ 0.0149,  0.0098,  0.0105]],

         [[ 0.0287,  0.0279,  0.0246],
          [ 0.0165,  0.0152,  0.0129],
          [ 0.0112,  0.0074,  0.0090]],

         [[ 0.0210,  0.0206,  0.0170],
          [ 0.0111,  0.0097,  0.0068],
          [ 0.0090,  0.0048,  0.0051]]],


        [[[-0.0103,  0.0128,  0.0401],
          [-0.0013,  0.0082,  0.0324],
          [ 0.0141,  0.0214,  0.0341]],

         [[-0.0249, -0.0055,  0.0217],
          [-0.0138, -0.0069,  0.0157],
          [ 0.0067,  0.0154,  0.0279]],

         [[-0.0473, -0.0346, -0.0106],
          [-0.0326, -0.0292, -0.0098],
          [-0.0084, -0.0010,  0.0099]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4414]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 34 | Batch_idx: 0 |  Loss: (0.3146) | Acc: (88.00%) (113/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.2650) | Acc: (90.00%) (1278/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.3156) | Acc: (89.00%) (2408/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.3198) | Acc: (89.00%) (3547/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.3340) | Acc: (88.00%) (4669/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.3328) | Acc: (88.00%) (5802/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.3343) | Acc: (88.00%) (6921/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.3316) | Acc: (88.00%) (8057/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.3303) | Acc: (88.00%) (9201/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.3315) | Acc: (88.00%) (10339/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.3300) | Acc: (88.00%) (11475/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.3268) | Acc: (88.00%) (12619/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.3268) | Acc: (88.00%) (13757/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.3230) | Acc: (88.00%) (14917/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.3212) | Acc: (89.00%) (16069/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.3196) | Acc: (89.00%) (17221/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.3183) | Acc: (89.00%) (18368/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.3174) | Acc: (89.00%) (19509/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.3158) | Acc: (89.00%) (20674/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.3152) | Acc: (89.00%) (21814/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.3128) | Acc: (89.00%) (22990/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.3122) | Acc: (89.00%) (24140/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.3114) | Acc: (89.00%) (25296/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.3108) | Acc: (89.00%) (26438/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.3089) | Acc: (89.00%) (27601/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.3082) | Acc: (89.00%) (28750/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.3063) | Acc: (89.00%) (29921/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.3060) | Acc: (89.00%) (31071/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.3051) | Acc: (89.00%) (32222/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.3054) | Acc: (89.00%) (33358/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.3041) | Acc: (89.00%) (34536/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.3025) | Acc: (89.00%) (35704/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.3007) | Acc: (89.00%) (36879/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.3004) | Acc: (89.00%) (38036/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.2996) | Acc: (89.00%) (39189/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.2988) | Acc: (89.00%) (40360/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.2996) | Acc: (89.00%) (41495/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.2996) | Acc: (89.00%) (42652/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.2985) | Acc: (89.00%) (43823/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.2978) | Acc: (89.00%) (44943/50000)
# TEST : Loss: (0.3464) | Acc: (88.00%) (8845/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3143e-01, -2.2803e-01,  7.8290e-02],
          [-7.3284e-02,  2.4865e-01,  1.6231e-01],
          [ 1.1911e-01,  8.2414e-03, -9.4084e-02]],

         [[-2.3098e-01,  1.9894e-01,  1.9572e-01],
          [-1.1956e-02,  2.6891e-01,  1.5793e-01],
          [ 2.0846e-01, -1.2221e-01,  1.4543e-01]],

         [[-1.7412e-01, -7.1207e-03, -2.2188e-02],
          [-2.2243e-01, -4.4543e-02, -3.6656e-02],
          [-1.6039e-01, -2.1279e-02, -1.0598e-01]]],


        [[[ 6.4956e-02, -1.0676e-01,  7.5323e-02],
          [-4.4966e-02, -7.7200e-02,  4.8854e-02],
          [ 8.7149e-02, -9.2332e-03, -1.5950e-01]],

         [[-9.3290e-02, -6.5587e-03, -1.6585e-02],
          [ 4.3213e-02,  2.1968e-02,  5.5504e-02],
          [ 7.5414e-02,  8.6410e-02, -1.4901e-01]],

         [[ 1.6803e-02, -1.1151e-01,  2.4245e-02],
          [-9.2585e-02,  6.2071e-02,  9.4589e-02],
          [ 3.0889e-02, -2.0711e-02, -7.1587e-02]]],


        [[[ 5.3343e-02,  1.0959e-01, -8.7819e-02],
          [ 9.2429e-03,  1.5225e-01, -1.2029e-01],
          [ 6.9601e-02,  2.4437e-01,  2.2922e-01]],

         [[-1.8913e-01, -1.0012e-02, -1.5443e-01],
          [-2.2950e-01, -1.5401e-01, -2.1447e-01],
          [-2.0090e-01, -2.9665e-01,  5.0944e-02]],

         [[ 1.5937e-01,  1.6603e-02,  1.9949e-01],
          [ 1.5974e-01,  4.8641e-02,  2.0661e-02],
          [-4.5008e-02,  7.4158e-02,  6.4225e-02]]],


        ...,


        [[[ 2.4220e-01,  2.8157e-02,  9.3988e-03],
          [ 2.0832e-01, -2.1755e-01, -4.4648e-02],
          [-9.0551e-02, -1.5009e-01, -1.2211e-01]],

         [[-7.7692e-02, -1.3458e-02, -7.1730e-02],
          [-1.5489e-01, -2.1807e-01,  1.7152e-01],
          [-3.7151e-02,  3.0000e-01,  2.7262e-01]],

         [[-3.4523e-02, -4.0944e-02,  2.3902e-01],
          [ 3.4333e-02, -2.6952e-01, -1.1599e-01],
          [ 1.9065e-02, -5.1568e-02, -7.3098e-02]]],


        [[[ 9.3119e-02,  2.9251e-02,  2.1890e-01],
          [ 1.9485e-01,  1.5008e-01,  1.4541e-04],
          [-2.6097e-01, -1.7435e-01, -8.6965e-02]],

         [[ 7.4985e-02,  1.3290e-02, -1.3752e-01],
          [ 6.6890e-02, -3.6815e-02, -2.7217e-01],
          [ 5.3512e-03,  1.4577e-01, -3.8045e-02]],

         [[-1.4833e-01, -4.5151e-02, -2.3105e-01],
          [-4.9659e-02,  9.4112e-02,  6.0862e-02],
          [ 1.6850e-01,  1.6069e-01,  1.1394e-01]]],


        [[[ 6.9849e-41, -4.2325e-41,  2.3668e-41],
          [ 2.3466e-41,  3.2971e-41, -2.1580e-41],
          [ 2.9530e-41, -7.6051e-41,  7.2262e-41]],

         [[ 8.8450e-42, -5.4717e-41,  9.1561e-42],
          [ 3.0253e-41,  2.1692e-41, -4.9745e-41],
          [ 7.3668e-41, -6.2069e-41, -1.4603e-41]],

         [[-3.5830e-41, -7.4143e-42, -7.3365e-41],
          [ 1.0532e-41,  6.8947e-41, -6.4856e-41],
          [-2.3770e-41,  5.5148e-41, -1.1405e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4352]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0062]], device='cuda:0')

Epoch: 35 | Batch_idx: 0 |  Loss: (0.2085) | Acc: (92.00%) (118/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.2447) | Acc: (92.00%) (1299/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.2500) | Acc: (91.00%) (2464/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.2699) | Acc: (90.00%) (3603/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.2645) | Acc: (91.00%) (4777/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.2647) | Acc: (91.00%) (5947/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.2725) | Acc: (90.00%) (7091/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.2725) | Acc: (90.00%) (8251/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.2768) | Acc: (90.00%) (9404/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.2774) | Acc: (90.00%) (10554/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.2757) | Acc: (90.00%) (11726/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.2735) | Acc: (90.00%) (12893/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.2746) | Acc: (90.00%) (14050/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.2735) | Acc: (90.00%) (15216/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.2735) | Acc: (90.00%) (16383/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.2721) | Acc: (90.00%) (17556/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.2725) | Acc: (90.00%) (18706/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.2716) | Acc: (90.00%) (19875/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.2702) | Acc: (90.00%) (21062/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.2703) | Acc: (90.00%) (22219/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.2708) | Acc: (90.00%) (23382/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.2726) | Acc: (90.00%) (24537/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.2714) | Acc: (90.00%) (25706/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.2723) | Acc: (90.00%) (26851/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.2727) | Acc: (90.00%) (28013/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.2720) | Acc: (90.00%) (29185/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.2728) | Acc: (90.00%) (30342/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.2722) | Acc: (90.00%) (31525/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.2725) | Acc: (90.00%) (32684/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.2726) | Acc: (90.00%) (33843/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.2717) | Acc: (90.00%) (35012/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.2717) | Acc: (90.00%) (36178/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.2707) | Acc: (90.00%) (37355/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.2701) | Acc: (90.00%) (38519/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.2688) | Acc: (90.00%) (39703/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.2680) | Acc: (91.00%) (40885/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.2682) | Acc: (91.00%) (42055/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.2685) | Acc: (90.00%) (43212/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.2682) | Acc: (91.00%) (44381/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.2677) | Acc: (91.00%) (45510/50000)
# TEST : Loss: (0.3410) | Acc: (88.00%) (8874/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3104e-01, -2.2729e-01,  7.8013e-02],
          [-7.3056e-02,  2.4780e-01,  1.6171e-01],
          [ 1.1874e-01,  8.2136e-03, -9.3757e-02]],

         [[-2.3025e-01,  1.9827e-01,  1.9502e-01],
          [-1.1917e-02,  2.6796e-01,  1.5735e-01],
          [ 2.0778e-01, -1.2179e-01,  1.4492e-01]],

         [[-1.7350e-01, -7.0950e-03, -2.2108e-02],
          [-2.2163e-01, -4.4383e-02, -3.6525e-02],
          [-1.5982e-01, -2.1203e-02, -1.0561e-01]]],


        [[[ 5.9892e-02, -9.8262e-02,  6.9778e-02],
          [-4.1532e-02, -7.1032e-02,  4.4968e-02],
          [ 8.0621e-02, -8.5014e-03, -1.4557e-01]],

         [[-8.5947e-02, -6.0261e-03, -1.5325e-02],
          [ 3.9910e-02,  2.0191e-02,  5.1020e-02],
          [ 6.9651e-02,  7.9418e-02, -1.3590e-01]],

         [[ 1.5404e-02, -1.0193e-01,  2.2295e-02],
          [-8.5144e-02,  5.6798e-02,  8.6709e-02],
          [ 2.8432e-02, -1.8966e-02, -6.5178e-02]]],


        [[[ 5.3271e-02,  1.0945e-01, -8.7700e-02],
          [ 9.2306e-03,  1.5205e-01, -1.2013e-01],
          [ 6.9503e-02,  2.4403e-01,  2.2889e-01]],

         [[-1.8886e-01, -9.9974e-03, -1.5421e-01],
          [-2.2916e-01, -1.5379e-01, -2.1415e-01],
          [-2.0060e-01, -2.9621e-01,  5.0868e-02]],

         [[ 1.5913e-01,  1.6578e-02,  1.9918e-01],
          [ 1.5950e-01,  4.8564e-02,  2.0628e-02],
          [-4.4937e-02,  7.4039e-02,  6.4121e-02]]],


        ...,


        [[[ 2.4140e-01,  2.8066e-02,  9.3676e-03],
          [ 2.0762e-01, -2.1683e-01, -4.4505e-02],
          [-9.0245e-02, -1.4959e-01, -1.2172e-01]],

         [[-7.7422e-02, -1.3412e-02, -7.1480e-02],
          [-1.5432e-01, -2.1729e-01,  1.7093e-01],
          [-3.7017e-02,  2.9896e-01,  2.7171e-01]],

         [[-3.4399e-02, -4.0793e-02,  2.3816e-01],
          [ 3.4196e-02, -2.6842e-01, -1.1556e-01],
          [ 1.8992e-02, -5.1369e-02, -7.2834e-02]]],


        [[[ 9.2886e-02,  2.9179e-02,  2.1837e-01],
          [ 1.9434e-01,  1.4969e-01,  1.4504e-04],
          [-2.6031e-01, -1.7391e-01, -8.6750e-02]],

         [[ 7.4793e-02,  1.3256e-02, -1.3715e-01],
          [ 6.6713e-02, -3.6717e-02, -2.7142e-01],
          [ 5.3375e-03,  1.4539e-01, -3.7947e-02]],

         [[-1.4793e-01, -4.5027e-02, -2.3037e-01],
          [-4.9523e-02,  9.3850e-02,  6.0685e-02],
          [ 1.6805e-01,  1.6026e-01,  1.1363e-01]]],


        [[[-6.2324e-41, -6.5366e-41,  7.9734e-43],
          [-8.8352e-42,  5.6977e-42,  7.1815e-41],
          [ 5.3282e-41, -6.1873e-41, -1.9484e-41]],

         [[-3.0484e-41, -7.0672e-41,  7.8665e-41],
          [ 8.1996e-41,  7.9364e-41, -6.7374e-41],
          [ 5.0244e-41, -2.7946e-41,  1.6540e-41]],

         [[-7.2580e-41,  1.2061e-41, -7.1797e-41],
          [ 3.3497e-41,  7.3057e-41,  8.9137e-42],
          [-7.7884e-42,  7.5482e-41,  5.9879e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4631]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0098]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 36 | Batch_idx: 0 |  Loss: (0.1952) | Acc: (93.00%) (120/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.2805) | Acc: (90.00%) (1276/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.2945) | Acc: (89.00%) (2414/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.3248) | Acc: (89.00%) (3538/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.3365) | Acc: (88.00%) (4654/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.3415) | Acc: (88.00%) (5776/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.3517) | Acc: (88.00%) (6876/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.3595) | Acc: (87.00%) (7980/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.3653) | Acc: (87.00%) (9091/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.3683) | Acc: (87.00%) (10194/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.3729) | Acc: (87.00%) (11286/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.3714) | Acc: (87.00%) (12411/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.3745) | Acc: (87.00%) (13524/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.3715) | Acc: (87.00%) (14659/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.3705) | Acc: (87.00%) (15787/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.3697) | Acc: (87.00%) (16904/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.3693) | Acc: (87.00%) (18021/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.3709) | Acc: (87.00%) (19127/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.3709) | Acc: (87.00%) (20248/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.3703) | Acc: (87.00%) (21367/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.3681) | Acc: (87.00%) (22499/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.3669) | Acc: (87.00%) (23633/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.3660) | Acc: (87.00%) (24758/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.3642) | Acc: (87.00%) (25899/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.3649) | Acc: (87.00%) (27005/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.3658) | Acc: (87.00%) (28122/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.3656) | Acc: (87.00%) (29264/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.3647) | Acc: (87.00%) (30400/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.3639) | Acc: (87.00%) (31536/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.3629) | Acc: (87.00%) (32673/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.3633) | Acc: (87.00%) (33795/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.3621) | Acc: (87.00%) (34937/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.3610) | Acc: (87.00%) (36067/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.3603) | Acc: (87.00%) (37207/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.3594) | Acc: (87.00%) (38331/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.3601) | Acc: (87.00%) (39444/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.3604) | Acc: (87.00%) (40568/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.3600) | Acc: (87.00%) (41707/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.3597) | Acc: (87.00%) (42831/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.3587) | Acc: (87.00%) (43941/50000)
# TEST : Loss: (0.4154) | Acc: (86.00%) (8645/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3541e-01, -2.2566e-01,  8.0076e-02],
          [-7.5409e-02,  2.5359e-01,  1.6694e-01],
          [ 1.0536e-01, -1.9072e-03, -1.0128e-01]],

         [[-2.3263e-01,  2.0330e-01,  2.0065e-01],
          [-1.2008e-02,  2.7559e-01,  1.6141e-01],
          [ 1.9800e-01, -1.2820e-01,  1.3639e-01]],

         [[-1.7576e-01, -8.0957e-03, -2.4412e-02],
          [-2.2226e-01, -4.4935e-02, -4.1508e-02],
          [-1.6669e-01, -2.8940e-02, -1.1362e-01]]],


        [[[ 6.2645e-02, -8.7575e-02,  6.8721e-02],
          [-3.0110e-02, -5.5553e-02,  5.2096e-02],
          [ 7.9950e-02,  1.2461e-04, -1.1778e-01]],

         [[-6.5471e-02,  1.4168e-03, -4.1871e-04],
          [ 4.7805e-02,  3.2297e-02,  6.4258e-02],
          [ 7.3191e-02,  8.3694e-02, -1.0812e-01]],

         [[ 3.2363e-02, -7.7697e-02,  3.9885e-02],
          [-6.2040e-02,  6.9799e-02,  9.9852e-02],
          [ 3.6869e-02, -4.1716e-03, -4.3764e-02]]],


        [[[ 6.4016e-02,  1.2400e-01, -7.8395e-02],
          [ 1.9213e-02,  1.6237e-01, -1.1747e-01],
          [ 7.8490e-02,  2.5270e-01,  2.2991e-01]],

         [[-1.8973e-01, -8.6522e-03, -1.5275e-01],
          [-2.3223e-01, -1.5711e-01, -2.1901e-01],
          [-2.0748e-01, -3.0437e-01,  3.7008e-02]],

         [[ 1.5899e-01,  1.7721e-02,  1.9810e-01],
          [ 1.6326e-01,  5.3018e-02,  1.9190e-02],
          [-4.2999e-02,  7.2963e-02,  5.1207e-02]]],


        ...,


        [[[ 2.4742e-01,  3.5874e-02,  1.9097e-02],
          [ 2.1132e-01, -2.1859e-01, -4.1289e-02],
          [-7.7642e-02, -1.4476e-01, -1.1700e-01]],

         [[-7.9647e-02, -7.0103e-03, -5.2880e-02],
          [-1.5259e-01, -2.1540e-01,  1.8326e-01],
          [-1.3985e-02,  3.1560e-01,  2.8717e-01]],

         [[-2.9834e-02, -3.7787e-02,  2.4886e-01],
          [ 4.1712e-02, -2.6351e-01, -1.0439e-01],
          [ 4.3013e-02, -3.5230e-02, -5.9617e-02]]],


        [[[ 1.0393e-01,  3.5891e-02,  2.1796e-01],
          [ 1.9349e-01,  1.4446e-01, -1.1697e-02],
          [-2.5747e-01, -1.7293e-01, -8.5914e-02]],

         [[ 8.5533e-02,  2.2054e-02, -1.3339e-01],
          [ 6.8443e-02, -3.7564e-02, -2.7900e-01],
          [ 1.1514e-02,  1.5493e-01, -2.6473e-02]],

         [[-1.5117e-01, -5.0000e-02, -2.4044e-01],
          [-5.7107e-02,  8.8093e-02,  5.0771e-02],
          [ 1.6641e-01,  1.6961e-01,  1.2408e-01]]],


        [[[-7.9243e-42, -3.4472e-43, -4.6593e-41],
          [ 5.6807e-41, -1.8269e-41, -5.0465e-41],
          [-6.5680e-41, -3.3815e-41, -2.4317e-41]],

         [[-6.7264e-41, -6.5519e-41,  6.6427e-41],
          [ 5.4886e-41,  4.2342e-41, -7.1273e-41],
          [ 3.0857e-41,  7.7574e-41,  6.1720e-41]],

         [[-6.1530e-41,  6.0256e-42, -3.0778e-41],
          [ 6.5672e-41,  8.2221e-41, -5.6527e-41],
          [-9.6409e-43,  3.7455e-41,  4.0746e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0217,  0.0194,  0.0157],
          [ 0.0293,  0.0264,  0.0257],
          [ 0.0335,  0.0330,  0.0301]],

         [[ 0.0206,  0.0177,  0.0116],
          [ 0.0269,  0.0243,  0.0207],
          [ 0.0298,  0.0297,  0.0243]],

         [[ 0.0179,  0.0175,  0.0128],
          [ 0.0244,  0.0252,  0.0232],
          [ 0.0274,  0.0307,  0.0255]]],


        [[[ 0.0001,  0.0001, -0.0000],
          [ 0.0002,  0.0001,  0.0000],
          [ 0.0001, -0.0000, -0.0000]],

         [[ 0.0001,  0.0001, -0.0000],
          [ 0.0002,  0.0001,  0.0000],
          [ 0.0001, -0.0001, -0.0000]],

         [[ 0.0000,  0.0000, -0.0000],
          [ 0.0001,  0.0000,  0.0000],
          [ 0.0000, -0.0001, -0.0000]]],


        [[[-0.0135, -0.0378, -0.0307],
          [ 0.0069, -0.0037,  0.0058],
          [ 0.0174,  0.0203,  0.0407]],

         [[-0.0105, -0.0358, -0.0359],
          [ 0.0073,  0.0025,  0.0023],
          [ 0.0128,  0.0223,  0.0348]],

         [[-0.0073, -0.0318, -0.0368],
          [-0.0008, -0.0056, -0.0112],
          [-0.0028,  0.0032,  0.0127]]],


        ...,


        [[[ 0.0132,  0.0240,  0.0250],
          [ 0.0175,  0.0273,  0.0287],
          [ 0.0150,  0.0261,  0.0327]],

         [[ 0.0011,  0.0115,  0.0134],
          [ 0.0040,  0.0145,  0.0156],
          [ 0.0028,  0.0150,  0.0202]],

         [[-0.0093, -0.0028, -0.0011],
          [-0.0080, -0.0008,  0.0013],
          [-0.0082,  0.0031,  0.0097]]],


        [[[-0.0193, -0.0183, -0.0180],
          [-0.0319, -0.0191, -0.0131],
          [-0.0279, -0.0159, -0.0078]],

         [[-0.0265, -0.0285, -0.0283],
          [-0.0363, -0.0252, -0.0196],
          [-0.0275, -0.0175, -0.0098]],

         [[-0.0212, -0.0210, -0.0186],
          [-0.0277, -0.0184, -0.0116],
          [-0.0184, -0.0116, -0.0033]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4638]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 37 | Batch_idx: 0 |  Loss: (0.2468) | Acc: (92.00%) (118/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.3006) | Acc: (89.00%) (1261/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.2799) | Acc: (89.00%) (2418/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.2759) | Acc: (90.00%) (3577/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.2813) | Acc: (89.00%) (4716/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.2758) | Acc: (90.00%) (5892/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.2759) | Acc: (90.00%) (7049/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.2778) | Acc: (90.00%) (8189/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.2814) | Acc: (90.00%) (9337/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.2804) | Acc: (90.00%) (10496/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.2806) | Acc: (90.00%) (11656/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.2828) | Acc: (90.00%) (12804/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.2868) | Acc: (89.00%) (13938/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.2897) | Acc: (89.00%) (15078/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.2916) | Acc: (89.00%) (16224/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.2921) | Acc: (89.00%) (17377/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.2923) | Acc: (89.00%) (18535/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.2934) | Acc: (89.00%) (19684/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.2935) | Acc: (89.00%) (20831/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.2950) | Acc: (89.00%) (21976/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.2973) | Acc: (89.00%) (23103/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.2972) | Acc: (89.00%) (24256/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.2982) | Acc: (89.00%) (25379/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.2990) | Acc: (89.00%) (26523/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.2996) | Acc: (89.00%) (27661/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.2995) | Acc: (89.00%) (28810/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.2998) | Acc: (89.00%) (29953/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.2987) | Acc: (89.00%) (31111/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.2986) | Acc: (89.00%) (32262/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.2982) | Acc: (89.00%) (33425/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.2980) | Acc: (89.00%) (34582/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.2976) | Acc: (89.00%) (35741/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.2981) | Acc: (89.00%) (36884/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.2981) | Acc: (89.00%) (38035/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.2986) | Acc: (89.00%) (39182/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.2994) | Acc: (89.00%) (40317/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.3007) | Acc: (89.00%) (41451/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.3013) | Acc: (89.00%) (42593/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.3008) | Acc: (89.00%) (43750/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.3009) | Acc: (89.00%) (44853/50000)
# TEST : Loss: (0.3796) | Acc: (87.00%) (8744/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4031e-01, -2.3361e-01,  7.9211e-02],
          [-7.3887e-02,  2.5608e-01,  1.7196e-01],
          [ 1.1306e-01, -1.5423e-04, -1.0169e-01]],

         [[-2.3197e-01,  2.0177e-01,  2.0636e-01],
          [-6.2007e-03,  2.8336e-01,  1.7019e-01],
          [ 2.0842e-01, -1.2217e-01,  1.3560e-01]],

         [[-1.7141e-01, -9.6586e-03, -1.9049e-02],
          [-2.1330e-01, -3.8686e-02, -3.3804e-02],
          [-1.5278e-01, -2.2766e-02, -1.0933e-01]]],


        [[[ 5.5091e-02, -7.9233e-02,  6.0018e-02],
          [-2.6548e-02, -4.8349e-02,  4.7400e-02],
          [ 6.9110e-02, -5.9186e-04, -1.0507e-01]],

         [[-5.8870e-02,  1.7414e-03, -1.0896e-03],
          [ 4.3723e-02,  3.1163e-02,  5.8750e-02],
          [ 6.3349e-02,  7.4349e-02, -9.6731e-02]],

         [[ 2.8541e-02, -6.8630e-02,  3.4208e-02],
          [-5.4624e-02,  6.4001e-02,  8.9696e-02],
          [ 3.0477e-02, -3.9112e-03, -4.0021e-02]]],


        [[[ 5.3356e-02,  1.1758e-01, -8.5521e-02],
          [ 7.7270e-03,  1.5962e-01, -1.1698e-01],
          [ 7.0708e-02,  2.5460e-01,  2.3569e-01]],

         [[-1.8808e-01, -2.3130e-03, -1.4587e-01],
          [-2.4103e-01, -1.5625e-01, -2.0908e-01],
          [-2.1392e-01, -3.0106e-01,  4.7995e-02]],

         [[ 1.7081e-01,  3.5441e-02,  2.1272e-01],
          [ 1.6508e-01,  6.6491e-02,  3.7025e-02],
          [-4.0766e-02,  8.5886e-02,  6.7375e-02]]],


        ...,


        [[[ 2.5094e-01,  3.2177e-02,  1.5999e-02],
          [ 2.1280e-01, -2.2465e-01, -4.8907e-02],
          [-7.8401e-02, -1.4983e-01, -1.2422e-01]],

         [[-8.5617e-02, -1.9645e-02, -5.9446e-02],
          [-1.5738e-01, -2.2726e-01,  1.7220e-01],
          [-1.8343e-02,  3.0796e-01,  2.7814e-01]],

         [[-2.0435e-02, -3.5252e-02,  2.4788e-01],
          [ 5.0540e-02, -2.6520e-01, -1.1477e-01],
          [ 4.6362e-02, -4.4501e-02, -7.6974e-02]]],


        [[[ 1.0096e-01,  3.2808e-02,  2.0968e-01],
          [ 1.8502e-01,  1.3683e-01, -2.3924e-02],
          [-2.6495e-01, -1.8077e-01, -9.7612e-02]],

         [[ 9.0901e-02,  2.1058e-02, -1.3631e-01],
          [ 7.0151e-02, -4.0712e-02, -2.8622e-01],
          [ 1.2950e-02,  1.5567e-01, -2.9263e-02]],

         [[-1.4484e-01, -4.5534e-02, -2.3297e-01],
          [-5.1667e-02,  9.4180e-02,  5.5724e-02],
          [ 1.7387e-01,  1.8321e-01,  1.3678e-01]]],


        [[[ 8.3358e-41,  8.6763e-41, -7.7326e-41],
          [-5.3175e-41, -3.2170e-41,  3.1470e-41],
          [ 5.1796e-41, -1.0911e-41,  4.9209e-41]],

         [[-6.9558e-41,  3.9674e-41, -7.0627e-41],
          [ 7.5334e-41,  1.5553e-41, -7.6455e-41],
          [ 4.9418e-41,  6.4875e-41,  4.4634e-41]],

         [[-4.4497e-41,  7.6811e-41, -4.7420e-41],
          [ 8.2210e-41,  6.3473e-41, -6.8816e-41],
          [ 5.0358e-41, -4.8461e-41, -1.9245e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0224, -0.0149, -0.0151],
          [-0.0184, -0.0128, -0.0103],
          [-0.0060, -0.0079, -0.0105]],

         [[-0.0191, -0.0095, -0.0098],
          [-0.0138, -0.0076, -0.0046],
          [-0.0020, -0.0042, -0.0039]],

         [[-0.0052, -0.0004, -0.0000],
          [-0.0040, -0.0007,  0.0037],
          [ 0.0044,  0.0011,  0.0025]]],


        [[[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0001],
          [-0.0000, -0.0000, -0.0001]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0001, -0.0001],
          [-0.0000, -0.0000, -0.0001]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0001, -0.0000],
          [-0.0000, -0.0000, -0.0001]]],


        [[[ 0.0258,  0.0088,  0.0043],
          [ 0.0268,  0.0222,  0.0097],
          [ 0.0094,  0.0139,  0.0018]],

         [[ 0.0087, -0.0083, -0.0151],
          [ 0.0162,  0.0145,  0.0051],
          [ 0.0048,  0.0191,  0.0167]],

         [[-0.0048, -0.0111, -0.0130],
          [ 0.0131,  0.0196,  0.0102],
          [ 0.0071,  0.0263,  0.0225]]],


        ...,


        [[[ 0.0248,  0.0214,  0.0231],
          [ 0.0094,  0.0136,  0.0186],
          [-0.0043,  0.0004,  0.0059]],

         [[ 0.0226,  0.0197,  0.0241],
          [ 0.0074,  0.0123,  0.0169],
          [-0.0060, -0.0015,  0.0016]],

         [[ 0.0196,  0.0212,  0.0240],
          [ 0.0070,  0.0125,  0.0150],
          [-0.0026,  0.0016,  0.0028]]],


        [[[ 0.0333,  0.0309,  0.0435],
          [ 0.0354,  0.0326,  0.0413],
          [ 0.0051,  0.0102,  0.0254]],

         [[ 0.0303,  0.0269,  0.0379],
          [ 0.0293,  0.0270,  0.0356],
          [ 0.0006,  0.0049,  0.0163]],

         [[ 0.0115,  0.0102,  0.0208],
          [ 0.0122,  0.0127,  0.0200],
          [-0.0090, -0.0037,  0.0039]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4623]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 38 | Batch_idx: 0 |  Loss: (0.2267) | Acc: (92.00%) (118/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.2726) | Acc: (90.00%) (1281/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.3068) | Acc: (89.00%) (2412/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.3095) | Acc: (89.00%) (3546/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.3208) | Acc: (89.00%) (4673/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.3213) | Acc: (89.00%) (5815/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.3234) | Acc: (88.00%) (6942/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.3215) | Acc: (88.00%) (8086/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.3222) | Acc: (88.00%) (9222/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.3251) | Acc: (88.00%) (10355/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.3224) | Acc: (88.00%) (11498/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.3212) | Acc: (88.00%) (12635/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.3151) | Acc: (89.00%) (13806/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.3135) | Acc: (89.00%) (14961/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.3080) | Acc: (89.00%) (16128/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.3069) | Acc: (89.00%) (17290/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.3034) | Acc: (89.00%) (18461/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.3019) | Acc: (89.00%) (19612/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.3009) | Acc: (89.00%) (20762/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.3020) | Acc: (89.00%) (21909/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.2988) | Acc: (89.00%) (23082/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.2977) | Acc: (89.00%) (24252/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.2980) | Acc: (89.00%) (25397/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.2964) | Acc: (89.00%) (26568/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.2939) | Acc: (89.00%) (27747/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.2935) | Acc: (89.00%) (28895/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.2931) | Acc: (89.00%) (30043/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.2915) | Acc: (90.00%) (31224/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.2924) | Acc: (89.00%) (32370/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.2914) | Acc: (90.00%) (33542/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.2916) | Acc: (90.00%) (34712/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.2904) | Acc: (90.00%) (35886/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.2889) | Acc: (90.00%) (37057/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.2885) | Acc: (90.00%) (38214/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.2878) | Acc: (90.00%) (39377/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.2871) | Acc: (90.00%) (40540/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.2858) | Acc: (90.00%) (41713/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.2861) | Acc: (90.00%) (42860/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.2856) | Acc: (90.00%) (44026/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.2849) | Acc: (90.00%) (45155/50000)
# TEST : Loss: (0.3481) | Acc: (88.00%) (8843/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4079e-01, -2.3427e-01,  7.7545e-02],
          [-7.4567e-02,  2.5350e-01,  1.6948e-01],
          [ 1.1017e-01, -2.8947e-03, -1.0367e-01]],

         [[-2.3248e-01,  1.9971e-01,  2.0426e-01],
          [-7.2904e-03,  2.8051e-01,  1.6751e-01],
          [ 2.0536e-01, -1.2464e-01,  1.3244e-01]],

         [[-1.7385e-01, -1.2322e-02, -2.1832e-02],
          [-2.1520e-01, -4.1439e-02, -3.7035e-02],
          [-1.5602e-01, -2.6310e-02, -1.1283e-01]]],


        [[[ 4.7967e-02, -6.8916e-02,  5.2657e-02],
          [-2.3022e-02, -4.1922e-02,  4.1213e-02],
          [ 6.0779e-02, -5.0186e-04, -9.0043e-02]],

         [[-5.1326e-02,  1.6427e-03, -9.8902e-04],
          [ 3.8524e-02,  2.7285e-02,  5.1052e-02],
          [ 5.5636e-02,  6.4648e-02, -8.2759e-02]],

         [[ 2.4628e-02, -5.8938e-02,  2.9643e-02],
          [-4.7167e-02,  5.5323e-02,  7.7482e-02],
          [ 2.6680e-02, -3.3041e-03, -3.4072e-02]]],


        [[[ 5.4428e-02,  1.1880e-01, -8.4342e-02],
          [ 8.5552e-03,  1.6038e-01, -1.1555e-01],
          [ 7.2142e-02,  2.5589e-01,  2.3668e-01]],

         [[-1.8696e-01, -9.7308e-04, -1.4448e-01],
          [-2.4045e-01, -1.5541e-01, -2.0762e-01],
          [-2.1296e-01, -2.9985e-01,  4.8633e-02]],

         [[ 1.7112e-01,  3.6199e-02,  2.1332e-01],
          [ 1.6418e-01,  6.5988e-02,  3.7573e-02],
          [-4.1015e-02,  8.5764e-02,  6.7489e-02]]],


        ...,


        [[[ 2.4593e-01,  2.8018e-02,  1.1563e-02],
          [ 2.0798e-01, -2.2766e-01, -5.3263e-02],
          [-8.1927e-02, -1.5337e-01, -1.2785e-01]],

         [[-8.8979e-02, -2.3140e-02, -6.3354e-02],
          [-1.6022e-01, -2.2932e-01,  1.6814e-01],
          [-2.0453e-02,  3.0467e-01,  2.7513e-01]],

         [[-2.3557e-02, -3.8444e-02,  2.4340e-01],
          [ 4.7158e-02, -2.6659e-01, -1.1720e-01],
          [ 4.4104e-02, -4.6208e-02, -7.8443e-02]]],


        [[[ 1.0327e-01,  3.5490e-02,  2.1134e-01],
          [ 1.8545e-01,  1.3782e-01, -2.2701e-02],
          [-2.6323e-01, -1.7944e-01, -9.6919e-02]],

         [[ 9.1395e-02,  2.1632e-02, -1.3584e-01],
          [ 6.9229e-02, -4.1317e-02, -2.8657e-01],
          [ 1.2796e-02,  1.5482e-01, -3.0226e-02]],

         [[-1.4385e-01, -4.5168e-02, -2.3234e-01],
          [-5.2349e-02,  9.2643e-02,  5.4286e-02],
          [ 1.7297e-01,  1.8169e-01,  1.3533e-01]]],


        [[[ 8.4326e-41, -1.4027e-41, -5.9156e-41],
          [-8.4937e-41,  2.2163e-41,  1.9809e-41],
          [-7.1186e-43, -2.5282e-41, -7.7830e-41]],

         [[ 1.8311e-41, -4.0799e-41,  1.8881e-41],
          [ 8.3744e-41,  6.2030e-41, -9.2304e-42],
          [ 8.5105e-41,  3.6134e-41, -6.9168e-42]],

         [[-8.0950e-41,  2.0706e-41, -8.7864e-41],
          [ 4.7594e-41, -3.5346e-41, -7.4253e-41],
          [ 8.2525e-41, -3.2950e-41, -3.5254e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4185]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0091]], device='cuda:0')

Epoch: 39 | Batch_idx: 0 |  Loss: (0.2122) | Acc: (94.00%) (121/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.2491) | Acc: (91.00%) (1292/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.2458) | Acc: (91.00%) (2462/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.2485) | Acc: (91.00%) (3635/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.2532) | Acc: (91.00%) (4803/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.2500) | Acc: (91.00%) (5985/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.2482) | Acc: (91.00%) (7176/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.2459) | Acc: (91.00%) (8348/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.2466) | Acc: (91.00%) (9523/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.2494) | Acc: (91.00%) (10682/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.2491) | Acc: (91.00%) (11849/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.2501) | Acc: (91.00%) (13017/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.2502) | Acc: (91.00%) (14194/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.2519) | Acc: (91.00%) (15355/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.2539) | Acc: (91.00%) (16521/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.2565) | Acc: (91.00%) (17675/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.2583) | Acc: (91.00%) (18828/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.2594) | Acc: (91.00%) (19980/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.2577) | Acc: (91.00%) (21165/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.2596) | Acc: (91.00%) (22315/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.2595) | Acc: (91.00%) (23483/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.2593) | Acc: (91.00%) (24652/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.2601) | Acc: (91.00%) (25803/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.2613) | Acc: (91.00%) (26970/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.2625) | Acc: (91.00%) (28123/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.2630) | Acc: (91.00%) (29281/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.2629) | Acc: (91.00%) (30456/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.2619) | Acc: (91.00%) (31628/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.2618) | Acc: (91.00%) (32797/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.2622) | Acc: (91.00%) (33966/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.2620) | Acc: (91.00%) (35135/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.2624) | Acc: (91.00%) (36293/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.2623) | Acc: (91.00%) (37463/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.2638) | Acc: (91.00%) (38602/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.2638) | Acc: (91.00%) (39773/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.2637) | Acc: (91.00%) (40943/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.2627) | Acc: (91.00%) (42125/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.2624) | Acc: (91.00%) (43293/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.2618) | Acc: (91.00%) (44457/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.2619) | Acc: (91.00%) (45572/50000)
# TEST : Loss: (0.3364) | Acc: (88.00%) (8880/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4034e-01, -2.3345e-01,  7.7254e-02],
          [-7.4318e-02,  2.5258e-01,  1.6883e-01],
          [ 1.0981e-01, -2.8844e-03, -1.0329e-01]],

         [[-2.3169e-01,  1.9899e-01,  2.0349e-01],
          [-7.2648e-03,  2.7947e-01,  1.6687e-01],
          [ 2.0465e-01, -1.2419e-01,  1.3195e-01]],

         [[-1.7319e-01, -1.2276e-02, -2.1751e-02],
          [-2.1439e-01, -4.1286e-02, -3.6901e-02],
          [-1.5544e-01, -2.6213e-02, -1.1243e-01]]],


        [[[ 4.0636e-02, -5.8216e-02,  4.5011e-02],
          [-1.9562e-02, -3.5375e-02,  3.4743e-02],
          [ 5.1909e-02, -4.2413e-04, -7.4656e-02]],

         [[-4.3403e-02,  1.3827e-03, -8.4083e-04],
          [ 3.2730e-02,  2.2975e-02,  4.2918e-02],
          [ 4.7363e-02,  5.4432e-02, -6.8590e-02]],

         [[ 2.0604e-02, -4.9078e-02,  2.4951e-02],
          [-3.9730e-02,  4.6149e-02,  6.4767e-02],
          [ 2.2551e-02, -2.7601e-03, -2.8134e-02]]],


        [[[ 5.4354e-02,  1.1864e-01, -8.4226e-02],
          [ 8.5438e-03,  1.6017e-01, -1.1539e-01],
          [ 7.2042e-02,  2.5554e-01,  2.3635e-01]],

         [[-1.8668e-01, -9.7168e-04, -1.4427e-01],
          [-2.4010e-01, -1.5518e-01, -2.0731e-01],
          [-2.1264e-01, -2.9941e-01,  4.8562e-02]],

         [[ 1.7085e-01,  3.6143e-02,  2.1299e-01],
          [ 1.6392e-01,  6.5883e-02,  3.7513e-02],
          [-4.0950e-02,  8.5629e-02,  6.7383e-02]]],


        ...,


        [[[ 2.4503e-01,  2.7916e-02,  1.1521e-02],
          [ 2.0720e-01, -2.2680e-01, -5.3070e-02],
          [-8.1619e-02, -1.5281e-01, -1.2740e-01]],

         [[-8.8635e-02, -2.3050e-02, -6.3114e-02],
          [-1.5956e-01, -2.2836e-01,  1.6749e-01],
          [-2.0370e-02,  3.0347e-01,  2.7408e-01]],

         [[-2.3459e-02, -3.8282e-02,  2.4242e-01],
          [ 4.6944e-02, -2.6533e-01, -1.1670e-01],
          [ 4.3908e-02, -4.6007e-02, -7.8122e-02]]],


        [[[ 1.0297e-01,  3.5390e-02,  2.1076e-01],
          [ 1.8489e-01,  1.3740e-01, -2.2636e-02],
          [-2.6246e-01, -1.7893e-01, -9.6646e-02]],

         [[ 9.1129e-02,  2.1568e-02, -1.3543e-01],
          [ 6.9017e-02, -4.1190e-02, -2.8569e-01],
          [ 1.2758e-02,  1.5436e-01, -3.0138e-02]],

         [[-1.4343e-01, -4.5034e-02, -2.3162e-01],
          [-5.2190e-02,  9.2359e-02,  5.4118e-02],
          [ 1.7244e-01,  1.8115e-01,  1.3492e-01]]],


        [[[ 6.0522e-42,  1.4806e-41, -5.9565e-41],
          [-1.0779e-40,  9.3219e-41, -8.4708e-41],
          [-1.0892e-41, -9.6240e-41,  1.4400e-41]],

         [[ 5.7378e-41, -9.1028e-42, -1.2725e-41],
          [-8.8842e-42,  9.6793e-41,  8.5544e-41],
          [-9.6202e-41,  9.9000e-41, -8.9177e-41]],

         [[-7.5824e-41, -6.5372e-41,  5.0307e-42],
          [-7.5349e-41, -4.2497e-41,  6.1755e-41],
          [-8.9530e-41,  5.1477e-41,  2.9255e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3943]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0030]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 40 | Batch_idx: 0 |  Loss: (0.2109) | Acc: (94.00%) (121/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.2603) | Acc: (91.00%) (1284/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.2743) | Acc: (90.00%) (2437/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.2966) | Acc: (89.00%) (3561/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.3072) | Acc: (89.00%) (4694/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.3158) | Acc: (89.00%) (5825/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.3279) | Acc: (88.00%) (6922/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.3306) | Acc: (88.00%) (8046/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.3347) | Acc: (88.00%) (9161/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.3399) | Acc: (88.00%) (10279/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.3420) | Acc: (88.00%) (11397/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.3465) | Acc: (88.00%) (12508/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.3513) | Acc: (87.00%) (13615/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.3530) | Acc: (87.00%) (14716/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.3566) | Acc: (87.00%) (15822/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.3590) | Acc: (87.00%) (16931/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.3586) | Acc: (87.00%) (18062/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.3604) | Acc: (87.00%) (19171/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.3581) | Acc: (87.00%) (20309/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.3607) | Acc: (87.00%) (21417/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.3614) | Acc: (87.00%) (22529/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.3611) | Acc: (87.00%) (23660/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.3623) | Acc: (87.00%) (24767/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.3607) | Acc: (87.00%) (25908/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.3589) | Acc: (87.00%) (27057/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.3575) | Acc: (87.00%) (28198/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.3570) | Acc: (87.00%) (29325/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.3562) | Acc: (87.00%) (30459/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.3560) | Acc: (87.00%) (31586/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.3554) | Acc: (87.00%) (32715/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.3540) | Acc: (87.00%) (33845/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.3520) | Acc: (87.00%) (34999/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.3523) | Acc: (87.00%) (36114/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.3526) | Acc: (87.00%) (37239/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.3528) | Acc: (87.00%) (38366/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.3520) | Acc: (87.00%) (39495/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.3514) | Acc: (87.00%) (40625/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.3502) | Acc: (87.00%) (41767/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.3497) | Acc: (87.00%) (42903/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.3487) | Acc: (88.00%) (44009/50000)
# TEST : Loss: (0.3950) | Acc: (87.00%) (8712/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4335e-01, -2.3383e-01,  6.7865e-02],
          [-7.0391e-02,  2.6031e-01,  1.6502e-01],
          [ 1.1582e-01, -6.9264e-04, -1.1121e-01]],

         [[-2.3401e-01,  2.0117e-01,  2.0121e-01],
          [-5.8458e-03,  2.8601e-01,  1.6495e-01],
          [ 2.0590e-01, -1.2681e-01,  1.2018e-01]],

         [[-1.7891e-01, -1.5266e-02, -2.6132e-02],
          [-2.1984e-01, -4.3832e-02, -4.0776e-02],
          [-1.6120e-01, -3.7666e-02, -1.2390e-01]]],


        [[[ 3.2698e-02, -4.8201e-02,  3.6837e-02],
          [-1.5996e-02, -2.8768e-02,  2.8368e-02],
          [ 4.2876e-02, -3.2478e-04, -5.8862e-02]],

         [[-3.5844e-02,  5.4001e-04, -7.8961e-04],
          [ 2.7105e-02,  1.8958e-02,  3.5184e-02],
          [ 3.9212e-02,  4.4526e-02, -5.3483e-02]],

         [[ 1.5910e-02, -4.0077e-02,  1.9997e-02],
          [-3.2142e-02,  3.7130e-02,  5.2344e-02],
          [ 1.8491e-02, -2.1401e-03, -2.1474e-02]]],


        [[[ 6.8055e-02,  1.2869e-01, -7.8767e-02],
          [ 2.1353e-02,  1.6928e-01, -1.1575e-01],
          [ 7.8736e-02,  2.6103e-01,  2.3600e-01]],

         [[-1.8126e-01,  5.5832e-04, -1.4381e-01],
          [-2.3985e-01, -1.6112e-01, -2.1256e-01],
          [-2.1913e-01, -3.1121e-01,  4.1288e-02]],

         [[ 1.7800e-01,  3.8600e-02,  2.0595e-01],
          [ 1.6969e-01,  6.6362e-02,  3.1833e-02],
          [-4.7338e-02,  7.3724e-02,  5.4281e-02]]],


        ...,


        [[[ 2.6314e-01,  4.5352e-02,  2.3416e-02],
          [ 2.3224e-01, -2.0529e-01, -3.2312e-02],
          [-5.2526e-02, -1.3096e-01, -1.0647e-01]],

         [[-8.4802e-02, -1.0008e-02, -4.6575e-02],
          [-1.5109e-01, -2.0945e-01,  1.9279e-01],
          [-3.0519e-04,  3.2527e-01,  2.9693e-01]],

         [[-9.8827e-03, -2.1076e-02,  2.4992e-01],
          [ 5.9733e-02, -2.4718e-01, -1.0484e-01],
          [ 6.0534e-02, -3.0868e-02, -6.8360e-02]]],


        [[[ 1.0584e-01,  4.9208e-02,  2.2940e-01],
          [ 1.9696e-01,  1.5291e-01, -1.0308e-02],
          [-2.5161e-01, -1.6590e-01, -8.4359e-02]],

         [[ 7.6866e-02,  1.8711e-02, -1.2704e-01],
          [ 6.0057e-02, -4.3292e-02, -2.8438e-01],
          [ 1.0849e-02,  1.5832e-01, -2.3972e-02]],

         [[-1.5754e-01, -4.6375e-02, -2.2308e-01],
          [-5.4198e-02,  1.0072e-01,  6.3288e-02],
          [ 1.7806e-01,  1.9828e-01,  1.4937e-01]]],


        [[[-1.6280e-41, -3.8496e-41, -9.0057e-41],
          [ 3.7587e-41, -1.0240e-40, -4.0612e-41],
          [ 4.5879e-42,  8.3030e-41,  8.3658e-41]],

         [[-5.8437e-41, -1.0702e-41,  4.2368e-41],
          [ 1.0644e-40, -1.0396e-40, -9.4876e-41],
          [-1.9429e-41, -9.7560e-41, -2.7168e-41]],

         [[ 2.7777e-41,  6.7227e-41,  4.1921e-41],
          [ 5.2047e-41, -1.5086e-41, -1.6863e-41],
          [ 8.4198e-41, -8.0939e-41,  9.1596e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0269, -0.0264, -0.0188],
          [-0.0188, -0.0145, -0.0045],
          [-0.0219, -0.0195, -0.0134]],

         [[-0.0160, -0.0151, -0.0082],
          [-0.0099, -0.0048,  0.0033],
          [-0.0150, -0.0122, -0.0088]],

         [[-0.0048,  0.0002,  0.0083],
          [-0.0009,  0.0080,  0.0194],
          [-0.0072, -0.0003,  0.0092]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0794, -0.0903, -0.0991],
          [-0.0966, -0.1152, -0.1114],
          [-0.0699, -0.0919, -0.0946]],

         [[-0.0621, -0.0624, -0.0650],
          [-0.0645, -0.0809, -0.0792],
          [-0.0212, -0.0538, -0.0599]],

         [[-0.0074, -0.0154, -0.0265],
          [-0.0083, -0.0333, -0.0388],
          [ 0.0269, -0.0111, -0.0173]]],


        ...,


        [[[-0.0069, -0.0022, -0.0029],
          [-0.0138, -0.0083, -0.0108],
          [-0.0040, -0.0034, -0.0039]],

         [[ 0.0085,  0.0119,  0.0105],
          [-0.0004,  0.0027,  0.0003],
          [ 0.0040,  0.0053,  0.0057]],

         [[ 0.0163,  0.0197,  0.0184],
          [ 0.0093,  0.0117,  0.0086],
          [ 0.0121,  0.0131,  0.0111]]],


        [[[-0.0362, -0.0398, -0.0376],
          [-0.0262, -0.0243, -0.0284],
          [-0.0260, -0.0221, -0.0317]],

         [[-0.0150, -0.0167, -0.0137],
          [-0.0029,  0.0016, -0.0032],
          [ 0.0016,  0.0075, -0.0010]],

         [[-0.0154, -0.0176, -0.0145],
          [-0.0017,  0.0008, -0.0046],
          [ 0.0037,  0.0066, -0.0028]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3899]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 41 | Batch_idx: 0 |  Loss: (0.3330) | Acc: (89.00%) (115/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.2897) | Acc: (90.00%) (1271/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.2847) | Acc: (90.00%) (2442/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.2863) | Acc: (90.00%) (3593/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.2923) | Acc: (90.00%) (4737/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.2917) | Acc: (90.00%) (5892/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.2905) | Acc: (90.00%) (7056/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.2918) | Acc: (90.00%) (8223/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.2941) | Acc: (90.00%) (9368/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.2944) | Acc: (90.00%) (10509/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.2913) | Acc: (90.00%) (11681/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.2890) | Acc: (90.00%) (12840/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.2867) | Acc: (90.00%) (14002/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.2882) | Acc: (90.00%) (15144/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.2879) | Acc: (90.00%) (16289/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.2876) | Acc: (90.00%) (17448/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.2868) | Acc: (90.00%) (18605/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.2876) | Acc: (90.00%) (19754/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.2895) | Acc: (90.00%) (20895/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.2894) | Acc: (90.00%) (22042/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.2890) | Acc: (90.00%) (23200/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.2884) | Acc: (90.00%) (24361/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.2866) | Acc: (90.00%) (25528/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.2850) | Acc: (90.00%) (26697/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.2858) | Acc: (90.00%) (27836/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.2875) | Acc: (90.00%) (28969/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.2881) | Acc: (90.00%) (30123/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.2885) | Acc: (90.00%) (31276/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.2899) | Acc: (90.00%) (32413/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.2894) | Acc: (90.00%) (33578/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.2887) | Acc: (90.00%) (34741/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.2889) | Acc: (90.00%) (35891/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.2887) | Acc: (90.00%) (37051/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.2886) | Acc: (90.00%) (38208/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.2892) | Acc: (90.00%) (39360/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.2895) | Acc: (90.00%) (40509/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.2893) | Acc: (90.00%) (41660/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.2897) | Acc: (90.00%) (42798/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.2897) | Acc: (90.00%) (43953/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.2904) | Acc: (90.00%) (45054/50000)
# TEST : Loss: (0.3985) | Acc: (87.00%) (8729/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4531e-01, -2.3466e-01,  7.2962e-02],
          [-7.4327e-02,  2.6190e-01,  1.7106e-01],
          [ 1.0758e-01, -2.9409e-03, -1.0403e-01]],

         [[-2.2819e-01,  2.0770e-01,  2.1231e-01],
          [-2.9060e-03,  2.9513e-01,  1.7621e-01],
          [ 2.0264e-01, -1.2129e-01,  1.3111e-01]],

         [[-1.7433e-01, -1.3242e-02, -1.7843e-02],
          [-2.2000e-01, -4.3970e-02, -3.7882e-02],
          [-1.6782e-01, -4.0049e-02, -1.1855e-01]]],


        [[[ 2.5672e-02, -3.7442e-02,  2.9262e-02],
          [-1.2495e-02, -2.2295e-02,  2.2102e-02],
          [ 3.3998e-02, -1.8419e-04, -4.4491e-02]],

         [[-2.7865e-02,  5.3625e-04, -5.4815e-04],
          [ 2.1375e-02,  1.4780e-02,  2.7293e-02],
          [ 3.0955e-02,  3.4589e-02, -4.0388e-02]],

         [[ 1.2317e-02, -3.0447e-02,  1.5566e-02],
          [-2.4852e-02,  2.8466e-02,  4.0219e-02],
          [ 1.4473e-02, -1.5679e-03, -1.6064e-02]]],


        [[[ 6.4169e-02,  1.2934e-01, -7.6495e-02],
          [ 2.6654e-02,  1.7490e-01, -1.1108e-01],
          [ 9.5293e-02,  2.7355e-01,  2.4471e-01]],

         [[-1.8765e-01, -1.9936e-03, -1.4348e-01],
          [-2.4043e-01, -1.6217e-01, -2.1259e-01],
          [-2.0626e-01, -3.0384e-01,  4.5709e-02]],

         [[ 1.7333e-01,  4.0230e-02,  2.0919e-01],
          [ 1.7463e-01,  7.1073e-02,  3.8023e-02],
          [-2.8636e-02,  8.7568e-02,  6.1424e-02]]],


        ...,


        [[[ 2.6314e-01,  4.1929e-02,  1.3605e-02],
          [ 2.2183e-01, -2.2146e-01, -4.2258e-02],
          [-6.6841e-02, -1.4388e-01, -1.1136e-01]],

         [[-8.6444e-02, -1.0189e-02, -4.5580e-02],
          [-1.5957e-01, -2.2146e-01,  1.9143e-01],
          [-1.1139e-02,  3.1647e-01,  2.9715e-01]],

         [[-1.9994e-03, -9.9275e-03,  2.5384e-01],
          [ 5.8693e-02, -2.4824e-01, -1.0260e-01],
          [ 5.4637e-02, -3.4210e-02, -6.7555e-02]]],


        [[[ 9.7660e-02,  5.4060e-02,  2.2476e-01],
          [ 1.9402e-01,  1.5480e-01, -2.0196e-02],
          [-2.5497e-01, -1.7075e-01, -9.6714e-02]],

         [[ 6.4784e-02,  1.7888e-02, -1.3607e-01],
          [ 5.4491e-02, -4.5355e-02, -2.9841e-01],
          [ 4.9145e-03,  1.5043e-01, -3.8285e-02]],

         [[-1.7006e-01, -4.3462e-02, -2.2211e-01],
          [-5.8057e-02,  1.0541e-01,  6.0088e-02],
          [ 1.7273e-01,  1.9808e-01,  1.4321e-01]]],


        [[[-5.5603e-36,  2.1483e-36,  7.9491e-36],
          [-5.6545e-36, -4.1843e-36,  6.8526e-36],
          [-1.0660e-36, -1.7918e-36,  2.2054e-36]],

         [[ 1.5014e-36,  1.4905e-36,  3.6270e-36],
          [ 1.8105e-36,  3.6718e-36, -2.7393e-36],
          [-3.6957e-37,  1.4299e-37, -3.3313e-38]],

         [[-3.9087e-36, -1.6391e-36, -4.3126e-36],
          [-3.6417e-36, -2.0857e-36, -5.8973e-36],
          [-6.2517e-37, -8.5230e-38, -1.3916e-36]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0160,  0.0107,  0.0073],
          [ 0.0057,  0.0016, -0.0002],
          [-0.0084, -0.0032, -0.0039]],

         [[ 0.0033,  0.0025,  0.0026],
          [-0.0087, -0.0089, -0.0078],
          [-0.0225, -0.0136, -0.0106]],

         [[-0.0052, -0.0058, -0.0049],
          [-0.0177, -0.0171, -0.0170],
          [-0.0238, -0.0140, -0.0156]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0039,  0.0166, -0.0096],
          [ 0.0078,  0.0240, -0.0007],
          [ 0.0082, -0.0023, -0.0271]],

         [[ 0.0112,  0.0201, -0.0074],
          [ 0.0178,  0.0301,  0.0024],
          [ 0.0261,  0.0114, -0.0202]],

         [[ 0.0323,  0.0354,  0.0057],
          [ 0.0369,  0.0451,  0.0198],
          [ 0.0398,  0.0234, -0.0024]]],


        ...,


        [[[-0.0030,  0.0020,  0.0186],
          [-0.0038,  0.0005,  0.0044],
          [-0.0046, -0.0046,  0.0018]],

         [[-0.0008,  0.0019,  0.0169],
          [-0.0056, -0.0013,  0.0028],
          [-0.0114, -0.0100, -0.0001]],

         [[ 0.0113,  0.0109,  0.0199],
          [ 0.0029,  0.0049,  0.0054],
          [-0.0044, -0.0041,  0.0046]]],


        [[[ 0.0049,  0.0063,  0.0107],
          [-0.0116, -0.0067,  0.0033],
          [ 0.0013,  0.0022,  0.0092]],

         [[ 0.0027,  0.0067,  0.0102],
          [-0.0051,  0.0002,  0.0077],
          [ 0.0137,  0.0135,  0.0180]],

         [[-0.0079, -0.0004,  0.0004],
          [-0.0115, -0.0043, -0.0012],
          [ 0.0038,  0.0044,  0.0076]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3886]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 42 | Batch_idx: 0 |  Loss: (0.2542) | Acc: (92.00%) (118/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.2689) | Acc: (90.00%) (1268/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.2941) | Acc: (89.00%) (2416/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.3058) | Acc: (89.00%) (3559/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.3095) | Acc: (89.00%) (4704/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.3180) | Acc: (89.00%) (5837/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.3178) | Acc: (89.00%) (6972/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.3117) | Acc: (89.00%) (8127/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.3078) | Acc: (89.00%) (9284/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.3052) | Acc: (89.00%) (10449/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.3036) | Acc: (89.00%) (11610/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.3050) | Acc: (89.00%) (12748/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.3019) | Acc: (89.00%) (13906/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.2995) | Acc: (89.00%) (15071/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.3001) | Acc: (89.00%) (16224/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.2969) | Acc: (90.00%) (17396/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.2976) | Acc: (89.00%) (18534/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.2981) | Acc: (89.00%) (19688/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.2958) | Acc: (90.00%) (20861/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.2938) | Acc: (90.00%) (22024/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.2939) | Acc: (90.00%) (23173/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.2919) | Acc: (90.00%) (24355/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.2906) | Acc: (90.00%) (25528/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.2888) | Acc: (90.00%) (26702/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.2866) | Acc: (90.00%) (27876/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.2856) | Acc: (90.00%) (29039/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.2845) | Acc: (90.00%) (30201/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.2851) | Acc: (90.00%) (31355/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.2845) | Acc: (90.00%) (32523/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.2835) | Acc: (90.00%) (33698/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.2825) | Acc: (90.00%) (34873/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.2830) | Acc: (90.00%) (36025/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.2821) | Acc: (90.00%) (37187/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.2809) | Acc: (90.00%) (38351/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.2796) | Acc: (90.00%) (39538/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.2799) | Acc: (90.00%) (40698/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.2792) | Acc: (90.00%) (41865/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.2780) | Acc: (90.00%) (43049/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.2776) | Acc: (90.00%) (44218/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.2779) | Acc: (90.00%) (45334/50000)
# TEST : Loss: (0.3430) | Acc: (88.00%) (8873/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4808e-01, -2.3625e-01,  7.1574e-02],
          [-7.6296e-02,  2.5978e-01,  1.6895e-01],
          [ 1.0515e-01, -4.8045e-03, -1.0600e-01]],

         [[-2.2978e-01,  2.0547e-01,  2.1090e-01],
          [-3.4651e-03,  2.9426e-01,  1.7551e-01],
          [ 2.0164e-01, -1.2119e-01,  1.3019e-01]],

         [[-1.7499e-01, -1.3565e-02, -1.7490e-02],
          [-2.1824e-01, -4.2153e-02, -3.6296e-02],
          [-1.6640e-01, -3.9187e-02, -1.1755e-01]]],


        [[[ 1.9039e-02, -2.7623e-02,  2.2053e-02],
          [-9.3146e-03, -1.6413e-02,  1.6244e-02],
          [ 2.5583e-02, -1.3548e-04, -3.1739e-02]],

         [[-2.0596e-02,  3.9367e-04, -4.0793e-04],
          [ 1.5935e-02,  1.0840e-02,  1.9962e-02],
          [ 2.3158e-02,  2.5367e-02, -2.8793e-02]],

         [[ 8.9310e-03, -2.1888e-02,  1.1410e-02],
          [-1.8238e-02,  2.0528e-02,  2.9116e-02],
          [ 1.0689e-02, -1.1326e-03, -1.1371e-02]]],


        [[[ 6.5661e-02,  1.3023e-01, -7.5117e-02],
          [ 2.8891e-02,  1.7621e-01, -1.1029e-01],
          [ 9.7779e-02,  2.7580e-01,  2.4583e-01]],

         [[-1.8687e-01, -2.0760e-03, -1.4329e-01],
          [-2.3903e-01, -1.6181e-01, -2.1302e-01],
          [-2.0481e-01, -3.0214e-01,  4.5915e-02]],

         [[ 1.7190e-01,  3.8668e-02,  2.0777e-01],
          [ 1.7380e-01,  6.9532e-02,  3.5851e-02],
          [-2.8679e-02,  8.7529e-02,  6.0332e-02]]],


        ...,


        [[[ 2.6552e-01,  4.4914e-02,  1.5586e-02],
          [ 2.2331e-01, -2.1878e-01, -4.0774e-02],
          [-6.4553e-02, -1.4267e-01, -1.1038e-01]],

         [[-8.0945e-02, -4.9508e-03, -4.1393e-02],
          [-1.5455e-01, -2.1644e-01,  1.9421e-01],
          [-6.5615e-03,  3.1873e-01,  2.9874e-01]],

         [[ 3.7753e-03, -3.5294e-03,  2.5848e-01],
          [ 6.3842e-02, -2.4095e-01, -9.6105e-02],
          [ 6.0222e-02, -2.8268e-02, -6.2037e-02]]],


        [[[ 9.7947e-02,  5.4777e-02,  2.2397e-01],
          [ 1.9514e-01,  1.5611e-01, -2.0276e-02],
          [-2.5388e-01, -1.6990e-01, -9.7445e-02]],

         [[ 6.6490e-02,  2.0248e-02, -1.3445e-01],
          [ 5.6996e-02, -4.2472e-02, -2.9681e-01],
          [ 5.7677e-03,  1.5121e-01, -3.8367e-02]],

         [[-1.6797e-01, -4.1616e-02, -2.2068e-01],
          [-5.5737e-02,  1.0714e-01,  6.0365e-02],
          [ 1.7268e-01,  1.9811e-01,  1.4221e-01]]],


        [[[-9.8378e-41, -1.0526e-40, -1.1032e-40],
          [ 1.2224e-40, -5.2015e-41,  9.9625e-41],
          [ 6.0453e-41, -1.1426e-40, -8.7775e-41]],

         [[ 1.5407e-41,  5.0583e-41,  1.0057e-40],
          [ 1.3228e-40,  1.1252e-40, -7.8379e-41],
          [ 9.9767e-41,  1.0302e-40, -1.0237e-40]],

         [[-4.9739e-41, -1.2374e-40, -5.9394e-41],
          [ 3.7912e-41, -1.1321e-40,  1.2382e-40],
          [-1.1013e-40, -4.9928e-41,  6.3449e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3048]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0286]], device='cuda:0')

Epoch: 43 | Batch_idx: 0 |  Loss: (0.2850) | Acc: (91.00%) (117/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.2632) | Acc: (91.00%) (1286/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.2708) | Acc: (91.00%) (2450/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.2583) | Acc: (91.00%) (3634/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.2572) | Acc: (91.00%) (4805/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.2511) | Acc: (91.00%) (5980/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.2504) | Acc: (91.00%) (7164/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.2578) | Acc: (91.00%) (8315/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.2568) | Acc: (91.00%) (9482/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.2556) | Acc: (91.00%) (10657/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.2561) | Acc: (91.00%) (11820/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.2559) | Acc: (91.00%) (12988/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.2547) | Acc: (91.00%) (14166/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.2556) | Acc: (91.00%) (15329/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.2541) | Acc: (91.00%) (16501/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.2558) | Acc: (91.00%) (17659/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.2564) | Acc: (91.00%) (18824/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.2550) | Acc: (91.00%) (20003/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.2549) | Acc: (91.00%) (21168/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.2533) | Acc: (91.00%) (22364/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.2534) | Acc: (91.00%) (23533/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.2542) | Acc: (91.00%) (24700/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.2541) | Acc: (91.00%) (25874/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.2542) | Acc: (91.00%) (27043/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.2542) | Acc: (91.00%) (28208/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.2554) | Acc: (91.00%) (29363/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.2544) | Acc: (91.00%) (30545/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.2541) | Acc: (91.00%) (31715/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.2538) | Acc: (91.00%) (32894/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.2542) | Acc: (91.00%) (34049/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.2542) | Acc: (91.00%) (35222/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.2533) | Acc: (91.00%) (36411/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.2528) | Acc: (91.00%) (37585/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.2514) | Acc: (91.00%) (38779/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.2505) | Acc: (91.00%) (39960/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.2501) | Acc: (91.00%) (41137/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.2498) | Acc: (91.00%) (42320/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.2494) | Acc: (91.00%) (43508/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.2502) | Acc: (91.00%) (44663/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.2500) | Acc: (91.00%) (45798/50000)
# TEST : Loss: (0.3295) | Acc: (89.00%) (8909/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4760e-01, -2.3543e-01,  7.1310e-02],
          [-7.6035e-02,  2.5882e-01,  1.6829e-01],
          [ 1.0479e-01, -4.7870e-03, -1.0561e-01]],

         [[-2.2899e-01,  2.0472e-01,  2.1011e-01],
          [-3.4525e-03,  2.9313e-01,  1.7483e-01],
          [ 2.0091e-01, -1.2073e-01,  1.2970e-01]],

         [[-1.7434e-01, -1.3516e-02, -1.7428e-02],
          [-2.1741e-01, -4.1998e-02, -3.6166e-02],
          [-1.6577e-01, -3.9042e-02, -1.1713e-01]]],


        [[[ 1.3229e-02, -1.9073e-02,  1.5627e-02],
          [-6.5143e-03, -1.1303e-02,  1.1163e-02],
          [ 1.8094e-02, -9.3610e-05, -2.1037e-02]],

         [[-1.4255e-02,  2.6961e-04, -2.8560e-04],
          [ 1.1141e-02,  7.4304e-03,  1.3636e-02],
          [ 1.6263e-02,  1.7388e-02, -1.9069e-02]],

         [[ 6.0361e-03, -1.4642e-02,  7.8152e-03],
          [-1.2512e-02,  1.3785e-02,  1.9644e-02],
          [ 7.3886e-03, -7.6279e-04, -7.4669e-03]]],


        [[[ 6.5568e-02,  1.3004e-01, -7.5009e-02],
          [ 2.8850e-02,  1.7597e-01, -1.1013e-01],
          [ 9.7635e-02,  2.7539e-01,  2.4547e-01]],

         [[-1.8659e-01, -2.0728e-03, -1.4306e-01],
          [-2.3866e-01, -1.6156e-01, -2.1268e-01],
          [-2.0448e-01, -3.0166e-01,  4.5844e-02]],

         [[ 1.7162e-01,  3.8605e-02,  2.0744e-01],
          [ 1.7352e-01,  6.9417e-02,  3.5792e-02],
          [-2.8631e-02,  8.7386e-02,  6.0233e-02]]],


        ...,


        [[[ 2.6448e-01,  4.4738e-02,  1.5524e-02],
          [ 2.2241e-01, -2.1789e-01, -4.0614e-02],
          [-6.4292e-02, -1.4210e-01, -1.0996e-01]],

         [[-8.0613e-02, -4.9301e-03, -4.1222e-02],
          [-1.5389e-01, -2.1551e-01,  1.9341e-01],
          [-6.5342e-03,  3.1742e-01,  2.9757e-01]],

         [[ 3.7589e-03, -3.5134e-03,  2.5735e-01],
          [ 6.3547e-02, -2.3978e-01, -9.5674e-02],
          [ 5.9950e-02, -2.8139e-02, -6.1774e-02]]],


        [[[ 9.7665e-02,  5.4623e-02,  2.2337e-01],
          [ 1.9456e-01,  1.5565e-01, -2.0219e-02],
          [-2.5316e-01, -1.6942e-01, -9.7171e-02]],

         [[ 6.6296e-02,  2.0189e-02, -1.3405e-01],
          [ 5.6822e-02, -4.2342e-02, -2.9591e-01],
          [ 5.7507e-03,  1.5076e-01, -3.8253e-02]],

         [[-1.6747e-01, -4.1489e-02, -2.1997e-01],
          [-5.5566e-02,  1.0680e-01,  6.0174e-02],
          [ 1.7216e-01,  1.9750e-01,  1.4177e-01]]],


        [[[-1.1795e-40, -4.6005e-42,  1.1725e-40],
          [-1.4351e-40, -9.4073e-41,  1.6125e-41],
          [ 7.2641e-41,  8.8187e-41, -8.7298e-41]],

         [[-1.4898e-40, -1.4658e-40, -8.7562e-41],
          [-1.2953e-40, -9.4016e-41, -1.4162e-40],
          [ 5.4390e-41, -1.1232e-40,  1.7401e-41]],

         [[-1.3735e-40,  1.1526e-40,  8.5534e-41],
          [-1.2633e-40, -3.2066e-41,  1.1089e-40],
          [ 9.2598e-41, -5.9956e-41,  7.6079e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3132]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0204]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 44 | Batch_idx: 0 |  Loss: (0.3144) | Acc: (92.00%) (118/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.2716) | Acc: (90.00%) (1279/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.2926) | Acc: (89.00%) (2415/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.3023) | Acc: (89.00%) (3547/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.3049) | Acc: (89.00%) (4683/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.3135) | Acc: (88.00%) (5809/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.3205) | Acc: (88.00%) (6929/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.3200) | Acc: (88.00%) (8076/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.3210) | Acc: (88.00%) (9208/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.3258) | Acc: (88.00%) (10328/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.3286) | Acc: (88.00%) (11454/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.3310) | Acc: (88.00%) (12577/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.3324) | Acc: (88.00%) (13721/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.3365) | Acc: (88.00%) (14831/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.3373) | Acc: (88.00%) (15953/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.3370) | Acc: (88.00%) (17084/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.3353) | Acc: (88.00%) (18223/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.3342) | Acc: (88.00%) (19364/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.3329) | Acc: (88.00%) (20504/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.3340) | Acc: (88.00%) (21647/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.3352) | Acc: (88.00%) (22771/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.3370) | Acc: (88.00%) (23892/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.3394) | Acc: (88.00%) (25006/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.3393) | Acc: (88.00%) (26128/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.3403) | Acc: (88.00%) (27248/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.3401) | Acc: (88.00%) (28380/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.3400) | Acc: (88.00%) (29517/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.3385) | Acc: (88.00%) (30679/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.3377) | Acc: (88.00%) (31819/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.3365) | Acc: (88.00%) (32972/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.3356) | Acc: (88.00%) (34112/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.3355) | Acc: (88.00%) (35244/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.3350) | Acc: (88.00%) (36394/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.3339) | Acc: (88.00%) (37542/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.3332) | Acc: (88.00%) (38693/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.3320) | Acc: (88.00%) (39842/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.3315) | Acc: (88.00%) (40982/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.3301) | Acc: (88.00%) (42153/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.3288) | Acc: (88.00%) (43310/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.3292) | Acc: (88.00%) (44398/50000)
# TEST : Loss: (0.4175) | Acc: (86.00%) (8622/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4989e-01, -2.3566e-01,  7.7932e-02],
          [-7.6608e-02,  2.6666e-01,  1.8301e-01],
          [ 1.0909e-01, -7.1176e-04, -9.9235e-02]],

         [[-2.3032e-01,  2.0493e-01,  2.1439e-01],
          [-7.6480e-03,  2.9979e-01,  1.8612e-01],
          [ 2.0252e-01, -1.1463e-01,  1.3627e-01]],

         [[-1.7457e-01, -1.3716e-02, -1.8282e-02],
          [-2.2488e-01, -4.2701e-02, -3.4321e-02],
          [-1.6530e-01, -3.9017e-02, -1.1587e-01]]],


        [[[ 8.5026e-03, -1.2138e-02,  1.0270e-02],
          [-4.2053e-03, -7.1707e-03,  7.0699e-03],
          [ 1.1869e-02, -5.9287e-05, -1.2746e-02]],

         [[-9.0892e-03,  1.7915e-04, -1.8579e-04],
          [ 7.2138e-03,  4.6947e-03,  8.5728e-03],
          [ 1.0576e-02,  1.0975e-02, -1.1542e-02]],

         [[ 3.7580e-03, -8.9626e-03,  4.9268e-03],
          [-7.8969e-03,  8.4899e-03,  1.2163e-02],
          [ 4.7155e-03, -4.7083e-04, -4.4740e-03]]],


        [[[ 6.4177e-02,  1.2196e-01, -8.6187e-02],
          [ 2.1835e-02,  1.7023e-01, -1.1437e-01],
          [ 8.8650e-02,  2.6586e-01,  2.4458e-01]],

         [[-1.8671e-01, -9.0400e-03, -1.4719e-01],
          [-2.5053e-01, -1.7037e-01, -2.1260e-01],
          [-2.1673e-01, -3.1544e-01,  4.4994e-02]],

         [[ 1.7964e-01,  4.1675e-02,  2.0989e-01],
          [ 1.7842e-01,  7.7947e-02,  4.7066e-02],
          [-2.5836e-02,  8.5483e-02,  6.4438e-02]]],


        ...,


        [[[ 2.6318e-01,  3.3707e-02, -7.8271e-03],
          [ 2.2718e-01, -2.1972e-01, -4.6747e-02],
          [-5.8174e-02, -1.4992e-01, -1.2182e-01]],

         [[-1.0308e-01, -3.0067e-02, -7.1119e-02],
          [-1.6695e-01, -2.2793e-01,  1.8268e-01],
          [-1.2319e-02,  2.9941e-01,  2.7865e-01]],

         [[-2.6091e-02, -3.7341e-02,  2.1740e-01],
          [ 3.8914e-02, -2.7053e-01, -1.2635e-01],
          [ 3.1629e-02, -7.1580e-02, -1.0463e-01]]],


        [[[ 9.8597e-02,  5.8017e-02,  2.2043e-01],
          [ 2.0479e-01,  1.5870e-01, -2.4191e-02],
          [-2.5420e-01, -1.7462e-01, -9.4343e-02]],

         [[ 6.9334e-02,  1.7639e-02, -1.4250e-01],
          [ 6.8107e-02, -4.0996e-02, -3.0118e-01],
          [ 9.1478e-03,  1.4765e-01, -3.5663e-02]],

         [[-1.8621e-01, -6.0997e-02, -2.4100e-01],
          [-6.2724e-02,  9.4237e-02,  4.5020e-02],
          [ 1.6225e-01,  1.8317e-01,  1.3204e-01]]],


        [[[ 9.8513e-41, -1.5567e-41,  9.9086e-42],
          [ 4.1155e-41,  1.2302e-40, -3.8111e-41],
          [ 1.4947e-40, -8.1774e-41,  4.2005e-41]],

         [[-6.6628e-41,  1.0830e-40,  5.6451e-41],
          [-9.8248e-41,  1.1774e-40, -1.8543e-41],
          [-6.9689e-41, -5.6904e-41,  1.4233e-40]],

         [[-8.9668e-41, -4.4976e-41, -1.4386e-40],
          [ 1.8127e-41, -1.3480e-40,  1.4016e-41],
          [-7.1880e-41, -1.2029e-40, -1.3780e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0123, -0.0057,  0.0053],
          [ 0.0158,  0.0029,  0.0072],
          [ 0.0152,  0.0080,  0.0072]],

         [[ 0.0235,  0.0072,  0.0139],
          [ 0.0242,  0.0100,  0.0097],
          [ 0.0200,  0.0098,  0.0058]],

         [[ 0.0167,  0.0009,  0.0107],
          [ 0.0163,  0.0039,  0.0064],
          [ 0.0111,  0.0028,  0.0007]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0747,  0.0607,  0.0369],
          [ 0.0453,  0.0317,  0.0175],
          [ 0.0565,  0.0622,  0.0384]],

         [[ 0.0778,  0.0677,  0.0557],
          [ 0.0590,  0.0509,  0.0459],
          [ 0.0727,  0.0858,  0.0724]],

         [[ 0.0690,  0.0570,  0.0524],
          [ 0.0606,  0.0484,  0.0462],
          [ 0.0812,  0.0897,  0.0745]]],


        ...,


        [[[-0.0034, -0.0070, -0.0115],
          [ 0.0000, -0.0052, -0.0144],
          [-0.0108, -0.0149, -0.0228]],

         [[-0.0037, -0.0056, -0.0095],
          [ 0.0013, -0.0019, -0.0109],
          [-0.0103, -0.0122, -0.0202]],

         [[-0.0028, -0.0046, -0.0096],
          [ 0.0003, -0.0031, -0.0128],
          [-0.0099, -0.0122, -0.0206]]],


        [[[ 0.0270,  0.0435,  0.0515],
          [ 0.0154,  0.0277,  0.0327],
          [-0.0250, -0.0083,  0.0048]],

         [[ 0.0113,  0.0231,  0.0273],
          [ 0.0007,  0.0094,  0.0108],
          [-0.0416, -0.0252, -0.0106]],

         [[ 0.0112,  0.0202,  0.0211],
          [-0.0018,  0.0059,  0.0058],
          [-0.0430, -0.0257, -0.0125]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3153]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 45 | Batch_idx: 0 |  Loss: (0.2363) | Acc: (94.00%) (121/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.2661) | Acc: (91.00%) (1283/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.2838) | Acc: (90.00%) (2432/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.2828) | Acc: (90.00%) (3584/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.2819) | Acc: (90.00%) (4745/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.2876) | Acc: (90.00%) (5894/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.2848) | Acc: (90.00%) (7056/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.2913) | Acc: (89.00%) (8179/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.2984) | Acc: (89.00%) (9306/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.2956) | Acc: (89.00%) (10456/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.2905) | Acc: (89.00%) (11631/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.2905) | Acc: (89.00%) (12787/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.2906) | Acc: (90.00%) (13944/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.2906) | Acc: (89.00%) (15089/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.2904) | Acc: (90.00%) (16247/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.2901) | Acc: (90.00%) (17404/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.2896) | Acc: (90.00%) (18554/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.2891) | Acc: (90.00%) (19716/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.2881) | Acc: (90.00%) (20883/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.2871) | Acc: (90.00%) (22044/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.2861) | Acc: (90.00%) (23206/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.2852) | Acc: (90.00%) (24367/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.2852) | Acc: (90.00%) (25527/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.2865) | Acc: (90.00%) (26659/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.2855) | Acc: (90.00%) (27819/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.2856) | Acc: (90.00%) (28973/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.2839) | Acc: (90.00%) (30134/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.2840) | Acc: (90.00%) (31280/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.2846) | Acc: (90.00%) (32428/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.2855) | Acc: (90.00%) (33562/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.2872) | Acc: (90.00%) (34702/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.2870) | Acc: (90.00%) (35850/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.2873) | Acc: (90.00%) (37005/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.2866) | Acc: (90.00%) (38170/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.2855) | Acc: (90.00%) (39344/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.2846) | Acc: (90.00%) (40521/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.2835) | Acc: (90.00%) (41697/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.2829) | Acc: (90.00%) (42858/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.2828) | Acc: (90.00%) (44014/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.2825) | Acc: (90.00%) (45142/50000)
# TEST : Loss: (0.3751) | Acc: (87.00%) (8795/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5797e-01, -2.4186e-01,  6.8826e-02],
          [-7.7503e-02,  2.6480e-01,  1.7722e-01],
          [ 1.1469e-01,  2.3201e-03, -1.0454e-01]],

         [[-2.3564e-01,  2.0094e-01,  2.0853e-01],
          [-4.8682e-03,  3.0291e-01,  1.8584e-01],
          [ 2.1159e-01, -1.0669e-01,  1.3236e-01]],

         [[-1.8080e-01, -1.7078e-02, -2.3659e-02],
          [-2.2759e-01, -4.4603e-02, -3.7080e-02],
          [-1.5901e-01, -3.5857e-02, -1.1951e-01]]],


        [[[ 4.9577e-03, -6.9975e-03,  6.1607e-03],
          [-2.4670e-03, -4.1162e-03,  4.0535e-03],
          [ 7.1010e-03, -2.9787e-05, -6.9114e-03]],

         [[-5.2555e-03,  1.0816e-04, -1.0686e-04],
          [ 4.2466e-03,  2.6841e-03,  4.8713e-03],
          [ 6.2611e-03,  6.2684e-03, -6.2495e-03]],

         [[ 2.1059e-03, -4.9267e-03,  2.8106e-03],
          [-4.5070e-03,  4.7030e-03,  6.7823e-03],
          [ 2.7283e-03, -2.5733e-04, -2.3878e-03]]],


        [[[ 5.7664e-02,  1.1713e-01, -8.5550e-02],
          [ 1.8113e-02,  1.6704e-01, -1.1864e-01],
          [ 9.1636e-02,  2.6502e-01,  2.4103e-01]],

         [[-1.9733e-01, -2.0725e-02, -1.5231e-01],
          [-2.6417e-01, -1.8645e-01, -2.2529e-01],
          [-2.1788e-01, -3.2458e-01,  3.4697e-02]],

         [[ 1.7282e-01,  3.3129e-02,  2.0022e-01],
          [ 1.7231e-01,  7.1860e-02,  3.7424e-02],
          [-2.3300e-02,  8.2096e-02,  5.3696e-02]]],


        ...,


        [[[ 2.7103e-01,  3.1145e-02, -1.7712e-03],
          [ 2.3762e-01, -2.2241e-01, -5.0802e-02],
          [-4.3979e-02, -1.5335e-01, -1.2567e-01]],

         [[-1.0336e-01, -3.5893e-02, -6.2522e-02],
          [-1.6303e-01, -2.3122e-01,  1.8114e-01],
          [ 4.2280e-04,  2.9991e-01,  2.8199e-01]],

         [[-2.4167e-02, -3.7753e-02,  2.1836e-01],
          [ 4.3229e-02, -2.6757e-01, -1.2621e-01],
          [ 3.9389e-02, -7.1575e-02, -1.0265e-01]]],


        [[[ 1.1386e-01,  7.8487e-02,  2.3784e-01],
          [ 2.0588e-01,  1.6744e-01, -1.6425e-02],
          [-2.5745e-01, -1.7011e-01, -8.2401e-02]],

         [[ 7.8621e-02,  2.5942e-02, -1.3526e-01],
          [ 6.5707e-02, -4.0772e-02, -3.0282e-01],
          [ 3.1387e-03,  1.4372e-01, -3.3034e-02]],

         [[-1.7156e-01, -4.4406e-02, -2.2135e-01],
          [-5.3765e-02,  1.0886e-01,  5.9213e-02],
          [ 1.6849e-01,  1.9157e-01,  1.4291e-01]]],


        [[[-6.2627e-41,  5.2767e-41,  1.3351e-40],
          [ 1.0819e-40,  9.1138e-41,  1.4700e-40],
          [ 1.0621e-40, -1.5290e-40, -1.4403e-40]],

         [[-7.9968e-41, -9.9896e-41,  6.4694e-41],
          [ 1.3688e-40, -3.1936e-42, -2.1685e-41],
          [-8.3034e-41,  1.6638e-40, -9.8336e-41]],

         [[ 8.2700e-41,  1.4385e-40, -5.7174e-41],
          [ 2.0421e-41, -5.1428e-43, -1.3912e-40],
          [ 1.3248e-40, -8.7357e-41,  8.7678e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0462,  0.0485,  0.0499],
          [ 0.0295,  0.0438,  0.0515],
          [ 0.0223,  0.0405,  0.0488]],

         [[ 0.0386,  0.0374,  0.0416],
          [ 0.0235,  0.0345,  0.0420],
          [ 0.0206,  0.0348,  0.0386]],

         [[ 0.0393,  0.0388,  0.0488],
          [ 0.0311,  0.0393,  0.0516],
          [ 0.0321,  0.0419,  0.0468]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0240,  0.0146,  0.0326],
          [ 0.0282,  0.0142,  0.0285],
          [ 0.0093,  0.0061,  0.0167]],

         [[ 0.0313,  0.0133,  0.0257],
          [ 0.0442,  0.0214,  0.0288],
          [ 0.0336,  0.0204,  0.0278]],

         [[ 0.0456,  0.0342,  0.0386],
          [ 0.0671,  0.0493,  0.0566],
          [ 0.0581,  0.0439,  0.0560]]],


        ...,


        [[[ 0.0079,  0.0127,  0.0095],
          [-0.0038,  0.0014,  0.0024],
          [-0.0128, -0.0059,  0.0024]],

         [[ 0.0104,  0.0123,  0.0071],
          [-0.0010,  0.0033,  0.0036],
          [-0.0111, -0.0050,  0.0044]],

         [[ 0.0127,  0.0115,  0.0077],
          [ 0.0009,  0.0026,  0.0008],
          [-0.0067, -0.0024,  0.0029]]],


        [[[ 0.0070,  0.0009,  0.0044],
          [ 0.0172,  0.0207,  0.0217],
          [ 0.0277,  0.0257,  0.0231]],

         [[ 0.0190,  0.0106,  0.0115],
          [ 0.0243,  0.0283,  0.0298],
          [ 0.0246,  0.0258,  0.0270]],

         [[ 0.0334,  0.0252,  0.0220],
          [ 0.0364,  0.0409,  0.0389],
          [ 0.0325,  0.0345,  0.0349]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3143]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 46 | Batch_idx: 0 |  Loss: (0.3458) | Acc: (89.00%) (115/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.2969) | Acc: (90.00%) (1273/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.3006) | Acc: (89.00%) (2413/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.3021) | Acc: (89.00%) (3556/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.3160) | Acc: (89.00%) (4682/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.3245) | Acc: (89.00%) (5818/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.3177) | Acc: (89.00%) (6969/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.3118) | Acc: (89.00%) (8127/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.3066) | Acc: (89.00%) (9290/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.3092) | Acc: (89.00%) (10433/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.3073) | Acc: (89.00%) (11586/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.3048) | Acc: (89.00%) (12724/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.3028) | Acc: (89.00%) (13873/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.3011) | Acc: (89.00%) (15028/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.3014) | Acc: (89.00%) (16169/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.2993) | Acc: (89.00%) (17329/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.2972) | Acc: (89.00%) (18497/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.2965) | Acc: (89.00%) (19659/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.2961) | Acc: (89.00%) (20818/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.2943) | Acc: (89.00%) (21987/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.2929) | Acc: (90.00%) (23156/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.2912) | Acc: (90.00%) (24324/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.2901) | Acc: (90.00%) (25487/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.2902) | Acc: (90.00%) (26653/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.2896) | Acc: (90.00%) (27811/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.2885) | Acc: (90.00%) (28982/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.2876) | Acc: (90.00%) (30150/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.2868) | Acc: (90.00%) (31308/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.2841) | Acc: (90.00%) (32498/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.2828) | Acc: (90.00%) (33669/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.2820) | Acc: (90.00%) (34843/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.2811) | Acc: (90.00%) (36017/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.2803) | Acc: (90.00%) (37189/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.2790) | Acc: (90.00%) (38367/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.2787) | Acc: (90.00%) (39534/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.2780) | Acc: (90.00%) (40708/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.2765) | Acc: (90.00%) (41900/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.2751) | Acc: (90.00%) (43086/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.2745) | Acc: (90.00%) (44254/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.2736) | Acc: (90.00%) (45384/50000)
# TEST : Loss: (0.3451) | Acc: (88.00%) (8874/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.6124e-01, -2.4465e-01,  6.3884e-02],
          [-8.0323e-02,  2.6048e-01,  1.7170e-01],
          [ 1.1119e-01, -1.3539e-03, -1.0943e-01]],

         [[-2.3825e-01,  1.9750e-01,  2.0333e-01],
          [-7.6853e-03,  2.9877e-01,  1.8048e-01],
          [ 2.0791e-01, -1.1004e-01,  1.2675e-01]],

         [[-1.8409e-01, -2.0205e-02, -2.8866e-02],
          [-2.3086e-01, -4.8565e-02, -4.2761e-02],
          [-1.6260e-01, -4.0206e-02, -1.2522e-01]]],


        [[[ 2.5640e-03, -3.5778e-03,  3.3022e-03],
          [-1.2910e-03, -2.0944e-03,  2.0546e-03],
          [ 3.7934e-03, -1.5247e-05, -3.2797e-03]],

         [[-2.6985e-03,  5.4480e-05, -5.6029e-05],
          [ 2.2215e-03,  1.3541e-03,  2.4424e-03],
          [ 3.3015e-03,  3.1625e-03, -2.9611e-03]],

         [[ 1.0354e-03, -2.3776e-03,  1.4160e-03],
          [-2.2775e-03,  2.2853e-03,  3.3243e-03],
          [ 1.3977e-03, -1.2570e-04, -1.1138e-03]]],


        [[[ 5.8466e-02,  1.1883e-01, -8.2875e-02],
          [ 1.8743e-02,  1.6850e-01, -1.1605e-01],
          [ 9.1579e-02,  2.6515e-01,  2.4259e-01]],

         [[-1.9653e-01, -1.9168e-02, -1.5019e-01],
          [-2.6389e-01, -1.8517e-01, -2.2337e-01],
          [-2.1885e-01, -3.2481e-01,  3.5385e-02]],

         [[ 1.7256e-01,  3.3900e-02,  2.0107e-01],
          [ 1.7088e-01,  7.1657e-02,  3.7724e-02],
          [-2.5746e-02,  8.0149e-02,  5.2952e-02]]],


        ...,


        [[[ 2.6770e-01,  2.9134e-02, -2.2941e-03],
          [ 2.3621e-01, -2.2134e-01, -5.0402e-02],
          [-4.2504e-02, -1.5133e-01, -1.2355e-01]],

         [[-1.0563e-01, -3.7674e-02, -6.2688e-02],
          [-1.6370e-01, -2.3060e-01,  1.8023e-01],
          [ 8.3871e-04,  2.9973e-01,  2.8198e-01]],

         [[-2.7171e-02, -3.9993e-02,  2.1639e-01],
          [ 4.0705e-02, -2.6750e-01, -1.2620e-01],
          [ 3.8516e-02, -7.0901e-02, -1.0146e-01]]],


        [[[ 1.1421e-01,  7.8785e-02,  2.3764e-01],
          [ 2.0402e-01,  1.6589e-01, -1.7340e-02],
          [-2.5917e-01, -1.7112e-01, -8.3238e-02]],

         [[ 7.7913e-02,  2.5217e-02, -1.3560e-01],
          [ 6.3492e-02, -4.2935e-02, -3.0424e-01],
          [ 4.0338e-04,  1.4110e-01, -3.5047e-02]],

         [[-1.7281e-01, -4.6491e-02, -2.2285e-01],
          [-5.6484e-02,  1.0498e-01,  5.5361e-02],
          [ 1.6477e-01,  1.8787e-01,  1.3914e-01]]],


        [[[-1.1082e-40, -6.4485e-41, -7.5705e-41],
          [-1.3544e-40, -1.4802e-40,  7.0753e-41],
          [ 2.3184e-41,  4.6013e-41, -6.6563e-41]],

         [[ 1.2756e-40, -4.0547e-41,  7.8928e-41],
          [-2.8729e-41, -1.4459e-40, -6.6698e-41],
          [ 1.2479e-40, -1.5918e-40,  1.5130e-40]],

         [[-6.1088e-41,  1.0447e-40, -1.3465e-40],
          [ 2.5268e-41,  1.9229e-40, -8.7620e-41],
          [ 1.5762e-40,  1.5926e-40,  3.9341e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2961]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0281]], device='cuda:0')

Epoch: 47 | Batch_idx: 0 |  Loss: (0.1573) | Acc: (93.00%) (120/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.2470) | Acc: (91.00%) (1294/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.2513) | Acc: (91.00%) (2464/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.2428) | Acc: (92.00%) (3654/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.2419) | Acc: (92.00%) (4832/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.2446) | Acc: (92.00%) (6013/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.2450) | Acc: (92.00%) (7184/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.2429) | Acc: (92.00%) (8368/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.2464) | Acc: (92.00%) (9540/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.2465) | Acc: (92.00%) (10717/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.2443) | Acc: (92.00%) (11904/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.2417) | Acc: (92.00%) (13095/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.2417) | Acc: (92.00%) (14264/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.2437) | Acc: (91.00%) (15426/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.2433) | Acc: (91.00%) (16600/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.2438) | Acc: (91.00%) (17774/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.2472) | Acc: (91.00%) (18923/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.2473) | Acc: (91.00%) (20100/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.2449) | Acc: (91.00%) (21283/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.2438) | Acc: (91.00%) (22460/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.2427) | Acc: (91.00%) (23636/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.2434) | Acc: (91.00%) (24810/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.2446) | Acc: (91.00%) (25970/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.2449) | Acc: (91.00%) (27133/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.2439) | Acc: (91.00%) (28321/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.2442) | Acc: (91.00%) (29496/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.2439) | Acc: (91.00%) (30678/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.2439) | Acc: (91.00%) (31859/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.2437) | Acc: (91.00%) (33027/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.2445) | Acc: (91.00%) (34186/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.2437) | Acc: (91.00%) (35363/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.2429) | Acc: (91.00%) (36548/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.2426) | Acc: (91.00%) (37725/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.2423) | Acc: (91.00%) (38911/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.2417) | Acc: (91.00%) (40104/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.2415) | Acc: (91.00%) (41283/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.2421) | Acc: (91.00%) (42442/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.2422) | Acc: (91.00%) (43621/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.2426) | Acc: (91.00%) (44786/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.2434) | Acc: (91.00%) (45908/50000)
# TEST : Loss: (0.3333) | Acc: (89.00%) (8908/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.6073e-01, -2.4381e-01,  6.3650e-02],
          [-8.0062e-02,  2.5955e-01,  1.7105e-01],
          [ 1.1083e-01, -1.3491e-03, -1.0904e-01]],

         [[-2.3746e-01,  1.9679e-01,  2.0256e-01],
          [-7.6590e-03,  2.9767e-01,  1.7979e-01],
          [ 2.0721e-01, -1.0964e-01,  1.2629e-01]],

         [[-1.8342e-01, -2.0131e-02, -2.8761e-02],
          [-2.3003e-01, -4.8390e-02, -4.2609e-02],
          [-1.6203e-01, -4.0061e-02, -1.2478e-01]]],


        [[[ 1.1467e-03, -1.5779e-03,  1.5430e-03],
          [-5.8581e-04, -9.1817e-04,  8.9653e-04],
          [ 1.7652e-03, -6.7338e-06, -1.3200e-03]],

         [[-1.1963e-03,  2.3589e-05, -2.5483e-05],
          [ 1.0075e-03,  5.8746e-04,  1.0516e-03],
          [ 1.5120e-03,  1.3721e-03, -1.1896e-03]],

         [[ 4.3524e-04, -9.7684e-04,  6.1326e-04],
          [-9.9009e-04,  9.4689e-04,  1.3921e-03],
          [ 6.1787e-04, -5.2422e-05, -4.3889e-04]]],


        [[[ 5.8377e-02,  1.1866e-01, -8.2749e-02],
          [ 1.8715e-02,  1.6825e-01, -1.1588e-01],
          [ 9.1436e-02,  2.6474e-01,  2.4221e-01]],

         [[-1.9620e-01, -1.9137e-02, -1.4994e-01],
          [-2.6346e-01, -1.8487e-01, -2.2300e-01],
          [-2.1848e-01, -3.2427e-01,  3.5328e-02]],

         [[ 1.7227e-01,  3.3842e-02,  2.0072e-01],
          [ 1.7058e-01,  7.1532e-02,  3.7657e-02],
          [-2.5702e-02,  8.0011e-02,  5.2861e-02]]],


        ...,


        [[[ 2.6638e-01,  2.8990e-02, -2.2828e-03],
          [ 2.3501e-01, -2.2018e-01, -5.0152e-02],
          [-4.2293e-02, -1.5057e-01, -1.2296e-01]],

         [[-1.0509e-01, -3.7475e-02, -6.2368e-02],
          [-1.6281e-01, -2.2930e-01,  1.7930e-01],
          [ 8.3433e-04,  2.9814e-01,  2.8058e-01]],

         [[-2.7024e-02, -3.9760e-02,  2.1521e-01],
          [ 4.0461e-02, -2.6573e-01, -1.2548e-01],
          [ 3.8297e-02, -7.0478e-02, -1.0091e-01]]],


        [[[ 1.1381e-01,  7.8522e-02,  2.3689e-01],
          [ 2.0329e-01,  1.6531e-01, -1.7283e-02],
          [-2.5829e-01, -1.7054e-01, -8.2972e-02]],

         [[ 7.7643e-02,  2.5130e-02, -1.3513e-01],
          [ 6.3266e-02, -4.2780e-02, -3.0317e-01],
          [ 4.0200e-04,  1.4060e-01, -3.4927e-02]],

         [[-1.7220e-01, -4.6321e-02, -2.2201e-01],
          [-5.6283e-02,  1.0459e-01,  5.5155e-02],
          [ 1.6419e-01,  1.8719e-01,  1.3864e-01]]],


        [[[ 1.0059e-40,  7.5709e-41,  1.0806e-40],
          [ 1.3277e-40, -3.1608e-41,  4.7515e-41],
          [-9.4006e-41, -1.2235e-40,  4.7563e-41]],

         [[ 5.7187e-41, -1.4346e-40, -1.4398e-40],
          [-3.2873e-41,  5.2333e-41, -3.3173e-41],
          [ 5.4310e-41, -1.8936e-40, -1.8930e-40]],

         [[-1.0491e-40, -2.3934e-41, -1.8137e-41],
          [-9.8573e-41, -1.1488e-40,  1.3362e-40],
          [-5.6647e-41,  7.3895e-41, -1.4132e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2933]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0041]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 48 | Batch_idx: 0 |  Loss: (0.2477) | Acc: (90.00%) (116/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.2416) | Acc: (91.00%) (1289/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.2681) | Acc: (90.00%) (2444/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.2858) | Acc: (90.00%) (3585/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.2982) | Acc: (90.00%) (4729/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.3056) | Acc: (89.00%) (5866/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.3214) | Acc: (89.00%) (6970/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.3275) | Acc: (88.00%) (8086/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.3308) | Acc: (88.00%) (9209/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.3346) | Acc: (88.00%) (10319/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.3327) | Acc: (88.00%) (11449/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.3304) | Acc: (88.00%) (12588/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.3333) | Acc: (88.00%) (13705/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.3316) | Acc: (88.00%) (14864/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.3329) | Acc: (88.00%) (15985/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.3335) | Acc: (88.00%) (17113/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.3337) | Acc: (88.00%) (18232/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.3326) | Acc: (88.00%) (19370/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.3327) | Acc: (88.00%) (20512/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.3339) | Acc: (88.00%) (21628/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.3329) | Acc: (88.00%) (22767/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.3338) | Acc: (88.00%) (23895/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.3358) | Acc: (88.00%) (25012/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.3354) | Acc: (88.00%) (26151/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.3359) | Acc: (88.00%) (27274/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.3350) | Acc: (88.00%) (28411/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.3340) | Acc: (88.00%) (29555/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.3341) | Acc: (88.00%) (30699/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.3326) | Acc: (88.00%) (31854/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.3318) | Acc: (88.00%) (33001/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.3304) | Acc: (88.00%) (34156/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.3296) | Acc: (88.00%) (35297/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.3287) | Acc: (88.00%) (36450/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.3279) | Acc: (88.00%) (37602/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.3266) | Acc: (88.00%) (38761/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.3258) | Acc: (88.00%) (39915/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.3238) | Acc: (88.00%) (41080/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.3229) | Acc: (88.00%) (42239/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.3229) | Acc: (88.00%) (43387/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.3219) | Acc: (88.00%) (44492/50000)
# TEST : Loss: (0.3707) | Acc: (87.00%) (8793/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.6696e-01, -2.4492e-01,  6.2406e-02],
          [-8.8067e-02,  2.6595e-01,  1.7955e-01],
          [ 1.0424e-01,  7.1792e-04, -9.7702e-02]],

         [[-2.4485e-01,  1.9592e-01,  2.0279e-01],
          [-1.6710e-02,  3.0257e-01,  1.8612e-01],
          [ 1.9663e-01, -1.0996e-01,  1.3113e-01]],

         [[-1.8881e-01, -2.5406e-02, -3.2177e-02],
          [-2.4209e-01, -5.2299e-02, -4.1284e-02],
          [-1.7871e-01, -4.7609e-02, -1.2146e-01]]],


        [[[ 4.2919e-04, -5.8052e-04,  6.0937e-04],
          [-2.2318e-04, -3.3532e-04,  3.2554e-04],
          [ 6.9361e-04, -2.4816e-06, -4.3406e-04]],

         [[-4.4289e-04,  8.4847e-06, -9.7365e-06],
          [ 3.8360e-04,  2.1181e-04,  3.7564e-04],
          [ 5.8262e-04,  4.9476e-04, -3.9025e-04]],

         [[ 1.5096e-04, -3.2944e-04,  2.2065e-04],
          [-3.5787e-04,  3.2267e-04,  4.8062e-04],
          [ 2.2797e-04, -1.8006e-05, -1.4062e-04]]],


        [[[ 6.1889e-02,  1.1600e-01, -8.9341e-02],
          [ 1.7796e-02,  1.6699e-01, -1.2293e-01],
          [ 8.4080e-02,  2.6890e-01,  2.4077e-01]],

         [[-1.9029e-01, -2.0664e-02, -1.5338e-01],
          [-2.7016e-01, -1.9506e-01, -2.3031e-01],
          [-2.2674e-01, -3.2453e-01,  3.5547e-02]],

         [[ 1.8339e-01,  3.7657e-02,  1.9979e-01],
          [ 1.7321e-01,  6.9019e-02,  3.0183e-02],
          [-2.5228e-02,  8.4183e-02,  4.8498e-02]]],


        ...,


        [[[ 2.7716e-01,  4.0418e-02,  1.6324e-02],
          [ 2.4041e-01, -2.0485e-01, -2.6170e-02],
          [-3.9335e-02, -1.3476e-01, -1.0204e-01]],

         [[-1.0303e-01, -3.1914e-02, -4.5421e-02],
          [-1.6189e-01, -2.1193e-01,  2.0300e-01],
          [ 8.0999e-03,  3.2418e-01,  3.0734e-01]],

         [[-3.3229e-02, -4.7816e-02,  2.1258e-01],
          [ 3.3872e-02, -2.6069e-01, -1.1989e-01],
          [ 3.9205e-02, -5.4994e-02, -8.9318e-02]]],


        [[[ 1.0566e-01,  8.3602e-02,  2.4109e-01],
          [ 1.9368e-01,  1.5664e-01, -2.6273e-02],
          [-2.6853e-01, -1.8018e-01, -9.3054e-02]],

         [[ 7.4959e-02,  3.0909e-02, -1.3416e-01],
          [ 5.6778e-02, -5.2101e-02, -3.1736e-01],
          [-9.8914e-03,  1.3192e-01, -4.2909e-02]],

         [[-1.8886e-01, -5.3894e-02, -2.3000e-01],
          [-7.2724e-02,  8.9047e-02,  3.7483e-02],
          [ 1.4951e-01,  1.7736e-01,  1.2946e-01]]],


        [[[-3.2189e-41,  9.6662e-42, -1.0662e-40],
          [-1.1396e-40, -3.5828e-41,  1.3064e-40],
          [ 1.5355e-40,  1.3793e-40,  8.7406e-41]],

         [[-1.1048e-40,  1.4885e-40, -9.7558e-42],
          [ 9.4988e-41,  1.6583e-41, -7.7720e-41],
          [ 6.0938e-41, -1.8110e-40,  2.1334e-40]],

         [[ 8.4162e-41, -2.8217e-41,  1.8945e-40],
          [ 1.1206e-40, -1.3657e-40,  1.9561e-40],
          [-1.8489e-40, -3.0529e-41, -4.6243e-43]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0243,  0.0221,  0.0144],
          [ 0.0257,  0.0192,  0.0120],
          [ 0.0314,  0.0223,  0.0142]],

         [[ 0.0166,  0.0133,  0.0074],
          [ 0.0182,  0.0110,  0.0036],
          [ 0.0243,  0.0130,  0.0045]],

         [[ 0.0097,  0.0060, -0.0013],
          [ 0.0101,  0.0029, -0.0056],
          [ 0.0132,  0.0033, -0.0046]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0068, -0.0077, -0.0160],
          [ 0.0085,  0.0014,  0.0016],
          [ 0.0216,  0.0118,  0.0049]],

         [[-0.0076, -0.0123, -0.0237],
          [ 0.0056, -0.0033, -0.0066],
          [ 0.0192,  0.0126,  0.0063]],

         [[-0.0068, -0.0097, -0.0194],
          [ 0.0059, -0.0037, -0.0050],
          [ 0.0210,  0.0101,  0.0051]]],


        ...,


        [[[ 0.0014,  0.0006, -0.0039],
          [ 0.0069,  0.0083,  0.0041],
          [ 0.0161,  0.0210,  0.0131]],

         [[ 0.0047,  0.0047, -0.0003],
          [ 0.0080,  0.0087,  0.0060],
          [ 0.0182,  0.0226,  0.0132]],

         [[ 0.0061,  0.0052, -0.0001],
          [ 0.0068,  0.0076,  0.0052],
          [ 0.0171,  0.0213,  0.0118]]],


        [[[-0.0158, -0.0101, -0.0109],
          [-0.0085, -0.0048, -0.0069],
          [-0.0042,  0.0019, -0.0026]],

         [[-0.0159, -0.0101, -0.0108],
          [-0.0117, -0.0074, -0.0089],
          [-0.0092, -0.0014, -0.0029]],

         [[-0.0219, -0.0146, -0.0132],
          [-0.0198, -0.0135, -0.0127],
          [-0.0141, -0.0064, -0.0064]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2925]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 49 | Batch_idx: 0 |  Loss: (0.2245) | Acc: (92.00%) (118/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.2926) | Acc: (89.00%) (1264/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.2906) | Acc: (90.00%) (2428/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.2890) | Acc: (90.00%) (3573/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.2788) | Acc: (90.00%) (4746/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.2826) | Acc: (90.00%) (5893/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.2780) | Acc: (90.00%) (7061/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.2727) | Acc: (90.00%) (8233/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.2706) | Acc: (90.00%) (9392/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.2690) | Acc: (90.00%) (10550/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.2683) | Acc: (90.00%) (11706/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.2688) | Acc: (90.00%) (12866/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.2705) | Acc: (90.00%) (14014/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.2744) | Acc: (90.00%) (15145/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.2752) | Acc: (90.00%) (16309/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.2746) | Acc: (90.00%) (17481/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.2775) | Acc: (90.00%) (18633/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.2763) | Acc: (90.00%) (19803/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.2768) | Acc: (90.00%) (20957/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.2787) | Acc: (90.00%) (22097/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.2777) | Acc: (90.00%) (23271/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.2780) | Acc: (90.00%) (24436/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.2794) | Acc: (90.00%) (25578/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.2787) | Acc: (90.00%) (26740/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.2789) | Acc: (90.00%) (27897/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.2794) | Acc: (90.00%) (29046/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.2798) | Acc: (90.00%) (30187/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.2812) | Acc: (90.00%) (31328/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.2813) | Acc: (90.00%) (32483/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.2817) | Acc: (90.00%) (33644/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.2806) | Acc: (90.00%) (34831/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.2798) | Acc: (90.00%) (35994/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.2788) | Acc: (90.00%) (37159/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.2794) | Acc: (90.00%) (38308/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.2787) | Acc: (90.00%) (39482/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.2776) | Acc: (90.00%) (40656/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.2769) | Acc: (90.00%) (41835/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.2773) | Acc: (90.00%) (43002/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.2767) | Acc: (90.00%) (44174/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.2772) | Acc: (90.00%) (45281/50000)
# TEST : Loss: (0.3667) | Acc: (87.00%) (8789/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5197e-01, -2.3512e-01,  6.5461e-02],
          [-7.5234e-02,  2.8048e-01,  1.8786e-01],
          [ 1.1964e-01,  1.4369e-02, -9.0552e-02]],

         [[-2.2943e-01,  2.0940e-01,  2.1033e-01],
          [-7.8793e-03,  3.1608e-01,  1.9568e-01],
          [ 2.0950e-01, -9.7240e-02,  1.3847e-01]],

         [[-1.7896e-01, -1.8056e-02, -2.9060e-02],
          [-2.3917e-01, -4.8670e-02, -4.1571e-02],
          [-1.7020e-01, -4.2709e-02, -1.2107e-01]]],


        [[[ 1.2907e-04, -1.7093e-04,  1.9576e-04],
          [-6.8594e-05, -9.7845e-05,  9.4322e-05],
          [ 2.2144e-04, -7.3220e-07, -1.1131e-04]],

         [[-1.3142e-04,  2.4298e-06, -3.0032e-06],
          [ 1.1781e-04,  6.0837e-05,  1.0667e-04],
          [ 1.8159e-04,  1.4212e-04, -9.9790e-05]],

         [[ 4.1341e-05, -8.7154e-05,  6.3216e-05],
          [-1.0311e-04,  8.6461e-05,  1.3087e-04],
          [ 6.7361e-05, -4.8719e-06, -3.4925e-05]]],


        [[[ 6.7019e-02,  1.2343e-01, -7.4104e-02],
          [ 2.2288e-02,  1.7249e-01, -1.1400e-01],
          [ 9.1489e-02,  2.6925e-01,  2.4308e-01]],

         [[-1.9159e-01, -2.4158e-02, -1.4847e-01],
          [-2.7444e-01, -1.9993e-01, -2.2768e-01],
          [-2.2639e-01, -3.3006e-01,  3.6663e-02]],

         [[ 1.8416e-01,  4.0723e-02,  2.0564e-01],
          [ 1.7195e-01,  7.2952e-02,  4.0364e-02],
          [-2.1937e-02,  8.5279e-02,  5.6582e-02]]],


        ...,


        [[[ 2.7064e-01,  3.0666e-02,  6.6340e-03],
          [ 2.3408e-01, -2.1993e-01, -4.1290e-02],
          [-3.7703e-02, -1.4603e-01, -1.1188e-01]],

         [[-1.1303e-01, -4.7068e-02, -5.4642e-02],
          [-1.7383e-01, -2.3162e-01,  1.8705e-01],
          [ 4.0121e-03,  3.0928e-01,  2.9610e-01]],

         [[-4.1061e-02, -5.8361e-02,  2.0585e-01],
          [ 2.8569e-02, -2.7312e-01, -1.2986e-01],
          [ 4.0378e-02, -6.1390e-02, -9.3355e-02]]],


        [[[ 9.9756e-02,  8.5459e-02,  2.4742e-01],
          [ 1.8984e-01,  1.5920e-01, -2.0352e-02],
          [-2.6303e-01, -1.7295e-01, -8.4079e-02]],

         [[ 5.9830e-02,  2.2320e-02, -1.3854e-01],
          [ 4.3777e-02, -5.9996e-02, -3.2467e-01],
          [-1.0766e-02,  1.3194e-01, -3.9093e-02]],

         [[-2.0501e-01, -6.2013e-02, -2.3009e-01],
          [-8.6016e-02,  8.6320e-02,  3.8095e-02],
          [ 1.5236e-01,  1.8831e-01,  1.4494e-01]]],


        [[[-3.7856e-41,  5.6673e-41,  1.5531e-40],
          [ 1.8377e-40,  9.4066e-41,  1.0059e-41],
          [-1.2965e-40,  1.4068e-40, -4.1941e-41]],

         [[-1.5638e-40,  1.8700e-41,  1.2770e-40],
          [-1.7451e-40, -3.2657e-41, -1.1440e-40],
          [ 1.4987e-40, -1.6120e-40, -2.4299e-40]],

         [[ 1.2030e-40,  1.0424e-40,  1.3244e-40],
          [-1.3795e-40, -1.6126e-40, -2.0965e-40],
          [ 1.0482e-40, -3.5503e-41, -8.8886e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0165, -0.0212, -0.0299],
          [-0.0180, -0.0142, -0.0123],
          [-0.0159, -0.0114, -0.0042]],

         [[-0.0022, -0.0078, -0.0176],
          [-0.0021, -0.0027, -0.0039],
          [-0.0011, -0.0010,  0.0026]],

         [[-0.0075, -0.0126, -0.0198],
          [-0.0080, -0.0084, -0.0085],
          [-0.0088, -0.0086, -0.0048]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0377, -0.0311, -0.0610],
          [-0.0686, -0.0627, -0.0598],
          [-0.0815, -0.0842, -0.0663]],

         [[-0.0029,  0.0153, -0.0077],
          [-0.0266, -0.0181, -0.0062],
          [-0.0347, -0.0349, -0.0137]],

         [[ 0.0397,  0.0500,  0.0182],
          [ 0.0174,  0.0273,  0.0248],
          [ 0.0175,  0.0128,  0.0190]]],


        ...,


        [[[ 0.0012,  0.0059, -0.0038],
          [-0.0168, -0.0119, -0.0159],
          [-0.0184, -0.0113, -0.0148]],

         [[ 0.0090,  0.0164,  0.0045],
          [-0.0097, -0.0042, -0.0099],
          [-0.0109, -0.0043, -0.0099]],

         [[ 0.0048,  0.0120,  0.0078],
          [-0.0093, -0.0036, -0.0030],
          [-0.0088, -0.0022, -0.0014]]],


        [[[ 0.0133,  0.0085,  0.0149],
          [ 0.0171,  0.0163,  0.0204],
          [ 0.0141,  0.0059,  0.0021]],

         [[ 0.0050, -0.0015,  0.0084],
          [ 0.0109,  0.0097,  0.0175],
          [ 0.0107,  0.0031,  0.0019]],

         [[ 0.0111,  0.0048,  0.0092],
          [ 0.0130,  0.0154,  0.0189],
          [ 0.0137,  0.0082,  0.0022]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2917]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 50 | Batch_idx: 0 |  Loss: (0.2391) | Acc: (95.00%) (122/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.2935) | Acc: (90.00%) (1273/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.3058) | Acc: (89.00%) (2411/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.3263) | Acc: (89.00%) (3539/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.3310) | Acc: (89.00%) (4671/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.3317) | Acc: (89.00%) (5811/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.3313) | Acc: (89.00%) (6950/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.3246) | Acc: (89.00%) (8099/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.3239) | Acc: (89.00%) (9240/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.3209) | Acc: (89.00%) (10392/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.3205) | Acc: (89.00%) (11530/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.3143) | Acc: (89.00%) (12706/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.3113) | Acc: (89.00%) (13857/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.3076) | Acc: (89.00%) (15016/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.3068) | Acc: (89.00%) (16174/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.3048) | Acc: (89.00%) (17331/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.3038) | Acc: (89.00%) (18482/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.3032) | Acc: (89.00%) (19619/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.3022) | Acc: (89.00%) (20773/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.3012) | Acc: (89.00%) (21924/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.2990) | Acc: (89.00%) (23091/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.2966) | Acc: (89.00%) (24271/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.2950) | Acc: (89.00%) (25438/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.2929) | Acc: (90.00%) (26621/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.2912) | Acc: (90.00%) (27800/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.2903) | Acc: (90.00%) (28956/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.2883) | Acc: (90.00%) (30129/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.2864) | Acc: (90.00%) (31306/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.2847) | Acc: (90.00%) (32490/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.2838) | Acc: (90.00%) (33650/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.2825) | Acc: (90.00%) (34815/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.2804) | Acc: (90.00%) (35998/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.2798) | Acc: (90.00%) (37162/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.2784) | Acc: (90.00%) (38348/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.2775) | Acc: (90.00%) (39527/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.2761) | Acc: (90.00%) (40707/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.2743) | Acc: (90.00%) (41903/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.2742) | Acc: (90.00%) (43065/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.2727) | Acc: (90.00%) (44246/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.2730) | Acc: (90.00%) (45359/50000)
# TEST : Loss: (0.3341) | Acc: (88.00%) (8891/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5202e-01, -2.3355e-01,  6.5876e-02],
          [-7.5384e-02,  2.7935e-01,  1.8627e-01],
          [ 1.1852e-01,  1.3786e-02, -9.0994e-02]],

         [[-2.2907e-01,  2.0974e-01,  2.1019e-01],
          [-8.4450e-03,  3.1481e-01,  1.9394e-01],
          [ 2.0777e-01, -9.7599e-02,  1.3709e-01]],

         [[-1.7953e-01, -1.7602e-02, -2.8826e-02],
          [-2.3912e-01, -4.8859e-02, -4.2133e-02],
          [-1.7026e-01, -4.2894e-02, -1.2106e-01]]],


        [[[ 2.9648e-05, -3.8255e-05,  4.8781e-05],
          [-1.6186e-05, -2.1656e-05,  2.0695e-05],
          [ 5.4759e-05, -1.6429e-07, -2.1004e-05]],

         [[-2.9696e-05,  5.2549e-07, -7.1179e-07],
          [ 2.7775e-05,  1.3205e-05,  2.2828e-05],
          [ 4.3596e-05,  3.0854e-05, -1.8765e-05]],

         [[ 8.4607e-06, -1.7092e-05,  1.3678e-05],
          [-2.2465e-05,  1.7226e-05,  2.6594e-05],
          [ 1.5142e-05, -9.8238e-07, -6.3350e-06]]],


        [[[ 6.8404e-02,  1.2525e-01, -7.0848e-02],
          [ 2.4826e-02,  1.7563e-01, -1.1018e-01],
          [ 9.5394e-02,  2.7288e-01,  2.4682e-01]],

         [[-1.9063e-01, -2.3248e-02, -1.4620e-01],
          [-2.7210e-01, -1.9687e-01, -2.2462e-01],
          [-2.2228e-01, -3.2595e-01,  3.9826e-02]],

         [[ 1.8409e-01,  4.1040e-02,  2.0687e-01],
          [ 1.7318e-01,  7.5142e-02,  4.2534e-02],
          [-1.8903e-02,  8.8273e-02,  5.9375e-02]]],


        ...,


        [[[ 2.7139e-01,  3.1575e-02,  8.7395e-03],
          [ 2.3517e-01, -2.1779e-01, -3.9504e-02],
          [-3.6296e-02, -1.4507e-01, -1.1084e-01]],

         [[-1.1140e-01, -4.6544e-02, -5.3153e-02],
          [-1.7138e-01, -2.2971e-01,  1.8739e-01],
          [ 3.9499e-03,  3.0702e-01,  2.9449e-01]],

         [[-3.9945e-02, -5.8702e-02,  2.0417e-01],
          [ 2.9586e-02, -2.7170e-01, -1.2987e-01],
          [ 3.9222e-02, -6.3065e-02, -9.4954e-02]]],


        [[[ 1.0140e-01,  8.6748e-02,  2.4711e-01],
          [ 1.8914e-01,  1.5787e-01, -2.1232e-02],
          [-2.6088e-01, -1.7181e-01, -8.3301e-02]],

         [[ 6.2093e-02,  2.4902e-02, -1.3668e-01],
          [ 4.4822e-02, -5.9065e-02, -3.2321e-01],
          [-7.6975e-03,  1.3423e-01, -3.6488e-02]],

         [[-2.0201e-01, -5.8961e-02, -2.2701e-01],
          [-8.4464e-02,  8.6731e-02,  3.8475e-02],
          [ 1.5470e-01,  1.9030e-01,  1.4718e-01]]],


        [[[-1.4535e-40,  1.0679e-41, -6.0189e-41],
          [ 2.1390e-40,  3.2422e-41,  1.4677e-41],
          [-5.2357e-41, -1.7221e-41, -5.8742e-42]],

         [[-1.8302e-40,  2.0465e-41, -1.9348e-41],
          [-5.1154e-41, -3.7204e-41, -1.3432e-40],
          [ 1.7654e-40, -1.8733e-40,  1.6307e-40]],

         [[ 1.3996e-40, -1.7466e-40,  1.2968e-40],
          [ 2.3506e-40, -1.0854e-40, -1.1684e-40],
          [ 1.3015e-41,  3.9716e-41,  1.0266e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2983]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0167]], device='cuda:0')

Epoch: 51 | Batch_idx: 0 |  Loss: (0.1826) | Acc: (95.00%) (122/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.2451) | Acc: (91.00%) (1288/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.2356) | Acc: (91.00%) (2469/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.2271) | Acc: (92.00%) (3665/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.2347) | Acc: (92.00%) (4837/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.2344) | Acc: (92.00%) (6025/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.2373) | Acc: (92.00%) (7200/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.2370) | Acc: (92.00%) (8371/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.2368) | Acc: (92.00%) (9558/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.2369) | Acc: (92.00%) (10730/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.2374) | Acc: (92.00%) (11908/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.2394) | Acc: (92.00%) (13072/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.2400) | Acc: (92.00%) (14249/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.2414) | Acc: (91.00%) (15424/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.2435) | Acc: (91.00%) (16586/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.2418) | Acc: (91.00%) (17769/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.2395) | Acc: (92.00%) (18960/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.2403) | Acc: (91.00%) (20125/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.2415) | Acc: (91.00%) (21299/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.2417) | Acc: (91.00%) (22472/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.2398) | Acc: (91.00%) (23668/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.2403) | Acc: (91.00%) (24845/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.2407) | Acc: (91.00%) (26017/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.2409) | Acc: (91.00%) (27190/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.2413) | Acc: (91.00%) (28359/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.2412) | Acc: (91.00%) (29539/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.2412) | Acc: (91.00%) (30709/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.2414) | Acc: (91.00%) (31880/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.2414) | Acc: (91.00%) (33049/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.2404) | Acc: (91.00%) (34238/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.2395) | Acc: (91.00%) (35432/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.2391) | Acc: (91.00%) (36617/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.2386) | Acc: (91.00%) (37796/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.2380) | Acc: (92.00%) (38983/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.2375) | Acc: (92.00%) (40167/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.2379) | Acc: (92.00%) (41339/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.2380) | Acc: (92.00%) (42526/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.2389) | Acc: (92.00%) (43694/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.2384) | Acc: (92.00%) (44883/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.2381) | Acc: (92.00%) (46017/50000)
# TEST : Loss: (0.3199) | Acc: (89.00%) (8925/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5152e-01, -2.3270e-01,  6.5619e-02],
          [-7.5121e-02,  2.7827e-01,  1.8549e-01],
          [ 1.1811e-01,  1.3734e-02, -9.0641e-02]],

         [[-2.2826e-01,  2.0894e-01,  2.0934e-01],
          [-8.4137e-03,  3.1355e-01,  1.9313e-01],
          [ 2.0701e-01, -9.7217e-02,  1.3655e-01]],

         [[-1.7883e-01, -1.7533e-02, -2.8714e-02],
          [-2.3818e-01, -4.8668e-02, -4.1970e-02],
          [-1.6960e-01, -4.2729e-02, -1.2061e-01]]],


        [[[ 4.8828e-06, -6.1005e-06,  8.8846e-06],
          [-2.7559e-06, -3.4062e-06,  3.2201e-06],
          [ 9.8793e-06, -2.6283e-08, -2.7113e-06]],

         [[-4.7922e-06,  8.0320e-08, -1.2185e-07],
          [ 4.7238e-06,  2.0275e-06,  3.4442e-06],
          [ 7.5827e-06,  4.7381e-06, -2.4117e-06]],

         [[ 1.2077e-06, -2.3141e-06,  2.0920e-06],
          [-3.4656e-06,  2.3783e-06,  3.7632e-06],
          [ 2.4278e-06, -1.3768e-07, -7.7860e-07]]],


        [[[ 6.8297e-02,  1.2505e-01, -7.0735e-02],
          [ 2.4787e-02,  1.7535e-01, -1.1000e-01],
          [ 9.5241e-02,  2.7245e-01,  2.4642e-01]],

         [[-1.9031e-01, -2.3209e-02, -1.4595e-01],
          [-2.7162e-01, -1.9653e-01, -2.2423e-01],
          [-2.2189e-01, -3.2539e-01,  3.9758e-02]],

         [[ 1.8377e-01,  4.0967e-02,  2.0650e-01],
          [ 1.7286e-01,  7.5002e-02,  4.2455e-02],
          [-1.8868e-02,  8.8111e-02,  5.9267e-02]]],


        ...,


        [[[ 2.7005e-01,  3.1415e-02,  8.6951e-03],
          [ 2.3395e-01, -2.1662e-01, -3.9304e-02],
          [-3.6112e-02, -1.4433e-01, -1.1030e-01]],

         [[-1.1080e-01, -4.6280e-02, -5.2864e-02],
          [-1.7039e-01, -2.2832e-01,  1.8638e-01],
          [ 3.9283e-03,  3.0532e-01,  2.9298e-01]],

         [[-3.9697e-02, -5.8294e-02,  2.0289e-01],
          [ 2.9379e-02, -2.6950e-01, -1.2901e-01],
          [ 3.8974e-02, -6.2638e-02, -9.4388e-02]]],


        [[[ 1.0101e-01,  8.6427e-02,  2.4627e-01],
          [ 1.8839e-01,  1.5727e-01, -2.1157e-02],
          [-2.5990e-01, -1.7117e-01, -8.3009e-02]],

         [[ 6.1844e-02,  2.4803e-02, -1.3613e-01],
          [ 4.4643e-02, -5.8826e-02, -3.2185e-01],
          [-7.6678e-03,  1.3370e-01, -3.6342e-02]],

         [[-2.0119e-01, -5.8715e-02, -2.2599e-01],
          [-8.4132e-02,  8.6374e-02,  3.8303e-02],
          [ 1.5410e-01,  1.8953e-01,  1.4656e-01]]],


        [[[ 6.6810e-41,  1.5438e-41,  1.6371e-40],
          [-1.7874e-40, -1.4854e-40,  2.0536e-41],
          [-6.0417e-41, -2.0502e-41,  4.4390e-41]],

         [[ 2.1494e-40,  1.3031e-40,  1.7573e-40],
          [-1.6619e-40,  9.8794e-41, -9.4431e-41],
          [-1.1614e-40, -1.1332e-40,  1.6135e-40]],

         [[-1.4151e-40, -4.5951e-41,  9.0028e-41],
          [-1.5822e-40, -1.2641e-40, -7.8145e-41],
          [-2.0453e-40, -1.4424e-40, -9.1571e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2988]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0326]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 52 | Batch_idx: 0 |  Loss: (0.2688) | Acc: (91.00%) (117/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.2669) | Acc: (90.00%) (1276/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.2731) | Acc: (90.00%) (2432/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.2772) | Acc: (90.00%) (3594/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.2868) | Acc: (90.00%) (4742/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.2927) | Acc: (90.00%) (5878/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3004) | Acc: (89.00%) (6998/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3063) | Acc: (89.00%) (8127/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3081) | Acc: (89.00%) (9268/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3097) | Acc: (89.00%) (10408/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3121) | Acc: (89.00%) (11536/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3123) | Acc: (89.00%) (12667/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3138) | Acc: (89.00%) (13817/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3182) | Acc: (89.00%) (14939/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3207) | Acc: (89.00%) (16063/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3248) | Acc: (88.00%) (17183/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3266) | Acc: (88.00%) (18309/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3266) | Acc: (88.00%) (19453/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3267) | Acc: (88.00%) (20593/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3260) | Acc: (88.00%) (21728/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3243) | Acc: (88.00%) (22896/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3243) | Acc: (89.00%) (24040/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3238) | Acc: (89.00%) (25186/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3239) | Acc: (89.00%) (26328/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3245) | Acc: (89.00%) (27460/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3257) | Acc: (88.00%) (28584/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3242) | Acc: (89.00%) (29750/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3242) | Acc: (89.00%) (30886/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3229) | Acc: (89.00%) (32038/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3230) | Acc: (89.00%) (33180/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3218) | Acc: (89.00%) (34329/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3197) | Acc: (89.00%) (35497/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3184) | Acc: (89.00%) (36652/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3178) | Acc: (89.00%) (37807/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3167) | Acc: (89.00%) (38968/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3164) | Acc: (89.00%) (40110/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3156) | Acc: (89.00%) (41268/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3144) | Acc: (89.00%) (42430/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3135) | Acc: (89.00%) (43596/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3128) | Acc: (89.00%) (44714/50000)
# TEST : Loss: (0.4224) | Acc: (86.00%) (8662/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4089e-01, -2.1830e-01,  7.6910e-02],
          [-6.9432e-02,  2.8693e-01,  1.9767e-01],
          [ 1.2327e-01,  1.9400e-02, -7.5813e-02]],

         [[-2.2951e-01,  2.0946e-01,  2.0331e-01],
          [-1.6029e-02,  3.0508e-01,  1.8274e-01],
          [ 1.9823e-01, -1.1193e-01,  1.2661e-01]],

         [[-1.8816e-01, -2.3013e-02, -4.5840e-02],
          [-2.5389e-01, -6.6021e-02, -6.6062e-02],
          [-1.8797e-01, -6.5077e-02, -1.3873e-01]]],


        [[[ 5.3228e-07, -6.3891e-07,  1.0975e-06],
          [-3.1311e-07, -3.5067e-07,  3.2709e-07],
          [ 1.2061e-06, -2.7636e-09, -2.1823e-07]],

         [[-5.0935e-07,  7.9796e-09, -1.3937e-08],
          [ 5.3593e-07,  2.0257e-07,  3.3670e-07],
          [ 8.8461e-07,  4.7348e-07, -1.9305e-07]],

         [[ 1.1020e-07, -1.9768e-07,  2.0800e-07],
          [-3.4827e-07,  2.0818e-07,  3.3964e-07],
          [ 2.5598e-07, -1.2277e-08, -5.8945e-08]]],


        [[[ 5.8612e-02,  1.1927e-01, -7.5440e-02],
          [ 3.0596e-02,  1.7821e-01, -1.0779e-01],
          [ 9.5726e-02,  2.6974e-01,  2.4498e-01]],

         [[-2.0078e-01, -3.2506e-02, -1.5251e-01],
          [-2.7081e-01, -2.0385e-01, -2.2551e-01],
          [-2.2688e-01, -3.3521e-01,  3.6483e-02]],

         [[ 1.8261e-01,  3.7603e-02,  2.0090e-01],
          [ 1.8432e-01,  7.8197e-02,  4.5713e-02],
          [-1.2144e-02,  8.9392e-02,  5.9856e-02]]],


        ...,


        [[[ 2.6805e-01,  4.0200e-02,  1.4513e-02],
          [ 2.2139e-01, -2.2192e-01, -4.4923e-02],
          [-5.3234e-02, -1.5192e-01, -1.1693e-01]],

         [[-1.1769e-01, -4.5186e-02, -5.1262e-02],
          [-1.8886e-01, -2.4090e-01,  1.7813e-01],
          [-1.9411e-02,  2.8695e-01,  2.7709e-01]],

         [[-3.7188e-02, -5.0890e-02,  2.0090e-01],
          [ 1.0031e-02, -2.9063e-01, -1.4867e-01],
          [ 1.4012e-02, -8.7678e-02, -1.1904e-01]]],


        [[[ 1.0027e-01,  9.5299e-02,  2.5178e-01],
          [ 1.8678e-01,  1.6277e-01, -1.0740e-02],
          [-2.5980e-01, -1.6903e-01, -7.5460e-02]],

         [[ 4.8264e-02,  1.3124e-02, -1.5204e-01],
          [ 3.4680e-02, -6.7132e-02, -3.2563e-01],
          [-1.1855e-02,  1.3098e-01, -3.3222e-02]],

         [[-2.1968e-01, -7.4683e-02, -2.4583e-01],
          [-9.6644e-02,  7.4994e-02,  2.9780e-02],
          [ 1.4578e-01,  1.8331e-01,  1.4055e-01]]],


        [[[ 7.9514e-41, -1.2874e-40,  1.9030e-40],
          [-1.6302e-40,  2.2332e-40,  2.3742e-41],
          [ 1.9132e-40, -2.7136e-40,  1.4054e-40]],

         [[ 2.0680e-40,  2.3295e-40,  9.0272e-41],
          [ 2.5770e-40, -1.6919e-40, -1.1086e-40],
          [ 1.9518e-40, -1.0095e-41,  3.3536e-40]],

         [[ 1.2388e-40, -5.3825e-41, -1.8367e-40],
          [ 2.0959e-40, -9.4588e-43,  1.4886e-41],
          [ 3.0934e-40,  5.3916e-41,  3.4220e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0169,  0.0095,  0.0191],
          [ 0.0114,  0.0060,  0.0189],
          [ 0.0073,  0.0084,  0.0245]],

         [[ 0.0104,  0.0044,  0.0139],
          [ 0.0058,  0.0023,  0.0148],
          [ 0.0049,  0.0065,  0.0188]],

         [[ 0.0087,  0.0015,  0.0087],
          [ 0.0062,  0.0009,  0.0102],
          [ 0.0056,  0.0063,  0.0169]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0464, -0.0499, -0.0452],
          [-0.0345, -0.0440, -0.0342],
          [-0.0200, -0.0256, -0.0346]],

         [[-0.0607, -0.0630, -0.0569],
          [-0.0469, -0.0527, -0.0407],
          [-0.0270, -0.0272, -0.0327]],

         [[-0.0600, -0.0642, -0.0541],
          [-0.0445, -0.0501, -0.0362],
          [-0.0276, -0.0263, -0.0307]]],


        ...,


        [[[ 0.0002,  0.0034,  0.0017],
          [ 0.0015,  0.0028,  0.0009],
          [ 0.0040,  0.0066,  0.0049]],

         [[-0.0007,  0.0028,  0.0014],
          [ 0.0017,  0.0034,  0.0017],
          [ 0.0033,  0.0062,  0.0049]],

         [[-0.0036,  0.0006,  0.0008],
          [-0.0022,  0.0004, -0.0001],
          [-0.0005,  0.0024,  0.0013]]],


        [[[ 0.0001,  0.0107,  0.0168],
          [ 0.0046,  0.0093,  0.0156],
          [-0.0020,  0.0017,  0.0104]],

         [[-0.0038,  0.0052,  0.0104],
          [-0.0009,  0.0032,  0.0089],
          [-0.0087, -0.0056,  0.0041]],

         [[-0.0095, -0.0022,  0.0025],
          [-0.0069, -0.0029,  0.0029],
          [-0.0131, -0.0089,  0.0002]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2973]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 53 | Batch_idx: 0 |  Loss: (0.2610) | Acc: (91.00%) (117/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.2557) | Acc: (90.00%) (1274/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.2644) | Acc: (90.00%) (2437/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.2657) | Acc: (90.00%) (3594/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.2671) | Acc: (90.00%) (4748/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.2744) | Acc: (90.00%) (5897/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.2671) | Acc: (90.00%) (7075/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.2709) | Acc: (90.00%) (8227/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.2709) | Acc: (90.00%) (9392/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.2676) | Acc: (90.00%) (10570/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.2673) | Acc: (90.00%) (11740/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.2629) | Acc: (90.00%) (12920/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.2650) | Acc: (90.00%) (14081/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.2629) | Acc: (91.00%) (15260/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.2647) | Acc: (90.00%) (16407/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.2652) | Acc: (90.00%) (17570/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.2664) | Acc: (90.00%) (18726/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.2670) | Acc: (90.00%) (19879/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.2668) | Acc: (90.00%) (21034/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.2675) | Acc: (90.00%) (22187/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.2688) | Acc: (90.00%) (23340/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.2686) | Acc: (90.00%) (24495/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.2710) | Acc: (90.00%) (25633/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.2704) | Acc: (90.00%) (26795/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.2706) | Acc: (90.00%) (27952/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.2709) | Acc: (90.00%) (29105/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.2711) | Acc: (90.00%) (30265/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.2721) | Acc: (90.00%) (31418/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.2714) | Acc: (90.00%) (32586/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.2706) | Acc: (90.00%) (33747/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.2705) | Acc: (90.00%) (34918/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.2704) | Acc: (90.00%) (36085/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.2705) | Acc: (90.00%) (37255/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.2706) | Acc: (90.00%) (38414/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.2697) | Acc: (90.00%) (39592/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.2700) | Acc: (90.00%) (40745/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.2698) | Acc: (90.00%) (41911/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.2695) | Acc: (90.00%) (43074/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.2694) | Acc: (90.00%) (44225/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.2704) | Acc: (90.00%) (45331/50000)
# TEST : Loss: (0.5128) | Acc: (83.00%) (8316/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5670e-01, -2.3282e-01,  6.0108e-02],
          [-8.0547e-02,  2.7968e-01,  1.9059e-01],
          [ 1.1208e-01,  1.3420e-02, -7.5816e-02]],

         [[-2.2852e-01,  2.1027e-01,  2.0371e-01],
          [-8.1117e-03,  3.1542e-01,  1.9196e-01],
          [ 2.0528e-01, -9.9963e-02,  1.4098e-01]],

         [[-1.8692e-01, -2.2076e-02, -4.3357e-02],
          [-2.5136e-01, -6.1837e-02, -5.9484e-02],
          [-1.8525e-01, -5.9467e-02, -1.2745e-01]]],


        [[[ 3.4687e-08, -3.9601e-08,  8.3614e-08],
          [-2.1487e-08, -2.1274e-08,  1.9512e-08],
          [ 9.0550e-08, -1.7214e-10, -9.7222e-09]],

         [[-3.2159e-08,  4.6298e-10, -9.6455e-10],
          [ 3.6714e-08,  1.1836e-08,  1.9144e-08],
          [ 6.2749e-08,  2.7673e-08, -8.5422e-09]],

         [[ 5.7465e-09, -9.4907e-09,  1.2080e-08],
          [-2.0499e-08,  1.0306e-08,  1.7471e-08],
          [ 1.6000e-08, -6.2211e-10, -2.4315e-09]]],


        [[[ 5.5061e-02,  1.2505e-01, -7.3220e-02],
          [ 2.7246e-02,  1.8471e-01, -1.0286e-01],
          [ 9.1028e-02,  2.7077e-01,  2.4771e-01]],

         [[-2.0081e-01, -2.5077e-02, -1.5469e-01],
          [-2.7571e-01, -2.0012e-01, -2.2784e-01],
          [-2.3569e-01, -3.3982e-01,  2.8984e-02]],

         [[ 1.8816e-01,  5.1362e-02,  1.9918e-01],
          [ 1.8515e-01,  8.9002e-02,  4.3207e-02],
          [-1.5692e-02,  8.9799e-02,  5.0740e-02]]],


        ...,


        [[[ 2.6463e-01,  3.4039e-02,  6.0098e-03],
          [ 2.1313e-01, -2.3623e-01, -5.7798e-02],
          [-4.9860e-02, -1.5714e-01, -1.2450e-01]],

         [[-1.1463e-01, -4.0700e-02, -4.6020e-02],
          [-1.8801e-01, -2.3724e-01,  1.8622e-01],
          [-5.2119e-03,  3.0024e-01,  2.9037e-01]],

         [[-2.8506e-02, -4.2567e-02,  2.1107e-01],
          [ 1.4192e-02, -2.8239e-01, -1.3302e-01],
          [ 3.0225e-02, -7.0474e-02, -9.7677e-02]]],


        [[[ 9.7965e-02,  9.4838e-02,  2.5396e-01],
          [ 1.8219e-01,  1.6038e-01, -8.6590e-03],
          [-2.6565e-01, -1.7292e-01, -7.7705e-02]],

         [[ 4.8589e-02,  1.5240e-02, -1.4667e-01],
          [ 4.0256e-02, -6.2810e-02, -3.1966e-01],
          [-6.0213e-03,  1.3704e-01, -2.3398e-02]],

         [[-2.2282e-01, -8.2654e-02, -2.4976e-01],
          [-9.1535e-02,  7.8756e-02,  3.8103e-02],
          [ 1.5521e-01,  1.9694e-01,  1.5825e-01]]],


        [[[ 9.2976e-41,  1.5466e-40,  7.6819e-42],
          [ 2.1753e-40, -1.5800e-40,  1.9624e-40],
          [ 6.6295e-41, -2.2715e-40, -1.1405e-40]],

         [[ 1.4231e-40,  2.6533e-40, -1.5668e-40],
          [-8.2974e-41,  1.7891e-40, -8.5628e-41],
          [ 2.2370e-40, -1.4919e-40, -1.9411e-40]],

         [[-1.4186e-40, -1.9404e-41,  2.4421e-40],
          [-1.7188e-40,  1.6745e-40, -2.2715e-40],
          [ 5.8377e-41,  6.1977e-41,  3.9833e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0100, -0.0078, -0.0136],
          [-0.0080, -0.0044, -0.0157],
          [-0.0124, -0.0090, -0.0205]],

         [[-0.0118, -0.0091, -0.0143],
          [-0.0093, -0.0063, -0.0173],
          [-0.0123, -0.0097, -0.0203]],

         [[-0.0151, -0.0108, -0.0112],
          [-0.0125, -0.0073, -0.0143],
          [-0.0122, -0.0077, -0.0161]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0513,  0.0562,  0.0708],
          [ 0.0466,  0.0434,  0.0537],
          [ 0.0544,  0.0473,  0.0579]],

         [[ 0.0476,  0.0580,  0.0743],
          [ 0.0395,  0.0406,  0.0543],
          [ 0.0472,  0.0416,  0.0535]],

         [[ 0.0352,  0.0474,  0.0621],
          [ 0.0332,  0.0357,  0.0468],
          [ 0.0346,  0.0317,  0.0445]]],


        ...,


        [[[-0.0133, -0.0135, -0.0271],
          [-0.0187, -0.0175, -0.0265],
          [-0.0215, -0.0216, -0.0302]],

         [[-0.0103, -0.0118, -0.0247],
          [-0.0150, -0.0155, -0.0248],
          [-0.0183, -0.0201, -0.0292]],

         [[-0.0058, -0.0080, -0.0191],
          [-0.0099, -0.0104, -0.0172],
          [-0.0116, -0.0121, -0.0181]]],


        [[[-0.0134, -0.0118, -0.0110],
          [-0.0182, -0.0172, -0.0136],
          [-0.0174, -0.0148, -0.0142]],

         [[-0.0171, -0.0150, -0.0137],
          [-0.0232, -0.0203, -0.0156],
          [-0.0222, -0.0177, -0.0157]],

         [[-0.0078, -0.0067, -0.0093],
          [-0.0138, -0.0118, -0.0123],
          [-0.0131, -0.0104, -0.0116]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2964]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 54 | Batch_idx: 0 |  Loss: (0.2008) | Acc: (95.00%) (122/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.2789) | Acc: (90.00%) (1270/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.2960) | Acc: (89.00%) (2398/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3105) | Acc: (89.00%) (3533/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3079) | Acc: (89.00%) (4671/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.3101) | Acc: (88.00%) (5803/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.3132) | Acc: (88.00%) (6940/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.3105) | Acc: (88.00%) (8083/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.3039) | Acc: (89.00%) (9262/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.3016) | Acc: (89.00%) (10418/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.2997) | Acc: (89.00%) (11574/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.2978) | Acc: (89.00%) (12735/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.2929) | Acc: (89.00%) (13896/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.2899) | Acc: (89.00%) (15065/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.2875) | Acc: (89.00%) (16232/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.2848) | Acc: (90.00%) (17412/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.2822) | Acc: (90.00%) (18602/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.2816) | Acc: (90.00%) (19766/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.2789) | Acc: (90.00%) (20944/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.2777) | Acc: (90.00%) (22115/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.2758) | Acc: (90.00%) (23291/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.2740) | Acc: (90.00%) (24471/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.2732) | Acc: (90.00%) (25637/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.2720) | Acc: (90.00%) (26806/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.2712) | Acc: (90.00%) (27976/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.2703) | Acc: (90.00%) (29142/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.2701) | Acc: (90.00%) (30303/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.2686) | Acc: (90.00%) (31486/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.2680) | Acc: (90.00%) (32644/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.2672) | Acc: (90.00%) (33803/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.2658) | Acc: (90.00%) (34984/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.2647) | Acc: (90.00%) (36167/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.2642) | Acc: (90.00%) (37327/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.2640) | Acc: (90.00%) (38493/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.2639) | Acc: (90.00%) (39655/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.2635) | Acc: (90.00%) (40832/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.2623) | Acc: (90.00%) (42019/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.2613) | Acc: (90.00%) (43203/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.2601) | Acc: (91.00%) (44387/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.2603) | Acc: (91.00%) (45508/50000)
# TEST : Loss: (0.3288) | Acc: (89.00%) (8936/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5638e-01, -2.3230e-01,  5.9739e-02],
          [-8.0542e-02,  2.7818e-01,  1.8943e-01],
          [ 1.1163e-01,  1.3217e-02, -7.5566e-02]],

         [[-2.2731e-01,  2.0951e-01,  2.0312e-01],
          [-7.6972e-03,  3.1410e-01,  1.9111e-01],
          [ 2.0522e-01, -9.9536e-02,  1.4034e-01]],

         [[-1.8626e-01, -2.2632e-02, -4.3853e-02],
          [-2.5056e-01, -6.2572e-02, -6.0347e-02],
          [-1.8471e-01, -6.0002e-02, -1.2814e-01]]],


        [[[ 1.1847e-09, -1.2696e-09,  3.4766e-09],
          [-7.8326e-10, -6.6381e-10,  5.9606e-10],
          [ 3.6961e-09, -5.5535e-12, -2.0520e-10]],

         [[-1.0553e-09,  1.3655e-11, -3.5536e-11],
          [ 1.3354e-09,  3.5222e-10,  5.5038e-10],
          [ 2.3847e-09,  8.2374e-10, -1.7873e-10]],

         [[ 1.4809e-10, -2.2025e-10,  3.5671e-10],
          [-6.1566e-10,  2.4862e-10,  4.4251e-10],
          [ 5.1845e-10, -1.5459e-11, -4.6538e-11]]],


        [[[ 5.6875e-02,  1.2771e-01, -7.1433e-02],
          [ 2.9331e-02,  1.8708e-01, -1.0129e-01],
          [ 9.1836e-02,  2.7150e-01,  2.4771e-01]],

         [[-1.9738e-01, -2.1461e-02, -1.5255e-01],
          [-2.7220e-01, -1.9688e-01, -2.2597e-01],
          [-2.3380e-01, -3.3821e-01,  2.9298e-02]],

         [[ 1.9175e-01,  5.5012e-02,  2.0095e-01],
          [ 1.8878e-01,  9.2425e-02,  4.5454e-02],
          [-1.3472e-02,  9.1421e-02,  5.1681e-02]]],


        ...,


        [[[ 2.6525e-01,  3.6149e-02,  9.4273e-03],
          [ 2.1427e-01, -2.3218e-01, -5.3028e-02],
          [-4.6914e-02, -1.5373e-01, -1.1979e-01]],

         [[-1.1244e-01, -3.8422e-02, -4.2597e-02],
          [-1.8504e-01, -2.3306e-01,  1.8938e-01],
          [-2.6295e-03,  3.0125e-01,  2.9264e-01]],

         [[-2.7889e-02, -4.1512e-02,  2.1170e-01],
          [ 1.5284e-02, -2.7807e-01, -1.2921e-01],
          [ 3.1629e-02, -6.8345e-02, -9.4679e-02]]],


        [[[ 9.6085e-02,  9.1643e-02,  2.5041e-01],
          [ 1.8043e-01,  1.5774e-01, -1.0148e-02],
          [-2.6460e-01, -1.7224e-01, -7.7506e-02]],

         [[ 4.6785e-02,  1.2317e-02, -1.4950e-01],
          [ 3.9353e-02, -6.4543e-02, -3.2022e-01],
          [-5.4085e-03,  1.3694e-01, -2.3383e-02]],

         [[-2.2405e-01, -8.5281e-02, -2.5218e-01],
          [-9.2670e-02,  7.6186e-02,  3.6036e-02],
          [ 1.5465e-01,  1.9603e-01,  1.5705e-01]]],


        [[[ 4.4982e-41, -1.1740e-40,  1.3186e-40],
          [-2.1155e-40,  5.2756e-41, -8.7995e-41],
          [ 7.5506e-41,  1.1708e-40,  1.4134e-40]],

         [[ 1.4307e-42,  1.8971e-40,  1.2082e-40],
          [-2.0074e-40, -6.0961e-41, -2.2729e-42],
          [ 1.4851e-40, -1.1351e-41,  1.9920e-40]],

         [[ 1.6663e-40,  7.6752e-41,  2.3231e-40],
          [ 1.7977e-40,  3.3547e-40,  1.8891e-41],
          [-3.1954e-40,  6.9872e-41, -1.4018e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2953]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0618]], device='cuda:0')

Epoch: 55 | Batch_idx: 0 |  Loss: (0.3404) | Acc: (88.00%) (113/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.2408) | Acc: (92.00%) (1296/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.2486) | Acc: (91.00%) (2471/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.2486) | Acc: (92.00%) (3651/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.2468) | Acc: (91.00%) (4823/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.2421) | Acc: (91.00%) (5992/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.2420) | Acc: (91.00%) (7168/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.2387) | Acc: (91.00%) (8350/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.2363) | Acc: (91.00%) (9536/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.2331) | Acc: (92.00%) (10727/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.2311) | Acc: (92.00%) (11917/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.2340) | Acc: (92.00%) (13090/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.2341) | Acc: (92.00%) (14272/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.2338) | Acc: (92.00%) (15450/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.2318) | Acc: (92.00%) (16650/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.2313) | Acc: (92.00%) (17836/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.2312) | Acc: (92.00%) (19019/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.2310) | Acc: (92.00%) (20202/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.2312) | Acc: (92.00%) (21370/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.2317) | Acc: (92.00%) (22556/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.2311) | Acc: (92.00%) (23736/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.2311) | Acc: (92.00%) (24922/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.2314) | Acc: (92.00%) (26088/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.2327) | Acc: (92.00%) (27263/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.2330) | Acc: (92.00%) (28450/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.2321) | Acc: (92.00%) (29636/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.2323) | Acc: (92.00%) (30816/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.2320) | Acc: (92.00%) (32006/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.2315) | Acc: (92.00%) (33197/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.2312) | Acc: (92.00%) (34376/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.2306) | Acc: (92.00%) (35566/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.2299) | Acc: (92.00%) (36761/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.2300) | Acc: (92.00%) (37938/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.2300) | Acc: (92.00%) (39119/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.2296) | Acc: (92.00%) (40303/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.2297) | Acc: (92.00%) (41487/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.2302) | Acc: (92.00%) (42659/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.2305) | Acc: (92.00%) (43831/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.2301) | Acc: (92.00%) (45026/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.2297) | Acc: (92.00%) (46168/50000)
# TEST : Loss: (0.3170) | Acc: (89.00%) (8957/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5581e-01, -2.3136e-01,  5.9483e-02],
          [-8.0233e-02,  2.7699e-01,  1.8858e-01],
          [ 1.1120e-01,  1.3162e-02, -7.5248e-02]],

         [[-2.2645e-01,  2.0865e-01,  2.0225e-01],
          [-7.6667e-03,  3.1276e-01,  1.9027e-01],
          [ 2.0441e-01, -9.9126e-02,  1.3977e-01]],

         [[-1.8548e-01, -2.2538e-02, -4.3676e-02],
          [-2.4951e-01, -6.2314e-02, -6.0105e-02],
          [-1.8394e-01, -5.9759e-02, -1.2763e-01]]],


        [[[ 1.7827e-11, -1.7623e-11,  6.7217e-11],
          [-1.2808e-11, -8.9004e-12,  7.7778e-12],
          [ 6.9802e-11, -7.7703e-14, -1.6657e-12]],

         [[-1.5091e-11,  1.7035e-13, -5.8899e-13],
          [ 2.1775e-11,  4.4445e-12,  6.6453e-12],
          [ 4.1122e-11,  1.0399e-11, -1.4347e-12]],

         [[ 1.5540e-12, -2.0202e-12,  4.4571e-12],
          [-7.8612e-12,  2.3971e-12,  4.5417e-12],
          [ 7.2947e-12, -1.5482e-13, -3.3298e-13]]],


        [[[ 5.6788e-02,  1.2752e-01, -7.1324e-02],
          [ 2.9287e-02,  1.8680e-01, -1.0114e-01],
          [ 9.1695e-02,  2.7110e-01,  2.4733e-01]],

         [[-1.9705e-01, -2.1425e-02, -1.5230e-01],
          [-2.7174e-01, -1.9655e-01, -2.2561e-01],
          [-2.3341e-01, -3.3766e-01,  2.9251e-02]],

         [[ 1.9141e-01,  5.4917e-02,  2.0060e-01],
          [ 1.8844e-01,  9.2262e-02,  4.5376e-02],
          [-1.3448e-02,  9.1263e-02,  5.1592e-02]]],


        ...,


        [[[ 2.6372e-01,  3.5928e-02,  9.3710e-03],
          [ 2.1293e-01, -2.3061e-01, -5.2699e-02],
          [-4.6619e-02, -1.5274e-01, -1.1908e-01]],

         [[-1.1170e-01, -3.8149e-02, -4.2318e-02],
          [-1.8367e-01, -2.3119e-01,  1.8810e-01],
          [-2.6114e-03,  2.9914e-01,  2.9082e-01]],

         [[-2.7677e-02, -4.1144e-02,  2.1006e-01],
          [ 1.5143e-02, -2.7493e-01, -1.2811e-01],
          [ 3.1368e-02, -6.7739e-02, -9.3976e-02]]],


        [[[ 9.5717e-02,  9.1291e-02,  2.4953e-01],
          [ 1.7972e-01,  1.5712e-01, -1.0111e-02],
          [-2.6358e-01, -1.7159e-01, -7.7225e-02]],

         [[ 4.6605e-02,  1.2268e-02, -1.4888e-01],
          [ 3.9201e-02, -6.4286e-02, -3.1888e-01],
          [-5.3880e-03,  1.3641e-01, -2.3290e-02]],

         [[-2.2312e-01, -8.4910e-02, -2.5101e-01],
          [-9.2301e-02,  7.5872e-02,  3.5873e-02],
          [ 1.5405e-01,  1.9526e-01,  1.5639e-01]]],


        [[[ 4.7082e-41, -1.3654e-40,  2.4406e-40],
          [-1.0986e-40, -1.0320e-40,  1.6896e-40],
          [ 2.0882e-40,  8.2611e-41, -1.0797e-40]],

         [[-1.7805e-40, -1.4964e-40,  2.5188e-40],
          [-1.6283e-40,  4.8008e-41,  1.0559e-40],
          [-1.1404e-41,  1.6477e-40, -2.0204e-40]],

         [[ 1.3219e-40,  1.4385e-40,  1.5637e-40],
          [-1.2203e-40, -3.8046e-40, -1.3953e-40],
          [ 2.9423e-40,  1.8897e-40,  1.5708e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2747]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0357]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 56 | Batch_idx: 0 |  Loss: (0.1964) | Acc: (93.00%) (120/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.2217) | Acc: (92.00%) (1301/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.2469) | Acc: (91.00%) (2455/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.2541) | Acc: (91.00%) (3616/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.2554) | Acc: (91.00%) (4788/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.2677) | Acc: (91.00%) (5943/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.2710) | Acc: (90.00%) (7096/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.2767) | Acc: (90.00%) (8239/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.2834) | Acc: (90.00%) (9375/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.2897) | Acc: (90.00%) (10505/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.2938) | Acc: (90.00%) (11636/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.2983) | Acc: (89.00%) (12763/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.2992) | Acc: (89.00%) (13913/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.2995) | Acc: (89.00%) (15060/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.2992) | Acc: (89.00%) (16218/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.2980) | Acc: (89.00%) (17369/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.2972) | Acc: (89.00%) (18517/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.2986) | Acc: (89.00%) (19665/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.2976) | Acc: (89.00%) (20824/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.2980) | Acc: (89.00%) (21965/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.2981) | Acc: (89.00%) (23108/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.2986) | Acc: (89.00%) (24265/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.2973) | Acc: (89.00%) (25427/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.2966) | Acc: (89.00%) (26588/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.2963) | Acc: (89.00%) (27755/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.2970) | Acc: (89.00%) (28895/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.2963) | Acc: (89.00%) (30049/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.2963) | Acc: (89.00%) (31212/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.2967) | Acc: (89.00%) (32347/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.2971) | Acc: (89.00%) (33498/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.2970) | Acc: (89.00%) (34655/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.2973) | Acc: (89.00%) (35809/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.2984) | Acc: (89.00%) (36944/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.2977) | Acc: (89.00%) (38114/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.2978) | Acc: (89.00%) (39265/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.2977) | Acc: (89.00%) (40421/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.2972) | Acc: (90.00%) (41590/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.2971) | Acc: (90.00%) (42744/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.2962) | Acc: (90.00%) (43901/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.2962) | Acc: (90.00%) (45013/50000)
# TEST : Loss: (0.3821) | Acc: (87.00%) (8783/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.6733e-01, -2.3978e-01,  5.4985e-02],
          [-8.4658e-02,  2.7941e-01,  1.9363e-01],
          [ 1.0714e-01,  1.5403e-02, -7.7037e-02]],

         [[-2.3192e-01,  2.0370e-01,  1.9864e-01],
          [-1.1023e-02,  3.1574e-01,  1.9189e-01],
          [ 1.9837e-01, -9.8921e-02,  1.3036e-01]],

         [[-1.8957e-01, -2.9728e-02, -5.0107e-02],
          [-2.5049e-01, -6.2906e-02, -6.3390e-02],
          [-1.8606e-01, -6.0287e-02, -1.3746e-01]]],


        [[[ 9.3406e-14, -8.3134e-14,  4.8725e-13],
          [-7.4751e-14, -4.0137e-14,  3.3855e-14],
          [ 4.9087e-13, -3.7039e-16, -3.8911e-15]],

         [[-7.4000e-14,  6.9932e-16, -3.4984e-15],
          [ 1.2662e-13,  1.8519e-14,  2.6139e-14],
          [ 2.5710e-13,  4.3353e-14, -3.3024e-15]],

         [[ 5.0882e-15, -5.5433e-15,  1.8334e-14],
          [-3.3264e-14,  7.0233e-15,  1.4444e-14],
          [ 3.5026e-14, -4.7678e-16, -6.5836e-16]]],


        [[[ 4.8522e-02,  1.2418e-01, -7.3363e-02],
          [ 2.6883e-02,  1.8451e-01, -9.7533e-02],
          [ 1.0346e-01,  2.8257e-01,  2.5986e-01]],

         [[-2.0479e-01, -2.9817e-02, -1.5955e-01],
          [-2.8259e-01, -2.0983e-01, -2.2958e-01],
          [-2.3077e-01, -3.3746e-01,  3.3657e-02]],

         [[ 1.8313e-01,  4.7825e-02,  1.9079e-01],
          [ 1.7653e-01,  8.1382e-02,  4.1944e-02],
          [-1.3504e-02,  9.2590e-02,  5.4518e-02]]],


        ...,


        [[[ 2.6631e-01,  3.8639e-02,  2.4308e-03],
          [ 2.1734e-01, -2.4011e-01, -6.7791e-02],
          [-4.6920e-02, -1.6035e-01, -1.2561e-01]],

         [[-1.0313e-01, -2.5904e-02, -3.1778e-02],
          [-1.7304e-01, -2.2783e-01,  1.8547e-01],
          [ 5.9298e-03,  3.0351e-01,  2.9281e-01]],

         [[-2.2078e-02, -3.3012e-02,  2.0742e-01],
          [ 1.5626e-02, -2.7828e-01, -1.4326e-01],
          [ 2.8772e-02, -6.8209e-02, -9.8198e-02]]],


        [[[ 9.0122e-02,  9.6046e-02,  2.5372e-01],
          [ 1.8397e-01,  1.6617e-01, -3.0306e-03],
          [-2.6643e-01, -1.7390e-01, -7.4323e-02]],

         [[ 4.1824e-02,  9.2744e-03, -1.5404e-01],
          [ 3.8187e-02, -6.3466e-02, -3.1345e-01],
          [-8.2234e-03,  1.3576e-01, -1.6047e-02]],

         [[-2.3681e-01, -9.5762e-02, -2.5855e-01],
          [-1.0182e-01,  7.1189e-02,  3.5979e-02],
          [ 1.4730e-01,  1.9351e-01,  1.5677e-01]]],


        [[[-9.2879e-41,  3.0560e-41,  2.7540e-40],
          [ 9.1998e-41,  2.4286e-40, -2.2186e-40],
          [ 9.3391e-41, -1.4385e-40, -2.0200e-41]],

         [[-3.3156e-40,  2.3590e-40, -3.0410e-41],
          [ 8.7137e-41, -8.1689e-41,  1.7935e-40],
          [ 3.2027e-40,  3.1487e-40, -4.3505e-41]],

         [[-9.3788e-41,  1.6370e-40, -4.7966e-42],
          [ 4.2047e-41,  3.6668e-40, -2.7795e-40],
          [-2.2006e-40, -2.1890e-40,  2.3597e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0104, -0.0056,  0.0071],
          [-0.0036,  0.0032,  0.0114],
          [-0.0194, -0.0087,  0.0085]],

         [[ 0.0040,  0.0071,  0.0191],
          [ 0.0128,  0.0178,  0.0225],
          [-0.0026,  0.0076,  0.0208]],

         [[ 0.0054,  0.0120,  0.0235],
          [ 0.0193,  0.0269,  0.0306],
          [ 0.0146,  0.0242,  0.0327]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0070,  0.0167,  0.0052],
          [ 0.0156,  0.0095, -0.0125],
          [ 0.0343,  0.0391,  0.0024]],

         [[-0.0096,  0.0163,  0.0164],
          [ 0.0084, -0.0014, -0.0143],
          [ 0.0197,  0.0223, -0.0054]],

         [[-0.0147,  0.0022,  0.0068],
          [-0.0094, -0.0249, -0.0303],
          [-0.0012, -0.0034, -0.0225]]],


        ...,


        [[[ 0.0112,  0.0041,  0.0013],
          [ 0.0116,  0.0086,  0.0115],
          [ 0.0033,  0.0120,  0.0129]],

         [[ 0.0137,  0.0082,  0.0066],
          [ 0.0153,  0.0133,  0.0184],
          [ 0.0049,  0.0160,  0.0202]],

         [[ 0.0080,  0.0020,  0.0015],
          [ 0.0090,  0.0069,  0.0133],
          [-0.0003,  0.0091,  0.0162]]],


        [[[ 0.0158,  0.0213,  0.0091],
          [ 0.0094,  0.0077,  0.0045],
          [ 0.0012, -0.0098, -0.0130]],

         [[ 0.0014,  0.0058, -0.0051],
          [-0.0058, -0.0071, -0.0080],
          [-0.0146, -0.0263, -0.0264]],

         [[-0.0028,  0.0020, -0.0096],
          [-0.0099, -0.0137, -0.0147],
          [-0.0210, -0.0335, -0.0301]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2750]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 57 | Batch_idx: 0 |  Loss: (0.2473) | Acc: (90.00%) (116/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.2448) | Acc: (91.00%) (1294/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.2691) | Acc: (91.00%) (2457/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.2647) | Acc: (91.00%) (3642/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.2644) | Acc: (91.00%) (4806/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.2597) | Acc: (91.00%) (5987/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.2563) | Acc: (91.00%) (7162/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.2560) | Acc: (91.00%) (8336/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.2550) | Acc: (91.00%) (9511/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.2602) | Acc: (91.00%) (10660/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.2612) | Acc: (91.00%) (11827/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.2595) | Acc: (91.00%) (13008/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.2592) | Acc: (91.00%) (14172/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.2592) | Acc: (91.00%) (15339/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.2586) | Acc: (91.00%) (16509/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.2591) | Acc: (91.00%) (17667/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.2598) | Acc: (91.00%) (18815/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.2614) | Acc: (91.00%) (19972/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.2621) | Acc: (91.00%) (21125/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.2614) | Acc: (91.00%) (22293/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.2625) | Acc: (91.00%) (23454/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.2632) | Acc: (91.00%) (24618/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.2631) | Acc: (91.00%) (25787/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.2625) | Acc: (91.00%) (26966/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.2636) | Acc: (91.00%) (28119/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.2641) | Acc: (91.00%) (29278/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.2638) | Acc: (91.00%) (30442/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.2633) | Acc: (91.00%) (31617/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.2633) | Acc: (91.00%) (32781/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.2642) | Acc: (91.00%) (33934/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.2651) | Acc: (91.00%) (35090/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.2655) | Acc: (91.00%) (36263/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.2653) | Acc: (91.00%) (37426/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.2649) | Acc: (91.00%) (38587/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.2642) | Acc: (91.00%) (39754/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.2638) | Acc: (91.00%) (40919/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.2634) | Acc: (91.00%) (42085/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.2631) | Acc: (91.00%) (43251/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.2630) | Acc: (91.00%) (44420/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.2621) | Acc: (91.00%) (45557/50000)
# TEST : Loss: (0.3315) | Acc: (89.00%) (8957/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5745e-01, -2.2951e-01,  5.7922e-02],
          [-7.5287e-02,  2.8857e-01,  1.9736e-01],
          [ 1.1509e-01,  1.8263e-02, -7.7039e-02]],

         [[-2.2600e-01,  2.1022e-01,  1.9830e-01],
          [-1.0719e-02,  3.1840e-01,  1.9072e-01],
          [ 2.0014e-01, -9.9732e-02,  1.2742e-01]],

         [[-1.8625e-01, -2.6988e-02, -5.1977e-02],
          [-2.5911e-01, -7.0200e-02, -6.8132e-02],
          [-1.9489e-01, -6.9768e-02, -1.4095e-01]]],


        [[[ 1.2204e-16, -9.4384e-17,  9.8016e-16],
          [-1.1278e-16, -4.2895e-17,  3.4503e-17],
          [ 9.4858e-16, -4.2641e-19, -1.7034e-18]],

         [[-8.8485e-17,  6.5872e-19, -5.4025e-18],
          [ 1.9011e-16,  1.7796e-17,  2.3245e-17],
          [ 4.2507e-16,  4.1692e-17, -1.4167e-18]],

         [[ 3.5307e-18, -3.0246e-18,  1.7317e-17],
          [-3.2636e-17,  4.1904e-18,  9.6343e-18],
          [ 4.0718e-17, -3.0443e-19, -2.2906e-19]]],


        [[[ 5.3499e-02,  1.3175e-01, -6.5931e-02],
          [ 2.7324e-02,  1.8970e-01, -9.3530e-02],
          [ 1.0700e-01,  2.8550e-01,  2.5765e-01]],

         [[-2.0360e-01, -2.7945e-02, -1.6027e-01],
          [-2.8928e-01, -2.1389e-01, -2.3352e-01],
          [-2.3563e-01, -3.4416e-01,  2.3825e-02]],

         [[ 1.8490e-01,  5.2256e-02,  1.8715e-01],
          [ 1.7099e-01,  8.0881e-02,  3.5205e-02],
          [-1.5926e-02,  8.9285e-02,  4.1862e-02]]],


        ...,


        [[[ 2.8545e-01,  5.3667e-02,  1.5317e-02],
          [ 2.3143e-01, -2.2203e-01, -5.3330e-02],
          [-4.8055e-02, -1.4659e-01, -1.0229e-01]],

         [[-9.0427e-02, -1.6407e-02, -2.0043e-02],
          [-1.5822e-01, -2.0768e-01,  2.0059e-01],
          [ 1.4397e-02,  3.2652e-01,  3.2195e-01]],

         [[-2.0613e-03, -1.6038e-02,  2.2257e-01],
          [ 4.1791e-02, -2.4250e-01, -1.2188e-01],
          [ 4.3834e-02, -4.2289e-02, -7.0466e-02]]],


        [[[ 9.3340e-02,  1.0318e-01,  2.4837e-01],
          [ 1.8302e-01,  1.7050e-01, -9.1544e-03],
          [-2.6558e-01, -1.6989e-01, -7.4862e-02]],

         [[ 5.5545e-02,  2.1966e-02, -1.5266e-01],
          [ 4.9475e-02, -5.4062e-02, -3.1143e-01],
          [ 2.9373e-03,  1.4797e-01, -6.8689e-03]],

         [[-2.2271e-01, -8.5092e-02, -2.5295e-01],
          [-8.7803e-02,  8.5138e-02,  4.7199e-02],
          [ 1.6623e-01,  2.1574e-01,  1.7373e-01]]],


        [[[-1.0344e-40, -1.0459e-40,  1.8884e-40],
          [ 2.5734e-40, -2.6331e-40,  3.5976e-41],
          [-1.2590e-40,  1.0717e-40, -8.1515e-41]],

         [[-2.9140e-40, -3.2905e-40,  1.7311e-40],
          [-4.8100e-41,  1.9836e-40, -2.5546e-42],
          [ 2.0359e-40, -3.0622e-40,  8.7896e-41]],

         [[ 1.6143e-40, -1.5751e-40,  3.3033e-40],
          [-1.5416e-40, -2.0088e-40, -3.0859e-40],
          [ 2.9811e-40, -2.4279e-40, -6.9653e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0422, -0.0403, -0.0347],
          [-0.0594, -0.0493, -0.0384],
          [-0.0709, -0.0604, -0.0481]],

         [[-0.0359, -0.0309, -0.0255],
          [-0.0507, -0.0399, -0.0320],
          [-0.0599, -0.0514, -0.0428]],

         [[-0.0277, -0.0274, -0.0211],
          [-0.0426, -0.0371, -0.0298],
          [-0.0537, -0.0515, -0.0422]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0494, -0.0598, -0.0722],
          [-0.0235, -0.0229, -0.0419],
          [-0.0269, -0.0293, -0.0342]],

         [[-0.0447, -0.0524, -0.0708],
          [-0.0146, -0.0105, -0.0356],
          [-0.0026, -0.0086, -0.0243]],

         [[-0.0270, -0.0309, -0.0494],
          [ 0.0006,  0.0134, -0.0125],
          [ 0.0162,  0.0240,  0.0057]]],


        ...,


        [[[ 0.0044, -0.0055, -0.0147],
          [-0.0120, -0.0175, -0.0239],
          [-0.0249, -0.0269, -0.0338]],

         [[-0.0048, -0.0114, -0.0172],
          [-0.0208, -0.0243, -0.0278],
          [-0.0326, -0.0335, -0.0396]],

         [[-0.0122, -0.0182, -0.0280],
          [-0.0264, -0.0310, -0.0379],
          [-0.0358, -0.0388, -0.0486]]],


        [[[-0.0111, -0.0132, -0.0060],
          [-0.0255, -0.0247, -0.0140],
          [-0.0250, -0.0227, -0.0102]],

         [[-0.0020, -0.0076, -0.0019],
          [-0.0130, -0.0171, -0.0054],
          [-0.0088, -0.0103,  0.0043]],

         [[-0.0008, -0.0015,  0.0079],
          [-0.0091, -0.0067,  0.0065],
          [-0.0042,  0.0013,  0.0143]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2742]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 58 | Batch_idx: 0 |  Loss: (0.2656) | Acc: (89.00%) (115/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.2434) | Acc: (91.00%) (1292/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.2634) | Acc: (90.00%) (2441/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.2657) | Acc: (90.00%) (3593/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.2664) | Acc: (90.00%) (4758/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.2686) | Acc: (90.00%) (5912/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.2686) | Acc: (90.00%) (7077/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.2650) | Acc: (90.00%) (8259/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.2627) | Acc: (90.00%) (9426/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.2617) | Acc: (90.00%) (10596/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.2600) | Acc: (91.00%) (11767/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.2576) | Acc: (91.00%) (12941/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.2574) | Acc: (91.00%) (14099/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.2594) | Acc: (90.00%) (15249/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.2568) | Acc: (91.00%) (16431/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.2540) | Acc: (91.00%) (17617/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.2527) | Acc: (91.00%) (18798/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.2501) | Acc: (91.00%) (19989/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.2487) | Acc: (91.00%) (21169/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.2472) | Acc: (91.00%) (22353/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.2455) | Acc: (91.00%) (23537/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.2443) | Acc: (91.00%) (24724/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.2410) | Acc: (91.00%) (25929/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.2391) | Acc: (91.00%) (27121/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.2383) | Acc: (91.00%) (28300/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.2383) | Acc: (91.00%) (29484/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.2383) | Acc: (91.00%) (30657/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.2379) | Acc: (91.00%) (31837/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.2360) | Acc: (91.00%) (33030/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.2355) | Acc: (91.00%) (34221/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.2348) | Acc: (91.00%) (35405/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.2332) | Acc: (91.00%) (36606/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.2323) | Acc: (91.00%) (37796/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.2324) | Acc: (91.00%) (38972/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.2316) | Acc: (92.00%) (40161/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.2302) | Acc: (92.00%) (41362/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.2304) | Acc: (92.00%) (42543/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.2304) | Acc: (92.00%) (43715/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.2300) | Acc: (92.00%) (44909/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.2301) | Acc: (92.00%) (46045/50000)
# TEST : Loss: (0.3055) | Acc: (90.00%) (9010/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5499e-01, -2.2649e-01,  5.9861e-02],
          [-7.1301e-02,  2.9132e-01,  1.9856e-01],
          [ 1.1872e-01,  2.1829e-02, -7.5191e-02]],

         [[-2.2437e-01,  2.1103e-01,  1.9892e-01],
          [-7.8519e-03,  3.2031e-01,  1.9143e-01],
          [ 2.0233e-01, -9.6747e-02,  1.2810e-01]],

         [[-1.8451e-01, -2.4899e-02, -4.9886e-02],
          [-2.5537e-01, -6.6719e-02, -6.5777e-02],
          [-1.9108e-01, -6.6261e-02, -1.3853e-01]]],


        [[[ 2.3837e-20, -1.5122e-20,  3.4926e-19],
          [-2.6948e-20, -6.3083e-21,  4.7431e-21],
          [ 3.1975e-19, -6.9678e-23, -6.8502e-23]],

         [[-1.5255e-20,  8.0936e-23, -1.3337e-21],
          [ 4.5120e-20,  2.2500e-21,  2.6305e-21],
          [ 1.1540e-19,  5.2766e-21, -5.5273e-23]],

         [[ 2.7947e-22, -1.6853e-22,  2.1360e-21],
          [-4.2501e-21,  2.6620e-22,  7.2008e-22],
          [ 6.7458e-21, -2.1352e-23, -6.5237e-24]]],


        [[[ 5.6793e-02,  1.3430e-01, -6.3285e-02],
          [ 2.9773e-02,  1.9125e-01, -9.1451e-02],
          [ 1.0943e-01,  2.8707e-01,  2.5873e-01]],

         [[-2.0060e-01, -2.6127e-02, -1.5798e-01],
          [-2.8709e-01, -2.1283e-01, -2.3184e-01],
          [-2.3360e-01, -3.4249e-01,  2.4770e-02]],

         [[ 1.8664e-01,  5.3199e-02,  1.8834e-01],
          [ 1.7129e-01,  8.0519e-02,  3.5915e-02],
          [-1.5315e-02,  8.9179e-02,  4.2032e-02]]],


        ...,


        [[[ 2.8208e-01,  5.3806e-02,  1.6611e-02],
          [ 2.2806e-01, -2.1976e-01, -5.1140e-02],
          [-4.7963e-02, -1.4422e-01, -9.9242e-02]],

         [[-9.1513e-02, -1.5660e-02, -1.8454e-02],
          [-1.5878e-01, -2.0469e-01,  2.0175e-01],
          [ 1.5453e-02,  3.2732e-01,  3.2356e-01]],

         [[-3.6236e-03, -1.5324e-02,  2.2319e-01],
          [ 3.9572e-02, -2.3891e-01, -1.1858e-01],
          [ 4.3895e-02, -4.0164e-02, -6.6635e-02]]],


        [[[ 9.3935e-02,  1.0435e-01,  2.4894e-01],
          [ 1.8485e-01,  1.7395e-01, -4.9861e-03],
          [-2.6119e-01, -1.6494e-01, -7.0614e-02]],

         [[ 5.4661e-02,  2.1661e-02, -1.5222e-01],
          [ 5.0085e-02, -5.1689e-02, -3.0760e-01],
          [ 4.4949e-03,  1.5006e-01, -4.7003e-03]],

         [[-2.2163e-01, -8.4705e-02, -2.5221e-01],
          [-8.6351e-02,  8.6896e-02,  4.9192e-02],
          [ 1.6719e-01,  2.1691e-01,  1.7434e-01]]],


        [[[-1.9647e-40,  1.8634e-40, -3.2130e-40],
          [ 2.8079e-40,  8.0614e-41,  4.0259e-41],
          [-3.0248e-40, -2.8615e-41, -9.1653e-41]],

         [[-2.3833e-40, -3.5876e-40, -3.9554e-41],
          [ 1.0848e-40, -1.0257e-40,  1.4544e-40],
          [ 3.0429e-40,  2.2020e-40, -1.9557e-40]],

         [[-1.9003e-40,  1.2551e-40, -2.2929e-40],
          [-2.4404e-40, -7.5156e-41,  3.1875e-40],
          [-1.9538e-40, -1.1660e-40,  6.7777e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3666]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0199]], device='cuda:0')

Epoch: 59 | Batch_idx: 0 |  Loss: (0.1846) | Acc: (92.00%) (119/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.2102) | Acc: (92.00%) (1305/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.2048) | Acc: (93.00%) (2503/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.2016) | Acc: (93.00%) (3701/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.1985) | Acc: (93.00%) (4903/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.1980) | Acc: (93.00%) (6105/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.1978) | Acc: (93.00%) (7299/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.1980) | Acc: (93.00%) (8492/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.2009) | Acc: (93.00%) (9682/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.2048) | Acc: (93.00%) (10859/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.2063) | Acc: (93.00%) (12041/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.2088) | Acc: (93.00%) (13227/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.2095) | Acc: (93.00%) (14407/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.2113) | Acc: (92.00%) (15586/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.2115) | Acc: (93.00%) (16785/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.2111) | Acc: (92.00%) (17974/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.2094) | Acc: (93.00%) (19180/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.2095) | Acc: (93.00%) (20369/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.2088) | Acc: (93.00%) (21565/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.2072) | Acc: (93.00%) (22771/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.2080) | Acc: (93.00%) (23949/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.2087) | Acc: (93.00%) (25130/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.2090) | Acc: (93.00%) (26323/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.2092) | Acc: (93.00%) (27505/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.2097) | Acc: (92.00%) (28687/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.2092) | Acc: (92.00%) (29877/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.2101) | Acc: (92.00%) (31053/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.2109) | Acc: (92.00%) (32224/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.2107) | Acc: (92.00%) (33412/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.2105) | Acc: (92.00%) (34598/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.2113) | Acc: (92.00%) (35771/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.2117) | Acc: (92.00%) (36954/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.2112) | Acc: (92.00%) (38153/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.2111) | Acc: (92.00%) (39343/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.2113) | Acc: (92.00%) (40523/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.2108) | Acc: (92.00%) (41721/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.2100) | Acc: (92.00%) (42928/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.2107) | Acc: (92.00%) (44111/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.2101) | Acc: (92.00%) (45306/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.2106) | Acc: (92.00%) (46443/50000)
# TEST : Loss: (0.3013) | Acc: (90.00%) (9018/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5446e-01, -2.2563e-01,  5.9619e-02],
          [-7.1045e-02,  2.9017e-01,  1.9774e-01],
          [ 1.1829e-01,  2.1745e-02, -7.4895e-02]],

         [[-2.2354e-01,  2.1020e-01,  1.9810e-01],
          [-7.8223e-03,  3.1903e-01,  1.9064e-01],
          [ 2.0157e-01, -9.6366e-02,  1.2760e-01]],

         [[-1.8374e-01, -2.4798e-02, -4.9688e-02],
          [-2.5433e-01, -6.6454e-02, -6.5524e-02],
          [-1.9032e-01, -6.6002e-02, -1.3801e-01]]],


        [[[ 2.7783e-25, -1.2839e-25,  1.0312e-23],
          [-4.3110e-25, -4.6620e-26,  3.1394e-26],
          [ 8.6799e-24, -6.1070e-28, -5.0896e-29]],

         [[-1.4573e-25,  4.4519e-28, -2.2445e-26],
          [ 7.1420e-25,  1.2976e-26,  1.2616e-26],
          [ 2.2498e-24,  3.0483e-26, -3.8683e-29]],

         [[ 7.2702e-28, -2.3320e-28,  1.1825e-26],
          [-2.5737e-26,  4.6815e-28,  1.6935e-27],
          [ 6.0450e-26, -4.4859e-29, -2.3858e-30]]],


        [[[ 5.6703e-02,  1.3409e-01, -6.3184e-02],
          [ 2.9726e-02,  1.9095e-01, -9.1307e-02],
          [ 1.0926e-01,  2.8663e-01,  2.5833e-01]],

         [[-2.0025e-01, -2.6082e-02, -1.5771e-01],
          [-2.8659e-01, -2.1246e-01, -2.3143e-01],
          [-2.3319e-01, -3.4191e-01,  2.4728e-02]],

         [[ 1.8629e-01,  5.3101e-02,  1.8799e-01],
          [ 1.7098e-01,  8.0370e-02,  3.5848e-02],
          [-1.5286e-02,  8.9016e-02,  4.1957e-02]]],


        ...,


        [[[ 2.8038e-01,  5.3457e-02,  1.6503e-02],
          [ 2.2655e-01, -2.1816e-01, -5.0792e-02],
          [-4.7649e-02, -1.4325e-01, -9.8629e-02]],

         [[-9.0923e-02, -1.5551e-02, -1.8329e-02],
          [-1.5762e-01, -2.0308e-01,  2.0033e-01],
          [ 1.5345e-02,  3.2507e-01,  3.2151e-01]],

         [[-3.5976e-03, -1.5200e-02,  2.2151e-01],
          [ 3.9229e-02, -2.3647e-01, -1.1759e-01],
          [ 4.3546e-02, -3.9830e-02, -6.6159e-02]]],


        [[[ 9.3559e-02,  1.0394e-01,  2.4806e-01],
          [ 1.8408e-01,  1.7325e-01, -4.9679e-03],
          [-2.6016e-01, -1.6431e-01, -7.0353e-02]],

         [[ 5.4425e-02,  2.1570e-02, -1.5159e-01],
          [ 4.9873e-02, -5.1475e-02, -3.0632e-01],
          [ 4.4770e-03,  1.4948e-01, -4.6814e-03]],

         [[-2.2063e-01, -8.4328e-02, -2.5104e-01],
          [-8.5983e-02,  8.6530e-02,  4.8972e-02],
          [ 1.6651e-01,  2.1605e-01,  1.7362e-01]]],


        [[[ 6.1178e-41, -2.1044e-40,  8.8329e-41],
          [ 1.2204e-40,  6.6856e-42, -1.6922e-40],
          [-3.2519e-40,  1.3075e-40, -3.0327e-41]],

         [[ 2.6292e-40, -1.2719e-40, -2.0927e-40],
          [ 1.1676e-40,  6.1764e-41,  2.3999e-40],
          [-3.6445e-40,  2.4008e-40,  1.8972e-40]],

         [[-2.0877e-40, -2.4331e-41, -7.4255e-42],
          [ 5.7654e-41, -2.4805e-40,  3.4766e-40],
          [ 2.7557e-40,  1.1879e-40, -5.0965e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3629]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0561]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.1779) | Acc: (95.00%) (122/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.2211) | Acc: (93.00%) (1310/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.2334) | Acc: (92.00%) (2480/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.2376) | Acc: (92.00%) (3659/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.2481) | Acc: (91.00%) (4816/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.2501) | Acc: (91.00%) (5982/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.2616) | Acc: (91.00%) (7122/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.2697) | Acc: (90.00%) (8269/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.2767) | Acc: (90.00%) (9410/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.2842) | Acc: (90.00%) (10543/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.2861) | Acc: (90.00%) (11694/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.2882) | Acc: (90.00%) (12839/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.2903) | Acc: (90.00%) (13991/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.2931) | Acc: (90.00%) (15124/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.2944) | Acc: (90.00%) (16269/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.2940) | Acc: (90.00%) (17419/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.2936) | Acc: (90.00%) (18578/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.2952) | Acc: (90.00%) (19719/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.2951) | Acc: (90.00%) (20877/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.2947) | Acc: (90.00%) (22029/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.2946) | Acc: (90.00%) (23187/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.2943) | Acc: (90.00%) (24342/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.2944) | Acc: (90.00%) (25503/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.2947) | Acc: (90.00%) (26643/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.2937) | Acc: (90.00%) (27804/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.2950) | Acc: (90.00%) (28948/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.2966) | Acc: (90.00%) (30081/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.2962) | Acc: (90.00%) (31233/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.2964) | Acc: (90.00%) (32382/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.2956) | Acc: (90.00%) (33541/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.2964) | Acc: (90.00%) (34685/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.2966) | Acc: (90.00%) (35833/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.2964) | Acc: (90.00%) (36985/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.2968) | Acc: (89.00%) (38128/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.2955) | Acc: (90.00%) (39293/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.2954) | Acc: (90.00%) (40437/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.2951) | Acc: (89.00%) (41586/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.2953) | Acc: (89.00%) (42739/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.2949) | Acc: (90.00%) (43894/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.2939) | Acc: (90.00%) (45016/50000)
# TEST : Loss: (0.3929) | Acc: (87.00%) (8723/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.6254e-01, -2.3277e-01,  5.6626e-02],
          [-7.0875e-02,  2.9209e-01,  2.0299e-01],
          [ 1.2692e-01,  2.7510e-02, -7.3335e-02]],

         [[-2.2985e-01,  2.0469e-01,  1.9687e-01],
          [-4.6660e-03,  3.2280e-01,  1.9202e-01],
          [ 2.1515e-01, -8.6380e-02,  1.2702e-01]],

         [[-1.8737e-01, -2.9609e-02, -5.1598e-02],
          [-2.5231e-01, -6.9479e-02, -6.9328e-02],
          [-1.7332e-01, -5.9277e-02, -1.4030e-01]]],


        [[[ 9.6390e-33, -1.0192e-33,  4.0737e-30],
          [-3.9605e-32, -8.6988e-35, -4.2149e-35],
          [ 2.8611e-30, -5.9346e-36, -4.7815e-38]],

         [[-2.2467e-33, -1.9684e-36, -2.3633e-33],
          [ 6.3739e-32, -5.0069e-35, -6.8008e-35],
          [ 3.4500e-31, -1.1691e-34, -3.8253e-38]],

         [[-2.7166e-36,  1.1583e-37, -5.1467e-35],
          [ 8.0514e-35, -7.2983e-37, -5.3380e-36],
          [ 6.6847e-34,  1.1244e-37, -2.1095e-39]]],


        [[[ 5.3331e-02,  1.2602e-01, -8.7421e-02],
          [ 3.4530e-02,  1.9055e-01, -1.0471e-01],
          [ 1.1191e-01,  2.8626e-01,  2.5363e-01]],

         [[-2.0014e-01, -3.1713e-02, -1.7621e-01],
          [-2.8298e-01, -2.1781e-01, -2.4256e-01],
          [-2.3037e-01, -3.4469e-01,  2.1704e-02]],

         [[ 1.9018e-01,  5.7030e-02,  1.8238e-01],
          [ 1.8326e-01,  8.6949e-02,  3.8422e-02],
          [-7.7440e-04,  9.8519e-02,  5.0185e-02]]],


        ...,


        [[[ 2.6806e-01,  3.5262e-02,  1.5093e-04],
          [ 2.0712e-01, -2.5196e-01, -7.7243e-02],
          [-6.7016e-02, -1.7482e-01, -1.2905e-01]],

         [[-1.1397e-01, -4.3188e-02, -4.2715e-02],
          [-1.8695e-01, -2.3965e-01,  1.6745e-01],
          [-1.1245e-02,  2.9322e-01,  2.8820e-01]],

         [[-1.2278e-02, -2.7228e-02,  2.0830e-01],
          [ 2.0356e-02, -2.5737e-01, -1.3719e-01],
          [ 2.9968e-02, -5.6154e-02, -8.8199e-02]]],


        [[[ 9.4290e-02,  1.1120e-01,  2.4956e-01],
          [ 1.7725e-01,  1.7028e-01, -1.0989e-02],
          [-2.6319e-01, -1.6915e-01, -7.3328e-02]],

         [[ 5.1018e-02,  1.6359e-02, -1.6612e-01],
          [ 4.1241e-02, -6.4824e-02, -3.2666e-01],
          [ 3.0451e-03,  1.4238e-01, -1.4599e-02]],

         [[-2.2572e-01, -8.7069e-02, -2.5556e-01],
          [-9.2531e-02,  7.8755e-02,  3.8345e-02],
          [ 1.6985e-01,  2.1627e-01,  1.6875e-01]]],


        [[[-3.2286e-41, -1.3875e-40, -3.8508e-40],
          [-1.5959e-40, -8.0572e-41,  2.8471e-40],
          [ 4.1984e-40,  2.3069e-40,  4.4685e-41]],

         [[-2.7694e-40, -4.1739e-40, -4.0369e-40],
          [ 2.1965e-40,  1.5938e-40,  1.7220e-40],
          [ 7.6231e-41, -2.9358e-40, -2.3087e-40]],

         [[ 3.2681e-41, -2.0039e-40,  8.0039e-41],
          [ 6.1935e-41, -2.7081e-40,  2.9000e-40],
          [ 3.8645e-40,  3.0536e-40, -9.1369e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0364, -0.0299, -0.0287],
          [-0.0331, -0.0259, -0.0270],
          [-0.0275, -0.0167, -0.0215]],

         [[-0.0333, -0.0259, -0.0231],
          [-0.0300, -0.0222, -0.0215],
          [-0.0258, -0.0146, -0.0177]],

         [[-0.0283, -0.0196, -0.0172],
          [-0.0248, -0.0170, -0.0171],
          [-0.0203, -0.0112, -0.0145]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0161,  0.0063,  0.0431],
          [ 0.0237,  0.0122,  0.0315],
          [ 0.0295,  0.0225,  0.0230]],

         [[ 0.0019, -0.0067,  0.0353],
          [ 0.0063, -0.0041,  0.0206],
          [ 0.0101,  0.0043,  0.0108]],

         [[-0.0055, -0.0112,  0.0283],
          [-0.0018, -0.0101,  0.0147],
          [ 0.0015, -0.0043,  0.0036]]],


        ...,


        [[[ 0.0073,  0.0051,  0.0107],
          [ 0.0074,  0.0062,  0.0100],
          [ 0.0095,  0.0061,  0.0071]],

         [[ 0.0062,  0.0038,  0.0099],
          [ 0.0067,  0.0058,  0.0096],
          [ 0.0097,  0.0067,  0.0075]],

         [[ 0.0031,  0.0004,  0.0055],
          [ 0.0042,  0.0028,  0.0052],
          [ 0.0068,  0.0032,  0.0032]]],


        [[[ 0.0305,  0.0204,  0.0205],
          [ 0.0201,  0.0178,  0.0181],
          [ 0.0152,  0.0170,  0.0139]],

         [[ 0.0315,  0.0174,  0.0140],
          [ 0.0190,  0.0141,  0.0115],
          [ 0.0100,  0.0113,  0.0076]],

         [[ 0.0237,  0.0116,  0.0077],
          [ 0.0129,  0.0075,  0.0051],
          [ 0.0061,  0.0058,  0.0021]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3606]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 61 | Batch_idx: 0 |  Loss: (0.2113) | Acc: (91.00%) (117/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.2523) | Acc: (91.00%) (1283/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.2405) | Acc: (91.00%) (2461/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.2453) | Acc: (91.00%) (3631/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.2530) | Acc: (91.00%) (4787/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.2529) | Acc: (91.00%) (5951/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.2503) | Acc: (91.00%) (7116/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.2541) | Acc: (91.00%) (8272/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.2530) | Acc: (91.00%) (9441/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.2569) | Acc: (90.00%) (10582/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.2583) | Acc: (90.00%) (11731/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.2556) | Acc: (90.00%) (12901/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.2542) | Acc: (90.00%) (14080/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.2517) | Acc: (91.00%) (15266/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.2502) | Acc: (91.00%) (16448/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.2505) | Acc: (91.00%) (17618/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.2522) | Acc: (91.00%) (18774/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.2535) | Acc: (91.00%) (19936/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.2525) | Acc: (91.00%) (21116/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.2512) | Acc: (91.00%) (22293/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.2501) | Acc: (91.00%) (23473/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.2495) | Acc: (91.00%) (24638/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.2518) | Acc: (91.00%) (25794/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.2516) | Acc: (91.00%) (26966/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.2521) | Acc: (91.00%) (28118/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.2523) | Acc: (91.00%) (29284/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.2520) | Acc: (91.00%) (30446/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.2516) | Acc: (91.00%) (31621/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.2515) | Acc: (91.00%) (32800/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.2506) | Acc: (91.00%) (33975/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.2511) | Acc: (91.00%) (35139/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.2519) | Acc: (91.00%) (36292/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.2525) | Acc: (91.00%) (37455/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.2536) | Acc: (91.00%) (38613/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.2539) | Acc: (91.00%) (39783/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.2545) | Acc: (91.00%) (40948/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.2547) | Acc: (91.00%) (42118/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.2546) | Acc: (91.00%) (43291/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.2538) | Acc: (91.00%) (44461/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.2547) | Acc: (91.00%) (45577/50000)
# TEST : Loss: (0.3552) | Acc: (88.00%) (8868/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.6803e-01, -2.3750e-01,  5.3252e-02],
          [-7.4949e-02,  2.8824e-01,  1.9642e-01],
          [ 1.1602e-01,  1.5259e-02, -9.0703e-02]],

         [[-2.3324e-01,  2.0452e-01,  1.9942e-01],
          [-1.0516e-03,  3.2710e-01,  1.9455e-01],
          [ 2.1460e-01, -8.5924e-02,  1.1988e-01]],

         [[-1.9351e-01, -3.2454e-02, -5.0911e-02],
          [-2.5381e-01, -7.1056e-02, -6.9133e-02],
          [-1.7567e-01, -6.1668e-02, -1.4517e-01]]],


        [[[-8.5157e-42, -6.6738e-41,  3.8486e-39],
          [ 4.8722e-41, -5.2222e-41,  2.9715e-41],
          [ 2.2870e-39, -5.0755e-41,  5.9572e-41]],

         [[-4.5353e-41, -2.6524e-41,  5.4683e-41],
          [-6.3993e-41,  1.8224e-41, -3.8812e-41],
          [-1.4970e-41, -1.1353e-41,  6.5180e-41]],

         [[-1.2473e-41, -1.5180e-41,  7.4059e-42],
          [-1.3305e-41,  6.1754e-41,  2.8386e-41],
          [ 2.5642e-41, -2.9088e-41,  1.4616e-42]]],


        [[[ 5.7675e-02,  1.2792e-01, -8.2774e-02],
          [ 4.0378e-02,  1.9997e-01, -9.8677e-02],
          [ 1.1561e-01,  2.9554e-01,  2.6209e-01]],

         [[-1.9772e-01, -3.0668e-02, -1.7056e-01],
          [-2.8333e-01, -2.1388e-01, -2.3793e-01],
          [-2.3349e-01, -3.4278e-01,  2.5499e-02]],

         [[ 1.9399e-01,  6.0032e-02,  1.8499e-01],
          [ 1.8453e-01,  9.3759e-02,  4.0821e-02],
          [-4.1742e-03,  1.0070e-01,  4.9254e-02]]],


        ...,


        [[[ 2.7473e-01,  4.1003e-02, -1.9013e-05],
          [ 2.1120e-01, -2.5408e-01, -8.2065e-02],
          [-6.4759e-02, -1.7414e-01, -1.2974e-01]],

         [[-1.1450e-01, -4.7847e-02, -5.2744e-02],
          [-1.9354e-01, -2.5391e-01,  1.4930e-01],
          [-1.4561e-02,  2.8841e-01,  2.7886e-01]],

         [[-1.1644e-02, -3.0432e-02,  2.0393e-01],
          [ 1.9210e-02, -2.6335e-01, -1.4091e-01],
          [ 3.3460e-02, -5.2768e-02, -8.5229e-02]]],


        [[[ 9.7898e-02,  1.1275e-01,  2.5097e-01],
          [ 1.7459e-01,  1.7148e-01, -8.3265e-03],
          [-2.6511e-01, -1.7221e-01, -8.0417e-02]],

         [[ 5.2504e-02,  1.1068e-02, -1.7424e-01],
          [ 3.4759e-02, -6.8730e-02, -3.3011e-01],
          [-1.9077e-03,  1.3670e-01, -2.5109e-02]],

         [[-2.2993e-01, -9.6164e-02, -2.6484e-01],
          [-1.0812e-01,  7.2320e-02,  3.6471e-02],
          [ 1.5814e-01,  2.1198e-01,  1.6238e-01]]],


        [[[ 7.0415e-41,  4.1595e-41,  4.5055e-40],
          [ 4.4468e-40, -8.6824e-41, -1.1535e-40],
          [-1.6506e-40,  1.5370e-40,  1.3311e-40]],

         [[ 2.5546e-42,  2.5157e-40, -3.3504e-40],
          [ 1.3602e-40,  7.1012e-41, -2.8404e-42],
          [ 2.7946e-40, -1.1663e-40, -5.9383e-41]],

         [[-1.5097e-40,  2.5625e-40,  2.7337e-40],
          [ 6.6052e-41,  2.7526e-40,  3.3275e-41],
          [ 3.1951e-40,  3.2714e-40, -9.7680e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0035,  0.0071,  0.0084],
          [-0.0027, -0.0002,  0.0054],
          [ 0.0014,  0.0050,  0.0202]],

         [[-0.0181, -0.0078, -0.0049],
          [-0.0136, -0.0119, -0.0067],
          [-0.0069, -0.0042,  0.0084]],

         [[-0.0158, -0.0022,  0.0071],
          [-0.0103, -0.0074,  0.0021],
          [-0.0020, -0.0031,  0.0113]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0140, -0.0302, -0.0062],
          [-0.0791, -0.0748, -0.0340],
          [-0.0825, -0.0766, -0.0283]],

         [[ 0.0193,  0.0060,  0.0166],
          [-0.0420, -0.0444, -0.0178],
          [-0.0529, -0.0501, -0.0130]],

         [[ 0.0504,  0.0309,  0.0339],
          [-0.0153, -0.0206,  0.0042],
          [-0.0376, -0.0359,  0.0105]]],


        ...,


        [[[ 0.0137,  0.0115,  0.0021],
          [ 0.0074,  0.0025, -0.0059],
          [ 0.0077,  0.0065, -0.0071]],

         [[ 0.0127,  0.0133,  0.0046],
          [ 0.0072,  0.0051, -0.0042],
          [ 0.0068,  0.0074, -0.0052]],

         [[ 0.0117,  0.0121,  0.0029],
          [ 0.0085,  0.0042, -0.0049],
          [ 0.0076,  0.0067, -0.0050]]],


        [[[ 0.0136, -0.0041, -0.0113],
          [ 0.0205, -0.0025, -0.0070],
          [ 0.0384,  0.0148,  0.0057]],

         [[-0.0094, -0.0239, -0.0295],
          [-0.0062, -0.0245, -0.0299],
          [ 0.0044, -0.0175, -0.0221]],

         [[-0.0102, -0.0171, -0.0217],
          [-0.0122, -0.0231, -0.0289],
          [-0.0075, -0.0243, -0.0245]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3596]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 62 | Batch_idx: 0 |  Loss: (0.1794) | Acc: (93.00%) (120/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.2150) | Acc: (93.00%) (1310/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.2526) | Acc: (91.00%) (2457/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.2620) | Acc: (91.00%) (3613/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.2801) | Acc: (90.00%) (4741/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.2775) | Acc: (90.00%) (5906/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.2720) | Acc: (90.00%) (7072/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.2731) | Acc: (90.00%) (8236/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.2718) | Acc: (90.00%) (9410/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.2679) | Acc: (90.00%) (10582/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.2645) | Acc: (90.00%) (11762/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.2623) | Acc: (91.00%) (12938/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.2621) | Acc: (91.00%) (14098/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.2619) | Acc: (90.00%) (15257/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.2595) | Acc: (91.00%) (16429/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.2579) | Acc: (91.00%) (17603/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.2572) | Acc: (91.00%) (18771/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.2563) | Acc: (91.00%) (19947/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.2550) | Acc: (91.00%) (21122/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.2534) | Acc: (91.00%) (22303/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.2510) | Acc: (91.00%) (23493/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.2494) | Acc: (91.00%) (24679/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.2481) | Acc: (91.00%) (25864/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.2474) | Acc: (91.00%) (27045/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.2462) | Acc: (91.00%) (28229/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.2443) | Acc: (91.00%) (29425/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.2435) | Acc: (91.00%) (30604/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.2421) | Acc: (91.00%) (31793/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.2425) | Acc: (91.00%) (32962/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.2418) | Acc: (91.00%) (34147/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.2409) | Acc: (91.00%) (35331/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.2404) | Acc: (91.00%) (36509/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.2389) | Acc: (91.00%) (37712/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.2386) | Acc: (91.00%) (38881/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.2378) | Acc: (91.00%) (40072/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.2369) | Acc: (91.00%) (41263/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.2364) | Acc: (91.00%) (42446/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.2358) | Acc: (91.00%) (43624/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.2349) | Acc: (91.00%) (44818/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.2345) | Acc: (91.00%) (45960/50000)
# TEST : Loss: (0.3322) | Acc: (89.00%) (8971/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.6810e-01, -2.3682e-01,  5.3461e-02],
          [-7.6737e-02,  2.8619e-01,  1.9501e-01],
          [ 1.1286e-01,  1.3305e-02, -9.3204e-02]],

         [[-2.3061e-01,  2.0627e-01,  2.0179e-01],
          [-6.5963e-04,  3.2745e-01,  1.9600e-01],
          [ 2.1326e-01, -8.5299e-02,  1.1901e-01]],

         [[-1.9040e-01, -3.0484e-02, -4.8681e-02],
          [-2.5205e-01, -6.9669e-02, -6.7369e-02],
          [-1.7528e-01, -6.0880e-02, -1.4477e-01]]],


        [[[-3.6252e-41, -5.6405e-41,  1.5148e-41],
          [ 6.5791e-42, -6.1193e-41,  3.8782e-41],
          [ 3.9320e-41, -3.0869e-41,  1.9101e-41]],

         [[-2.4565e-41, -1.9932e-41,  3.9667e-41],
          [-2.0743e-41,  1.9980e-41, -3.9692e-41],
          [ 2.6975e-42, -1.6015e-41,  2.0564e-41]],

         [[ 1.2197e-41,  3.0166e-41,  1.1793e-41],
          [-2.8512e-41,  2.6294e-41,  5.6730e-41],
          [ 4.8387e-42, -6.2646e-41, -6.6738e-41]]],


        [[[ 5.8740e-02,  1.2918e-01, -8.1862e-02],
          [ 4.2595e-02,  2.0215e-01, -9.6426e-02],
          [ 1.1769e-01,  2.9726e-01,  2.6320e-01]],

         [[-1.9558e-01, -2.8478e-02, -1.6824e-01],
          [-2.7984e-01, -2.1015e-01, -2.3388e-01],
          [-2.3022e-01, -3.3940e-01,  2.8200e-02]],

         [[ 1.9617e-01,  6.2961e-02,  1.8774e-01],
          [ 1.8825e-01,  9.8226e-02,  4.5511e-02],
          [-6.1393e-05,  1.0481e-01,  5.2660e-02]]],


        ...,


        [[[ 2.7166e-01,  3.9990e-02, -6.6681e-04],
          [ 2.0752e-01, -2.5307e-01, -8.1959e-02],
          [-6.7420e-02, -1.7474e-01, -1.2860e-01]],

         [[-1.1419e-01, -4.7714e-02, -5.2895e-02],
          [-1.9364e-01, -2.5223e-01,  1.4812e-01],
          [-1.6307e-02,  2.8560e-01,  2.7767e-01]],

         [[-1.1997e-02, -3.1192e-02,  2.0114e-01],
          [ 1.7396e-02, -2.6158e-01, -1.4078e-01],
          [ 3.1048e-02, -5.3872e-02, -8.5227e-02]]],


        [[[ 9.3453e-02,  1.0970e-01,  2.4842e-01],
          [ 1.6958e-01,  1.6857e-01, -1.0077e-02],
          [-2.7051e-01, -1.7590e-01, -8.2922e-02]],

         [[ 5.0956e-02,  1.0707e-02, -1.7290e-01],
          [ 3.3357e-02, -6.7955e-02, -3.2759e-01],
          [-4.3561e-03,  1.3607e-01, -2.3777e-02]],

         [[-2.2950e-01, -9.5449e-02, -2.6273e-01],
          [-1.0813e-01,  7.3300e-02,  3.8553e-02],
          [ 1.5621e-01,  2.1231e-01,  1.6418e-01]]],


        [[[ 7.5524e-41,  2.4569e-40,  4.8293e-40],
          [ 1.4398e-40,  6.7178e-42, -2.1662e-40],
          [-6.6588e-41, -3.5199e-41,  1.4272e-40]],

         [[ 3.1650e-40, -2.5649e-40,  4.5461e-40],
          [ 3.8910e-41, -1.3314e-40, -2.0213e-40],
          [ 2.9505e-40, -4.3412e-40,  1.3663e-40]],

         [[-2.5934e-40,  1.7117e-40,  2.9077e-40],
          [ 1.6959e-40,  4.9235e-40,  3.5111e-41],
          [ 3.8377e-41, -3.5576e-40, -5.0797e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2965]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0004]], device='cuda:0')

Epoch: 63 | Batch_idx: 0 |  Loss: (0.2615) | Acc: (89.00%) (115/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.2417) | Acc: (92.00%) (1298/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.2262) | Acc: (92.00%) (2487/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.2292) | Acc: (92.00%) (3669/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.2218) | Acc: (92.00%) (4866/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.2188) | Acc: (92.00%) (6066/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.2138) | Acc: (93.00%) (7269/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.2171) | Acc: (92.00%) (8440/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.2135) | Acc: (93.00%) (9643/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.2137) | Acc: (92.00%) (10827/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.2122) | Acc: (92.00%) (12022/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.2131) | Acc: (92.00%) (13197/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.2127) | Acc: (92.00%) (14390/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.2133) | Acc: (92.00%) (15569/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.2148) | Acc: (92.00%) (16747/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.2153) | Acc: (92.00%) (17940/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.2152) | Acc: (92.00%) (19127/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.2162) | Acc: (92.00%) (20307/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.2146) | Acc: (92.00%) (21502/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.2142) | Acc: (92.00%) (22689/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.2155) | Acc: (92.00%) (23860/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.2154) | Acc: (92.00%) (25044/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.2146) | Acc: (92.00%) (26239/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.2150) | Acc: (92.00%) (27417/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.2146) | Acc: (92.00%) (28610/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.2146) | Acc: (92.00%) (29791/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.2145) | Acc: (92.00%) (30982/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.2133) | Acc: (92.00%) (32180/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.2139) | Acc: (92.00%) (33367/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.2153) | Acc: (92.00%) (34541/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.2157) | Acc: (92.00%) (35719/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.2148) | Acc: (92.00%) (36913/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.2149) | Acc: (92.00%) (38101/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.2149) | Acc: (92.00%) (39286/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.2159) | Acc: (92.00%) (40458/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.2155) | Acc: (92.00%) (41656/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.2157) | Acc: (92.00%) (42840/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.2156) | Acc: (92.00%) (44023/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.2158) | Acc: (92.00%) (45216/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.2155) | Acc: (92.00%) (46359/50000)
# TEST : Loss: (0.3204) | Acc: (89.00%) (8983/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.6748e-01, -2.3586e-01,  5.3228e-02],
          [-7.6440e-02,  2.8497e-01,  1.9413e-01],
          [ 1.1243e-01,  1.3248e-02, -9.2803e-02]],

         [[-2.2971e-01,  2.0542e-01,  2.0091e-01],
          [-6.5697e-04,  3.2604e-01,  1.9513e-01],
          [ 2.1240e-01, -8.4932e-02,  1.1850e-01]],

         [[-1.8958e-01, -3.0353e-02, -4.8476e-02],
          [-2.5095e-01, -6.9366e-02, -6.7086e-02],
          [-1.7452e-01, -6.0616e-02, -1.4417e-01]]],


        [[[ 6.2908e-41,  5.8689e-41,  4.9593e-41],
          [ 2.9179e-41,  5.8789e-41, -3.9646e-41],
          [ 1.9835e-41,  2.1018e-41,  6.7746e-41]],

         [[ 1.1346e-41,  3.5559e-41, -2.7732e-42],
          [-1.8543e-41, -1.5770e-41,  5.9090e-41],
          [-5.0871e-41,  2.8536e-41,  6.8156e-41]],

         [[-5.9073e-41, -4.8049e-41,  3.5943e-42],
          [ 1.7145e-41,  3.2900e-41, -4.4159e-41],
          [-1.0243e-42,  3.1266e-41, -4.2887e-41]]],


        [[[ 5.8648e-02,  1.2898e-01, -8.1737e-02],
          [ 4.2528e-02,  2.0184e-01, -9.6279e-02],
          [ 1.1751e-01,  2.9680e-01,  2.6279e-01]],

         [[-1.9524e-01, -2.8430e-02, -1.6796e-01],
          [-2.7935e-01, -2.0979e-01, -2.3348e-01],
          [-2.2982e-01, -3.3881e-01,  2.8151e-02]],

         [[ 1.9581e-01,  6.2848e-02,  1.8740e-01],
          [ 1.8790e-01,  9.8045e-02,  4.5428e-02],
          [-6.1279e-05,  1.0462e-01,  5.2564e-02]]],


        ...,


        [[[ 2.6975e-01,  3.9689e-02, -6.6197e-04],
          [ 2.0588e-01, -2.5078e-01, -8.1312e-02],
          [-6.6908e-02, -1.7337e-01, -1.2767e-01]],

         [[-1.1333e-01, -4.7329e-02, -5.2493e-02],
          [-1.9196e-01, -2.4976e-01,  1.4690e-01],
          [-1.6177e-02,  2.8329e-01,  2.7560e-01]],

         [[-1.1896e-02, -3.0901e-02,  1.9943e-01],
          [ 1.7220e-02, -2.5833e-01, -1.3940e-01],
          [ 3.0765e-02, -5.3353e-02, -8.4503e-02]]],


        [[[ 9.3046e-02,  1.0924e-01,  2.4744e-01],
          [ 1.6882e-01,  1.6784e-01, -1.0036e-02],
          [-2.6930e-01, -1.7515e-01, -8.2582e-02]],

         [[ 5.0722e-02,  1.0658e-02, -1.7210e-01],
          [ 3.3204e-02, -6.7647e-02, -3.2607e-01],
          [-4.3363e-03,  1.3547e-01, -2.3671e-02]],

         [[-2.2838e-01, -9.4980e-02, -2.6135e-01],
          [-1.0762e-01,  7.2954e-02,  3.8361e-02],
          [ 1.5550e-01,  2.1134e-01,  1.6342e-01]]],


        [[[-3.2308e-41,  2.5857e-40,  3.1382e-40],
          [ 3.7356e-40,  1.1152e-40, -3.6711e-41],
          [-2.9243e-40, -2.4661e-40,  5.4295e-41]],

         [[ 2.2264e-40,  6.1444e-41,  5.0085e-41],
          [ 1.4818e-40, -2.4861e-40,  2.0558e-40],
          [-3.4791e-40, -1.2910e-40, -6.5727e-41]],

         [[-1.6884e-40, -3.1236e-41,  3.0625e-40],
          [ 1.7891e-40,  3.0780e-40, -6.7288e-41],
          [ 1.4554e-40,  3.6548e-40,  9.8927e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2967]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0046]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 64 | Batch_idx: 0 |  Loss: (0.1914) | Acc: (93.00%) (120/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.2144) | Acc: (93.00%) (1310/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.2250) | Acc: (92.00%) (2475/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.2443) | Acc: (91.00%) (3635/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.2536) | Acc: (91.00%) (4788/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.2695) | Acc: (90.00%) (5926/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.2813) | Acc: (90.00%) (7042/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.2911) | Acc: (89.00%) (8168/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.2963) | Acc: (89.00%) (9295/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.2973) | Acc: (89.00%) (10436/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3040) | Acc: (89.00%) (11558/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3023) | Acc: (89.00%) (12712/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3044) | Acc: (89.00%) (13851/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3022) | Acc: (89.00%) (15013/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3013) | Acc: (89.00%) (16173/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.2996) | Acc: (89.00%) (17332/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.2993) | Acc: (89.00%) (18473/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3000) | Acc: (89.00%) (19619/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.2981) | Acc: (89.00%) (20783/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.2955) | Acc: (89.00%) (21951/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.2945) | Acc: (89.00%) (23116/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.2924) | Acc: (89.00%) (24290/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.2913) | Acc: (89.00%) (25449/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.2921) | Acc: (89.00%) (26600/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.2920) | Acc: (89.00%) (27751/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.2938) | Acc: (89.00%) (28886/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.2931) | Acc: (89.00%) (30032/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.2939) | Acc: (89.00%) (31172/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.2933) | Acc: (89.00%) (32330/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.2949) | Acc: (89.00%) (33454/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.2946) | Acc: (89.00%) (34625/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.2953) | Acc: (89.00%) (35764/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.2947) | Acc: (89.00%) (36930/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.2947) | Acc: (89.00%) (38072/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.2939) | Acc: (89.00%) (39240/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.2930) | Acc: (89.00%) (40400/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.2930) | Acc: (89.00%) (41553/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.2926) | Acc: (89.00%) (42718/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.2935) | Acc: (89.00%) (43859/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.2935) | Acc: (89.00%) (44983/50000)
# TEST : Loss: (0.3910) | Acc: (87.00%) (8780/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7193e-01, -2.3419e-01,  6.1083e-02],
          [-7.3049e-02,  2.9161e-01,  2.0887e-01],
          [ 1.1133e-01,  1.6446e-02, -8.1274e-02]],

         [[-2.2943e-01,  2.1226e-01,  2.1057e-01],
          [ 6.7226e-03,  3.3970e-01,  2.1314e-01],
          [ 2.1511e-01, -7.4337e-02,  1.3110e-01]],

         [[-1.8713e-01, -2.2073e-02, -3.2028e-02],
          [-2.4601e-01, -6.3473e-02, -5.0903e-02],
          [-1.7113e-01, -5.5318e-02, -1.3044e-01]]],


        [[[ 4.5266e-41,  5.6865e-41,  6.0805e-41],
          [ 3.8773e-41,  1.8333e-41,  5.1259e-42],
          [ 5.4054e-41,  4.9743e-41, -5.6725e-41]],

         [[ 3.8146e-41,  5.6746e-41,  2.1300e-43],
          [-1.2620e-41,  3.4309e-41,  2.7946e-41],
          [-6.5135e-41,  6.8949e-41, -6.8948e-41]],

         [[ 2.8923e-42,  7.1260e-41,  5.7404e-41],
          [-3.2210e-41,  9.0846e-42,  5.4024e-41],
          [-2.5494e-41, -7.1683e-41,  5.9594e-41]]],


        [[[ 5.7054e-02,  1.2836e-01, -8.6094e-02],
          [ 3.5858e-02,  1.9653e-01, -1.0437e-01],
          [ 1.1933e-01,  3.0082e-01,  2.6139e-01]],

         [[-2.0049e-01, -3.1341e-02, -1.7408e-01],
          [-2.9356e-01, -2.2500e-01, -2.4997e-01],
          [-2.3338e-01, -3.4482e-01,  1.5637e-02]],

         [[ 1.9116e-01,  6.0336e-02,  1.7693e-01],
          [ 1.7779e-01,  8.7517e-02,  3.1263e-02],
          [ 2.1300e-03,  1.0251e-01,  3.9924e-02]]],


        ...,


        [[[ 2.5911e-01,  2.7496e-02,  1.2777e-04],
          [ 2.1319e-01, -2.4881e-01, -8.0638e-02],
          [-5.4058e-02, -1.6645e-01, -1.2285e-01]],

         [[-1.2850e-01, -6.5267e-02, -5.2159e-02],
          [-1.9194e-01, -2.5446e-01,  1.4195e-01],
          [-9.4887e-03,  2.8017e-01,  2.7156e-01]],

         [[-2.8555e-02, -5.0553e-02,  1.9566e-01],
          [ 1.2732e-02, -2.7024e-01, -1.5076e-01],
          [ 3.3861e-02, -6.2828e-02, -9.5364e-02]]],


        [[[ 9.6587e-02,  1.1236e-01,  2.4409e-01],
          [ 1.6551e-01,  1.5595e-01, -2.7067e-02],
          [-2.7567e-01, -1.8503e-01, -9.7660e-02]],

         [[ 6.7795e-02,  2.4057e-02, -1.7190e-01],
          [ 3.6960e-02, -7.1667e-02, -3.4135e-01],
          [-7.9837e-03,  1.2875e-01, -3.7447e-02]],

         [[-2.1545e-01, -7.8708e-02, -2.5278e-01],
          [-1.0428e-01,  8.0722e-02,  3.6116e-02],
          [ 1.5836e-01,  2.2265e-01,  1.6853e-01]]],


        [[[-1.4883e-40,  4.8465e-41, -8.8125e-41],
          [-7.7521e-41,  1.1642e-40,  3.7411e-40],
          [ 3.9070e-40, -2.5863e-40, -4.5953e-41]],

         [[-3.3706e-40,  4.0580e-40, -5.0468e-40],
          [ 1.5262e-40, -1.4536e-40, -4.4856e-42],
          [ 3.2068e-40,  3.1833e-40,  3.8970e-41]],

         [[ 4.2283e-41, -2.5389e-40,  1.0078e-40],
          [ 7.7682e-41, -1.1906e-40,  3.6620e-40],
          [-6.8807e-41, -5.9667e-41,  1.0390e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0129,  0.0186,  0.0166],
          [ 0.0078,  0.0156,  0.0150],
          [-0.0001,  0.0134,  0.0097]],

         [[ 0.0106,  0.0157,  0.0126],
          [ 0.0033,  0.0112,  0.0086],
          [-0.0038,  0.0087,  0.0029]],

         [[ 0.0133,  0.0181,  0.0146],
          [ 0.0076,  0.0146,  0.0117],
          [ 0.0034,  0.0127,  0.0083]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0207,  0.0122, -0.0163],
          [ 0.0209,  0.0026, -0.0001],
          [ 0.0036, -0.0030,  0.0103]],

         [[-0.0011, -0.0174, -0.0429],
          [ 0.0093, -0.0123, -0.0166],
          [-0.0084, -0.0156, -0.0060]],

         [[-0.0175, -0.0323, -0.0562],
          [-0.0152, -0.0351, -0.0380],
          [-0.0344, -0.0388, -0.0231]]],


        ...,


        [[[ 0.0094,  0.0085,  0.0021],
          [ 0.0047,  0.0024, -0.0039],
          [ 0.0013, -0.0024, -0.0058]],

         [[ 0.0043,  0.0044, -0.0003],
          [ 0.0006, -0.0005, -0.0059],
          [-0.0016, -0.0047, -0.0081]],

         [[ 0.0034,  0.0043,  0.0007],
          [ 0.0009,  0.0006, -0.0031],
          [-0.0010, -0.0028, -0.0051]]],


        [[[ 0.0112,  0.0113,  0.0086],
          [ 0.0111,  0.0117,  0.0151],
          [-0.0033,  0.0008,  0.0061]],

         [[ 0.0075,  0.0057,  0.0038],
          [ 0.0059,  0.0068,  0.0131],
          [-0.0075, -0.0020,  0.0056]],

         [[ 0.0024,  0.0001, -0.0017],
          [ 0.0014,  0.0009,  0.0071],
          [-0.0113, -0.0069,  0.0030]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2961]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 65 | Batch_idx: 0 |  Loss: (0.2692) | Acc: (90.00%) (116/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.2305) | Acc: (92.00%) (1303/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.2293) | Acc: (92.00%) (2491/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.2276) | Acc: (92.00%) (3676/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.2265) | Acc: (92.00%) (4861/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.2289) | Acc: (92.00%) (6042/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.2274) | Acc: (92.00%) (7223/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.2280) | Acc: (92.00%) (8411/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.2256) | Acc: (92.00%) (9603/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.2289) | Acc: (92.00%) (10769/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.2292) | Acc: (92.00%) (11947/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.2307) | Acc: (92.00%) (13111/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.2309) | Acc: (92.00%) (14279/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.2333) | Acc: (92.00%) (15448/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.2337) | Acc: (92.00%) (16628/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.2340) | Acc: (92.00%) (17799/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.2367) | Acc: (91.00%) (18951/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.2387) | Acc: (91.00%) (20108/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.2393) | Acc: (91.00%) (21265/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.2388) | Acc: (91.00%) (22441/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.2392) | Acc: (91.00%) (23616/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.2392) | Acc: (91.00%) (24774/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.2410) | Acc: (91.00%) (25935/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.2418) | Acc: (91.00%) (27106/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.2420) | Acc: (91.00%) (28277/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.2431) | Acc: (91.00%) (29437/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.2442) | Acc: (91.00%) (30600/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.2435) | Acc: (91.00%) (31787/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.2428) | Acc: (91.00%) (32965/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.2443) | Acc: (91.00%) (34129/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.2437) | Acc: (91.00%) (35317/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.2444) | Acc: (91.00%) (36479/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.2443) | Acc: (91.00%) (37671/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.2445) | Acc: (91.00%) (38840/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.2443) | Acc: (91.00%) (40007/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.2442) | Acc: (91.00%) (41192/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.2442) | Acc: (91.00%) (42371/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.2434) | Acc: (91.00%) (43549/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.2426) | Acc: (91.00%) (44733/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.2418) | Acc: (91.00%) (45871/50000)
# TEST : Loss: (0.3240) | Acc: (89.00%) (8977/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8556e-01, -2.4135e-01,  5.4030e-02],
          [-8.7272e-02,  2.8706e-01,  2.0519e-01],
          [ 1.0616e-01,  1.7774e-02, -8.2667e-02]],

         [[-2.3866e-01,  2.0819e-01,  2.0452e-01],
          [-4.4714e-03,  3.3656e-01,  2.0932e-01],
          [ 2.0955e-01, -7.3903e-02,  1.2788e-01]],

         [[-1.9644e-01, -2.7189e-02, -4.1503e-02],
          [-2.5694e-01, -7.0127e-02, -5.9455e-02],
          [-1.7632e-01, -5.7946e-02, -1.3335e-01]]],


        [[[ 3.0593e-41,  3.5450e-41, -7.0844e-41],
          [ 1.5015e-41,  6.8613e-41, -4.1334e-41],
          [-3.7252e-41, -2.0163e-41, -3.0677e-41]],

         [[-3.4099e-41,  6.0539e-41,  5.8251e-41],
          [-3.2565e-41, -6.1699e-42,  6.4820e-41],
          [ 2.5990e-41,  5.0391e-41, -1.8370e-41]],

         [[ 1.6811e-41,  5.2865e-41,  3.0760e-41],
          [ 8.4793e-42, -2.0745e-41,  6.8872e-41],
          [ 4.1226e-41, -5.7341e-41, -5.3081e-42]]],


        [[[ 5.5484e-02,  1.3174e-01, -8.5606e-02],
          [ 3.4035e-02,  2.0330e-01, -9.6782e-02],
          [ 1.1545e-01,  3.0194e-01,  2.6433e-01]],

         [[-1.9931e-01, -2.8856e-02, -1.7451e-01],
          [-2.9681e-01, -2.2444e-01, -2.4506e-01],
          [-2.3928e-01, -3.4797e-01,  1.7878e-02]],

         [[ 1.9558e-01,  7.0563e-02,  1.7853e-01],
          [ 1.7676e-01,  9.3887e-02,  3.7058e-02],
          [-2.7165e-03,  1.0244e-01,  4.1263e-02]]],


        ...,


        [[[ 2.8192e-01,  4.0663e-02,  1.1369e-02],
          [ 2.3566e-01, -2.2596e-01, -6.2206e-02],
          [-2.7155e-02, -1.4034e-01, -1.0420e-01]],

         [[-1.2206e-01, -6.2902e-02, -4.6857e-02],
          [-1.8835e-01, -2.4985e-01,  1.4713e-01],
          [ 3.1573e-04,  2.8900e-01,  2.7874e-01]],

         [[-2.8140e-02, -5.4608e-02,  1.9565e-01],
          [ 7.2292e-03, -2.6739e-01, -1.4088e-01],
          [ 3.3578e-02, -5.6599e-02, -8.7263e-02]]],


        [[[ 9.0598e-02,  1.1392e-01,  2.6245e-01],
          [ 1.6645e-01,  1.6366e-01, -1.0465e-02],
          [-2.8106e-01, -1.8024e-01, -8.4545e-02]],

         [[ 6.3211e-02,  2.0579e-02, -1.5751e-01],
          [ 3.5686e-02, -6.7836e-02, -3.2647e-01],
          [-1.2680e-02,  1.3672e-01, -2.1901e-02]],

         [[-2.2166e-01, -8.1971e-02, -2.3529e-01],
          [-1.0299e-01,  8.9292e-02,  5.6679e-02],
          [ 1.6160e-01,  2.4019e-01,  1.8998e-01]]],


        [[[-1.5241e-40, -1.8001e-40, -4.2179e-40],
          [-4.3938e-40,  6.6954e-42,  5.0182e-40],
          [-1.9356e-40, -4.1624e-41, -1.5665e-40]],

         [[ 3.5832e-40, -1.6982e-40, -5.2348e-40],
          [ 3.8890e-41,  8.4490e-41, -2.3308e-40],
          [ 3.3150e-40,  3.2946e-40,  1.5298e-40]],

         [[ 2.7195e-40, -2.6446e-40, -3.5238e-40],
          [-1.4733e-40, -4.6768e-40, -3.0005e-40],
          [-1.8655e-40, -2.9156e-40, -5.1091e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0296,  0.0266,  0.0235],
          [ 0.0132,  0.0130,  0.0118],
          [-0.0111, -0.0147, -0.0114]],

         [[ 0.0336,  0.0309,  0.0371],
          [ 0.0188,  0.0208,  0.0303],
          [-0.0013,  0.0015,  0.0147]],

         [[ 0.0246,  0.0205,  0.0312],
          [ 0.0128,  0.0151,  0.0275],
          [ 0.0005,  0.0017,  0.0143]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0272, -0.0333, -0.0303],
          [-0.0358, -0.0385, -0.0447],
          [-0.0668, -0.0648, -0.0643]],

         [[-0.0428, -0.0650, -0.0612],
          [-0.0480, -0.0680, -0.0783],
          [-0.0839, -0.0914, -0.0967]],

         [[-0.0547, -0.0835, -0.0775],
          [-0.0670, -0.0858, -0.0915],
          [-0.0983, -0.1040, -0.1037]]],


        ...,


        [[[ 0.0196,  0.0086,  0.0078],
          [ 0.0094,  0.0080,  0.0142],
          [ 0.0063,  0.0129,  0.0207]],

         [[ 0.0210,  0.0097,  0.0098],
          [ 0.0186,  0.0153,  0.0199],
          [ 0.0203,  0.0225,  0.0262]],

         [[ 0.0144,  0.0056,  0.0051],
          [ 0.0165,  0.0125,  0.0148],
          [ 0.0190,  0.0190,  0.0213]]],


        [[[ 0.0119,  0.0218,  0.0311],
          [ 0.0011,  0.0099,  0.0237],
          [-0.0045,  0.0021,  0.0195]],

         [[ 0.0085,  0.0096,  0.0146],
          [-0.0060, -0.0008,  0.0126],
          [-0.0149, -0.0070,  0.0058]],

         [[ 0.0060,  0.0083,  0.0132],
          [-0.0047,  0.0019,  0.0121],
          [-0.0125, -0.0044,  0.0055]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2952]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 66 | Batch_idx: 0 |  Loss: (0.1519) | Acc: (94.00%) (121/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.2295) | Acc: (91.00%) (1291/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.2489) | Acc: (91.00%) (2458/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.2728) | Acc: (90.00%) (3607/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.2780) | Acc: (90.00%) (4752/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.2708) | Acc: (90.00%) (5932/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.2702) | Acc: (90.00%) (7098/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.2713) | Acc: (90.00%) (8258/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.2721) | Acc: (90.00%) (9413/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.2705) | Acc: (90.00%) (10585/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.2690) | Acc: (90.00%) (11755/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.2686) | Acc: (90.00%) (12923/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.2671) | Acc: (90.00%) (14091/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.2672) | Acc: (90.00%) (15257/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.2648) | Acc: (91.00%) (16432/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.2618) | Acc: (91.00%) (17620/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.2598) | Acc: (91.00%) (18801/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.2581) | Acc: (91.00%) (19978/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.2578) | Acc: (91.00%) (21154/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.2574) | Acc: (91.00%) (22326/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.2569) | Acc: (91.00%) (23496/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.2564) | Acc: (91.00%) (24665/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.2535) | Acc: (91.00%) (25867/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.2543) | Acc: (91.00%) (27040/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.2528) | Acc: (91.00%) (28231/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.2526) | Acc: (91.00%) (29409/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.2523) | Acc: (91.00%) (30586/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.2513) | Acc: (91.00%) (31776/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.2510) | Acc: (91.00%) (32947/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.2501) | Acc: (91.00%) (34128/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.2484) | Acc: (91.00%) (35314/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.2480) | Acc: (91.00%) (36487/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.2474) | Acc: (91.00%) (37675/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.2465) | Acc: (91.00%) (38853/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.2462) | Acc: (91.00%) (40027/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.2451) | Acc: (91.00%) (41229/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.2448) | Acc: (91.00%) (42400/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.2438) | Acc: (91.00%) (43587/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.2432) | Acc: (91.00%) (44775/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.2425) | Acc: (91.00%) (45912/50000)
# TEST : Loss: (0.3137) | Acc: (89.00%) (8991/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8848e-01, -2.4372e-01,  5.0712e-02],
          [-8.8267e-02,  2.8494e-01,  2.0288e-01],
          [ 1.0683e-01,  1.9119e-02, -8.1522e-02]],

         [[-2.4152e-01,  2.0410e-01,  1.9984e-01],
          [-5.6205e-03,  3.3362e-01,  2.0525e-01],
          [ 2.0972e-01, -7.3654e-02,  1.2561e-01]],

         [[-1.9838e-01, -2.9181e-02, -4.4589e-02],
          [-2.5649e-01, -7.0727e-02, -6.2096e-02],
          [-1.7483e-01, -5.7333e-02, -1.3467e-01]]],


        [[[-4.4711e-41, -7.3425e-41,  2.2398e-41],
          [-2.6316e-42, -1.8940e-41,  1.4363e-42],
          [ 7.1604e-41, -4.6103e-42, -8.6110e-42]],

         [[-1.0131e-42, -4.7781e-41, -2.9245e-41],
          [ 3.0952e-41, -6.0657e-41, -5.7551e-42],
          [-6.6564e-41, -5.7582e-41, -5.1414e-42]],

         [[-3.9718e-41,  6.8556e-41, -7.2231e-41],
          [ 4.2434e-41,  2.6414e-42,  2.4939e-41],
          [-1.1107e-41, -6.8560e-41, -5.8797e-41]]],


        [[[ 5.7541e-02,  1.3462e-01, -8.2295e-02],
          [ 3.6379e-02,  2.0636e-01, -9.2811e-02],
          [ 1.1795e-01,  3.0455e-01,  2.6729e-01]],

         [[-1.9724e-01, -2.4904e-02, -1.6966e-01],
          [-2.9443e-01, -2.2014e-01, -2.3930e-01],
          [-2.3616e-01, -3.4384e-01,  2.2464e-02]],

         [[ 1.9693e-01,  7.4712e-02,  1.8348e-01],
          [ 1.7849e-01,  9.8064e-02,  4.3056e-02],
          [ 2.5733e-04,  1.0618e-01,  4.6243e-02]]],


        ...,


        [[[ 2.7783e-01,  3.7749e-02,  7.5914e-03],
          [ 2.3333e-01, -2.2519e-01, -6.6809e-02],
          [-2.5627e-02, -1.4101e-01, -1.0821e-01]],

         [[-1.2507e-01, -6.7214e-02, -5.2414e-02],
          [-1.8953e-01, -2.5179e-01,  1.3748e-01],
          [-1.4946e-03,  2.8212e-01,  2.6951e-01]],

         [[-3.1209e-02, -5.8511e-02,  1.8848e-01],
          [ 3.1998e-03, -2.6886e-01, -1.4674e-01],
          [ 3.0332e-02, -6.0719e-02, -9.2731e-02]]],


        [[[ 8.6677e-02,  1.0947e-01,  2.5852e-01],
          [ 1.6407e-01,  1.6111e-01, -1.2118e-02],
          [-2.8112e-01, -1.8071e-01, -8.5390e-02]],

         [[ 6.1644e-02,  1.8774e-02, -1.5851e-01],
          [ 3.5787e-02, -6.7728e-02, -3.2591e-01],
          [-1.1710e-02,  1.3682e-01, -2.1338e-02]],

         [[-2.2251e-01, -8.3841e-02, -2.3578e-01],
          [-1.0242e-01,  8.8512e-02,  5.5891e-02],
          [ 1.6235e-01,  2.3985e-01,  1.9010e-01]]],


        [[[-3.2280e-41, -3.0485e-40, -5.5275e-40],
          [-4.5077e-40, -1.1132e-40,  7.3397e-41],
          [-1.9878e-40,  1.9235e-40, -1.6353e-40]],

         [[ 2.4741e-40, -1.7467e-40, -1.8236e-40],
          [-8.2217e-41, -1.5408e-40, -2.4081e-40],
          [ 9.8538e-41,  5.7997e-40,  1.5688e-40]],

         [[ 2.8150e-40, -3.6871e-41, -2.4686e-40],
          [-2.7032e-40,  3.4514e-40,  4.2210e-41],
          [-1.9314e-40,  4.1065e-40, -1.2256e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2668]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0436]], device='cuda:0')

Epoch: 67 | Batch_idx: 0 |  Loss: (0.1991) | Acc: (93.00%) (120/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.2190) | Acc: (92.00%) (1305/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.2136) | Acc: (92.00%) (2491/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.2148) | Acc: (92.00%) (3671/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.2090) | Acc: (92.00%) (4853/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.2173) | Acc: (92.00%) (6025/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.2190) | Acc: (92.00%) (7212/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.2168) | Acc: (92.00%) (8405/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.2183) | Acc: (92.00%) (9588/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.2157) | Acc: (92.00%) (10784/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.2159) | Acc: (92.00%) (11957/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.2166) | Acc: (92.00%) (13141/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.2185) | Acc: (92.00%) (14321/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.2178) | Acc: (92.00%) (15511/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.2185) | Acc: (92.00%) (16697/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.2162) | Acc: (92.00%) (17894/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.2168) | Acc: (92.00%) (19077/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.2168) | Acc: (92.00%) (20260/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.2161) | Acc: (92.00%) (21447/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.2152) | Acc: (92.00%) (22646/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.2153) | Acc: (92.00%) (23831/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.2140) | Acc: (92.00%) (25016/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.2136) | Acc: (92.00%) (26199/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.2133) | Acc: (92.00%) (27393/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.2130) | Acc: (92.00%) (28582/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.2139) | Acc: (92.00%) (29756/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.2136) | Acc: (92.00%) (30953/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.2150) | Acc: (92.00%) (32128/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.2159) | Acc: (92.00%) (33306/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.2161) | Acc: (92.00%) (34500/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.2163) | Acc: (92.00%) (35677/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.2167) | Acc: (92.00%) (36860/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.2168) | Acc: (92.00%) (38046/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.2167) | Acc: (92.00%) (39238/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.2166) | Acc: (92.00%) (40432/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.2170) | Acc: (92.00%) (41620/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.2166) | Acc: (92.00%) (42816/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.2159) | Acc: (92.00%) (44019/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.2163) | Acc: (92.00%) (45206/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.2165) | Acc: (92.00%) (46334/50000)
# TEST : Loss: (0.3031) | Acc: (90.00%) (9016/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8781e-01, -2.4278e-01,  5.0507e-02],
          [-8.7939e-02,  2.8379e-01,  2.0202e-01],
          [ 1.0644e-01,  1.9042e-02, -8.1183e-02]],

         [[-2.4061e-01,  2.0329e-01,  1.9901e-01],
          [-5.5987e-03,  3.3224e-01,  2.0437e-01],
          [ 2.0892e-01, -7.3352e-02,  1.2509e-01]],

         [[-1.9757e-01, -2.9061e-02, -4.4407e-02],
          [-2.5543e-01, -7.0436e-02, -6.1842e-02],
          [-1.7413e-01, -5.7097e-02, -1.3413e-01]]],


        [[[ 2.0211e-41,  6.4437e-41,  7.4883e-41],
          [-6.3255e-41,  1.4246e-41,  1.5018e-41],
          [ 3.2278e-41, -4.9732e-42, -1.7508e-41]],

         [[-2.5455e-41,  1.8222e-41, -3.4906e-41],
          [ 3.6965e-41,  7.6638e-41, -3.3364e-41],
          [ 2.1101e-41,  6.7418e-41,  6.4740e-43]],

         [[-6.1932e-41,  5.8070e-41,  5.1161e-41],
          [-7.1393e-41,  6.4004e-41, -5.6219e-41],
          [ 2.3434e-41,  1.7348e-42, -7.3030e-41]]],


        [[[ 5.7444e-02,  1.3439e-01, -8.2152e-02],
          [ 3.6318e-02,  2.0601e-01, -9.2650e-02],
          [ 1.1775e-01,  3.0404e-01,  2.6682e-01]],

         [[-1.9687e-01, -2.4857e-02, -1.6933e-01],
          [-2.9388e-01, -2.1973e-01, -2.3883e-01],
          [-2.3572e-01, -3.4321e-01,  2.2422e-02]],

         [[ 1.9655e-01,  7.4565e-02,  1.8311e-01],
          [ 1.7814e-01,  9.7867e-02,  4.2968e-02],
          [ 2.5683e-04,  1.0597e-01,  4.6151e-02]]],


        ...,


        [[[ 2.7528e-01,  3.7369e-02,  7.5187e-03],
          [ 2.3078e-01, -2.2214e-01, -6.6066e-02],
          [-2.5372e-02, -1.3950e-01, -1.0718e-01]],

         [[-1.2381e-01, -6.6457e-02, -5.1882e-02],
          [-1.8723e-01, -2.4795e-01,  1.3590e-01],
          [-1.4790e-03,  2.7900e-01,  2.6692e-01]],

         [[-3.0846e-02, -5.7734e-02,  1.8630e-01],
          [ 3.1536e-03, -2.6352e-01, -1.4470e-01],
          [ 2.9961e-02, -5.9915e-02, -9.1698e-02]]],


        [[[ 8.6278e-02,  1.0898e-01,  2.5742e-01],
          [ 1.6332e-01,  1.6038e-01, -1.2066e-02],
          [-2.7986e-01, -1.7991e-01, -8.5027e-02]],

         [[ 6.1351e-02,  1.8685e-02, -1.5775e-01],
          [ 3.5616e-02, -6.7408e-02, -3.2434e-01],
          [-1.1656e-02,  1.3619e-01, -2.1238e-02]],

         [[-2.2138e-01, -8.3409e-02, -2.3451e-01],
          [-1.0191e-01,  8.8072e-02,  5.5600e-02],
          [ 1.6157e-01,  2.3870e-01,  1.8917e-01]]],


        [[[ 9.3671e-41, -1.9112e-40, -5.7161e-40],
          [-8.3311e-41, -1.1471e-40, -3.9070e-40],
          [ 4.2372e-40,  3.1900e-40, -1.6872e-40]],

         [[-1.1921e-40,  4.4279e-40, -1.8759e-40],
          [-8.5212e-41,  9.0824e-41, -4.4575e-42],
          [ 3.4976e-40,  2.2312e-40,  3.8952e-41]],

         [[ 4.7376e-41,  2.0588e-40,  1.1067e-40],
          [ 8.6708e-41, -3.7590e-40,  2.8566e-40],
          [-7.7071e-41, -1.8783e-40, -1.2604e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2648]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0079]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 68 | Batch_idx: 0 |  Loss: (0.2232) | Acc: (92.00%) (119/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.2206) | Acc: (93.00%) (1310/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.2376) | Acc: (92.00%) (2475/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.2463) | Acc: (91.00%) (3647/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.2493) | Acc: (91.00%) (4808/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.2536) | Acc: (91.00%) (5966/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.2568) | Acc: (91.00%) (7133/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.2670) | Acc: (90.00%) (8270/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.2707) | Acc: (90.00%) (9420/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.2722) | Acc: (90.00%) (10587/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.2744) | Acc: (90.00%) (11739/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.2768) | Acc: (90.00%) (12886/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.2801) | Acc: (90.00%) (14036/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.2822) | Acc: (90.00%) (15179/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.2851) | Acc: (90.00%) (16319/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.2859) | Acc: (90.00%) (17466/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.2850) | Acc: (90.00%) (18630/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.2861) | Acc: (90.00%) (19777/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.2872) | Acc: (90.00%) (20922/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.2900) | Acc: (90.00%) (22051/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.2912) | Acc: (90.00%) (23188/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.2918) | Acc: (90.00%) (24332/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.2911) | Acc: (90.00%) (25487/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.2902) | Acc: (90.00%) (26634/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.2921) | Acc: (89.00%) (27753/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.2922) | Acc: (89.00%) (28908/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.2911) | Acc: (90.00%) (30072/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.2886) | Acc: (90.00%) (31251/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.2888) | Acc: (90.00%) (32407/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.2883) | Acc: (90.00%) (33573/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.2877) | Acc: (90.00%) (34728/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.2874) | Acc: (90.00%) (35893/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.2870) | Acc: (90.00%) (37068/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.2865) | Acc: (90.00%) (38231/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.2857) | Acc: (90.00%) (39400/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.2852) | Acc: (90.00%) (40572/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.2842) | Acc: (90.00%) (41748/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.2845) | Acc: (90.00%) (42895/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.2842) | Acc: (90.00%) (44054/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.2839) | Acc: (90.00%) (45174/50000)
# TEST : Loss: (0.4513) | Acc: (86.00%) (8643/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9039e-01, -2.3968e-01,  4.7726e-02],
          [-9.0440e-02,  2.9151e-01,  2.0918e-01],
          [ 1.0200e-01,  1.2930e-02, -8.2461e-02]],

         [[-2.3410e-01,  2.1580e-01,  2.0831e-01],
          [-1.1309e-03,  3.4699e-01,  2.1972e-01],
          [ 2.0932e-01, -6.9283e-02,  1.3439e-01]],

         [[-1.9412e-01, -2.0665e-02, -3.8192e-02],
          [-2.5064e-01, -5.8958e-02, -5.0472e-02],
          [-1.7181e-01, -5.6169e-02, -1.2644e-01]]],


        [[[ 3.9009e-41, -4.3868e-41,  6.7650e-41],
          [ 3.3497e-41, -2.8036e-41, -1.3193e-41],
          [-1.0556e-41,  3.8917e-41, -2.9768e-41]],

         [[ 5.9300e-41, -8.3195e-42,  5.2727e-41],
          [-6.5169e-41, -6.5651e-41,  5.3820e-41],
          [ 7.7713e-41, -1.9101e-41,  2.5976e-41]],

         [[ 4.5206e-41, -3.5565e-42, -4.6118e-41],
          [ 7.9482e-41,  6.1633e-41, -5.2409e-41],
          [-6.1967e-41, -5.8360e-41, -6.0284e-41]]],


        [[[ 4.4067e-02,  1.1231e-01, -8.9631e-02],
          [ 2.6476e-02,  1.9112e-01, -9.6068e-02],
          [ 1.0574e-01,  2.9449e-01,  2.7295e-01]],

         [[-2.0719e-01, -5.2190e-02, -1.8078e-01],
          [-3.0925e-01, -2.4393e-01, -2.4457e-01],
          [-2.5372e-01, -3.5954e-01,  2.7602e-02]],

         [[ 1.8838e-01,  5.6492e-02,  1.7509e-01],
          [ 1.6686e-01,  8.2624e-02,  3.8810e-02],
          [-1.8003e-02,  9.1327e-02,  4.6398e-02]]],


        ...,


        [[[ 2.7290e-01,  3.3156e-02,  6.4180e-03],
          [ 2.2991e-01, -2.2889e-01, -6.7858e-02],
          [-2.0936e-02, -1.4435e-01, -1.1981e-01]],

         [[-1.2682e-01, -7.8948e-02, -5.7602e-02],
          [-1.8414e-01, -2.5343e-01,  1.3370e-01],
          [ 6.4709e-03,  2.7605e-01,  2.5554e-01]],

         [[-3.7961e-02, -6.9444e-02,  1.7748e-01],
          [ 2.8785e-03, -2.6913e-01, -1.4164e-01],
          [ 3.4100e-02, -6.2197e-02, -9.9160e-02]]],


        [[[ 1.0153e-01,  1.2204e-01,  2.6039e-01],
          [ 1.7112e-01,  1.6849e-01, -6.3088e-03],
          [-2.8789e-01, -1.8232e-01, -8.6377e-02]],

         [[ 7.4847e-02,  2.6292e-02, -1.5813e-01],
          [ 3.8904e-02, -6.3110e-02, -3.1889e-01],
          [-1.7701e-02,  1.3873e-01, -1.8061e-02]],

         [[-2.2767e-01, -8.4864e-02, -2.3638e-01],
          [-1.1550e-01,  8.5773e-02,  6.1031e-02],
          [ 1.4629e-01,  2.3809e-01,  1.9114e-01]]],


        [[[ 9.5974e-41,  5.4480e-41,  5.0278e-40],
          [ 4.2764e-40,  6.7262e-42, -5.2300e-40],
          [ 3.0364e-40,  2.0246e-40, -5.1960e-41]],

         [[-3.7525e-40, -3.0918e-40,  4.3440e-40],
          [ 3.8887e-41,  2.1995e-40,  2.4450e-40],
          [ 1.0388e-40, -5.3027e-40, -8.5335e-41]],

         [[-1.9978e-40, -3.7716e-41,  3.6238e-40],
          [-1.5899e-40, -5.0968e-40, -4.5116e-40],
          [-7.9228e-41, -1.9248e-40, -5.1035e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0307, -0.0282, -0.0257],
          [-0.0319, -0.0275, -0.0276],
          [-0.0255, -0.0293, -0.0341]],

         [[-0.0176, -0.0201, -0.0203],
          [-0.0227, -0.0230, -0.0227],
          [-0.0207, -0.0272, -0.0280]],

         [[-0.0190, -0.0210, -0.0271],
          [-0.0253, -0.0251, -0.0282],
          [-0.0219, -0.0263, -0.0277]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0087, -0.0052, -0.0209],
          [ 0.0223,  0.0064, -0.0015],
          [ 0.0216,  0.0059, -0.0002]],

         [[-0.0001, -0.0072, -0.0210],
          [ 0.0092, -0.0018, -0.0114],
          [ 0.0029, -0.0063, -0.0139]],

         [[-0.0128, -0.0155, -0.0255],
          [-0.0087, -0.0129, -0.0189],
          [-0.0134, -0.0171, -0.0228]]],


        ...,


        [[[-0.0013, -0.0010, -0.0023],
          [-0.0041, -0.0005, -0.0028],
          [ 0.0016,  0.0038,  0.0000]],

         [[-0.0014,  0.0005,  0.0003],
          [-0.0030,  0.0006, -0.0018],
          [ 0.0034,  0.0037, -0.0007]],

         [[-0.0029, -0.0016, -0.0018],
          [-0.0030, -0.0001, -0.0028],
          [ 0.0029,  0.0028, -0.0023]]],


        [[[-0.0250, -0.0330, -0.0223],
          [-0.0176, -0.0276, -0.0161],
          [-0.0042, -0.0209, -0.0078]],

         [[-0.0381, -0.0468, -0.0264],
          [-0.0275, -0.0361, -0.0193],
          [-0.0126, -0.0248, -0.0108]],

         [[-0.0354, -0.0414, -0.0228],
          [-0.0227, -0.0273, -0.0125],
          [-0.0082, -0.0186, -0.0079]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2634]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 69 | Batch_idx: 0 |  Loss: (0.2406) | Acc: (89.00%) (115/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.2314) | Acc: (91.00%) (1291/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.2301) | Acc: (91.00%) (2470/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.2305) | Acc: (91.00%) (3650/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.2327) | Acc: (91.00%) (4822/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.2404) | Acc: (91.00%) (5984/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.2373) | Acc: (91.00%) (7166/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.2403) | Acc: (91.00%) (8327/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.2358) | Acc: (91.00%) (9522/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.2379) | Acc: (91.00%) (10699/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.2420) | Acc: (91.00%) (11842/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.2494) | Acc: (91.00%) (12982/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.2490) | Acc: (91.00%) (14153/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.2473) | Acc: (91.00%) (15343/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.2461) | Acc: (91.00%) (16520/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.2459) | Acc: (91.00%) (17684/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.2462) | Acc: (91.00%) (18844/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.2459) | Acc: (91.00%) (20012/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.2451) | Acc: (91.00%) (21188/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.2450) | Acc: (91.00%) (22369/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.2444) | Acc: (91.00%) (23545/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.2437) | Acc: (91.00%) (24724/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.2419) | Acc: (91.00%) (25913/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.2420) | Acc: (91.00%) (27073/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.2400) | Acc: (91.00%) (28264/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.2403) | Acc: (91.00%) (29439/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.2399) | Acc: (91.00%) (30620/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.2394) | Acc: (91.00%) (31797/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.2383) | Acc: (91.00%) (32976/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.2385) | Acc: (91.00%) (34147/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.2385) | Acc: (91.00%) (35326/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.2394) | Acc: (91.00%) (36490/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.2392) | Acc: (91.00%) (37672/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.2401) | Acc: (91.00%) (38828/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.2403) | Acc: (91.00%) (40001/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.2395) | Acc: (91.00%) (41185/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.2399) | Acc: (91.00%) (42352/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.2397) | Acc: (91.00%) (43525/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.2395) | Acc: (91.00%) (44705/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.2402) | Acc: (91.00%) (45821/50000)
# TEST : Loss: (0.3637) | Acc: (88.00%) (8845/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8885e-01, -2.4087e-01,  3.9507e-02],
          [-8.4290e-02,  2.9417e-01,  2.0601e-01],
          [ 1.0678e-01,  7.1353e-03, -8.9041e-02]],

         [[-2.4323e-01,  2.0514e-01,  1.8988e-01],
          [-3.9034e-03,  3.4330e-01,  2.0699e-01],
          [ 2.0417e-01, -8.0698e-02,  1.1721e-01]],

         [[-2.0651e-01, -3.7298e-02, -6.1561e-02],
          [-2.6252e-01, -7.3137e-02, -7.0455e-02],
          [-1.8416e-01, -7.2841e-02, -1.4614e-01]]],


        [[[-8.3716e-41,  3.9451e-41,  3.9156e-41],
          [ 4.0049e-41,  2.1314e-41,  2.1939e-41],
          [-5.5650e-41, -6.2547e-41, -5.5421e-42]],

         [[-7.8998e-41, -4.8168e-41,  4.5695e-41],
          [-2.5261e-41, -6.3276e-41, -8.1942e-41],
          [ 3.8101e-42,  2.8595e-41,  4.1577e-41]],

         [[ 5.5232e-41, -7.4475e-41, -1.3032e-43],
          [-4.6209e-41,  7.4548e-41,  4.3977e-41],
          [ 8.2955e-41, -4.5234e-42, -1.9618e-44]]],


        [[[ 4.9619e-02,  1.2058e-01, -8.2560e-02],
          [ 2.9264e-02,  1.9740e-01, -8.8909e-02],
          [ 1.0756e-01,  2.9791e-01,  2.7486e-01]],

         [[-2.0216e-01, -4.7811e-02, -1.7880e-01],
          [-3.0538e-01, -2.4240e-01, -2.4242e-01],
          [-2.4977e-01, -3.5949e-01,  2.6119e-02]],

         [[ 2.0035e-01,  6.7229e-02,  1.7904e-01],
          [ 1.8423e-01,  9.7160e-02,  4.7181e-02],
          [ 1.2438e-03,  1.0406e-01,  4.8950e-02]]],


        ...,


        [[[ 2.7645e-01,  5.0394e-02,  1.9186e-02],
          [ 2.5112e-01, -2.1145e-01, -6.2927e-02],
          [-4.7796e-03, -1.2954e-01, -1.2188e-01]],

         [[-1.3302e-01, -7.3273e-02, -5.3152e-02],
          [-1.7340e-01, -2.4908e-01,  1.2732e-01],
          [ 1.1710e-02,  2.8212e-01,  2.4814e-01]],

         [[-5.8140e-02, -7.3639e-02,  1.7427e-01],
          [-2.4758e-03, -2.7271e-01, -1.4875e-01],
          [ 2.8146e-02, -6.0545e-02, -1.0758e-01]]],


        [[[ 1.1031e-01,  1.3077e-01,  2.6725e-01],
          [ 1.6752e-01,  1.6584e-01, -8.9650e-03],
          [-2.9249e-01, -1.8405e-01, -8.7224e-02]],

         [[ 7.6963e-02,  2.3801e-02, -1.6103e-01],
          [ 2.8649e-02, -7.7837e-02, -3.3426e-01],
          [-3.1660e-02,  1.2415e-01, -3.1795e-02]],

         [[-2.2266e-01, -8.3620e-02, -2.2983e-01],
          [-1.1687e-01,  8.3678e-02,  6.0594e-02],
          [ 1.4447e-01,  2.3732e-01,  1.8905e-01]]],


        [[[-3.2285e-41,  3.1049e-40, -1.0533e-40],
          [ 5.6424e-40,  1.3363e-40, -1.6659e-40],
          [-8.1251e-41, -2.9976e-40,  7.1470e-41]],

         [[-2.5288e-40, -5.6363e-41, -3.2357e-40],
          [ 1.6777e-40,  9.5615e-41,  2.4952e-40],
          [-2.8079e-40, -4.1081e-40, -8.7880e-41]],

         [[ 3.0306e-40, -2.9207e-40,  2.4303e-40],
          [-2.8839e-40, -1.3824e-40, -2.0771e-40],
          [-2.0890e-40,  4.4013e-40,  1.2143e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0370, -0.0430, -0.0485],
          [-0.0307, -0.0401, -0.0454],
          [-0.0261, -0.0318, -0.0376]],

         [[-0.0397, -0.0436, -0.0489],
          [-0.0338, -0.0397, -0.0437],
          [-0.0279, -0.0284, -0.0310]],

         [[-0.0367, -0.0402, -0.0416],
          [-0.0364, -0.0418, -0.0397],
          [-0.0339, -0.0356, -0.0315]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0182, -0.0281, -0.0441],
          [-0.0132, -0.0356, -0.0587],
          [-0.0184, -0.0470, -0.0662]],

         [[-0.0249, -0.0298, -0.0394],
          [-0.0123, -0.0319, -0.0520],
          [-0.0150, -0.0452, -0.0656]],

         [[-0.0175, -0.0182, -0.0245],
          [-0.0029, -0.0194, -0.0382],
          [-0.0033, -0.0311, -0.0496]]],


        ...,


        [[[ 0.0105,  0.0057, -0.0004],
          [ 0.0110,  0.0074,  0.0022],
          [ 0.0107,  0.0074,  0.0087]],

         [[ 0.0068,  0.0029, -0.0030],
          [ 0.0062,  0.0035, -0.0011],
          [ 0.0056,  0.0028,  0.0038]],

         [[ 0.0027,  0.0013, -0.0024],
          [ 0.0013,  0.0009, -0.0017],
          [ 0.0011,  0.0004,  0.0024]]],


        [[[-0.0258, -0.0216, -0.0263],
          [-0.0270, -0.0230, -0.0285],
          [-0.0260, -0.0259, -0.0226]],

         [[-0.0176, -0.0125, -0.0183],
          [-0.0181, -0.0145, -0.0194],
          [-0.0206, -0.0214, -0.0169]],

         [[-0.0143, -0.0102, -0.0174],
          [-0.0123, -0.0085, -0.0156],
          [-0.0161, -0.0152, -0.0132]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2627]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 70 | Batch_idx: 0 |  Loss: (0.3198) | Acc: (89.00%) (115/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.2359) | Acc: (91.00%) (1288/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.2407) | Acc: (91.00%) (2460/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.2571) | Acc: (90.00%) (3609/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.2582) | Acc: (90.00%) (4775/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.2610) | Acc: (90.00%) (5935/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.2582) | Acc: (91.00%) (7116/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.2595) | Acc: (90.00%) (8270/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.2594) | Acc: (90.00%) (9432/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.2599) | Acc: (91.00%) (10602/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.2560) | Acc: (91.00%) (11787/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.2535) | Acc: (91.00%) (12961/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.2535) | Acc: (91.00%) (14125/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.2545) | Acc: (91.00%) (15289/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.2523) | Acc: (91.00%) (16468/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.2522) | Acc: (91.00%) (17638/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.2526) | Acc: (91.00%) (18811/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.2516) | Acc: (91.00%) (20003/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.2501) | Acc: (91.00%) (21187/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.2482) | Acc: (91.00%) (22374/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.2465) | Acc: (91.00%) (23559/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.2456) | Acc: (91.00%) (24736/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.2442) | Acc: (91.00%) (25931/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.2430) | Acc: (91.00%) (27116/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.2420) | Acc: (91.00%) (28299/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.2419) | Acc: (91.00%) (29470/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.2417) | Acc: (91.00%) (30638/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.2410) | Acc: (91.00%) (31820/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.2403) | Acc: (91.00%) (33004/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.2396) | Acc: (91.00%) (34188/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.2383) | Acc: (91.00%) (35387/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.2384) | Acc: (91.00%) (36563/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.2373) | Acc: (91.00%) (37766/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.2367) | Acc: (91.00%) (38946/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.2361) | Acc: (91.00%) (40144/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.2348) | Acc: (92.00%) (41339/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.2351) | Acc: (92.00%) (42514/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.2343) | Acc: (92.00%) (43697/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.2345) | Acc: (91.00%) (44861/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.2331) | Acc: (92.00%) (46014/50000)
# TEST : Loss: (0.3109) | Acc: (89.00%) (8975/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8462e-01, -2.3575e-01,  4.4561e-02],
          [-8.1831e-02,  2.9636e-01,  2.0973e-01],
          [ 1.0826e-01,  9.5783e-03, -8.5335e-02]],

         [[-2.3726e-01,  2.1026e-01,  1.9560e-01],
          [-5.7554e-05,  3.4655e-01,  2.1163e-01],
          [ 2.0708e-01, -7.6761e-02,  1.2084e-01]],

         [[-2.0097e-01, -3.2382e-02, -5.6772e-02],
          [-2.5793e-01, -6.9563e-02, -6.6829e-02],
          [-1.8001e-01, -6.9374e-02, -1.4297e-01]]],


        [[[ 8.2586e-41, -4.1854e-41, -4.6204e-41],
          [-7.7858e-41,  2.6371e-41, -7.8467e-41],
          [-4.6218e-41,  3.5282e-41,  7.6472e-41]],

         [[ 6.4960e-41,  6.7188e-41, -8.9469e-41],
          [ 7.4373e-41, -4.2766e-41, -2.0697e-42],
          [-7.7723e-41,  6.3434e-41,  9.3485e-41]],

         [[ 8.1640e-42, -2.0540e-41,  8.2860e-41],
          [-3.3662e-41,  5.4299e-41,  6.5113e-41],
          [-6.8994e-41, -4.9949e-41,  9.4379e-41]]],


        [[[ 5.0778e-02,  1.2301e-01, -7.9469e-02],
          [ 3.1465e-02,  2.0069e-01, -8.4603e-02],
          [ 1.0941e-01,  3.0079e-01,  2.7825e-01]],

         [[-2.0222e-01, -4.6736e-02, -1.7726e-01],
          [-3.0401e-01, -2.3952e-01, -2.3893e-01],
          [-2.4842e-01, -3.5634e-01,  2.9254e-02]],

         [[ 1.9831e-01,  6.6651e-02,  1.7866e-01],
          [ 1.8347e-01,  9.8266e-02,  4.8958e-02],
          [ 9.4666e-04,  1.0525e-01,  5.0540e-02]]],


        ...,


        [[[ 2.7734e-01,  5.5071e-02,  2.4854e-02],
          [ 2.5134e-01, -2.0536e-01, -5.7457e-02],
          [-2.5954e-03, -1.2485e-01, -1.1806e-01]],

         [[-1.2912e-01, -6.7756e-02, -4.7181e-02],
          [-1.6867e-01, -2.4135e-01,  1.3061e-01],
          [ 1.3919e-02,  2.8249e-01,  2.4833e-01]],

         [[-5.6883e-02, -7.0085e-02,  1.7606e-01],
          [-1.0558e-03, -2.6452e-01, -1.4355e-01],
          [ 2.9465e-02, -5.8078e-02, -1.0573e-01]]],


        [[[ 1.1209e-01,  1.3222e-01,  2.7039e-01],
          [ 1.7019e-01,  1.6901e-01, -3.4223e-03],
          [-2.8769e-01, -1.7944e-01, -8.2074e-02]],

         [[ 7.6422e-02,  2.2718e-02, -1.5923e-01],
          [ 2.9899e-02, -7.6151e-02, -3.3023e-01],
          [-2.8901e-02,  1.2623e-01, -2.8938e-02]],

         [[-2.2175e-01, -8.4183e-02, -2.2802e-01],
          [-1.1549e-01,  8.4299e-02,  6.2553e-02],
          [ 1.4631e-01,  2.3847e-01,  1.9008e-01]]],


        [[[-1.6416e-40,  3.1555e-40,  5.2593e-40],
          [-2.1925e-40,  1.3579e-40,  3.3380e-40],
          [ 4.4337e-40, -3.0411e-40,  7.4130e-41]],

         [[ 1.3580e-40, -1.8779e-40, -6.9443e-41],
          [ 1.6962e-40, -1.6381e-40, -4.4996e-42],
          [-4.1529e-40,  1.0548e-40,  3.8990e-41]],

         [[ 4.9526e-41, -2.9630e-40, -1.3992e-40],
          [-1.6368e-40,  3.7669e-40,  1.7479e-40],
          [-8.3831e-41, -3.2916e-40,  1.2363e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2591]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0049]], device='cuda:0')

Epoch: 71 | Batch_idx: 0 |  Loss: (0.2522) | Acc: (91.00%) (117/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.2107) | Acc: (93.00%) (1312/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.2239) | Acc: (92.00%) (2489/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.2201) | Acc: (92.00%) (3680/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.2275) | Acc: (92.00%) (4849/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.2295) | Acc: (92.00%) (6026/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.2272) | Acc: (92.00%) (7210/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.2245) | Acc: (92.00%) (8407/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.2226) | Acc: (92.00%) (9597/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.2209) | Acc: (92.00%) (10788/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.2210) | Acc: (92.00%) (11976/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.2188) | Acc: (92.00%) (13173/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.2180) | Acc: (92.00%) (14361/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.2189) | Acc: (92.00%) (15541/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.2180) | Acc: (92.00%) (16729/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.2202) | Acc: (92.00%) (17905/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.2194) | Acc: (92.00%) (19106/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.2180) | Acc: (92.00%) (20296/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.2182) | Acc: (92.00%) (21477/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.2175) | Acc: (92.00%) (22673/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.2169) | Acc: (92.00%) (23862/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.2153) | Acc: (92.00%) (25070/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.2152) | Acc: (92.00%) (26262/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.2146) | Acc: (92.00%) (27448/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.2133) | Acc: (92.00%) (28646/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.2140) | Acc: (92.00%) (29829/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.2136) | Acc: (92.00%) (31025/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.2137) | Acc: (92.00%) (32213/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.2133) | Acc: (92.00%) (33409/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.2134) | Acc: (92.00%) (34591/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.2131) | Acc: (92.00%) (35784/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.2126) | Acc: (92.00%) (36987/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.2123) | Acc: (92.00%) (38181/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.2116) | Acc: (92.00%) (39382/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.2110) | Acc: (92.00%) (40581/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.2102) | Acc: (92.00%) (41778/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.2101) | Acc: (92.00%) (42962/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.2108) | Acc: (92.00%) (44140/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.2102) | Acc: (92.00%) (45332/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.2099) | Acc: (92.00%) (46483/50000)
# TEST : Loss: (0.3013) | Acc: (90.00%) (9007/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8396e-01, -2.3485e-01,  4.4385e-02],
          [-8.1526e-02,  2.9518e-01,  2.0886e-01],
          [ 1.0786e-01,  9.5405e-03, -8.4994e-02]],

         [[-2.3637e-01,  2.0943e-01,  1.9481e-01],
          [-5.7329e-05,  3.4515e-01,  2.1075e-01],
          [ 2.0629e-01, -7.6455e-02,  1.2035e-01]],

         [[-2.0014e-01, -3.2249e-02, -5.6542e-02],
          [-2.5687e-01, -6.9283e-02, -6.6563e-02],
          [-1.7930e-01, -6.9099e-02, -1.4241e-01]]],


        [[[-8.6002e-41,  8.7981e-41, -3.0327e-41],
          [ 8.1854e-41, -8.0489e-41,  1.7694e-41],
          [ 8.9469e-41, -7.8611e-41,  6.1349e-42]],

         [[-1.5162e-42,  7.8249e-41,  7.7427e-41],
          [-7.9759e-41, -6.1998e-41,  6.7093e-41],
          [ 8.9853e-41,  4.2246e-41, -4.4336e-41]],

         [[ 2.4056e-41,  4.0464e-41, -3.8099e-41],
          [ 5.5566e-41, -6.4394e-41,  6.4537e-41],
          [-3.0014e-41,  4.7140e-42, -9.5985e-41]]],


        [[[ 5.0692e-02,  1.2279e-01, -7.9327e-02],
          [ 3.1411e-02,  2.0034e-01, -8.4453e-02],
          [ 1.0922e-01,  3.0026e-01,  2.7776e-01]],

         [[-2.0184e-01, -4.6645e-02, -1.7691e-01],
          [-3.0341e-01, -2.3904e-01, -2.3846e-01],
          [-2.4793e-01, -3.5566e-01,  2.9198e-02]],

         [[ 1.9791e-01,  6.6515e-02,  1.7830e-01],
          [ 1.8309e-01,  9.8060e-02,  4.8855e-02],
          [ 9.4472e-04,  1.0504e-01,  5.0438e-02]]],


        ...,


        [[[ 2.7449e-01,  5.4441e-02,  2.4593e-02],
          [ 2.4837e-01, -2.0234e-01, -5.6765e-02],
          [-2.5678e-03, -1.2337e-01, -1.1682e-01]],

         [[-1.2761e-01, -6.6843e-02, -4.6628e-02],
          [-1.6628e-01, -2.3674e-01,  1.2882e-01],
          [ 1.3756e-02,  2.7881e-01,  2.4552e-01]],

         [[-5.6081e-02, -6.8905e-02,  1.7356e-01],
          [-1.0368e-03, -2.5706e-01, -1.4102e-01],
          [ 2.9050e-02, -5.7147e-02, -1.0430e-01]]],


        [[[ 1.1163e-01,  1.3168e-01,  2.6936e-01],
          [ 1.6948e-01,  1.6831e-01, -3.4092e-03],
          [-2.8650e-01, -1.7870e-01, -8.1756e-02]],

         [[ 7.6108e-02,  2.2626e-02, -1.5860e-01],
          [ 2.9774e-02, -7.5838e-02, -3.2890e-01],
          [-2.8778e-02,  1.2570e-01, -2.8821e-02]],

         [[-2.2080e-01, -8.3825e-02, -2.2704e-01],
          [-1.1498e-01,  8.3941e-02,  6.2287e-02],
          [ 1.4567e-01,  2.3745e-01,  1.8928e-01]]],


        [[[-1.6556e-40, -2.0607e-40,  2.7687e-40],
          [-4.8839e-40,  6.7220e-42,  5.9641e-40],
          [ 3.1473e-40, -4.6187e-41, -5.1976e-41]],

         [[ 4.0209e-40,  2.0758e-40,  4.5543e-40],
          [ 3.8879e-41, -2.9762e-40, -2.6644e-40],
          [-1.5524e-40,  5.0344e-40,  1.6986e-40]],

         [[-2.1208e-40, -3.7691e-41, -4.0358e-40],
          [ 9.6245e-41,  5.1317e-40, -8.4486e-41],
          [ 1.7659e-40, -7.1437e-41, -5.1386e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2601]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0230]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 72 | Batch_idx: 0 |  Loss: (0.2881) | Acc: (88.00%) (113/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.2307) | Acc: (92.00%) (1297/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.2328) | Acc: (91.00%) (2464/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.2414) | Acc: (91.00%) (3630/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.2475) | Acc: (91.00%) (4791/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.2578) | Acc: (91.00%) (5950/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.2669) | Acc: (90.00%) (7091/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.2647) | Acc: (90.00%) (8259/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.2646) | Acc: (90.00%) (9433/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.2660) | Acc: (90.00%) (10595/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.2695) | Acc: (90.00%) (11743/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.2724) | Acc: (90.00%) (12889/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.2700) | Acc: (90.00%) (14060/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.2719) | Acc: (90.00%) (15212/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.2722) | Acc: (90.00%) (16361/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.2736) | Acc: (90.00%) (17517/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.2742) | Acc: (90.00%) (18666/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.2741) | Acc: (90.00%) (19828/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.2758) | Acc: (90.00%) (20979/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.2754) | Acc: (90.00%) (22156/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.2756) | Acc: (90.00%) (23312/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.2754) | Acc: (90.00%) (24477/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.2742) | Acc: (90.00%) (25650/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.2756) | Acc: (90.00%) (26807/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.2760) | Acc: (90.00%) (27964/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.2758) | Acc: (90.00%) (29121/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.2758) | Acc: (90.00%) (30278/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.2762) | Acc: (90.00%) (31442/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.2764) | Acc: (90.00%) (32609/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.2771) | Acc: (90.00%) (33761/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.2769) | Acc: (90.00%) (34917/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.2777) | Acc: (90.00%) (36060/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.2783) | Acc: (90.00%) (37216/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.2790) | Acc: (90.00%) (38375/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.2799) | Acc: (90.00%) (39519/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.2795) | Acc: (90.00%) (40682/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.2777) | Acc: (90.00%) (41866/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.2775) | Acc: (90.00%) (43032/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.2771) | Acc: (90.00%) (44191/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.2762) | Acc: (90.00%) (45332/50000)
# TEST : Loss: (0.3609) | Acc: (88.00%) (8842/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7635e-01, -2.2222e-01,  6.2674e-02],
          [-7.8913e-02,  3.0330e-01,  2.1865e-01],
          [ 1.1253e-01,  2.4742e-02, -6.3569e-02]],

         [[-2.3554e-01,  2.1464e-01,  2.0293e-01],
          [-5.2343e-03,  3.4674e-01,  2.1289e-01],
          [ 2.0030e-01, -7.0627e-02,  1.2979e-01]],

         [[-2.0321e-01, -3.5012e-02, -5.5727e-02],
          [-2.6716e-01, -7.6722e-02, -7.0431e-02],
          [-1.9035e-01, -7.2327e-02, -1.3785e-01]]],


        [[[-4.4215e-41,  8.2140e-41,  5.4433e-41],
          [-4.7144e-41, -1.0152e-40,  3.8072e-41],
          [ 6.9870e-41, -2.5404e-41, -8.7119e-41]],

         [[-8.7546e-41,  4.8716e-41, -9.5769e-41],
          [ 2.9486e-41,  2.5254e-41,  8.5367e-41],
          [-5.5236e-41, -4.8472e-41,  8.7278e-41]],

         [[ 8.8945e-41,  8.4411e-41,  4.3973e-42],
          [ 5.9220e-41, -5.1707e-41, -4.3345e-41],
          [ 7.7898e-41, -8.1579e-41, -7.0345e-43]]],


        [[[ 5.8501e-02,  1.2673e-01, -7.0012e-02],
          [ 3.6575e-02,  1.9783e-01, -8.5989e-02],
          [ 1.0482e-01,  2.9270e-01,  2.7803e-01]],

         [[-1.8944e-01, -3.8783e-02, -1.6305e-01],
          [-3.0379e-01, -2.4758e-01, -2.3817e-01],
          [-2.5657e-01, -3.6727e-01,  3.2610e-02]],

         [[ 2.1544e-01,  7.9265e-02,  1.9414e-01],
          [ 1.9093e-01,  9.6971e-02,  5.2348e-02],
          [ 5.9303e-05,  9.6566e-02,  4.9014e-02]]],


        ...,


        [[[ 2.7382e-01,  5.8259e-02,  2.7327e-02],
          [ 2.5282e-01, -1.8855e-01, -5.1418e-02],
          [-1.0054e-02, -1.3197e-01, -1.1092e-01]],

         [[-1.3730e-01, -7.2364e-02, -4.9258e-02],
          [-1.7179e-01, -2.2891e-01,  1.2854e-01],
          [-4.2151e-03,  2.6201e-01,  2.5232e-01]],

         [[-6.4246e-02, -8.4169e-02,  1.4875e-01],
          [-1.5828e-02, -2.6886e-01, -1.6602e-01],
          [-6.8452e-04, -9.0478e-02, -1.1731e-01]]],


        [[[ 1.2680e-01,  1.4818e-01,  2.8251e-01],
          [ 1.7843e-01,  1.7614e-01,  2.8901e-03],
          [-2.8153e-01, -1.7352e-01, -7.9823e-02]],

         [[ 8.1728e-02,  3.1166e-02, -1.4932e-01],
          [ 3.2999e-02, -7.3413e-02, -3.2765e-01],
          [-2.4774e-02,  1.2861e-01, -2.9677e-02]],

         [[-2.1758e-01, -7.9622e-02, -2.2173e-01],
          [-1.1350e-01,  8.5845e-02,  6.3079e-02],
          [ 1.4851e-01,  2.4247e-01,  1.8878e-01]]],


        [[[-3.2278e-41,  5.6562e-41, -2.4246e-40],
          [-3.5875e-40, -1.2573e-40, -3.0637e-40],
          [-8.5437e-41,  2.1856e-40, -1.8230e-40]],

         [[ 2.7235e-40, -4.5876e-40, -2.0434e-40],
          [-9.4760e-41, -1.6671e-40, -2.6951e-40],
          [ 2.4450e-40,  3.7539e-40,  1.7142e-40]],

         [[-2.1520e-40,  2.2754e-40, -2.7574e-40],
          [ 2.3023e-40,  1.2147e-40, -3.5059e-40],
          [ 3.1072e-40,  3.2554e-40, -1.3737e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0178, -0.0155, -0.0254],
          [-0.0042, -0.0011, -0.0120],
          [-0.0068, -0.0017, -0.0080]],

         [[-0.0201, -0.0156, -0.0255],
          [-0.0091, -0.0039, -0.0123],
          [-0.0089, -0.0031, -0.0077]],

         [[-0.0139, -0.0061, -0.0124],
          [-0.0054,  0.0007, -0.0049],
          [-0.0087, -0.0034, -0.0063]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0198, -0.0271, -0.0372],
          [-0.0410, -0.0169, -0.0137],
          [-0.0214, -0.0139, -0.0243]],

         [[-0.0437, -0.0477, -0.0544],
          [-0.0567, -0.0219, -0.0124],
          [-0.0335, -0.0135, -0.0125]],

         [[-0.0412, -0.0472, -0.0594],
          [-0.0539, -0.0233, -0.0100],
          [-0.0343, -0.0166, -0.0083]]],


        ...,


        [[[ 0.0024,  0.0002,  0.0054],
          [ 0.0052,  0.0004,  0.0016],
          [ 0.0066, -0.0013, -0.0009]],

         [[ 0.0034, -0.0007,  0.0050],
          [ 0.0046, -0.0007,  0.0011],
          [ 0.0045, -0.0048, -0.0043]],

         [[ 0.0025, -0.0015,  0.0035],
          [ 0.0041, -0.0013, -0.0004],
          [ 0.0058, -0.0022, -0.0026]]],


        [[[ 0.0150,  0.0246,  0.0191],
          [ 0.0148,  0.0217,  0.0162],
          [ 0.0130,  0.0140,  0.0143]],

         [[ 0.0098,  0.0188,  0.0155],
          [ 0.0098,  0.0139,  0.0087],
          [ 0.0105,  0.0091,  0.0101]],

         [[ 0.0071,  0.0108,  0.0046],
          [ 0.0012, -0.0004, -0.0055],
          [-0.0018, -0.0064, -0.0033]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2606]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 73 | Batch_idx: 0 |  Loss: (0.1557) | Acc: (94.00%) (121/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.2299) | Acc: (91.00%) (1290/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.2255) | Acc: (91.00%) (2467/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.2194) | Acc: (92.00%) (3656/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.2202) | Acc: (92.00%) (4832/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.2118) | Acc: (92.00%) (6038/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.2148) | Acc: (92.00%) (7217/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.2206) | Acc: (92.00%) (8394/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.2227) | Acc: (92.00%) (9571/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.2246) | Acc: (92.00%) (10746/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.2265) | Acc: (92.00%) (11914/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.2245) | Acc: (92.00%) (13095/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.2253) | Acc: (92.00%) (14256/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.2288) | Acc: (91.00%) (15421/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.2290) | Acc: (91.00%) (16600/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.2290) | Acc: (92.00%) (17785/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.2288) | Acc: (92.00%) (18971/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.2285) | Acc: (92.00%) (20151/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.2286) | Acc: (92.00%) (21329/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.2294) | Acc: (92.00%) (22505/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.2303) | Acc: (92.00%) (23673/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.2294) | Acc: (92.00%) (24857/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.2290) | Acc: (92.00%) (26042/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.2306) | Acc: (92.00%) (27209/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.2312) | Acc: (91.00%) (28377/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.2315) | Acc: (92.00%) (29560/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.2316) | Acc: (92.00%) (30738/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.2315) | Acc: (92.00%) (31918/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.2315) | Acc: (91.00%) (33090/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.2320) | Acc: (92.00%) (34273/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.2317) | Acc: (92.00%) (35462/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.2318) | Acc: (92.00%) (36630/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.2321) | Acc: (91.00%) (37794/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.2327) | Acc: (91.00%) (38963/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.2325) | Acc: (91.00%) (40141/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.2333) | Acc: (91.00%) (41307/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.2336) | Acc: (91.00%) (42471/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.2343) | Acc: (91.00%) (43632/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.2345) | Acc: (91.00%) (44800/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.2349) | Acc: (91.00%) (45933/50000)
# TEST : Loss: (0.3329) | Acc: (89.00%) (8937/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9666e-01, -2.4072e-01,  4.4359e-02],
          [-8.9092e-02,  2.9276e-01,  2.0332e-01],
          [ 1.0407e-01,  1.7185e-02, -7.5820e-02]],

         [[-2.4844e-01,  1.9986e-01,  1.8657e-01],
          [-6.8255e-03,  3.4244e-01,  2.0189e-01],
          [ 2.0078e-01, -6.9025e-02,  1.2181e-01]],

         [[-2.1647e-01, -5.0500e-02, -7.2750e-02],
          [-2.6912e-01, -8.4777e-02, -8.5603e-02],
          [-1.9179e-01, -7.6419e-02, -1.5092e-01]]],


        [[[ 8.2288e-41,  7.9029e-41, -1.0427e-40],
          [ 5.8012e-41, -8.8182e-41, -1.4424e-41],
          [-4.0573e-41,  7.7315e-41, -1.0522e-40]],

         [[-1.1021e-40,  7.9313e-41, -5.4233e-41],
          [-5.0022e-41,  1.5304e-41,  5.7774e-41],
          [-2.9443e-41, -4.8615e-41, -6.4136e-41]],

         [[ 8.6680e-41, -8.4823e-41, -4.0181e-41],
          [-3.3743e-41, -8.8712e-41,  9.9772e-41],
          [ 9.9708e-41,  3.8201e-41,  8.3216e-41]]],


        [[[ 4.4143e-02,  1.1424e-01, -8.4759e-02],
          [ 3.2596e-02,  1.9692e-01, -9.7319e-02],
          [ 1.0822e-01,  2.9795e-01,  2.7289e-01]],

         [[-1.9769e-01, -4.7454e-02, -1.7413e-01],
          [-3.0363e-01, -2.4866e-01, -2.4898e-01],
          [-2.5160e-01, -3.6703e-01,  2.4659e-02]],

         [[ 2.1466e-01,  7.6314e-02,  1.8441e-01],
          [ 2.0360e-01,  1.0379e-01,  4.5707e-02],
          [ 1.6483e-02,  1.0296e-01,  4.4850e-02]]],


        ...,


        [[[ 2.7333e-01,  6.4583e-02,  4.1427e-02],
          [ 2.4617e-01, -1.9789e-01, -5.1744e-02],
          [-1.8037e-02, -1.2940e-01, -1.0700e-01]],

         [[-1.3924e-01, -7.0918e-02, -3.6824e-02],
          [-1.7559e-01, -2.4471e-01,  1.2002e-01],
          [-1.2965e-02,  2.6145e-01,  2.4984e-01]],

         [[-6.0697e-02, -7.5482e-02,  1.6310e-01],
          [-2.0007e-02, -2.6995e-01, -1.6133e-01],
          [-1.3775e-02, -7.9598e-02, -1.1057e-01]]],


        [[[ 1.2684e-01,  1.5157e-01,  2.8682e-01],
          [ 1.7541e-01,  1.6794e-01,  7.1362e-04],
          [-2.8411e-01, -1.7788e-01, -7.7313e-02]],

         [[ 8.1363e-02,  3.0706e-02, -1.4652e-01],
          [ 3.3817e-02, -7.8598e-02, -3.2910e-01],
          [-2.5167e-02,  1.2446e-01, -2.8630e-02]],

         [[-2.2443e-01, -8.6098e-02, -2.2197e-01],
          [-1.1904e-01,  7.8406e-02,  6.3969e-02],
          [ 1.4633e-01,  2.4091e-01,  1.9467e-01]]],


        [[[ 1.0313e-40,  3.2465e-40, -5.1025e-40],
          [ 1.7966e-40, -1.2703e-40, -4.4195e-40],
          [-3.5688e-40,  2.2118e-40, -1.8392e-40]],

         [[-1.2977e-40, -3.2721e-40, -4.7471e-40],
          [-9.5867e-41,  1.0155e-40, -4.4757e-42],
          [ 3.8148e-40, -1.5965e-40,  3.8997e-41]],

         [[ 4.9540e-41,  2.3009e-40,  1.2294e-40],
          [ 9.9101e-41, -4.1274e-40, -2.2097e-40],
          [ 1.7936e-40, -7.3522e-41, -1.3870e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0048, -0.0167, -0.0289],
          [ 0.0012, -0.0112, -0.0240],
          [-0.0074, -0.0156, -0.0319]],

         [[-0.0015, -0.0131, -0.0196],
          [ 0.0045, -0.0074, -0.0140],
          [-0.0010, -0.0080, -0.0169]],

         [[-0.0125, -0.0222, -0.0217],
          [-0.0080, -0.0174, -0.0170],
          [-0.0121, -0.0142, -0.0164]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0358,  0.0158,  0.0243],
          [ 0.0477,  0.0114,  0.0201],
          [ 0.0340, -0.0004,  0.0084]],

         [[ 0.0094, -0.0014,  0.0052],
          [ 0.0252, -0.0040, -0.0023],
          [ 0.0150, -0.0172, -0.0172]],

         [[-0.0002, -0.0063, -0.0106],
          [ 0.0166, -0.0019, -0.0052],
          [-0.0007, -0.0184, -0.0217]]],


        ...,


        [[[-0.0107, -0.0098, -0.0087],
          [-0.0144, -0.0123, -0.0101],
          [-0.0136, -0.0132, -0.0090]],

         [[-0.0057, -0.0057, -0.0042],
          [-0.0094, -0.0089, -0.0070],
          [-0.0096, -0.0105, -0.0072]],

         [[-0.0012, -0.0017, -0.0001],
          [-0.0035, -0.0031, -0.0015],
          [-0.0025, -0.0031, -0.0004]]],


        [[[ 0.0094, -0.0023,  0.0061],
          [ 0.0063, -0.0066, -0.0109],
          [ 0.0026, -0.0095, -0.0112]],

         [[ 0.0034, -0.0057,  0.0039],
          [ 0.0022, -0.0068, -0.0100],
          [-0.0022, -0.0108, -0.0117]],

         [[-0.0094, -0.0160, -0.0051],
          [-0.0089, -0.0162, -0.0181],
          [-0.0116, -0.0184, -0.0205]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2600]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 74 | Batch_idx: 0 |  Loss: (0.1424) | Acc: (95.00%) (122/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.2162) | Acc: (92.00%) (1305/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2266) | Acc: (92.00%) (2483/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2406) | Acc: (91.00%) (3646/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2446) | Acc: (91.00%) (4821/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2500) | Acc: (91.00%) (5985/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2530) | Acc: (91.00%) (7155/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2527) | Acc: (91.00%) (8323/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2515) | Acc: (91.00%) (9490/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2457) | Acc: (91.00%) (10681/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2427) | Acc: (91.00%) (11871/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2428) | Acc: (91.00%) (13047/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2408) | Acc: (91.00%) (14230/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2405) | Acc: (91.00%) (15404/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2403) | Acc: (91.00%) (16581/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2377) | Acc: (91.00%) (17777/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2364) | Acc: (92.00%) (18968/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2350) | Acc: (92.00%) (20153/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2348) | Acc: (92.00%) (21327/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2340) | Acc: (92.00%) (22502/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2334) | Acc: (92.00%) (23693/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2340) | Acc: (92.00%) (24874/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2340) | Acc: (92.00%) (26056/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2339) | Acc: (92.00%) (27243/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2339) | Acc: (92.00%) (28425/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2334) | Acc: (92.00%) (29601/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2311) | Acc: (92.00%) (30799/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2297) | Acc: (92.00%) (31990/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2291) | Acc: (92.00%) (33183/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2276) | Acc: (92.00%) (34387/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2266) | Acc: (92.00%) (35586/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2271) | Acc: (92.00%) (36772/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2261) | Acc: (92.00%) (37971/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2251) | Acc: (92.00%) (39158/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2240) | Acc: (92.00%) (40363/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2227) | Acc: (92.00%) (41579/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2219) | Acc: (92.00%) (42771/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2223) | Acc: (92.00%) (43958/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2212) | Acc: (92.00%) (45160/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2201) | Acc: (92.00%) (46320/50000)
# TEST : Loss: (0.3160) | Acc: (89.00%) (8969/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0163e-01, -2.4535e-01,  4.0039e-02],
          [-9.4412e-02,  2.8604e-01,  1.9768e-01],
          [ 9.9250e-02,  1.2981e-02, -7.8469e-02]],

         [[-2.5183e-01,  1.9528e-01,  1.8304e-01],
          [-1.1145e-02,  3.3713e-01,  1.9779e-01],
          [ 1.9612e-01, -7.2017e-02,  1.1922e-01]],

         [[-2.1918e-01, -5.3050e-02, -7.4412e-02],
          [-2.7131e-01, -8.7311e-02, -8.7758e-02],
          [-1.9371e-01, -7.8541e-02, -1.5247e-01]]],


        [[[ 7.6722e-41,  1.1385e-40, -1.0961e-40],
          [ 8.1508e-41, -8.1738e-41, -8.3119e-41],
          [ 8.5507e-41, -6.7296e-41,  6.3636e-41]],

         [[-2.6444e-41, -9.3605e-41,  4.1170e-42],
          [-7.7723e-41, -5.4725e-41, -7.7322e-41],
          [-1.2547e-41, -1.0417e-41, -9.7407e-41]],

         [[ 3.5653e-41,  5.2581e-41,  7.9301e-41],
          [ 8.6141e-41,  1.4398e-41,  9.5095e-41],
          [-2.9132e-41, -6.8539e-41,  1.1384e-40]]],


        [[[ 4.1204e-02,  1.1130e-01, -8.8550e-02],
          [ 2.8199e-02,  1.9293e-01, -1.0240e-01],
          [ 1.0299e-01,  2.9344e-01,  2.6691e-01]],

         [[-1.9885e-01, -4.8931e-02, -1.7680e-01],
          [-3.0617e-01, -2.5065e-01, -2.5226e-01],
          [-2.5442e-01, -3.6857e-01,  2.1524e-02]],

         [[ 2.1502e-01,  7.6264e-02,  1.8300e-01],
          [ 2.0266e-01,  1.0284e-01,  4.3633e-02],
          [ 1.5664e-02,  1.0235e-01,  4.3373e-02]]],


        ...,


        [[[ 2.7048e-01,  6.3275e-02,  4.0768e-02],
          [ 2.4409e-01, -1.9643e-01, -5.0532e-02],
          [-1.7821e-02, -1.2825e-01, -1.0619e-01]],

         [[-1.3846e-01, -7.1107e-02, -3.7242e-02],
          [-1.7425e-01, -2.4274e-01,  1.1873e-01],
          [-1.3494e-02,  2.5771e-01,  2.4646e-01]],

         [[-6.0126e-02, -7.5668e-02,  1.6005e-01],
          [-2.0341e-02, -2.6531e-01, -1.5857e-01],
          [-1.4531e-02, -8.0072e-02, -1.1049e-01]]],


        [[[ 1.2505e-01,  1.5031e-01,  2.8472e-01],
          [ 1.7241e-01,  1.6526e-01, -6.7876e-04],
          [-2.8458e-01, -1.7808e-01, -7.8511e-02]],

         [[ 8.1159e-02,  3.0849e-02, -1.4652e-01],
          [ 3.3288e-02, -7.8796e-02, -3.2837e-01],
          [-2.5053e-02,  1.2446e-01, -2.8936e-02]],

         [[-2.2274e-01, -8.4916e-02, -2.2127e-01],
          [-1.1782e-01,  7.8586e-02,  6.3895e-02],
          [ 1.4682e-01,  2.4119e-01,  1.9424e-01]]],


        [[[ 1.0393e-40,  3.2672e-40, -2.4820e-40],
          [ 5.8900e-40,  6.7150e-42, -4.4621e-40],
          [-2.2337e-40, -4.6205e-41, -5.1960e-41]],

         [[-4.0209e-40,  7.8171e-41, -3.4331e-40],
          [ 3.8890e-41,  2.3812e-40,  2.6530e-40],
          [ 1.1282e-40, -5.6725e-40, -9.5819e-41]],

         [[ 3.1911e-40, -3.7702e-41,  3.9372e-40],
          [-1.6948e-40, -5.5089e-40,  1.8093e-40],
          [-8.9511e-41, -7.4395e-41, -5.1161e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2415]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0023]], device='cuda:0')

Epoch: 75 | Batch_idx: 0 |  Loss: (0.2819) | Acc: (90.00%) (116/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.1821) | Acc: (93.00%) (1323/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.1798) | Acc: (93.00%) (2525/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.1925) | Acc: (93.00%) (3717/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.1972) | Acc: (93.00%) (4914/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.1970) | Acc: (93.00%) (6116/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.2002) | Acc: (93.00%) (7306/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.1981) | Acc: (93.00%) (8506/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.1989) | Acc: (93.00%) (9698/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.1966) | Acc: (93.00%) (10904/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.1970) | Acc: (93.00%) (12097/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.1967) | Acc: (93.00%) (13300/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.1953) | Acc: (93.00%) (14508/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.1949) | Acc: (93.00%) (15701/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.1962) | Acc: (93.00%) (16884/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.1966) | Acc: (93.00%) (18079/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.1965) | Acc: (93.00%) (19278/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.1977) | Acc: (93.00%) (20469/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.1992) | Acc: (93.00%) (21650/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.1997) | Acc: (93.00%) (22831/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.2022) | Acc: (93.00%) (24013/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.2026) | Acc: (93.00%) (25199/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.2031) | Acc: (93.00%) (26392/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.2023) | Acc: (93.00%) (27590/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.2018) | Acc: (93.00%) (28795/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.2004) | Acc: (93.00%) (30008/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.2005) | Acc: (93.00%) (31205/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.2008) | Acc: (93.00%) (32393/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.2012) | Acc: (93.00%) (33577/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.2017) | Acc: (93.00%) (34768/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.2014) | Acc: (93.00%) (35961/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.2009) | Acc: (93.00%) (37166/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.1997) | Acc: (93.00%) (38375/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.2002) | Acc: (93.00%) (39572/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.2004) | Acc: (93.00%) (40757/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.2004) | Acc: (93.00%) (41947/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.2008) | Acc: (93.00%) (43128/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.2002) | Acc: (93.00%) (44337/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.2001) | Acc: (93.00%) (45522/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.2001) | Acc: (93.00%) (46675/50000)
# TEST : Loss: (0.3006) | Acc: (90.00%) (9016/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0086e-01, -2.4434e-01,  3.9866e-02],
          [-9.4031e-02,  2.8478e-01,  1.9676e-01],
          [ 9.8849e-02,  1.2924e-02, -7.8115e-02]],

         [[-2.5081e-01,  1.9446e-01,  1.8224e-01],
          [-1.1098e-02,  3.3563e-01,  1.9688e-01],
          [ 1.9530e-01, -7.1698e-02,  1.1869e-01]],

         [[-2.1820e-01, -5.2818e-02, -7.4097e-02],
          [-2.7010e-01, -8.6933e-02, -8.7387e-02],
          [-1.9287e-01, -7.8203e-02, -1.5183e-01]]],


        [[[ 6.2823e-41,  3.5397e-41,  6.9476e-41],
          [ 8.4175e-41,  1.1014e-40,  8.3910e-42],
          [ 9.5974e-41,  4.7989e-41,  7.6714e-41]],

         [[-2.6975e-42, -1.2693e-40, -2.3630e-41],
          [-5.2189e-41,  8.0534e-41, -6.2799e-41],
          [ 1.2247e-41,  4.6358e-41, -6.1111e-41]],

         [[ 6.5237e-41, -9.2627e-41,  9.5731e-41],
          [ 8.1700e-41,  1.7488e-42,  1.5322e-41],
          [-6.2672e-41, -3.6057e-41, -3.3533e-41]]],


        [[[ 4.1135e-02,  1.1111e-01, -8.8395e-02],
          [ 2.8151e-02,  1.9259e-01, -1.0222e-01],
          [ 1.0281e-01,  2.9293e-01,  2.6643e-01]],

         [[-1.9849e-01, -4.8841e-02, -1.7646e-01],
          [-3.0557e-01, -2.5017e-01, -2.5177e-01],
          [-2.5393e-01, -3.6787e-01,  2.1484e-02]],

         [[ 2.1459e-01,  7.6113e-02,  1.8263e-01],
          [ 2.0223e-01,  1.0263e-01,  4.3542e-02],
          [ 1.5632e-02,  1.0214e-01,  4.3284e-02]]],


        ...,


        [[[ 2.6796e-01,  6.2646e-02,  4.0386e-02],
          [ 2.4157e-01, -1.9413e-01, -5.0006e-02],
          [-1.7644e-02, -1.2688e-01, -1.0514e-01]],

         [[-1.3685e-01, -7.0164e-02, -3.6816e-02],
          [-1.7192e-01, -2.3859e-01,  1.1717e-01],
          [-1.3338e-02,  2.5438e-01,  2.4366e-01]],

         [[-5.9240e-02, -7.4294e-02,  1.5770e-01],
          [-1.9957e-02, -2.5731e-01, -1.5556e-01],
          [-1.4315e-02, -7.8670e-02, -1.0886e-01]]],


        [[[ 1.2443e-01,  1.4956e-01,  2.8343e-01],
          [ 1.7156e-01,  1.6444e-01, -6.7571e-04],
          [-2.8325e-01, -1.7723e-01, -7.8158e-02]],

         [[ 8.0786e-02,  3.0706e-02, -1.4585e-01],
          [ 3.3132e-02, -7.8426e-02, -3.2687e-01],
          [-2.4937e-02,  1.2388e-01, -2.8802e-02]],

         [[-2.2171e-01, -8.4519e-02, -2.2021e-01],
          [-1.1725e-01,  7.8209e-02,  6.3586e-02],
          [ 1.4612e-01,  2.4004e-01,  1.9330e-01]]],


        [[[-3.2301e-41,  5.6552e-41,  2.8864e-40],
          [ 4.5489e-40,  1.4247e-40, -5.8417e-40],
          [ 1.8551e-40, -3.1762e-40,  8.2545e-41]],

         [[-2.6792e-40,  3.5193e-40,  6.2229e-41],
          [ 1.7534e-40,  1.0327e-40,  2.6710e-40],
          [-2.9583e-40, -4.3407e-40, -9.6734e-41]],

         [[ 3.2094e-40, -3.0941e-40,  2.6068e-40],
          [-3.0613e-40, -1.4694e-40,  4.5315e-40],
          [-2.2624e-40, -3.4706e-40,  1.3050e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2097]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0421]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 76 | Batch_idx: 0 |  Loss: (0.1560) | Acc: (94.00%) (121/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.2102) | Acc: (92.00%) (1308/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.2288) | Acc: (92.00%) (2482/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.2290) | Acc: (92.00%) (3660/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.2317) | Acc: (92.00%) (4843/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.2372) | Acc: (91.00%) (5998/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.2425) | Acc: (91.00%) (7160/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.2476) | Acc: (91.00%) (8327/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.2481) | Acc: (91.00%) (9495/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.2496) | Acc: (91.00%) (10665/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.2550) | Acc: (91.00%) (11806/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.2559) | Acc: (91.00%) (12977/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.2595) | Acc: (91.00%) (14126/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.2674) | Acc: (90.00%) (15255/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.2696) | Acc: (90.00%) (16411/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.2706) | Acc: (90.00%) (17558/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.2707) | Acc: (90.00%) (18728/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.2697) | Acc: (90.00%) (19909/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.2692) | Acc: (90.00%) (21070/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.2686) | Acc: (90.00%) (22244/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.2693) | Acc: (90.00%) (23401/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.2691) | Acc: (90.00%) (24568/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.2702) | Acc: (90.00%) (25711/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.2711) | Acc: (90.00%) (26868/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.2712) | Acc: (90.00%) (28025/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.2712) | Acc: (90.00%) (29195/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.2715) | Acc: (90.00%) (30354/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.2721) | Acc: (90.00%) (31497/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.2725) | Acc: (90.00%) (32647/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.2725) | Acc: (90.00%) (33817/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.2729) | Acc: (90.00%) (34981/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.2726) | Acc: (90.00%) (36143/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.2724) | Acc: (90.00%) (37313/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.2718) | Acc: (90.00%) (38491/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.2728) | Acc: (90.00%) (39641/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.2727) | Acc: (90.00%) (40804/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.2737) | Acc: (90.00%) (41940/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.2729) | Acc: (90.00%) (43106/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.2735) | Acc: (90.00%) (44265/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.2731) | Acc: (90.00%) (45391/50000)
# TEST : Loss: (0.3660) | Acc: (88.00%) (8810/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7824e-01, -2.2236e-01,  4.9643e-02],
          [-7.1410e-02,  3.0442e-01,  2.0660e-01],
          [ 1.1448e-01,  2.3708e-02, -7.5553e-02]],

         [[-2.3088e-01,  2.1514e-01,  1.9186e-01],
          [ 1.1420e-02,  3.5758e-01,  2.1308e-01],
          [ 2.1270e-01, -5.5240e-02,  1.2925e-01]],

         [[-2.0714e-01, -4.4224e-02, -6.9904e-02],
          [-2.5918e-01, -7.9588e-02, -7.8854e-02],
          [-1.8476e-01, -7.3948e-02, -1.4642e-01]]],


        [[[-1.3532e-40, -1.4574e-40, -1.1865e-40],
          [-7.4113e-41, -2.3218e-41,  1.2466e-40],
          [ 4.2768e-41,  8.3768e-41, -1.4519e-40]],

         [[ 2.9703e-41,  1.1973e-40,  6.1587e-42],
          [-6.2488e-41,  5.3046e-41,  1.0858e-40],
          [-1.3360e-40, -7.6166e-41,  7.8890e-41]],

         [[-5.7471e-41,  7.6388e-41,  8.7888e-41],
          [ 4.5801e-41,  7.5964e-41, -1.4584e-40],
          [-1.1983e-40,  7.5691e-41,  1.2527e-40]]],


        [[[ 5.5070e-02,  1.2088e-01, -7.4047e-02],
          [ 4.0011e-02,  2.0051e-01, -8.7970e-02],
          [ 1.1480e-01,  3.0910e-01,  2.9359e-01]],

         [[-1.9008e-01, -4.4740e-02, -1.6822e-01],
          [-3.0464e-01, -2.5732e-01, -2.5072e-01],
          [-2.4853e-01, -3.6362e-01,  3.8665e-02]],

         [[ 2.1437e-01,  7.3687e-02,  1.7510e-01],
          [ 1.9835e-01,  9.1905e-02,  3.2877e-02],
          [ 1.2941e-02,  9.7395e-02,  4.3980e-02]]],


        ...,


        [[[ 2.5568e-01,  4.8821e-02,  4.0462e-02],
          [ 2.3597e-01, -2.0487e-01, -6.1913e-02],
          [-1.0492e-02, -1.2725e-01, -1.0849e-01]],

         [[-1.4770e-01, -8.2442e-02, -2.6573e-02],
          [-1.7501e-01, -2.4681e-01,  1.1131e-01],
          [-1.3934e-02,  2.4620e-01,  2.4216e-01]],

         [[-6.9221e-02, -9.4658e-02,  1.5925e-01],
          [-2.3961e-02, -2.6902e-01, -1.6370e-01],
          [-1.0760e-02, -7.7319e-02, -1.0761e-01]]],


        [[[ 1.1111e-01,  1.4572e-01,  2.7711e-01],
          [ 1.7319e-01,  1.6179e-01, -8.5446e-03],
          [-2.7186e-01, -1.7453e-01, -8.3493e-02]],

         [[ 5.8733e-02,  1.8151e-02, -1.5911e-01],
          [ 2.6768e-02, -8.7183e-02, -3.4574e-01],
          [-2.2597e-02,  1.1754e-01, -4.5001e-02]],

         [[-2.4869e-01, -9.7477e-02, -2.2845e-01],
          [-1.2747e-01,  7.1794e-02,  5.0996e-02],
          [ 1.4457e-01,  2.3848e-01,  1.8686e-01]]],


        [[[-1.6976e-40, -2.1680e-40,  5.6185e-40],
          [-9.3134e-41,  1.4322e-40, -1.8171e-40],
          [ 4.6078e-40, -3.1915e-40,  8.3516e-41]],

         [[ 1.4212e-40,  2.1669e-40,  4.7246e-40],
          [ 1.7597e-40, -1.7018e-40, -4.4785e-42],
          [-4.3421e-40,  1.1199e-40,  3.9007e-41]],

         [[ 4.9532e-41, -3.1089e-40, -1.4737e-40],
          [-1.7115e-40,  3.9865e-40,  3.1906e-40],
          [-9.1128e-41, -2.1262e-40,  1.3128e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0001,  0.0092,  0.0107],
          [ 0.0039,  0.0102,  0.0122],
          [ 0.0097,  0.0151,  0.0203]],

         [[ 0.0090,  0.0144,  0.0159],
          [ 0.0133,  0.0179,  0.0199],
          [ 0.0212,  0.0257,  0.0309]],

         [[ 0.0148,  0.0186,  0.0211],
          [ 0.0184,  0.0227,  0.0257],
          [ 0.0250,  0.0292,  0.0341]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0407, -0.0456, -0.0713],
          [-0.0209, -0.0420, -0.0570],
          [-0.0143, -0.0390, -0.0506]],

         [[-0.0532, -0.0578, -0.0741],
          [-0.0381, -0.0624, -0.0724],
          [-0.0337, -0.0556, -0.0646]],

         [[-0.0642, -0.0635, -0.0698],
          [-0.0576, -0.0737, -0.0713],
          [-0.0560, -0.0708, -0.0657]]],


        ...,


        [[[-0.0039, -0.0030, -0.0095],
          [-0.0074, -0.0029, -0.0082],
          [-0.0085, -0.0042, -0.0058]],

         [[-0.0040, -0.0009, -0.0063],
          [-0.0047,  0.0008, -0.0046],
          [-0.0039,  0.0006, -0.0014]],

         [[-0.0040, -0.0009, -0.0047],
          [-0.0044,  0.0005, -0.0034],
          [-0.0017,  0.0012, -0.0003]]],


        [[[-0.0116, -0.0129, -0.0072],
          [-0.0101, -0.0085,  0.0036],
          [-0.0032,  0.0005,  0.0063]],

         [[-0.0170, -0.0160, -0.0087],
          [-0.0145, -0.0096,  0.0027],
          [-0.0084, -0.0042,  0.0024]],

         [[-0.0204, -0.0195, -0.0118],
          [-0.0132, -0.0110, -0.0006],
          [-0.0076, -0.0039,  0.0018]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2086]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 77 | Batch_idx: 0 |  Loss: (0.1966) | Acc: (93.00%) (120/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2308) | Acc: (91.00%) (1294/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.2364) | Acc: (91.00%) (2468/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.2394) | Acc: (91.00%) (3643/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.2367) | Acc: (92.00%) (4831/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.2382) | Acc: (91.00%) (6002/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.2308) | Acc: (92.00%) (7197/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.2288) | Acc: (92.00%) (8385/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.2290) | Acc: (92.00%) (9559/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.2259) | Acc: (92.00%) (10753/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.2287) | Acc: (92.00%) (11926/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.2286) | Acc: (92.00%) (13110/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.2287) | Acc: (92.00%) (14295/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.2297) | Acc: (92.00%) (15479/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.2299) | Acc: (92.00%) (16666/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.2293) | Acc: (92.00%) (17848/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.2299) | Acc: (92.00%) (19026/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.2283) | Acc: (92.00%) (20213/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.2302) | Acc: (92.00%) (21371/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.2311) | Acc: (92.00%) (22554/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.2303) | Acc: (92.00%) (23745/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.2301) | Acc: (92.00%) (24929/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.2319) | Acc: (92.00%) (26093/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.2305) | Acc: (92.00%) (27283/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.2310) | Acc: (92.00%) (28451/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.2304) | Acc: (92.00%) (29637/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.2301) | Acc: (92.00%) (30816/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.2300) | Acc: (92.00%) (32000/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.2313) | Acc: (92.00%) (33161/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.2310) | Acc: (92.00%) (34342/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.2315) | Acc: (92.00%) (35522/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.2312) | Acc: (92.00%) (36700/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.2321) | Acc: (92.00%) (37871/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.2308) | Acc: (92.00%) (39072/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.2311) | Acc: (92.00%) (40244/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.2321) | Acc: (92.00%) (41415/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.2331) | Acc: (92.00%) (42578/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.2328) | Acc: (92.00%) (43752/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.2324) | Acc: (92.00%) (44936/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.2328) | Acc: (92.00%) (46055/50000)
# TEST : Loss: (0.3448) | Acc: (89.00%) (8907/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8188e-01, -2.2785e-01,  5.4577e-02],
          [-7.0359e-02,  3.1034e-01,  2.1792e-01],
          [ 1.1288e-01,  3.2178e-02, -6.6901e-02]],

         [[-2.3453e-01,  2.0828e-01,  1.9546e-01],
          [ 9.8829e-03,  3.6074e-01,  2.1919e-01],
          [ 2.0918e-01, -4.9593e-02,  1.3139e-01]],

         [[-2.0586e-01, -4.5082e-02, -6.3599e-02],
          [-2.5543e-01, -7.4980e-02, -7.3997e-02],
          [-1.8323e-01, -6.7195e-02, -1.4279e-01]]],


        [[[-1.3203e-40,  5.3123e-41, -1.6584e-41],
          [-8.9439e-41,  1.3357e-41,  5.4247e-41],
          [-6.5584e-41, -5.5011e-41,  6.4000e-41]],

         [[-1.3873e-40, -3.4752e-42, -1.2273e-40],
          [ 4.5221e-41, -3.1213e-41,  7.8676e-41],
          [ 5.8552e-41,  3.4878e-41,  1.5145e-40]],

         [[-4.5192e-42, -4.3540e-41, -1.0539e-40],
          [ 1.1796e-40,  3.0338e-42, -1.3080e-40],
          [-1.0238e-40, -9.5933e-41,  9.2382e-41]]],


        [[[ 5.3075e-02,  1.1594e-01, -7.8682e-02],
          [ 4.1757e-02,  1.9592e-01, -9.7886e-02],
          [ 1.1765e-01,  3.0616e-01,  2.8675e-01]],

         [[-1.9368e-01, -4.9727e-02, -1.7149e-01],
          [-3.0867e-01, -2.6688e-01, -2.6007e-01],
          [-2.4983e-01, -3.7155e-01,  3.0184e-02]],

         [[ 2.1539e-01,  7.2130e-02,  1.6991e-01],
          [ 1.9890e-01,  8.3726e-02,  2.0790e-02],
          [ 1.3854e-02,  8.8452e-02,  3.0876e-02]]],


        ...,


        [[[ 2.7999e-01,  6.0047e-02,  5.4977e-02],
          [ 2.5147e-01, -1.9267e-01, -3.8211e-02],
          [ 5.0178e-03, -1.1994e-01, -8.4415e-02]],

         [[-1.3174e-01, -8.4505e-02, -1.7688e-02],
          [-1.7082e-01, -2.5390e-01,  1.2390e-01],
          [-1.4187e-02,  2.3475e-01,  2.5286e-01]],

         [[-4.1179e-02, -7.8901e-02,  1.8143e-01],
          [-1.0575e-02, -2.5162e-01, -1.3191e-01],
          [-8.0047e-03, -8.2275e-02, -9.3987e-02]]],


        [[[ 1.1979e-01,  1.5208e-01,  2.7868e-01],
          [ 1.7211e-01,  1.6365e-01, -6.0811e-03],
          [-2.7126e-01, -1.6957e-01, -7.5056e-02]],

         [[ 7.1271e-02,  2.5156e-02, -1.5305e-01],
          [ 3.2646e-02, -8.2161e-02, -3.3964e-01],
          [-1.3506e-02,  1.2669e-01, -3.1692e-02]],

         [[-2.3549e-01, -8.8045e-02, -2.1479e-01],
          [-1.1662e-01,  8.4904e-02,  6.9459e-02],
          [ 1.6254e-01,  2.6075e-01,  2.1167e-01]]],


        [[[-1.7025e-40, -2.1799e-40,  2.9200e-40],
          [-5.0731e-40,  6.7094e-42,  3.6249e-40],
          [ 3.2439e-40, -4.6205e-41, -5.1960e-41]],

         [[ 4.1791e-40, -1.9521e-40,  4.7422e-40],
          [ 3.8885e-41, -3.0831e-40, -2.7881e-40],
          [-1.6051e-40,  5.2519e-40,  1.7614e-40]],

         [[-2.2469e-40, -3.7695e-41, -4.2228e-40],
          [ 1.0247e-40,  5.3770e-40, -9.0831e-41],
          [ 1.8268e-40,  1.9789e-40, -5.1147e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0015,  0.0109,  0.0183],
          [ 0.0114,  0.0149,  0.0240],
          [ 0.0103,  0.0102,  0.0076]],

         [[ 0.0054,  0.0127,  0.0163],
          [ 0.0118,  0.0136,  0.0195],
          [ 0.0092,  0.0087,  0.0046]],

         [[ 0.0223,  0.0221,  0.0235],
          [ 0.0268,  0.0241,  0.0293],
          [ 0.0182,  0.0162,  0.0133]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0467, -0.0135,  0.0047],
          [-0.0182,  0.0151,  0.0331],
          [-0.0052,  0.0087,  0.0337]],

         [[-0.0332, -0.0016,  0.0116],
          [-0.0162,  0.0185,  0.0360],
          [-0.0182,  0.0036,  0.0316]],

         [[-0.0327, -0.0016,  0.0040],
          [-0.0135,  0.0232,  0.0348],
          [-0.0191,  0.0025,  0.0283]]],


        ...,


        [[[-0.0021, -0.0009, -0.0074],
          [-0.0056,  0.0021, -0.0038],
          [ 0.0008,  0.0094,  0.0023]],

         [[-0.0083, -0.0055, -0.0114],
          [-0.0119, -0.0035, -0.0094],
          [-0.0052,  0.0037, -0.0028]],

         [[-0.0032,  0.0009, -0.0022],
          [-0.0087, -0.0005, -0.0044],
          [-0.0041,  0.0045, -0.0013]]],


        [[[ 0.0262,  0.0080,  0.0077],
          [ 0.0275,  0.0156,  0.0136],
          [ 0.0310,  0.0232,  0.0255]],

         [[ 0.0238,  0.0086,  0.0082],
          [ 0.0260,  0.0145,  0.0120],
          [ 0.0268,  0.0189,  0.0214]],

         [[ 0.0307,  0.0213,  0.0217],
          [ 0.0285,  0.0230,  0.0232],
          [ 0.0248,  0.0234,  0.0291]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2081]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 78 | Batch_idx: 0 |  Loss: (0.2674) | Acc: (91.00%) (117/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2379) | Acc: (91.00%) (1286/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2565) | Acc: (90.00%) (2435/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2576) | Acc: (90.00%) (3610/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2632) | Acc: (90.00%) (4763/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2601) | Acc: (90.00%) (5933/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2565) | Acc: (91.00%) (7112/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2532) | Acc: (91.00%) (8288/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2559) | Acc: (91.00%) (9440/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.2530) | Acc: (91.00%) (10621/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.2484) | Acc: (91.00%) (11814/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.2454) | Acc: (91.00%) (13010/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.2427) | Acc: (91.00%) (14202/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.2429) | Acc: (91.00%) (15376/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.2402) | Acc: (91.00%) (16570/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.2396) | Acc: (91.00%) (17743/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.2378) | Acc: (91.00%) (18933/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.2390) | Acc: (91.00%) (20105/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.2377) | Acc: (91.00%) (21288/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.2363) | Acc: (91.00%) (22477/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.2348) | Acc: (91.00%) (23661/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.2339) | Acc: (92.00%) (24849/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.2323) | Acc: (92.00%) (26046/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.2314) | Acc: (92.00%) (27244/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.2302) | Acc: (92.00%) (28434/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.2293) | Acc: (92.00%) (29622/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.2278) | Acc: (92.00%) (30826/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.2264) | Acc: (92.00%) (32024/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2254) | Acc: (92.00%) (33213/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2253) | Acc: (92.00%) (34389/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2245) | Acc: (92.00%) (35571/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2236) | Acc: (92.00%) (36767/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2231) | Acc: (92.00%) (37956/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2224) | Acc: (92.00%) (39156/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2216) | Acc: (92.00%) (40345/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2213) | Acc: (92.00%) (41537/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2204) | Acc: (92.00%) (42734/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2196) | Acc: (92.00%) (43927/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2188) | Acc: (92.00%) (45129/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2183) | Acc: (92.00%) (46280/50000)
# TEST : Loss: (0.3170) | Acc: (89.00%) (8968/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8292e-01, -2.2748e-01,  5.3561e-02],
          [-7.2284e-02,  3.0799e-01,  2.1576e-01],
          [ 1.0978e-01,  3.0711e-02, -6.6114e-02]],

         [[-2.3469e-01,  2.0795e-01,  1.9536e-01],
          [ 8.7701e-03,  3.5978e-01,  2.1906e-01],
          [ 2.0690e-01, -4.8923e-02,  1.3303e-01]],

         [[-2.0593e-01, -4.4044e-02, -6.2393e-02],
          [-2.5487e-01, -7.3666e-02, -7.2889e-02],
          [-1.8263e-01, -6.5480e-02, -1.3972e-01]]],


        [[[-3.8337e-41, -8.6857e-41,  5.0321e-42],
          [ 9.7923e-41, -1.1240e-41,  1.8829e-40],
          [ 9.6126e-41, -4.0881e-41, -1.2746e-40]],

         [[-1.0377e-40, -1.8086e-40, -8.8828e-41],
          [-1.7693e-41, -1.0077e-40, -1.4652e-40],
          [ 6.8713e-41, -2.1396e-41, -5.1550e-41]],

         [[-1.2245e-40,  1.0800e-40,  1.2803e-40],
          [ 2.6814e-41, -8.9795e-41,  1.4469e-40],
          [ 1.2589e-40,  2.9359e-41, -1.5379e-40]]],


        [[[ 5.2116e-02,  1.1306e-01, -8.2188e-02],
          [ 4.0763e-02,  1.9364e-01, -1.0066e-01],
          [ 1.1658e-01,  3.0447e-01,  2.8440e-01]],

         [[-1.9509e-01, -5.3074e-02, -1.7496e-01],
          [-3.0979e-01, -2.6913e-01, -2.6267e-01],
          [-2.5046e-01, -3.7275e-01,  2.8039e-02]],

         [[ 2.1253e-01,  6.7894e-02,  1.6617e-01],
          [ 1.9617e-01,  8.0070e-02,  1.7436e-02],
          [ 1.1960e-02,  8.5848e-02,  2.8456e-02]]],


        ...,


        [[[ 2.7897e-01,  6.0797e-02,  5.7216e-02],
          [ 2.5129e-01, -1.8975e-01, -3.6235e-02],
          [ 5.7286e-03, -1.2001e-01, -8.3618e-02]],

         [[-1.2823e-01, -8.1589e-02, -1.4206e-02],
          [-1.6508e-01, -2.4784e-01,  1.2503e-01],
          [-1.2964e-02,  2.3071e-01,  2.5045e-01]],

         [[-4.1979e-02, -7.9267e-02,  1.7926e-01],
          [-9.9776e-03, -2.4527e-01, -1.2997e-01],
          [-8.9549e-03, -8.4310e-02, -9.5049e-02]]],


        [[[ 1.1605e-01,  1.4995e-01,  2.7698e-01],
          [ 1.6649e-01,  1.6003e-01, -8.1995e-03],
          [-2.7590e-01, -1.7230e-01, -7.8320e-02]],

         [[ 6.8559e-02,  2.3787e-02, -1.5303e-01],
          [ 2.8463e-02, -8.4386e-02, -3.4042e-01],
          [-1.8102e-02,  1.2363e-01, -3.4577e-02]],

         [[-2.3737e-01, -8.9880e-02, -2.1520e-01],
          [-1.2020e-01,  8.1605e-02,  6.6827e-02],
          [ 1.5799e-01,  2.5737e-01,  2.0816e-01]]],


        [[[-3.2317e-41,  5.6570e-41, -2.5508e-40],
          [-3.7058e-40, -1.3096e-40,  5.0144e-40],
          [-8.9525e-41,  2.2907e-40, -1.8889e-40]],

         [[ 2.8115e-40, -4.7183e-40,  6.2227e-41],
          [-9.9171e-41, -1.7115e-40, -2.7984e-40],
          [ 2.5327e-40,  3.8899e-40,  1.7666e-40]],

         [[-2.2575e-40,  2.3775e-40, -2.8618e-40],
          [ 2.4064e-40,  1.2662e-40, -3.6655e-40],
          [ 3.2091e-40,  4.7387e-40, -1.4271e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1315]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0043]], device='cuda:0')

Epoch: 79 | Batch_idx: 0 |  Loss: (0.1268) | Acc: (94.00%) (121/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.1647) | Acc: (94.00%) (1333/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.1854) | Acc: (94.00%) (2528/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.1814) | Acc: (94.00%) (3730/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.1828) | Acc: (93.00%) (4928/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.1850) | Acc: (93.00%) (6121/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.1827) | Acc: (93.00%) (7333/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.1852) | Acc: (93.00%) (8529/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.1859) | Acc: (93.00%) (9720/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.1853) | Acc: (93.00%) (10926/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.1853) | Acc: (93.00%) (12127/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.1859) | Acc: (93.00%) (13322/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.1856) | Acc: (93.00%) (14523/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.1878) | Acc: (93.00%) (15721/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.1879) | Acc: (93.00%) (16921/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.1860) | Acc: (93.00%) (18129/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.1867) | Acc: (93.00%) (19319/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.1869) | Acc: (93.00%) (20517/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.1866) | Acc: (93.00%) (21713/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.1872) | Acc: (93.00%) (22907/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.1858) | Acc: (93.00%) (24119/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.1852) | Acc: (93.00%) (25325/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.1850) | Acc: (93.00%) (26531/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.1849) | Acc: (93.00%) (27729/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.1849) | Acc: (93.00%) (28932/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.1848) | Acc: (93.00%) (30134/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.1857) | Acc: (93.00%) (31326/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.1869) | Acc: (93.00%) (32519/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.1866) | Acc: (93.00%) (33724/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.1862) | Acc: (93.00%) (34933/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.1871) | Acc: (93.00%) (36113/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.1878) | Acc: (93.00%) (37308/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.1873) | Acc: (93.00%) (38515/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.1883) | Acc: (93.00%) (39699/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.1885) | Acc: (93.00%) (40901/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.1879) | Acc: (93.00%) (42119/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.1881) | Acc: (93.00%) (43314/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.1887) | Acc: (93.00%) (44502/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.1885) | Acc: (93.00%) (45698/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.1886) | Acc: (93.00%) (46855/50000)
# TEST : Loss: (0.3076) | Acc: (89.00%) (8991/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8212e-01, -2.2642e-01,  5.3295e-02],
          [-7.1955e-02,  3.0645e-01,  2.1461e-01],
          [ 1.0928e-01,  3.0562e-02, -6.5780e-02]],

         [[-2.3358e-01,  2.0693e-01,  1.9436e-01],
          [ 8.7273e-03,  3.5793e-01,  2.1789e-01],
          [ 2.0591e-01, -4.8679e-02,  1.3236e-01]],

         [[-2.0484e-01, -4.3818e-02, -6.2081e-02],
          [-2.5354e-01, -7.3294e-02, -7.2528e-02],
          [-1.8171e-01, -6.5157e-02, -1.3904e-01]]],


        [[[ 1.3699e-41, -7.4010e-41, -1.2006e-40],
          [-8.4294e-41,  1.2304e-40, -1.9242e-40],
          [ 4.6030e-41, -7.8904e-41,  1.7407e-40]],

         [[ 6.8539e-41,  1.1634e-40, -1.4957e-40],
          [ 9.3656e-41,  9.0593e-41,  5.1648e-41],
          [ 8.2806e-41,  3.4770e-41,  6.9458e-41]],

         [[-5.1904e-42, -5.9823e-41, -1.2137e-40],
          [-1.4638e-40,  6.6842e-41, -1.3972e-40],
          [ 1.4839e-40, -9.0224e-41, -3.4749e-41]]],


        [[[ 5.2026e-02,  1.1286e-01, -8.2037e-02],
          [ 4.0691e-02,  1.9330e-01, -1.0048e-01],
          [ 1.1637e-01,  3.0391e-01,  2.8387e-01]],

         [[-1.9473e-01, -5.2974e-02, -1.7462e-01],
          [-3.0918e-01, -2.6860e-01, -2.6215e-01],
          [-2.4997e-01, -3.7202e-01,  2.7984e-02]],

         [[ 2.1213e-01,  6.7761e-02,  1.6584e-01],
          [ 1.9577e-01,  7.9905e-02,  1.7400e-02],
          [ 1.1936e-02,  8.5672e-02,  2.8397e-02]]],


        ...,


        [[[ 2.7630e-01,  6.0187e-02,  5.6681e-02],
          [ 2.4870e-01, -1.8755e-01, -3.5861e-02],
          [ 5.6721e-03, -1.1873e-01, -8.2773e-02]],

         [[-1.2667e-01, -8.0473e-02, -1.4044e-02],
          [-1.6269e-01, -2.4329e-01,  1.2336e-01],
          [-1.2807e-02,  2.2755e-01,  2.4749e-01]],

         [[-4.1350e-02, -7.7802e-02,  1.7671e-01],
          [-9.7802e-03, -2.3722e-01, -1.2764e-01],
          [-8.8183e-03, -8.2753e-02, -9.3662e-02]]],


        [[[ 1.1548e-01,  1.4922e-01,  2.7574e-01],
          [ 1.6569e-01,  1.5926e-01, -8.1635e-03],
          [-2.7465e-01, -1.7153e-01, -7.7982e-02]],

         [[ 6.8237e-02,  2.3673e-02, -1.5230e-01],
          [ 2.8327e-02, -8.3980e-02, -3.3880e-01],
          [-1.8017e-02,  1.2306e-01, -3.4417e-02]],

         [[-2.3622e-01, -8.9430e-02, -2.1409e-01],
          [-1.1960e-01,  8.1196e-02,  6.6485e-02],
          [ 1.5723e-01,  2.5613e-01,  2.0713e-01]]],


        [[[ 1.0633e-40,  3.3295e-40, -5.3138e-40],
          [ 1.8291e-40, -1.3138e-40,  9.1226e-41],
          [-3.6699e-40,  2.2995e-40, -1.8944e-40]],

         [[-1.3341e-40, -3.3445e-40, -3.5245e-40],
          [-9.9534e-41,  1.0529e-40, -4.4701e-42],
          [ 3.9242e-40, -1.6340e-40,  3.9012e-41]],

         [[ 4.9523e-41,  2.3859e-40,  1.2725e-40],
          [ 1.0340e-40, -4.2546e-40, -2.2983e-40],
          [ 1.8362e-40,  3.3697e-40, -1.4314e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1431]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0069]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 80 | Batch_idx: 0 |  Loss: (0.2067) | Acc: (93.00%) (120/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.1744) | Acc: (94.00%) (1331/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.1929) | Acc: (93.00%) (2510/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2242) | Acc: (92.00%) (3669/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2351) | Acc: (92.00%) (4831/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2456) | Acc: (91.00%) (6000/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2534) | Acc: (91.00%) (7150/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2559) | Acc: (91.00%) (8313/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2545) | Acc: (91.00%) (9494/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2543) | Acc: (91.00%) (10671/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2547) | Acc: (91.00%) (11833/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2548) | Acc: (91.00%) (13011/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2582) | Acc: (91.00%) (14174/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2612) | Acc: (91.00%) (15325/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2628) | Acc: (91.00%) (16476/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2642) | Acc: (91.00%) (17638/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2629) | Acc: (91.00%) (18815/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2625) | Acc: (91.00%) (19977/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2640) | Acc: (91.00%) (21134/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2640) | Acc: (91.00%) (22304/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2628) | Acc: (91.00%) (23478/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2621) | Acc: (91.00%) (24654/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2633) | Acc: (91.00%) (25812/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2622) | Acc: (91.00%) (26985/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2625) | Acc: (91.00%) (28145/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2631) | Acc: (91.00%) (29296/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2633) | Acc: (91.00%) (30448/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2645) | Acc: (91.00%) (31608/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2650) | Acc: (91.00%) (32762/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2658) | Acc: (91.00%) (33911/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2674) | Acc: (90.00%) (35059/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2676) | Acc: (90.00%) (36214/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2682) | Acc: (90.00%) (37371/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2684) | Acc: (90.00%) (38531/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2691) | Acc: (90.00%) (39684/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2685) | Acc: (90.00%) (40846/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2691) | Acc: (90.00%) (41995/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2689) | Acc: (90.00%) (43165/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2683) | Acc: (90.00%) (44343/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2682) | Acc: (90.00%) (45462/50000)
# TEST : Loss: (0.3893) | Acc: (87.00%) (8785/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8449e-01, -2.3121e-01,  4.8820e-02],
          [-7.4037e-02,  3.0565e-01,  2.1825e-01],
          [ 9.7231e-02,  2.1629e-02, -5.7710e-02]],

         [[-2.2848e-01,  2.1018e-01,  2.0313e-01],
          [ 1.2545e-02,  3.6330e-01,  2.3064e-01],
          [ 2.0001e-01, -5.0709e-02,  1.4582e-01]],

         [[-2.0576e-01, -5.0177e-02, -6.3968e-02],
          [-2.5828e-01, -7.9033e-02, -7.5364e-02],
          [-1.9180e-01, -7.4942e-02, -1.3902e-01]]],


        [[[-2.0726e-40,  5.2959e-41,  5.4278e-41],
          [-1.0091e-40,  1.4773e-40,  1.8159e-40],
          [-1.2605e-41,  1.0037e-40,  3.2907e-41]],

         [[-2.4217e-41, -1.5033e-40,  8.0306e-41],
          [-7.6749e-41,  1.0792e-40, -1.7411e-40],
          [-1.3766e-40,  5.9394e-41,  1.7888e-40]],

         [[ 1.6132e-40,  4.1239e-41,  1.7193e-41],
          [ 4.1738e-41, -7.0197e-41, -1.6629e-40],
          [-1.2241e-40,  7.9683e-41,  7.8177e-41]]],


        [[[ 6.6726e-02,  1.1984e-01, -8.2109e-02],
          [ 5.1983e-02,  1.9915e-01, -9.9293e-02],
          [ 1.3317e-01,  3.1285e-01,  2.8716e-01]],

         [[-1.8330e-01, -4.9078e-02, -1.7923e-01],
          [-3.0632e-01, -2.7317e-01, -2.6829e-01],
          [-2.3997e-01, -3.7186e-01,  2.5203e-02]],

         [[ 2.2033e-01,  7.2377e-02,  1.6164e-01],
          [ 1.9897e-01,  7.9854e-02,  1.2566e-02],
          [ 1.8512e-02,  8.3286e-02,  1.9996e-02]]],


        ...,


        [[[ 2.5576e-01,  3.6916e-02,  3.6920e-02],
          [ 2.2097e-01, -2.2092e-01, -6.8298e-02],
          [ 1.9270e-03, -1.3470e-01, -1.0347e-01]],

         [[-1.3168e-01, -9.1616e-02, -1.9886e-02],
          [-1.8295e-01, -2.6716e-01,  9.9213e-02],
          [-8.4240e-03,  2.2120e-01,  2.3678e-01]],

         [[-4.8061e-02, -8.6789e-02,  1.6551e-01],
          [-3.4915e-02, -2.5759e-01, -1.5176e-01],
          [-1.2351e-02, -8.5731e-02, -1.0258e-01]]],


        [[[ 1.1089e-01,  1.4129e-01,  2.6530e-01],
          [ 1.5715e-01,  1.4874e-01, -1.3152e-02],
          [-2.9146e-01, -1.8962e-01, -8.9741e-02]],

         [[ 7.1395e-02,  2.0876e-02, -1.6543e-01],
          [ 2.7595e-02, -8.9058e-02, -3.4571e-01],
          [-2.2047e-02,  1.1541e-01, -3.8852e-02]],

         [[-2.3447e-01, -9.1437e-02, -2.1942e-01],
          [-1.1770e-01,  8.1786e-02,  6.9201e-02],
          [ 1.5957e-01,  2.5394e-01,  2.0830e-01]]],


        [[[ 1.0659e-40,  3.3362e-40, -2.5702e-40],
          [ 5.9982e-40,  6.7206e-42, -4.6009e-40],
          [-2.2897e-40, -4.6202e-41, -5.1952e-41]],

         [[-4.1117e-40,  8.1201e-41, -3.5345e-40],
          [ 3.8887e-41,  2.4430e-40,  2.7247e-40],
          [ 1.1584e-40, -5.7976e-40, -9.9435e-41]],

         [[ 3.2639e-40, -3.7694e-41,  4.0451e-40],
          [-1.7313e-40, -5.6500e-40,  1.8467e-40],
          [-9.3021e-41, -7.7873e-41, -5.1091e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0216, -0.0161, -0.0208],
          [-0.0252, -0.0228, -0.0238],
          [-0.0274, -0.0271, -0.0271]],

         [[-0.0217, -0.0150, -0.0180],
          [-0.0246, -0.0216, -0.0210],
          [-0.0265, -0.0260, -0.0248]],

         [[-0.0229, -0.0166, -0.0189],
          [-0.0249, -0.0224, -0.0214],
          [-0.0266, -0.0274, -0.0263]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0578, -0.0560, -0.0394],
          [-0.0328, -0.0331, -0.0230],
          [-0.0206, -0.0301, -0.0276]],

         [[-0.0527, -0.0518, -0.0347],
          [-0.0339, -0.0351, -0.0242],
          [-0.0239, -0.0318, -0.0278]],

         [[-0.0441, -0.0424, -0.0248],
          [-0.0309, -0.0309, -0.0154],
          [-0.0207, -0.0260, -0.0169]]],


        ...,


        [[[ 0.0021,  0.0026, -0.0001],
          [ 0.0011,  0.0024,  0.0017],
          [ 0.0041,  0.0057,  0.0049]],

         [[ 0.0019,  0.0014, -0.0013],
          [-0.0004,  0.0004,  0.0001],
          [ 0.0019,  0.0034,  0.0038]],

         [[ 0.0005, -0.0002, -0.0029],
          [-0.0011, -0.0009, -0.0018],
          [ 0.0005,  0.0013,  0.0012]]],


        [[[ 0.0036, -0.0004, -0.0007],
          [-0.0077, -0.0089, -0.0048],
          [-0.0107, -0.0143, -0.0108]],

         [[-0.0046, -0.0077, -0.0061],
          [-0.0139, -0.0142, -0.0083],
          [-0.0161, -0.0184, -0.0129]],

         [[-0.0049, -0.0083, -0.0097],
          [-0.0122, -0.0142, -0.0115],
          [-0.0159, -0.0197, -0.0170]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1409]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 81 | Batch_idx: 0 |  Loss: (0.1642) | Acc: (95.00%) (122/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2331) | Acc: (92.00%) (1298/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2288) | Acc: (92.00%) (2475/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2229) | Acc: (92.00%) (3668/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2277) | Acc: (92.00%) (4836/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2230) | Acc: (92.00%) (6030/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2215) | Acc: (92.00%) (7218/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2200) | Acc: (92.00%) (8402/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2252) | Acc: (92.00%) (9565/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2291) | Acc: (92.00%) (10729/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2311) | Acc: (92.00%) (11902/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2314) | Acc: (92.00%) (13086/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2320) | Acc: (92.00%) (14269/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2317) | Acc: (92.00%) (15454/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2332) | Acc: (92.00%) (16632/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2315) | Acc: (92.00%) (17811/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2316) | Acc: (92.00%) (18984/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2320) | Acc: (92.00%) (20155/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2306) | Acc: (92.00%) (21339/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2312) | Acc: (92.00%) (22524/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2314) | Acc: (92.00%) (23693/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2313) | Acc: (92.00%) (24878/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2301) | Acc: (92.00%) (26072/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2301) | Acc: (92.00%) (27251/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2293) | Acc: (92.00%) (28439/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2286) | Acc: (92.00%) (29621/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2282) | Acc: (92.00%) (30806/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2286) | Acc: (92.00%) (31988/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2284) | Acc: (92.00%) (33162/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2288) | Acc: (92.00%) (34346/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2282) | Acc: (92.00%) (35534/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2285) | Acc: (92.00%) (36702/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2283) | Acc: (92.00%) (37883/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2278) | Acc: (92.00%) (39067/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2271) | Acc: (92.00%) (40256/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2271) | Acc: (92.00%) (41434/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2269) | Acc: (92.00%) (42625/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2268) | Acc: (92.00%) (43812/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2268) | Acc: (92.00%) (44992/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2273) | Acc: (92.00%) (46130/50000)
# TEST : Loss: (0.3688) | Acc: (88.00%) (8827/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8009e-01, -2.2941e-01,  4.6843e-02],
          [-6.5978e-02,  3.1288e-01,  2.2060e-01],
          [ 9.9684e-02,  2.3803e-02, -5.6606e-02]],

         [[-2.2882e-01,  2.0150e-01,  1.9000e-01],
          [ 1.2134e-02,  3.5751e-01,  2.1766e-01],
          [ 1.9285e-01, -6.2005e-02,  1.3132e-01]],

         [[-2.0953e-01, -6.1739e-02, -7.8889e-02],
          [-2.6594e-01, -9.2232e-02, -9.3881e-02],
          [-2.0561e-01, -9.4048e-02, -1.5929e-01]]],


        [[[-6.0651e-41, -2.0898e-41,  1.0309e-40],
          [ 1.6341e-40, -1.4236e-40, -1.4287e-40],
          [-1.5476e-41,  1.1838e-40, -2.1106e-40]],

         [[-2.8729e-41,  1.2230e-40, -1.0822e-40],
          [ 3.0771e-41,  6.4547e-41,  1.7838e-40],
          [-6.2843e-41, -1.4581e-41,  9.7704e-41]],

         [[-7.4141e-41, -8.7225e-41,  2.1806e-41],
          [ 4.6344e-41, -3.9581e-41,  1.3253e-40],
          [ 8.5492e-41,  4.9271e-41, -1.6058e-40]]],


        [[[ 4.9312e-02,  1.2009e-01, -7.7489e-02],
          [ 3.8061e-02,  2.0128e-01, -8.9265e-02],
          [ 1.2901e-01,  3.1543e-01,  3.0704e-01]],

         [[-1.9420e-01, -4.6603e-02, -1.6677e-01],
          [-3.1863e-01, -2.7224e-01, -2.5273e-01],
          [-2.4174e-01, -3.7150e-01,  4.6666e-02]],

         [[ 2.0956e-01,  7.5613e-02,  1.7233e-01],
          [ 1.9222e-01,  8.6196e-02,  2.9727e-02],
          [ 1.9040e-02,  8.5731e-02,  3.6608e-02]]],


        ...,


        [[[ 2.7158e-01,  4.9776e-02,  5.1793e-02],
          [ 2.3348e-01, -2.1157e-01, -6.1061e-02],
          [ 6.0204e-03, -1.3835e-01, -1.0466e-01]],

         [[-1.2958e-01, -9.4069e-02, -1.8552e-02],
          [-1.7908e-01, -2.7063e-01,  8.8150e-02],
          [-1.8853e-02,  2.0136e-01,  2.1813e-01]],

         [[-4.2394e-02, -7.9289e-02,  1.8134e-01],
          [-2.3628e-02, -2.3709e-01, -1.4632e-01],
          [-1.1926e-02, -8.9287e-02, -1.0751e-01]]],


        [[[ 1.1802e-01,  1.5167e-01,  2.7733e-01],
          [ 1.6899e-01,  1.5715e-01, -4.0643e-03],
          [-2.7781e-01, -1.7851e-01, -8.2640e-02]],

         [[ 7.8982e-02,  2.6168e-02, -1.5697e-01],
          [ 3.8876e-02, -8.1345e-02, -3.3586e-01],
          [-1.2856e-02,  1.2607e-01, -2.9560e-02]],

         [[-2.3539e-01, -9.8182e-02, -2.2216e-01],
          [-1.1232e-01,  7.9770e-02,  6.8724e-02],
          [ 1.6679e-01,  2.6188e-01,  2.1219e-01]]],


        [[[-3.2308e-41,  5.6561e-41,  2.9595e-40],
          [ 4.6160e-40,  1.4546e-40, -5.9957e-40],
          [ 1.8780e-40, -3.2368e-40,  8.6394e-41]],

         [[-2.7291e-40,  3.5942e-40,  6.2233e-41],
          [ 1.7785e-40,  1.0584e-40,  2.7305e-40],
          [-3.0085e-40, -4.4186e-40, -9.9725e-41]],

         [[ 3.2697e-40, -3.1525e-40,  2.6663e-40],
          [-3.1219e-40, -1.4984e-40,  4.6239e-40],
          [-2.3208e-40, -3.5574e-40,  1.3359e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0162, -0.0233, -0.0129],
          [-0.0052, -0.0078,  0.0056],
          [-0.0095, -0.0045,  0.0094]],

         [[-0.0017, -0.0071,  0.0004],
          [ 0.0063,  0.0079,  0.0196],
          [-0.0023,  0.0070,  0.0191]],

         [[ 0.0062, -0.0017,  0.0057],
          [ 0.0108,  0.0091,  0.0230],
          [ 0.0035,  0.0092,  0.0252]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0078,  0.0223,  0.0212],
          [-0.0059,  0.0108,  0.0054],
          [-0.0068,  0.0071,  0.0057]],

         [[ 0.0214,  0.0328,  0.0273],
          [ 0.0131,  0.0224,  0.0077],
          [ 0.0157,  0.0214,  0.0114]],

         [[ 0.0307,  0.0405,  0.0342],
          [ 0.0238,  0.0326,  0.0179],
          [ 0.0286,  0.0329,  0.0222]]],


        ...,


        [[[ 0.0006, -0.0022, -0.0112],
          [-0.0036, -0.0009, -0.0085],
          [-0.0046,  0.0006, -0.0006]],

         [[ 0.0000, -0.0050, -0.0133],
          [-0.0037, -0.0027, -0.0093],
          [-0.0039,  0.0002,  0.0008]],

         [[ 0.0030, -0.0007, -0.0069],
          [-0.0009, -0.0002, -0.0050],
          [-0.0011,  0.0013,  0.0021]]],


        [[[-0.0064,  0.0009,  0.0030],
          [-0.0070,  0.0022,  0.0067],
          [-0.0003,  0.0030,  0.0067]],

         [[-0.0162, -0.0098, -0.0065],
          [-0.0140, -0.0048, -0.0015],
          [-0.0049, -0.0048, -0.0026]],

         [[-0.0291, -0.0241, -0.0202],
          [-0.0277, -0.0188, -0.0149],
          [-0.0209, -0.0188, -0.0164]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1405]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 82 | Batch_idx: 0 |  Loss: (0.2308) | Acc: (90.00%) (116/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2306) | Acc: (92.00%) (1300/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2375) | Acc: (92.00%) (2478/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2389) | Acc: (92.00%) (3658/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2446) | Acc: (92.00%) (4834/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2487) | Acc: (91.00%) (5994/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2470) | Acc: (91.00%) (7170/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2422) | Acc: (91.00%) (8358/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2390) | Acc: (92.00%) (9545/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2371) | Acc: (92.00%) (10721/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2360) | Acc: (92.00%) (11907/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2340) | Acc: (92.00%) (13099/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2335) | Acc: (92.00%) (14282/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2309) | Acc: (92.00%) (15477/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2289) | Acc: (92.00%) (16671/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2259) | Acc: (92.00%) (17878/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2246) | Acc: (92.00%) (19076/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2246) | Acc: (92.00%) (20253/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2219) | Acc: (92.00%) (21455/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2209) | Acc: (92.00%) (22654/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2184) | Acc: (92.00%) (23859/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2181) | Acc: (92.00%) (25057/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2174) | Acc: (92.00%) (26249/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2171) | Acc: (92.00%) (27437/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2163) | Acc: (92.00%) (28634/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2145) | Acc: (92.00%) (29846/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2138) | Acc: (92.00%) (31045/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2137) | Acc: (92.00%) (32227/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2137) | Acc: (92.00%) (33411/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2126) | Acc: (92.00%) (34612/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2120) | Acc: (92.00%) (35811/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2111) | Acc: (92.00%) (37008/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2108) | Acc: (92.00%) (38205/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2106) | Acc: (92.00%) (39388/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2110) | Acc: (92.00%) (40573/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2105) | Acc: (92.00%) (41764/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2094) | Acc: (92.00%) (42972/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2090) | Acc: (93.00%) (44174/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2090) | Acc: (93.00%) (45361/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2089) | Acc: (93.00%) (46502/50000)
# TEST : Loss: (0.3078) | Acc: (90.00%) (9026/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7953e-01, -2.2709e-01,  4.6648e-02],
          [-6.7284e-02,  3.1135e-01,  2.1716e-01],
          [ 9.7022e-02,  2.1847e-02, -6.0628e-02]],

         [[-2.2962e-01,  1.9999e-01,  1.8783e-01],
          [ 8.6422e-03,  3.5363e-01,  2.1331e-01],
          [ 1.8829e-01, -6.4950e-02,  1.2626e-01]],

         [[-2.1073e-01, -6.2812e-02, -8.0412e-02],
          [-2.6819e-01, -9.4643e-02, -9.7432e-02],
          [-2.0841e-01, -9.6845e-02, -1.6330e-01]]],


        [[[-1.1949e-40, -7.3565e-41, -1.9763e-40],
          [ 1.0036e-40,  1.7556e-40, -6.9350e-41],
          [-6.1923e-41,  6.3486e-41,  4.6306e-41]],

         [[ 1.1194e-40, -1.2841e-40,  1.3029e-40],
          [ 3.5856e-41, -1.2356e-40, -1.9182e-40],
          [ 6.3371e-41,  3.2939e-41, -2.3413e-40]],

         [[ 1.4087e-40, -1.8329e-40, -1.2214e-40],
          [-9.7076e-41,  4.7028e-42,  1.5551e-40],
          [-4.5125e-41,  5.2633e-42, -1.8753e-40]]],


        [[[ 4.5525e-02,  1.1611e-01, -7.9829e-02],
          [ 3.3460e-02,  1.9610e-01, -9.2876e-02],
          [ 1.2366e-01,  3.0957e-01,  3.0271e-01]],

         [[-1.9681e-01, -4.9122e-02, -1.6793e-01],
          [-3.2254e-01, -2.7647e-01, -2.5556e-01],
          [-2.4685e-01, -3.7678e-01,  4.2599e-02]],

         [[ 2.0703e-01,  7.3868e-02,  1.7138e-01],
          [ 1.8846e-01,  8.2284e-02,  2.7183e-02],
          [ 1.4357e-02,  8.0373e-02,  3.3063e-02]]],


        ...,


        [[[ 2.6840e-01,  4.7395e-02,  4.9811e-02],
          [ 2.3357e-01, -2.0796e-01, -5.9649e-02],
          [ 7.8422e-03, -1.3633e-01, -1.0432e-01]],

         [[-1.3061e-01, -9.6827e-02, -2.1536e-02],
          [-1.7613e-01, -2.6702e-01,  8.5901e-02],
          [-1.8448e-02,  1.9797e-01,  2.1379e-01]],

         [[-4.5010e-02, -8.3394e-02,  1.7417e-01],
          [-2.3110e-02, -2.3205e-01, -1.4684e-01],
          [-1.2045e-02, -8.9021e-02, -1.0887e-01]]],


        [[[ 1.1221e-01,  1.4587e-01,  2.7205e-01],
          [ 1.6407e-01,  1.5181e-01, -9.2318e-03],
          [-2.8080e-01, -1.8155e-01, -8.6236e-02]],

         [[ 7.3888e-02,  2.1776e-02, -1.6022e-01],
          [ 3.5274e-02, -8.4699e-02, -3.3900e-01],
          [-1.5710e-02,  1.2342e-01, -3.1931e-02]],

         [[-2.3728e-01, -1.0047e-01, -2.2366e-01],
          [-1.1343e-01,  7.7522e-02,  6.5829e-02],
          [ 1.6482e-01,  2.6017e-01,  2.1080e-01]]],


        [[[-1.7160e-40, -2.2154e-40,  5.7400e-40],
          [-9.4986e-41,  1.4570e-40, -1.8489e-40],
          [ 4.6650e-40, -3.2419e-40,  8.6704e-41]],

         [[ 1.4421e-40,  2.2084e-40,  4.7943e-40],
          [ 1.7806e-40, -1.7228e-40, -4.4505e-42],
          [-4.4044e-40,  1.1410e-40,  3.9012e-41]],

         [[ 4.9516e-41, -3.1572e-40, -1.4987e-40],
          [-1.7368e-40,  4.0596e-40,  3.2418e-40],
          [-9.3539e-41, -2.1742e-40,  1.3384e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1430]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0071]], device='cuda:0')

Epoch: 83 | Batch_idx: 0 |  Loss: (0.2992) | Acc: (90.00%) (116/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2284) | Acc: (92.00%) (1303/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2109) | Acc: (93.00%) (2506/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.1986) | Acc: (93.00%) (3713/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.1980) | Acc: (93.00%) (4912/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2038) | Acc: (93.00%) (6098/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.1995) | Acc: (93.00%) (7302/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.1997) | Acc: (93.00%) (8492/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.1990) | Acc: (93.00%) (9684/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.1982) | Acc: (93.00%) (10871/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.1974) | Acc: (93.00%) (12071/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.1989) | Acc: (93.00%) (13261/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.1983) | Acc: (93.00%) (14462/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.1949) | Acc: (93.00%) (15679/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.1939) | Acc: (93.00%) (16877/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.1930) | Acc: (93.00%) (18075/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.1935) | Acc: (93.00%) (19268/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.1932) | Acc: (93.00%) (20467/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.1919) | Acc: (93.00%) (21673/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.1913) | Acc: (93.00%) (22871/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.1921) | Acc: (93.00%) (24060/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.1916) | Acc: (93.00%) (25261/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.1934) | Acc: (93.00%) (26441/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.1935) | Acc: (93.00%) (27643/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.1934) | Acc: (93.00%) (28848/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.1921) | Acc: (93.00%) (30051/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.1916) | Acc: (93.00%) (31249/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.1917) | Acc: (93.00%) (32448/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.1914) | Acc: (93.00%) (33643/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.1920) | Acc: (93.00%) (34839/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.1921) | Acc: (93.00%) (36034/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.1917) | Acc: (93.00%) (37232/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.1925) | Acc: (93.00%) (38416/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.1928) | Acc: (93.00%) (39600/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.1925) | Acc: (93.00%) (40796/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.1927) | Acc: (93.00%) (41992/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.1927) | Acc: (93.00%) (43183/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.1929) | Acc: (93.00%) (44377/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.1927) | Acc: (93.00%) (45579/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.1927) | Acc: (93.00%) (46739/50000)
# TEST : Loss: (0.3010) | Acc: (90.00%) (9028/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7877e-01, -2.2606e-01,  4.6427e-02],
          [-6.6985e-02,  3.0983e-01,  2.1606e-01],
          [ 9.6588e-02,  2.1740e-02, -6.0327e-02]],

         [[-2.2859e-01,  1.9906e-01,  1.8694e-01],
          [ 8.6023e-03,  3.5192e-01,  2.1228e-01],
          [ 1.8743e-01, -6.4637e-02,  1.2566e-01]],

         [[-2.0970e-01, -6.2511e-02, -8.0042e-02],
          [-2.6690e-01, -9.4201e-02, -9.6994e-02],
          [-2.0744e-01, -9.6395e-02, -1.6257e-01]]],


        [[[-1.6876e-40,  1.1523e-40,  1.4879e-40],
          [-1.0698e-40,  1.4727e-40,  5.0447e-42],
          [-1.9048e-41, -3.8660e-41, -1.6566e-40]],

         [[ 4.5586e-41,  2.5708e-41, -4.2811e-41],
          [-1.2583e-40, -1.7415e-40, -1.3539e-40],
          [-1.1849e-40, -7.8896e-41, -2.4158e-40]],

         [[ 1.3704e-40,  2.1540e-40, -5.5001e-41],
          [ 1.4851e-40, -8.5800e-41,  2.7229e-40],
          [ 1.7726e-40,  9.7278e-41,  2.2542e-40]]],


        [[[ 4.5441e-02,  1.1589e-01, -7.9674e-02],
          [ 3.3398e-02,  1.9573e-01, -9.2700e-02],
          [ 1.2343e-01,  3.0899e-01,  3.0213e-01]],

         [[-1.9642e-01, -4.9021e-02, -1.6758e-01],
          [-3.2187e-01, -2.7590e-01, -2.5503e-01],
          [-2.4634e-01, -3.7602e-01,  4.2514e-02]],

         [[ 2.0661e-01,  7.3714e-02,  1.7102e-01],
          [ 1.8806e-01,  8.2108e-02,  2.7126e-02],
          [ 1.4327e-02,  8.0206e-02,  3.2995e-02]]],


        ...,


        [[[ 2.6566e-01,  4.6877e-02,  4.9299e-02],
          [ 2.3089e-01, -2.0523e-01, -5.8964e-02],
          [ 7.7568e-03, -1.3470e-01, -1.0319e-01]],

         [[-1.2899e-01, -9.5446e-02, -2.1275e-02],
          [-1.7344e-01, -2.6163e-01,  8.4664e-02],
          [-1.8212e-02,  1.9502e-01,  2.1113e-01]],

         [[-4.4322e-02, -8.1805e-02,  1.7159e-01],
          [-2.2634e-02, -2.2387e-01, -1.4401e-01],
          [-1.1853e-02, -8.7240e-02, -1.0719e-01]]],


        [[[ 1.1169e-01,  1.4519e-01,  2.7087e-01],
          [ 1.6329e-01,  1.5110e-01, -9.1919e-03],
          [-2.7953e-01, -1.8073e-01, -8.5861e-02]],

         [[ 7.3529e-02,  2.1669e-02, -1.5944e-01],
          [ 3.5099e-02, -8.4284e-02, -3.3736e-01],
          [-1.5635e-02,  1.2283e-01, -3.1780e-02]],

         [[-2.3608e-01, -9.9955e-02, -2.2249e-01],
          [-1.1286e-01,  7.7132e-02,  6.5490e-02],
          [ 1.6401e-01,  2.5890e-01,  2.0974e-01]]],


        [[[-1.7175e-40, -2.2193e-40,  2.9706e-40],
          [-5.1342e-40,  6.7094e-42,  3.7049e-40],
          [ 3.2755e-40, -4.6234e-41, -5.1950e-41]],

         [[ 4.2308e-40, -1.9690e-40,  4.7999e-40],
          [ 3.8892e-41, -3.1178e-40, -2.8285e-40],
          [-1.6225e-40,  5.3224e-40,  1.7820e-40]],

         [[-2.2884e-40, -3.7685e-41, -4.2846e-40],
          [ 1.0450e-40,  5.4576e-40, -9.2917e-41],
          [ 1.8469e-40,  1.9985e-40, -5.1147e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1306]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0041]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 84 | Batch_idx: 0 |  Loss: (0.2254) | Acc: (91.00%) (117/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.1943) | Acc: (93.00%) (1315/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2023) | Acc: (93.00%) (2507/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2025) | Acc: (93.00%) (3696/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2132) | Acc: (92.00%) (4863/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2202) | Acc: (92.00%) (6042/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2232) | Acc: (92.00%) (7215/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2287) | Acc: (92.00%) (8369/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2333) | Acc: (91.00%) (9537/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2377) | Acc: (91.00%) (10693/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2445) | Acc: (91.00%) (11841/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2483) | Acc: (91.00%) (13004/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2503) | Acc: (91.00%) (14168/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2506) | Acc: (91.00%) (15338/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2538) | Acc: (91.00%) (16487/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2586) | Acc: (91.00%) (17620/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2612) | Acc: (91.00%) (18771/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2613) | Acc: (91.00%) (19928/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2607) | Acc: (91.00%) (21103/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2597) | Acc: (91.00%) (22285/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2601) | Acc: (91.00%) (23449/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2602) | Acc: (91.00%) (24614/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2613) | Acc: (91.00%) (25769/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2618) | Acc: (91.00%) (26933/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2619) | Acc: (91.00%) (28093/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2627) | Acc: (91.00%) (29246/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2627) | Acc: (91.00%) (30410/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2633) | Acc: (91.00%) (31575/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2626) | Acc: (91.00%) (32750/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2618) | Acc: (91.00%) (33923/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2609) | Acc: (91.00%) (35103/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2614) | Acc: (91.00%) (36259/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2625) | Acc: (91.00%) (37411/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2632) | Acc: (91.00%) (38567/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2625) | Acc: (91.00%) (39738/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2616) | Acc: (91.00%) (40910/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2612) | Acc: (91.00%) (42085/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2610) | Acc: (91.00%) (43249/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2614) | Acc: (91.00%) (44406/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2615) | Acc: (91.00%) (45534/50000)
# TEST : Loss: (0.3641) | Acc: (88.00%) (8882/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.6973e-01, -2.2310e-01,  5.7363e-02],
          [-6.1584e-02,  3.1538e-01,  2.2605e-01],
          [ 1.0173e-01,  3.2275e-02, -4.6187e-02]],

         [[-2.1310e-01,  2.1135e-01,  2.0442e-01],
          [ 1.6070e-02,  3.6063e-01,  2.2142e-01],
          [ 1.8800e-01, -5.7200e-02,  1.2976e-01]],

         [[-1.9874e-01, -5.6845e-02, -6.8090e-02],
          [-2.6898e-01, -9.7155e-02, -9.3265e-02],
          [-2.1651e-01, -9.7873e-02, -1.5726e-01]]],


        [[[-1.9694e-40, -1.3380e-40,  1.7155e-40],
          [ 1.0272e-40, -2.8767e-41, -1.9729e-40],
          [-2.3783e-41, -4.3564e-41,  2.4203e-41]],

         [[-1.4695e-40,  1.6194e-40, -4.7630e-41],
          [-2.1174e-40, -1.6860e-40,  2.1989e-40],
          [ 1.2171e-40,  7.9115e-41,  2.6223e-40]],

         [[-1.5074e-41,  1.9394e-42,  2.0726e-40],
          [-6.1157e-41,  4.3302e-41,  1.4294e-40],
          [-6.1146e-41, -1.2924e-40, -7.0683e-41]]],


        [[[ 5.6571e-02,  1.1570e-01, -8.8369e-02],
          [ 3.6522e-02,  1.8662e-01, -1.1098e-01],
          [ 1.3039e-01,  3.1281e-01,  3.0086e-01]],

         [[-1.7935e-01, -4.5099e-02, -1.6617e-01],
          [-3.1800e-01, -2.8635e-01, -2.6593e-01],
          [-2.3623e-01, -3.7145e-01,  4.5040e-02]],

         [[ 2.2822e-01,  8.4658e-02,  1.7291e-01],
          [ 2.0127e-01,  8.2732e-02,  1.9470e-02],
          [ 3.4631e-02,  9.2888e-02,  3.4710e-02]]],


        ...,


        [[[ 2.5897e-01,  5.3012e-02,  5.7891e-02],
          [ 2.1900e-01, -2.1834e-01, -5.7222e-02],
          [ 8.2686e-03, -1.3826e-01, -9.9223e-02]],

         [[-1.2893e-01, -8.6305e-02, -9.5524e-03],
          [-1.6381e-01, -2.6114e-01,  9.2437e-02],
          [ 3.3179e-03,  2.0747e-01,  2.2361e-01]],

         [[-6.1703e-02, -8.7909e-02,  1.6930e-01],
          [-3.0061e-02, -2.4506e-01, -1.4524e-01],
          [-8.1760e-03, -9.6334e-02, -1.1001e-01]]],


        [[[ 1.1427e-01,  1.4650e-01,  2.7012e-01],
          [ 1.6936e-01,  1.5589e-01, -1.3620e-02],
          [-2.7534e-01, -1.8125e-01, -8.9779e-02]],

         [[ 6.7065e-02,  1.3000e-02, -1.6477e-01],
          [ 3.1935e-02, -9.0555e-02, -3.4807e-01],
          [-1.5760e-02,  1.1438e-01, -3.9768e-02]],

         [[-2.4905e-01, -1.0966e-01, -2.2586e-01],
          [-1.1873e-01,  7.6481e-02,  6.2915e-02],
          [ 1.6180e-01,  2.5620e-01,  2.0248e-01]]],


        [[[-3.2310e-41,  5.6544e-41, -2.5925e-40],
          [-3.7437e-40, -1.3264e-40,  5.1026e-40],
          [-9.0806e-41,  2.3246e-40, -1.9108e-40]],

         [[ 2.8402e-40, -4.7601e-40,  6.2227e-41],
          [-1.0059e-40, -1.7257e-40, -2.8317e-40],
          [ 2.5607e-40,  3.9334e-40,  1.7837e-40]],

         [[-2.2918e-40,  2.4106e-40, -2.8958e-40],
          [ 2.4402e-40,  1.2828e-40, -3.7176e-40],
          [ 3.2421e-40,  4.7878e-40, -1.4445e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0163,  0.0223,  0.0247],
          [ 0.0209,  0.0241,  0.0216],
          [ 0.0356,  0.0268,  0.0236]],

         [[ 0.0113,  0.0152,  0.0208],
          [ 0.0119,  0.0145,  0.0121],
          [ 0.0288,  0.0163,  0.0126]],

         [[ 0.0157,  0.0153,  0.0205],
          [ 0.0196,  0.0181,  0.0182],
          [ 0.0364,  0.0239,  0.0219]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0390, -0.0505, -0.0313],
          [-0.0413, -0.0445, -0.0125],
          [-0.0576, -0.0421, -0.0151]],

         [[-0.0475, -0.0431, -0.0247],
          [-0.0680, -0.0518, -0.0206],
          [-0.0937, -0.0627, -0.0315]],

         [[-0.0597, -0.0643, -0.0533],
          [-0.0787, -0.0725, -0.0423],
          [-0.0973, -0.0683, -0.0338]]],


        ...,


        [[[-0.0093, -0.0041, -0.0013],
          [-0.0086, -0.0036, -0.0007],
          [-0.0118, -0.0083, -0.0051]],

         [[-0.0073, -0.0018,  0.0011],
          [-0.0059, -0.0009,  0.0014],
          [-0.0080, -0.0043, -0.0019]],

         [[-0.0048, -0.0001,  0.0023],
          [-0.0041,  0.0002,  0.0018],
          [-0.0070, -0.0036, -0.0019]]],


        [[[-0.0238, -0.0259, -0.0260],
          [-0.0453, -0.0494, -0.0361],
          [-0.0611, -0.0632, -0.0506]],

         [[-0.0278, -0.0220, -0.0209],
          [-0.0436, -0.0479, -0.0330],
          [-0.0547, -0.0578, -0.0376]],

         [[-0.0135, -0.0092, -0.0070],
          [-0.0241, -0.0305, -0.0192],
          [-0.0362, -0.0415, -0.0257]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1335]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 85 | Batch_idx: 0 |  Loss: (0.1852) | Acc: (92.00%) (118/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2264) | Acc: (91.00%) (1294/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2174) | Acc: (92.00%) (2486/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2224) | Acc: (91.00%) (3645/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2162) | Acc: (92.00%) (4833/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2198) | Acc: (92.00%) (6007/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2205) | Acc: (92.00%) (7189/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2140) | Acc: (92.00%) (8392/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2137) | Acc: (92.00%) (9583/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2131) | Acc: (92.00%) (10774/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2134) | Acc: (92.00%) (11952/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2152) | Acc: (92.00%) (13129/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2169) | Acc: (92.00%) (14305/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2195) | Acc: (92.00%) (15480/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2183) | Acc: (92.00%) (16671/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2192) | Acc: (92.00%) (17845/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2197) | Acc: (92.00%) (19022/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2212) | Acc: (92.00%) (20196/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2227) | Acc: (92.00%) (21355/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2233) | Acc: (92.00%) (22539/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2239) | Acc: (92.00%) (23716/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2237) | Acc: (92.00%) (24893/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2237) | Acc: (92.00%) (26076/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2225) | Acc: (92.00%) (27268/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2221) | Acc: (92.00%) (28459/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2211) | Acc: (92.00%) (29653/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2219) | Acc: (92.00%) (30838/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2229) | Acc: (92.00%) (32005/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2223) | Acc: (92.00%) (33194/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2226) | Acc: (92.00%) (34366/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2232) | Acc: (92.00%) (35544/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2226) | Acc: (92.00%) (36733/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2226) | Acc: (92.00%) (37916/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2224) | Acc: (92.00%) (39093/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2222) | Acc: (92.00%) (40277/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2227) | Acc: (92.00%) (41449/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2226) | Acc: (92.00%) (42627/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2237) | Acc: (92.00%) (43785/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2240) | Acc: (92.00%) (44960/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2241) | Acc: (92.00%) (46105/50000)
# TEST : Loss: (0.3361) | Acc: (89.00%) (8925/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7530e-01, -2.2077e-01,  6.0544e-02],
          [-6.1571e-02,  3.2054e-01,  2.3896e-01],
          [ 9.9895e-02,  3.6359e-02, -3.8476e-02]],

         [[-2.2552e-01,  2.0845e-01,  2.0208e-01],
          [ 1.0431e-02,  3.6153e-01,  2.2811e-01],
          [ 1.8327e-01, -5.6014e-02,  1.3104e-01]],

         [[-2.0522e-01, -5.5400e-02, -7.0996e-02],
          [-2.6886e-01, -9.2334e-02, -8.7221e-02],
          [-2.1560e-01, -9.3804e-02, -1.5306e-01]]],


        [[[ 1.6059e-42,  1.1627e-40, -9.5098e-41],
          [-3.2720e-41,  8.3327e-41, -1.8926e-40],
          [ 1.1889e-40,  1.0613e-40,  2.7837e-41]],

         [[ 6.0634e-41,  1.0642e-40,  9.8127e-41],
          [ 1.7023e-40,  1.1902e-40, -3.3600e-40],
          [-1.1987e-40,  9.1800e-41, -1.5836e-40]],

         [[-1.3805e-40, -8.0149e-41, -1.5421e-40],
          [-1.0923e-40,  8.9600e-41,  1.6482e-40],
          [-7.1330e-41,  9.6572e-41,  1.7186e-40]]],


        [[[ 6.3866e-02,  1.2273e-01, -8.0503e-02],
          [ 4.6937e-02,  2.0036e-01, -9.4026e-02],
          [ 1.3206e-01,  3.1652e-01,  3.1169e-01]],

         [[-1.7953e-01, -4.5166e-02, -1.6451e-01],
          [-3.1798e-01, -2.8367e-01, -2.5584e-01],
          [-2.4147e-01, -3.7475e-01,  5.1703e-02]],

         [[ 2.2462e-01,  8.5668e-02,  1.7457e-01],
          [ 1.9881e-01,  8.6483e-02,  2.8326e-02],
          [ 2.7615e-02,  8.9353e-02,  4.0167e-02]]],


        ...,


        [[[ 2.6019e-01,  5.4809e-02,  6.4102e-02],
          [ 2.1639e-01, -2.1604e-01, -5.4783e-02],
          [ 5.8883e-03, -1.3509e-01, -9.1401e-02]],

         [[-1.2925e-01, -8.7714e-02, -4.2919e-03],
          [-1.6650e-01, -2.5643e-01,  9.5161e-02],
          [-2.7765e-03,  2.1022e-01,  2.3475e-01]],

         [[-6.3066e-02, -9.1306e-02,  1.7029e-01],
          [-3.1822e-02, -2.3569e-01, -1.4322e-01],
          [-8.6526e-03, -8.4930e-02, -9.5598e-02]]],


        [[[ 1.0371e-01,  1.4503e-01,  2.6663e-01],
          [ 1.6145e-01,  1.5320e-01, -2.0054e-02],
          [-2.7245e-01, -1.7880e-01, -8.7174e-02]],

         [[ 6.1704e-02,  1.3769e-02, -1.6945e-01],
          [ 2.8012e-02, -9.2028e-02, -3.5648e-01],
          [-1.2181e-02,  1.1807e-01, -3.7031e-02]],

         [[-2.5182e-01, -1.0736e-01, -2.2913e-01],
          [-1.1778e-01,  8.1067e-02,  5.9251e-02],
          [ 1.7028e-01,  2.6977e-01,  2.1508e-01]]],


        [[[ 1.0737e-40,  3.3559e-40, -5.3828e-40],
          [ 1.8396e-40, -1.3278e-40,  9.3074e-41],
          [-3.7020e-40,  2.3273e-40, -1.9125e-40]],

         [[-1.3455e-40, -3.3674e-40, -3.5638e-40],
          [-1.0071e-40,  1.0648e-40, -4.4449e-42],
          [ 3.9590e-40, -1.6463e-40,  3.9021e-41]],

         [[ 4.9525e-41,  2.4133e-40,  1.2862e-40],
          [ 1.0481e-40, -4.2961e-40, -2.3271e-40],
          [ 1.8495e-40,  3.3966e-40, -1.4458e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0440,  0.0323,  0.0397],
          [ 0.0469,  0.0361,  0.0332],
          [ 0.0508,  0.0370,  0.0359]],

         [[ 0.0356,  0.0203,  0.0230],
          [ 0.0398,  0.0257,  0.0185],
          [ 0.0436,  0.0283,  0.0228]],

         [[ 0.0322,  0.0205,  0.0162],
          [ 0.0350,  0.0255,  0.0122],
          [ 0.0355,  0.0234,  0.0115]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0353, -0.0168, -0.0389],
          [ 0.0184,  0.0200, -0.0057],
          [ 0.0400,  0.0264,  0.0153]],

         [[-0.0486, -0.0320, -0.0536],
          [-0.0010,  0.0011, -0.0228],
          [ 0.0261,  0.0134,  0.0037]],

         [[-0.0610, -0.0495, -0.0681],
          [-0.0176, -0.0189, -0.0365],
          [ 0.0122, -0.0040, -0.0094]]],


        ...,


        [[[-0.0038, -0.0051, -0.0059],
          [-0.0034, -0.0044, -0.0024],
          [-0.0109, -0.0080, -0.0051]],

         [[-0.0012, -0.0028, -0.0037],
          [-0.0015, -0.0020, -0.0008],
          [-0.0078, -0.0046, -0.0025]],

         [[ 0.0015,  0.0002, -0.0005],
          [ 0.0002, -0.0005,  0.0011],
          [-0.0069, -0.0039, -0.0009]]],


        [[[-0.0349, -0.0298, -0.0288],
          [-0.0297, -0.0306, -0.0263],
          [-0.0278, -0.0299, -0.0237]],

         [[-0.0275, -0.0254, -0.0234],
          [-0.0253, -0.0222, -0.0132],
          [-0.0237, -0.0219, -0.0129]],

         [[-0.0224, -0.0181, -0.0116],
          [-0.0190, -0.0127, -0.0010],
          [-0.0181, -0.0145, -0.0040]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1331]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 86 | Batch_idx: 0 |  Loss: (0.2190) | Acc: (95.00%) (122/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2011) | Acc: (93.00%) (1316/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2102) | Acc: (92.00%) (2498/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2240) | Acc: (92.00%) (3674/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2363) | Acc: (92.00%) (4836/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2371) | Acc: (92.00%) (6012/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2361) | Acc: (92.00%) (7197/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2368) | Acc: (92.00%) (8372/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2399) | Acc: (92.00%) (9539/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2403) | Acc: (92.00%) (10718/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2397) | Acc: (91.00%) (11889/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2369) | Acc: (91.00%) (13071/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2331) | Acc: (92.00%) (14270/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2305) | Acc: (92.00%) (15456/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2298) | Acc: (92.00%) (16632/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2277) | Acc: (92.00%) (17822/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2272) | Acc: (92.00%) (19005/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2277) | Acc: (92.00%) (20190/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2263) | Acc: (92.00%) (21378/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2251) | Acc: (92.00%) (22575/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2251) | Acc: (92.00%) (23755/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2233) | Acc: (92.00%) (24955/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2218) | Acc: (92.00%) (26150/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2199) | Acc: (92.00%) (27348/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2187) | Acc: (92.00%) (28546/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2181) | Acc: (92.00%) (29726/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2166) | Acc: (92.00%) (30928/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2152) | Acc: (92.00%) (32126/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2150) | Acc: (92.00%) (33319/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2152) | Acc: (92.00%) (34505/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2150) | Acc: (92.00%) (35697/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2145) | Acc: (92.00%) (36897/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2133) | Acc: (92.00%) (38102/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2131) | Acc: (92.00%) (39284/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2121) | Acc: (92.00%) (40480/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2114) | Acc: (92.00%) (41674/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2109) | Acc: (92.00%) (42870/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2111) | Acc: (92.00%) (44055/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2107) | Acc: (92.00%) (45255/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2103) | Acc: (92.00%) (46408/50000)
# TEST : Loss: (0.3091) | Acc: (90.00%) (9022/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7268e-01, -2.1759e-01,  6.1769e-02],
          [-6.0734e-02,  3.2032e-01,  2.3877e-01],
          [ 9.8744e-02,  3.6038e-02, -3.8880e-02]],

         [[-2.2208e-01,  2.1120e-01,  2.0408e-01],
          [ 1.1468e-02,  3.6193e-01,  2.2889e-01],
          [ 1.8226e-01, -5.5676e-02,  1.3062e-01]],

         [[-2.0271e-01, -5.3642e-02, -6.9670e-02],
          [-2.6746e-01, -9.1669e-02, -8.6383e-02],
          [-2.1543e-01, -9.3965e-02, -1.5268e-01]]],


        [[[-2.1755e-40, -4.4176e-41, -1.9369e-40],
          [-3.8575e-41,  2.3094e-40, -2.1650e-40],
          [-1.6173e-40, -1.8762e-40,  3.0651e-41]],

         [[-1.4990e-40,  1.2366e-40, -1.8828e-40],
          [-6.4799e-41, -1.3341e-40,  1.6112e-40],
          [ 3.5348e-41,  1.0328e-40,  2.4641e-40]],

         [[ 1.1885e-40, -1.3884e-40,  1.8158e-40],
          [-8.1486e-41,  5.4680e-41, -2.7211e-40],
          [ 1.8229e-40,  1.5469e-40, -1.9394e-40]]],


        [[[ 6.4185e-02,  1.2300e-01, -7.8759e-02],
          [ 4.6942e-02,  2.0083e-01, -9.2485e-02],
          [ 1.2962e-01,  3.1565e-01,  3.1096e-01]],

         [[-1.7939e-01, -4.4953e-02, -1.6300e-01],
          [-3.1767e-01, -2.8262e-01, -2.5402e-01],
          [-2.4346e-01, -3.7470e-01,  5.1408e-02]],

         [[ 2.2472e-01,  8.6355e-02,  1.7549e-01],
          [ 1.9864e-01,  8.7518e-02,  2.9413e-02],
          [ 2.5332e-02,  8.8912e-02,  3.9533e-02]]],


        ...,


        [[[ 2.5887e-01,  5.5163e-02,  6.5528e-02],
          [ 2.1598e-01, -2.1146e-01, -5.1575e-02],
          [ 8.2710e-03, -1.3236e-01, -8.8812e-02]],

         [[-1.2823e-01, -8.6918e-02, -2.7458e-03],
          [-1.6287e-01, -2.4953e-01,  9.6517e-02],
          [-3.7702e-04,  2.0851e-01,  2.3349e-01]],

         [[-6.3594e-02, -9.1384e-02,  1.6862e-01],
          [-3.0191e-02, -2.2644e-01, -1.3937e-01],
          [-5.8372e-03, -8.2548e-02, -9.3778e-02]]],


        [[[ 1.0269e-01,  1.4379e-01,  2.6453e-01],
          [ 1.5912e-01,  1.5144e-01, -2.1186e-02],
          [-2.7427e-01, -1.8063e-01, -8.9212e-02]],

         [[ 6.0999e-02,  1.3015e-02, -1.7021e-01],
          [ 2.6718e-02, -9.3237e-02, -3.5736e-01],
          [-1.4666e-02,  1.1475e-01, -3.9874e-02]],

         [[-2.5099e-01, -1.0718e-01, -2.2973e-01],
          [-1.1799e-01,  7.9725e-02,  5.6469e-02],
          [ 1.6766e-01,  2.6630e-01,  2.1106e-01]]],


        [[[ 1.0746e-40,  3.3580e-40, -2.5986e-40],
          [ 6.0326e-40,  6.7178e-42, -4.6456e-40],
          [-2.3071e-40, -4.6243e-41, -5.1950e-41]],

         [[-4.1403e-40,  8.2141e-41, -3.5670e-40],
          [ 3.8893e-41,  2.4628e-40,  2.7478e-40],
          [ 1.1681e-40, -5.8376e-40, -1.0058e-40]],

         [[ 3.2872e-40, -3.7680e-41,  4.0795e-40],
          [-1.7428e-40, -5.6958e-40,  1.8583e-40],
          [-9.4177e-41, -7.8995e-41, -5.1063e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0590]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0136]], device='cuda:0')

Epoch: 87 | Batch_idx: 0 |  Loss: (0.2186) | Acc: (93.00%) (120/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2047) | Acc: (93.00%) (1312/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.1865) | Acc: (93.00%) (2512/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.1971) | Acc: (93.00%) (3694/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.1967) | Acc: (93.00%) (4883/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.1912) | Acc: (93.00%) (6093/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.1878) | Acc: (93.00%) (7298/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.1908) | Acc: (93.00%) (8485/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.1909) | Acc: (93.00%) (9679/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.1879) | Acc: (93.00%) (10893/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.1874) | Acc: (93.00%) (12091/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.1896) | Acc: (93.00%) (13276/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.1885) | Acc: (93.00%) (14483/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.1882) | Acc: (93.00%) (15687/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.1900) | Acc: (93.00%) (16873/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.1904) | Acc: (93.00%) (18070/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.1900) | Acc: (93.00%) (19262/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.1900) | Acc: (93.00%) (20463/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.1898) | Acc: (93.00%) (21669/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.1907) | Acc: (93.00%) (22860/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.1902) | Acc: (93.00%) (24062/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.1909) | Acc: (93.00%) (25251/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.1913) | Acc: (93.00%) (26441/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.1914) | Acc: (93.00%) (27647/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.1910) | Acc: (93.00%) (28849/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.1919) | Acc: (93.00%) (30033/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.1911) | Acc: (93.00%) (31241/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.1916) | Acc: (93.00%) (32427/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.1907) | Acc: (93.00%) (33637/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.1898) | Acc: (93.00%) (34847/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.1903) | Acc: (93.00%) (36041/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.1907) | Acc: (93.00%) (37238/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.1904) | Acc: (93.00%) (38446/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.1908) | Acc: (93.00%) (39626/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.1904) | Acc: (93.00%) (40823/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.1902) | Acc: (93.00%) (42018/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.1909) | Acc: (93.00%) (43200/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.1906) | Acc: (93.00%) (44393/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.1903) | Acc: (93.00%) (45596/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.1905) | Acc: (93.00%) (46748/50000)
# TEST : Loss: (0.3019) | Acc: (90.00%) (9023/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7200e-01, -2.1667e-01,  6.1492e-02],
          [-6.0480e-02,  3.1887e-01,  2.3763e-01],
          [ 9.8341e-02,  3.5879e-02, -3.8702e-02]],

         [[-2.2114e-01,  2.1026e-01,  2.0315e-01],
          [ 1.1417e-02,  3.6024e-01,  2.2779e-01],
          [ 1.8148e-01, -5.5423e-02,  1.3001e-01]],

         [[-2.0176e-01, -5.3393e-02, -6.9356e-02],
          [-2.6619e-01, -9.1241e-02, -8.5990e-02],
          [-2.1444e-01, -9.3532e-02, -1.5199e-01]]],


        [[[-2.4798e-40, -5.0527e-41,  1.8860e-41],
          [ 1.5342e-40,  1.1341e-40, -1.4525e-40],
          [ 2.0189e-40,  1.4067e-40, -1.3127e-40]],

         [[-1.6824e-40,  9.0867e-41,  1.8062e-40],
          [ 2.2055e-41,  1.7418e-42,  7.9950e-41],
          [ 1.3972e-40, -3.7321e-41, -2.6156e-40]],

         [[-1.9629e-41, -1.5765e-40,  2.0306e-40],
          [ 8.4568e-42,  8.0154e-42,  2.2059e-40],
          [ 5.2920e-41,  1.7343e-40, -2.2236e-40]]],


        [[[ 6.4060e-02,  1.2275e-01, -7.8600e-02],
          [ 4.6851e-02,  2.0043e-01, -9.2303e-02],
          [ 1.2937e-01,  3.1503e-01,  3.1036e-01]],

         [[-1.7902e-01, -4.4856e-02, -1.6265e-01],
          [-3.1699e-01, -2.8200e-01, -2.5348e-01],
          [-2.4294e-01, -3.7392e-01,  5.1303e-02]],

         [[ 2.2424e-01,  8.6166e-02,  1.7510e-01],
          [ 1.9820e-01,  8.7321e-02,  2.9348e-02],
          [ 2.5278e-02,  8.8722e-02,  3.9450e-02]]],


        ...,


        [[[ 2.5617e-01,  5.4541e-02,  6.4852e-02],
          [ 2.1341e-01, -2.0842e-01, -5.0955e-02],
          [ 8.1789e-03, -1.3071e-01, -8.7803e-02]],

         [[-1.2659e-01, -8.5624e-02, -2.7126e-03],
          [-1.6031e-01, -2.4361e-01,  9.5078e-02],
          [-3.7207e-04,  2.0525e-01,  2.3045e-01]],

         [[-6.2580e-02, -8.9600e-02,  1.6614e-01],
          [-2.9545e-02, -2.1708e-01, -1.3668e-01],
          [-5.7388e-03, -8.0804e-02, -9.2268e-02]]],


        [[[ 1.0223e-01,  1.4315e-01,  2.6339e-01],
          [ 1.5839e-01,  1.5076e-01, -2.1093e-02],
          [-2.7306e-01, -1.7984e-01, -8.8828e-02]],

         [[ 6.0717e-02,  1.2954e-02, -1.6938e-01],
          [ 2.6591e-02, -9.2785e-02, -3.5562e-01],
          [-1.4598e-02,  1.1422e-01, -3.9688e-02]],

         [[-2.4974e-01, -1.0663e-01, -2.2850e-01],
          [-1.1739e-01,  7.9312e-02,  5.6168e-02],
          [ 1.6683e-01,  2.6498e-01,  2.0999e-01]]],


        [[[-3.2290e-41,  5.6540e-41,  2.9831e-40],
          [ 4.6370e-40,  1.4644e-40, -6.0449e-40],
          [ 1.8854e-40, -3.2563e-40,  8.7625e-41]],

         [[-2.7449e-40,  3.6176e-40,  6.2215e-41],
          [ 1.7866e-40,  1.0667e-40,  2.7497e-40],
          [-3.0244e-40, -4.4432e-40, -1.0069e-40]],

         [[ 3.2891e-40, -3.1709e-40,  2.6855e-40],
          [-3.1410e-40, -1.5080e-40,  4.6532e-40],
          [-2.3397e-40, -3.5853e-40,  1.3460e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0693]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0026]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2358) | Acc: (93.00%) (120/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.1992) | Acc: (93.00%) (1318/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2052) | Acc: (92.00%) (2497/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2157) | Acc: (92.00%) (3666/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2248) | Acc: (91.00%) (4825/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2344) | Acc: (91.00%) (5985/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2411) | Acc: (91.00%) (7145/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2484) | Acc: (91.00%) (8292/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2520) | Acc: (91.00%) (9449/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2557) | Acc: (91.00%) (10601/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2558) | Acc: (91.00%) (11766/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2592) | Acc: (90.00%) (12920/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2610) | Acc: (90.00%) (14080/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2610) | Acc: (90.00%) (15243/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2623) | Acc: (90.00%) (16395/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2592) | Acc: (90.00%) (17583/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2617) | Acc: (90.00%) (18732/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2617) | Acc: (90.00%) (19902/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2639) | Acc: (90.00%) (21053/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2627) | Acc: (90.00%) (22239/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2629) | Acc: (90.00%) (23403/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2637) | Acc: (90.00%) (24568/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2641) | Acc: (90.00%) (25737/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2631) | Acc: (91.00%) (26911/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2641) | Acc: (90.00%) (28063/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2635) | Acc: (90.00%) (29233/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2632) | Acc: (90.00%) (30400/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2625) | Acc: (91.00%) (31570/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2621) | Acc: (91.00%) (32744/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2617) | Acc: (91.00%) (33915/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2630) | Acc: (91.00%) (35065/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2607) | Acc: (91.00%) (36260/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2611) | Acc: (91.00%) (37430/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2602) | Acc: (91.00%) (38604/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2600) | Acc: (91.00%) (39780/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2604) | Acc: (91.00%) (40928/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2601) | Acc: (91.00%) (42103/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2596) | Acc: (91.00%) (43270/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2590) | Acc: (91.00%) (44450/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2586) | Acc: (91.00%) (45570/50000)
# TEST : Loss: (0.3194) | Acc: (89.00%) (8938/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7095e-01, -2.2073e-01,  5.7168e-02],
          [-5.5979e-02,  3.2131e-01,  2.3692e-01],
          [ 1.0471e-01,  3.7751e-02, -3.7384e-02]],

         [[-2.1097e-01,  2.1452e-01,  2.0476e-01],
          [ 2.6635e-02,  3.7062e-01,  2.3014e-01],
          [ 1.9543e-01, -4.9070e-02,  1.3097e-01]],

         [[-2.0011e-01, -5.6108e-02, -7.4079e-02],
          [-2.6076e-01, -9.2228e-02, -9.0580e-02],
          [-2.1511e-01, -1.0210e-01, -1.5836e-01]]],


        [[[-1.6719e-40,  1.7134e-40, -1.4507e-40],
          [-5.0026e-41, -4.0807e-41,  7.7534e-42],
          [-1.5366e-40, -7.2706e-41, -2.7020e-40]],

         [[-1.3075e-40, -1.1733e-41,  1.4405e-40],
          [ 1.3386e-40,  1.7488e-40, -2.0016e-40],
          [ 4.5377e-41,  1.7139e-41, -4.7591e-41]],

         [[-1.9647e-40, -1.1756e-40, -2.3526e-40],
          [ 1.2372e-40,  6.9822e-41, -2.2297e-40],
          [-2.2714e-40,  1.3385e-40,  3.0113e-40]]],


        [[[ 4.4124e-02,  1.1532e-01, -7.7293e-02],
          [ 3.4197e-02,  1.9971e-01, -9.4058e-02],
          [ 1.1969e-01,  3.0913e-01,  3.0562e-01]],

         [[-1.9736e-01, -5.2578e-02, -1.6297e-01],
          [-3.3218e-01, -2.8673e-01, -2.5980e-01],
          [-2.5192e-01, -3.8077e-01,  4.3789e-02]],

         [[ 2.1453e-01,  9.0214e-02,  1.8204e-01],
          [ 1.9418e-01,  9.5945e-02,  2.9002e-02],
          [ 2.5943e-02,  8.9820e-02,  3.1604e-02]]],


        ...,


        [[[ 2.6269e-01,  5.3582e-02,  6.3897e-02],
          [ 2.0940e-01, -2.1954e-01, -5.9714e-02],
          [-9.2093e-03, -1.4232e-01, -9.7400e-02]],

         [[-1.1079e-01, -7.8721e-02,  5.0434e-04],
          [-1.5067e-01, -2.3770e-01,  9.3581e-02],
          [-6.7775e-03,  2.0385e-01,  2.3217e-01]],

         [[-4.9886e-02, -8.6991e-02,  1.6828e-01],
          [-3.0774e-02, -2.1765e-01, -1.4008e-01],
          [-1.9450e-02, -8.0365e-02, -8.7937e-02]]],


        [[[ 1.1575e-01,  1.5670e-01,  2.7640e-01],
          [ 1.7016e-01,  1.6401e-01, -5.8923e-03],
          [-2.7502e-01, -1.7345e-01, -7.6927e-02]],

         [[ 6.9667e-02,  2.3953e-02, -1.5566e-01],
          [ 3.4872e-02, -8.0692e-02, -3.4003e-01],
          [-1.9302e-02,  1.1978e-01, -2.8889e-02]],

         [[-2.4819e-01, -1.0483e-01, -2.2325e-01],
          [-1.1985e-01,  8.4592e-02,  6.6994e-02],
          [ 1.5532e-01,  2.7094e-01,  2.2017e-01]]],


        [[[-1.7216e-40, -2.2304e-40,  5.7788e-40],
          [-9.5605e-41,  1.4652e-40, -1.8589e-40],
          [ 4.6832e-40, -3.2578e-40,  8.7730e-41]],

         [[ 1.4488e-40,  2.2211e-40,  4.8160e-40],
          [ 1.7873e-40, -1.7293e-40, -4.4407e-42],
          [-4.4240e-40,  1.1477e-40,  3.9005e-41]],

         [[ 4.9525e-41, -3.1725e-40, -1.5061e-40],
          [-1.7448e-40,  4.0825e-40,  3.2579e-40],
          [-9.4335e-41, -2.1894e-40,  1.3468e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0064, -0.0134, -0.0105],
          [-0.0103, -0.0122, -0.0092],
          [-0.0076, -0.0039, -0.0051]],

         [[-0.0114, -0.0173, -0.0139],
          [-0.0143, -0.0155, -0.0121],
          [-0.0110, -0.0071, -0.0085]],

         [[-0.0138, -0.0175, -0.0158],
          [-0.0173, -0.0169, -0.0150],
          [-0.0157, -0.0104, -0.0127]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0654,  0.0406,  0.0112],
          [ 0.0458,  0.0218, -0.0033],
          [ 0.0019, -0.0125, -0.0051]],

         [[ 0.0522,  0.0275, -0.0017],
          [ 0.0338,  0.0116, -0.0088],
          [-0.0055, -0.0165, -0.0031]],

         [[ 0.0320,  0.0142, -0.0046],
          [ 0.0158,  0.0021, -0.0094],
          [-0.0143, -0.0177,  0.0000]]],


        ...,


        [[[ 0.0034,  0.0062,  0.0060],
          [ 0.0035,  0.0030,  0.0038],
          [ 0.0075,  0.0066,  0.0064]],

         [[ 0.0037,  0.0064,  0.0077],
          [ 0.0022,  0.0012,  0.0032],
          [ 0.0058,  0.0044,  0.0049]],

         [[ 0.0022,  0.0042,  0.0046],
          [ 0.0015,  0.0004,  0.0015],
          [ 0.0048,  0.0032,  0.0025]]],


        [[[-0.0059, -0.0032,  0.0005],
          [-0.0007,  0.0053,  0.0031],
          [-0.0047, -0.0003,  0.0007]],

         [[-0.0026,  0.0001,  0.0034],
          [ 0.0028,  0.0064,  0.0053],
          [-0.0008,  0.0013,  0.0029]],

         [[-0.0128, -0.0095, -0.0052],
          [-0.0077, -0.0030, -0.0035],
          [-0.0096, -0.0059, -0.0038]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0713]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 89 | Batch_idx: 0 |  Loss: (0.1955) | Acc: (95.00%) (122/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2170) | Acc: (93.00%) (1311/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2231) | Acc: (92.00%) (2491/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2089) | Acc: (93.00%) (3699/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2100) | Acc: (93.00%) (4886/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2070) | Acc: (93.00%) (6072/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2064) | Acc: (92.00%) (7255/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2072) | Acc: (92.00%) (8432/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2071) | Acc: (92.00%) (9626/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2055) | Acc: (92.00%) (10827/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2061) | Acc: (92.00%) (12013/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2066) | Acc: (92.00%) (13192/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2060) | Acc: (92.00%) (14379/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2053) | Acc: (92.00%) (15564/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2059) | Acc: (92.00%) (16752/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2065) | Acc: (92.00%) (17940/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2063) | Acc: (92.00%) (19117/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2066) | Acc: (92.00%) (20302/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2066) | Acc: (92.00%) (21499/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2070) | Acc: (92.00%) (22691/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2076) | Acc: (92.00%) (23882/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2084) | Acc: (92.00%) (25063/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2104) | Acc: (92.00%) (26234/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2124) | Acc: (92.00%) (27401/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2133) | Acc: (92.00%) (28578/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2132) | Acc: (92.00%) (29765/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2130) | Acc: (92.00%) (30964/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2126) | Acc: (92.00%) (32158/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2125) | Acc: (92.00%) (33342/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2127) | Acc: (92.00%) (34518/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2121) | Acc: (92.00%) (35708/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2128) | Acc: (92.00%) (36886/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2132) | Acc: (92.00%) (38075/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2144) | Acc: (92.00%) (39240/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2147) | Acc: (92.00%) (40424/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2150) | Acc: (92.00%) (41606/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2163) | Acc: (92.00%) (42762/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2166) | Acc: (92.00%) (43947/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2179) | Acc: (92.00%) (45108/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2175) | Acc: (92.00%) (46254/50000)
# TEST : Loss: (0.3906) | Acc: (87.00%) (8765/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8436e-01, -2.2882e-01,  4.2896e-02],
          [-5.8466e-02,  3.2183e-01,  2.3258e-01],
          [ 1.0399e-01,  3.3217e-02, -4.2946e-02]],

         [[-2.2812e-01,  2.0232e-01,  1.8644e-01],
          [ 1.7759e-02,  3.6431e-01,  2.1922e-01],
          [ 1.8539e-01, -6.2900e-02,  1.1896e-01]],

         [[-2.1111e-01, -6.2168e-02, -8.3405e-02],
          [-2.6793e-01, -9.5113e-02, -9.5463e-02],
          [-2.2604e-01, -1.1430e-01, -1.6569e-01]]],


        [[[ 2.2925e-42,  6.4720e-41, -2.8751e-40],
          [ 1.3476e-40,  1.4656e-40,  2.0039e-40],
          [ 7.6835e-41,  4.3669e-41,  2.3960e-40]],

         [[-1.7555e-41,  1.1723e-40,  1.5939e-40],
          [-1.0254e-40,  3.2393e-40, -2.2322e-40],
          [ 4.7462e-41,  8.4982e-41,  8.4947e-41]],

         [[-2.2560e-41,  2.1104e-42,  3.1621e-40],
          [ 2.0151e-40,  8.0014e-41,  2.7904e-40],
          [ 3.1682e-40, -1.8158e-40, -2.8072e-40]]],


        [[[ 4.4469e-02,  1.1073e-01, -8.3269e-02],
          [ 3.3929e-02,  2.0098e-01, -9.6331e-02],
          [ 1.2557e-01,  3.1305e-01,  3.1002e-01]],

         [[-1.9413e-01, -5.5963e-02, -1.6549e-01],
          [-3.3311e-01, -2.8731e-01, -2.5904e-01],
          [-2.4690e-01, -3.7759e-01,  5.0349e-02]],

         [[ 2.2020e-01,  8.8289e-02,  1.7754e-01],
          [ 2.0306e-01,  1.0371e-01,  3.3533e-02],
          [ 3.7268e-02,  9.7303e-02,  3.8626e-02]]],


        ...,


        [[[ 2.7071e-01,  4.3390e-02,  5.3623e-02],
          [ 2.1572e-01, -2.2051e-01, -6.2564e-02],
          [ 7.1118e-03, -1.3591e-01, -8.8349e-02]],

         [[-1.1125e-01, -9.7237e-02, -1.4317e-02],
          [-1.5812e-01, -2.5588e-01,  7.8961e-02],
          [ 2.2941e-04,  2.0160e-01,  2.3399e-01]],

         [[-4.8678e-02, -1.0055e-01,  1.5881e-01],
          [-3.4430e-02, -2.2035e-01, -1.4502e-01],
          [-4.9875e-03, -6.6298e-02, -7.4464e-02]]],


        [[[ 1.0070e-01,  1.5576e-01,  2.7780e-01],
          [ 1.6655e-01,  1.6580e-01, -2.7199e-03],
          [-2.7430e-01, -1.7040e-01, -7.7684e-02]],

         [[ 5.0268e-02,  1.5692e-02, -1.6257e-01],
          [ 3.0881e-02, -8.2669e-02, -3.4314e-01],
          [-1.6521e-02,  1.2602e-01, -2.9774e-02]],

         [[-2.6431e-01, -1.1274e-01, -2.2647e-01],
          [-1.2584e-01,  7.9224e-02,  6.3305e-02],
          [ 1.5764e-01,  2.7468e-01,  2.1604e-01]]],


        [[[-1.7219e-40, -2.2316e-40,  2.9865e-40],
          [-5.1540e-40,  6.7459e-42,  3.7302e-40],
          [ 3.2856e-40, -4.6239e-41, -5.1946e-41]],

         [[ 4.2470e-40, -1.9745e-40,  4.8178e-40],
          [ 3.8890e-41, -3.1286e-40, -2.8412e-40],
          [-1.6277e-40,  5.3446e-40,  1.7884e-40]],

         [[-2.3015e-40, -3.7675e-41, -4.3035e-40],
          [ 1.0514e-40,  5.4828e-40, -9.3575e-41],
          [ 1.8530e-40,  2.0048e-40, -5.0853e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0173, -0.0091, -0.0037],
          [-0.0138, -0.0060, -0.0041],
          [-0.0140, -0.0085, -0.0079]],

         [[-0.0068, -0.0079, -0.0074],
          [-0.0039, -0.0057, -0.0089],
          [-0.0012, -0.0056, -0.0106]],

         [[-0.0056, -0.0063, -0.0035],
          [-0.0018, -0.0030, -0.0049],
          [-0.0007, -0.0040, -0.0080]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0003, -0.0277, -0.0397],
          [-0.0064, -0.0108, -0.0049],
          [-0.0367, -0.0171, -0.0078]],

         [[ 0.0180,  0.0062,  0.0108],
          [ 0.0087,  0.0097,  0.0219],
          [-0.0262, -0.0064,  0.0226]],

         [[ 0.0229,  0.0138,  0.0191],
          [ 0.0223,  0.0242,  0.0338],
          [-0.0040,  0.0172,  0.0409]]],


        ...,


        [[[ 0.0009,  0.0039,  0.0053],
          [-0.0022, -0.0039, -0.0011],
          [-0.0024, -0.0056, -0.0051]],

         [[ 0.0036,  0.0069,  0.0037],
          [ 0.0032,  0.0010, -0.0004],
          [ 0.0055,  0.0039,  0.0032]],

         [[ 0.0051,  0.0080,  0.0053],
          [ 0.0048,  0.0025,  0.0015],
          [ 0.0078,  0.0059,  0.0059]]],


        [[[-0.0135, -0.0104, -0.0117],
          [-0.0144, -0.0177, -0.0118],
          [-0.0186, -0.0204, -0.0145]],

         [[-0.0034, -0.0077, -0.0076],
          [ 0.0032, -0.0066, -0.0030],
          [-0.0029, -0.0085,  0.0033]],

         [[ 0.0077,  0.0062,  0.0072],
          [ 0.0149,  0.0074,  0.0105],
          [ 0.0091,  0.0037,  0.0132]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0711]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.2759) | Acc: (90.00%) (116/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2017) | Acc: (93.00%) (1311/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2251) | Acc: (92.00%) (2480/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2449) | Acc: (91.00%) (3636/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2493) | Acc: (91.00%) (4805/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2488) | Acc: (91.00%) (5977/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2453) | Acc: (91.00%) (7157/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2469) | Acc: (91.00%) (8327/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2457) | Acc: (91.00%) (9500/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2425) | Acc: (91.00%) (10689/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2392) | Acc: (91.00%) (11878/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2358) | Acc: (92.00%) (13072/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2360) | Acc: (91.00%) (14242/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2351) | Acc: (92.00%) (15429/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2342) | Acc: (92.00%) (16614/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2346) | Acc: (92.00%) (17782/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2326) | Acc: (92.00%) (18972/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2318) | Acc: (92.00%) (20163/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2303) | Acc: (92.00%) (21359/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2300) | Acc: (92.00%) (22538/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2276) | Acc: (92.00%) (23740/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2256) | Acc: (92.00%) (24937/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2253) | Acc: (92.00%) (26128/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2261) | Acc: (92.00%) (27295/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2243) | Acc: (92.00%) (28499/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2224) | Acc: (92.00%) (29701/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2208) | Acc: (92.00%) (30896/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2202) | Acc: (92.00%) (32085/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2192) | Acc: (92.00%) (33287/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2180) | Acc: (92.00%) (34480/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2174) | Acc: (92.00%) (35674/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2167) | Acc: (92.00%) (36865/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2161) | Acc: (92.00%) (38064/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2152) | Acc: (92.00%) (39260/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2142) | Acc: (92.00%) (40464/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2131) | Acc: (92.00%) (41664/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2129) | Acc: (92.00%) (42852/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2126) | Acc: (92.00%) (44040/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2128) | Acc: (92.00%) (45217/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2124) | Acc: (92.00%) (46366/50000)
# TEST : Loss: (0.3102) | Acc: (89.00%) (8981/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8439e-01, -2.2829e-01,  4.2888e-02],
          [-5.9502e-02,  3.1931e-01,  2.3120e-01],
          [ 1.0269e-01,  3.2035e-02, -4.3709e-02]],

         [[-2.2900e-01,  2.0072e-01,  1.8562e-01],
          [ 1.5349e-02,  3.6132e-01,  2.1794e-01],
          [ 1.8234e-01, -6.4360e-02,  1.1743e-01]],

         [[-2.1117e-01, -6.1948e-02, -8.2977e-02],
          [-2.6843e-01, -9.5525e-02, -9.5249e-02],
          [-2.2653e-01, -1.1470e-01, -1.6591e-01]]],


        [[[ 3.4430e-42, -6.9460e-41,  2.3510e-41],
          [-1.9408e-40, -2.6247e-40, -5.9464e-41],
          [-4.8517e-41,  4.5801e-41, -1.8089e-40]],

         [[ 1.2081e-40, -1.4240e-41, -1.0197e-40],
          [ 2.5058e-41,  2.1645e-40, -1.0401e-40],
          [-8.8121e-41,  9.5266e-41, -2.0076e-40]],

         [[-2.6901e-41,  2.5798e-42,  4.1966e-40],
          [ 2.2408e-40,  1.7177e-41, -5.4770e-41],
          [-7.2528e-41,  1.6462e-40,  2.1603e-40]]],


        [[[ 4.3336e-02,  1.1225e-01, -7.9132e-02],
          [ 3.1465e-02,  1.9962e-01, -9.5171e-02],
          [ 1.2277e-01,  3.0995e-01,  3.0840e-01]],

         [[-1.9626e-01, -5.5643e-02, -1.6317e-01],
          [-3.3681e-01, -2.8932e-01, -2.5907e-01],
          [-2.5056e-01, -3.8068e-01,  4.7438e-02]],

         [[ 2.1775e-01,  8.8143e-02,  1.7805e-01],
          [ 1.9848e-01,  1.0069e-01,  3.1914e-02],
          [ 3.2813e-02,  9.2681e-02,  3.4498e-02]]],


        ...,


        [[[ 2.6652e-01,  4.0097e-02,  5.0402e-02],
          [ 2.1106e-01, -2.2102e-01, -6.5375e-02],
          [ 5.0243e-03, -1.3761e-01, -9.2062e-02]],

         [[-1.1150e-01, -9.8599e-02, -1.5161e-02],
          [-1.5979e-01, -2.5531e-01,  7.5701e-02],
          [-2.0026e-03,  1.9570e-01,  2.2704e-01]],

         [[-4.9157e-02, -1.0090e-01,  1.5744e-01],
          [-3.6386e-02, -2.1482e-01, -1.4268e-01],
          [-6.0018e-03, -6.6445e-02, -7.5797e-02]]],


        [[[ 1.0095e-01,  1.5651e-01,  2.7827e-01],
          [ 1.6525e-01,  1.6526e-01, -1.5022e-03],
          [-2.7236e-01, -1.6891e-01, -7.7128e-02]],

         [[ 4.9746e-02,  1.6433e-02, -1.6097e-01],
          [ 2.8522e-02, -8.3383e-02, -3.4183e-01],
          [-1.6730e-02,  1.2553e-01, -3.1162e-02]],

         [[-2.6341e-01, -1.1221e-01, -2.2510e-01],
          [-1.2746e-01,  7.7412e-02,  6.2420e-02],
          [ 1.5625e-01,  2.7332e-01,  2.1359e-01]]],


        [[[-3.2280e-41,  5.6528e-41, -2.6058e-40],
          [-3.7560e-40, -1.3315e-40,  5.1304e-40],
          [-9.1209e-41,  2.3355e-40, -1.9177e-40]],

         [[ 2.8490e-40, -4.7737e-40,  6.2209e-41],
          [-1.0103e-40, -1.7304e-40, -2.8422e-40],
          [ 2.5698e-40,  3.9471e-40,  1.7889e-40]],

         [[-2.3025e-40,  2.4210e-40, -2.9063e-40],
          [ 2.4507e-40,  1.2881e-40, -3.7340e-40],
          [ 3.2525e-40,  4.8032e-40, -1.4497e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0473]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0653]], device='cuda:0')

Epoch: 91 | Batch_idx: 0 |  Loss: (0.1261) | Acc: (96.00%) (124/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.1774) | Acc: (93.00%) (1323/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.1652) | Acc: (94.00%) (2539/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.1744) | Acc: (94.00%) (3732/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.1845) | Acc: (93.00%) (4911/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.1903) | Acc: (93.00%) (6095/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.1907) | Acc: (93.00%) (7296/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.1903) | Acc: (93.00%) (8498/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.1876) | Acc: (93.00%) (9706/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.1880) | Acc: (93.00%) (10905/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.1861) | Acc: (93.00%) (12114/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.1861) | Acc: (93.00%) (13313/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.1859) | Acc: (93.00%) (14520/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.1883) | Acc: (93.00%) (15707/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.1873) | Acc: (93.00%) (16912/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.1880) | Acc: (93.00%) (18112/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.1894) | Acc: (93.00%) (19302/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.1896) | Acc: (93.00%) (20502/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.1896) | Acc: (93.00%) (21706/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.1896) | Acc: (93.00%) (22898/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.1886) | Acc: (93.00%) (24109/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.1878) | Acc: (93.00%) (25316/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.1876) | Acc: (93.00%) (26519/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.1865) | Acc: (93.00%) (27736/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.1865) | Acc: (93.00%) (28929/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.1872) | Acc: (93.00%) (30120/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.1869) | Acc: (93.00%) (31322/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.1875) | Acc: (93.00%) (32519/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.1868) | Acc: (93.00%) (33717/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.1864) | Acc: (93.00%) (34920/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.1865) | Acc: (93.00%) (36122/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.1873) | Acc: (93.00%) (37313/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.1881) | Acc: (93.00%) (38507/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.1881) | Acc: (93.00%) (39707/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.1889) | Acc: (93.00%) (40889/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.1893) | Acc: (93.00%) (42079/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.1889) | Acc: (93.00%) (43276/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.1878) | Acc: (93.00%) (44499/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.1876) | Acc: (93.00%) (45708/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.1876) | Acc: (93.00%) (46869/50000)
# TEST : Loss: (0.3078) | Acc: (89.00%) (8981/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8360e-01, -2.2723e-01,  4.2678e-02],
          [-5.9231e-02,  3.1775e-01,  2.2999e-01],
          [ 1.0223e-01,  3.1882e-02, -4.3492e-02]],

         [[-2.2798e-01,  1.9978e-01,  1.8473e-01],
          [ 1.5278e-02,  3.5957e-01,  2.1685e-01],
          [ 1.8152e-01, -6.4057e-02,  1.1687e-01]],

         [[-2.1013e-01, -6.1646e-02, -8.2584e-02],
          [-2.6712e-01, -9.5065e-02, -9.4800e-02],
          [-2.2545e-01, -1.1416e-01, -1.6514e-01]]],


        [[[-2.2713e-40,  1.1659e-42, -3.4708e-40],
          [ 9.3656e-41, -2.8836e-40, -2.2208e-40],
          [-5.0649e-41, -1.0654e-40,  2.8932e-40]],

         [[-2.5306e-40, -1.4603e-41,  3.9022e-41],
          [ 2.7187e-41,  2.6050e-42,  1.2102e-40],
          [-9.9519e-41,  2.7400e-41, -5.6797e-41]],

         [[ 2.8815e-40, -1.5791e-40,  7.2938e-41],
          [ 1.6655e-40, -5.9346e-41,  2.5656e-40],
          [-1.5671e-40,  1.9311e-41,  3.9989e-40]]],


        [[[ 4.3256e-02,  1.1204e-01, -7.8982e-02],
          [ 3.1407e-02,  1.9925e-01, -9.4991e-02],
          [ 1.2254e-01,  3.0936e-01,  3.0781e-01]],

         [[-1.9587e-01, -5.5528e-02, -1.6282e-01],
          [-3.3610e-01, -2.8870e-01, -2.5852e-01],
          [-2.5003e-01, -3.7989e-01,  4.7342e-02]],

         [[ 2.1729e-01,  8.7952e-02,  1.7765e-01],
          [ 1.9804e-01,  1.0046e-01,  3.1843e-02],
          [ 3.2743e-02,  9.2478e-02,  3.4425e-02]]],


        ...,


        [[[ 2.6383e-01,  3.9668e-02,  4.9903e-02],
          [ 2.0863e-01, -2.1809e-01, -6.4626e-02],
          [ 4.9712e-03, -1.3601e-01, -9.1085e-02]],

         [[-1.1014e-01, -9.7259e-02, -1.4991e-02],
          [-1.5734e-01, -2.5008e-01,  7.4655e-02],
          [-1.9777e-03,  1.9288e-01,  2.2435e-01]],

         [[-4.8432e-02, -9.9173e-02,  1.5534e-01],
          [-3.5635e-02, -2.0722e-01, -1.4010e-01],
          [-5.9074e-03, -6.5145e-02, -7.4687e-02]]],


        [[[ 1.0038e-01,  1.5563e-01,  2.7684e-01],
          [ 1.6432e-01,  1.6433e-01, -1.4944e-03],
          [-2.7089e-01, -1.6800e-01, -7.6723e-02]],

         [[ 4.9464e-02,  1.6339e-02, -1.6005e-01],
          [ 2.8362e-02, -8.2915e-02, -3.3991e-01],
          [-1.6639e-02,  1.2484e-01, -3.0990e-02]],

         [[-2.6186e-01, -1.1155e-01, -2.2374e-01],
          [-1.2674e-01,  7.6974e-02,  6.2054e-02],
          [ 1.5539e-01,  2.7183e-01,  2.1240e-01]]],


        [[[ 1.0771e-40,  3.3642e-40, -5.4046e-40],
          [ 1.8424e-40, -1.3318e-40,  9.3639e-41],
          [-3.7121e-40,  2.3363e-40, -1.9182e-40]],

         [[-1.3494e-40, -3.3752e-40, -3.5763e-40],
          [-1.0107e-40,  1.0685e-40, -4.4127e-42],
          [ 3.9701e-40, -1.6502e-40,  3.8993e-41]],

         [[ 4.9505e-41,  2.4218e-40,  1.2910e-40],
          [ 1.0523e-40, -4.3089e-40, -2.3359e-40],
          [ 1.8539e-40,  3.4051e-40, -1.4500e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0867]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0496]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 92 | Batch_idx: 0 |  Loss: (0.1635) | Acc: (90.00%) (116/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.1727) | Acc: (93.00%) (1321/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.1867) | Acc: (93.00%) (2513/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.1893) | Acc: (93.00%) (3700/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2071) | Acc: (92.00%) (4866/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2074) | Acc: (92.00%) (6052/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2159) | Acc: (92.00%) (7217/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2252) | Acc: (92.00%) (8380/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2288) | Acc: (92.00%) (9555/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2364) | Acc: (91.00%) (10703/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2386) | Acc: (91.00%) (11880/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2422) | Acc: (91.00%) (13034/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2456) | Acc: (91.00%) (14185/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2492) | Acc: (91.00%) (15343/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2483) | Acc: (91.00%) (16522/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2503) | Acc: (91.00%) (17686/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2512) | Acc: (91.00%) (18847/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2549) | Acc: (91.00%) (19983/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2566) | Acc: (91.00%) (21141/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2585) | Acc: (91.00%) (22293/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2586) | Acc: (91.00%) (23460/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2596) | Acc: (91.00%) (24619/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2618) | Acc: (91.00%) (25765/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2621) | Acc: (91.00%) (26920/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2625) | Acc: (91.00%) (28081/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2623) | Acc: (91.00%) (29251/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2612) | Acc: (91.00%) (30430/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2619) | Acc: (91.00%) (31591/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2610) | Acc: (91.00%) (32766/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2610) | Acc: (91.00%) (33929/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2601) | Acc: (91.00%) (35112/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2600) | Acc: (91.00%) (36289/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2600) | Acc: (91.00%) (37456/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2591) | Acc: (91.00%) (38632/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2583) | Acc: (91.00%) (39805/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2577) | Acc: (91.00%) (40975/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2573) | Acc: (91.00%) (42155/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2572) | Acc: (91.00%) (43331/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2571) | Acc: (91.00%) (44503/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2577) | Acc: (91.00%) (45618/50000)
# TEST : Loss: (0.3766) | Acc: (88.00%) (8828/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9179e-01, -2.3505e-01,  3.5634e-02],
          [-6.2526e-02,  3.1837e-01,  2.2854e-01],
          [ 1.1641e-01,  4.5602e-02, -4.1885e-02]],

         [[-2.2465e-01,  2.0403e-01,  1.8778e-01],
          [ 1.9285e-02,  3.6884e-01,  2.2270e-01],
          [ 2.0020e-01, -4.6337e-02,  1.2216e-01]],

         [[-2.1449e-01, -6.1570e-02, -7.9306e-02],
          [-2.6944e-01, -9.4129e-02, -9.1203e-02],
          [-2.1092e-01, -1.0505e-01, -1.5816e-01]]],


        [[[-3.3086e-40,  8.5275e-41, -2.9772e-40],
          [ 1.8480e-40,  3.6178e-40,  3.4978e-40],
          [ 1.0843e-40, -1.9911e-40,  4.9738e-41]],

         [[-1.8926e-40,  1.5512e-40,  4.1320e-41],
          [-1.3845e-40, -2.5176e-40,  3.0120e-40],
          [ 5.7188e-41, -5.4045e-41, -2.3702e-40]],

         [[ 3.9823e-40, -2.5798e-40, -1.7160e-40],
          [ 1.0511e-41, -1.4918e-40, -2.4035e-40],
          [-1.7013e-40, -1.5326e-40, -4.5172e-40]]],


        [[[ 4.6586e-02,  1.1282e-01, -7.4069e-02],
          [ 2.9171e-02,  1.9640e-01, -9.8817e-02],
          [ 1.2192e-01,  3.0497e-01,  3.0640e-01]],

         [[-1.9644e-01, -6.3251e-02, -1.6499e-01],
          [-3.4362e-01, -2.9947e-01, -2.6541e-01],
          [-2.5993e-01, -3.9515e-01,  4.2517e-02]],

         [[ 2.1800e-01,  8.7568e-02,  1.7797e-01],
          [ 1.9081e-01,  9.4261e-02,  2.4888e-02],
          [ 2.3417e-02,  7.9585e-02,  2.6706e-02]]],


        ...,


        [[[ 2.6224e-01,  4.3485e-02,  6.3216e-02],
          [ 1.9726e-01, -2.1835e-01, -5.2355e-02],
          [ 6.3361e-03, -1.2697e-01, -7.1022e-02]],

         [[-1.1318e-01, -9.8329e-02, -4.5628e-03],
          [-1.7162e-01, -2.5666e-01,  8.5624e-02],
          [-1.4175e-03,  2.0285e-01,  2.4705e-01]],

         [[-5.6335e-02, -1.0804e-01,  1.5255e-01],
          [-4.9412e-02, -2.0546e-01, -1.2979e-01],
          [ 2.0662e-03, -3.7970e-02, -4.6210e-02]]],


        [[[ 1.2958e-01,  1.8091e-01,  2.9029e-01],
          [ 1.8415e-01,  1.7483e-01,  2.0251e-04],
          [-2.6717e-01, -1.7206e-01, -7.9090e-02]],

         [[ 7.4603e-02,  3.5850e-02, -1.4776e-01],
          [ 4.7727e-02, -7.8503e-02, -3.4475e-01],
          [-1.4960e-02,  1.1664e-01, -3.8702e-02]],

         [[-2.3535e-01, -9.1506e-02, -2.1199e-01],
          [-1.0686e-01,  8.9032e-02,  6.4493e-02],
          [ 1.6169e-01,  2.7337e-01,  2.0998e-01]]],


        [[[ 1.0773e-40,  3.3649e-40, -2.6075e-40],
          [ 6.0429e-40,  6.7557e-42, -4.6600e-40],
          [-2.3128e-40, -4.6236e-41, -5.1943e-41]],

         [[-4.1495e-40,  8.2422e-41, -3.5772e-40],
          [ 3.8908e-41,  2.4688e-40,  2.7552e-40],
          [ 1.1714e-40, -5.8503e-40, -1.0097e-40]],

         [[ 3.2944e-40, -3.7702e-41,  4.0908e-40],
          [-1.7468e-40, -5.7097e-40,  1.8623e-40],
          [-9.4518e-41, -7.9342e-41, -5.0713e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0112,  0.0112,  0.0191],
          [ 0.0154,  0.0136,  0.0161],
          [ 0.0135,  0.0070,  0.0043]],

         [[ 0.0094,  0.0099,  0.0188],
          [ 0.0141,  0.0115,  0.0128],
          [ 0.0112,  0.0034, -0.0009]],

         [[ 0.0122,  0.0122,  0.0211],
          [ 0.0157,  0.0142,  0.0154],
          [ 0.0165,  0.0107,  0.0064]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0754, -0.0753, -0.0633],
          [-0.0775, -0.0692, -0.0526],
          [-0.0674, -0.0589, -0.0392]],

         [[-0.0558, -0.0564, -0.0419],
          [-0.0538, -0.0496, -0.0357],
          [-0.0440, -0.0368, -0.0216]],

         [[-0.0384, -0.0430, -0.0319],
          [-0.0408, -0.0402, -0.0285],
          [-0.0325, -0.0276, -0.0128]]],


        ...,


        [[[-0.0067, -0.0069, -0.0096],
          [-0.0083, -0.0061, -0.0110],
          [ 0.0017,  0.0019, -0.0060]],

         [[-0.0036, -0.0058, -0.0094],
          [-0.0063, -0.0057, -0.0103],
          [ 0.0027,  0.0018, -0.0056]],

         [[-0.0008, -0.0030, -0.0068],
          [-0.0022, -0.0020, -0.0062],
          [ 0.0058,  0.0046, -0.0014]]],


        [[[-0.0030, -0.0045, -0.0037],
          [-0.0123, -0.0099, -0.0086],
          [-0.0123, -0.0077, -0.0043]],

         [[-0.0045, -0.0068, -0.0064],
          [-0.0150, -0.0137, -0.0114],
          [-0.0142, -0.0096, -0.0049]],

         [[ 0.0020, -0.0003, -0.0002],
          [-0.0063, -0.0060, -0.0049],
          [-0.0061, -0.0033, -0.0006]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0817]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 93 | Batch_idx: 0 |  Loss: (0.2136) | Acc: (92.00%) (118/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2541) | Acc: (91.00%) (1292/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2260) | Acc: (92.00%) (2492/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2216) | Acc: (92.00%) (3680/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2192) | Acc: (92.00%) (4872/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2190) | Acc: (92.00%) (6063/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2153) | Acc: (92.00%) (7250/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2147) | Acc: (92.00%) (8442/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2144) | Acc: (92.00%) (9624/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2108) | Acc: (92.00%) (10826/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2121) | Acc: (92.00%) (12003/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2135) | Acc: (92.00%) (13186/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2151) | Acc: (92.00%) (14357/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2132) | Acc: (92.00%) (15550/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2139) | Acc: (92.00%) (16730/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2120) | Acc: (92.00%) (17931/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2119) | Acc: (92.00%) (19115/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2136) | Acc: (92.00%) (20290/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2132) | Acc: (92.00%) (21479/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2130) | Acc: (92.00%) (22668/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2124) | Acc: (92.00%) (23854/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2129) | Acc: (92.00%) (25034/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2142) | Acc: (92.00%) (26207/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2146) | Acc: (92.00%) (27383/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2149) | Acc: (92.00%) (28574/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2140) | Acc: (92.00%) (29765/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2127) | Acc: (92.00%) (30955/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2135) | Acc: (92.00%) (32130/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2148) | Acc: (92.00%) (33294/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2155) | Acc: (92.00%) (34469/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2163) | Acc: (92.00%) (35641/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2160) | Acc: (92.00%) (36829/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2160) | Acc: (92.00%) (38012/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2160) | Acc: (92.00%) (39186/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2155) | Acc: (92.00%) (40379/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2159) | Acc: (92.00%) (41543/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2170) | Acc: (92.00%) (42700/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2179) | Acc: (92.00%) (43870/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2193) | Acc: (92.00%) (45031/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2198) | Acc: (92.00%) (46162/50000)
# TEST : Loss: (0.3183) | Acc: (89.00%) (8961/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9802e-01, -2.3823e-01,  3.7283e-02],
          [-6.8480e-02,  3.1847e-01,  2.3165e-01],
          [ 1.0360e-01,  4.3400e-02, -4.0911e-02]],

         [[-2.3028e-01,  1.9871e-01,  1.8822e-01],
          [ 1.7349e-02,  3.7112e-01,  2.2937e-01],
          [ 1.9409e-01, -4.2593e-02,  1.2672e-01]],

         [[-2.1769e-01, -7.1435e-02, -8.5930e-02],
          [-2.6919e-01, -1.0026e-01, -9.6043e-02],
          [-2.1120e-01, -1.0742e-01, -1.6359e-01]]],


        [[[-3.5668e-40,  9.1676e-41,  3.1553e-41],
          [ 1.9779e-40, -6.4282e-41, -2.6124e-40],
          [-2.3678e-40, -1.2458e-40,  3.3368e-40]],

         [[-2.1457e-41,  2.5921e-40,  2.2279e-40],
          [ 2.8083e-41, -2.7105e-40,  3.2359e-40],
          [ 2.4000e-40, -1.4843e-40,  2.6863e-41]],

         [[ 3.3372e-40, -1.8378e-40, -3.6666e-40],
          [-1.7171e-40,  1.1705e-40,  2.9551e-40],
          [-9.2559e-41,  1.9478e-41, -1.0113e-41]]],


        [[[ 3.4320e-02,  9.8202e-02, -7.9393e-02],
          [ 2.0523e-02,  1.9057e-01, -1.0593e-01],
          [ 1.1950e-01,  3.0773e-01,  3.0821e-01]],

         [[-2.0718e-01, -7.5234e-02, -1.6577e-01],
          [-3.5396e-01, -3.0678e-01, -2.6834e-01],
          [-2.6397e-01, -3.9187e-01,  4.6752e-02]],

         [[ 2.1237e-01,  8.5386e-02,  1.8610e-01],
          [ 1.8382e-01,  9.1867e-02,  2.6941e-02],
          [ 2.1827e-02,  8.1863e-02,  2.9343e-02]]],


        ...,


        [[[ 2.7745e-01,  6.8316e-02,  7.5451e-02],
          [ 2.1420e-01, -2.0781e-01, -4.7172e-02],
          [ 1.8504e-02, -1.2074e-01, -6.8871e-02]],

         [[-1.0858e-01, -8.0779e-02, -7.1731e-04],
          [-1.6779e-01, -2.6011e-01,  7.4845e-02],
          [-7.6504e-03,  1.8815e-01,  2.3124e-01]],

         [[-7.3715e-02, -1.0246e-01,  1.4914e-01],
          [-6.2161e-02, -2.1337e-01, -1.4300e-01],
          [-1.4011e-02, -5.5755e-02, -6.7536e-02]]],


        [[[ 1.2770e-01,  1.7776e-01,  2.7773e-01],
          [ 1.7853e-01,  1.6731e-01, -1.0196e-02],
          [-2.7166e-01, -1.7510e-01, -8.1542e-02]],

         [[ 7.2442e-02,  3.1019e-02, -1.6163e-01],
          [ 4.7850e-02, -8.2099e-02, -3.5678e-01],
          [-2.1017e-02,  1.1339e-01, -4.4731e-02]],

         [[-2.4100e-01, -9.5769e-02, -2.1841e-01],
          [-1.0703e-01,  9.0283e-02,  6.3724e-02],
          [ 1.5303e-01,  2.7227e-01,  2.0940e-01]]],


        [[[-3.2273e-41,  5.6535e-41,  2.9903e-40],
          [ 4.6436e-40,  1.4676e-40, -6.0607e-40],
          [ 1.8877e-40, -3.2622e-40,  8.8013e-41]],

         [[-2.7500e-40,  3.6248e-40,  6.2211e-41],
          [ 1.7892e-40,  1.0692e-40,  2.7558e-40],
          [-3.0291e-40, -4.4513e-40, -1.0100e-40]],

         [[ 3.2950e-40, -3.1770e-40,  2.6916e-40],
          [-3.1471e-40, -1.5108e-40,  4.6624e-40],
          [-2.3455e-40, -3.5937e-40,  1.3493e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0247, -0.0166, -0.0183],
          [-0.0192, -0.0121, -0.0151],
          [-0.0252, -0.0181, -0.0176]],

         [[-0.0295, -0.0232, -0.0227],
          [-0.0257, -0.0191, -0.0194],
          [-0.0324, -0.0244, -0.0237]],

         [[-0.0213, -0.0161, -0.0117],
          [-0.0178, -0.0131, -0.0085],
          [-0.0244, -0.0181, -0.0121]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0577, -0.0423, -0.0291],
          [-0.0455, -0.0323, -0.0179],
          [-0.0579, -0.0428, -0.0402]],

         [[-0.0547, -0.0407, -0.0338],
          [-0.0391, -0.0304, -0.0218],
          [-0.0483, -0.0362, -0.0382]],

         [[-0.0480, -0.0378, -0.0344],
          [-0.0309, -0.0250, -0.0230],
          [-0.0362, -0.0280, -0.0352]]],


        ...,


        [[[-0.0164, -0.0083, -0.0006],
          [-0.0095, -0.0046,  0.0004],
          [-0.0099, -0.0079, -0.0089]],

         [[-0.0140, -0.0054,  0.0022],
          [-0.0076, -0.0034,  0.0012],
          [-0.0097, -0.0082, -0.0081]],

         [[-0.0094, -0.0030,  0.0038],
          [-0.0067, -0.0042,  0.0003],
          [-0.0098, -0.0090, -0.0081]]],


        [[[ 0.0169,  0.0204,  0.0198],
          [ 0.0187,  0.0199,  0.0163],
          [ 0.0134,  0.0143,  0.0091]],

         [[ 0.0138,  0.0181,  0.0167],
          [ 0.0112,  0.0135,  0.0097],
          [ 0.0062,  0.0074,  0.0017]],

         [[ 0.0036,  0.0079,  0.0060],
          [-0.0002,  0.0028, -0.0008],
          [-0.0053, -0.0036, -0.0089]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0815]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 94 | Batch_idx: 0 |  Loss: (0.1755) | Acc: (94.00%) (121/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.1971) | Acc: (93.00%) (1317/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2385) | Acc: (91.00%) (2463/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2439) | Acc: (91.00%) (3625/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2378) | Acc: (91.00%) (4804/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2371) | Acc: (91.00%) (5985/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2335) | Acc: (91.00%) (7171/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2322) | Acc: (91.00%) (8353/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2271) | Acc: (91.00%) (9537/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2242) | Acc: (92.00%) (10720/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2238) | Acc: (92.00%) (11897/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2223) | Acc: (92.00%) (13085/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2218) | Acc: (92.00%) (14267/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2196) | Acc: (92.00%) (15472/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2180) | Acc: (92.00%) (16675/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2170) | Acc: (92.00%) (17868/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2155) | Acc: (92.00%) (19055/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2150) | Acc: (92.00%) (20250/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2145) | Acc: (92.00%) (21444/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2137) | Acc: (92.00%) (22648/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2138) | Acc: (92.00%) (23840/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2119) | Acc: (92.00%) (25044/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2109) | Acc: (92.00%) (26245/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2106) | Acc: (92.00%) (27436/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2116) | Acc: (92.00%) (28612/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2116) | Acc: (92.00%) (29800/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2104) | Acc: (92.00%) (30999/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2112) | Acc: (92.00%) (32173/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2099) | Acc: (92.00%) (33386/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2098) | Acc: (92.00%) (34587/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2096) | Acc: (92.00%) (35779/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2087) | Acc: (92.00%) (36979/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2087) | Acc: (92.00%) (38178/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2081) | Acc: (92.00%) (39388/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2075) | Acc: (92.00%) (40570/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2075) | Acc: (92.00%) (41774/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2073) | Acc: (92.00%) (42965/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2062) | Acc: (93.00%) (44170/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2050) | Acc: (93.00%) (45380/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2040) | Acc: (93.00%) (46550/50000)
# TEST : Loss: (0.2974) | Acc: (90.00%) (9018/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9608e-01, -2.3696e-01,  3.8240e-02],
          [-6.7259e-02,  3.1813e-01,  2.3218e-01],
          [ 1.0419e-01,  4.4272e-02, -3.8729e-02]],

         [[-2.2743e-01,  1.9931e-01,  1.8964e-01],
          [ 1.9310e-02,  3.7139e-01,  2.3062e-01],
          [ 1.9559e-01, -4.0195e-02,  1.2939e-01]],

         [[-2.1461e-01, -7.0463e-02, -8.4632e-02],
          [-2.6644e-01, -9.9096e-02, -9.4864e-02],
          [-2.0846e-01, -1.0548e-01, -1.6133e-01]]],


        [[[ 1.9564e-40,  1.1182e-42,  3.1730e-40],
          [-7.5687e-41,  2.2105e-40, -2.7926e-40],
          [-2.5189e-40,  5.9013e-41,  4.5459e-40]],

         [[-2.1666e-40, -1.5801e-41,  2.3776e-40],
          [ 2.2193e-40,  2.5616e-42,  2.4720e-40],
          [ 6.6478e-41, -1.5750e-40, -7.2844e-41]],

         [[ 5.9634e-41,  2.4649e-42,  9.5602e-41],
          [-1.8355e-40,  1.2296e-40, -7.9431e-41],
          [ 9.4445e-41,  2.1914e-40,  2.8975e-40]]],


        [[[ 3.5154e-02,  9.7462e-02, -7.9925e-02],
          [ 2.1592e-02,  1.9004e-01, -1.0658e-01],
          [ 1.2026e-01,  3.0749e-01,  3.0734e-01]],

         [[-2.0710e-01, -7.6629e-02, -1.6681e-01],
          [-3.5422e-01, -3.0824e-01, -2.6991e-01],
          [-2.6487e-01, -3.9321e-01,  4.4301e-02]],

         [[ 2.1021e-01,  8.2426e-02,  1.8312e-01],
          [ 1.8085e-01,  8.7965e-02,  2.3373e-02],
          [ 1.8670e-02,  7.7928e-02,  2.5538e-02]]],


        ...,


        [[[ 2.7205e-01,  6.5851e-02,  7.3046e-02],
          [ 2.0744e-01, -2.0953e-01, -4.9927e-02],
          [ 1.5144e-02, -1.2141e-01, -6.7752e-02]],

         [[-1.0894e-01, -8.1577e-02, -3.1960e-03],
          [-1.6946e-01, -2.5952e-01,  7.0514e-02],
          [-9.0884e-03,  1.8599e-01,  2.3031e-01]],

         [[-7.4566e-02, -1.0228e-01,  1.4485e-01],
          [-6.5078e-02, -2.1056e-01, -1.4466e-01],
          [-1.5161e-02, -5.4332e-02, -6.5471e-02]]],


        [[[ 1.2901e-01,  1.7955e-01,  2.8017e-01],
          [ 1.7909e-01,  1.6861e-01, -6.9905e-03],
          [-2.6907e-01, -1.7249e-01, -7.8158e-02]],

         [[ 7.3588e-02,  3.2311e-02, -1.5846e-01],
          [ 4.8698e-02, -8.0508e-02, -3.5284e-01],
          [-2.0265e-02,  1.1381e-01, -4.2563e-02]],

         [[-2.3913e-01, -9.4640e-02, -2.1553e-01],
          [-1.0619e-01,  9.0282e-02,  6.4729e-02],
          [ 1.5235e-01,  2.7116e-01,  2.0927e-01]]],


        [[[-1.7232e-40, -2.2353e-40,  5.7908e-40],
          [-9.5784e-41,  1.4678e-40, -1.8624e-40],
          [ 4.6888e-40, -3.2628e-40,  8.8052e-41]],

         [[ 1.4507e-40,  2.2250e-40,  4.8229e-40],
          [ 1.7894e-40, -1.7314e-40, -4.4099e-42],
          [-4.4298e-40,  1.1495e-40,  3.8990e-41]],

         [[ 4.9498e-41, -3.1774e-40, -1.5085e-40],
          [-1.7473e-40,  4.0899e-40,  3.2630e-40],
          [-9.4554e-41, -2.1943e-40,  1.3495e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0186]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0000]], device='cuda:0')

Epoch: 95 | Batch_idx: 0 |  Loss: (0.1870) | Acc: (95.00%) (122/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.1833) | Acc: (94.00%) (1327/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.1900) | Acc: (93.00%) (2518/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.1800) | Acc: (93.00%) (3722/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.1791) | Acc: (93.00%) (4924/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.1775) | Acc: (93.00%) (6128/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.1777) | Acc: (93.00%) (7334/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.1789) | Acc: (93.00%) (8523/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.1775) | Acc: (93.00%) (9729/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.1787) | Acc: (93.00%) (10931/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.1788) | Acc: (93.00%) (12130/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.1768) | Acc: (93.00%) (13344/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.1779) | Acc: (93.00%) (14540/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.1801) | Acc: (93.00%) (15733/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.1812) | Acc: (93.00%) (16920/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.1812) | Acc: (93.00%) (18138/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.1819) | Acc: (93.00%) (19332/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.1810) | Acc: (93.00%) (20550/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.1814) | Acc: (93.00%) (21743/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.1821) | Acc: (93.00%) (22942/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.1825) | Acc: (93.00%) (24145/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.1826) | Acc: (93.00%) (25341/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.1823) | Acc: (93.00%) (26546/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.1830) | Acc: (93.00%) (27742/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.1831) | Acc: (93.00%) (28943/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.1822) | Acc: (93.00%) (30153/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.1816) | Acc: (93.00%) (31371/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.1814) | Acc: (93.00%) (32582/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.1818) | Acc: (93.00%) (33772/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.1819) | Acc: (93.00%) (34973/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.1822) | Acc: (93.00%) (36172/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.1824) | Acc: (93.00%) (37366/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.1813) | Acc: (93.00%) (38591/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.1824) | Acc: (93.00%) (39785/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.1835) | Acc: (93.00%) (40973/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.1839) | Acc: (93.00%) (42166/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.1831) | Acc: (93.00%) (43378/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.1831) | Acc: (93.00%) (44572/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.1832) | Acc: (93.00%) (45777/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.1825) | Acc: (93.00%) (46943/50000)
# TEST : Loss: (0.2894) | Acc: (90.00%) (9039/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9531e-01, -2.3596e-01,  3.8074e-02],
          [-6.6982e-02,  3.1673e-01,  2.3112e-01],
          [ 1.0376e-01,  4.4079e-02, -3.8558e-02]],

         [[-2.2648e-01,  1.9844e-01,  1.8880e-01],
          [ 1.9227e-02,  3.6974e-01,  2.2958e-01],
          [ 1.9477e-01, -4.0022e-02,  1.2882e-01]],

         [[-2.1358e-01, -7.0133e-02, -8.4251e-02],
          [-2.6520e-01, -9.8647e-02, -9.4446e-02],
          [-2.0753e-01, -1.0502e-01, -1.6064e-01]]],


        [[[ 3.0903e-40, -1.0114e-40,  3.5492e-41],
          [-1.8109e-40,  3.3561e-40, -9.0082e-41],
          [-6.6562e-41,  2.6589e-40,  2.7069e-40]],

         [[-2.3044e-40,  1.8754e-40,  4.9268e-41],
          [ 2.3587e-40,  1.0557e-40,  2.6012e-40],
          [ 7.2212e-41, -6.3109e-41, -7.8201e-41]],

         [[-3.5252e-40,  2.1284e-40,  3.0649e-40],
          [ 1.3108e-41,  2.4193e-41, -2.9198e-40],
          [ 2.0185e-40,  2.3249e-40, -1.1760e-40]]],


        [[[ 3.5090e-02,  9.7283e-02, -7.9772e-02],
          [ 2.1552e-02,  1.8968e-01, -1.0638e-01],
          [ 1.2002e-01,  3.0689e-01,  3.0674e-01]],

         [[-2.0668e-01, -7.6473e-02, -1.6646e-01],
          [-3.5346e-01, -3.0756e-01, -2.6931e-01],
          [-2.6429e-01, -3.9237e-01,  4.4207e-02]],

         [[ 2.0978e-01,  8.2254e-02,  1.8273e-01],
          [ 1.8045e-01,  8.7768e-02,  2.3320e-02],
          [ 1.8629e-02,  7.7756e-02,  2.5482e-02]]],


        ...,


        [[[ 2.6953e-01,  6.5205e-02,  7.2382e-02],
          [ 2.0522e-01, -2.0699e-01, -4.9404e-02],
          [ 1.4992e-02, -1.2010e-01, -6.7066e-02]],

         [[-1.0769e-01, -8.0539e-02, -3.1625e-03],
          [-1.6702e-01, -2.5459e-01,  6.9608e-02],
          [-8.9806e-03,  1.8348e-01,  2.2769e-01]],

         [[-7.3502e-02, -1.0055e-01,  1.4298e-01],
          [-6.3788e-02, -2.0363e-01, -1.4223e-01],
          [-1.4938e-02, -5.3381e-02, -6.4571e-02]]],


        [[[ 1.2822e-01,  1.7845e-01,  2.7861e-01],
          [ 1.7801e-01,  1.6762e-01, -6.9530e-03],
          [-2.6749e-01, -1.7152e-01, -7.7735e-02]],

         [[ 7.3140e-02,  3.2114e-02, -1.5751e-01],
          [ 4.8397e-02, -8.0028e-02, -3.5079e-01],
          [-2.0142e-02,  1.1315e-01, -4.2316e-02]],

         [[-2.3764e-01, -9.4051e-02, -2.1416e-01],
          [-1.0552e-01,  8.9729e-02,  6.4328e-02],
          [ 1.5139e-01,  2.6953e-01,  2.0799e-01]]],


        [[[-1.7234e-40, -2.2356e-40,  2.9914e-40],
          [-5.1598e-40,  6.7613e-42,  3.7377e-40],
          [ 3.2886e-40, -4.6243e-41, -5.1941e-41]],

         [[ 4.2518e-40, -1.9763e-40,  4.8235e-40],
          [ 3.8896e-41, -3.1320e-40, -2.8449e-40],
          [-1.6292e-40,  5.3513e-40,  1.7902e-40]],

         [[-2.3058e-40, -3.7695e-41, -4.3094e-40],
          [ 1.0532e-40,  5.4909e-40, -9.3771e-41],
          [ 1.8551e-40,  2.0067e-40, -5.0685e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0409]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0232]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 96 | Batch_idx: 0 |  Loss: (0.1513) | Acc: (94.00%) (121/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.1782) | Acc: (94.00%) (1329/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.1876) | Acc: (93.00%) (2525/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2099) | Acc: (93.00%) (3692/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2257) | Acc: (92.00%) (4849/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2276) | Acc: (92.00%) (6037/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2270) | Acc: (92.00%) (7220/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2306) | Acc: (92.00%) (8391/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2334) | Acc: (92.00%) (9568/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2357) | Acc: (92.00%) (10743/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2420) | Acc: (91.00%) (11885/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2459) | Acc: (91.00%) (13046/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2468) | Acc: (91.00%) (14218/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2486) | Acc: (91.00%) (15389/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2496) | Acc: (91.00%) (16549/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2485) | Acc: (91.00%) (17719/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2490) | Acc: (91.00%) (18880/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2502) | Acc: (91.00%) (20039/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2484) | Acc: (91.00%) (21221/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2510) | Acc: (91.00%) (22371/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2512) | Acc: (91.00%) (23535/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2509) | Acc: (91.00%) (24707/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2522) | Acc: (91.00%) (25862/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2520) | Acc: (91.00%) (27032/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2542) | Acc: (91.00%) (28188/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2534) | Acc: (91.00%) (29367/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2534) | Acc: (91.00%) (30534/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2538) | Acc: (91.00%) (31700/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2531) | Acc: (91.00%) (32882/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2528) | Acc: (91.00%) (34056/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2533) | Acc: (91.00%) (35211/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2533) | Acc: (91.00%) (36376/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2533) | Acc: (91.00%) (37552/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2532) | Acc: (91.00%) (38713/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2530) | Acc: (91.00%) (39886/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2522) | Acc: (91.00%) (41066/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2516) | Acc: (91.00%) (42248/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2509) | Acc: (91.00%) (43431/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2516) | Acc: (91.00%) (44594/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2518) | Acc: (91.00%) (45710/50000)
# TEST : Loss: (0.3641) | Acc: (88.00%) (8868/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9477e-01, -2.2061e-01,  5.7299e-02],
          [-7.3504e-02,  3.1877e-01,  2.3718e-01],
          [ 1.0241e-01,  4.4393e-02, -4.0528e-02]],

         [[-2.2701e-01,  2.0875e-01,  2.0309e-01],
          [ 1.0244e-02,  3.6541e-01,  2.2648e-01],
          [ 1.9451e-01, -4.1954e-02,  1.2052e-01]],

         [[-2.1283e-01, -5.9364e-02, -7.2153e-02],
          [-2.7515e-01, -1.0793e-01, -1.0109e-01],
          [-2.1383e-01, -1.1565e-01, -1.7121e-01]]],


        [[[ 2.1841e-40, -1.0628e-40,  3.7453e-41],
          [-1.9011e-40, -2.9317e-40,  2.2874e-40],
          [ 1.4108e-40,  1.7148e-40,  3.9443e-40]],

         [[-2.8490e-41,  3.0356e-40, -1.6144e-40],
          [ 3.5496e-41,  4.3517e-40, -4.8534e-40],
          [-2.8766e-41, -6.8208e-41,  2.6919e-41]],

         [[ 2.8316e-40,  3.8858e-42,  5.3703e-40],
          [ 2.3103e-40, -8.4990e-41,  2.3853e-40],
          [ 1.0462e-40,  2.6594e-41, -4.5458e-40]]],


        [[[ 4.6293e-02,  1.1019e-01, -7.5447e-02],
          [ 4.1957e-02,  2.0786e-01, -9.7986e-02],
          [ 1.3876e-01,  3.2279e-01,  3.1696e-01]],

         [[-2.0417e-01, -7.1220e-02, -1.7213e-01],
          [-3.4401e-01, -2.9805e-01, -2.6763e-01],
          [-2.5665e-01, -3.8664e-01,  4.6172e-02]],

         [[ 2.1462e-01,  9.1453e-02,  1.8020e-01],
          [ 1.8808e-01,  9.9937e-02,  2.6518e-02],
          [ 2.4460e-02,  8.3933e-02,  2.5935e-02]]],


        ...,


        [[[ 2.5099e-01,  4.6494e-02,  6.5596e-02],
          [ 1.8010e-01, -2.3313e-01, -6.6251e-02],
          [ 1.5279e-02, -1.2740e-01, -8.2630e-02]],

         [[-1.0956e-01, -9.1807e-02, -2.5179e-05],
          [-1.7217e-01, -2.7215e-01,  6.0850e-02],
          [ 7.4309e-03,  1.8821e-01,  2.2491e-01]],

         [[-7.8015e-02, -1.1936e-01,  1.4395e-01],
          [-6.5222e-02, -2.2148e-01, -1.4409e-01],
          [ 1.0778e-02, -3.8642e-02, -5.8078e-02]]],


        [[[ 1.2974e-01,  1.6716e-01,  2.7042e-01],
          [ 1.5640e-01,  1.4595e-01, -1.4890e-02],
          [-3.0318e-01, -2.0118e-01, -9.9424e-02]],

         [[ 7.1756e-02,  1.7044e-02, -1.7197e-01],
          [ 3.0501e-02, -9.9552e-02, -3.6221e-01],
          [-5.5716e-02,  8.5441e-02, -6.3712e-02]],

         [[-2.3273e-01, -1.0233e-01, -2.1892e-01],
          [-1.1771e-01,  7.9925e-02,  6.3791e-02],
          [ 1.2777e-01,  2.5987e-01,  2.0018e-01]]],


        [[[-3.2275e-41,  5.6533e-41, -2.6097e-40],
          [-3.7594e-40, -1.3330e-40,  5.1386e-40],
          [-9.1332e-41,  2.3388e-40, -1.9198e-40]],

         [[ 2.8516e-40, -4.7779e-40,  6.2220e-41],
          [-1.0118e-40, -1.7316e-40, -2.8453e-40],
          [ 2.5727e-40,  3.9512e-40,  1.7904e-40]],

         [[-2.3060e-40,  2.4242e-40, -2.9094e-40],
          [ 2.4539e-40,  1.2900e-40, -3.7390e-40],
          [ 3.2558e-40,  4.8081e-40, -1.4512e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0020,  0.0068,  0.0220],
          [-0.0060, -0.0013,  0.0095],
          [-0.0096, -0.0044,  0.0021]],

         [[-0.0000,  0.0074,  0.0194],
          [-0.0055, -0.0004,  0.0112],
          [-0.0101, -0.0047,  0.0037]],

         [[ 0.0062,  0.0111,  0.0205],
          [ 0.0015,  0.0036,  0.0124],
          [ 0.0001,  0.0037,  0.0101]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0620,  0.0807,  0.0857],
          [ 0.0729,  0.0713,  0.0724],
          [ 0.0581,  0.0605,  0.0410]],

         [[ 0.0111,  0.0248,  0.0309],
          [ 0.0471,  0.0393,  0.0328],
          [ 0.0420,  0.0403,  0.0118]],

         [[-0.0029,  0.0123,  0.0222],
          [ 0.0293,  0.0231,  0.0239],
          [ 0.0195,  0.0174, -0.0048]]],


        ...,


        [[[-0.0091, -0.0131, -0.0150],
          [-0.0084, -0.0117, -0.0110],
          [-0.0057, -0.0071, -0.0042]],

         [[ 0.0005, -0.0037, -0.0088],
          [-0.0004, -0.0046, -0.0062],
          [-0.0011, -0.0029, -0.0010]],

         [[ 0.0011, -0.0035, -0.0092],
          [ 0.0011, -0.0028, -0.0047],
          [-0.0003, -0.0016,  0.0009]]],


        [[[ 0.0013, -0.0026, -0.0096],
          [-0.0014, -0.0057, -0.0059],
          [ 0.0000, -0.0027,  0.0017]],

         [[ 0.0016, -0.0037, -0.0107],
          [-0.0017, -0.0054, -0.0065],
          [-0.0011, -0.0031, -0.0004]],

         [[ 0.0066,  0.0021, -0.0044],
          [ 0.0040, -0.0004, -0.0020],
          [ 0.0025, -0.0014,  0.0019]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0427]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 97 | Batch_idx: 0 |  Loss: (0.1922) | Acc: (92.00%) (119/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2036) | Acc: (93.00%) (1311/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2115) | Acc: (92.00%) (2492/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2110) | Acc: (92.00%) (3680/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2116) | Acc: (92.00%) (4862/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2136) | Acc: (92.00%) (6048/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2078) | Acc: (92.00%) (7255/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2102) | Acc: (92.00%) (8433/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2082) | Acc: (92.00%) (9632/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2061) | Acc: (92.00%) (10831/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2023) | Acc: (93.00%) (12033/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2023) | Acc: (93.00%) (13230/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2030) | Acc: (93.00%) (14418/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2033) | Acc: (93.00%) (15597/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2034) | Acc: (93.00%) (16796/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2049) | Acc: (93.00%) (17981/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2056) | Acc: (92.00%) (19153/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2083) | Acc: (92.00%) (20334/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2103) | Acc: (92.00%) (21506/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2122) | Acc: (92.00%) (22676/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2114) | Acc: (92.00%) (23866/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2136) | Acc: (92.00%) (25026/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2143) | Acc: (92.00%) (26208/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2141) | Acc: (92.00%) (27401/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2141) | Acc: (92.00%) (28591/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2147) | Acc: (92.00%) (29770/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2156) | Acc: (92.00%) (30949/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2163) | Acc: (92.00%) (32124/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2162) | Acc: (92.00%) (33309/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2164) | Acc: (92.00%) (34495/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2160) | Acc: (92.00%) (35683/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2157) | Acc: (92.00%) (36869/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2148) | Acc: (92.00%) (38072/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2147) | Acc: (92.00%) (39254/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2150) | Acc: (92.00%) (40435/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2165) | Acc: (92.00%) (41598/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2170) | Acc: (92.00%) (42768/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2179) | Acc: (92.00%) (43928/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2172) | Acc: (92.00%) (45124/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2172) | Acc: (92.00%) (46261/50000)
# TEST : Loss: (0.3137) | Acc: (89.00%) (8988/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9442e-01, -2.2346e-01,  5.6331e-02],
          [-7.1979e-02,  3.1902e-01,  2.3584e-01],
          [ 1.0301e-01,  4.7771e-02, -4.1256e-02]],

         [[-2.2056e-01,  2.1198e-01,  2.1040e-01],
          [ 2.1246e-02,  3.7472e-01,  2.3499e-01],
          [ 2.0613e-01, -2.7836e-02,  1.3048e-01]],

         [[-2.1255e-01, -6.0430e-02, -7.0409e-02],
          [-2.7114e-01, -1.0520e-01, -9.6518e-02],
          [-2.0703e-01, -1.0659e-01, -1.6330e-01]]],


        [[[-1.0660e-40,  1.1547e-42, -2.9194e-40],
          [-8.6955e-41,  3.6819e-40, -2.1056e-40],
          [ 2.5785e-40,  6.7449e-41,  6.7251e-41]],

         [[ 1.9338e-40,  2.0284e-40, -2.8013e-40],
          [-1.8508e-40,  4.5426e-40, -1.6797e-40],
          [-1.3977e-40,  3.9692e-41,  1.4128e-40]],

         [[-4.4991e-41, -2.2380e-40,  3.3428e-40],
          [ 1.6133e-41, -8.9445e-41,  2.2445e-41],
          [ 2.2125e-40, -1.9847e-40, -4.7252e-40]]],


        [[[ 3.6223e-02,  1.1111e-01, -7.2578e-02],
          [ 2.6717e-02,  2.0629e-01, -9.8037e-02],
          [ 1.2449e-01,  3.2506e-01,  3.2105e-01]],

         [[-2.0943e-01, -6.5725e-02, -1.6565e-01],
          [-3.5380e-01, -2.9737e-01, -2.6492e-01],
          [-2.6297e-01, -3.8135e-01,  5.4081e-02]],

         [[ 2.1432e-01,  1.0300e-01,  1.8807e-01],
          [ 1.8585e-01,  1.0795e-01,  3.0802e-02],
          [ 2.7644e-02,  9.4816e-02,  3.2784e-02]]],


        ...,


        [[[ 2.6192e-01,  6.3766e-02,  8.4701e-02],
          [ 1.8815e-01, -2.1484e-01, -5.2700e-02],
          [ 1.1048e-02, -1.2086e-01, -7.7521e-02]],

         [[-1.0339e-01, -8.8975e-02,  2.4065e-03],
          [-1.7513e-01, -2.7369e-01,  5.0187e-02],
          [-8.1680e-03,  1.8012e-01,  2.1108e-01]],

         [[-8.4277e-02, -1.3159e-01,  1.3587e-01],
          [-8.3389e-02, -2.4286e-01, -1.5986e-01],
          [-1.6599e-02, -5.7570e-02, -7.6716e-02]]],


        [[[ 1.2504e-01,  1.7571e-01,  2.8894e-01],
          [ 1.6128e-01,  1.4866e-01, -1.9489e-03],
          [-3.0713e-01, -2.0935e-01, -9.4280e-02]],

         [[ 7.3305e-02,  2.5030e-02, -1.5685e-01],
          [ 4.1712e-02, -9.3681e-02, -3.4892e-01],
          [-5.6290e-02,  8.0536e-02, -5.3823e-02]],

         [[-2.3274e-01, -9.4086e-02, -2.0419e-01],
          [-1.0851e-01,  8.9115e-02,  7.8374e-02],
          [ 1.3115e-01,  2.6558e-01,  2.1574e-01]]],


        [[[ 1.0781e-40,  3.3667e-40, -5.4111e-40],
          [ 1.8435e-40, -1.3331e-40,  9.3778e-41],
          [-3.7150e-40,  2.3390e-40, -1.9199e-40]],

         [[-1.3505e-40, -3.3775e-40, -3.5800e-40],
          [-1.0119e-40,  1.0699e-40, -4.4113e-42],
          [ 3.9737e-40, -1.6515e-40,  3.8980e-41]],

         [[ 4.9506e-41,  2.4245e-40,  1.2924e-40],
          [ 1.0535e-40, -4.3128e-40, -2.3387e-40],
          [ 1.8554e-40,  3.4077e-40, -1.4514e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0112, -0.0067, -0.0038],
          [-0.0075, -0.0039, -0.0053],
          [ 0.0005,  0.0026,  0.0007]],

         [[-0.0052,  0.0017,  0.0049],
          [-0.0005,  0.0060,  0.0048],
          [ 0.0064,  0.0101,  0.0080]],

         [[ 0.0015,  0.0052,  0.0088],
          [ 0.0052,  0.0090,  0.0081],
          [ 0.0109,  0.0128,  0.0102]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0030,  0.0053,  0.0028],
          [-0.0032,  0.0022,  0.0005],
          [ 0.0126,  0.0103,  0.0034]],

         [[ 0.0007, -0.0019, -0.0050],
          [-0.0068, -0.0078, -0.0086],
          [ 0.0030, -0.0031, -0.0078]],

         [[-0.0102, -0.0152, -0.0203],
          [-0.0111, -0.0178, -0.0226],
          [-0.0038, -0.0152, -0.0253]]],


        ...,


        [[[-0.0052, -0.0026, -0.0029],
          [-0.0049, -0.0022, -0.0040],
          [-0.0031, -0.0030, -0.0049]],

         [[-0.0043, -0.0022, -0.0028],
          [-0.0044, -0.0017, -0.0036],
          [-0.0032, -0.0028, -0.0048]],

         [[-0.0020, -0.0003, -0.0019],
          [-0.0027, -0.0003, -0.0026],
          [-0.0023, -0.0016, -0.0038]]],


        [[[ 0.0287,  0.0247,  0.0246],
          [ 0.0202,  0.0252,  0.0286],
          [ 0.0177,  0.0276,  0.0280]],

         [[ 0.0306,  0.0277,  0.0235],
          [ 0.0230,  0.0247,  0.0243],
          [ 0.0216,  0.0265,  0.0261]],

         [[ 0.0253,  0.0227,  0.0161],
          [ 0.0194,  0.0201,  0.0168],
          [ 0.0197,  0.0236,  0.0201]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0426]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 98 | Batch_idx: 0 |  Loss: (0.1082) | Acc: (97.00%) (125/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.1659) | Acc: (94.00%) (1327/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.1920) | Acc: (93.00%) (2507/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2008) | Acc: (93.00%) (3692/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2109) | Acc: (92.00%) (4870/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2053) | Acc: (92.00%) (6068/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2121) | Acc: (92.00%) (7240/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2119) | Acc: (92.00%) (8428/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2096) | Acc: (92.00%) (9623/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2100) | Acc: (92.00%) (10812/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2103) | Acc: (92.00%) (11999/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2096) | Acc: (92.00%) (13198/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2096) | Acc: (92.00%) (14379/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2084) | Acc: (92.00%) (15573/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2080) | Acc: (92.00%) (16756/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2087) | Acc: (92.00%) (17943/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2060) | Acc: (92.00%) (19158/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2068) | Acc: (92.00%) (20339/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2050) | Acc: (92.00%) (21542/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2035) | Acc: (93.00%) (22750/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2031) | Acc: (93.00%) (23952/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2023) | Acc: (93.00%) (25154/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2025) | Acc: (93.00%) (26342/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2028) | Acc: (93.00%) (27529/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2023) | Acc: (93.00%) (28729/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2022) | Acc: (93.00%) (29927/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2018) | Acc: (93.00%) (31122/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.1997) | Acc: (93.00%) (32338/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.1992) | Acc: (93.00%) (33537/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.1989) | Acc: (93.00%) (34730/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.1980) | Acc: (93.00%) (35934/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.1981) | Acc: (93.00%) (37131/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.1977) | Acc: (93.00%) (38335/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.1969) | Acc: (93.00%) (39542/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.1963) | Acc: (93.00%) (40750/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.1960) | Acc: (93.00%) (41944/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.1963) | Acc: (93.00%) (43137/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.1963) | Acc: (93.00%) (44335/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.1967) | Acc: (93.00%) (45522/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.1962) | Acc: (93.00%) (46688/50000)
# TEST : Loss: (0.2966) | Acc: (90.00%) (9045/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9416e-01, -2.2325e-01,  5.5573e-02],
          [-7.2586e-02,  3.1709e-01,  2.3463e-01],
          [ 1.0143e-01,  4.6987e-02, -4.1670e-02]],

         [[-2.2080e-01,  2.1021e-01,  2.0851e-01],
          [ 1.9843e-02,  3.7205e-01,  2.3326e-01],
          [ 2.0385e-01, -2.8908e-02,  1.2914e-01]],

         [[-2.1313e-01, -6.1173e-02, -7.1216e-02],
          [-2.7198e-01, -1.0633e-01, -9.7167e-02],
          [-2.0825e-01, -1.0762e-01, -1.6371e-01]]],


        [[[ 2.3768e-40,  1.1736e-40,  3.8528e-40],
          [ 1.4068e-40, -1.9950e-40, -3.3424e-40],
          [ 1.5286e-40, -1.6193e-40, -4.0311e-40]],

         [[ 3.1601e-40, -2.5563e-40, -1.7558e-40],
          [-3.0726e-40,  1.2126e-40,  2.9282e-40],
          [-1.4401e-40,  1.5627e-40,  1.4514e-40]],

         [[-2.8121e-40, -2.3163e-40, -3.5377e-40],
          [ 2.4920e-40,  2.4195e-41, -9.3813e-41],
          [ 1.1337e-40,  2.6469e-40, -1.3272e-40]]],


        [[[ 3.4995e-02,  1.1047e-01, -7.1556e-02],
          [ 2.6803e-02,  2.0595e-01, -9.7102e-02],
          [ 1.2452e-01,  3.2436e-01,  3.2147e-01]],

         [[-2.1075e-01, -6.6683e-02, -1.6492e-01],
          [-3.5315e-01, -2.9699e-01, -2.6374e-01],
          [-2.6246e-01, -3.8117e-01,  5.4981e-02]],

         [[ 2.1202e-01,  1.0166e-01,  1.8822e-01],
          [ 1.8535e-01,  1.0767e-01,  3.1740e-02],
          [ 2.7520e-02,  9.4244e-02,  3.3945e-02]]],


        ...,


        [[[ 2.6034e-01,  6.4516e-02,  8.4000e-02],
          [ 1.8820e-01, -2.1008e-01, -5.2371e-02],
          [ 1.3474e-02, -1.1695e-01, -7.6597e-02]],

         [[-1.0358e-01, -8.8451e-02,  8.1954e-04],
          [-1.7212e-01, -2.6765e-01,  4.8000e-02],
          [-5.6653e-03,  1.8093e-01,  2.0883e-01]],

         [[-8.5565e-02, -1.3095e-01,  1.3278e-01],
          [-8.2129e-02, -2.3502e-01, -1.5884e-01],
          [-1.4468e-02, -5.4387e-02, -7.5873e-02]]],


        [[[ 1.2417e-01,  1.7628e-01,  2.8869e-01],
          [ 1.6132e-01,  1.4781e-01, -2.7592e-03],
          [-3.0350e-01, -2.0903e-01, -9.4982e-02]],

         [[ 7.0671e-02,  2.4125e-02, -1.5584e-01],
          [ 4.0206e-02, -9.5019e-02, -3.4858e-01],
          [-5.5596e-02,  7.8419e-02, -5.5036e-02]],

         [[-2.3519e-01, -9.6015e-02, -2.0436e-01],
          [-1.1112e-01,  8.5455e-02,  7.5651e-02],
          [ 1.2896e-01,  2.6121e-01,  2.1242e-01]]],


        [[[ 1.0782e-40,  3.3669e-40, -2.6103e-40],
          [ 6.0463e-40,  6.7543e-42, -4.6646e-40],
          [-2.3143e-40, -4.6246e-41, -5.1952e-41]],

         [[-4.1523e-40,  8.2496e-41, -3.5804e-40],
          [ 3.8894e-41,  2.4709e-40,  2.7575e-40],
          [ 1.1721e-40, -5.8542e-40, -1.0110e-40]],

         [[ 3.2966e-40, -3.7688e-41,  4.0942e-40],
          [-1.7480e-40, -5.7140e-40,  1.8635e-40],
          [-9.4609e-41, -7.9462e-41, -5.0769e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0040]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0086]], device='cuda:0')

Epoch: 99 | Batch_idx: 0 |  Loss: (0.2100) | Acc: (92.00%) (119/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.1863) | Acc: (93.00%) (1317/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.1842) | Acc: (93.00%) (2515/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.1818) | Acc: (93.00%) (3721/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.1797) | Acc: (93.00%) (4924/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.1789) | Acc: (93.00%) (6125/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.1763) | Acc: (93.00%) (7338/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.1787) | Acc: (93.00%) (8528/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.1798) | Acc: (93.00%) (9734/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.1806) | Acc: (93.00%) (10938/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.1811) | Acc: (93.00%) (12144/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.1800) | Acc: (93.00%) (13351/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.1797) | Acc: (94.00%) (14562/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.1784) | Acc: (94.00%) (15769/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.1783) | Acc: (94.00%) (16977/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.1771) | Acc: (94.00%) (18178/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.1787) | Acc: (93.00%) (19371/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.1786) | Acc: (94.00%) (20575/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.1793) | Acc: (93.00%) (21757/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.1786) | Acc: (93.00%) (22965/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.1792) | Acc: (93.00%) (24162/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.1790) | Acc: (93.00%) (25365/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.1784) | Acc: (93.00%) (26577/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.1792) | Acc: (93.00%) (27774/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.1796) | Acc: (93.00%) (28966/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.1792) | Acc: (93.00%) (30178/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.1790) | Acc: (93.00%) (31392/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.1797) | Acc: (93.00%) (32583/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.1802) | Acc: (93.00%) (33780/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.1807) | Acc: (93.00%) (34981/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.1798) | Acc: (93.00%) (36195/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.1800) | Acc: (93.00%) (37400/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.1803) | Acc: (93.00%) (38585/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.1789) | Acc: (93.00%) (39810/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.1788) | Acc: (93.00%) (41014/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.1784) | Acc: (93.00%) (42223/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.1786) | Acc: (93.00%) (43429/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.1781) | Acc: (94.00%) (44643/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.1787) | Acc: (94.00%) (45844/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.1788) | Acc: (93.00%) (46999/50000)
# TEST : Loss: (0.2901) | Acc: (90.00%) (9053/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9342e-01, -2.2235e-01,  5.5342e-02],
          [-7.2298e-02,  3.1577e-01,  2.3361e-01],
          [ 1.0104e-01,  4.6795e-02, -4.1495e-02]],

         [[-2.1992e-01,  2.0935e-01,  2.0764e-01],
          [ 1.9762e-02,  3.7050e-01,  2.3228e-01],
          [ 2.0303e-01, -2.8790e-02,  1.2861e-01]],

         [[-2.1213e-01, -6.0896e-02, -7.0909e-02],
          [-2.7072e-01, -1.0586e-01, -9.6753e-02],
          [-2.0732e-01, -1.0715e-01, -1.6302e-01]]],


        [[[-1.1349e-40,  1.2098e-40, -7.5941e-41],
          [-9.4058e-41,  2.7433e-40,  2.5597e-40],
          [-7.9560e-41, -2.8645e-40, -5.3609e-40]],

         [[ 2.0634e-40, -2.2361e-41,  5.6903e-41],
          [-1.9762e-40, -2.3556e-40,  5.4222e-40],
          [-2.8725e-41,  1.5985e-40,  2.6909e-41]],

         [[ 4.3512e-40,  3.9236e-42, -1.2416e-40],
          [ 2.5637e-40,  1.4525e-40, -4.5850e-40],
          [-1.2257e-40,  2.7162e-40,  3.5081e-40]]],


        [[[ 3.4929e-02,  1.1025e-01, -7.1412e-02],
          [ 2.6751e-02,  2.0554e-01, -9.6908e-02],
          [ 1.2427e-01,  3.2371e-01,  3.2082e-01]],

         [[-2.1031e-01, -6.6538e-02, -1.6455e-01],
          [-3.5238e-01, -2.9633e-01, -2.6314e-01],
          [-2.6188e-01, -3.8033e-01,  5.4861e-02]],

         [[ 2.1156e-01,  1.0144e-01,  1.8780e-01],
          [ 1.8493e-01,  1.0743e-01,  3.1666e-02],
          [ 2.7458e-02,  9.4031e-02,  3.3868e-02]]],


        ...,


        [[[ 2.5777e-01,  6.3843e-02,  8.3182e-02],
          [ 1.8601e-01, -2.0732e-01, -5.1776e-02],
          [ 1.3332e-02, -1.1563e-01, -7.5802e-02]],

         [[-1.0230e-01, -8.7229e-02,  8.1020e-04],
          [-1.6939e-01, -2.6198e-01,  4.7321e-02],
          [-5.5950e-03,  1.7839e-01,  2.0636e-01]],

         [[-8.4221e-02, -1.2855e-01,  1.3092e-01],
          [-8.0313e-02, -2.2626e-01, -1.5588e-01],
          [-1.4245e-02, -5.3399e-02, -7.4779e-02]]],


        [[[ 1.2340e-01,  1.7517e-01,  2.8702e-01],
          [ 1.6033e-01,  1.4693e-01, -2.7437e-03],
          [-3.0175e-01, -2.0785e-01, -9.4453e-02]],

         [[ 7.0236e-02,  2.3978e-02, -1.5490e-01],
          [ 3.9957e-02, -9.4442e-02, -3.4650e-01],
          [-5.5263e-02,  7.7961e-02, -5.4715e-02]],

         [[-2.3370e-01, -9.5416e-02, -2.0307e-01],
          [-1.1042e-01,  8.4925e-02,  7.5174e-02],
          [ 1.2816e-01,  2.5963e-01,  2.1112e-01]]],


        [[[-3.2275e-41,  5.6519e-41,  2.9928e-40],
          [ 4.6456e-40,  1.4684e-40, -6.0656e-40],
          [ 1.8885e-40, -3.2642e-40,  8.8119e-41]],

         [[-2.7516e-40,  3.6269e-40,  6.2213e-41],
          [ 1.7899e-40,  1.0701e-40,  2.7577e-40],
          [-3.0307e-40, -4.4535e-40, -1.0111e-40]],

         [[ 3.2967e-40, -3.1786e-40,  2.6936e-40],
          [-3.1489e-40, -1.5117e-40,  4.6654e-40],
          [-2.3471e-40, -3.5965e-40,  1.3501e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0336]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0223]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 100 | Batch_idx: 0 |  Loss: (0.1905) | Acc: (92.00%) (119/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.1717) | Acc: (93.00%) (1319/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.1918) | Acc: (93.00%) (2502/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.1935) | Acc: (93.00%) (3701/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2001) | Acc: (93.00%) (4889/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2170) | Acc: (92.00%) (6044/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2294) | Acc: (91.00%) (7183/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2420) | Acc: (91.00%) (8319/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2474) | Acc: (91.00%) (9464/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2531) | Acc: (91.00%) (10610/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2584) | Acc: (90.00%) (11764/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2620) | Acc: (90.00%) (12911/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2643) | Acc: (90.00%) (14056/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2630) | Acc: (90.00%) (15224/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2601) | Acc: (90.00%) (16407/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2608) | Acc: (90.00%) (17563/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2590) | Acc: (90.00%) (18750/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2601) | Acc: (90.00%) (19915/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2592) | Acc: (91.00%) (21091/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2580) | Acc: (91.00%) (22272/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2549) | Acc: (91.00%) (23473/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2543) | Acc: (91.00%) (24639/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2534) | Acc: (91.00%) (25824/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2544) | Acc: (91.00%) (26978/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2551) | Acc: (91.00%) (28126/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2542) | Acc: (91.00%) (29305/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2538) | Acc: (91.00%) (30490/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2522) | Acc: (91.00%) (31676/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2526) | Acc: (91.00%) (32848/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2528) | Acc: (91.00%) (34015/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2542) | Acc: (91.00%) (35171/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2529) | Acc: (91.00%) (36359/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2527) | Acc: (91.00%) (37528/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2518) | Acc: (91.00%) (38713/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2524) | Acc: (91.00%) (39875/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2511) | Acc: (91.00%) (41054/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2517) | Acc: (91.00%) (42224/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2517) | Acc: (91.00%) (43387/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2516) | Acc: (91.00%) (44555/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2516) | Acc: (91.00%) (45684/50000)
# TEST : Loss: (0.3379) | Acc: (89.00%) (8907/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8753e-01, -2.1342e-01,  6.5950e-02],
          [-6.9239e-02,  3.1827e-01,  2.3504e-01],
          [ 1.0214e-01,  3.9985e-02, -4.2671e-02]],

         [[-2.1770e-01,  2.1806e-01,  2.1795e-01],
          [ 1.8615e-02,  3.7322e-01,  2.3439e-01],
          [ 2.0106e-01, -3.6973e-02,  1.2498e-01]],

         [[-2.1336e-01, -5.8143e-02, -6.7263e-02],
          [-2.7676e-01, -1.1022e-01, -1.0165e-01],
          [-2.1346e-01, -1.2235e-01, -1.7467e-01]]],


        [[[-3.6218e-40,  1.1351e-42, -3.2176e-40],
          [-2.1977e-40,  4.0444e-40, -1.0734e-40],
          [ 1.6190e-40, -1.7073e-40, -1.7543e-40]],

         [[-3.3127e-41,  2.2429e-40,  3.0318e-40],
          [ 4.2256e-41, -2.4137e-40,  3.0917e-40],
          [ 9.3568e-41,  3.9674e-41, -9.7610e-41]],

         [[-1.7304e-40,  2.5229e-40, -3.7423e-40],
          [ 1.6093e-41,  1.4824e-40,  5.2148e-40],
          [-2.4869e-40,  2.9745e-41,  4.8369e-40]]],


        [[[ 3.2861e-02,  1.1428e-01, -5.6591e-02],
          [ 2.1055e-02,  2.0479e-01, -9.7244e-02],
          [ 1.1892e-01,  3.1500e-01,  3.1008e-01]],

         [[-2.1120e-01, -6.0408e-02, -1.5099e-01],
          [-3.6216e-01, -3.0346e-01, -2.6954e-01],
          [-2.6742e-01, -3.9422e-01,  3.8521e-02]],

         [[ 2.1790e-01,  1.1321e-01,  1.9947e-01],
          [ 1.9016e-01,  1.1482e-01,  3.1060e-02],
          [ 3.5000e-02,  9.4925e-02,  2.6562e-02]]],


        ...,


        [[[ 2.5346e-01,  5.7729e-02,  6.9433e-02],
          [ 1.8711e-01, -2.1642e-01, -6.6780e-02],
          [ 2.2328e-02, -1.1656e-01, -7.7944e-02]],

         [[-9.4997e-02, -8.3694e-02, -1.0589e-03],
          [-1.6026e-01, -2.7222e-01,  3.9354e-02],
          [ 7.0226e-03,  1.7625e-01,  2.0895e-01]],

         [[-8.6238e-02, -1.3410e-01,  1.2760e-01],
          [-7.6288e-02, -2.4441e-01, -1.5589e-01],
          [-5.3240e-03, -5.6616e-02, -6.2278e-02]]],


        [[[ 1.4629e-01,  1.9016e-01,  2.9386e-01],
          [ 1.6688e-01,  1.5216e-01, -3.0868e-03],
          [-2.9670e-01, -2.0046e-01, -9.4478e-02]],

         [[ 9.3734e-02,  3.5734e-02, -1.4996e-01],
          [ 4.9100e-02, -9.3202e-02, -3.5097e-01],
          [-5.0429e-02,  8.2614e-02, -5.6568e-02]],

         [[-2.2375e-01, -9.1154e-02, -2.0294e-01],
          [-1.1111e-01,  8.3662e-02,  7.1004e-02],
          [ 1.2872e-01,  2.6592e-01,  2.1583e-01]]],


        [[[-1.7238e-40, -2.2368e-40,  5.7947e-40],
          [-9.5839e-41,  1.4685e-40, -1.8634e-40],
          [ 4.6907e-40, -3.2644e-40,  8.8132e-41]],

         [[ 1.4514e-40,  2.2260e-40,  4.8251e-40],
          [ 1.7899e-40, -1.7319e-40, -4.4071e-42],
          [-4.4319e-40,  1.1503e-40,  3.8980e-41]],

         [[ 4.9491e-41, -3.1787e-40, -1.5091e-40],
          [-1.7481e-40,  4.0922e-40,  3.2646e-40],
          [-9.4618e-41, -2.1958e-40,  1.3502e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0023,  0.0025, -0.0050],
          [ 0.0113,  0.0150,  0.0048],
          [ 0.0148,  0.0163,  0.0061]],

         [[ 0.0110,  0.0171,  0.0120],
          [ 0.0243,  0.0289,  0.0207],
          [ 0.0284,  0.0314,  0.0233]],

         [[ 0.0140,  0.0212,  0.0202],
          [ 0.0245,  0.0307,  0.0268],
          [ 0.0292,  0.0350,  0.0313]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0663,  0.0622,  0.0490],
          [ 0.0764,  0.0733,  0.0633],
          [ 0.1003,  0.0859,  0.0792]],

         [[ 0.0546,  0.0490,  0.0346],
          [ 0.0613,  0.0584,  0.0494],
          [ 0.0865,  0.0715,  0.0658]],

         [[ 0.0437,  0.0354,  0.0199],
          [ 0.0452,  0.0407,  0.0320],
          [ 0.0650,  0.0498,  0.0445]]],


        ...,


        [[[-0.0000,  0.0003,  0.0015],
          [-0.0017, -0.0014,  0.0003],
          [-0.0037, -0.0040, -0.0023]],

         [[ 0.0021,  0.0021,  0.0032],
          [ 0.0003,  0.0009,  0.0024],
          [-0.0010, -0.0012, -0.0002]],

         [[ 0.0015,  0.0010,  0.0016],
          [-0.0004, -0.0003,  0.0008],
          [-0.0016, -0.0024, -0.0018]]],


        [[[ 0.0154,  0.0115,  0.0083],
          [ 0.0147,  0.0146,  0.0163],
          [ 0.0139,  0.0138,  0.0178]],

         [[ 0.0145,  0.0110,  0.0089],
          [ 0.0143,  0.0137,  0.0163],
          [ 0.0149,  0.0150,  0.0181]],

         [[ 0.0120,  0.0084,  0.0058],
          [ 0.0098,  0.0090,  0.0121],
          [ 0.0107,  0.0116,  0.0142]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0311]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 101 | Batch_idx: 0 |  Loss: (0.1910) | Acc: (92.00%) (118/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2186) | Acc: (92.00%) (1300/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2177) | Acc: (92.00%) (2492/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2122) | Acc: (92.00%) (3677/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2049) | Acc: (93.00%) (4881/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2052) | Acc: (93.00%) (6077/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2083) | Acc: (92.00%) (7259/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2056) | Acc: (93.00%) (8457/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2123) | Acc: (92.00%) (9631/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2131) | Acc: (92.00%) (10811/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2132) | Acc: (92.00%) (12003/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2133) | Acc: (92.00%) (13190/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2154) | Acc: (92.00%) (14374/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2162) | Acc: (92.00%) (15551/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2156) | Acc: (92.00%) (16734/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2168) | Acc: (92.00%) (17906/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2154) | Acc: (92.00%) (19099/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2152) | Acc: (92.00%) (20282/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2153) | Acc: (92.00%) (21477/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2141) | Acc: (92.00%) (22674/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2150) | Acc: (92.00%) (23852/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2157) | Acc: (92.00%) (25025/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2154) | Acc: (92.00%) (26218/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2158) | Acc: (92.00%) (27391/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2154) | Acc: (92.00%) (28580/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2147) | Acc: (92.00%) (29773/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2145) | Acc: (92.00%) (30964/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2141) | Acc: (92.00%) (32148/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2137) | Acc: (92.00%) (33330/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2148) | Acc: (92.00%) (34515/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2145) | Acc: (92.00%) (35712/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2138) | Acc: (92.00%) (36905/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2145) | Acc: (92.00%) (38079/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2144) | Acc: (92.00%) (39266/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2147) | Acc: (92.00%) (40448/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2140) | Acc: (92.00%) (41636/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2126) | Acc: (92.00%) (42845/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2123) | Acc: (92.00%) (44038/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2119) | Acc: (92.00%) (45229/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2119) | Acc: (92.00%) (46370/50000)
# TEST : Loss: (0.3408) | Acc: (89.00%) (8935/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9421e-01, -2.2555e-01,  4.5151e-02],
          [-6.6946e-02,  3.1652e-01,  2.3178e-01],
          [ 1.1927e-01,  5.2297e-02, -3.3347e-02]],

         [[-2.2154e-01,  2.0994e-01,  2.0021e-01],
          [ 1.9728e-02,  3.7066e-01,  2.2906e-01],
          [ 2.1451e-01, -2.8532e-02,  1.2891e-01]],

         [[-2.2751e-01, -7.2367e-02, -8.2496e-02],
          [-2.8426e-01, -1.1722e-01, -1.0676e-01],
          [-2.0390e-01, -1.1595e-01, -1.7000e-01]]],


        [[[-2.4495e-40, -1.2460e-40, -4.5411e-40],
          [-1.0009e-40,  1.6155e-40, -3.6182e-40],
          [ 2.8962e-40,  7.7175e-41,  3.2915e-40]],

         [[-2.8442e-40,  2.2965e-40,  3.1002e-40],
          [-2.0817e-40, -4.9868e-40, -3.1454e-40],
          [ 9.6398e-41, -8.6312e-41, -1.0012e-40]],

         [[-1.7673e-40,  2.5739e-40,  1.2175e-40],
          [-2.3580e-40,  2.4186e-41,  1.5299e-40],
          [-1.2845e-40, -2.2333e-40,  3.6628e-40]]],


        [[[ 4.4367e-02,  1.1603e-01, -5.9085e-02],
          [ 2.5302e-02,  2.0148e-01, -9.9207e-02],
          [ 1.2254e-01,  3.1466e-01,  3.1628e-01]],

         [[-1.9711e-01, -5.7388e-02, -1.5411e-01],
          [-3.5811e-01, -3.0605e-01, -2.7227e-01],
          [-2.6821e-01, -3.9643e-01,  4.5472e-02]],

         [[ 2.2840e-01,  1.1914e-01,  1.9846e-01],
          [ 1.9472e-01,  1.1768e-01,  3.4437e-02],
          [ 3.7167e-02,  9.8848e-02,  3.9159e-02]]],


        ...,


        [[[ 2.6985e-01,  6.8040e-02,  8.6092e-02],
          [ 2.0174e-01, -2.0535e-01, -5.2366e-02],
          [ 2.2050e-02, -1.0966e-01, -7.2257e-02]],

         [[-7.7794e-02, -7.4001e-02,  1.0485e-02],
          [-1.4610e-01, -2.6152e-01,  4.5189e-02],
          [-1.5816e-03,  1.7335e-01,  2.0152e-01]],

         [[-7.8941e-02, -1.2608e-01,  1.3298e-01],
          [-8.8258e-02, -2.4509e-01, -1.5783e-01],
          [-2.7550e-02, -5.9663e-02, -6.9666e-02]]],


        [[[ 1.4416e-01,  1.9769e-01,  2.9257e-01],
          [ 1.6607e-01,  1.5976e-01, -9.4889e-03],
          [-2.9484e-01, -1.9727e-01, -1.0378e-01]],

         [[ 9.7316e-02,  4.6123e-02, -1.4646e-01],
          [ 5.1216e-02, -8.1545e-02, -3.5143e-01],
          [-4.5395e-02,  9.0364e-02, -5.9746e-02]],

         [[-2.2128e-01, -8.0942e-02, -1.9491e-01],
          [-1.0918e-01,  9.8394e-02,  7.6195e-02],
          [ 1.3412e-01,  2.7801e-01,  2.1801e-01]]],


        [[[-1.7238e-40, -2.2370e-40,  2.9930e-40],
          [-5.1617e-40,  6.7529e-42,  3.7402e-40],
          [ 3.2897e-40, -4.6258e-41, -5.1955e-41]],

         [[ 4.2535e-40, -1.9770e-40,  4.8252e-40],
          [ 3.8893e-41, -3.1330e-40, -2.8461e-40],
          [-1.6299e-40,  5.3536e-40,  1.7908e-40]],

         [[-2.3072e-40, -3.7678e-41, -4.3111e-40],
          [ 1.0539e-40,  5.4933e-40, -9.3817e-41],
          [ 1.8558e-40,  2.0071e-40, -5.0769e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0015, -0.0072,  0.0017],
          [ 0.0061, -0.0021,  0.0001],
          [ 0.0116,  0.0067,  0.0010]],

         [[-0.0157, -0.0220, -0.0123],
          [-0.0072, -0.0153, -0.0114],
          [ 0.0004, -0.0042, -0.0083]],

         [[-0.0132, -0.0204, -0.0105],
          [-0.0066, -0.0135, -0.0073],
          [ 0.0000, -0.0020, -0.0023]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0149,  0.0058,  0.0035],
          [ 0.0079,  0.0179,  0.0245],
          [ 0.0085,  0.0202,  0.0265]],

         [[-0.0131,  0.0054, -0.0029],
          [ 0.0081,  0.0169,  0.0171],
          [ 0.0052,  0.0142,  0.0171]],

         [[-0.0075,  0.0025, -0.0099],
          [ 0.0061,  0.0069,  0.0018],
          [ 0.0026,  0.0048,  0.0014]]],


        ...,


        [[[ 0.0061, -0.0015, -0.0007],
          [ 0.0079,  0.0025,  0.0045],
          [ 0.0091,  0.0051,  0.0061]],

         [[ 0.0050, -0.0020, -0.0021],
          [ 0.0065,  0.0011,  0.0021],
          [ 0.0072,  0.0037,  0.0039]],

         [[ 0.0045, -0.0010, -0.0009],
          [ 0.0041,  0.0002,  0.0019],
          [ 0.0041,  0.0018,  0.0028]]],


        [[[-0.0076, -0.0105, -0.0160],
          [-0.0058, -0.0088, -0.0117],
          [-0.0106, -0.0120, -0.0112]],

         [[-0.0128, -0.0141, -0.0182],
          [-0.0109, -0.0132, -0.0154],
          [-0.0156, -0.0172, -0.0157]],

         [[-0.0148, -0.0155, -0.0192],
          [-0.0125, -0.0133, -0.0159],
          [-0.0164, -0.0170, -0.0162]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0310]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 102 | Batch_idx: 0 |  Loss: (0.2243) | Acc: (92.00%) (118/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2348) | Acc: (91.00%) (1284/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.2480) | Acc: (91.00%) (2448/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2599) | Acc: (90.00%) (3607/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2670) | Acc: (90.00%) (4767/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2616) | Acc: (91.00%) (5941/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2540) | Acc: (91.00%) (7127/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2534) | Acc: (91.00%) (8294/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2457) | Acc: (91.00%) (9486/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2418) | Acc: (91.00%) (10668/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2391) | Acc: (91.00%) (11853/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2383) | Acc: (91.00%) (13034/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2331) | Acc: (91.00%) (14235/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2318) | Acc: (91.00%) (15422/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2302) | Acc: (92.00%) (16605/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2282) | Acc: (92.00%) (17792/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2273) | Acc: (92.00%) (18976/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2258) | Acc: (92.00%) (20160/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2223) | Acc: (92.00%) (21373/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2214) | Acc: (92.00%) (22564/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2191) | Acc: (92.00%) (23773/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2178) | Acc: (92.00%) (24969/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2173) | Acc: (92.00%) (26158/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2167) | Acc: (92.00%) (27351/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2151) | Acc: (92.00%) (28555/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2139) | Acc: (92.00%) (29751/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2142) | Acc: (92.00%) (30937/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2130) | Acc: (92.00%) (32136/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2122) | Acc: (92.00%) (33327/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2112) | Acc: (92.00%) (34533/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2103) | Acc: (92.00%) (35728/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2092) | Acc: (92.00%) (36933/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2086) | Acc: (92.00%) (38131/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2080) | Acc: (92.00%) (39333/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2067) | Acc: (92.00%) (40545/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2058) | Acc: (92.00%) (41752/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2048) | Acc: (92.00%) (42962/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2046) | Acc: (92.00%) (44163/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2039) | Acc: (93.00%) (45361/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2038) | Acc: (93.00%) (46516/50000)
# TEST : Loss: (0.3130) | Acc: (89.00%) (8997/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9533e-01, -2.2568e-01,  4.4049e-02],
          [-6.9844e-02,  3.1319e-01,  2.2906e-01],
          [ 1.1452e-01,  4.8240e-02, -3.5476e-02]],

         [[-2.2047e-01,  2.1080e-01,  2.0075e-01],
          [ 1.8819e-02,  3.6984e-01,  2.2874e-01],
          [ 2.1191e-01, -2.9400e-02,  1.2880e-01]],

         [[-2.2670e-01, -7.0562e-02, -8.0967e-02],
          [-2.8457e-01, -1.1667e-01, -1.0637e-01],
          [-2.0556e-01, -1.1692e-01, -1.7011e-01]]],


        [[[ 1.3398e-40, -1.2694e-40, -3.3597e-40],
          [ 1.5288e-40,  1.6401e-40, -2.4055e-40],
          [ 1.6724e-40,  7.9500e-41,  5.9308e-40]],

         [[-2.8912e-40, -2.2384e-41,  6.0580e-41],
          [-2.1296e-40, -2.5130e-40, -1.9182e-40],
          [-2.8731e-41, -8.8603e-41,  2.6919e-41]],

         [[ 7.7807e-41,  3.8858e-42,  5.0892e-40],
          [-2.4041e-40, -1.0464e-40, -3.5945e-40],
          [ 1.2528e-40, -2.2776e-40, -1.4494e-40]]],


        [[[ 4.7877e-02,  1.1877e-01, -5.6770e-02],
          [ 2.6768e-02,  2.0215e-01, -9.8535e-02],
          [ 1.2332e-01,  3.1459e-01,  3.1568e-01]],

         [[-1.9218e-01, -5.3254e-02, -1.4994e-01],
          [-3.5508e-01, -3.0339e-01, -2.6980e-01],
          [-2.6573e-01, -3.9401e-01,  4.6508e-02]],

         [[ 2.3237e-01,  1.2355e-01,  2.0275e-01],
          [ 1.9731e-01,  1.2104e-01,  3.8384e-02],
          [ 3.9856e-02,  1.0188e-01,  4.2137e-02]]],


        ...,


        [[[ 2.7303e-01,  7.3351e-02,  9.2837e-02],
          [ 2.0604e-01, -1.9669e-01, -4.4618e-02],
          [ 2.8718e-02, -1.0245e-01, -6.5272e-02]],

         [[-7.1330e-02, -6.6715e-02,  1.8242e-02],
          [-1.3685e-01, -2.4757e-01,  5.3172e-02],
          [ 5.2931e-03,  1.7746e-01,  2.0597e-01]],

         [[-7.5896e-02, -1.2152e-01,  1.3618e-01],
          [-8.3043e-02, -2.2989e-01, -1.4899e-01],
          [-2.3208e-02, -5.5183e-02, -6.4390e-02]]],


        [[[ 1.4269e-01,  1.9860e-01,  2.9427e-01],
          [ 1.6441e-01,  1.6014e-01, -7.0704e-03],
          [-2.9477e-01, -1.9593e-01, -1.0241e-01]],

         [[ 9.6389e-02,  4.7817e-02, -1.4268e-01],
          [ 5.0356e-02, -8.0130e-02, -3.4773e-01],
          [-4.6200e-02,  9.0426e-02, -5.8904e-02]],

         [[-2.2097e-01, -7.9220e-02, -1.9170e-01],
          [-1.0928e-01,  9.8531e-02,  7.7053e-02],
          [ 1.3274e-01,  2.7704e-01,  2.1710e-01]]],


        [[[-3.2272e-41,  5.6514e-41, -2.6109e-40],
          [-3.7607e-40, -1.3335e-40,  5.1414e-40],
          [-9.1360e-41,  2.3396e-40, -1.9206e-40]],

         [[ 2.8525e-40, -4.7793e-40,  6.2219e-41],
          [-1.0122e-40, -1.7320e-40, -2.8462e-40],
          [ 2.5733e-40,  3.9528e-40,  1.7908e-40]],

         [[-2.3073e-40,  2.4254e-40, -2.9103e-40],
          [ 2.4550e-40,  1.2903e-40, -3.7403e-40],
          [ 3.2570e-40,  4.8094e-40, -1.4518e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0570]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0251]], device='cuda:0')

Epoch: 103 | Batch_idx: 0 |  Loss: (0.2100) | Acc: (93.00%) (120/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.1623) | Acc: (94.00%) (1328/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.1790) | Acc: (93.00%) (2522/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.1788) | Acc: (93.00%) (3723/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.1794) | Acc: (93.00%) (4926/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.1854) | Acc: (93.00%) (6116/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.1879) | Acc: (93.00%) (7307/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.1904) | Acc: (93.00%) (8507/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.1911) | Acc: (93.00%) (9699/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.1909) | Acc: (93.00%) (10894/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.1864) | Acc: (93.00%) (12119/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.1851) | Acc: (93.00%) (13324/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.1862) | Acc: (93.00%) (14521/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.1867) | Acc: (93.00%) (15712/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.1844) | Acc: (93.00%) (16934/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.1842) | Acc: (93.00%) (18132/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.1836) | Acc: (93.00%) (19335/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.1830) | Acc: (93.00%) (20540/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.1820) | Acc: (93.00%) (21750/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.1824) | Acc: (93.00%) (22941/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.1813) | Acc: (93.00%) (24145/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.1810) | Acc: (93.00%) (25351/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.1796) | Acc: (93.00%) (26569/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.1792) | Acc: (93.00%) (27778/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.1794) | Acc: (93.00%) (28969/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.1797) | Acc: (93.00%) (30172/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.1798) | Acc: (93.00%) (31370/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.1795) | Acc: (93.00%) (32581/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.1789) | Acc: (93.00%) (33791/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.1790) | Acc: (93.00%) (34996/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.1792) | Acc: (93.00%) (36199/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.1795) | Acc: (93.00%) (37397/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.1792) | Acc: (93.00%) (38600/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.1793) | Acc: (93.00%) (39801/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.1790) | Acc: (93.00%) (41016/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.1796) | Acc: (93.00%) (42204/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.1792) | Acc: (93.00%) (43417/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.1792) | Acc: (93.00%) (44618/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.1789) | Acc: (93.00%) (45829/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.1783) | Acc: (93.00%) (46998/50000)
# TEST : Loss: (0.3032) | Acc: (90.00%) (9023/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9464e-01, -2.2483e-01,  4.3875e-02],
          [-6.9582e-02,  3.1193e-01,  2.2810e-01],
          [ 1.1409e-01,  4.8046e-02, -3.5331e-02]],

         [[-2.1966e-01,  2.0999e-01,  1.9996e-01],
          [ 1.8746e-02,  3.6835e-01,  2.2781e-01],
          [ 2.1110e-01, -2.9283e-02,  1.2828e-01]],

         [[-2.2577e-01, -7.0278e-02, -8.0646e-02],
          [-2.8339e-01, -1.1620e-01, -1.0596e-01],
          [-2.0474e-01, -1.1646e-01, -1.6946e-01]]],


        [[[ 3.9579e-40,  1.1337e-42,  4.6435e-41],
          [ 2.8465e-40, -2.2439e-40,  1.4604e-40],
          [-8.9502e-41,  2.1152e-40,  3.3949e-40]],

         [[-3.3120e-41, -2.8290e-40, -1.9794e-40],
          [ 4.2420e-41,  2.6574e-40, -1.9514e-40],
          [-1.5835e-40,  3.9675e-41,  1.5792e-40]],

         [[-3.1242e-40, -2.5770e-40,  3.8647e-40],
          [ 1.6115e-41, -1.0651e-40, -4.9571e-40],
          [ 2.5730e-40,  2.9769e-41, -5.4023e-40]]],


        [[[ 4.7781e-02,  1.1853e-01, -5.6653e-02],
          [ 2.6714e-02,  2.0174e-01, -9.8331e-02],
          [ 1.2307e-01,  3.1395e-01,  3.1505e-01]],

         [[-1.9175e-01, -5.3133e-02, -1.4960e-01],
          [-3.5426e-01, -3.0269e-01, -2.6918e-01],
          [-2.6513e-01, -3.9314e-01,  4.6409e-02]],

         [[ 2.3184e-01,  1.2327e-01,  2.0229e-01],
          [ 1.9685e-01,  1.2076e-01,  3.8295e-02],
          [ 3.9766e-02,  1.0165e-01,  4.2045e-02]]],


        ...,


        [[[ 2.6993e-01,  7.2471e-02,  9.1806e-02],
          [ 2.0334e-01, -1.9382e-01, -4.4043e-02],
          [ 2.8379e-02, -1.0116e-01, -6.4498e-02]],

         [[-7.0300e-02, -6.5614e-02,  1.8000e-02],
          [-1.3431e-01, -2.4128e-01,  5.2272e-02],
          [ 5.2178e-03,  1.7454e-01,  2.0310e-01]],

         [[-7.4536e-02, -1.1884e-01,  1.3396e-01],
          [-8.0877e-02, -2.1830e-01, -1.4560e-01],
          [-2.2797e-02, -5.3977e-02, -6.3296e-02]]],


        [[[ 1.4183e-01,  1.9740e-01,  2.9259e-01],
          [ 1.6346e-01,  1.5922e-01, -7.0318e-03],
          [-2.9318e-01, -1.9488e-01, -1.0187e-01]],

         [[ 9.5812e-02,  4.7533e-02, -1.4183e-01],
          [ 5.0057e-02, -7.9656e-02, -3.4567e-01],
          [-4.5936e-02,  8.9913e-02, -5.8562e-02]],

         [[-2.1963e-01, -7.8743e-02, -1.9050e-01],
          [-1.0862e-01,  9.7933e-02,  7.6574e-02],
          [ 1.3194e-01,  2.7541e-01,  2.1578e-01]]],


        [[[ 1.0785e-40,  3.3674e-40, -5.4131e-40],
          [ 1.8438e-40, -1.3336e-40,  9.3848e-41],
          [-3.7159e-40,  2.3397e-40, -1.9206e-40]],

         [[-1.3509e-40, -3.3782e-40, -3.5812e-40],
          [-1.0122e-40,  1.0703e-40, -4.4113e-42],
          [ 3.9746e-40, -1.6516e-40,  3.8973e-41]],

         [[ 4.9491e-41,  2.4255e-40,  1.2930e-40],
          [ 1.0539e-40, -4.3142e-40, -2.3394e-40],
          [ 1.8559e-40,  3.4084e-40, -1.4519e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0503]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0176]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 104 | Batch_idx: 0 |  Loss: (0.1357) | Acc: (96.00%) (124/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.1779) | Acc: (94.00%) (1324/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.1880) | Acc: (93.00%) (2525/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.2057) | Acc: (93.00%) (3698/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.2069) | Acc: (93.00%) (4887/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.2124) | Acc: (92.00%) (6066/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.2167) | Acc: (92.00%) (7245/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.2265) | Acc: (92.00%) (8406/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.2328) | Acc: (92.00%) (9574/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.2351) | Acc: (92.00%) (10735/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.2387) | Acc: (91.00%) (11892/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.2410) | Acc: (91.00%) (13052/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.2427) | Acc: (91.00%) (14206/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.2429) | Acc: (91.00%) (15371/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.2451) | Acc: (91.00%) (16525/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.2463) | Acc: (91.00%) (17698/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.2466) | Acc: (91.00%) (18867/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.2462) | Acc: (91.00%) (20044/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.2463) | Acc: (91.00%) (21228/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.2465) | Acc: (91.00%) (22395/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.2453) | Acc: (91.00%) (23582/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.2457) | Acc: (91.00%) (24754/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.2454) | Acc: (91.00%) (25930/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.2449) | Acc: (91.00%) (27109/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.2460) | Acc: (91.00%) (28284/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.2458) | Acc: (91.00%) (29464/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.2452) | Acc: (91.00%) (30631/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.2442) | Acc: (91.00%) (31810/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.2432) | Acc: (91.00%) (32992/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.2429) | Acc: (91.00%) (34168/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.2440) | Acc: (91.00%) (35337/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.2446) | Acc: (91.00%) (36512/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.2448) | Acc: (91.00%) (37682/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.2450) | Acc: (91.00%) (38852/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.2451) | Acc: (91.00%) (40016/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.2446) | Acc: (91.00%) (41190/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.2445) | Acc: (91.00%) (42367/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.2449) | Acc: (91.00%) (43523/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.2448) | Acc: (91.00%) (44698/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.2451) | Acc: (91.00%) (45823/50000)
# TEST : Loss: (0.3938) | Acc: (87.00%) (8781/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0934e-01, -2.2994e-01,  3.5980e-02],
          [-8.4925e-02,  3.1515e-01,  2.2128e-01],
          [ 9.2096e-02,  3.9310e-02, -5.2682e-02]],

         [[-2.3074e-01,  2.0900e-01,  1.9856e-01],
          [ 4.4470e-03,  3.7500e-01,  2.2704e-01],
          [ 1.8805e-01, -3.5779e-02,  1.1676e-01]],

         [[-2.2988e-01, -6.7824e-02, -7.8080e-02],
          [-2.9403e-01, -1.0886e-01, -1.0123e-01],
          [-2.2164e-01, -1.1869e-01, -1.7204e-01]]],


        [[[ 2.6929e-40,  1.3287e-40,  5.7147e-40],
          [ 1.5665e-40, -3.5951e-40,  4.1138e-40],
          [-2.2248e-40,  8.3166e-41, -4.5161e-40]],

         [[ 2.3026e-40, -2.8620e-40, -3.3214e-40],
          [ 3.0535e-40,  5.3282e-40, -6.6003e-41],
          [-1.6010e-40,  1.7157e-40,  1.5945e-40]],

         [[-3.1586e-40, -2.6082e-40, -1.3622e-40],
          [ 2.7985e-40,  2.4193e-41, -1.0549e-40],
          [ 1.2895e-40,  2.9425e-40, -4.1357e-40]]],


        [[[ 3.5762e-02,  9.5294e-02, -8.5356e-02],
          [ 2.1956e-02,  1.9692e-01, -1.0586e-01],
          [ 1.2791e-01,  3.1996e-01,  3.2093e-01]],

         [[-1.9773e-01, -7.3320e-02, -1.7821e-01],
          [-3.5407e-01, -3.0545e-01, -2.7465e-01],
          [-2.5178e-01, -3.8594e-01,  5.1805e-02]],

         [[ 2.3645e-01,  1.1827e-01,  1.8547e-01],
          [ 2.0480e-01,  1.2981e-01,  4.2268e-02],
          [ 5.6981e-02,  1.1504e-01,  5.0855e-02]]],


        ...,


        [[[ 2.3707e-01,  3.5425e-02,  7.1978e-02],
          [ 1.8235e-01, -2.2742e-01, -5.9155e-02],
          [ 1.2282e-02, -1.2899e-01, -7.2869e-02]],

         [[-9.3722e-02, -9.7584e-02,  4.6777e-03],
          [-1.4391e-01, -2.7084e-01,  4.5609e-02],
          [-5.6382e-03,  1.5318e-01,  2.0935e-01]],

         [[-9.3402e-02, -1.4668e-01,  1.2195e-01],
          [-8.2259e-02, -2.5230e-01, -1.4634e-01],
          [-2.1581e-02, -6.6457e-02, -5.0292e-02]]],


        [[[ 1.3999e-01,  2.0008e-01,  2.8188e-01],
          [ 1.6682e-01,  1.6017e-01, -1.0232e-02],
          [-2.8388e-01, -1.9173e-01, -9.8959e-02]],

         [[ 8.5204e-02,  4.2592e-02, -1.5590e-01],
          [ 4.6668e-02, -8.5245e-02, -3.5603e-01],
          [-4.2805e-02,  8.7249e-02, -6.3566e-02]],

         [[-2.4716e-01, -9.5671e-02, -2.0959e-01],
          [-1.2939e-01,  8.1570e-02,  5.8568e-02],
          [ 1.1949e-01,  2.6489e-01,  2.0407e-01]]],


        [[[ 1.0785e-40,  3.3675e-40, -2.6111e-40],
          [ 6.0474e-40,  6.7543e-42, -4.6659e-40],
          [-2.3149e-40, -4.6251e-41, -5.1959e-41]],

         [[-4.1533e-40,  8.2521e-41, -3.5813e-40],
          [ 3.8892e-41,  2.4715e-40,  2.7582e-40],
          [ 1.1723e-40, -5.8551e-40, -1.0114e-40]],

         [[ 3.2972e-40, -3.7678e-41,  4.0953e-40],
          [-1.7483e-40, -5.7154e-40,  1.8640e-40],
          [-9.4638e-41, -7.9498e-41, -5.0755e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0223,  0.0241,  0.0313],
          [ 0.0235,  0.0248,  0.0259],
          [ 0.0366,  0.0353,  0.0315]],

         [[ 0.0356,  0.0367,  0.0410],
          [ 0.0367,  0.0374,  0.0387],
          [ 0.0492,  0.0489,  0.0465]],

         [[ 0.0324,  0.0289,  0.0315],
          [ 0.0331,  0.0302,  0.0314],
          [ 0.0441,  0.0413,  0.0383]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0126,  0.0255,  0.0387],
          [ 0.0196,  0.0479,  0.0385],
          [ 0.0146,  0.0617,  0.0510]],

         [[ 0.0006,  0.0242,  0.0353],
          [ 0.0182,  0.0523,  0.0383],
          [ 0.0183,  0.0656,  0.0546]],

         [[ 0.0023,  0.0199,  0.0225],
          [ 0.0114,  0.0441,  0.0261],
          [ 0.0080,  0.0522,  0.0412]]],


        ...,


        [[[-0.0161, -0.0055, -0.0099],
          [-0.0079, -0.0041, -0.0071],
          [-0.0035, -0.0044, -0.0066]],

         [[-0.0153, -0.0071, -0.0136],
          [-0.0072, -0.0057, -0.0107],
          [-0.0045, -0.0077, -0.0118]],

         [[-0.0111, -0.0038, -0.0093],
          [-0.0040, -0.0028, -0.0074],
          [-0.0006, -0.0037, -0.0079]]],


        [[[ 0.0028,  0.0014,  0.0064],
          [ 0.0070,  0.0036,  0.0059],
          [-0.0038, -0.0006,  0.0093]],

         [[ 0.0083,  0.0046,  0.0071],
          [ 0.0127,  0.0069,  0.0064],
          [-0.0012, -0.0003,  0.0066]],

         [[ 0.0112,  0.0084,  0.0086],
          [ 0.0156,  0.0114,  0.0096],
          [ 0.0038,  0.0059,  0.0114]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0465]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 105 | Batch_idx: 0 |  Loss: (0.0997) | Acc: (96.00%) (124/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.2099) | Acc: (92.00%) (1306/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2176) | Acc: (92.00%) (2490/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2140) | Acc: (92.00%) (3677/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2154) | Acc: (92.00%) (4865/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2114) | Acc: (92.00%) (6062/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2122) | Acc: (92.00%) (7240/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2132) | Acc: (92.00%) (8416/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2155) | Acc: (92.00%) (9585/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2144) | Acc: (92.00%) (10769/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2182) | Acc: (92.00%) (11933/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2175) | Acc: (92.00%) (13118/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2163) | Acc: (92.00%) (14306/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2136) | Acc: (92.00%) (15510/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2151) | Acc: (92.00%) (16690/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2158) | Acc: (92.00%) (17883/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2155) | Acc: (92.00%) (19075/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2165) | Acc: (92.00%) (20258/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2159) | Acc: (92.00%) (21442/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2157) | Acc: (92.00%) (22630/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2158) | Acc: (92.00%) (23814/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2167) | Acc: (92.00%) (24994/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2167) | Acc: (92.00%) (26184/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2161) | Acc: (92.00%) (27379/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2165) | Acc: (92.00%) (28567/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2170) | Acc: (92.00%) (29745/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2167) | Acc: (92.00%) (30928/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2170) | Acc: (92.00%) (32112/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2167) | Acc: (92.00%) (33301/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2162) | Acc: (92.00%) (34491/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2156) | Acc: (92.00%) (35681/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2142) | Acc: (92.00%) (36880/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2140) | Acc: (92.00%) (38066/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2148) | Acc: (92.00%) (39242/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2147) | Acc: (92.00%) (40429/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2153) | Acc: (92.00%) (41609/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2160) | Acc: (92.00%) (42782/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2158) | Acc: (92.00%) (43958/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2150) | Acc: (92.00%) (45153/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2145) | Acc: (92.00%) (46307/50000)
# TEST : Loss: (0.3912) | Acc: (88.00%) (8800/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9568e-01, -2.2460e-01,  3.4472e-02],
          [-6.9859e-02,  3.2698e-01,  2.2664e-01],
          [ 9.7098e-02,  4.4174e-02, -4.9393e-02]],

         [[-2.1429e-01,  2.1408e-01,  1.9462e-01],
          [ 1.8876e-02,  3.8184e-01,  2.2413e-01],
          [ 1.9198e-01, -3.6662e-02,  1.1098e-01]],

         [[-2.2314e-01, -7.5284e-02, -9.0728e-02],
          [-2.9073e-01, -1.1508e-01, -1.1351e-01],
          [-2.2612e-01, -1.2855e-01, -1.8344e-01]]],


        [[[-1.2696e-40,  1.3428e-40,  1.7984e-40],
          [-1.0772e-40, -9.7317e-41,  2.8233e-40],
          [-9.2784e-41, -1.8170e-40,  3.4712e-40]],

         [[ 2.3309e-40, -2.2383e-41, -2.0299e-40],
          [ 3.0825e-40,  2.7180e-40,  1.9970e-40],
          [-2.8720e-41,  1.7296e-40,  2.6905e-41]],

         [[-4.5206e-40,  3.9026e-42, -5.3749e-40],
          [ 2.8263e-40,  1.5781e-40,  4.2735e-40],
          [-1.3590e-40,  2.9692e-40,  1.1843e-40]]],


        [[[ 4.1659e-02,  1.0873e-01, -6.9116e-02],
          [ 2.0377e-02,  1.9826e-01, -9.8863e-02],
          [ 1.2172e-01,  3.1695e-01,  3.2336e-01]],

         [[-1.9760e-01, -6.4770e-02, -1.6605e-01],
          [-3.6260e-01, -3.1136e-01, -2.7413e-01],
          [-2.6356e-01, -3.9718e-01,  4.7438e-02]],

         [[ 2.3530e-01,  1.2620e-01,  1.9486e-01],
          [ 1.9789e-01,  1.2491e-01,  4.1322e-02],
          [ 4.6831e-02,  1.0271e-01,  4.1816e-02]]],


        ...,


        [[[ 2.3245e-01,  4.6818e-02,  8.2313e-02],
          [ 1.7469e-01, -2.2697e-01, -6.4345e-02],
          [ 1.0980e-02, -1.2408e-01, -7.3468e-02]],

         [[-1.0088e-01, -8.4237e-02,  1.8812e-02],
          [-1.5989e-01, -2.7451e-01,  3.9122e-02],
          [-1.5113e-02,  1.5207e-01,  2.0724e-01]],

         [[-8.8849e-02, -1.2553e-01,  1.3532e-01],
          [-8.6885e-02, -2.4413e-01, -1.5059e-01],
          [-2.6689e-02, -6.1412e-02, -4.9922e-02]]],


        [[[ 1.3106e-01,  1.9807e-01,  2.8549e-01],
          [ 1.6166e-01,  1.6328e-01,  5.8236e-03],
          [-2.8546e-01, -1.8703e-01, -8.0452e-02]],

         [[ 8.2839e-02,  3.8489e-02, -1.5594e-01],
          [ 4.2547e-02, -8.8568e-02, -3.4539e-01],
          [-4.3316e-02,  8.9672e-02, -4.6303e-02]],

         [[-2.5651e-01, -1.1031e-01, -2.2173e-01],
          [-1.3487e-01,  7.4967e-02,  6.1940e-02],
          [ 1.2395e-01,  2.6946e-01,  2.1780e-01]]],


        [[[-3.2268e-41,  5.6517e-41,  2.9934e-40],
          [ 4.6463e-40,  1.4687e-40, -6.0671e-40],
          [ 1.8887e-40, -3.2649e-40,  8.8154e-41]],

         [[-2.7522e-40,  3.6276e-40,  6.2223e-41],
          [ 1.7901e-40,  1.0704e-40,  2.7582e-40],
          [-3.0313e-40, -4.4540e-40, -1.0115e-40]],

         [[ 3.2973e-40, -3.1791e-40,  2.6942e-40],
          [-3.1495e-40, -1.5120e-40,  4.6663e-40],
          [-2.3476e-40, -3.5974e-40,  1.3504e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0412, -0.0443, -0.0419],
          [-0.0391, -0.0369, -0.0332],
          [-0.0454, -0.0412, -0.0304]],

         [[-0.0391, -0.0403, -0.0389],
          [-0.0387, -0.0348, -0.0314],
          [-0.0449, -0.0391, -0.0286]],

         [[-0.0328, -0.0315, -0.0343],
          [-0.0320, -0.0277, -0.0271],
          [-0.0355, -0.0290, -0.0200]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0125, -0.0028,  0.0088],
          [-0.0173, -0.0049, -0.0146],
          [-0.0434, -0.0334, -0.0248]],

         [[-0.0275, -0.0027,  0.0103],
          [-0.0293, -0.0024, -0.0072],
          [-0.0588, -0.0348, -0.0216]],

         [[-0.0386, -0.0038,  0.0138],
          [-0.0351,  0.0002,  0.0039],
          [-0.0637, -0.0337, -0.0162]]],


        ...,


        [[[ 0.0040, -0.0004,  0.0001],
          [ 0.0017,  0.0001,  0.0026],
          [-0.0034, -0.0044, -0.0009]],

         [[ 0.0039, -0.0008, -0.0001],
          [ 0.0016, -0.0001,  0.0028],
          [-0.0042, -0.0051, -0.0012]],

         [[ 0.0024, -0.0017, -0.0010],
          [ 0.0015, -0.0002,  0.0025],
          [-0.0034, -0.0045, -0.0010]]],


        [[[-0.0278, -0.0236, -0.0236],
          [-0.0286, -0.0269, -0.0220],
          [-0.0269, -0.0254, -0.0216]],

         [[-0.0232, -0.0198, -0.0217],
          [-0.0245, -0.0236, -0.0200],
          [-0.0245, -0.0238, -0.0208]],

         [[-0.0206, -0.0193, -0.0209],
          [-0.0206, -0.0196, -0.0164],
          [-0.0202, -0.0189, -0.0169]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0464]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 106 | Batch_idx: 0 |  Loss: (0.1717) | Acc: (93.00%) (120/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.1910) | Acc: (93.00%) (1319/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.2245) | Acc: (92.00%) (2479/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2369) | Acc: (91.00%) (3643/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2432) | Acc: (91.00%) (4813/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2404) | Acc: (91.00%) (5990/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2348) | Acc: (92.00%) (7188/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2339) | Acc: (92.00%) (8363/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2347) | Acc: (92.00%) (9545/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2319) | Acc: (92.00%) (10738/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2288) | Acc: (92.00%) (11935/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2289) | Acc: (92.00%) (13114/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2266) | Acc: (92.00%) (14305/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2262) | Acc: (92.00%) (15488/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2254) | Acc: (92.00%) (16674/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2231) | Acc: (92.00%) (17870/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2234) | Acc: (92.00%) (19043/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2227) | Acc: (92.00%) (20231/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2216) | Acc: (92.00%) (21428/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2205) | Acc: (92.00%) (22611/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2209) | Acc: (92.00%) (23788/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2191) | Acc: (92.00%) (24988/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2184) | Acc: (92.00%) (26177/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.2173) | Acc: (92.00%) (27379/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.2169) | Acc: (92.00%) (28565/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.2167) | Acc: (92.00%) (29753/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.2157) | Acc: (92.00%) (30943/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.2151) | Acc: (92.00%) (32136/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.2142) | Acc: (92.00%) (33332/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.2133) | Acc: (92.00%) (34538/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.2130) | Acc: (92.00%) (35736/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.2127) | Acc: (92.00%) (36935/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.2117) | Acc: (92.00%) (38130/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.2114) | Acc: (92.00%) (39323/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.2105) | Acc: (92.00%) (40526/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.2099) | Acc: (92.00%) (41720/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.2090) | Acc: (92.00%) (42918/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.2089) | Acc: (92.00%) (44110/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.2084) | Acc: (92.00%) (45307/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.2074) | Acc: (92.00%) (46468/50000)
# TEST : Loss: (0.3079) | Acc: (90.00%) (9014/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9306e-01, -2.2115e-01,  3.8716e-02],
          [-6.6933e-02,  3.2944e-01,  2.3037e-01],
          [ 1.0015e-01,  4.8220e-02, -4.5198e-02]],

         [[-2.1056e-01,  2.1705e-01,  1.9904e-01],
          [ 2.2464e-02,  3.8509e-01,  2.2884e-01],
          [ 1.9550e-01, -3.1386e-02,  1.1576e-01]],

         [[-2.1846e-01, -7.1077e-02, -8.5144e-02],
          [-2.8559e-01, -1.1019e-01, -1.0787e-01],
          [-2.2082e-01, -1.2315e-01, -1.7818e-01]]],


        [[[-3.9665e-40,  1.1224e-42,  5.8291e-40],
          [-2.4308e-40,  3.0465e-40, -1.1857e-40],
          [ 1.7390e-40, -3.1722e-40, -1.8934e-40]],

         [[-3.3145e-41,  2.4655e-40, -2.0539e-40],
          [ 4.2396e-41, -2.6367e-40,  3.3569e-40],
          [ 1.0535e-40,  3.9675e-41, -1.0800e-40]],

         [[-1.8615e-40,  2.7345e-40, -4.0766e-40],
          [ 1.6086e-41,  1.5891e-40,  5.6538e-40],
          [-2.7143e-40,  2.9772e-41,  5.2450e-40]]],


        [[[ 4.6532e-02,  1.1295e-01, -6.5767e-02],
          [ 2.6127e-02,  2.0303e-01, -9.4582e-02],
          [ 1.3043e-01,  3.2333e-01,  3.2699e-01]],

         [[-1.9135e-01, -5.9949e-02, -1.6222e-01],
          [-3.5522e-01, -3.0543e-01, -2.6940e-01],
          [-2.5275e-01, -3.8889e-01,  5.2035e-02]],

         [[ 2.4168e-01,  1.3124e-01,  1.9861e-01],
          [ 2.0483e-01,  1.3051e-01,  4.5828e-02],
          [ 5.7145e-02,  1.1043e-01,  4.6844e-02]]],


        ...,


        [[[ 2.2951e-01,  4.7285e-02,  8.1277e-02],
          [ 1.7290e-01, -2.2198e-01, -6.3414e-02],
          [ 1.0961e-02, -1.2064e-01, -7.2453e-02]],

         [[-1.0105e-01, -8.2756e-02,  1.7747e-02],
          [-1.5720e-01, -2.6577e-01,  3.8097e-02],
          [-1.4491e-02,  1.5228e-01,  2.0459e-01]],

         [[-9.1605e-02, -1.2542e-01,  1.3105e-01],
          [-8.8322e-02, -2.3550e-01, -1.5062e-01],
          [-2.7860e-02, -6.0196e-02, -5.1051e-02]]],


        [[[ 1.3698e-01,  2.0379e-01,  2.8957e-01],
          [ 1.6742e-01,  1.6907e-01,  1.0873e-02],
          [-2.7812e-01, -1.8113e-01, -7.5452e-02]],

         [[ 8.8419e-02,  4.4499e-02, -1.4928e-01],
          [ 4.8692e-02, -8.1773e-02, -3.3818e-01],
          [-3.7239e-02,  9.3999e-02, -4.1423e-02]],

         [[-2.5074e-01, -1.0501e-01, -2.1589e-01],
          [-1.2960e-01,  7.9115e-02,  6.5496e-02],
          [ 1.2768e-01,  2.7157e-01,  2.2001e-01]]],


        [[[-1.7239e-40, -2.2372e-40,  5.7958e-40],
          [-9.5850e-41,  1.4688e-40, -1.8637e-40],
          [ 4.6912e-40, -3.2649e-40,  8.8160e-41]],

         [[ 1.4515e-40,  2.2265e-40,  4.8259e-40],
          [ 1.7902e-40, -1.7320e-40, -4.4113e-42],
          [-4.4325e-40,  1.1507e-40,  3.8970e-41]],

         [[ 4.9491e-41, -3.1792e-40, -1.5093e-40],
          [-1.7484e-40,  4.0928e-40,  3.2652e-40],
          [-9.4641e-41, -2.1962e-40,  1.3504e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0326]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0565]], device='cuda:0')

Epoch: 107 | Batch_idx: 0 |  Loss: (0.1817) | Acc: (92.00%) (119/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.1661) | Acc: (94.00%) (1324/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.1680) | Acc: (94.00%) (2536/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.1732) | Acc: (94.00%) (3736/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.1705) | Acc: (94.00%) (4947/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.1713) | Acc: (94.00%) (6152/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.1732) | Acc: (94.00%) (7353/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.1759) | Acc: (94.00%) (8551/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.1775) | Acc: (94.00%) (9756/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.1755) | Acc: (94.00%) (10970/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.1753) | Acc: (94.00%) (12169/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.1761) | Acc: (94.00%) (13374/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.1782) | Acc: (94.00%) (14568/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.1779) | Acc: (94.00%) (15770/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.1786) | Acc: (94.00%) (16967/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.1794) | Acc: (93.00%) (18163/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.1790) | Acc: (94.00%) (19375/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.1798) | Acc: (93.00%) (20571/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.1786) | Acc: (94.00%) (21780/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.1778) | Acc: (94.00%) (22991/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.1777) | Acc: (94.00%) (24202/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.1784) | Acc: (94.00%) (25396/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.1785) | Acc: (94.00%) (26602/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.1788) | Acc: (94.00%) (27798/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.1787) | Acc: (94.00%) (28998/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.1788) | Acc: (94.00%) (30201/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.1783) | Acc: (94.00%) (31404/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.1786) | Acc: (93.00%) (32606/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.1782) | Acc: (94.00%) (33812/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.1784) | Acc: (93.00%) (35009/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.1786) | Acc: (93.00%) (36214/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.1793) | Acc: (93.00%) (37417/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.1787) | Acc: (94.00%) (38629/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.1789) | Acc: (94.00%) (39832/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.1793) | Acc: (94.00%) (41033/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.1791) | Acc: (94.00%) (42236/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.1798) | Acc: (93.00%) (43426/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.1803) | Acc: (93.00%) (44615/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.1800) | Acc: (93.00%) (45822/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.1798) | Acc: (93.00%) (46980/50000)
# TEST : Loss: (0.2966) | Acc: (90.00%) (9051/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9238e-01, -2.2032e-01,  3.8564e-02],
          [-6.6684e-02,  3.2811e-01,  2.2940e-01],
          [ 9.9779e-02,  4.8027e-02, -4.5011e-02]],

         [[-2.0974e-01,  2.1617e-01,  1.9822e-01],
          [ 2.2374e-02,  3.8348e-01,  2.2786e-01],
          [ 1.9474e-01, -3.1258e-02,  1.1528e-01]],

         [[-2.1751e-01, -7.0778e-02, -8.4799e-02],
          [-2.8437e-01, -1.0973e-01, -1.0743e-01],
          [-2.1990e-01, -1.2265e-01, -1.7747e-01]]],


        [[[-2.6442e-40, -1.3421e-40,  4.5216e-40],
          [-1.0996e-40,  4.4198e-40, -3.9032e-40],
          [ 3.0997e-40, -1.8387e-40, -5.9762e-40]],

         [[-3.0377e-40,  2.4849e-40,  6.2879e-41],
          [-2.2795e-40, -5.3646e-40, -2.0411e-40],
          [ 1.0637e-40, -9.5751e-41, -1.0890e-40]],

         [[ 2.1967e-40,  2.7528e-40,  1.3117e-40],
          [-2.5474e-40,  2.4182e-41,  1.6231e-40],
          [-1.3809e-40, -2.4149e-40,  3.9214e-40]]],


        [[[ 4.6442e-02,  1.1273e-01, -6.5637e-02],
          [ 2.6076e-02,  2.0264e-01, -9.4396e-02],
          [ 1.3017e-01,  3.2269e-01,  3.2634e-01]],

         [[-1.9094e-01, -5.9820e-02, -1.6187e-01],
          [-3.5443e-01, -3.0477e-01, -2.6881e-01],
          [-2.5218e-01, -3.8805e-01,  5.1926e-02]],

         [[ 2.4115e-01,  1.3096e-01,  1.9817e-01],
          [ 2.0437e-01,  1.3022e-01,  4.5725e-02],
          [ 5.7015e-02,  1.1019e-01,  4.6742e-02]]],


        ...,


        [[[ 2.2670e-01,  4.6677e-02,  8.0306e-02],
          [ 1.7046e-01, -2.1842e-01, -6.2532e-02],
          [ 1.0817e-02, -1.1891e-01, -7.1508e-02]],

         [[-9.9485e-02, -8.1265e-02,  1.7493e-02],
          [-1.5414e-01, -2.5835e-01,  3.7411e-02],
          [-1.4271e-02,  1.4946e-01,  2.0152e-01]],

         [[-8.9824e-02, -1.2240e-01,  1.2877e-01],
          [-8.5858e-02, -2.2257e-01, -1.4701e-01],
          [-2.7317e-02, -5.8709e-02, -5.0111e-02]]],


        [[[ 1.3600e-01,  2.0231e-01,  2.8762e-01],
          [ 1.6628e-01,  1.6792e-01,  1.0803e-02],
          [-2.7634e-01, -1.7997e-01, -7.4976e-02]],

         [[ 8.7808e-02,  4.4192e-02, -1.4827e-01],
          [ 4.8356e-02, -8.1213e-02, -3.3590e-01],
          [-3.6989e-02,  9.3380e-02, -4.1147e-02]],

         [[-2.4894e-01, -1.0428e-01, -2.1436e-01],
          [-1.2868e-01,  7.8561e-02,  6.5026e-02],
          [ 1.2678e-01,  2.6971e-01,  2.1847e-01]]],


        [[[-1.7239e-40, -2.2373e-40,  2.9936e-40],
          [-5.1622e-40,  6.7557e-42,  3.7410e-40],
          [ 3.2900e-40, -4.6253e-41, -5.1959e-41]],

         [[ 4.2539e-40, -1.9772e-40,  4.8260e-40],
          [ 3.8896e-41, -3.1333e-40, -2.8465e-40],
          [-1.6301e-40,  5.3544e-40,  1.7909e-40]],

         [[-2.3075e-40, -3.7678e-41, -4.3118e-40],
          [ 1.0540e-40,  5.4941e-40, -9.3841e-41],
          [ 1.8560e-40,  2.0074e-40, -5.0741e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0408]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0501]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 108 | Batch_idx: 0 |  Loss: (0.1724) | Acc: (93.00%) (120/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.1619) | Acc: (94.00%) (1333/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.1891) | Acc: (93.00%) (2504/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.2075) | Acc: (92.00%) (3679/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.2154) | Acc: (92.00%) (4856/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.2316) | Acc: (92.00%) (6008/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.2391) | Acc: (91.00%) (7173/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.2447) | Acc: (91.00%) (8339/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.2496) | Acc: (91.00%) (9489/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.2525) | Acc: (91.00%) (10657/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.2534) | Acc: (91.00%) (11827/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.2538) | Acc: (91.00%) (12994/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.2510) | Acc: (91.00%) (14174/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.2514) | Acc: (91.00%) (15343/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.2513) | Acc: (91.00%) (16519/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.2527) | Acc: (91.00%) (17688/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.2516) | Acc: (91.00%) (18870/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.2524) | Acc: (91.00%) (20031/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.2520) | Acc: (91.00%) (21203/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.2528) | Acc: (91.00%) (22370/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.2533) | Acc: (91.00%) (23530/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.2531) | Acc: (91.00%) (24699/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.2519) | Acc: (91.00%) (25878/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.2536) | Acc: (91.00%) (27027/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.2521) | Acc: (91.00%) (28211/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.2524) | Acc: (91.00%) (29380/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.2522) | Acc: (91.00%) (30546/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.2533) | Acc: (91.00%) (31706/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.2525) | Acc: (91.00%) (32887/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.2516) | Acc: (91.00%) (34064/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.2514) | Acc: (91.00%) (35246/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.2512) | Acc: (91.00%) (36421/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.2499) | Acc: (91.00%) (37612/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.2495) | Acc: (91.00%) (38782/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.2495) | Acc: (91.00%) (39959/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.2486) | Acc: (91.00%) (41138/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.2487) | Acc: (91.00%) (42304/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.2481) | Acc: (91.00%) (43493/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.2474) | Acc: (91.00%) (44668/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.2477) | Acc: (91.00%) (45784/50000)
# TEST : Loss: (0.3746) | Acc: (88.00%) (8811/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9402e-01, -2.1447e-01,  4.0175e-02],
          [-6.8008e-02,  3.3897e-01,  2.3289e-01],
          [ 1.0719e-01,  6.0759e-02, -4.4775e-02]],

         [[-2.0770e-01,  2.2440e-01,  2.0469e-01],
          [ 2.3187e-02,  3.9387e-01,  2.3222e-01],
          [ 2.0378e-01, -1.9699e-02,  1.1253e-01]],

         [[-2.1650e-01, -6.3774e-02, -7.8175e-02],
          [-2.8414e-01, -1.0241e-01, -1.0257e-01],
          [-2.1100e-01, -1.1727e-01, -1.7790e-01]]],


        [[[ 1.4221e-40, -1.3503e-40, -8.8694e-41],
          [ 1.6125e-40,  1.7206e-40, -2.5655e-40],
          [ 1.7581e-40,  8.7612e-41, -4.6409e-40]],

         [[-3.0543e-40, -2.2393e-41,  3.3490e-40],
          [-2.2965e-40, -2.6721e-40, -6.9432e-41],
          [-2.8745e-41, -9.6558e-41,  2.6902e-41]],

         [[ 3.5760e-40,  3.8760e-42,  5.4071e-40],
          [-2.5635e-40, -1.1226e-40, -3.8246e-40],
          [ 1.3339e-40, -2.4304e-40, -1.5215e-40]]],


        [[[ 3.1029e-02,  9.1228e-02, -7.6668e-02],
          [ 1.4116e-02,  1.8546e-01, -1.0639e-01],
          [ 1.2157e-01,  3.1335e-01,  3.2144e-01]],

         [[-2.0253e-01, -7.9894e-02, -1.7074e-01],
          [-3.6786e-01, -3.2392e-01, -2.7488e-01],
          [-2.6360e-01, -3.9799e-01,  5.1829e-02]],

         [[ 2.4148e-01,  1.2295e-01,  1.9265e-01],
          [ 2.0046e-01,  1.1908e-01,  4.0023e-02],
          [ 4.6369e-02,  1.0242e-01,  4.5856e-02]]],


        ...,


        [[[ 2.3849e-01,  4.8021e-02,  8.2907e-02],
          [ 1.7157e-01, -2.2417e-01, -5.3860e-02],
          [ 1.1659e-03, -1.2897e-01, -6.2487e-02]],

         [[-8.3128e-02, -7.7005e-02,  2.2472e-02],
          [-1.4590e-01, -2.6597e-01,  4.0919e-02],
          [-2.0527e-02,  1.3969e-01,  2.0925e-01]],

         [[-6.9819e-02, -1.2357e-01,  1.2733e-01],
          [-6.9116e-02, -2.3981e-01, -1.5321e-01],
          [-4.0185e-02, -7.4595e-02, -5.5948e-02]]],


        [[[ 1.2843e-01,  2.0108e-01,  2.9790e-01],
          [ 1.5874e-01,  1.6284e-01,  1.9685e-02],
          [-2.7908e-01, -1.8285e-01, -6.7930e-02]],

         [[ 8.1048e-02,  4.2132e-02, -1.4009e-01],
          [ 4.2472e-02, -8.6743e-02, -3.2930e-01],
          [-3.6665e-02,  9.2008e-02, -3.4470e-02]],

         [[-2.5869e-01, -1.1388e-01, -2.1198e-01],
          [-1.3609e-01,  6.9116e-02,  7.0188e-02],
          [ 1.2580e-01,  2.7038e-01,  2.3147e-01]]],


        [[[-3.2265e-41,  5.6516e-41, -2.6112e-40],
          [-3.7611e-40, -1.3337e-40,  5.1422e-40],
          [-9.1373e-41,  2.3399e-40, -1.9208e-40]],

         [[ 2.8527e-40, -4.7797e-40,  6.2232e-41],
          [-1.0123e-40, -1.7320e-40, -2.8466e-40],
          [ 2.5736e-40,  3.9532e-40,  1.7909e-40]],

         [[-2.3075e-40,  2.4257e-40, -2.9106e-40],
          [ 2.4553e-40,  1.2904e-40, -3.7409e-40],
          [ 3.2572e-40,  4.8098e-40, -1.4520e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0003,  0.0056,  0.0083],
          [ 0.0051,  0.0070,  0.0076],
          [-0.0031,  0.0028, -0.0031]],

         [[-0.0047,  0.0030,  0.0093],
          [ 0.0028,  0.0054,  0.0090],
          [-0.0036,  0.0031, -0.0004]],

         [[ 0.0021,  0.0097,  0.0170],
          [ 0.0067,  0.0105,  0.0164],
          [ 0.0031,  0.0083,  0.0070]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0387,  0.0255,  0.0136],
          [ 0.0423,  0.0303,  0.0302],
          [ 0.0499,  0.0496,  0.0409]],

         [[ 0.0192,  0.0090,  0.0044],
          [ 0.0303,  0.0203,  0.0207],
          [ 0.0473,  0.0471,  0.0343]],

         [[ 0.0133,  0.0004, -0.0070],
          [ 0.0301,  0.0169,  0.0114],
          [ 0.0432,  0.0418,  0.0274]]],


        ...,


        [[[ 0.0067,  0.0056,  0.0025],
          [ 0.0008,  0.0035, -0.0007],
          [ 0.0002,  0.0031,  0.0005]],

         [[ 0.0034,  0.0027, -0.0014],
          [-0.0028, -0.0003, -0.0047],
          [-0.0035, -0.0015, -0.0039]],

         [[ 0.0027,  0.0016, -0.0013],
          [-0.0008,  0.0000, -0.0033],
          [-0.0008,  0.0000, -0.0025]]],


        [[[ 0.0089,  0.0091, -0.0000],
          [ 0.0092,  0.0115,  0.0014],
          [ 0.0077,  0.0131,  0.0024]],

         [[ 0.0144,  0.0138,  0.0057],
          [ 0.0109,  0.0137,  0.0065],
          [ 0.0070,  0.0124,  0.0045]],

         [[ 0.0176,  0.0199,  0.0133],
          [ 0.0158,  0.0205,  0.0140],
          [ 0.0118,  0.0176,  0.0114]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0373]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 109 | Batch_idx: 0 |  Loss: (0.2254) | Acc: (94.00%) (121/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.2303) | Acc: (92.00%) (1302/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.2069) | Acc: (93.00%) (2504/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.2028) | Acc: (93.00%) (3703/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.1970) | Acc: (93.00%) (4898/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.1952) | Acc: (93.00%) (6098/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.1992) | Acc: (93.00%) (7281/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.1964) | Acc: (93.00%) (8487/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.1963) | Acc: (93.00%) (9683/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.2004) | Acc: (93.00%) (10861/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.2041) | Acc: (93.00%) (12028/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.2033) | Acc: (93.00%) (13220/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.2025) | Acc: (93.00%) (14417/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.2044) | Acc: (93.00%) (15599/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.2064) | Acc: (92.00%) (16780/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.2062) | Acc: (92.00%) (17970/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.2056) | Acc: (93.00%) (19169/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.2063) | Acc: (92.00%) (20354/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.2086) | Acc: (92.00%) (21527/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.2087) | Acc: (92.00%) (22715/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.2091) | Acc: (92.00%) (23903/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.2088) | Acc: (92.00%) (25100/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.2082) | Acc: (92.00%) (26296/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.2078) | Acc: (92.00%) (27485/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.2091) | Acc: (92.00%) (28664/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.2084) | Acc: (92.00%) (29863/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.2082) | Acc: (92.00%) (31053/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.2083) | Acc: (92.00%) (32242/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.2094) | Acc: (92.00%) (33415/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.2099) | Acc: (92.00%) (34596/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.2103) | Acc: (92.00%) (35778/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.2107) | Acc: (92.00%) (36962/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.2099) | Acc: (92.00%) (38160/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.2093) | Acc: (92.00%) (39363/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.2089) | Acc: (92.00%) (40560/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.2095) | Acc: (92.00%) (41744/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.2091) | Acc: (92.00%) (42939/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.2091) | Acc: (92.00%) (44121/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.2096) | Acc: (92.00%) (45304/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.2104) | Acc: (92.00%) (46439/50000)
# TEST : Loss: (0.3497) | Acc: (89.00%) (8910/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8853e-01, -2.1048e-01,  4.3381e-02],
          [-6.9330e-02,  3.3854e-01,  2.3369e-01],
          [ 1.0684e-01,  5.9648e-02, -3.9447e-02]],

         [[-2.0277e-01,  2.2726e-01,  2.0252e-01],
          [ 1.9919e-02,  3.8911e-01,  2.2418e-01],
          [ 1.9844e-01, -2.4485e-02,  1.1235e-01]],

         [[-2.2040e-01, -6.6380e-02, -8.3819e-02],
          [-2.9783e-01, -1.1525e-01, -1.1512e-01],
          [-2.2167e-01, -1.2738e-01, -1.8315e-01]]],


        [[[ 4.1649e-40,  1.1280e-42, -4.9927e-40],
          [ 2.9871e-40, -2.3790e-40,  1.5277e-40],
          [-9.6722e-41,  2.2516e-40,  8.2714e-41]],

         [[-3.3146e-41, -2.9623e-40,  3.3632e-40],
          [ 4.2403e-41,  2.7910e-40, -2.0680e-40],
          [-1.6545e-40,  3.9678e-41,  1.6407e-40]],

         [[ 8.5504e-41, -2.7034e-40,  4.0650e-40],
          [ 1.6111e-41, -1.1290e-40, -5.2144e-40],
          [ 2.7091e-40,  2.9771e-41, -5.6445e-40]]],


        [[[ 3.3277e-02,  9.7518e-02, -7.9118e-02],
          [ 2.3272e-02,  1.9080e-01, -1.0915e-01],
          [ 1.3369e-01,  3.1949e-01,  3.2421e-01]],

         [[-2.0249e-01, -7.4633e-02, -1.7295e-01],
          [-3.6202e-01, -3.2224e-01, -2.7996e-01],
          [-2.5256e-01, -3.9327e-01,  5.2227e-02]],

         [[ 2.4022e-01,  1.3147e-01,  1.9097e-01],
          [ 2.0902e-01,  1.2679e-01,  3.6870e-02],
          [ 5.9088e-02,  1.0897e-01,  4.2965e-02]]],


        ...,


        [[[ 2.5098e-01,  5.5960e-02,  7.7743e-02],
          [ 1.7486e-01, -2.1324e-01, -5.3791e-02],
          [ 1.9733e-02, -1.0970e-01, -5.2004e-02]],

         [[-7.2667e-02, -7.1401e-02,  1.2560e-02],
          [-1.4929e-01, -2.5472e-01,  3.4931e-02],
          [-6.4167e-03,  1.5497e-01,  2.1769e-01]],

         [[-7.5528e-02, -1.3419e-01,  1.0384e-01],
          [-1.0103e-01, -2.6385e-01, -1.7708e-01],
          [-4.7070e-02, -7.7406e-02, -6.0947e-02]]],


        [[[ 1.3408e-01,  2.2088e-01,  3.0895e-01],
          [ 1.5755e-01,  1.7032e-01,  2.2408e-02],
          [-2.6509e-01, -1.6790e-01, -6.4775e-02]],

         [[ 8.4287e-02,  5.4673e-02, -1.3186e-01],
          [ 3.3648e-02, -8.6875e-02, -3.3090e-01],
          [-3.1491e-02,  9.7992e-02, -4.0294e-02]],

         [[-2.7049e-01, -1.1911e-01, -2.2077e-01],
          [-1.5547e-01,  5.6294e-02,  5.3464e-02],
          [ 1.1638e-01,  2.6366e-01,  2.1202e-01]]],


        [[[ 1.0786e-40,  3.3676e-40, -5.4137e-40],
          [ 1.8439e-40, -1.3337e-40,  9.3860e-41],
          [-3.7162e-40,  2.3400e-40, -1.9208e-40]],

         [[-1.3510e-40, -3.3784e-40, -3.5814e-40],
          [-1.0123e-40,  1.0704e-40, -4.4113e-42],
          [ 3.9749e-40, -1.6517e-40,  3.8972e-41]],

         [[ 4.9491e-41,  2.4257e-40,  1.2931e-40],
          [ 1.0540e-40, -4.3145e-40, -2.3397e-40],
          [ 1.8560e-40,  3.4086e-40, -1.4520e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0347,  0.0343,  0.0192],
          [ 0.0346,  0.0305,  0.0187],
          [ 0.0425,  0.0351,  0.0327]],

         [[ 0.0186,  0.0152, -0.0012],
          [ 0.0238,  0.0169,  0.0044],
          [ 0.0376,  0.0282,  0.0242]],

         [[ 0.0093,  0.0046, -0.0097],
          [ 0.0167,  0.0095, -0.0024],
          [ 0.0343,  0.0249,  0.0197]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0327, -0.0256, -0.0317],
          [ 0.0028, -0.0034, -0.0082],
          [ 0.0081, -0.0033, -0.0081]],

         [[-0.0524, -0.0528, -0.0566],
          [-0.0052, -0.0182, -0.0240],
          [ 0.0085, -0.0075, -0.0139]],

         [[-0.0470, -0.0492, -0.0524],
          [-0.0081, -0.0235, -0.0260],
          [ 0.0028, -0.0145, -0.0183]]],


        ...,


        [[[-0.0010, -0.0066, -0.0011],
          [-0.0007, -0.0070, -0.0004],
          [ 0.0022, -0.0047,  0.0019]],

         [[ 0.0052,  0.0008,  0.0046],
          [ 0.0054,  0.0010,  0.0060],
          [ 0.0063,  0.0007,  0.0071]],

         [[ 0.0029, -0.0010,  0.0009],
          [ 0.0040,  0.0001,  0.0029],
          [ 0.0055,  0.0009,  0.0048]]],


        [[[ 0.0026,  0.0116,  0.0116],
          [ 0.0116,  0.0161,  0.0156],
          [ 0.0112,  0.0174,  0.0186]],

         [[ 0.0050,  0.0132,  0.0125],
          [ 0.0151,  0.0200,  0.0184],
          [ 0.0129,  0.0196,  0.0200]],

         [[ 0.0050,  0.0109,  0.0094],
          [ 0.0125,  0.0153,  0.0131],
          [ 0.0096,  0.0143,  0.0145]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0372]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 110 | Batch_idx: 0 |  Loss: (0.1489) | Acc: (94.00%) (121/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.2125) | Acc: (92.00%) (1299/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.2304) | Acc: (91.00%) (2469/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.2453) | Acc: (91.00%) (3628/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.2442) | Acc: (91.00%) (4805/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.2443) | Acc: (91.00%) (5980/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.2400) | Acc: (91.00%) (7162/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.2396) | Acc: (91.00%) (8338/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.2364) | Acc: (91.00%) (9523/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.2354) | Acc: (91.00%) (10696/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.2321) | Acc: (91.00%) (11882/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.2305) | Acc: (91.00%) (13070/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.2283) | Acc: (92.00%) (14263/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.2262) | Acc: (92.00%) (15455/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.2234) | Acc: (92.00%) (16655/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.2214) | Acc: (92.00%) (17850/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.2208) | Acc: (92.00%) (19036/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.2179) | Acc: (92.00%) (20250/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.2168) | Acc: (92.00%) (21439/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.2149) | Acc: (92.00%) (22630/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.2142) | Acc: (92.00%) (23825/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.2141) | Acc: (92.00%) (25005/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.2143) | Acc: (92.00%) (26193/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.2128) | Acc: (92.00%) (27390/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.2119) | Acc: (92.00%) (28582/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.2114) | Acc: (92.00%) (29775/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.2106) | Acc: (92.00%) (30975/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.2098) | Acc: (92.00%) (32168/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.2081) | Acc: (92.00%) (33380/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.2076) | Acc: (92.00%) (34571/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.2072) | Acc: (92.00%) (35766/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.2066) | Acc: (92.00%) (36958/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.2054) | Acc: (92.00%) (38172/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.2041) | Acc: (92.00%) (39378/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.2039) | Acc: (92.00%) (40569/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.2036) | Acc: (92.00%) (41766/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.2033) | Acc: (92.00%) (42955/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.2031) | Acc: (92.00%) (44151/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.2025) | Acc: (92.00%) (45353/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.2017) | Acc: (93.00%) (46517/50000)
# TEST : Loss: (0.3156) | Acc: (89.00%) (8954/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9039e-01, -2.1194e-01,  4.3067e-02],
          [-7.0710e-02,  3.3663e-01,  2.3315e-01],
          [ 1.0518e-01,  5.9496e-02, -4.0372e-02]],

         [[-2.0329e-01,  2.2586e-01,  2.0298e-01],
          [ 1.9207e-02,  3.8809e-01,  2.2484e-01],
          [ 1.9708e-01, -2.3618e-02,  1.1197e-01]],

         [[-2.1939e-01, -6.4926e-02, -8.0149e-02],
          [-2.9657e-01, -1.1336e-01, -1.1161e-01],
          [-2.2145e-01, -1.2581e-01, -1.8144e-01]]],


        [[[ 2.8084e-40,  1.3855e-40, -3.6447e-40],
          [ 1.6256e-40, -3.7648e-40,  4.2825e-40],
          [-2.3457e-40,  8.8880e-41,  4.9628e-40]],

         [[ 2.4166e-40, -2.9735e-40,  6.2862e-41],
          [ 3.1706e-40,  5.5517e-40, -7.0188e-41],
          [-1.6604e-40,  1.7714e-40,  1.6459e-40]],

         [[-3.2666e-40, -2.7139e-40, -1.4174e-40],
          [ 2.9105e-40,  2.4174e-41, -1.1084e-40],
          [ 1.3464e-40,  3.0496e-40, -4.2873e-40]]],


        [[[ 3.3865e-02,  9.8057e-02, -7.7767e-02],
          [ 2.4066e-02,  1.9105e-01, -1.0808e-01],
          [ 1.3399e-01,  3.1930e-01,  3.2471e-01]],

         [[-2.0084e-01, -7.2502e-02, -1.7001e-01],
          [-3.5994e-01, -3.1989e-01, -2.7724e-01],
          [-2.5122e-01, -3.9160e-01,  5.3893e-02]],

         [[ 2.4210e-01,  1.3375e-01,  1.9386e-01],
          [ 2.1111e-01,  1.2927e-01,  3.9979e-02],
          [ 6.0758e-02,  1.1071e-01,  4.5495e-02]]],


        ...,


        [[[ 2.4686e-01,  5.4325e-02,  7.6190e-02],
          [ 1.6952e-01, -2.1314e-01, -5.5516e-02],
          [ 1.4932e-02, -1.1179e-01, -5.4744e-02]],

         [[-7.4979e-02, -7.3268e-02,  1.0476e-02],
          [-1.5193e-01, -2.5498e-01,  3.1123e-02],
          [-1.1319e-02,  1.4859e-01,  2.1162e-01]],

         [[-7.4306e-02, -1.3102e-01,  1.0413e-01],
          [-1.0028e-01, -2.5498e-01, -1.7431e-01],
          [-4.8645e-02, -7.7934e-02, -6.1765e-02]]],


        [[[ 1.3295e-01,  2.1930e-01,  3.0545e-01],
          [ 1.5579e-01,  1.6961e-01,  2.0985e-02],
          [-2.6324e-01, -1.6632e-01, -6.5701e-02]],

         [[ 8.3883e-02,  5.5009e-02, -1.3129e-01],
          [ 3.2858e-02, -8.5218e-02, -3.2876e-01],
          [-3.0231e-02,  9.9323e-02, -3.9458e-02]],

         [[-2.6701e-01, -1.1629e-01, -2.1775e-01],
          [-1.5322e-01,  5.8759e-02,  5.5487e-02],
          [ 1.1835e-01,  2.6569e-01,  2.1354e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -2.6113e-40],
          [ 6.0477e-40,  6.7599e-42, -4.6664e-40],
          [-2.3150e-40, -4.6253e-41, -5.1956e-41]],

         [[-4.1535e-40,  8.2531e-41, -3.5815e-40],
          [ 3.8897e-41,  2.4717e-40,  2.7584e-40],
          [ 1.1724e-40, -5.8555e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.7675e-41,  4.0956e-40],
          [-1.7485e-40, -5.7158e-40,  1.8640e-40],
          [-9.4647e-41, -7.9514e-41, -5.0713e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0357]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0406]], device='cuda:0')

Epoch: 111 | Batch_idx: 0 |  Loss: (0.2179) | Acc: (96.00%) (123/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.1895) | Acc: (94.00%) (1330/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.1847) | Acc: (94.00%) (2539/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.1857) | Acc: (94.00%) (3742/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.1853) | Acc: (94.00%) (4950/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.1852) | Acc: (94.00%) (6142/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.1838) | Acc: (94.00%) (7349/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.1867) | Acc: (93.00%) (8539/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.1862) | Acc: (93.00%) (9734/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.1854) | Acc: (93.00%) (10932/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.1856) | Acc: (93.00%) (12128/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.1851) | Acc: (93.00%) (13325/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.1847) | Acc: (93.00%) (14521/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.1844) | Acc: (93.00%) (15722/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.1830) | Acc: (93.00%) (16937/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.1824) | Acc: (93.00%) (18141/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.1826) | Acc: (93.00%) (19335/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.1829) | Acc: (93.00%) (20532/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.1826) | Acc: (93.00%) (21729/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.1834) | Acc: (93.00%) (22921/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.1829) | Acc: (93.00%) (24126/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.1841) | Acc: (93.00%) (25329/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.1838) | Acc: (93.00%) (26538/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.1837) | Acc: (93.00%) (27739/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.1834) | Acc: (93.00%) (28941/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.1828) | Acc: (93.00%) (30156/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.1817) | Acc: (93.00%) (31369/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.1820) | Acc: (93.00%) (32570/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.1825) | Acc: (93.00%) (33765/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.1820) | Acc: (93.00%) (34978/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.1812) | Acc: (93.00%) (36194/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.1822) | Acc: (93.00%) (37387/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.1818) | Acc: (93.00%) (38591/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.1817) | Acc: (93.00%) (39791/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.1815) | Acc: (93.00%) (40990/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.1814) | Acc: (93.00%) (42199/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.1815) | Acc: (93.00%) (43395/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.1810) | Acc: (93.00%) (44608/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.1808) | Acc: (93.00%) (45811/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.1810) | Acc: (93.00%) (46960/50000)
# TEST : Loss: (0.3009) | Acc: (90.00%) (9007/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8972e-01, -2.1114e-01,  4.2896e-02],
          [-7.0449e-02,  3.3527e-01,  2.3215e-01],
          [ 1.0479e-01,  5.9251e-02, -4.0201e-02]],

         [[-2.0253e-01,  2.2496e-01,  2.0216e-01],
          [ 1.9132e-02,  3.8647e-01,  2.2388e-01],
          [ 1.9631e-01, -2.3519e-02,  1.1150e-01]],

         [[-2.1847e-01, -6.4654e-02, -7.9823e-02],
          [-2.9534e-01, -1.1288e-01, -1.1115e-01],
          [-2.2054e-01, -1.2529e-01, -1.8070e-01]]],


        [[[-1.3178e-40,  1.3902e-40,  1.8494e-40],
          [-1.1260e-40, -1.0207e-40,  2.9173e-40],
          [-9.7829e-41, -1.8643e-40,  3.5987e-40]],

         [[ 2.4261e-40, -2.2394e-41, -2.1276e-40],
          [ 3.1804e-40,  2.8115e-40,  2.0546e-40],
          [-2.8732e-41,  1.7760e-40,  2.6888e-41]],

         [[-4.6557e-40,  3.8732e-42, -5.5604e-40],
          [ 2.9196e-40,  1.6224e-40,  4.4081e-40],
          [-1.4066e-40,  3.0585e-40,  1.2264e-40]]],


        [[[ 3.3805e-02,  9.7883e-02, -7.7624e-02],
          [ 2.4024e-02,  1.9072e-01, -1.0789e-01],
          [ 1.3375e-01,  3.1873e-01,  3.2414e-01]],

         [[-2.0044e-01, -7.2359e-02, -1.6967e-01],
          [-3.5923e-01, -3.1926e-01, -2.7669e-01],
          [-2.5072e-01, -3.9085e-01,  5.3791e-02]],

         [[ 2.4160e-01,  1.3348e-01,  1.9346e-01],
          [ 2.1067e-01,  1.2899e-01,  3.9896e-02],
          [ 6.0630e-02,  1.1048e-01,  4.5401e-02]]],


        ...,


        [[[ 2.4434e-01,  5.3740e-02,  7.5441e-02],
          [ 1.6751e-01, -2.1032e-01, -5.4897e-02],
          [ 1.4770e-02, -1.1048e-01, -5.4171e-02]],

         [[-7.4059e-02, -7.2241e-02,  1.0353e-02],
          [-1.4957e-01, -2.4976e-01,  3.0681e-02],
          [-1.1174e-02,  1.4638e-01,  2.0909e-01]],

         [[-7.3095e-02, -1.2839e-01,  1.0254e-01],
          [-9.7897e-02, -2.4339e-01, -1.7074e-01],
          [-4.7813e-02, -7.6297e-02, -6.0824e-02]]],


        [[[ 1.3197e-01,  2.1768e-01,  3.0334e-01],
          [ 1.5469e-01,  1.6841e-01,  2.0846e-02],
          [-2.6143e-01, -1.6520e-01, -6.5274e-02]],

         [[ 8.3219e-02,  5.4587e-02, -1.3030e-01],
          [ 3.2598e-02, -8.4566e-02, -3.2629e-01],
          [-2.9995e-02,  9.8593e-02, -3.9168e-02]],

         [[-2.6476e-01, -1.1535e-01, -2.1591e-01],
          [-1.5194e-01,  5.8288e-02,  5.5021e-02],
          [ 1.1738e-01,  2.6365e-01,  2.1183e-01]]],


        [[[-3.2262e-41,  5.6516e-41,  2.9937e-40],
          [ 4.6465e-40,  1.4689e-40, -6.0676e-40],
          [ 1.8888e-40, -3.2651e-40,  8.8168e-41]],

         [[-2.7522e-40,  3.6278e-40,  6.2226e-41],
          [ 1.7902e-40,  1.0705e-40,  2.7584e-40],
          [-3.0314e-40, -4.4542e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.1793e-40,  2.6944e-40],
          [-3.1497e-40, -1.5121e-40,  4.6666e-40],
          [-2.3477e-40, -3.5977e-40,  1.3506e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0783]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0099]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 112 | Batch_idx: 0 |  Loss: (0.2000) | Acc: (93.00%) (120/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1548) | Acc: (95.00%) (1338/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1673) | Acc: (94.00%) (2532/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1789) | Acc: (93.00%) (3717/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.1861) | Acc: (93.00%) (4911/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.2023) | Acc: (93.00%) (6076/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.2117) | Acc: (92.00%) (7241/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.2177) | Acc: (92.00%) (8405/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.2217) | Acc: (92.00%) (9572/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.2288) | Acc: (92.00%) (10726/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.2340) | Acc: (91.00%) (11878/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.2370) | Acc: (91.00%) (13042/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.2390) | Acc: (91.00%) (14209/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.2411) | Acc: (91.00%) (15374/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.2425) | Acc: (91.00%) (16543/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.2456) | Acc: (91.00%) (17704/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.2463) | Acc: (91.00%) (18875/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.2463) | Acc: (91.00%) (20040/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.2489) | Acc: (91.00%) (21194/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.2503) | Acc: (91.00%) (22346/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.2487) | Acc: (91.00%) (23531/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.2482) | Acc: (91.00%) (24711/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.2482) | Acc: (91.00%) (25884/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.2480) | Acc: (91.00%) (27050/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.2490) | Acc: (91.00%) (28209/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.2506) | Acc: (91.00%) (29367/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.2515) | Acc: (91.00%) (30527/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.2526) | Acc: (91.00%) (31681/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.2518) | Acc: (91.00%) (32864/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.2515) | Acc: (91.00%) (34032/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.2509) | Acc: (91.00%) (35214/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.2519) | Acc: (91.00%) (36367/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.2526) | Acc: (91.00%) (37534/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.2523) | Acc: (91.00%) (38714/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.2517) | Acc: (91.00%) (39899/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.2512) | Acc: (91.00%) (41067/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.2508) | Acc: (91.00%) (42244/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.2501) | Acc: (91.00%) (43423/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.2492) | Acc: (91.00%) (44607/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.2486) | Acc: (91.00%) (45745/50000)
# TEST : Loss: (0.3662) | Acc: (88.00%) (8812/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9572e-01, -2.1266e-01,  4.2156e-02],
          [-7.0644e-02,  3.3855e-01,  2.2790e-01],
          [ 9.8611e-02,  4.7812e-02, -5.8494e-02]],

         [[-1.9943e-01,  2.3314e-01,  2.1034e-01],
          [ 2.9807e-02,  4.0181e-01,  2.3030e-01],
          [ 2.0302e-01, -2.0527e-02,  1.0568e-01]],

         [[-2.1329e-01, -6.2691e-02, -7.4740e-02],
          [-2.8750e-01, -1.0746e-01, -1.0988e-01],
          [-2.1801e-01, -1.2817e-01, -1.8630e-01]]],


        [[[-4.0869e-40,  1.1140e-42,  5.9983e-40],
          [-2.5122e-40,  3.1244e-40, -1.2243e-40],
          [ 1.7808e-40, -3.2511e-40, -1.9293e-40]],

         [[-3.3162e-41,  2.5426e-40, -2.1357e-40],
          [ 4.2392e-41, -2.7137e-40,  2.0600e-40],
          [ 1.0947e-40,  3.9657e-41, -1.1158e-40]],

         [[-1.8990e-40,  2.8073e-40, -4.1924e-40],
          [ 1.6095e-41,  1.6260e-40,  5.8031e-40],
          [-2.7933e-40,  2.9783e-41,  5.3850e-40]]],


        [[[ 4.7248e-02,  1.1548e-01, -5.5962e-02],
          [ 2.4596e-02,  1.9409e-01, -1.0467e-01],
          [ 1.2661e-01,  3.1749e-01,  3.2275e-01]],

         [[-1.8527e-01, -5.4918e-02, -1.5092e-01],
          [-3.6619e-01, -3.2402e-01, -2.8188e-01],
          [-2.6548e-01, -4.0196e-01,  4.1736e-02]],

         [[ 2.5330e-01,  1.4701e-01,  2.0577e-01],
          [ 2.0125e-01,  1.2129e-01,  2.8317e-02],
          [ 4.6381e-02,  9.6806e-02,  2.4855e-02]]],


        ...,


        [[[ 2.2632e-01,  3.3612e-02,  6.7942e-02],
          [ 1.5718e-01, -2.3008e-01, -6.7699e-02],
          [ 1.7716e-02, -1.0883e-01, -6.0477e-02]],

         [[-8.6915e-02, -8.9151e-02,  8.6561e-03],
          [-1.5154e-01, -2.7124e-01,  1.7103e-02],
          [ 1.2226e-03,  1.5559e-01,  2.0984e-01]],

         [[-7.9876e-02, -1.3743e-01,  1.0562e-01],
          [-8.1686e-02, -2.4712e-01, -1.6875e-01],
          [-1.9541e-02, -4.6911e-02, -4.8067e-02]]],


        [[[ 1.4348e-01,  2.2849e-01,  3.1107e-01],
          [ 1.5703e-01,  1.6793e-01,  2.7703e-02],
          [-2.6107e-01, -1.6890e-01, -6.1995e-02]],

         [[ 8.6841e-02,  5.7986e-02, -1.2478e-01],
          [ 3.1258e-02, -8.6906e-02, -3.2032e-01],
          [-2.8797e-02,  9.3552e-02, -4.0359e-02]],

         [[-2.6960e-01, -1.2078e-01, -2.1923e-01],
          [-1.6104e-01,  4.8276e-02,  4.8818e-02],
          [ 1.1213e-01,  2.5367e-01,  1.9755e-01]]],


        [[[-1.7239e-40, -2.2374e-40,  5.7962e-40],
          [-9.5863e-41,  1.4689e-40, -1.8639e-40],
          [ 4.6914e-40, -3.2651e-40,  8.8170e-41]],

         [[ 1.4515e-40,  2.2266e-40,  4.8261e-40],
          [ 1.7902e-40, -1.7321e-40, -4.4113e-42],
          [-4.4327e-40,  1.1508e-40,  3.8969e-41]],

         [[ 4.9490e-41, -3.1793e-40, -1.5094e-40],
          [-1.7485e-40,  4.0930e-40,  3.2653e-40],
          [-9.4648e-41, -2.1964e-40,  1.3506e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0254,  0.0123,  0.0117],
          [ 0.0298,  0.0148,  0.0052],
          [ 0.0230,  0.0079, -0.0056]],

         [[ 0.0179,  0.0031,  0.0008],
          [ 0.0218,  0.0048, -0.0070],
          [ 0.0139, -0.0025, -0.0164]],

         [[ 0.0084, -0.0029, -0.0067],
          [ 0.0110, -0.0017, -0.0120],
          [ 0.0049, -0.0077, -0.0188]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0160,  0.0211,  0.0249],
          [ 0.0266,  0.0195,  0.0218],
          [ 0.0267,  0.0246,  0.0101]],

         [[ 0.0347,  0.0352,  0.0319],
          [ 0.0456,  0.0323,  0.0278],
          [ 0.0379,  0.0314,  0.0142]],

         [[ 0.0497,  0.0453,  0.0380],
          [ 0.0591,  0.0404,  0.0296],
          [ 0.0537,  0.0440,  0.0237]]],


        ...,


        [[[-0.0031, -0.0024, -0.0010],
          [-0.0031, -0.0022, -0.0035],
          [ 0.0004, -0.0014, -0.0060]],

         [[-0.0013, -0.0015, -0.0016],
          [-0.0011, -0.0011, -0.0041],
          [ 0.0029,  0.0007, -0.0051]],

         [[-0.0010, -0.0005,  0.0003],
          [ 0.0003,  0.0002, -0.0022],
          [ 0.0050,  0.0023, -0.0030]]],


        [[[-0.0088, -0.0114, -0.0154],
          [-0.0116, -0.0128, -0.0105],
          [-0.0151, -0.0123, -0.0042]],

         [[-0.0037, -0.0061, -0.0117],
          [-0.0075, -0.0082, -0.0074],
          [-0.0098, -0.0070,  0.0003]],

         [[ 0.0014, -0.0021, -0.0067],
          [ 0.0001, -0.0008,  0.0005],
          [-0.0008,  0.0020,  0.0080]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0768]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 113 | Batch_idx: 0 |  Loss: (0.2358) | Acc: (89.00%) (114/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.2056) | Acc: (92.00%) (1297/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.2193) | Acc: (92.00%) (2485/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.2151) | Acc: (92.00%) (3665/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.2023) | Acc: (92.00%) (4870/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.2044) | Acc: (92.00%) (6053/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.2018) | Acc: (92.00%) (7244/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.2016) | Acc: (92.00%) (8433/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1980) | Acc: (92.00%) (9630/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.2013) | Acc: (92.00%) (10810/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.2032) | Acc: (92.00%) (11984/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.2037) | Acc: (92.00%) (13165/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.2036) | Acc: (92.00%) (14352/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.2055) | Acc: (92.00%) (15535/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.2054) | Acc: (92.00%) (16724/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.2070) | Acc: (92.00%) (17900/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.2081) | Acc: (92.00%) (19083/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.2088) | Acc: (92.00%) (20262/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.2088) | Acc: (92.00%) (21450/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.2083) | Acc: (92.00%) (22646/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.2086) | Acc: (92.00%) (23818/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.2112) | Acc: (92.00%) (24978/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.2116) | Acc: (92.00%) (26174/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.2110) | Acc: (92.00%) (27372/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.2122) | Acc: (92.00%) (28557/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.2116) | Acc: (92.00%) (29751/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.2131) | Acc: (92.00%) (30928/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.2134) | Acc: (92.00%) (32113/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.2137) | Acc: (92.00%) (33291/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.2145) | Acc: (92.00%) (34473/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.2142) | Acc: (92.00%) (35661/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.2139) | Acc: (92.00%) (36853/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.2147) | Acc: (92.00%) (38025/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.2148) | Acc: (92.00%) (39202/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.2138) | Acc: (92.00%) (40401/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.2146) | Acc: (92.00%) (41575/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.2141) | Acc: (92.00%) (42769/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.2136) | Acc: (92.00%) (43963/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.2128) | Acc: (92.00%) (45164/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.2117) | Acc: (92.00%) (46328/50000)
# TEST : Loss: (0.3525) | Acc: (88.00%) (8871/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9780e-01, -2.1974e-01,  4.5299e-02],
          [-7.4987e-02,  3.3474e-01,  2.3208e-01],
          [ 1.0207e-01,  4.8117e-02, -5.8280e-02]],

         [[-2.0164e-01,  2.2332e-01,  2.0905e-01],
          [ 2.3052e-02,  3.9440e-01,  2.3106e-01],
          [ 2.0214e-01, -2.4210e-02,  1.0324e-01]],

         [[-2.1469e-01, -7.3486e-02, -7.7572e-02],
          [-2.9529e-01, -1.1902e-01, -1.1166e-01],
          [-2.2074e-01, -1.3545e-01, -1.8901e-01]]],


        [[[-2.7108e-40, -1.3750e-40,  4.6272e-40],
          [-1.1334e-40,  4.5169e-40, -4.0001e-40],
          [ 3.1693e-40, -1.8715e-40, -6.0950e-40]],

         [[-3.1036e-40,  2.5489e-40,  6.2861e-41],
          [-2.3472e-40, -5.4928e-40, -7.0862e-41],
          [ 1.0980e-40, -9.8984e-41, -1.1188e-40]],

         [[ 2.2587e-40,  2.8131e-40,  1.3439e-40],
          [-2.6118e-40,  2.4189e-41,  1.6543e-40],
          [-1.4138e-40, -2.4764e-40,  4.0084e-40]]],


        [[[ 4.1674e-02,  1.0897e-01, -6.2253e-02],
          [ 2.5650e-02,  1.9503e-01, -1.0168e-01],
          [ 1.2386e-01,  3.1455e-01,  3.2761e-01]],

         [[-1.8967e-01, -6.5483e-02, -1.6281e-01],
          [-3.6575e-01, -3.2912e-01, -2.8294e-01],
          [-2.6493e-01, -4.0720e-01,  4.3592e-02]],

         [[ 2.5226e-01,  1.4104e-01,  1.9591e-01],
          [ 2.0509e-01,  1.2124e-01,  2.9288e-02],
          [ 5.1431e-02,  9.7058e-02,  3.0106e-02]]],


        ...,


        [[[ 2.4359e-01,  5.8331e-02,  1.0883e-01],
          [ 1.7851e-01, -2.0315e-01, -2.5278e-02],
          [ 4.0020e-02, -8.4145e-02, -2.7817e-02]],

         [[-6.8634e-02, -6.1035e-02,  4.9259e-02],
          [-1.2807e-01, -2.4264e-01,  5.7499e-02],
          [ 1.6370e-02,  1.7263e-01,  2.3878e-01]],

         [[-7.8714e-02, -1.3317e-01,  1.2168e-01],
          [-6.6624e-02, -2.3007e-01, -1.4463e-01],
          [-1.2857e-02, -4.4065e-02, -3.6663e-02]]],


        [[[ 1.4126e-01,  2.3679e-01,  3.1102e-01],
          [ 1.7038e-01,  1.8523e-01,  3.4425e-02],
          [-2.4812e-01, -1.6253e-01, -6.8359e-02]],

         [[ 8.4704e-02,  5.8336e-02, -1.3211e-01],
          [ 3.8576e-02, -8.1478e-02, -3.2383e-01],
          [-2.6452e-02,  8.8641e-02, -5.5462e-02]],

         [[-2.6849e-01, -1.1733e-01, -2.2066e-01],
          [-1.5300e-01,  5.4411e-02,  4.6732e-02],
          [ 1.1200e-01,  2.5013e-01,  1.8492e-01]]],


        [[[-1.7239e-40, -2.2374e-40,  2.9937e-40],
          [-5.1625e-40,  6.7599e-42,  3.7412e-40],
          [ 3.2901e-40, -4.6254e-41, -5.1957e-41]],

         [[ 4.2541e-40, -1.9773e-40,  4.8261e-40],
          [ 3.8897e-41, -3.1333e-40, -2.8467e-40],
          [-1.6301e-40,  5.3547e-40,  1.7910e-40]],

         [[-2.3077e-40, -3.7675e-41, -4.3119e-40],
          [ 1.0541e-40,  5.4943e-40, -9.3844e-41],
          [ 1.8561e-40,  2.0074e-40, -5.0699e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0257, -0.0226, -0.0251],
          [-0.0187, -0.0128, -0.0178],
          [-0.0100, -0.0090, -0.0097]],

         [[-0.0162, -0.0118, -0.0138],
          [-0.0120, -0.0046, -0.0099],
          [-0.0058, -0.0047, -0.0059]],

         [[-0.0086, -0.0064, -0.0091],
          [-0.0063, -0.0016, -0.0067],
          [-0.0022, -0.0024, -0.0037]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0356,  0.0226,  0.0120],
          [ 0.0277,  0.0185,  0.0096],
          [ 0.0002,  0.0045, -0.0019]],

         [[ 0.0420,  0.0286,  0.0203],
          [ 0.0375,  0.0244,  0.0168],
          [ 0.0140,  0.0142,  0.0081]],

         [[ 0.0487,  0.0376,  0.0334],
          [ 0.0432,  0.0310,  0.0266],
          [ 0.0239,  0.0218,  0.0168]]],


        ...,


        [[[-0.0046, -0.0033, -0.0015],
          [-0.0033, -0.0030, -0.0020],
          [-0.0018, -0.0039, -0.0032]],

         [[-0.0034, -0.0034, -0.0026],
          [-0.0015, -0.0017, -0.0018],
          [ 0.0012, -0.0007, -0.0008]],

         [[-0.0028, -0.0029, -0.0028],
          [ 0.0001, -0.0005, -0.0017],
          [ 0.0035,  0.0014,  0.0006]]],


        [[[-0.0055, -0.0040, -0.0047],
          [-0.0117, -0.0086, -0.0051],
          [-0.0133, -0.0051,  0.0001]],

         [[-0.0029, -0.0016, -0.0035],
          [-0.0086, -0.0066, -0.0044],
          [-0.0095, -0.0021,  0.0020]],

         [[-0.0023, -0.0029, -0.0043],
          [-0.0074, -0.0072, -0.0051],
          [-0.0076, -0.0024,  0.0008]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0766]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 114 | Batch_idx: 0 |  Loss: (0.1359) | Acc: (95.00%) (122/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.2137) | Acc: (93.00%) (1310/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.2275) | Acc: (92.00%) (2479/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.2359) | Acc: (92.00%) (3652/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.2334) | Acc: (91.00%) (4828/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.2345) | Acc: (91.00%) (5994/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.2326) | Acc: (91.00%) (7169/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.2282) | Acc: (92.00%) (8362/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.2310) | Acc: (91.00%) (9528/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.2278) | Acc: (91.00%) (10716/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.2260) | Acc: (92.00%) (11902/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.2231) | Acc: (92.00%) (13103/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.2188) | Acc: (92.00%) (14308/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.2171) | Acc: (92.00%) (15502/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.2150) | Acc: (92.00%) (16700/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.2128) | Acc: (92.00%) (17895/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.2124) | Acc: (92.00%) (19082/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.2107) | Acc: (92.00%) (20292/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.2089) | Acc: (92.00%) (21497/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.2072) | Acc: (92.00%) (22696/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.2068) | Acc: (92.00%) (23884/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.2055) | Acc: (92.00%) (25086/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.2045) | Acc: (92.00%) (26276/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.2037) | Acc: (92.00%) (27484/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.2042) | Acc: (92.00%) (28674/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.2033) | Acc: (92.00%) (29877/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.2023) | Acc: (93.00%) (31085/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.2021) | Acc: (93.00%) (32282/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.2009) | Acc: (93.00%) (33491/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.2004) | Acc: (93.00%) (34682/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1999) | Acc: (93.00%) (35877/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1987) | Acc: (93.00%) (37086/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1984) | Acc: (93.00%) (38285/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1970) | Acc: (93.00%) (39496/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1961) | Acc: (93.00%) (40691/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1957) | Acc: (93.00%) (41885/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1951) | Acc: (93.00%) (43088/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1946) | Acc: (93.00%) (44290/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1941) | Acc: (93.00%) (45495/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1934) | Acc: (93.00%) (46656/50000)
# TEST : Loss: (0.3034) | Acc: (90.00%) (9021/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9644e-01, -2.1764e-01,  4.6753e-02],
          [-7.5217e-02,  3.3349e-01,  2.3220e-01],
          [ 1.0116e-01,  4.8289e-02, -5.7022e-02]],

         [[-2.0069e-01,  2.2257e-01,  2.0844e-01],
          [ 2.2170e-02,  3.9185e-01,  2.2999e-01],
          [ 2.0109e-01, -2.3825e-02,  1.0379e-01]],

         [[-2.1361e-01, -7.3703e-02, -7.7776e-02],
          [-2.9533e-01, -1.2027e-01, -1.1224e-01],
          [-2.2094e-01, -1.3559e-01, -1.8848e-01]]],


        [[[ 1.4496e-40, -1.3777e-40, -9.1566e-41],
          [ 1.6404e-40,  1.7472e-40, -2.6191e-40],
          [ 1.7869e-40,  9.0312e-41, -4.7147e-40]],

         [[-3.1090e-40, -2.2394e-41,  3.4052e-40],
          [-2.3527e-40, -2.7252e-40, -2.0994e-40],
          [-2.8736e-41, -9.9247e-41,  2.6898e-41]],

         [[ 3.6531e-40,  3.8410e-42,  5.5138e-40],
          [-2.6170e-40, -1.1477e-40, -3.9013e-40],
          [ 1.3609e-40, -2.4815e-40, -1.5456e-40]]],


        [[[ 4.1517e-02,  1.0935e-01, -6.0633e-02],
          [ 2.5154e-02,  1.9480e-01, -1.0050e-01],
          [ 1.2368e-01,  3.1437e-01,  3.2832e-01]],

         [[-1.9073e-01, -6.5774e-02, -1.6169e-01],
          [-3.6662e-01, -3.2931e-01, -2.8201e-01],
          [-2.6508e-01, -4.0678e-01,  4.4188e-02]],

         [[ 2.4970e-01,  1.3936e-01,  1.9518e-01],
          [ 2.0279e-01,  1.1978e-01,  2.8823e-02],
          [ 5.0064e-02,  9.5941e-02,  2.9800e-02]]],


        ...,


        [[[ 2.4426e-01,  6.1581e-02,  1.1162e-01],
          [ 1.7879e-01, -1.9730e-01, -2.1613e-02],
          [ 3.8427e-02, -8.2027e-02, -2.5108e-02]],

         [[-6.5240e-02, -5.7086e-02,  5.1282e-02],
          [-1.2430e-01, -2.3508e-01,  5.9245e-02],
          [ 1.3504e-02,  1.6994e-01,  2.3778e-01]],

         [[-7.4727e-02, -1.2775e-01,  1.2086e-01],
          [-6.3593e-02, -2.1921e-01, -1.4286e-01],
          [-1.7683e-02, -4.8146e-02, -3.8649e-02]]],


        [[[ 1.4073e-01,  2.3370e-01,  3.0773e-01],
          [ 1.7238e-01,  1.8571e-01,  3.5969e-02],
          [-2.4142e-01, -1.5856e-01, -6.5539e-02]],

         [[ 8.2647e-02,  5.5267e-02, -1.3355e-01],
          [ 3.9855e-02, -8.0214e-02, -3.2091e-01],
          [-2.3347e-02,  8.9088e-02, -5.4526e-02]],

         [[-2.6731e-01, -1.1809e-01, -2.2073e-01],
          [-1.5064e-01,  5.4715e-02,  4.6499e-02],
          [ 1.1318e-01,  2.4906e-01,  1.8337e-01]]],


        [[[-3.2263e-41,  5.6513e-41, -2.6114e-40],
          [-3.7612e-40, -1.3337e-40,  5.1424e-40],
          [-9.1374e-41,  2.3400e-40, -1.9208e-40]],

         [[ 2.8528e-40, -4.7798e-40,  6.2225e-41],
          [-1.0123e-40, -1.7321e-40, -2.8467e-40],
          [ 2.5737e-40,  3.9534e-40,  1.7910e-40]],

         [[-2.3077e-40,  2.4258e-40, -2.9106e-40],
          [ 2.4554e-40,  1.2905e-40, -3.7410e-40],
          [ 3.2573e-40,  4.8099e-40, -1.4520e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0299]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0239]], device='cuda:0')

Epoch: 115 | Batch_idx: 0 |  Loss: (0.1609) | Acc: (93.00%) (120/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.1553) | Acc: (94.00%) (1333/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.1488) | Acc: (94.00%) (2552/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.1522) | Acc: (95.00%) (3770/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.1597) | Acc: (94.00%) (4961/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.1588) | Acc: (94.00%) (6172/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.1628) | Acc: (94.00%) (7361/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.1658) | Acc: (94.00%) (8562/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.1630) | Acc: (94.00%) (9778/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.1666) | Acc: (94.00%) (10973/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.1649) | Acc: (94.00%) (12198/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.1641) | Acc: (94.00%) (13409/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.1649) | Acc: (94.00%) (14610/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.1657) | Acc: (94.00%) (15818/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.1657) | Acc: (94.00%) (17029/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.1655) | Acc: (94.00%) (18234/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.1656) | Acc: (94.00%) (19443/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.1660) | Acc: (94.00%) (20649/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.1653) | Acc: (94.00%) (21863/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.1664) | Acc: (94.00%) (23057/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.1671) | Acc: (94.00%) (24259/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.1666) | Acc: (94.00%) (25470/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.1669) | Acc: (94.00%) (26672/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.1674) | Acc: (94.00%) (27879/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.1674) | Acc: (94.00%) (29086/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.1670) | Acc: (94.00%) (30301/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.1677) | Acc: (94.00%) (31501/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.1675) | Acc: (94.00%) (32715/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.1670) | Acc: (94.00%) (33924/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.1670) | Acc: (94.00%) (35130/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.1678) | Acc: (94.00%) (36329/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.1675) | Acc: (94.00%) (37549/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.1677) | Acc: (94.00%) (38753/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.1679) | Acc: (94.00%) (39950/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.1678) | Acc: (94.00%) (41162/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.1677) | Acc: (94.00%) (42367/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.1677) | Acc: (94.00%) (43585/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.1677) | Acc: (94.00%) (44786/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.1685) | Acc: (94.00%) (45986/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.1681) | Acc: (94.00%) (47163/50000)
# TEST : Loss: (0.2933) | Acc: (90.00%) (9040/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9571e-01, -2.1677e-01,  4.6556e-02],
          [-7.4921e-02,  3.3205e-01,  2.3115e-01],
          [ 1.0076e-01,  4.8080e-02, -5.6771e-02]],

         [[-1.9989e-01,  2.2163e-01,  2.0754e-01],
          [ 2.2078e-02,  3.9012e-01,  2.2897e-01],
          [ 2.0027e-01, -2.3722e-02,  1.0335e-01]],

         [[-2.1266e-01, -7.3377e-02, -7.7440e-02],
          [-2.9401e-01, -1.1973e-01, -1.1176e-01],
          [-2.1998e-01, -1.3500e-01, -1.8768e-01]]],


        [[[ 4.2335e-40,  1.1140e-42, -5.0888e-40],
          [ 3.0333e-40, -2.4237e-40,  1.5499e-40],
          [-9.9136e-41,  2.2963e-40,  8.4715e-41]],

         [[-3.3146e-41, -3.0064e-40,  3.4099e-40],
          [ 4.2393e-41,  2.8355e-40, -7.1148e-41],
          [-1.6779e-40,  3.9658e-41,  1.6610e-40]],

         [[ 8.7630e-41, -2.7451e-40,  4.1311e-40],
          [ 1.6101e-41, -1.1498e-40, -5.2990e-40],
          [ 2.7542e-40,  2.9768e-41, -5.7241e-40]]],


        [[[ 4.1436e-02,  1.0913e-01, -6.0511e-02],
          [ 2.5105e-02,  1.9442e-01, -1.0030e-01],
          [ 1.2344e-01,  3.1376e-01,  3.2767e-01]],

         [[-1.9033e-01, -6.5635e-02, -1.6135e-01],
          [-3.6582e-01, -3.2860e-01, -2.8140e-01],
          [-2.6452e-01, -4.0592e-01,  4.4096e-02]],

         [[ 2.4915e-01,  1.3905e-01,  1.9476e-01],
          [ 2.0233e-01,  1.1951e-01,  2.8758e-02],
          [ 4.9954e-02,  9.5730e-02,  2.9734e-02]]],


        ...,


        [[[ 2.4155e-01,  6.0876e-02,  1.1044e-01],
          [ 1.7654e-01, -1.9460e-01, -2.1350e-02],
          [ 3.7978e-02, -8.1001e-02, -2.4815e-02]],

         [[-6.4342e-02, -5.6241e-02,  5.0641e-02],
          [-1.2213e-01, -2.3002e-01,  5.8317e-02],
          [ 1.3315e-02,  1.6721e-01,  2.3461e-01]],

         [[-7.3393e-02, -1.2505e-01,  1.1892e-01],
          [-6.1974e-02, -2.0923e-01, -1.3969e-01],
          [-1.7369e-02, -4.7084e-02, -3.8003e-02]]],


        [[[ 1.3910e-01,  2.3096e-01,  3.0447e-01],
          [ 1.7047e-01,  1.8367e-01,  3.5611e-02],
          [-2.3903e-01, -1.5700e-01, -6.4916e-02]],

         [[ 8.1814e-02,  5.4731e-02, -1.3223e-01],
          [ 3.9453e-02, -7.9449e-02, -3.1780e-01],
          [-2.3122e-02,  8.8271e-02, -5.4012e-02]],

         [[-2.6481e-01, -1.1704e-01, -2.1863e-01],
          [-1.4923e-01,  5.4231e-02,  4.6054e-02],
          [ 1.1213e-01,  2.4690e-01,  1.8167e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -5.4139e-40],
          [ 1.8439e-40, -1.3337e-40,  9.3863e-41],
          [-3.7163e-40,  2.3400e-40, -1.9208e-40]],

         [[-1.3510e-40, -3.3786e-40, -3.5816e-40],
          [-1.0123e-40,  1.0705e-40, -4.4099e-42],
          [ 3.9750e-40, -1.6517e-40,  3.8969e-41]],

         [[ 4.9487e-41,  2.4258e-40,  1.2932e-40],
          [ 1.0541e-40, -4.3147e-40, -2.3397e-40],
          [ 1.8561e-40,  3.4087e-40, -1.4520e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0040]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0031]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 116 | Batch_idx: 0 |  Loss: (0.1572) | Acc: (92.00%) (118/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1612) | Acc: (94.00%) (1337/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1739) | Acc: (94.00%) (2536/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1807) | Acc: (93.00%) (3723/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1928) | Acc: (93.00%) (4910/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.2006) | Acc: (93.00%) (6095/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.2041) | Acc: (93.00%) (7278/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.2069) | Acc: (93.00%) (8463/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.2110) | Acc: (92.00%) (9633/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.2153) | Acc: (92.00%) (10801/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.2244) | Acc: (92.00%) (11940/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.2314) | Acc: (92.00%) (13105/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.2343) | Acc: (92.00%) (14269/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.2336) | Acc: (92.00%) (15454/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.2387) | Acc: (92.00%) (16612/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.2399) | Acc: (91.00%) (17771/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.2422) | Acc: (91.00%) (18930/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.2415) | Acc: (91.00%) (20113/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.2430) | Acc: (91.00%) (21270/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.2446) | Acc: (91.00%) (22432/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.2441) | Acc: (91.00%) (23612/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.2432) | Acc: (91.00%) (24786/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.2438) | Acc: (91.00%) (25955/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.2438) | Acc: (91.00%) (27127/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.2440) | Acc: (91.00%) (28309/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.2440) | Acc: (91.00%) (29481/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.2440) | Acc: (91.00%) (30658/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.2454) | Acc: (91.00%) (31809/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.2461) | Acc: (91.00%) (32976/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.2459) | Acc: (91.00%) (34143/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.2464) | Acc: (91.00%) (35303/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.2463) | Acc: (91.00%) (36476/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.2449) | Acc: (91.00%) (37664/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.2449) | Acc: (91.00%) (38843/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.2448) | Acc: (91.00%) (40020/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.2441) | Acc: (91.00%) (41206/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.2440) | Acc: (91.00%) (42393/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.2431) | Acc: (91.00%) (43578/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.2422) | Acc: (91.00%) (44767/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.2419) | Acc: (91.00%) (45902/50000)
# TEST : Loss: (0.3872) | Acc: (88.00%) (8803/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0218e-01, -2.1516e-01,  4.2468e-02],
          [-6.5300e-02,  3.4526e-01,  2.3403e-01],
          [ 1.0780e-01,  4.8188e-02, -6.3242e-02]],

         [[-2.0679e-01,  2.2445e-01,  2.0905e-01],
          [ 3.2362e-02,  4.0396e-01,  2.3458e-01],
          [ 2.0914e-01, -2.0698e-02,  1.0050e-01]],

         [[-2.0896e-01, -6.4682e-02, -7.1256e-02],
          [-2.8416e-01, -1.1049e-01, -1.0458e-01],
          [-2.1094e-01, -1.3179e-01, -1.8096e-01]]],


        [[[ 2.8464e-40,  1.4040e-40, -3.7045e-40],
          [ 1.6446e-40, -3.8202e-40,  4.3375e-40],
          [-2.3855e-40,  9.0710e-41,  5.0298e-40]],

         [[ 2.4540e-40, -3.0100e-40,  6.2878e-41],
          [ 3.2090e-40,  5.6250e-40,  2.0736e-40],
          [-1.6798e-40,  1.7896e-40,  1.6626e-40]],

         [[-3.3017e-40, -2.7485e-40, -1.4355e-40],
          [ 2.9469e-40,  2.4188e-41, -1.1259e-40],
          [ 1.3651e-40,  3.0844e-40, -4.3367e-40]]],


        [[[ 4.6452e-02,  1.1302e-01, -5.4009e-02],
          [ 3.8945e-02,  2.0157e-01, -9.2275e-02],
          [ 1.4263e-01,  3.2712e-01,  3.3414e-01]],

         [[-1.9624e-01, -7.1827e-02, -1.6278e-01],
          [-3.6520e-01, -3.3147e-01, -2.7823e-01],
          [-2.5400e-01, -4.0185e-01,  4.4371e-02]],

         [[ 2.4221e-01,  1.3372e-01,  1.9466e-01],
          [ 2.0688e-01,  1.2387e-01,  3.6364e-02],
          [ 6.0746e-02,  1.0218e-01,  3.2056e-02]]],


        ...,


        [[[ 2.3775e-01,  7.0006e-02,  1.0501e-01],
          [ 1.6466e-01, -2.0846e-01, -4.4213e-02],
          [ 3.4970e-02, -9.5527e-02, -3.8114e-02]],

         [[-8.4097e-02, -5.4179e-02,  4.1653e-02],
          [-1.4911e-01, -2.5420e-01,  2.3021e-02],
          [-4.9888e-03,  1.4003e-01,  2.0671e-01]],

         [[-9.5657e-02, -1.1532e-01,  1.1667e-01],
          [-8.2094e-02, -2.2615e-01, -1.6712e-01],
          [-3.1002e-02, -7.4031e-02, -6.6033e-02]]],


        [[[ 1.2969e-01,  2.2209e-01,  2.9318e-01],
          [ 1.3716e-01,  1.4973e-01,  2.6981e-03],
          [-2.7469e-01, -1.8713e-01, -8.7333e-02]],

         [[ 7.7044e-02,  5.2721e-02, -1.3109e-01],
          [ 2.0219e-02, -9.4641e-02, -3.3023e-01],
          [-4.3495e-02,  7.4896e-02, -5.6284e-02]],

         [[-2.6170e-01, -1.1149e-01, -2.0401e-01],
          [-1.5388e-01,  5.7810e-02,  5.4367e-02],
          [ 1.0461e-01,  2.5294e-01,  1.9824e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -2.6114e-40],
          [ 6.0478e-40,  6.7585e-42, -4.6665e-40],
          [-2.3150e-40, -4.6255e-41, -5.1959e-41]],

         [[-4.1536e-40,  8.2528e-41, -3.5816e-40],
          [ 3.8896e-41,  2.4718e-40,  2.7585e-40],
          [ 1.1724e-40, -5.8556e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.7677e-41,  4.0958e-40],
          [-1.7485e-40, -5.7160e-40,  1.8641e-40],
          [-9.4647e-41, -7.9517e-41, -5.0713e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0124, -0.0102, -0.0074],
          [-0.0005, -0.0026, -0.0035],
          [ 0.0015, -0.0026, -0.0091]],

         [[-0.0172, -0.0160, -0.0106],
          [-0.0049, -0.0081, -0.0070],
          [-0.0037, -0.0090, -0.0125]],

         [[-0.0124, -0.0116, -0.0056],
          [-0.0018, -0.0033,  0.0011],
          [-0.0013, -0.0038, -0.0031]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0218, -0.0404, -0.0258],
          [-0.0321, -0.0439, -0.0047],
          [-0.0261, -0.0255,  0.0142]],

         [[-0.0239, -0.0372, -0.0194],
          [-0.0274, -0.0353,  0.0033],
          [-0.0175, -0.0110,  0.0261]],

         [[-0.0252, -0.0320, -0.0142],
          [-0.0226, -0.0249,  0.0136],
          [-0.0131, -0.0029,  0.0356]]],


        ...,


        [[[-0.0109, -0.0073, -0.0036],
          [-0.0036, -0.0022, -0.0021],
          [-0.0006, -0.0031, -0.0079]],

         [[-0.0104, -0.0060, -0.0028],
          [-0.0049, -0.0023, -0.0016],
          [-0.0037, -0.0053, -0.0090]],

         [[-0.0088, -0.0049, -0.0021],
          [-0.0041, -0.0017, -0.0006],
          [-0.0043, -0.0064, -0.0086]]],


        [[[ 0.0152,  0.0008,  0.0042],
          [ 0.0141,  0.0038,  0.0044],
          [ 0.0118,  0.0045,  0.0002]],

         [[ 0.0096, -0.0028,  0.0004],
          [ 0.0097,  0.0010,  0.0014],
          [ 0.0071,  0.0015, -0.0018]],

         [[ 0.0059, -0.0033, -0.0006],
          [ 0.0065,  0.0001,  0.0005],
          [ 0.0047,  0.0003, -0.0026]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0031]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 117 | Batch_idx: 0 |  Loss: (0.3002) | Acc: (91.00%) (117/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.2049) | Acc: (93.00%) (1314/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1990) | Acc: (93.00%) (2508/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.2061) | Acc: (92.00%) (3684/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.2099) | Acc: (92.00%) (4863/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.2116) | Acc: (92.00%) (6040/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.2135) | Acc: (92.00%) (7227/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.2127) | Acc: (92.00%) (8415/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.2085) | Acc: (92.00%) (9608/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.2083) | Acc: (92.00%) (10801/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.2058) | Acc: (92.00%) (12006/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.2038) | Acc: (92.00%) (13210/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.2049) | Acc: (93.00%) (14408/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.2027) | Acc: (93.00%) (15604/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.2056) | Acc: (92.00%) (16768/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.2073) | Acc: (92.00%) (17941/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.2069) | Acc: (92.00%) (19137/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.2087) | Acc: (92.00%) (20315/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.2071) | Acc: (92.00%) (21513/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.2074) | Acc: (92.00%) (22702/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.2065) | Acc: (92.00%) (23904/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.2066) | Acc: (92.00%) (25086/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.2066) | Acc: (92.00%) (26277/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.2069) | Acc: (92.00%) (27463/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.2060) | Acc: (92.00%) (28663/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.2058) | Acc: (92.00%) (29857/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.2046) | Acc: (92.00%) (31060/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.2056) | Acc: (92.00%) (32237/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.2066) | Acc: (92.00%) (33415/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.2062) | Acc: (92.00%) (34611/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.2066) | Acc: (92.00%) (35793/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.2068) | Acc: (92.00%) (36993/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.2064) | Acc: (92.00%) (38185/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.2063) | Acc: (92.00%) (39380/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.2072) | Acc: (92.00%) (40562/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.2076) | Acc: (92.00%) (41749/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.2086) | Acc: (92.00%) (42912/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.2081) | Acc: (92.00%) (44105/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.2074) | Acc: (92.00%) (45311/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.2072) | Acc: (92.00%) (46456/50000)
# TEST : Loss: (0.3678) | Acc: (88.00%) (8871/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0138e-01, -2.1214e-01,  4.2607e-02],
          [-6.1509e-02,  3.5029e-01,  2.3521e-01],
          [ 1.0928e-01,  5.2414e-02, -6.0206e-02]],

         [[-2.0139e-01,  2.2908e-01,  2.0819e-01],
          [ 4.1245e-02,  4.1442e-01,  2.3778e-01],
          [ 2.1306e-01, -1.2610e-02,  1.0600e-01]],

         [[-2.0580e-01, -6.1260e-02, -7.2072e-02],
          [-2.8054e-01, -1.0615e-01, -1.0382e-01],
          [-2.0932e-01, -1.2834e-01, -1.7636e-01]]],


        [[[-1.3332e-40,  1.4054e-40,  1.8658e-40],
          [-1.1421e-40, -1.0360e-40,  2.9474e-40],
          [-9.9489e-41, -1.8799e-40,  3.6402e-40]],

         [[ 2.4571e-40, -2.2394e-41, -2.1593e-40],
          [ 3.2121e-40,  2.8419e-40,  2.0756e-40],
          [-2.8732e-41,  1.7910e-40,  2.6895e-41]],

         [[-4.6993e-40,  3.8396e-42, -5.6204e-40],
          [ 2.9499e-40,  1.6367e-40,  4.4515e-40],
          [-1.4219e-40,  3.0872e-40,  1.2399e-40]]],


        [[[ 4.2312e-02,  1.0765e-01, -5.1649e-02],
          [ 3.7029e-02,  1.9585e-01, -8.9364e-02],
          [ 1.4452e-01,  3.2583e-01,  3.3540e-01]],

         [[-1.9524e-01, -7.5754e-02, -1.5613e-01],
          [-3.6878e-01, -3.4335e-01, -2.7866e-01],
          [-2.5253e-01, -4.0609e-01,  4.4409e-02]],

         [[ 2.4714e-01,  1.3333e-01,  2.0087e-01],
          [ 2.0763e-01,  1.1622e-01,  3.6021e-02],
          [ 6.5296e-02,  9.8198e-02,  2.9324e-02]]],


        ...,


        [[[ 2.1591e-01,  4.0282e-02,  7.5824e-02],
          [ 1.5004e-01, -2.3493e-01, -6.8346e-02],
          [ 2.4663e-02, -1.1491e-01, -5.5719e-02]],

         [[-9.5813e-02, -6.9088e-02,  2.9258e-02],
          [-1.4773e-01, -2.6356e-01,  1.6304e-02],
          [ 2.0851e-04,  1.3480e-01,  2.0324e-01]],

         [[-1.0792e-01, -1.3170e-01,  9.9795e-02],
          [-8.4577e-02, -2.3501e-01, -1.7393e-01],
          [-3.2969e-02, -7.9237e-02, -6.5884e-02]]],


        [[[ 1.3093e-01,  2.2922e-01,  3.0185e-01],
          [ 1.4547e-01,  1.5403e-01,  9.3079e-03],
          [-2.5759e-01, -1.7521e-01, -7.7785e-02]],

         [[ 7.1150e-02,  5.2715e-02, -1.2646e-01],
          [ 2.0281e-02, -9.5345e-02, -3.2673e-01],
          [-3.4005e-02,  8.1575e-02, -4.9287e-02]],

         [[-2.6610e-01, -1.1194e-01, -1.9857e-01],
          [-1.5236e-01,  5.7955e-02,  5.9210e-02],
          [ 1.1262e-01,  2.6078e-01,  2.0838e-01]]],


        [[[-3.2263e-41,  5.6513e-41,  2.9937e-40],
          [ 4.6465e-40,  1.4689e-40, -6.0678e-40],
          [ 1.8888e-40, -3.2651e-40,  8.8170e-41]],

         [[-2.7523e-40,  3.6278e-40,  6.2222e-41],
          [ 1.7902e-40,  1.0705e-40,  2.7585e-40],
          [-3.0314e-40, -4.4543e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.1793e-40,  2.6945e-40],
          [-3.1497e-40, -1.5121e-40,  4.6667e-40],
          [-2.3477e-40, -3.5977e-40,  1.3506e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0069, -0.0109, -0.0075],
          [ 0.0069,  0.0003, -0.0017],
          [ 0.0184,  0.0121,  0.0093]],

         [[-0.0073, -0.0116, -0.0079],
          [ 0.0061, -0.0001, -0.0020],
          [ 0.0188,  0.0140,  0.0117]],

         [[-0.0028, -0.0095, -0.0094],
          [ 0.0079,  0.0001, -0.0040],
          [ 0.0169,  0.0123,  0.0093]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0283,  0.0177,  0.0082],
          [ 0.0441,  0.0164,  0.0085],
          [ 0.0542,  0.0366,  0.0286]],

         [[ 0.0403,  0.0309,  0.0222],
          [ 0.0518,  0.0262,  0.0194],
          [ 0.0598,  0.0442,  0.0371]],

         [[ 0.0404,  0.0292,  0.0224],
          [ 0.0506,  0.0283,  0.0209],
          [ 0.0605,  0.0456,  0.0356]]],


        ...,


        [[[ 0.0059,  0.0047,  0.0093],
          [ 0.0049,  0.0007,  0.0052],
          [ 0.0022, -0.0020,  0.0007]],

         [[ 0.0066,  0.0049,  0.0093],
          [ 0.0055,  0.0012,  0.0056],
          [ 0.0031, -0.0011,  0.0009]],

         [[ 0.0036,  0.0035,  0.0064],
          [ 0.0028,  0.0000,  0.0034],
          [ 0.0014, -0.0018, -0.0002]]],


        [[[ 0.0006,  0.0029,  0.0073],
          [ 0.0015,  0.0044,  0.0052],
          [ 0.0041,  0.0035,  0.0011]],

         [[-0.0006,  0.0023,  0.0069],
          [ 0.0016,  0.0049,  0.0062],
          [ 0.0045,  0.0040,  0.0020]],

         [[-0.0013,  0.0019,  0.0068],
          [ 0.0003,  0.0038,  0.0064],
          [ 0.0033,  0.0030,  0.0026]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0031]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 118 | Batch_idx: 0 |  Loss: (0.1853) | Acc: (92.00%) (119/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.2469) | Acc: (91.00%) (1290/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.2397) | Acc: (92.00%) (2478/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.2410) | Acc: (91.00%) (3645/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.2412) | Acc: (92.00%) (4829/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.2426) | Acc: (91.00%) (5996/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.2412) | Acc: (91.00%) (7175/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.2351) | Acc: (92.00%) (8368/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.2308) | Acc: (92.00%) (9557/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.2255) | Acc: (92.00%) (10760/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.2239) | Acc: (92.00%) (11952/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.2209) | Acc: (92.00%) (13142/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.2178) | Acc: (92.00%) (14345/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.2158) | Acc: (92.00%) (15546/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.2138) | Acc: (92.00%) (16749/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.2109) | Acc: (92.00%) (17960/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.2096) | Acc: (92.00%) (19160/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.2079) | Acc: (93.00%) (20363/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.2067) | Acc: (93.00%) (21560/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.2047) | Acc: (93.00%) (22768/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.2045) | Acc: (93.00%) (23968/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.2029) | Acc: (93.00%) (25173/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.2011) | Acc: (93.00%) (26381/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1989) | Acc: (93.00%) (27591/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1964) | Acc: (93.00%) (28813/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1959) | Acc: (93.00%) (30008/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1953) | Acc: (93.00%) (31213/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1943) | Acc: (93.00%) (32421/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1932) | Acc: (93.00%) (33640/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1920) | Acc: (93.00%) (34862/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1916) | Acc: (93.00%) (36065/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1920) | Acc: (93.00%) (37246/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1909) | Acc: (93.00%) (38461/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1904) | Acc: (93.00%) (39665/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1903) | Acc: (93.00%) (40864/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1901) | Acc: (93.00%) (42069/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1898) | Acc: (93.00%) (43264/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1886) | Acc: (93.00%) (44487/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1877) | Acc: (93.00%) (45709/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1872) | Acc: (93.00%) (46871/50000)
# TEST : Loss: (0.2987) | Acc: (90.00%) (9042/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0058e-01, -2.1103e-01,  4.1358e-02],
          [-6.1459e-02,  3.4842e-01,  2.3238e-01],
          [ 1.0841e-01,  5.1240e-02, -6.2199e-02]],

         [[-1.9999e-01,  2.2910e-01,  2.0663e-01],
          [ 4.1453e-02,  4.1261e-01,  2.3518e-01],
          [ 2.1220e-01, -1.3392e-02,  1.0358e-01]],

         [[-2.0597e-01, -6.1356e-02, -7.3187e-02],
          [-2.8059e-01, -1.0699e-01, -1.0559e-01],
          [-2.0945e-01, -1.2928e-01, -1.7799e-01]]],


        [[[-4.1254e-40,  1.1140e-42,  6.0525e-40],
          [-2.5385e-40,  3.1495e-40, -1.2371e-40],
          [ 1.7940e-40, -3.2766e-40, -1.9410e-40]],

         [[-3.3148e-41,  2.5674e-40, -2.1619e-40],
          [ 4.2393e-41, -2.7384e-40, -7.1407e-41],
          [ 1.1079e-40,  3.9650e-41, -1.1272e-40]],

         [[-1.9111e-40,  2.8304e-40, -4.2295e-40],
          [ 1.6102e-41,  1.6379e-40,  5.8508e-40],
          [-2.8186e-40,  2.9772e-41,  5.4296e-40]]],


        [[[ 4.4320e-02,  1.0915e-01, -5.0441e-02],
          [ 3.8531e-02,  1.9708e-01, -8.7895e-02],
          [ 1.4516e-01,  3.2605e-01,  3.3608e-01]],

         [[-1.9422e-01, -7.5357e-02, -1.5606e-01],
          [-3.6781e-01, -3.4252e-01, -2.7827e-01],
          [-2.5236e-01, -4.0615e-01,  4.3807e-02]],

         [[ 2.4612e-01,  1.3252e-01,  1.9951e-01],
          [ 2.0578e-01,  1.1480e-01,  3.4511e-02],
          [ 6.2811e-02,  9.5461e-02,  2.7297e-02]]],


        ...,


        [[[ 2.1124e-01,  3.8206e-02,  7.2460e-02],
          [ 1.4528e-01, -2.3468e-01, -7.0636e-02],
          [ 2.1784e-02, -1.1463e-01, -5.6964e-02]],

         [[-9.7119e-02, -6.9080e-02,  2.7246e-02],
          [-1.4887e-01, -2.6094e-01,  1.4164e-02],
          [-1.5088e-03,  1.3362e-01,  2.0065e-01]],

         [[-1.0748e-01, -1.2946e-01,  9.7497e-02],
          [-8.4543e-02, -2.2851e-01, -1.7253e-01],
          [-3.2876e-02, -7.6103e-02, -6.4976e-02]]],


        [[[ 1.3244e-01,  2.2838e-01,  2.9893e-01],
          [ 1.4666e-01,  1.5353e-01,  9.1263e-03],
          [-2.5357e-01, -1.7231e-01, -7.6130e-02]],

         [[ 7.3167e-02,  5.3736e-02, -1.2533e-01],
          [ 2.2486e-02, -9.3903e-02, -3.2431e-01],
          [-3.2201e-02,  8.1757e-02, -4.8476e-02]],

         [[-2.6323e-01, -1.1136e-01, -1.9833e-01],
          [-1.5008e-01,  5.6778e-02,  5.6850e-02],
          [ 1.1195e-01,  2.5837e-01,  2.0558e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  5.7963e-40],
          [-9.5866e-41,  1.4689e-40, -1.8639e-40],
          [ 4.6914e-40, -3.2652e-40,  8.8170e-41]],

         [[ 1.4516e-40,  2.2266e-40,  4.8261e-40],
          [ 1.7902e-40, -1.7321e-40, -4.4071e-42],
          [-4.4327e-40,  1.1509e-40,  3.8969e-41]],

         [[ 4.9484e-41, -3.1794e-40, -1.5093e-40],
          [-1.7485e-40,  4.0930e-40,  3.2654e-40],
          [-9.4647e-41, -2.1965e-40,  1.3506e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0105]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0061]], device='cuda:0')

Epoch: 119 | Batch_idx: 0 |  Loss: (0.1056) | Acc: (98.00%) (126/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1791) | Acc: (94.00%) (1330/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1641) | Acc: (94.00%) (2543/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1642) | Acc: (94.00%) (3758/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1656) | Acc: (94.00%) (4963/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1633) | Acc: (94.00%) (6177/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1658) | Acc: (94.00%) (7389/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1664) | Acc: (94.00%) (8594/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1678) | Acc: (94.00%) (9792/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1654) | Acc: (94.00%) (11015/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1654) | Acc: (94.00%) (12227/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1679) | Acc: (94.00%) (13420/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1685) | Acc: (94.00%) (14627/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1679) | Acc: (94.00%) (15837/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1676) | Acc: (94.00%) (17044/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1673) | Acc: (94.00%) (18252/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1673) | Acc: (94.00%) (19459/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1686) | Acc: (94.00%) (20660/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1691) | Acc: (94.00%) (21856/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1696) | Acc: (94.00%) (23056/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1684) | Acc: (94.00%) (24274/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1675) | Acc: (94.00%) (25486/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1669) | Acc: (94.00%) (26700/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1675) | Acc: (94.00%) (27895/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1668) | Acc: (94.00%) (29100/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1670) | Acc: (94.00%) (30305/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1660) | Acc: (94.00%) (31527/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1663) | Acc: (94.00%) (32736/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1662) | Acc: (94.00%) (33948/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1669) | Acc: (94.00%) (35141/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1668) | Acc: (94.00%) (36355/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1665) | Acc: (94.00%) (37572/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1663) | Acc: (94.00%) (38772/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1653) | Acc: (94.00%) (39996/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1653) | Acc: (94.00%) (41208/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1649) | Acc: (94.00%) (42419/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1647) | Acc: (94.00%) (43629/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1652) | Acc: (94.00%) (44827/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1646) | Acc: (94.00%) (46057/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1643) | Acc: (94.00%) (47225/50000)
# TEST : Loss: (0.2923) | Acc: (90.00%) (9040/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9980e-01, -2.1016e-01,  4.1178e-02],
          [-6.1208e-02,  3.4688e-01,  2.3131e-01],
          [ 1.0797e-01,  5.1011e-02, -6.1915e-02]],

         [[-1.9919e-01,  2.2814e-01,  2.0574e-01],
          [ 4.1278e-02,  4.1079e-01,  2.3411e-01],
          [ 2.1131e-01, -1.3332e-02,  1.0312e-01]],

         [[-2.0506e-01, -6.1091e-02, -7.2876e-02],
          [-2.7932e-01, -1.0652e-01, -1.0513e-01],
          [-2.0852e-01, -1.2870e-01, -1.7721e-01]]],


        [[[-2.7321e-40, -1.3853e-40,  4.6606e-40],
          [-1.1442e-40,  4.5482e-40, -4.0312e-40],
          [ 3.1914e-40, -1.8821e-40, -6.1330e-40]],

         [[-3.1245e-40,  2.5694e-40,  6.2887e-41],
          [-2.3690e-40, -5.5337e-40, -2.1114e-40],
          [ 1.1090e-40, -1.0003e-40, -1.1278e-40]],

         [[ 2.2785e-40,  2.8323e-40,  1.3540e-40],
          [-2.6322e-40,  2.4214e-41,  1.6641e-40],
          [-1.4241e-40, -2.4960e-40,  4.0363e-40]]],


        [[[ 4.4233e-02,  1.0894e-01, -5.0338e-02],
          [ 3.8455e-02,  1.9669e-01, -8.7717e-02],
          [ 1.4486e-01,  3.2537e-01,  3.3539e-01]],

         [[-1.9381e-01, -7.5194e-02, -1.5571e-01],
          [-3.6700e-01, -3.4175e-01, -2.7765e-01],
          [-2.5179e-01, -4.0523e-01,  4.3712e-02]],

         [[ 2.4558e-01,  1.3223e-01,  1.9906e-01],
          [ 2.0532e-01,  1.1453e-01,  3.4431e-02],
          [ 6.2665e-02,  9.5237e-02,  2.7235e-02]]],


        ...,


        [[[ 2.0903e-01,  3.7809e-02,  7.1735e-02],
          [ 1.4365e-01, -2.3200e-01, -6.9874e-02],
          [ 2.1550e-02, -1.1338e-01, -5.6366e-02]],

         [[-9.5841e-02, -6.8141e-02,  2.6923e-02],
          [-1.4653e-01, -2.5645e-01,  1.3967e-02],
          [-1.4889e-03,  1.3173e-01,  1.9815e-01]],

         [[-1.0561e-01, -1.2700e-01,  9.6071e-02],
          [-8.2465e-02, -2.2108e-01, -1.6916e-01],
          [-3.2292e-02, -7.4538e-02, -6.3942e-02]]],


        [[[ 1.3090e-01,  2.2565e-01,  2.9565e-01],
          [ 1.4508e-01,  1.5184e-01,  9.0337e-03],
          [-2.5103e-01, -1.7054e-01, -7.5368e-02]],

         [[ 7.2392e-02,  5.3178e-02, -1.2400e-01],
          [ 2.2251e-02, -9.2933e-02, -3.2094e-01],
          [-3.1872e-02,  8.0933e-02, -4.7970e-02]],

         [[-2.6050e-01, -1.1026e-01, -1.9622e-01],
          [-1.4852e-01,  5.6211e-02,  5.6244e-02],
          [ 1.1081e-01,  2.5588e-01,  2.0345e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  2.9938e-40],
          [-5.1625e-40,  6.7585e-42,  3.7412e-40],
          [ 3.2901e-40, -4.6257e-41, -5.1959e-41]],

         [[ 4.2542e-40, -1.9773e-40,  4.8261e-40],
          [ 3.8896e-41, -3.1334e-40, -2.8467e-40],
          [-1.6302e-40,  5.3547e-40,  1.7910e-40]],

         [[-2.3077e-40, -3.7677e-41, -4.3119e-40],
          [ 1.0541e-40,  5.4943e-40, -9.3842e-41],
          [ 1.8561e-40,  2.0074e-40, -5.0713e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0100]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0137]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1818) | Acc: (91.00%) (117/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1760) | Acc: (94.00%) (1326/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1744) | Acc: (94.00%) (2527/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1962) | Acc: (93.00%) (3704/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.2101) | Acc: (92.00%) (4874/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.2234) | Acc: (92.00%) (6039/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.2275) | Acc: (92.00%) (7221/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.2276) | Acc: (92.00%) (8399/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.2303) | Acc: (92.00%) (9564/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.2303) | Acc: (92.00%) (10738/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.2274) | Acc: (92.00%) (11926/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.2305) | Acc: (92.00%) (13096/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.2350) | Acc: (92.00%) (14251/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.2372) | Acc: (91.00%) (15417/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.2373) | Acc: (91.00%) (16588/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.2381) | Acc: (91.00%) (17754/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.2386) | Acc: (91.00%) (18925/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.2377) | Acc: (91.00%) (20116/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.2375) | Acc: (91.00%) (21304/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.2380) | Acc: (91.00%) (22476/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.2371) | Acc: (91.00%) (23660/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.2376) | Acc: (91.00%) (24833/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.2393) | Acc: (91.00%) (25994/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.2407) | Acc: (91.00%) (27157/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.2410) | Acc: (91.00%) (28331/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.2413) | Acc: (91.00%) (29495/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.2415) | Acc: (91.00%) (30663/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.2419) | Acc: (91.00%) (31814/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.2427) | Acc: (91.00%) (32982/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.2424) | Acc: (91.00%) (34165/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.2427) | Acc: (91.00%) (35341/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.2424) | Acc: (91.00%) (36529/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.2433) | Acc: (91.00%) (37686/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.2433) | Acc: (91.00%) (38855/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.2431) | Acc: (91.00%) (40031/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.2428) | Acc: (91.00%) (41204/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.2419) | Acc: (91.00%) (42385/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.2421) | Acc: (91.00%) (43552/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.2411) | Acc: (91.00%) (44749/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.2409) | Acc: (91.00%) (45890/50000)
# TEST : Loss: (0.3396) | Acc: (89.00%) (8905/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0332e-01, -2.2530e-01,  2.0934e-02],
          [-5.3755e-02,  3.4433e-01,  2.2841e-01],
          [ 1.2311e-01,  5.4041e-02, -5.9330e-02]],

         [[-2.0927e-01,  2.0960e-01,  1.8627e-01],
          [ 3.9650e-02,  4.0171e-01,  2.2518e-01],
          [ 2.1664e-01, -1.5284e-02,  1.0084e-01]],

         [[-2.2066e-01, -8.2254e-02, -9.2608e-02],
          [-2.8543e-01, -1.2233e-01, -1.1810e-01],
          [-2.0780e-01, -1.3901e-01, -1.8345e-01]]],


        [[[ 1.4584e-40, -1.3860e-40, -9.2496e-41],
          [ 1.6496e-40,  1.7560e-40, -2.6361e-40],
          [ 1.7961e-40,  9.1192e-41, -4.7382e-40]],

         [[-3.1262e-40, -2.2391e-41,  3.4234e-40],
          [-2.3707e-40, -2.7421e-40, -7.1514e-41],
          [-2.8714e-41, -1.0012e-40,  2.6915e-41]],

         [[ 3.6777e-40,  3.8480e-42,  5.5473e-40],
          [-2.6339e-40, -1.1556e-40, -3.9257e-40],
          [ 1.3697e-40, -2.4975e-40, -1.5529e-40]]],


        [[[ 3.3406e-02,  1.0340e-01, -5.4321e-02],
          [ 2.9154e-02,  1.9219e-01, -8.8790e-02],
          [ 1.3664e-01,  3.2029e-01,  3.3928e-01]],

         [[-2.0132e-01, -8.0917e-02, -1.5958e-01],
          [-3.7750e-01, -3.4923e-01, -2.7801e-01],
          [-2.5804e-01, -4.0876e-01,  5.1803e-02]],

         [[ 2.4437e-01,  1.3454e-01,  2.0323e-01],
          [ 2.0434e-01,  1.1809e-01,  4.2718e-02],
          [ 6.7186e-02,  9.8096e-02,  3.5814e-02]]],


        ...,


        [[[ 2.1776e-01,  5.0977e-02,  7.4538e-02],
          [ 1.5493e-01, -2.2301e-01, -5.9788e-02],
          [ 5.3963e-02, -8.6854e-02, -2.7642e-02]],

         [[-9.1661e-02, -5.5758e-02,  2.9715e-02],
          [-1.3864e-01, -2.4470e-01,  2.8761e-02],
          [ 1.8712e-02,  1.4771e-01,  2.2288e-01]],

         [[-1.1574e-01, -1.2880e-01,  8.0650e-02],
          [-9.2300e-02, -2.1981e-01, -1.6427e-01],
          [-3.4304e-02, -7.0422e-02, -4.8881e-02]]],


        [[[ 1.2624e-01,  2.2697e-01,  2.9833e-01],
          [ 1.5127e-01,  1.5317e-01,  1.3103e-02],
          [-2.4426e-01, -1.6514e-01, -6.2879e-02]],

         [[ 6.1414e-02,  4.8832e-02, -1.2750e-01],
          [ 2.4333e-02, -9.3148e-02, -3.1602e-01],
          [-2.7486e-02,  8.7058e-02, -3.2753e-02]],

         [[-2.6657e-01, -1.1027e-01, -1.9652e-01],
          [-1.4617e-01,  6.1406e-02,  6.5260e-02],
          [ 1.1457e-01,  2.7091e-01,  2.2515e-01]]],


        [[[-3.2265e-41,  5.6512e-41, -2.6114e-40],
          [-3.7612e-40, -1.3337e-40,  5.1425e-40],
          [-9.1376e-41,  2.3400e-40, -1.9209e-40]],

         [[ 2.8529e-40, -4.7799e-40,  6.2223e-41],
          [-1.0123e-40, -1.7321e-40, -2.8467e-40],
          [ 2.5737e-40,  3.9534e-40,  1.7910e-40]],

         [[-2.3077e-40,  2.4258e-40, -2.9107e-40],
          [ 2.4554e-40,  1.2904e-40, -3.7410e-40],
          [ 3.2574e-40,  4.8100e-40, -1.4520e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0057,  0.0158,  0.0225],
          [ 0.0025,  0.0119,  0.0135],
          [ 0.0005,  0.0034, -0.0014]],

         [[ 0.0098,  0.0185,  0.0226],
          [ 0.0076,  0.0135,  0.0124],
          [ 0.0069,  0.0066,  0.0008]],

         [[ 0.0137,  0.0206,  0.0244],
          [ 0.0126,  0.0165,  0.0162],
          [ 0.0114,  0.0104,  0.0047]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0127, -0.0056, -0.0075],
          [-0.0004,  0.0097,  0.0175],
          [ 0.0186,  0.0311,  0.0418]],

         [[-0.0270, -0.0198, -0.0180],
          [-0.0151, -0.0050,  0.0047],
          [ 0.0067,  0.0154,  0.0249]],

         [[-0.0464, -0.0388, -0.0366],
          [-0.0334, -0.0252, -0.0167],
          [-0.0107, -0.0061,  0.0018]]],


        ...,


        [[[-0.0036, -0.0044, -0.0097],
          [-0.0064, -0.0067, -0.0133],
          [-0.0088, -0.0102, -0.0175]],

         [[-0.0030, -0.0034, -0.0074],
          [-0.0048, -0.0046, -0.0102],
          [-0.0058, -0.0068, -0.0138]],

         [[-0.0004, -0.0006, -0.0034],
          [-0.0017, -0.0016, -0.0058],
          [-0.0020, -0.0029, -0.0086]]],


        [[[ 0.0083,  0.0073,  0.0109],
          [ 0.0099,  0.0067,  0.0099],
          [ 0.0156,  0.0107,  0.0141]],

         [[ 0.0071,  0.0039,  0.0071],
          [ 0.0095,  0.0047,  0.0068],
          [ 0.0150,  0.0089,  0.0108]],

         [[ 0.0086,  0.0049,  0.0074],
          [ 0.0100,  0.0046,  0.0060],
          [ 0.0140,  0.0075,  0.0087]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0081]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 121 | Batch_idx: 0 |  Loss: (0.1415) | Acc: (96.00%) (123/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.2194) | Acc: (91.00%) (1295/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.2042) | Acc: (92.00%) (2484/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.2095) | Acc: (92.00%) (3662/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1975) | Acc: (92.00%) (4874/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1969) | Acc: (92.00%) (6071/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1954) | Acc: (93.00%) (7270/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1952) | Acc: (93.00%) (8464/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1914) | Acc: (93.00%) (9675/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1922) | Acc: (93.00%) (10871/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1937) | Acc: (93.00%) (12061/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1959) | Acc: (93.00%) (13239/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1990) | Acc: (93.00%) (14411/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.2000) | Acc: (93.00%) (15605/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.2012) | Acc: (92.00%) (16784/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.2031) | Acc: (92.00%) (17963/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.2027) | Acc: (92.00%) (19152/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.2032) | Acc: (92.00%) (20336/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.2037) | Acc: (92.00%) (21527/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.2014) | Acc: (93.00%) (22738/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.2024) | Acc: (93.00%) (23931/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.2026) | Acc: (93.00%) (25123/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.2029) | Acc: (93.00%) (26315/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.2035) | Acc: (92.00%) (27492/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.2031) | Acc: (93.00%) (28692/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.2042) | Acc: (92.00%) (29874/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.2043) | Acc: (92.00%) (31060/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.2041) | Acc: (92.00%) (32255/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.2049) | Acc: (92.00%) (33441/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.2046) | Acc: (92.00%) (34629/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.2044) | Acc: (92.00%) (35820/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.2048) | Acc: (92.00%) (37002/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.2055) | Acc: (92.00%) (38195/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.2059) | Acc: (92.00%) (39377/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.2056) | Acc: (92.00%) (40564/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.2049) | Acc: (92.00%) (41760/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.2051) | Acc: (92.00%) (42953/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.2053) | Acc: (92.00%) (44136/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.2053) | Acc: (92.00%) (45325/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.2052) | Acc: (92.00%) (46477/50000)
# TEST : Loss: (0.3263) | Acc: (89.00%) (8965/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.1020e-01, -2.2929e-01,  1.5329e-02],
          [-5.7083e-02,  3.4726e-01,  2.3112e-01],
          [ 1.1905e-01,  6.2023e-02, -5.1789e-02]],

         [[-2.1400e-01,  2.0728e-01,  1.8615e-01],
          [ 3.9959e-02,  4.0681e-01,  2.3123e-01],
          [ 2.1560e-01, -5.8884e-03,  1.0952e-01]],

         [[-2.1613e-01, -7.5710e-02, -8.5566e-02],
          [-2.8523e-01, -1.1858e-01, -1.1094e-01],
          [-2.1412e-01, -1.3712e-01, -1.7538e-01]]],


        [[[ 4.2551e-40,  1.1351e-42, -5.1192e-40],
          [ 3.0483e-40, -2.4378e-40,  1.5569e-40],
          [-9.9889e-41,  2.3107e-40,  8.5353e-41]],

         [[-3.3148e-41, -3.0202e-40,  3.4248e-40],
          [ 4.2385e-41,  2.8491e-40,  2.0808e-40],
          [-1.6851e-40,  3.9634e-41,  1.6676e-40]],

         [[ 8.8310e-41, -2.7582e-40,  4.1518e-40],
          [ 1.6111e-41, -1.1562e-40, -5.3258e-40],
          [ 2.7685e-40,  2.9776e-41, -5.7489e-40]]],


        [[[ 3.6895e-02,  1.0159e-01, -5.5853e-02],
          [ 3.3081e-02,  1.9281e-01, -8.9583e-02],
          [ 1.4545e-01,  3.2377e-01,  3.4295e-01]],

         [[-1.9940e-01, -8.4975e-02, -1.6338e-01],
          [-3.7611e-01, -3.5526e-01, -2.8541e-01],
          [-2.5303e-01, -4.1252e-01,  4.7922e-02]],

         [[ 2.4626e-01,  1.3047e-01,  1.9449e-01],
          [ 2.0454e-01,  1.1326e-01,  3.1177e-02],
          [ 6.8948e-02,  9.2910e-02,  2.7882e-02]]],


        ...,


        [[[ 2.1057e-01,  4.6851e-02,  7.3779e-02],
          [ 1.5276e-01, -2.3547e-01, -6.9877e-02],
          [ 4.6036e-02, -1.0278e-01, -4.4319e-02]],

         [[-1.0117e-01, -6.6678e-02,  2.1735e-02],
          [-1.4533e-01, -2.6899e-01,  2.9784e-03],
          [ 7.1737e-03,  1.2709e-01,  1.9945e-01]],

         [[-1.1222e-01, -1.2743e-01,  8.0504e-02],
          [-8.7224e-02, -2.3476e-01, -1.6924e-01],
          [-3.8916e-02, -8.3068e-02, -5.8312e-02]]],


        [[[ 1.3452e-01,  2.3058e-01,  3.0435e-01],
          [ 1.5834e-01,  1.5895e-01,  2.1469e-02],
          [-2.3534e-01, -1.5888e-01, -6.8095e-02]],

         [[ 6.2876e-02,  4.5050e-02, -1.2672e-01],
          [ 2.7081e-02, -9.3569e-02, -3.1319e-01],
          [-2.2040e-02,  8.9314e-02, -4.0308e-02]],

         [[-2.6324e-01, -1.1587e-01, -1.9697e-01],
          [-1.4496e-01,  6.0421e-02,  7.0853e-02],
          [ 1.1806e-01,  2.7652e-01,  2.2255e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -5.4140e-40],
          [ 1.8440e-40, -1.3337e-40,  9.3867e-41],
          [-3.7163e-40,  2.3400e-40, -1.9209e-40]],

         [[-1.3510e-40, -3.3786e-40, -3.5816e-40],
          [-1.0123e-40,  1.0705e-40, -4.4071e-42],
          [ 3.9750e-40, -1.6517e-40,  3.8970e-41]],

         [[ 4.9484e-41,  2.4258e-40,  1.2932e-40],
          [ 1.0541e-40, -4.3147e-40, -2.3397e-40],
          [ 1.8561e-40,  3.4087e-40, -1.4520e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0219,  0.0210,  0.0194],
          [ 0.0094,  0.0131,  0.0171],
          [ 0.0059,  0.0119,  0.0230]],

         [[ 0.0194,  0.0151,  0.0124],
          [ 0.0049,  0.0058,  0.0077],
          [ 0.0007,  0.0049,  0.0120]],

         [[ 0.0145,  0.0090,  0.0059],
          [ 0.0025,  0.0023,  0.0032],
          [-0.0024, -0.0005,  0.0065]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0715,  0.0859,  0.0984],
          [ 0.1175,  0.1065,  0.0939],
          [ 0.1173,  0.1167,  0.0907]],

         [[ 0.0579,  0.0652,  0.0827],
          [ 0.1090,  0.0904,  0.0809],
          [ 0.1092,  0.1036,  0.0762]],

         [[ 0.0538,  0.0600,  0.0727],
          [ 0.1043,  0.0843,  0.0706],
          [ 0.0981,  0.0877,  0.0556]]],


        ...,


        [[[ 0.0070,  0.0059,  0.0031],
          [ 0.0025,  0.0024, -0.0009],
          [-0.0000, -0.0006, -0.0035]],

         [[ 0.0050,  0.0046,  0.0016],
          [ 0.0000,  0.0010, -0.0019],
          [-0.0024, -0.0019, -0.0048]],

         [[ 0.0039,  0.0026, -0.0011],
          [-0.0001,  0.0003, -0.0032],
          [-0.0025, -0.0023, -0.0051]]],


        [[[ 0.0063,  0.0049,  0.0160],
          [ 0.0069,  0.0104,  0.0180],
          [ 0.0085,  0.0098,  0.0134]],

         [[ 0.0022, -0.0004,  0.0079],
          [-0.0004,  0.0018,  0.0071],
          [-0.0013, -0.0006,  0.0017]],

         [[-0.0006, -0.0026,  0.0054],
          [-0.0028, -0.0015,  0.0032],
          [-0.0039, -0.0041, -0.0020]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0081]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 122 | Batch_idx: 0 |  Loss: (0.1068) | Acc: (96.00%) (124/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1801) | Acc: (93.00%) (1321/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.2168) | Acc: (92.00%) (2484/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.2159) | Acc: (92.00%) (3664/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.2166) | Acc: (92.00%) (4843/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.2240) | Acc: (92.00%) (6011/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.2261) | Acc: (91.00%) (7179/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.2256) | Acc: (91.00%) (8355/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.2209) | Acc: (92.00%) (9551/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.2206) | Acc: (92.00%) (10729/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.2180) | Acc: (92.00%) (11927/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.2181) | Acc: (92.00%) (13098/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.2157) | Acc: (92.00%) (14295/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.2146) | Acc: (92.00%) (15491/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.2154) | Acc: (92.00%) (16668/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.2142) | Acc: (92.00%) (17852/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.2140) | Acc: (92.00%) (19042/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.2116) | Acc: (92.00%) (20245/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.2092) | Acc: (92.00%) (21450/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.2074) | Acc: (92.00%) (22650/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.2069) | Acc: (92.00%) (23836/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.2069) | Acc: (92.00%) (25028/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.2056) | Acc: (92.00%) (26229/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.2042) | Acc: (92.00%) (27432/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.2049) | Acc: (92.00%) (28613/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.2042) | Acc: (92.00%) (29813/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.2031) | Acc: (92.00%) (31010/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.2027) | Acc: (92.00%) (32205/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.2018) | Acc: (92.00%) (33407/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.2006) | Acc: (92.00%) (34615/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1997) | Acc: (92.00%) (35824/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1988) | Acc: (93.00%) (37030/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1976) | Acc: (93.00%) (38244/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1964) | Acc: (93.00%) (39455/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1957) | Acc: (93.00%) (40655/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1947) | Acc: (93.00%) (41868/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1943) | Acc: (93.00%) (43071/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1933) | Acc: (93.00%) (44283/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1937) | Acc: (93.00%) (45477/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1936) | Acc: (93.00%) (46624/50000)
# TEST : Loss: (0.3238) | Acc: (89.00%) (8955/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.1018e-01, -2.2981e-01,  1.3342e-02],
          [-5.6192e-02,  3.4537e-01,  2.2850e-01],
          [ 1.1948e-01,  6.1489e-02, -5.3367e-02]],

         [[-2.1622e-01,  2.0310e-01,  1.8161e-01],
          [ 3.8400e-02,  4.0274e-01,  2.2688e-01],
          [ 2.1347e-01, -8.4065e-03,  1.0546e-01]],

         [[-2.1836e-01, -7.8642e-02, -8.8719e-02],
          [-2.8564e-01, -1.2057e-01, -1.1352e-01],
          [-2.1473e-01, -1.3864e-01, -1.7753e-01]]],


        [[[ 2.8582e-40,  1.4100e-40, -3.7231e-40],
          [ 1.6509e-40, -3.8376e-40,  4.3549e-40],
          [-2.3980e-40,  9.1320e-41,  5.0508e-40]],

         [[ 2.4658e-40, -3.0213e-40,  6.2889e-41],
          [ 3.2210e-40,  5.6476e-40,  2.0817e-40],
          [-1.6856e-40,  1.7950e-40,  1.6681e-40]],

         [[-3.3128e-40, -2.7593e-40, -1.4415e-40],
          [ 2.9585e-40,  2.4210e-41, -1.1315e-40],
          [ 1.3709e-40,  3.0954e-40, -4.3518e-40]]],


        [[[ 3.5147e-02,  9.9123e-02, -5.9174e-02],
          [ 2.9482e-02,  1.8979e-01, -9.2452e-02],
          [ 1.4258e-01,  3.2013e-01,  3.3932e-01]],

         [[-2.0097e-01, -8.7415e-02, -1.6735e-01],
          [-3.7957e-01, -3.5815e-01, -2.8905e-01],
          [-2.5586e-01, -4.1593e-01,  4.3650e-02]],

         [[ 2.4327e-01,  1.2698e-01,  1.8953e-01],
          [ 1.9921e-01,  1.0864e-01,  2.6423e-02],
          [ 6.4470e-02,  8.7553e-02,  2.2953e-02]]],


        ...,


        [[[ 2.0595e-01,  4.3772e-02,  7.1502e-02],
          [ 1.4987e-01, -2.3509e-01, -7.0710e-02],
          [ 4.4944e-02, -1.0282e-01, -4.4188e-02]],

         [[-1.0162e-01, -6.7350e-02,  2.1737e-02],
          [-1.4358e-01, -2.6571e-01,  2.8810e-03],
          [ 7.2268e-03,  1.2516e-01,  1.9809e-01]],

         [[-1.1200e-01, -1.2623e-01,  8.0500e-02],
          [-8.5137e-02, -2.2616e-01, -1.6489e-01],
          [-3.7758e-02, -8.1280e-02, -5.6086e-02]]],


        [[[ 1.3736e-01,  2.3269e-01,  3.0343e-01],
          [ 1.5950e-01,  1.5964e-01,  2.1138e-02],
          [-2.3154e-01, -1.5547e-01, -6.6528e-02]],

         [[ 6.7110e-02,  4.9406e-02, -1.2276e-01],
          [ 3.0297e-02, -8.9863e-02, -3.0946e-01],
          [-1.8472e-02,  9.2000e-02, -3.7697e-02]],

         [[-2.5587e-01, -1.1005e-01, -1.9183e-01],
          [-1.3963e-01,  6.3762e-02,  7.2833e-02],
          [ 1.2170e-01,  2.7890e-01,  2.2448e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -2.6114e-40],
          [ 6.0478e-40,  6.7571e-42, -4.6665e-40],
          [-2.3150e-40, -4.6257e-41, -5.1959e-41]],

         [[-4.1536e-40,  8.2529e-41, -3.5816e-40],
          [ 3.8896e-41,  2.4718e-40,  2.7585e-40],
          [ 1.1724e-40, -5.8556e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.7677e-41,  4.0958e-40],
          [-1.7484e-40, -5.7160e-40,  1.8641e-40],
          [-9.4647e-41, -7.9518e-41, -5.0727e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0234]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0487]], device='cuda:0')

Epoch: 123 | Batch_idx: 0 |  Loss: (0.1421) | Acc: (94.00%) (121/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1935) | Acc: (93.00%) (1314/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1851) | Acc: (93.00%) (2517/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1770) | Acc: (94.00%) (3732/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1776) | Acc: (93.00%) (4933/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1811) | Acc: (93.00%) (6123/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1831) | Acc: (93.00%) (7326/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1853) | Acc: (93.00%) (8511/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1816) | Acc: (93.00%) (9724/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1816) | Acc: (93.00%) (10917/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1822) | Acc: (93.00%) (12116/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1799) | Acc: (93.00%) (13327/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1798) | Acc: (93.00%) (14536/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1788) | Acc: (93.00%) (15744/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1796) | Acc: (93.00%) (16935/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1811) | Acc: (93.00%) (18125/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1804) | Acc: (93.00%) (19333/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1818) | Acc: (93.00%) (20527/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1817) | Acc: (93.00%) (21726/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1808) | Acc: (93.00%) (22935/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1799) | Acc: (93.00%) (24147/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1784) | Acc: (93.00%) (25367/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1787) | Acc: (93.00%) (26571/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1785) | Acc: (93.00%) (27776/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1773) | Acc: (93.00%) (28992/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1777) | Acc: (93.00%) (30189/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1766) | Acc: (93.00%) (31401/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1764) | Acc: (93.00%) (32606/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1757) | Acc: (94.00%) (33818/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1771) | Acc: (93.00%) (34998/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1772) | Acc: (93.00%) (36203/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1778) | Acc: (93.00%) (37404/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1777) | Acc: (93.00%) (38601/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1772) | Acc: (93.00%) (39809/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1773) | Acc: (93.00%) (41015/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1763) | Acc: (94.00%) (42234/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1764) | Acc: (93.00%) (43434/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1770) | Acc: (93.00%) (44618/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1773) | Acc: (93.00%) (45818/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1773) | Acc: (93.00%) (46967/50000)
# TEST : Loss: (0.3041) | Acc: (90.00%) (9027/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0933e-01, -2.2880e-01,  1.3281e-02],
          [-5.5951e-02,  3.4377e-01,  2.2740e-01],
          [ 1.1896e-01,  6.1204e-02, -5.3112e-02]],

         [[-2.1531e-01,  2.0219e-01,  1.8078e-01],
          [ 3.8231e-02,  4.0088e-01,  2.2582e-01],
          [ 2.1253e-01, -8.3677e-03,  1.0496e-01]],

         [[-2.1736e-01, -7.8283e-02, -8.8323e-02],
          [-2.8434e-01, -1.2003e-01, -1.1302e-01],
          [-2.1376e-01, -1.3801e-01, -1.7674e-01]]],


        [[[-1.3381e-40,  1.4106e-40,  1.8714e-40],
          [-1.1468e-40, -1.0405e-40,  2.9573e-40],
          [-9.9995e-41, -1.8847e-40,  3.6530e-40]],

         [[ 2.4666e-40, -2.2352e-41, -2.1695e-40],
          [ 3.2221e-40,  2.8512e-40, -7.1605e-41],
          [-2.8700e-41,  1.7954e-40,  2.6932e-41]],

         [[-4.7130e-40,  3.8648e-42, -5.6396e-40],
          [ 2.9596e-40,  1.6415e-40,  4.4651e-40],
          [-1.4270e-40,  3.0966e-40,  1.2446e-40]]],


        [[[ 3.5079e-02,  9.8931e-02, -5.9055e-02],
          [ 2.9425e-02,  1.8942e-01, -9.2267e-02],
          [ 1.4230e-01,  3.1950e-01,  3.3863e-01]],

         [[-2.0056e-01, -8.7233e-02, -1.6700e-01],
          [-3.7876e-01, -3.5738e-01, -2.8842e-01],
          [-2.5531e-01, -4.1504e-01,  4.3555e-02]],

         [[ 2.4274e-01,  1.2670e-01,  1.8911e-01],
          [ 1.9877e-01,  1.0840e-01,  2.6362e-02],
          [ 6.4325e-02,  8.7354e-02,  2.2900e-02]]],


        ...,


        [[[ 2.0374e-01,  4.3291e-02,  7.0746e-02],
          [ 1.4813e-01, -2.3217e-01, -6.9869e-02],
          [ 4.4441e-02, -1.0159e-01, -4.3672e-02]],

         [[-1.0021e-01, -6.6355e-02,  2.1462e-02],
          [-1.4125e-01, -2.6069e-01,  2.8370e-03],
          [ 7.1286e-03,  1.2326e-01,  1.9542e-01]],

         [[-1.0977e-01, -1.2335e-01,  7.9157e-02],
          [-8.2714e-02, -2.1548e-01, -1.6103e-01],
          [-3.7045e-02, -7.9441e-02, -5.5115e-02]]],


        [[[ 1.3610e-01,  2.3045e-01,  3.0060e-01],
          [ 1.5810e-01,  1.5815e-01,  2.0949e-02],
          [-2.2959e-01, -1.5411e-01, -6.5950e-02]],

         [[ 6.6512e-02,  4.8961e-02, -1.2161e-01],
          [ 3.0024e-02, -8.9039e-02, -3.0657e-01],
          [-1.8308e-02,  9.1185e-02, -3.7355e-02]],

         [[-2.5346e-01, -1.0902e-01, -1.8991e-01],
          [-1.3828e-01,  6.3148e-02,  7.2089e-02],
          [ 1.2054e-01,  2.7632e-01,  2.2230e-01]]],


        [[[-3.2265e-41,  5.6512e-41,  2.9938e-40],
          [ 4.6465e-40,  1.4689e-40, -6.0678e-40],
          [ 1.8888e-40, -3.2652e-40,  8.8171e-41]],

         [[-2.7523e-40,  3.6279e-40,  6.2223e-41],
          [ 1.7903e-40,  1.0705e-40,  2.7585e-40],
          [-3.0315e-40, -4.4543e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.1794e-40,  2.6945e-40],
          [-3.1497e-40, -1.5122e-40,  4.6667e-40],
          [-2.3478e-40, -3.5978e-40,  1.3506e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0270]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0187]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1317) | Acc: (96.00%) (123/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1766) | Acc: (93.00%) (1323/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1997) | Acc: (92.00%) (2497/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1968) | Acc: (93.00%) (3691/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.2111) | Acc: (92.00%) (4853/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.2167) | Acc: (92.00%) (6024/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.2302) | Acc: (91.00%) (7183/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.2359) | Acc: (91.00%) (8339/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.2376) | Acc: (91.00%) (9500/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.2378) | Acc: (91.00%) (10681/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.2389) | Acc: (91.00%) (11843/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.2405) | Acc: (91.00%) (13010/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.2416) | Acc: (91.00%) (14181/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.2425) | Acc: (91.00%) (15349/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.2435) | Acc: (91.00%) (16521/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.2440) | Acc: (91.00%) (17697/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.2443) | Acc: (91.00%) (18870/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.2441) | Acc: (91.00%) (20048/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.2434) | Acc: (91.00%) (21230/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.2417) | Acc: (91.00%) (22416/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.2404) | Acc: (91.00%) (23604/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.2417) | Acc: (91.00%) (24766/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.2413) | Acc: (91.00%) (25952/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.2417) | Acc: (91.00%) (27118/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.2413) | Acc: (91.00%) (28299/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.2418) | Acc: (91.00%) (29468/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.2410) | Acc: (91.00%) (30650/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.2412) | Acc: (91.00%) (31824/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.2400) | Acc: (91.00%) (32997/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.2387) | Acc: (91.00%) (34192/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.2368) | Acc: (91.00%) (35390/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.2370) | Acc: (91.00%) (36564/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.2363) | Acc: (91.00%) (37750/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.2363) | Acc: (91.00%) (38919/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.2365) | Acc: (91.00%) (40094/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.2359) | Acc: (91.00%) (41283/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.2353) | Acc: (91.00%) (42468/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.2346) | Acc: (91.00%) (43662/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.2363) | Acc: (91.00%) (44820/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.2360) | Acc: (91.00%) (45957/50000)
# TEST : Loss: (0.4605) | Acc: (86.00%) (8682/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0242e-01, -2.1827e-01,  2.2725e-02],
          [-5.4184e-02,  3.4767e-01,  2.3299e-01],
          [ 1.1471e-01,  5.6090e-02, -6.4372e-02]],

         [[-2.0869e-01,  2.1301e-01,  1.9101e-01],
          [ 3.7311e-02,  4.0570e-01,  2.3244e-01],
          [ 2.1009e-01, -7.7705e-03,  9.5997e-02]],

         [[-2.1465e-01, -7.3961e-02, -7.8129e-02],
          [-2.8884e-01, -1.2224e-01, -1.0770e-01],
          [-2.1828e-01, -1.4299e-01, -1.8488e-01]]],


        [[[-4.1375e-40,  1.1463e-42,  6.0700e-40],
          [-2.5466e-40,  3.1577e-40, -1.2405e-40],
          [ 1.7984e-40, -3.2846e-40, -1.9447e-40]],

         [[-3.3163e-41,  2.5755e-40, -2.1703e-40],
          [ 4.2402e-41, -2.7463e-40, -2.1158e-40],
          [ 1.1124e-40,  3.9620e-41, -1.1304e-40]],

         [[-1.9149e-40,  2.8380e-40, -4.2415e-40],
          [ 1.6128e-41,  1.6419e-40,  5.8658e-40],
          [-2.8269e-40,  2.9804e-41,  5.4440e-40]]],


        [[[ 3.3389e-02,  9.7809e-02, -6.4451e-02],
          [ 2.4719e-02,  1.9398e-01, -9.2653e-02],
          [ 1.3994e-01,  3.2895e-01,  3.4805e-01]],

         [[-2.0428e-01, -9.1163e-02, -1.7387e-01],
          [-3.8546e-01, -3.5509e-01, -2.9087e-01],
          [-2.5605e-01, -4.0752e-01,  4.9822e-02]],

         [[ 2.3927e-01,  1.2505e-01,  1.8423e-01],
          [ 1.9487e-01,  1.1394e-01,  2.6448e-02],
          [ 6.9459e-02,  9.7859e-02,  2.8754e-02]]],


        ...,


        [[[ 1.9854e-01,  3.4204e-02,  7.4405e-02],
          [ 1.6450e-01, -2.2431e-01, -5.2184e-02],
          [ 7.3242e-02, -8.2232e-02, -3.6532e-02]],

         [[-1.1506e-01, -9.0822e-02,  1.4165e-02],
          [-1.3652e-01, -2.6859e-01,  7.9284e-03],
          [ 1.9884e-02,  1.2848e-01,  1.9217e-01]],

         [[-1.2286e-01, -1.5183e-01,  6.9052e-02],
          [-7.2369e-02, -2.2562e-01, -1.4966e-01],
          [-2.5643e-02, -7.5452e-02, -5.7766e-02]]],


        [[[ 1.0981e-01,  2.1685e-01,  2.9768e-01],
          [ 1.3671e-01,  1.4556e-01,  2.3640e-02],
          [-2.4502e-01, -1.6807e-01, -6.6064e-02]],

         [[ 4.6628e-02,  3.9298e-02, -1.1918e-01],
          [ 1.5688e-02, -9.4310e-02, -2.9638e-01],
          [-2.6246e-02,  8.4210e-02, -2.8533e-02]],

         [[-2.6121e-01, -1.0471e-01, -1.7226e-01],
          [-1.3651e-01,  7.7438e-02,  9.9875e-02],
          [ 1.3285e-01,  2.9493e-01,  2.5491e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  5.7964e-40],
          [-9.5863e-41,  1.4689e-40, -1.8639e-40],
          [ 4.6914e-40, -3.2652e-40,  8.8171e-41]],

         [[ 1.4516e-40,  2.2266e-40,  4.8261e-40],
          [ 1.7903e-40, -1.7321e-40, -4.4057e-42],
          [-4.4328e-40,  1.1509e-40,  3.8970e-41]],

         [[ 4.9483e-41, -3.1794e-40, -1.5094e-40],
          [-1.7484e-40,  4.0930e-40,  3.2654e-40],
          [-9.4647e-41, -2.1965e-40,  1.3506e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0195, -0.0231, -0.0277],
          [-0.0182, -0.0261, -0.0296],
          [-0.0252, -0.0351, -0.0346]],

         [[-0.0178, -0.0202, -0.0232],
          [-0.0159, -0.0221, -0.0236],
          [-0.0213, -0.0314, -0.0300]],

         [[-0.0244, -0.0271, -0.0254],
          [-0.0213, -0.0266, -0.0230],
          [-0.0238, -0.0325, -0.0281]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0348, -0.0179, -0.0042],
          [-0.0144, -0.0092, -0.0022],
          [ 0.0079, -0.0006, -0.0093]],

         [[-0.0127, -0.0023,  0.0021],
          [ 0.0147,  0.0130,  0.0146],
          [ 0.0318,  0.0220,  0.0100]],

         [[ 0.0189,  0.0239,  0.0234],
          [ 0.0461,  0.0408,  0.0372],
          [ 0.0555,  0.0414,  0.0313]]],


        ...,


        [[[ 0.0010,  0.0026,  0.0033],
          [-0.0008,  0.0014,  0.0035],
          [-0.0011,  0.0004,  0.0027]],

         [[-0.0005,  0.0016,  0.0026],
          [-0.0027, -0.0000,  0.0019],
          [-0.0036, -0.0017,  0.0006]],

         [[-0.0010,  0.0011,  0.0013],
          [-0.0032,  0.0003,  0.0017],
          [-0.0042, -0.0014,  0.0008]]],


        [[[ 0.0045,  0.0016, -0.0033],
          [ 0.0021, -0.0005, -0.0037],
          [-0.0048, -0.0023,  0.0013]],

         [[-0.0038, -0.0048, -0.0100],
          [-0.0072, -0.0085, -0.0116],
          [-0.0125, -0.0105, -0.0082]],

         [[-0.0145, -0.0145, -0.0182],
          [-0.0167, -0.0175, -0.0208],
          [-0.0206, -0.0200, -0.0192]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0244]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 125 | Batch_idx: 0 |  Loss: (0.1831) | Acc: (93.00%) (120/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1868) | Acc: (93.00%) (1310/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.2002) | Acc: (92.00%) (2496/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.2021) | Acc: (92.00%) (3689/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1965) | Acc: (93.00%) (4893/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1992) | Acc: (93.00%) (6077/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1984) | Acc: (93.00%) (7277/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1982) | Acc: (93.00%) (8474/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.2048) | Acc: (93.00%) (9646/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.2076) | Acc: (92.00%) (10827/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.2081) | Acc: (92.00%) (12022/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.2056) | Acc: (93.00%) (13220/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.2093) | Acc: (92.00%) (14386/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.2111) | Acc: (92.00%) (15562/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.2076) | Acc: (92.00%) (16766/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.2070) | Acc: (92.00%) (17956/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.2068) | Acc: (92.00%) (19146/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.2061) | Acc: (92.00%) (20342/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.2067) | Acc: (92.00%) (21520/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.2066) | Acc: (92.00%) (22707/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.2072) | Acc: (92.00%) (23890/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.2070) | Acc: (92.00%) (25079/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.2062) | Acc: (92.00%) (26270/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.2054) | Acc: (92.00%) (27471/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.2061) | Acc: (92.00%) (28645/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.2052) | Acc: (92.00%) (29839/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.2049) | Acc: (92.00%) (31023/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.2041) | Acc: (92.00%) (32220/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.2043) | Acc: (92.00%) (33401/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.2042) | Acc: (92.00%) (34584/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.2032) | Acc: (92.00%) (35787/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.2034) | Acc: (92.00%) (36978/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.2038) | Acc: (92.00%) (38160/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.2037) | Acc: (92.00%) (39355/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.2039) | Acc: (92.00%) (40550/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.2041) | Acc: (92.00%) (41737/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.2045) | Acc: (92.00%) (42923/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.2045) | Acc: (92.00%) (44104/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.2053) | Acc: (92.00%) (45286/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.2056) | Acc: (92.00%) (46426/50000)
# TEST : Loss: (0.3780) | Acc: (88.00%) (8874/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0639e-01, -2.2257e-01,  1.8770e-02],
          [-5.1848e-02,  3.5326e-01,  2.3204e-01],
          [ 1.2555e-01,  6.5144e-02, -6.6700e-02]],

         [[-2.1308e-01,  2.0632e-01,  1.8206e-01],
          [ 4.0057e-02,  4.1028e-01,  2.2625e-01],
          [ 2.2206e-01,  2.1974e-03,  9.1067e-02]],

         [[-2.1951e-01, -8.0702e-02, -8.6846e-02],
          [-2.8460e-01, -1.1766e-01, -1.1292e-01],
          [-2.0321e-01, -1.3272e-01, -1.8722e-01]]],


        [[[-2.7387e-40, -1.3883e-40,  4.6715e-40],
          [-1.1476e-40,  4.5583e-40, -4.0406e-40],
          [ 3.1984e-40, -1.8854e-40, -6.1449e-40]],

         [[-3.1313e-40,  2.5761e-40,  6.2858e-41],
          [-2.3755e-40, -5.5466e-40, -7.1646e-41],
          [ 1.1128e-40, -1.0037e-40, -1.1306e-40]],

         [[ 2.2844e-40,  2.8385e-40,  1.3573e-40],
          [-2.6384e-40,  2.4217e-41,  1.6672e-40],
          [-1.4276e-40, -2.5018e-40,  4.0449e-40]]],


        [[[ 5.1132e-02,  1.1649e-01, -4.5956e-02],
          [ 3.0519e-02,  1.9939e-01, -8.8711e-02],
          [ 1.3431e-01,  3.2307e-01,  3.4608e-01]],

         [[-1.8905e-01, -7.6863e-02, -1.5967e-01],
          [-3.8584e-01, -3.5797e-01, -2.9267e-01],
          [-2.6656e-01, -4.2001e-01,  4.5069e-02]],

         [[ 2.5179e-01,  1.3923e-01,  1.9451e-01],
          [ 1.9246e-01,  1.1224e-01,  2.1893e-02],
          [ 5.8023e-02,  8.5615e-02,  1.9449e-02]]],


        ...,


        [[[ 2.2441e-01,  5.9590e-02,  8.4661e-02],
          [ 1.7559e-01, -2.0705e-01, -3.9748e-02],
          [ 7.8883e-02, -7.2788e-02, -2.7141e-02]],

         [[-8.5433e-02, -6.3246e-02,  1.6246e-02],
          [-1.2424e-01, -2.4689e-01,  1.8645e-02],
          [ 2.4957e-02,  1.3852e-01,  2.0149e-01]],

         [[-1.1576e-01, -1.4033e-01,  4.7448e-02],
          [-9.0604e-02, -2.3024e-01, -1.5489e-01],
          [-4.4251e-02, -8.7779e-02, -6.1035e-02]]],


        [[[ 1.1442e-01,  2.1625e-01,  2.9157e-01],
          [ 1.4064e-01,  1.4518e-01,  1.6884e-02],
          [-2.5791e-01, -1.8673e-01, -8.2140e-02]],

         [[ 5.7578e-02,  3.9215e-02, -1.2587e-01],
          [ 2.1994e-02, -9.6361e-02, -3.0279e-01],
          [-3.4428e-02,  6.8978e-02, -3.9608e-02]],

         [[-2.5892e-01, -1.1415e-01, -1.9369e-01],
          [-1.3643e-01,  6.7882e-02,  8.2399e-02],
          [ 1.2269e-01,  2.8005e-01,  2.4005e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  2.9938e-40],
          [-5.1625e-40,  6.7571e-42,  3.7413e-40],
          [ 3.2901e-40, -4.6258e-41, -5.1959e-41]],

         [[ 4.2542e-40, -1.9773e-40,  4.8261e-40],
          [ 3.8896e-41, -3.1334e-40, -2.8467e-40],
          [-1.6302e-40,  5.3548e-40,  1.7910e-40]],

         [[-2.3078e-40, -3.7677e-41, -4.3119e-40],
          [ 1.0542e-40,  5.4943e-40, -9.3844e-41],
          [ 1.8561e-40,  2.0074e-40, -5.0727e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0039, -0.0033, -0.0077],
          [ 0.0065,  0.0040,  0.0074],
          [ 0.0024,  0.0157,  0.0170]],

         [[-0.0008, -0.0077, -0.0139],
          [ 0.0045,  0.0039,  0.0041],
          [ 0.0005,  0.0138,  0.0144]],

         [[ 0.0010, -0.0060, -0.0143],
          [ 0.0044,  0.0023, -0.0006],
          [-0.0011,  0.0111,  0.0097]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0514, -0.0632, -0.0640],
          [-0.0545, -0.0663, -0.0530],
          [-0.0544, -0.0580, -0.0489]],

         [[-0.0387, -0.0526, -0.0498],
          [-0.0431, -0.0585, -0.0422],
          [-0.0410, -0.0477, -0.0342]],

         [[-0.0280, -0.0446, -0.0430],
          [-0.0317, -0.0478, -0.0329],
          [-0.0269, -0.0337, -0.0231]]],


        ...,


        [[[-0.0022, -0.0046,  0.0055],
          [-0.0049, -0.0075,  0.0021],
          [-0.0071, -0.0091,  0.0004]],

         [[ 0.0023,  0.0010,  0.0108],
          [ 0.0013, -0.0019,  0.0070],
          [ 0.0006, -0.0027,  0.0040]],

         [[ 0.0022,  0.0017,  0.0098],
          [ 0.0017, -0.0009,  0.0068],
          [ 0.0019, -0.0016,  0.0034]]],


        [[[-0.0163, -0.0053,  0.0009],
          [-0.0229, -0.0133, -0.0097],
          [-0.0254, -0.0216, -0.0204]],

         [[-0.0045,  0.0000,  0.0043],
          [-0.0114, -0.0093, -0.0083],
          [-0.0165, -0.0168, -0.0197]],

         [[-0.0009,  0.0018,  0.0051],
          [-0.0063, -0.0043, -0.0037],
          [-0.0082, -0.0080, -0.0124]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0244]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1426) | Acc: (95.00%) (122/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1958) | Acc: (93.00%) (1322/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.2220) | Acc: (92.00%) (2489/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.2341) | Acc: (92.00%) (3659/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.2446) | Acc: (91.00%) (4804/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.2425) | Acc: (91.00%) (5986/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.2355) | Acc: (91.00%) (7174/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.2343) | Acc: (91.00%) (8358/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.2331) | Acc: (92.00%) (9544/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.2297) | Acc: (92.00%) (10744/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.2284) | Acc: (92.00%) (11927/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.2262) | Acc: (92.00%) (13110/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.2242) | Acc: (92.00%) (14301/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.2239) | Acc: (92.00%) (15478/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.2240) | Acc: (92.00%) (16651/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.2211) | Acc: (92.00%) (17854/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.2185) | Acc: (92.00%) (19056/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.2163) | Acc: (92.00%) (20253/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.2150) | Acc: (92.00%) (21445/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.2143) | Acc: (92.00%) (22629/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.2132) | Acc: (92.00%) (23828/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.2121) | Acc: (92.00%) (25031/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.2105) | Acc: (92.00%) (26230/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.2110) | Acc: (92.00%) (27415/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.2098) | Acc: (92.00%) (28613/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.2090) | Acc: (92.00%) (29812/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.2096) | Acc: (92.00%) (31000/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.2087) | Acc: (92.00%) (32197/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.2090) | Acc: (92.00%) (33384/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.2088) | Acc: (92.00%) (34572/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.2081) | Acc: (92.00%) (35768/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.2077) | Acc: (92.00%) (36961/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.2080) | Acc: (92.00%) (38142/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.2079) | Acc: (92.00%) (39331/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.2071) | Acc: (92.00%) (40529/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.2071) | Acc: (92.00%) (41720/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.2069) | Acc: (92.00%) (42915/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.2060) | Acc: (92.00%) (44111/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.2065) | Acc: (92.00%) (45284/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.2067) | Acc: (92.00%) (46422/50000)
# TEST : Loss: (0.3144) | Acc: (90.00%) (9019/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0830e-01, -2.2360e-01,  1.6791e-02],
          [-5.5013e-02,  3.4906e-01,  2.2791e-01],
          [ 1.2318e-01,  6.1411e-02, -7.0196e-02]],

         [[-2.1430e-01,  2.0481e-01,  1.8095e-01],
          [ 3.6885e-02,  4.0640e-01,  2.2327e-01],
          [ 2.2006e-01, -1.8728e-04,  8.8430e-02]],

         [[-2.2094e-01, -8.1193e-02, -8.6311e-02],
          [-2.8665e-01, -1.1936e-01, -1.1381e-01],
          [-2.0338e-01, -1.3418e-01, -1.8817e-01]]],


        [[[ 1.4610e-40, -1.3886e-40, -9.2766e-41],
          [ 1.6523e-40,  1.7588e-40, -2.6413e-40],
          [ 1.7989e-40,  9.1447e-41, -4.7456e-40]],

         [[-3.1319e-40, -2.2359e-41,  3.4286e-40],
          [-2.3761e-40, -2.7475e-40,  2.0838e-40],
          [-2.8690e-41, -1.0039e-40,  2.6937e-41]],

         [[ 3.6851e-40,  3.8760e-42,  5.5579e-40],
          [-2.6390e-40, -1.1579e-40, -3.9334e-40],
          [ 1.3723e-40, -2.5024e-40, -1.5554e-40]]],


        [[[ 5.0203e-02,  1.1645e-01, -4.4590e-02],
          [ 3.0340e-02,  2.0029e-01, -8.6230e-02],
          [ 1.3369e-01,  3.2379e-01,  3.4776e-01]],

         [[-1.8937e-01, -7.5961e-02, -1.5712e-01],
          [-3.8516e-01, -3.5510e-01, -2.8803e-01],
          [-2.6660e-01, -4.1719e-01,  4.8791e-02]],

         [[ 2.5121e-01,  1.4028e-01,  1.9655e-01],
          [ 1.9307e-01,  1.1518e-01,  2.6456e-02],
          [ 5.8688e-02,  8.8370e-02,  2.3683e-02]]],


        ...,


        [[[ 2.2408e-01,  6.0794e-02,  8.2648e-02],
          [ 1.7696e-01, -2.0176e-01, -3.9193e-02],
          [ 8.0638e-02, -7.0570e-02, -2.7488e-02]],

         [[-8.4498e-02, -6.2858e-02,  1.2430e-02],
          [-1.2106e-01, -2.4080e-01,  1.6569e-02],
          [ 2.5684e-02,  1.3696e-01,  1.9774e-01]],

         [[-1.1357e-01, -1.3762e-01,  4.3298e-02],
          [-8.6969e-02, -2.1647e-01, -1.5340e-01],
          [-4.3769e-02, -8.6756e-02, -6.1865e-02]]],


        [[[ 1.1646e-01,  2.1425e-01,  2.9041e-01],
          [ 1.4732e-01,  1.4949e-01,  2.2284e-02],
          [-2.4961e-01, -1.8094e-01, -7.5659e-02]],

         [[ 5.7859e-02,  3.7040e-02, -1.2560e-01],
          [ 2.7901e-02, -9.1697e-02, -2.9581e-01],
          [-2.8117e-02,  7.2364e-02, -3.3655e-02]],

         [[-2.5504e-01, -1.1316e-01, -1.9094e-01],
          [-1.2845e-01,  7.2531e-02,  8.7637e-02],
          [ 1.2786e-01,  2.8221e-01,  2.4422e-01]]],


        [[[-3.2265e-41,  5.6510e-41, -2.6114e-40],
          [-3.7612e-40, -1.3337e-40,  5.1426e-40],
          [-9.1376e-41,  2.3400e-40, -1.9209e-40]],

         [[ 2.8529e-40, -4.7799e-40,  6.2223e-41],
          [-1.0123e-40, -1.7321e-40, -2.8467e-40],
          [ 2.5737e-40,  3.9535e-40,  1.7910e-40]],

         [[-2.3078e-40,  2.4258e-40, -2.9107e-40],
          [ 2.4555e-40,  1.2904e-40, -3.7410e-40],
          [ 3.2574e-40,  4.8100e-40, -1.4520e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0485]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0376]], device='cuda:0')

Epoch: 127 | Batch_idx: 0 |  Loss: (0.3772) | Acc: (88.00%) (113/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.2040) | Acc: (92.00%) (1307/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.2148) | Acc: (92.00%) (2495/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1956) | Acc: (93.00%) (3701/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1875) | Acc: (93.00%) (4915/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1833) | Acc: (93.00%) (6123/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1829) | Acc: (93.00%) (7324/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1827) | Acc: (93.00%) (8524/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1825) | Acc: (93.00%) (9723/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1821) | Acc: (93.00%) (10923/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1782) | Acc: (93.00%) (12140/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1790) | Acc: (93.00%) (13337/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1785) | Acc: (93.00%) (14534/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1777) | Acc: (93.00%) (15749/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1767) | Acc: (93.00%) (16950/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1767) | Acc: (93.00%) (18149/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1761) | Acc: (93.00%) (19354/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1761) | Acc: (93.00%) (20555/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1747) | Acc: (93.00%) (21767/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1745) | Acc: (93.00%) (22970/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1756) | Acc: (93.00%) (24176/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1750) | Acc: (93.00%) (25385/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1744) | Acc: (94.00%) (26596/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1740) | Acc: (93.00%) (27792/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1741) | Acc: (93.00%) (28996/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1747) | Acc: (93.00%) (30184/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1741) | Acc: (93.00%) (31393/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1745) | Acc: (93.00%) (32593/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1749) | Acc: (93.00%) (33793/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1759) | Acc: (93.00%) (34982/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1770) | Acc: (93.00%) (36169/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1774) | Acc: (93.00%) (37366/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1768) | Acc: (93.00%) (38575/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1770) | Acc: (93.00%) (39769/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1770) | Acc: (93.00%) (40971/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1772) | Acc: (93.00%) (42171/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1775) | Acc: (93.00%) (43365/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1777) | Acc: (93.00%) (44570/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1770) | Acc: (93.00%) (45781/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1768) | Acc: (93.00%) (46943/50000)
# TEST : Loss: (0.3049) | Acc: (90.00%) (9026/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0745e-01, -2.2262e-01,  1.6714e-02],
          [-5.4771e-02,  3.4740e-01,  2.2677e-01],
          [ 1.2263e-01,  6.1121e-02, -6.9859e-02]],

         [[-2.1339e-01,  2.0389e-01,  1.8011e-01],
          [ 3.6721e-02,  4.0451e-01,  2.2220e-01],
          [ 2.1910e-01, -1.8642e-04,  8.8021e-02]],

         [[-2.1991e-01, -8.0818e-02, -8.5918e-02],
          [-2.8532e-01, -1.1881e-01, -1.1329e-01],
          [-2.0245e-01, -1.3357e-01, -1.8732e-01]]],


        [[[ 4.2619e-40,  1.1519e-42, -5.1288e-40],
          [ 3.0528e-40, -2.4419e-40,  1.5593e-40],
          [-1.0012e-40,  2.3151e-40,  8.5546e-41]],

         [[-3.3174e-41, -3.0243e-40,  3.4292e-40],
          [ 4.2395e-41,  2.8534e-40,  2.0841e-40],
          [-1.6872e-40,  3.9622e-41,  1.6698e-40]],

         [[ 8.8493e-41, -2.7620e-40,  4.1585e-40],
          [ 1.6116e-41, -1.1581e-40, -5.3344e-40],
          [ 2.7727e-40,  2.9796e-41, -5.7569e-40]]],


        [[[ 5.0097e-02,  1.1620e-01, -4.4494e-02],
          [ 3.0276e-02,  1.9987e-01, -8.6047e-02],
          [ 1.3341e-01,  3.2310e-01,  3.4701e-01]],

         [[-1.8893e-01, -7.5784e-02, -1.5675e-01],
          [-3.8424e-01, -3.5425e-01, -2.8734e-01],
          [-2.6597e-01, -4.1622e-01,  4.8678e-02]],

         [[ 2.5060e-01,  1.3994e-01,  1.9607e-01],
          [ 1.9259e-01,  1.1489e-01,  2.6390e-02],
          [ 5.8542e-02,  8.8152e-02,  2.3626e-02]]],


        ...,


        [[[ 2.2132e-01,  6.0028e-02,  8.1669e-02],
          [ 1.7469e-01, -1.9898e-01, -3.8688e-02],
          [ 7.9663e-02, -6.9660e-02, -2.7141e-02]],

         [[-8.3117e-02, -6.1739e-02,  1.2243e-02],
          [-1.1880e-01, -2.3543e-01,  1.6273e-02],
          [ 2.5286e-02,  1.3457e-01,  1.9464e-01]],

         [[-1.1092e-01, -1.3366e-01,  4.2410e-02],
          [-8.4229e-02, -2.0404e-01, -1.4908e-01],
          [-4.2847e-02, -8.4495e-02, -6.0605e-02]]],


        [[[ 1.1538e-01,  2.1209e-01,  2.8760e-01],
          [ 1.4600e-01,  1.4805e-01,  2.2078e-02],
          [-2.4747e-01, -1.7932e-01, -7.4982e-02]],

         [[ 5.7349e-02,  3.6709e-02, -1.2445e-01],
          [ 2.7653e-02, -9.0874e-02, -2.9312e-01],
          [-2.7873e-02,  7.1744e-02, -3.3359e-02]],

         [[-2.5269e-01, -1.1212e-01, -1.8912e-01],
          [-1.2726e-01,  7.1868e-02,  8.6815e-02],
          [ 1.2671e-01,  2.7975e-01,  2.4203e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -5.4140e-40],
          [ 1.8440e-40, -1.3337e-40,  9.3867e-41],
          [-3.7164e-40,  2.3400e-40, -1.9209e-40]],

         [[-1.3510e-40, -3.3786e-40, -3.5817e-40],
          [-1.0123e-40,  1.0705e-40, -4.4057e-42],
          [ 3.9750e-40, -1.6517e-40,  3.8970e-41]],

         [[ 4.9483e-41,  2.4258e-40,  1.2932e-40],
          [ 1.0542e-40, -4.3148e-40, -2.3397e-40],
          [ 1.8561e-40,  3.4087e-40, -1.4520e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0634]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0686]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 128 | Batch_idx: 0 |  Loss: (0.1723) | Acc: (93.00%) (120/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1650) | Acc: (94.00%) (1333/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1724) | Acc: (94.00%) (2532/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1869) | Acc: (93.00%) (3719/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.2009) | Acc: (93.00%) (4893/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.2135) | Acc: (92.00%) (6061/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.2197) | Acc: (92.00%) (7231/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.2227) | Acc: (92.00%) (8400/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.2259) | Acc: (92.00%) (9579/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.2295) | Acc: (92.00%) (10739/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.2348) | Acc: (91.00%) (11885/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.2359) | Acc: (91.00%) (13060/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.2396) | Acc: (91.00%) (14217/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.2445) | Acc: (91.00%) (15358/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.2425) | Acc: (91.00%) (16537/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.2410) | Acc: (91.00%) (17720/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.2413) | Acc: (91.00%) (18893/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.2412) | Acc: (91.00%) (20079/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.2413) | Acc: (91.00%) (21252/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.2427) | Acc: (91.00%) (22416/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.2427) | Acc: (91.00%) (23592/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.2439) | Acc: (91.00%) (24757/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.2441) | Acc: (91.00%) (25933/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.2436) | Acc: (91.00%) (27107/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.2434) | Acc: (91.00%) (28272/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.2431) | Acc: (91.00%) (29439/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.2439) | Acc: (91.00%) (30612/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.2440) | Acc: (91.00%) (31786/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.2431) | Acc: (91.00%) (32978/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.2429) | Acc: (91.00%) (34157/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.2435) | Acc: (91.00%) (35326/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.2439) | Acc: (91.00%) (36502/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.2426) | Acc: (91.00%) (37698/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.2424) | Acc: (91.00%) (38884/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.2417) | Acc: (91.00%) (40069/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.2410) | Acc: (91.00%) (41253/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.2405) | Acc: (91.00%) (42434/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.2408) | Acc: (91.00%) (43605/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.2404) | Acc: (91.00%) (44783/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.2399) | Acc: (91.00%) (45916/50000)
# TEST : Loss: (0.3553) | Acc: (88.00%) (8882/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9465e-01, -2.0445e-01,  2.8203e-02],
          [-4.9972e-02,  3.6488e-01,  2.4558e-01],
          [ 1.2612e-01,  7.8419e-02, -5.2606e-02]],

         [[-2.0120e-01,  2.1773e-01,  1.8715e-01],
          [ 3.9772e-02,  4.1628e-01,  2.3428e-01],
          [ 2.2181e-01,  1.1653e-02,  9.7012e-02]],

         [[-2.1181e-01, -7.1253e-02, -8.5823e-02],
          [-2.8843e-01, -1.1669e-01, -1.1231e-01],
          [-2.0551e-01, -1.3191e-01, -1.8477e-01]]],


        [[[ 2.8620e-40,  1.4120e-40, -3.7290e-40],
          [ 1.6527e-40, -3.8428e-40,  4.3605e-40],
          [-2.4018e-40,  9.1495e-41,  5.0574e-40]],

         [[ 2.4691e-40, -3.0247e-40,  6.2862e-41],
          [ 3.2249e-40,  5.6547e-40, -7.1668e-41],
          [-1.6874e-40,  1.7967e-40,  1.6699e-40]],

         [[-3.3164e-40, -2.7624e-40, -1.4429e-40],
          [ 2.9622e-40,  2.4227e-41, -1.1334e-40],
          [ 1.3725e-40,  3.0990e-40, -4.3569e-40]]],


        [[[ 4.7084e-02,  1.0995e-01, -4.7447e-02],
          [ 4.3208e-02,  2.0370e-01, -8.9914e-02],
          [ 1.5219e-01,  3.2814e-01,  3.4424e-01]],

         [[-1.9695e-01, -8.9449e-02, -1.6656e-01],
          [-3.7585e-01, -3.5634e-01, -2.9607e-01],
          [-2.4456e-01, -4.0969e-01,  4.8132e-02]],

         [[ 2.4748e-01,  1.3840e-01,  1.9983e-01],
          [ 2.0628e-01,  1.2181e-01,  2.7951e-02],
          [ 8.2322e-02,  9.7797e-02,  2.7555e-02]]],


        ...,


        [[[ 2.1955e-01,  4.8356e-02,  8.3169e-02],
          [ 1.6449e-01, -2.2364e-01, -4.8505e-02],
          [ 7.8377e-02, -7.7763e-02, -2.9837e-02]],

         [[-5.8784e-02, -4.9705e-02,  3.7911e-02],
          [-1.0454e-01, -2.3839e-01,  3.3647e-02],
          [ 4.1079e-02,  1.4416e-01,  2.1143e-01]],

         [[-9.2415e-02, -1.2883e-01,  5.8819e-02],
          [-8.9279e-02, -2.4186e-01, -1.3788e-01],
          [-4.1802e-02, -8.4046e-02, -4.4780e-02]]],


        [[[ 1.0096e-01,  1.8934e-01,  2.6845e-01],
          [ 1.3618e-01,  1.2356e-01,  2.2400e-03],
          [-2.5752e-01, -2.1023e-01, -9.9087e-02]],

         [[ 3.1391e-02,  7.3773e-03, -1.5115e-01],
          [ 7.7577e-03, -1.1975e-01, -3.1928e-01],
          [-4.6184e-02,  3.7028e-02, -6.3510e-02]],

         [[-2.6961e-01, -1.3368e-01, -2.0956e-01],
          [-1.4286e-01,  4.7329e-02,  6.0883e-02],
          [ 1.1188e-01,  2.5128e-01,  2.1427e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -2.6114e-40],
          [ 6.0479e-40,  6.7571e-42, -4.6665e-40],
          [-2.3151e-40, -4.6258e-41, -5.1959e-41]],

         [[-4.1536e-40,  8.2529e-41, -3.5817e-40],
          [ 3.8896e-41,  2.4718e-40,  2.7585e-40],
          [ 1.1724e-40, -5.8556e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.7677e-41,  4.0958e-40],
          [-1.7484e-40, -5.7161e-40,  1.8641e-40],
          [-9.4647e-41, -7.9518e-41, -5.0727e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0139, -0.0058, -0.0125],
          [-0.0154, -0.0091, -0.0127],
          [-0.0085, -0.0090, -0.0196]],

         [[-0.0168, -0.0117, -0.0221],
          [-0.0169, -0.0145, -0.0219],
          [-0.0135, -0.0160, -0.0259]],

         [[-0.0127, -0.0115, -0.0231],
          [-0.0138, -0.0154, -0.0219],
          [-0.0143, -0.0185, -0.0245]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0215, -0.0054, -0.0011],
          [-0.0009,  0.0128,  0.0270],
          [ 0.0048,  0.0038,  0.0156]],

         [[-0.0389, -0.0171, -0.0073],
          [-0.0219, -0.0072,  0.0106],
          [-0.0138, -0.0144,  0.0009]],

         [[-0.0508, -0.0256, -0.0155],
          [-0.0356, -0.0178, -0.0010],
          [-0.0246, -0.0249, -0.0122]]],


        ...,


        [[[ 0.0025, -0.0055, -0.0013],
          [ 0.0063, -0.0019,  0.0020],
          [-0.0021, -0.0097, -0.0080]],

         [[ 0.0022, -0.0058, -0.0010],
          [ 0.0060, -0.0020,  0.0026],
          [-0.0013, -0.0081, -0.0057]],

         [[ 0.0018, -0.0053, -0.0011],
          [ 0.0058, -0.0008,  0.0029],
          [ 0.0020, -0.0033, -0.0014]]],


        [[[-0.0015, -0.0015, -0.0015],
          [-0.0020, -0.0011, -0.0011],
          [-0.0044, -0.0034, -0.0039]],

         [[-0.0000, -0.0002, -0.0004],
          [-0.0007,  0.0003,  0.0000],
          [-0.0031, -0.0020, -0.0026]],

         [[ 0.0013,  0.0009,  0.0004],
          [ 0.0001,  0.0010,  0.0009],
          [-0.0022, -0.0011, -0.0014]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0620]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 129 | Batch_idx: 0 |  Loss: (0.2043) | Acc: (92.00%) (119/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.2177) | Acc: (93.00%) (1315/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.2185) | Acc: (92.00%) (2496/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.2176) | Acc: (92.00%) (3681/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.2114) | Acc: (92.00%) (4876/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.2157) | Acc: (92.00%) (6061/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.2107) | Acc: (92.00%) (7258/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.2109) | Acc: (92.00%) (8438/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.2109) | Acc: (92.00%) (9627/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.2083) | Acc: (92.00%) (10824/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.2096) | Acc: (92.00%) (11997/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.2097) | Acc: (92.00%) (13170/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.2058) | Acc: (92.00%) (14385/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.2037) | Acc: (92.00%) (15589/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.2029) | Acc: (93.00%) (16787/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.2018) | Acc: (93.00%) (17977/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.2046) | Acc: (92.00%) (19150/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.2076) | Acc: (92.00%) (20326/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.2081) | Acc: (92.00%) (21515/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.2082) | Acc: (92.00%) (22709/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.2067) | Acc: (92.00%) (23914/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.2073) | Acc: (92.00%) (25094/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.2072) | Acc: (92.00%) (26274/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.2077) | Acc: (92.00%) (27456/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.2072) | Acc: (92.00%) (28651/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.2059) | Acc: (92.00%) (29860/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.2058) | Acc: (92.00%) (31047/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.2064) | Acc: (92.00%) (32232/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.2061) | Acc: (92.00%) (33440/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.2062) | Acc: (92.00%) (34628/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.2065) | Acc: (92.00%) (35807/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.2063) | Acc: (92.00%) (36993/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.2062) | Acc: (92.00%) (38183/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.2060) | Acc: (92.00%) (39379/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.2050) | Acc: (92.00%) (40582/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.2042) | Acc: (92.00%) (41777/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.2041) | Acc: (92.00%) (42966/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.2037) | Acc: (93.00%) (44166/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.2041) | Acc: (92.00%) (45350/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.2039) | Acc: (92.00%) (46494/50000)
# TEST : Loss: (0.3162) | Acc: (89.00%) (8994/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0023e-01, -2.0689e-01,  1.9226e-02],
          [-5.2016e-02,  3.6647e-01,  2.4001e-01],
          [ 1.2299e-01,  7.6008e-02, -5.7553e-02]],

         [[-2.1142e-01,  2.1217e-01,  1.7443e-01],
          [ 3.3474e-02,  4.1315e-01,  2.2199e-01],
          [ 2.1203e-01,  3.6662e-03,  8.4498e-02]],

         [[-2.1712e-01, -7.4855e-02, -9.7224e-02],
          [-2.9728e-01, -1.2353e-01, -1.2659e-01],
          [-2.1806e-01, -1.4302e-01, -1.9749e-01]]],


        [[[-1.3397e-40,  1.4121e-40,  1.8729e-40],
          [-1.1483e-40, -1.0420e-40,  2.9603e-40],
          [-1.0016e-40, -1.8861e-40,  3.6572e-40]],

         [[ 2.4696e-40, -2.2372e-41, -2.1725e-40],
          [ 3.2251e-40,  2.8539e-40, -2.1175e-40],
          [-2.8696e-41,  1.7969e-40,  2.6936e-41]],

         [[-4.7173e-40,  3.8676e-42, -5.6451e-40],
          [ 2.9625e-40,  1.6429e-40,  4.4691e-40],
          [-1.4286e-40,  3.0992e-40,  1.2456e-40]]],


        [[[ 4.6171e-02,  1.1534e-01, -3.2564e-02],
          [ 3.6634e-02,  1.9946e-01, -9.1963e-02],
          [ 1.4351e-01,  3.2171e-01,  3.3716e-01]],

         [[-1.9603e-01, -8.3486e-02, -1.4847e-01],
          [-3.8245e-01, -3.6318e-01, -2.9668e-01],
          [-2.4820e-01, -4.1646e-01,  3.9542e-02]],

         [[ 2.5251e-01,  1.5216e-01,  2.2307e-01],
          [ 2.0884e-01,  1.2510e-01,  3.2588e-02],
          [ 8.9299e-02,  9.8162e-02,  1.9673e-02]]],


        ...,


        [[[ 2.1262e-01,  4.6772e-02,  7.6885e-02],
          [ 1.5548e-01, -2.3399e-01, -6.2347e-02],
          [ 6.9139e-02, -9.1051e-02, -4.8619e-02]],

         [[-5.8031e-02, -4.4725e-02,  2.9982e-02],
          [-1.0571e-01, -2.4434e-01,  1.2475e-02],
          [ 3.8023e-02,  1.3086e-01,  1.8579e-01]],

         [[-9.4971e-02, -1.3575e-01,  3.7764e-02],
          [-9.4535e-02, -2.6659e-01, -1.7871e-01],
          [-5.0881e-02, -1.0965e-01, -7.9624e-02]]],


        [[[ 1.0719e-01,  2.0344e-01,  2.8893e-01],
          [ 1.4731e-01,  1.4390e-01,  2.8785e-02],
          [-2.4354e-01, -1.9149e-01, -8.6471e-02]],

         [[ 3.5254e-02,  1.6774e-02, -1.2848e-01],
          [ 1.2231e-02, -1.0449e-01, -2.8899e-01],
          [-3.3005e-02,  5.6728e-02, -4.7790e-02]],

         [[-2.7068e-01, -1.3387e-01, -1.9696e-01],
          [-1.3841e-01,  5.8468e-02,  8.4271e-02],
          [ 1.2122e-01,  2.6827e-01,  2.2873e-01]]],


        [[[-3.2265e-41,  5.6510e-41,  2.9938e-40],
          [ 4.6466e-40,  1.4689e-40, -6.0678e-40],
          [ 1.8888e-40, -3.2652e-40,  8.8171e-41]],

         [[-2.7523e-40,  3.6279e-40,  6.2223e-41],
          [ 1.7903e-40,  1.0705e-40,  2.7585e-40],
          [-3.0315e-40, -4.4543e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.1794e-40,  2.6945e-40],
          [-3.1497e-40, -1.5122e-40,  4.6667e-40],
          [-2.3478e-40, -3.5978e-40,  1.3506e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0448,  0.0418,  0.0412],
          [ 0.0321,  0.0324,  0.0250],
          [ 0.0198,  0.0170,  0.0086]],

         [[ 0.0255,  0.0273,  0.0318],
          [ 0.0113,  0.0165,  0.0159],
          [ 0.0022,  0.0024, -0.0009]],

         [[ 0.0212,  0.0275,  0.0322],
          [ 0.0092,  0.0178,  0.0187],
          [ 0.0034,  0.0069,  0.0059]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0455,  0.0274,  0.0198],
          [ 0.0427,  0.0288,  0.0241],
          [ 0.0413,  0.0350,  0.0302]],

         [[ 0.0231,  0.0106,  0.0023],
          [ 0.0212,  0.0125,  0.0074],
          [ 0.0242,  0.0194,  0.0133]],

         [[ 0.0030, -0.0025, -0.0049],
          [-0.0023, -0.0044, -0.0006],
          [-0.0067, -0.0057, -0.0028]]],


        ...,


        [[[ 0.0034,  0.0023,  0.0019],
          [ 0.0012, -0.0013, -0.0017],
          [-0.0029, -0.0012, -0.0006]],

         [[ 0.0013,  0.0008,  0.0008],
          [ 0.0003, -0.0020, -0.0024],
          [-0.0037, -0.0023, -0.0021]],

         [[ 0.0028,  0.0018,  0.0020],
          [ 0.0026,  0.0009,  0.0000],
          [ 0.0001,  0.0009, -0.0002]]],


        [[[ 0.0001,  0.0017,  0.0002],
          [-0.0036, -0.0027, -0.0052],
          [-0.0061, -0.0059, -0.0040]],

         [[ 0.0009,  0.0018,  0.0009],
          [-0.0038, -0.0040, -0.0048],
          [-0.0062, -0.0072, -0.0045]],

         [[-0.0007,  0.0013,  0.0018],
          [-0.0054, -0.0039, -0.0023],
          [-0.0085, -0.0075, -0.0042]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0619]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 130 | Batch_idx: 0 |  Loss: (0.1945) | Acc: (92.00%) (118/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.2003) | Acc: (92.00%) (1302/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.2205) | Acc: (92.00%) (2477/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.2218) | Acc: (92.00%) (3656/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.2216) | Acc: (92.00%) (4835/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.2111) | Acc: (92.00%) (6041/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.2057) | Acc: (92.00%) (7243/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.2026) | Acc: (92.00%) (8447/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.2024) | Acc: (92.00%) (9635/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.2009) | Acc: (92.00%) (10831/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.2000) | Acc: (93.00%) (12028/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1963) | Acc: (93.00%) (13245/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1950) | Acc: (93.00%) (14445/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1942) | Acc: (93.00%) (15645/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1927) | Acc: (93.00%) (16855/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1900) | Acc: (93.00%) (18071/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1888) | Acc: (93.00%) (19272/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1889) | Acc: (93.00%) (20481/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1870) | Acc: (93.00%) (21694/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1862) | Acc: (93.00%) (22896/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1860) | Acc: (93.00%) (24096/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1855) | Acc: (93.00%) (25301/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1855) | Acc: (93.00%) (26498/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1854) | Acc: (93.00%) (27692/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1850) | Acc: (93.00%) (28896/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1839) | Acc: (93.00%) (30110/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1827) | Acc: (93.00%) (31320/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1824) | Acc: (93.00%) (32522/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1815) | Acc: (93.00%) (33738/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1805) | Acc: (93.00%) (34956/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1797) | Acc: (93.00%) (36172/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1792) | Acc: (93.00%) (37381/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1789) | Acc: (93.00%) (38590/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1781) | Acc: (93.00%) (39802/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1785) | Acc: (93.00%) (40995/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1789) | Acc: (93.00%) (42192/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1786) | Acc: (93.00%) (43406/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1781) | Acc: (93.00%) (44616/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1777) | Acc: (93.00%) (45829/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1775) | Acc: (93.00%) (46980/50000)
# TEST : Loss: (0.2928) | Acc: (90.00%) (9057/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0493e-01, -2.1149e-01,  1.3130e-02],
          [-5.5469e-02,  3.6123e-01,  2.3501e-01],
          [ 1.2063e-01,  7.3290e-02, -5.9866e-02]],

         [[-2.1599e-01,  2.0642e-01,  1.6810e-01],
          [ 3.0152e-02,  4.0839e-01,  2.1719e-01],
          [ 2.0971e-01,  1.6401e-03,  8.1613e-02]],

         [[-2.2063e-01, -7.8633e-02, -1.0150e-01],
          [-2.9894e-01, -1.2594e-01, -1.2924e-01],
          [-2.1880e-01, -1.4436e-01, -1.9872e-01]]],


        [[[-4.1412e-40,  1.1477e-42,  6.0752e-40],
          [-2.5491e-40,  3.1601e-40, -1.2417e-40],
          [ 1.7998e-40, -3.2869e-40, -1.9457e-40]],

         [[-3.3174e-41,  2.5778e-40, -2.1727e-40],
          [ 4.2384e-41, -2.7488e-40, -7.1690e-41],
          [ 1.1137e-40,  3.9629e-41, -1.1314e-40]],

         [[-1.9161e-40,  2.8403e-40, -4.2449e-40],
          [ 1.6116e-41,  1.6431e-40,  5.8704e-40],
          [-2.8295e-40,  2.9789e-41,  5.4482e-40]]],


        [[[ 4.4959e-02,  1.1423e-01, -3.3750e-02],
          [ 3.5287e-02,  1.9813e-01, -9.3066e-02],
          [ 1.4063e-01,  3.1879e-01,  3.3438e-01]],

         [[-1.9598e-01, -8.3496e-02, -1.4857e-01],
          [-3.8277e-01, -3.6332e-01, -2.9686e-01],
          [-2.4999e-01, -4.1754e-01,  3.8087e-02]],

         [[ 2.5261e-01,  1.5252e-01,  2.2301e-01],
          [ 2.0836e-01,  1.2505e-01,  3.2469e-02],
          [ 8.8526e-02,  9.7557e-02,  1.9197e-02]]],


        ...,


        [[[ 2.1155e-01,  4.7515e-02,  7.7190e-02],
          [ 1.5540e-01, -2.3031e-01, -6.0314e-02],
          [ 7.1092e-02, -8.8213e-02, -4.7173e-02]],

         [[-5.7225e-02, -4.3304e-02,  3.0199e-02],
          [-1.0355e-01, -2.3936e-01,  1.3954e-02],
          [ 3.9875e-02,  1.3170e-01,  1.8488e-01]],

         [[-9.6073e-02, -1.3438e-01,  3.5818e-02],
          [-9.4065e-02, -2.5797e-01, -1.7460e-01],
          [-4.9436e-02, -1.0665e-01, -7.8979e-02]]],


        [[[ 1.0802e-01,  2.0290e-01,  2.8815e-01],
          [ 1.4750e-01,  1.4293e-01,  2.9292e-02],
          [-2.3963e-01, -1.9007e-01, -8.6381e-02]],

         [[ 3.5797e-02,  1.7143e-02, -1.2632e-01],
          [ 1.4226e-02, -1.0258e-01, -2.8533e-01],
          [-3.0808e-02,  5.5909e-02, -4.8026e-02]],

         [[-2.6631e-01, -1.3174e-01, -1.9387e-01],
          [-1.3382e-01,  5.9545e-02,  8.4901e-02],
          [ 1.2278e-01,  2.6619e-01,  2.2639e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  5.7964e-40],
          [-9.5863e-41,  1.4689e-40, -1.8639e-40],
          [ 4.6914e-40, -3.2652e-40,  8.8171e-41]],

         [[ 1.4516e-40,  2.2266e-40,  4.8261e-40],
          [ 1.7903e-40, -1.7321e-40, -4.4057e-42],
          [-4.4328e-40,  1.1509e-40,  3.8970e-41]],

         [[ 4.9483e-41, -3.1794e-40, -1.5094e-40],
          [-1.7484e-40,  4.0930e-40,  3.2654e-40],
          [-9.4647e-41, -2.1965e-40,  1.3506e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0995]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0426]], device='cuda:0')

Epoch: 131 | Batch_idx: 0 |  Loss: (0.1113) | Acc: (96.00%) (124/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1580) | Acc: (94.00%) (1327/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1642) | Acc: (94.00%) (2540/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1598) | Acc: (94.00%) (3757/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1597) | Acc: (94.00%) (4964/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1635) | Acc: (94.00%) (6171/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1634) | Acc: (94.00%) (7383/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1622) | Acc: (94.00%) (8592/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1616) | Acc: (94.00%) (9800/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1602) | Acc: (94.00%) (11011/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1625) | Acc: (94.00%) (12214/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1624) | Acc: (94.00%) (13427/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1620) | Acc: (94.00%) (14646/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1625) | Acc: (94.00%) (15847/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1610) | Acc: (94.00%) (17064/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1613) | Acc: (94.00%) (18262/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1605) | Acc: (94.00%) (19479/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1608) | Acc: (94.00%) (20691/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1609) | Acc: (94.00%) (21907/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1604) | Acc: (94.00%) (23114/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1615) | Acc: (94.00%) (24321/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1621) | Acc: (94.00%) (25527/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1620) | Acc: (94.00%) (26740/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1630) | Acc: (94.00%) (27944/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1624) | Acc: (94.00%) (29164/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1635) | Acc: (94.00%) (30357/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1637) | Acc: (94.00%) (31565/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1632) | Acc: (94.00%) (32776/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1628) | Acc: (94.00%) (33987/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1628) | Acc: (94.00%) (35192/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1626) | Acc: (94.00%) (36402/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1627) | Acc: (94.00%) (37614/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1620) | Acc: (94.00%) (38831/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1617) | Acc: (94.00%) (40047/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1622) | Acc: (94.00%) (41244/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1624) | Acc: (94.00%) (42457/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1623) | Acc: (94.00%) (43667/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1620) | Acc: (94.00%) (44876/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1627) | Acc: (94.00%) (46074/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1627) | Acc: (94.00%) (47239/50000)
# TEST : Loss: (0.2849) | Acc: (90.00%) (9065/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.0414e-01, -2.1062e-01,  1.3074e-02],
          [-5.5239e-02,  3.5965e-01,  2.3395e-01],
          [ 1.2013e-01,  7.2969e-02, -5.9604e-02]],

         [[-2.1512e-01,  2.0556e-01,  1.6741e-01],
          [ 3.0025e-02,  4.0665e-01,  2.1625e-01],
          [ 2.0884e-01,  1.6331e-03,  8.1268e-02]],

         [[-2.1968e-01, -7.8299e-02, -1.0108e-01],
          [-2.9765e-01, -1.2541e-01, -1.2870e-01],
          [-2.1787e-01, -1.4376e-01, -1.9790e-01]]],


        [[[-2.7406e-40, -1.3894e-40,  4.6748e-40],
          [-1.1484e-40,  4.5611e-40, -4.0434e-40],
          [ 3.2008e-40, -1.8862e-40, -6.1485e-40]],

         [[-3.1334e-40,  2.5780e-40,  6.2873e-41],
          [-2.3778e-40, -5.5506e-40,  2.0847e-40],
          [ 1.1138e-40, -1.0046e-40, -1.1315e-40]],

         [[ 2.2865e-40,  2.8405e-40,  1.3583e-40],
          [-2.6406e-40,  2.4226e-41,  1.6681e-40],
          [-1.4289e-40, -2.5039e-40,  4.0477e-40]]],


        [[[ 4.4871e-02,  1.1400e-01, -3.3682e-02],
          [ 3.5218e-02,  1.9774e-01, -9.2882e-02],
          [ 1.4035e-01,  3.1816e-01,  3.3371e-01]],

         [[-1.9557e-01, -8.3317e-02, -1.4825e-01],
          [-3.8193e-01, -3.6252e-01, -2.9621e-01],
          [-2.4944e-01, -4.1662e-01,  3.8006e-02]],

         [[ 2.5205e-01,  1.5217e-01,  2.2251e-01],
          [ 2.0788e-01,  1.2476e-01,  3.2394e-02],
          [ 8.8321e-02,  9.7330e-02,  1.9153e-02]]],


        ...,


        [[[ 2.0943e-01,  4.7039e-02,  7.6404e-02],
          [ 1.5383e-01, -2.2799e-01, -5.9696e-02],
          [ 7.0372e-02, -8.7311e-02, -4.6676e-02]],

         [[-5.6472e-02, -4.2712e-02,  2.9804e-02],
          [-1.0212e-01, -2.3587e-01,  1.3759e-02],
          [ 3.9365e-02,  1.2991e-01,  1.8241e-01]],

         [[-9.4152e-02, -1.3120e-01,  3.5133e-02],
          [-9.1635e-02, -2.4880e-01, -1.7016e-01],
          [-4.8492e-02, -1.0418e-01, -7.7455e-02]]],


        [[[ 1.0698e-01,  2.0081e-01,  2.8532e-01],
          [ 1.4608e-01,  1.4144e-01,  2.8999e-02],
          [-2.3723e-01, -1.8805e-01, -8.5487e-02]],

         [[ 3.5401e-02,  1.6945e-02, -1.2488e-01],
          [ 1.4060e-02, -1.0132e-01, -2.8186e-01],
          [-3.0443e-02,  5.5238e-02, -4.7453e-02]],

         [[-2.6297e-01, -1.3007e-01, -1.9139e-01],
          [-1.3214e-01,  5.8790e-02,  8.3813e-02],
          [ 1.2130e-01,  2.6302e-01,  2.2368e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  2.9938e-40],
          [-5.1625e-40,  6.7571e-42,  3.7413e-40],
          [ 3.2901e-40, -4.6258e-41, -5.1959e-41]],

         [[ 4.2542e-40, -1.9773e-40,  4.8261e-40],
          [ 3.8896e-41, -3.1334e-40, -2.8467e-40],
          [-1.6302e-40,  5.3548e-40,  1.7910e-40]],

         [[-2.3078e-40, -3.7677e-41, -4.3120e-40],
          [ 1.0542e-40,  5.4943e-40, -9.3845e-41],
          [ 1.8561e-40,  2.0074e-40, -5.0727e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0959]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0484]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 132 | Batch_idx: 0 |  Loss: (0.1430) | Acc: (94.00%) (121/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1853) | Acc: (93.00%) (1320/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1783) | Acc: (94.00%) (2529/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1742) | Acc: (94.00%) (3734/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1936) | Acc: (93.00%) (4904/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.2093) | Acc: (93.00%) (6073/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.2250) | Acc: (92.00%) (7224/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.2270) | Acc: (92.00%) (8402/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.2298) | Acc: (92.00%) (9576/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.2336) | Acc: (92.00%) (10733/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.2357) | Acc: (92.00%) (11894/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.2367) | Acc: (91.00%) (13058/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.2374) | Acc: (91.00%) (14230/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.2420) | Acc: (91.00%) (15384/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.2417) | Acc: (91.00%) (16555/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.2398) | Acc: (91.00%) (17733/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.2394) | Acc: (91.00%) (18912/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.2392) | Acc: (91.00%) (20091/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.2413) | Acc: (91.00%) (21250/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.2418) | Acc: (91.00%) (22420/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.2429) | Acc: (91.00%) (23589/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.2425) | Acc: (91.00%) (24753/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.2417) | Acc: (91.00%) (25941/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.2423) | Acc: (91.00%) (27121/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.2432) | Acc: (91.00%) (28293/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.2424) | Acc: (91.00%) (29472/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.2430) | Acc: (91.00%) (30637/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.2423) | Acc: (91.00%) (31828/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.2418) | Acc: (91.00%) (32999/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.2412) | Acc: (91.00%) (34187/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.2420) | Acc: (91.00%) (35352/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.2417) | Acc: (91.00%) (36529/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.2416) | Acc: (91.00%) (37703/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.2412) | Acc: (91.00%) (38880/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.2406) | Acc: (91.00%) (40064/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.2403) | Acc: (91.00%) (41251/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.2399) | Acc: (91.00%) (42435/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.2400) | Acc: (91.00%) (43614/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.2392) | Acc: (91.00%) (44810/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.2399) | Acc: (91.00%) (45935/50000)
# TEST : Loss: (0.3226) | Acc: (90.00%) (9005/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9728e-01, -1.9951e-01,  3.1168e-02],
          [-4.9575e-02,  3.7459e-01,  2.5219e-01],
          [ 1.2759e-01,  8.7051e-02, -4.3910e-02]],

         [[-2.0338e-01,  2.1910e-01,  1.8146e-01],
          [ 3.5681e-02,  4.1973e-01,  2.2809e-01],
          [ 2.1685e-01,  1.2589e-02,  9.1726e-02]],

         [[-2.1050e-01, -6.8509e-02, -8.8647e-02],
          [-2.9480e-01, -1.2100e-01, -1.2088e-01],
          [-2.1352e-01, -1.3994e-01, -1.8923e-01]]],


        [[[ 1.4620e-40, -1.3894e-40, -9.2854e-41],
          [ 1.6533e-40,  1.7595e-40, -2.6427e-40],
          [ 1.8001e-40,  9.1555e-41, -4.7479e-40]],

         [[-3.1336e-40, -2.2372e-41,  3.4306e-40],
          [-2.3780e-40, -2.7491e-40,  2.0848e-40],
          [-2.8699e-41, -1.0046e-40,  2.6939e-41]],

         [[ 3.6876e-40,  3.8774e-42,  5.5612e-40],
          [-2.6408e-40, -1.1587e-40, -3.9356e-40],
          [ 1.3729e-40, -2.5040e-40, -1.5560e-40]]],


        [[[ 4.0057e-02,  1.0813e-01, -4.1690e-02],
          [ 3.2383e-02,  1.9261e-01, -9.9653e-02],
          [ 1.4158e-01,  3.1635e-01,  3.3293e-01]],

         [[-2.0547e-01, -9.8956e-02, -1.6680e-01],
          [-3.9325e-01, -3.7948e-01, -3.1314e-01],
          [-2.5751e-01, -4.2782e-01,  3.3156e-02]],

         [[ 2.4003e-01,  1.3744e-01,  2.0246e-01],
          [ 2.0062e-01,  1.1456e-01,  1.9452e-02],
          [ 8.5491e-02,  9.1055e-02,  1.6429e-02]]],


        ...,


        [[[ 2.0740e-01,  3.9355e-02,  7.7209e-02],
          [ 1.5409e-01, -2.3494e-01, -5.3934e-02],
          [ 7.3101e-02, -9.4193e-02, -5.4521e-02]],

         [[-5.7709e-02, -4.5598e-02,  3.8858e-02],
          [-9.9466e-02, -2.4302e-01,  2.0770e-02],
          [ 4.2893e-02,  1.1726e-01,  1.6953e-01]],

         [[-9.1049e-02, -1.3122e-01,  4.7853e-02],
          [-8.7680e-02, -2.4529e-01, -1.4673e-01],
          [-4.2627e-02, -1.1096e-01, -8.4260e-02]]],


        [[[ 9.0594e-02,  1.9627e-01,  2.6846e-01],
          [ 1.3413e-01,  1.4490e-01,  2.8912e-02],
          [-2.3045e-01, -1.6710e-01, -7.5199e-02]],

         [[ 8.9086e-03,  7.7855e-03, -1.4615e-01],
          [ 3.6226e-03, -9.2254e-02, -2.7984e-01],
          [-2.8553e-02,  7.6599e-02, -3.4536e-02]],

         [[-2.8347e-01, -1.3718e-01, -2.1368e-01],
          [-1.3783e-01,  6.5913e-02,  7.9223e-02],
          [ 1.2364e-01,  2.8228e-01,  2.3358e-01]]],


        [[[-3.2265e-41,  5.6510e-41, -2.6114e-40],
          [-3.7612e-40, -1.3337e-40,  5.1426e-40],
          [-9.1376e-41,  2.3400e-40, -1.9209e-40]],

         [[ 2.8529e-40, -4.7799e-40,  6.2223e-41],
          [-1.0123e-40, -1.7321e-40, -2.8467e-40],
          [ 2.5737e-40,  3.9535e-40,  1.7910e-40]],

         [[-2.3078e-40,  2.4258e-40, -2.9107e-40],
          [ 2.4555e-40,  1.2904e-40, -3.7410e-40],
          [ 3.2574e-40,  4.8100e-40, -1.4520e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0213,  0.0166,  0.0183],
          [ 0.0169,  0.0086,  0.0088],
          [ 0.0075,  0.0010,  0.0019]],

         [[ 0.0153,  0.0127,  0.0161],
          [ 0.0097,  0.0044,  0.0071],
          [ 0.0038, -0.0010,  0.0026]],

         [[ 0.0133,  0.0108,  0.0150],
          [ 0.0057,  0.0011,  0.0046],
          [-0.0008, -0.0047, -0.0016]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0436, -0.0298, -0.0309],
          [-0.0303, -0.0258, -0.0205],
          [-0.0110, -0.0115, -0.0110]],

         [[-0.0348, -0.0200, -0.0232],
          [-0.0199, -0.0164, -0.0146],
          [-0.0025, -0.0029, -0.0024]],

         [[-0.0262, -0.0139, -0.0178],
          [-0.0145, -0.0147, -0.0136],
          [ 0.0006, -0.0028, -0.0031]]],


        ...,


        [[[ 0.0063,  0.0090,  0.0087],
          [ 0.0086,  0.0129,  0.0121],
          [ 0.0094,  0.0145,  0.0123]],

         [[-0.0004,  0.0021,  0.0019],
          [ 0.0025,  0.0061,  0.0056],
          [ 0.0023,  0.0069,  0.0047]],

         [[-0.0037, -0.0021, -0.0019],
          [-0.0022,  0.0004,  0.0000],
          [-0.0049, -0.0014, -0.0034]]],


        [[[-0.0057, -0.0058, -0.0076],
          [-0.0048, -0.0036, -0.0028],
          [-0.0031,  0.0017,  0.0036]],

         [[-0.0012, -0.0010, -0.0023],
          [-0.0004,  0.0015,  0.0029],
          [ 0.0007,  0.0066,  0.0096]],

         [[ 0.0019,  0.0031,  0.0024],
          [ 0.0018,  0.0052,  0.0071],
          [ 0.0030,  0.0097,  0.0128]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0924]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 133 | Batch_idx: 0 |  Loss: (0.2077) | Acc: (93.00%) (120/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1827) | Acc: (93.00%) (1317/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1927) | Acc: (93.00%) (2508/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1970) | Acc: (93.00%) (3707/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.2027) | Acc: (93.00%) (4888/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.2027) | Acc: (93.00%) (6078/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.2043) | Acc: (93.00%) (7269/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1999) | Acc: (93.00%) (8475/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1984) | Acc: (93.00%) (9668/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1962) | Acc: (93.00%) (10865/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1945) | Acc: (93.00%) (12062/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1939) | Acc: (93.00%) (13255/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1956) | Acc: (93.00%) (14441/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1962) | Acc: (93.00%) (15622/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1957) | Acc: (93.00%) (16819/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1947) | Acc: (93.00%) (18019/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1954) | Acc: (93.00%) (19203/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1951) | Acc: (93.00%) (20394/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1950) | Acc: (93.00%) (21603/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1952) | Acc: (93.00%) (22799/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1958) | Acc: (93.00%) (23994/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1981) | Acc: (93.00%) (25171/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1979) | Acc: (93.00%) (26363/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1983) | Acc: (93.00%) (27555/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1986) | Acc: (93.00%) (28744/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1999) | Acc: (93.00%) (29921/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.2008) | Acc: (93.00%) (31107/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1998) | Acc: (93.00%) (32316/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.2011) | Acc: (93.00%) (33491/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.2018) | Acc: (93.00%) (34670/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.2023) | Acc: (93.00%) (35854/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.2023) | Acc: (93.00%) (37043/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.2021) | Acc: (93.00%) (38238/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.2023) | Acc: (93.00%) (39431/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.2026) | Acc: (93.00%) (40625/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.2035) | Acc: (93.00%) (41800/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.2033) | Acc: (93.00%) (42999/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.2024) | Acc: (93.00%) (44208/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.2024) | Acc: (93.00%) (45397/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.2023) | Acc: (93.00%) (46544/50000)
# TEST : Loss: (0.3958) | Acc: (88.00%) (8847/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9921e-01, -2.0413e-01,  2.5759e-02],
          [-4.8882e-02,  3.7112e-01,  2.4895e-01],
          [ 1.2677e-01,  8.3217e-02, -4.5856e-02]],

         [[-2.0238e-01,  2.1713e-01,  1.7851e-01],
          [ 3.9509e-02,  4.1816e-01,  2.2441e-01],
          [ 2.2035e-01,  1.4551e-02,  9.1421e-02]],

         [[-2.1086e-01, -7.2361e-02, -9.2611e-02],
          [-2.9740e-01, -1.2844e-01, -1.2658e-01],
          [-2.1699e-01, -1.4489e-01, -1.9465e-01]]],


        [[[ 4.2641e-40,  1.1463e-42, -5.1315e-40],
          [ 3.0544e-40, -2.4435e-40,  1.5602e-40],
          [-1.0018e-40,  2.3166e-40,  8.5607e-41]],

         [[-3.3176e-41, -3.0258e-40,  3.4307e-40],
          [ 4.2379e-41,  2.8548e-40, -7.1711e-41],
          [-1.6880e-40,  3.9630e-41,  1.6704e-40]],

         [[ 8.8579e-41, -2.7632e-40,  4.1604e-40],
          [ 1.6104e-41, -1.1588e-40, -5.3367e-40],
          [ 2.7739e-40,  2.9786e-41, -5.7591e-40]]],


        [[[ 4.7725e-02,  1.1561e-01, -3.6027e-02],
          [ 4.5058e-02,  2.0357e-01, -8.7971e-02],
          [ 1.5431e-01,  3.2874e-01,  3.4144e-01]],

         [[-1.9415e-01, -9.1152e-02, -1.6049e-01],
          [-3.8246e-01, -3.7296e-01, -3.0430e-01],
          [-2.4900e-01, -4.2284e-01,  3.4913e-02]],

         [[ 2.5360e-01,  1.4781e-01,  2.0848e-01],
          [ 2.1611e-01,  1.2605e-01,  3.0583e-02],
          [ 9.8912e-02,  9.8587e-02,  1.8888e-02]]],


        ...,


        [[[ 2.0644e-01,  3.6828e-02,  8.4872e-02],
          [ 1.4190e-01, -2.5362e-01, -6.3564e-02],
          [ 5.9719e-02, -1.1250e-01, -5.9129e-02]],

         [[-4.7782e-02, -3.7030e-02,  5.6854e-02],
          [-1.0379e-01, -2.5113e-01,  2.1620e-02],
          [ 3.9195e-02,  1.1132e-01,  1.8112e-01]],

         [[-6.9400e-02, -1.1460e-01,  7.3484e-02],
          [-6.9579e-02, -2.4118e-01, -1.3563e-01],
          [-2.3251e-02, -9.9322e-02, -6.1681e-02]]],


        [[[ 9.6024e-02,  2.1553e-01,  2.9925e-01],
          [ 1.4264e-01,  1.6075e-01,  5.7706e-02],
          [-2.2001e-01, -1.5028e-01, -5.3538e-02]],

         [[ 2.7781e-02,  4.0283e-02, -9.8569e-02],
          [ 2.4402e-02, -6.2797e-02, -2.3975e-01],
          [-7.3346e-04,  1.0592e-01, -6.0217e-03]],

         [[-2.7229e-01, -1.1900e-01, -1.8423e-01],
          [-1.2569e-01,  8.1729e-02,  9.6588e-02],
          [ 1.4609e-01,  3.0297e-01,  2.4561e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -5.4140e-40],
          [ 1.8440e-40, -1.3337e-40,  9.3869e-41],
          [-3.7164e-40,  2.3400e-40, -1.9209e-40]],

         [[-1.3510e-40, -3.3786e-40, -3.5817e-40],
          [-1.0123e-40,  1.0705e-40, -4.4057e-42],
          [ 3.9750e-40, -1.6517e-40,  3.8970e-41]],

         [[ 4.9483e-41,  2.4258e-40,  1.2932e-40],
          [ 1.0542e-40, -4.3148e-40, -2.3397e-40],
          [ 1.8561e-40,  3.4087e-40, -1.4520e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0041, -0.0028,  0.0139],
          [-0.0009, -0.0016,  0.0059],
          [-0.0079, -0.0056,  0.0059]],

         [[-0.0019, -0.0005,  0.0152],
          [-0.0026, -0.0028,  0.0062],
          [-0.0118, -0.0069,  0.0075]],

         [[ 0.0011,  0.0016,  0.0130],
          [ 0.0004, -0.0001,  0.0066],
          [-0.0064, -0.0036,  0.0077]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0034, -0.0045,  0.0096],
          [-0.0034, -0.0061, -0.0046],
          [-0.0014,  0.0025, -0.0037]],

         [[-0.0118, -0.0136,  0.0034],
          [-0.0117, -0.0166, -0.0143],
          [-0.0084, -0.0070, -0.0149]],

         [[-0.0213, -0.0177, -0.0002],
          [-0.0212, -0.0211, -0.0175],
          [-0.0212, -0.0159, -0.0201]]],


        ...,


        [[[-0.0058, -0.0084, -0.0088],
          [-0.0006, -0.0050, -0.0069],
          [ 0.0015, -0.0031, -0.0068]],

         [[-0.0045, -0.0064, -0.0072],
          [-0.0006, -0.0042, -0.0063],
          [ 0.0013, -0.0027, -0.0069]],

         [[-0.0003, -0.0016, -0.0025],
          [ 0.0022, -0.0001, -0.0019],
          [ 0.0031,  0.0004, -0.0028]]],


        [[[-0.0023, -0.0010,  0.0002],
          [-0.0028,  0.0010,  0.0047],
          [-0.0020,  0.0021,  0.0040]],

         [[-0.0022, -0.0005,  0.0013],
          [-0.0030,  0.0012,  0.0055],
          [-0.0017,  0.0020,  0.0040]],

         [[-0.0009,  0.0009,  0.0025],
          [-0.0021,  0.0019,  0.0060],
          [-0.0014,  0.0017,  0.0038]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0922]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1150) | Acc: (96.00%) (124/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1686) | Acc: (93.00%) (1320/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1881) | Acc: (93.00%) (2507/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.2046) | Acc: (92.00%) (3681/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.2148) | Acc: (92.00%) (4844/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.2164) | Acc: (92.00%) (6034/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.2153) | Acc: (92.00%) (7225/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.2145) | Acc: (92.00%) (8403/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.2118) | Acc: (92.00%) (9605/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.2105) | Acc: (92.00%) (10797/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.2070) | Acc: (92.00%) (12003/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.2064) | Acc: (92.00%) (13196/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.2057) | Acc: (92.00%) (14383/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.2036) | Acc: (92.00%) (15591/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.2016) | Acc: (93.00%) (16791/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1994) | Acc: (93.00%) (18001/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1975) | Acc: (93.00%) (19197/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1944) | Acc: (93.00%) (20416/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1945) | Acc: (93.00%) (21611/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1923) | Acc: (93.00%) (22827/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1918) | Acc: (93.00%) (24031/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1905) | Acc: (93.00%) (25227/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1892) | Acc: (93.00%) (26445/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1892) | Acc: (93.00%) (27650/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1901) | Acc: (93.00%) (28831/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1892) | Acc: (93.00%) (30033/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1888) | Acc: (93.00%) (31238/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1868) | Acc: (93.00%) (32455/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1865) | Acc: (93.00%) (33649/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1854) | Acc: (93.00%) (34860/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1856) | Acc: (93.00%) (36051/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1854) | Acc: (93.00%) (37249/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1845) | Acc: (93.00%) (38458/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1839) | Acc: (93.00%) (39655/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1839) | Acc: (93.00%) (40847/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1842) | Acc: (93.00%) (42042/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1841) | Acc: (93.00%) (43245/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1842) | Acc: (93.00%) (44443/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1834) | Acc: (93.00%) (45658/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1831) | Acc: (93.00%) (46815/50000)
# TEST : Loss: (0.3034) | Acc: (90.00%) (9043/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9998e-01, -2.0405e-01,  2.3692e-02],
          [-4.9443e-02,  3.6955e-01,  2.4699e-01],
          [ 1.2582e-01,  8.2636e-02, -4.7883e-02]],

         [[-2.0293e-01,  2.1625e-01,  1.7689e-01],
          [ 3.9477e-02,  4.1749e-01,  2.2384e-01],
          [ 2.2024e-01,  1.5419e-02,  8.9879e-02]],

         [[-2.1074e-01, -7.1634e-02, -9.2157e-02],
          [-2.9551e-01, -1.2664e-01, -1.2512e-01],
          [-2.1528e-01, -1.4316e-01, -1.9445e-01]]],


        [[[ 2.8632e-40,  1.4125e-40, -3.7307e-40],
          [ 1.6535e-40, -3.8447e-40,  4.3623e-40],
          [-2.4028e-40,  9.1573e-41,  5.0593e-40]],

         [[ 2.4703e-40, -3.0259e-40,  6.2880e-41],
          [ 3.2258e-40,  5.6570e-40, -2.1182e-40],
          [-1.6880e-40,  1.7973e-40,  1.6705e-40]],

         [[-3.3173e-40, -2.7633e-40, -1.4438e-40],
          [ 2.9631e-40,  2.4226e-41, -1.1338e-40],
          [ 1.3730e-40,  3.1000e-40, -4.3581e-40]]],


        [[[ 4.8266e-02,  1.1681e-01, -3.5020e-02],
          [ 4.6300e-02,  2.0517e-01, -8.5859e-02],
          [ 1.5567e-01,  3.2975e-01,  3.4251e-01]],

         [[-1.9307e-01, -8.9688e-02, -1.5957e-01],
          [-3.8027e-01, -3.7021e-01, -3.0165e-01],
          [-2.4695e-01, -4.2063e-01,  3.6547e-02]],

         [[ 2.5380e-01,  1.4833e-01,  2.0813e-01],
          [ 2.1729e-01,  1.2754e-01,  3.2324e-02],
          [ 1.0113e-01,  1.0005e-01,  2.0582e-02]]],


        ...,


        [[[ 2.0533e-01,  3.8345e-02,  8.6535e-02],
          [ 1.3937e-01, -2.4990e-01, -6.1127e-02],
          [ 5.9494e-02, -1.0925e-01, -5.4816e-02]],

         [[-4.5615e-02, -3.3988e-02,  5.8718e-02],
          [-1.0355e-01, -2.4600e-01,  2.2673e-02],
          [ 3.8817e-02,  1.1179e-01,  1.8242e-01]],

         [[-6.7045e-02, -1.0962e-01,  7.3694e-02],
          [-6.9975e-02, -2.2986e-01, -1.3261e-01],
          [-2.2853e-02, -9.5014e-02, -5.7904e-02]]],


        [[[ 9.5712e-02,  2.1427e-01,  2.9685e-01],
          [ 1.4113e-01,  1.5885e-01,  5.5877e-02],
          [-2.1885e-01, -1.4958e-01, -5.4338e-02]],

         [[ 2.8642e-02,  4.1286e-02, -9.6894e-02],
          [ 2.4556e-02, -6.1896e-02, -2.3836e-01],
          [-1.1839e-03,  1.0467e-01, -6.9638e-03]],

         [[-2.6840e-01, -1.1703e-01, -1.8213e-01],
          [-1.2380e-01,  8.1192e-02,  9.4602e-02],
          [ 1.4465e-01,  3.0033e-01,  2.4261e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -2.6114e-40],
          [ 6.0479e-40,  6.7571e-42, -4.6665e-40],
          [-2.3151e-40, -4.6258e-41, -5.1959e-41]],

         [[-4.1536e-40,  8.2529e-41, -3.5817e-40],
          [ 3.8896e-41,  2.4718e-40,  2.7585e-40],
          [ 1.1724e-40, -5.8556e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.7677e-41,  4.0958e-40],
          [-1.7484e-40, -5.7161e-40,  1.8641e-40],
          [-9.4647e-41, -7.9518e-41, -5.0727e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0250]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0158]], device='cuda:0')

Epoch: 135 | Batch_idx: 0 |  Loss: (0.1685) | Acc: (93.00%) (120/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1589) | Acc: (94.00%) (1336/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1582) | Acc: (94.00%) (2544/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1573) | Acc: (94.00%) (3761/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1605) | Acc: (94.00%) (4969/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1625) | Acc: (94.00%) (6179/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1625) | Acc: (94.00%) (7388/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1581) | Acc: (94.00%) (8613/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1590) | Acc: (94.00%) (9823/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1605) | Acc: (94.00%) (11030/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1612) | Acc: (94.00%) (12240/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1617) | Acc: (94.00%) (13447/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1641) | Acc: (94.00%) (14644/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1637) | Acc: (94.00%) (15862/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1622) | Acc: (94.00%) (17076/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1643) | Acc: (94.00%) (18275/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1651) | Acc: (94.00%) (19474/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1638) | Acc: (94.00%) (20688/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1643) | Acc: (94.00%) (21888/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1644) | Acc: (94.00%) (23096/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1642) | Acc: (94.00%) (24302/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1652) | Acc: (94.00%) (25495/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1654) | Acc: (94.00%) (26699/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1653) | Acc: (94.00%) (27905/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1648) | Acc: (94.00%) (29120/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1649) | Acc: (94.00%) (30328/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1648) | Acc: (94.00%) (31538/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1646) | Acc: (94.00%) (32748/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1649) | Acc: (94.00%) (33952/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1647) | Acc: (94.00%) (35160/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1646) | Acc: (94.00%) (36371/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1647) | Acc: (94.00%) (37584/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1650) | Acc: (94.00%) (38787/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1653) | Acc: (94.00%) (39991/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1655) | Acc: (94.00%) (41200/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1653) | Acc: (94.00%) (42414/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1653) | Acc: (94.00%) (43632/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1651) | Acc: (94.00%) (44838/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1654) | Acc: (94.00%) (46042/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1659) | Acc: (94.00%) (47200/50000)
# TEST : Loss: (0.2945) | Acc: (90.00%) (9050/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9918e-01, -2.0316e-01,  2.3584e-02],
          [-4.9228e-02,  3.6780e-01,  2.4576e-01],
          [ 1.2526e-01,  8.2248e-02, -4.7654e-02]],

         [[-2.0209e-01,  2.1529e-01,  1.7608e-01],
          [ 3.9304e-02,  4.1557e-01,  2.2278e-01],
          [ 2.1927e-01,  1.5350e-02,  8.9468e-02]],

         [[-2.0977e-01, -7.1303e-02, -9.1738e-02],
          [-2.9415e-01, -1.2606e-01, -1.2455e-01],
          [-2.1431e-01, -1.4252e-01, -1.9359e-01]]],


        [[[-1.3400e-40,  1.4126e-40,  1.8735e-40],
          [-1.1486e-40, -1.0426e-40,  2.9613e-40],
          [-1.0018e-40, -1.8864e-40,  3.6585e-40]],

         [[ 2.4704e-40, -2.2380e-41, -2.1734e-40],
          [ 3.2259e-40,  2.8549e-40, -7.1720e-41],
          [-2.8700e-41,  1.7974e-40,  2.6940e-41]],

         [[-4.7185e-40,  3.8774e-42, -5.6472e-40],
          [ 2.9633e-40,  1.6434e-40,  4.4706e-40],
          [-1.4292e-40,  3.1001e-40,  1.2463e-40]]],


        [[[ 4.8166e-02,  1.1656e-01, -3.4947e-02],
          [ 4.6204e-02,  2.0475e-01, -8.5682e-02],
          [ 1.5534e-01,  3.2906e-01,  3.4180e-01]],

         [[-1.9262e-01, -8.9480e-02, -1.5921e-01],
          [-3.7936e-01, -3.6933e-01, -3.0094e-01],
          [-2.4635e-01, -4.1963e-01,  3.6463e-02]],

         [[ 2.5320e-01,  1.4798e-01,  2.0764e-01],
          [ 2.1676e-01,  1.2722e-01,  3.2247e-02],
          [ 1.0088e-01,  9.9810e-02,  2.0533e-02]]],


        ...,


        [[[ 2.0273e-01,  3.7851e-02,  8.5453e-02],
          [ 1.3753e-01, -2.4645e-01, -6.0311e-02],
          [ 5.8754e-02, -1.0783e-01, -5.4098e-02]],

         [[-4.4897e-02, -3.3409e-02,  5.7826e-02],
          [-1.0169e-01, -2.4094e-01,  2.2270e-02],
          [ 3.8226e-02,  1.0988e-01,  1.7948e-01]],

         [[-6.5625e-02, -1.0673e-01,  7.2179e-02],
          [-6.7905e-02, -2.1758e-01, -1.2864e-01],
          [-2.2374e-02, -9.2406e-02, -5.6611e-02]]],


        [[[ 9.4717e-02,  2.1172e-01,  2.9361e-01],
          [ 1.3962e-01,  1.5694e-01,  5.5243e-02],
          [-2.1650e-01, -1.4790e-01, -5.3735e-02]],

         [[ 2.8288e-02,  4.0793e-02, -9.5724e-02],
          [ 2.4253e-02, -6.1181e-02, -2.3551e-01],
          [-1.1697e-03,  1.0355e-01, -6.8861e-03]],

         [[-2.6475e-01, -1.1560e-01, -1.7981e-01],
          [-1.2224e-01,  8.0289e-02,  9.3484e-02],
          [ 1.4295e-01,  2.9726e-01,  2.4001e-01]]],


        [[[-3.2265e-41,  5.6510e-41,  2.9938e-40],
          [ 4.6466e-40,  1.4689e-40, -6.0678e-40],
          [ 1.8888e-40, -3.2652e-40,  8.8171e-41]],

         [[-2.7523e-40,  3.6279e-40,  6.2223e-41],
          [ 1.7903e-40,  1.0705e-40,  2.7585e-40],
          [-3.0315e-40, -4.4543e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.1794e-40,  2.6945e-40],
          [-3.1497e-40, -1.5122e-40,  4.6667e-40],
          [-2.3478e-40, -3.5978e-40,  1.3506e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0088]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0088]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 136 | Batch_idx: 0 |  Loss: (0.2236) | Acc: (92.00%) (119/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1645) | Acc: (94.00%) (1330/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1749) | Acc: (94.00%) (2527/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1848) | Acc: (93.00%) (3721/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1971) | Acc: (93.00%) (4900/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.2017) | Acc: (93.00%) (6086/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.2080) | Acc: (93.00%) (7267/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.2113) | Acc: (92.00%) (8443/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.2173) | Acc: (92.00%) (9606/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.2199) | Acc: (92.00%) (10788/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.2257) | Acc: (92.00%) (11937/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.2292) | Acc: (92.00%) (13116/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.2332) | Acc: (92.00%) (14271/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.2369) | Acc: (92.00%) (15433/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.2365) | Acc: (92.00%) (16608/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.2349) | Acc: (92.00%) (17801/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.2367) | Acc: (92.00%) (18974/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.2356) | Acc: (92.00%) (20159/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.2354) | Acc: (92.00%) (21340/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.2344) | Acc: (92.00%) (22535/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.2335) | Acc: (92.00%) (23717/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.2334) | Acc: (92.00%) (24893/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.2327) | Acc: (92.00%) (26071/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.2347) | Acc: (92.00%) (27240/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.2345) | Acc: (92.00%) (28416/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.2340) | Acc: (92.00%) (29593/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.2352) | Acc: (92.00%) (30757/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.2365) | Acc: (91.00%) (31909/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.2368) | Acc: (91.00%) (33081/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.2381) | Acc: (91.00%) (34245/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.2377) | Acc: (91.00%) (35420/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.2370) | Acc: (91.00%) (36613/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.2368) | Acc: (91.00%) (37785/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.2369) | Acc: (91.00%) (38957/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.2354) | Acc: (92.00%) (40157/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.2350) | Acc: (92.00%) (41338/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.2338) | Acc: (92.00%) (42529/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.2333) | Acc: (92.00%) (43717/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.2334) | Acc: (92.00%) (44892/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.2334) | Acc: (92.00%) (46016/50000)
# TEST : Loss: (0.3549) | Acc: (88.00%) (8893/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8421e-01, -1.8940e-01,  3.3033e-02],
          [-4.0952e-02,  3.8622e-01,  2.5761e-01],
          [ 1.1714e-01,  7.5968e-02, -5.2100e-02]],

         [[-1.8772e-01,  2.2467e-01,  1.7790e-01],
          [ 4.9361e-02,  4.3225e-01,  2.3152e-01],
          [ 2.1413e-01,  1.1353e-02,  8.6602e-02]],

         [[-2.0319e-01, -6.3155e-02, -8.6600e-02],
          [-2.9177e-01, -1.1339e-01, -1.1532e-01],
          [-2.2250e-01, -1.4454e-01, -1.9276e-01]]],


        [[[-4.1423e-40,  1.1491e-42,  6.0769e-40],
          [-2.5498e-40,  3.1607e-40, -1.2420e-40],
          [ 1.8004e-40, -3.2876e-40, -1.9460e-40]],

         [[-3.3176e-41,  2.5785e-40, -2.1735e-40],
          [ 4.2379e-41, -2.7495e-40,  2.0850e-40],
          [ 1.1141e-40,  3.9630e-41, -1.1317e-40]],

         [[-1.9164e-40,  2.8410e-40, -4.2462e-40],
          [ 1.6107e-41,  1.6434e-40,  5.8719e-40],
          [-2.8304e-40,  2.9787e-41,  5.4498e-40]]],


        [[[ 4.9101e-02,  1.1531e-01, -3.5041e-02],
          [ 4.3127e-02,  1.9838e-01, -9.5943e-02],
          [ 1.4620e-01,  3.1400e-01,  3.2849e-01]],

         [[-1.9643e-01, -9.8026e-02, -1.6458e-01],
          [-3.8952e-01, -3.8356e-01, -3.1402e-01],
          [-2.5602e-01, -4.3657e-01,  2.7365e-02]],

         [[ 2.4912e-01,  1.4531e-01,  2.0759e-01],
          [ 2.0970e-01,  1.1791e-01,  2.3404e-02],
          [ 9.5314e-02,  8.8511e-02,  1.6392e-02]]],


        ...,


        [[[ 1.9427e-01,  3.5130e-02,  8.1690e-02],
          [ 1.2053e-01, -2.5840e-01, -5.7217e-02],
          [ 5.5596e-02, -9.6405e-02, -2.9330e-02]],

         [[-5.6811e-02, -3.4708e-02,  5.9002e-02],
          [-1.1593e-01, -2.4959e-01,  3.5158e-02],
          [ 4.1151e-02,  1.3042e-01,  2.1199e-01]],

         [[-8.4868e-02, -1.1759e-01,  6.0422e-02],
          [-9.2462e-02, -2.3135e-01, -1.1558e-01],
          [-2.8387e-02, -6.7460e-02, -2.2446e-02]]],


        [[[ 9.1908e-02,  1.8957e-01,  2.6976e-01],
          [ 1.3053e-01,  1.2641e-01,  2.5743e-02],
          [-2.4070e-01, -1.8113e-01, -7.1623e-02]],

         [[ 4.1444e-03,  2.5266e-03, -1.3458e-01],
          [-5.0628e-03, -1.0876e-01, -2.8452e-01],
          [-4.8592e-02,  4.8014e-02, -5.0583e-02]],

         [[-2.9677e-01, -1.5404e-01, -2.2060e-01],
          [-1.5313e-01,  3.5492e-02,  4.4361e-02],
          [ 9.7884e-02,  2.4808e-01,  2.0247e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  5.7964e-40],
          [-9.5863e-41,  1.4689e-40, -1.8639e-40],
          [ 4.6914e-40, -3.2652e-40,  8.8171e-41]],

         [[ 1.4516e-40,  2.2266e-40,  4.8261e-40],
          [ 1.7903e-40, -1.7321e-40, -4.4057e-42],
          [-4.4328e-40,  1.1509e-40,  3.8970e-41]],

         [[ 4.9483e-41, -3.1794e-40, -1.5094e-40],
          [-1.7484e-40,  4.0930e-40,  3.2654e-40],
          [-9.4647e-41, -2.1965e-40,  1.3506e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0180,  0.0183,  0.0142],
          [ 0.0185,  0.0117,  0.0166],
          [ 0.0208,  0.0088,  0.0122]],

         [[ 0.0014,  0.0029,  0.0011],
          [ 0.0046,  0.0015,  0.0065],
          [ 0.0101,  0.0019,  0.0060]],

         [[ 0.0039,  0.0046,  0.0003],
          [ 0.0081,  0.0040,  0.0055],
          [ 0.0137,  0.0062,  0.0069]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0856, -0.0738, -0.0738],
          [-0.0846, -0.0759, -0.0767],
          [-0.0717, -0.0657, -0.0668]],

         [[-0.0694, -0.0579, -0.0573],
          [-0.0696, -0.0605, -0.0619],
          [-0.0583, -0.0506, -0.0522]],

         [[-0.0580, -0.0502, -0.0494],
          [-0.0579, -0.0501, -0.0530],
          [-0.0495, -0.0404, -0.0433]]],


        ...,


        [[[ 0.0071,  0.0028,  0.0109],
          [ 0.0079,  0.0028,  0.0091],
          [ 0.0089,  0.0035,  0.0093]],

         [[ 0.0036, -0.0006,  0.0070],
          [ 0.0045, -0.0002,  0.0056],
          [ 0.0047, -0.0005,  0.0049]],

         [[ 0.0062,  0.0028,  0.0085],
          [ 0.0077,  0.0033,  0.0068],
          [ 0.0078,  0.0023,  0.0056]]],


        [[[-0.0038, -0.0039, -0.0030],
          [-0.0029, -0.0033, -0.0026],
          [-0.0026, -0.0032, -0.0016]],

         [[-0.0023, -0.0025, -0.0019],
          [-0.0020, -0.0025, -0.0023],
          [-0.0022, -0.0029, -0.0016]],

         [[-0.0013, -0.0015, -0.0012],
          [-0.0011, -0.0015, -0.0016],
          [-0.0014, -0.0018, -0.0006]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0082]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 137 | Batch_idx: 0 |  Loss: (0.2474) | Acc: (91.00%) (117/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1832) | Acc: (94.00%) (1327/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1928) | Acc: (93.00%) (2518/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1972) | Acc: (93.00%) (3705/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1984) | Acc: (93.00%) (4890/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1963) | Acc: (93.00%) (6088/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1938) | Acc: (93.00%) (7291/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1893) | Acc: (93.00%) (8505/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1916) | Acc: (93.00%) (9685/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1942) | Acc: (93.00%) (10870/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1976) | Acc: (93.00%) (12053/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1963) | Acc: (93.00%) (13248/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1973) | Acc: (93.00%) (14444/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1967) | Acc: (93.00%) (15646/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1963) | Acc: (93.00%) (16842/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1992) | Acc: (93.00%) (18020/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1995) | Acc: (93.00%) (19205/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1991) | Acc: (93.00%) (20395/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.2011) | Acc: (93.00%) (21568/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.2013) | Acc: (93.00%) (22751/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.2025) | Acc: (93.00%) (23943/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.2012) | Acc: (93.00%) (25150/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.2003) | Acc: (93.00%) (26340/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.2007) | Acc: (93.00%) (27531/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.2001) | Acc: (93.00%) (28733/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.2006) | Acc: (93.00%) (29915/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.2007) | Acc: (93.00%) (31111/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.2006) | Acc: (93.00%) (32303/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.2005) | Acc: (93.00%) (33499/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1999) | Acc: (93.00%) (34709/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1994) | Acc: (93.00%) (35904/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1988) | Acc: (93.00%) (37102/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1991) | Acc: (93.00%) (38287/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1993) | Acc: (93.00%) (39469/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1984) | Acc: (93.00%) (40668/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1976) | Acc: (93.00%) (41871/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1977) | Acc: (93.00%) (43067/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1973) | Acc: (93.00%) (44267/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1975) | Acc: (93.00%) (45465/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1976) | Acc: (93.00%) (46615/50000)
# TEST : Loss: (0.3705) | Acc: (88.00%) (8894/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9474e-01, -1.9974e-01,  2.8417e-02],
          [-4.9818e-02,  3.7619e-01,  2.5076e-01],
          [ 1.0584e-01,  6.5886e-02, -5.9656e-02]],

         [[-2.0076e-01,  2.1241e-01,  1.7452e-01],
          [ 3.7741e-02,  4.2104e-01,  2.2486e-01],
          [ 2.0116e-01,  2.8420e-03,  7.8286e-02]],

         [[-2.2024e-01, -7.8566e-02, -9.1456e-02],
          [-3.0613e-01, -1.2684e-01, -1.1986e-01],
          [-2.3809e-01, -1.5534e-01, -1.9845e-01]]],


        [[[-2.7412e-40, -1.3897e-40,  4.6759e-40],
          [-1.1487e-40,  4.5620e-40, -4.0443e-40],
          [ 3.2015e-40, -1.8865e-40, -6.1495e-40]],

         [[-3.1340e-40,  2.5785e-40,  6.2879e-41],
          [-2.3785e-40, -5.5519e-40,  2.0850e-40],
          [ 1.1142e-40, -1.0049e-40, -1.1317e-40]],

         [[ 2.2871e-40,  2.8411e-40,  1.3583e-40],
          [-2.6413e-40,  2.4226e-41,  1.6685e-40],
          [-1.4292e-40, -2.5045e-40,  4.0487e-40]]],


        [[[ 3.1136e-02,  1.1144e-01, -2.9593e-02],
          [ 3.7981e-02,  2.0225e-01, -8.8673e-02],
          [ 1.4754e-01,  3.2367e-01,  3.4270e-01]],

         [[-2.1291e-01, -1.0049e-01, -1.6127e-01],
          [-3.9804e-01, -3.8270e-01, -3.1073e-01],
          [-2.5836e-01, -4.3026e-01,  3.6238e-02]],

         [[ 2.3463e-01,  1.4527e-01,  2.0791e-01],
          [ 2.0065e-01,  1.1903e-01,  2.2458e-02],
          [ 8.9116e-02,  9.0978e-02,  1.8794e-02]]],


        ...,


        [[[ 1.9547e-01,  3.6973e-02,  8.1975e-02],
          [ 1.2764e-01, -2.5501e-01, -5.4839e-02],
          [ 5.5727e-02, -1.0425e-01, -3.9439e-02]],

         [[-6.3941e-02, -4.5039e-02,  4.3788e-02],
          [-1.1205e-01, -2.5893e-01,  2.2376e-02],
          [ 3.5093e-02,  1.0837e-01,  1.8720e-01]],

         [[-1.0080e-01, -1.3817e-01,  4.0743e-02],
          [-9.3626e-02, -2.5270e-01, -1.2748e-01],
          [-4.2260e-02, -9.9713e-02, -4.9446e-02]]],


        [[[ 9.6900e-02,  2.1259e-01,  2.8617e-01],
          [ 1.2926e-01,  1.3805e-01,  3.2347e-02],
          [-2.4703e-01, -1.7469e-01, -7.2012e-02]],

         [[ 9.7108e-03,  3.1072e-02, -1.0584e-01],
          [-5.8656e-03, -9.0146e-02, -2.6551e-01],
          [-6.4686e-02,  4.9013e-02, -5.0041e-02]],

         [[-2.9923e-01, -1.3747e-01, -2.0363e-01],
          [-1.5513e-01,  4.8698e-02,  5.7453e-02],
          [ 8.1106e-02,  2.4912e-01,  2.0390e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  2.9938e-40],
          [-5.1625e-40,  6.7571e-42,  3.7413e-40],
          [ 3.2901e-40, -4.6258e-41, -5.1959e-41]],

         [[ 4.2542e-40, -1.9773e-40,  4.8261e-40],
          [ 3.8896e-41, -3.1334e-40, -2.8467e-40],
          [-1.6302e-40,  5.3548e-40,  1.7910e-40]],

         [[-2.3078e-40, -3.7677e-41, -4.3120e-40],
          [ 1.0542e-40,  5.4943e-40, -9.3845e-41],
          [ 1.8561e-40,  2.0074e-40, -5.0727e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0310, -0.0273, -0.0239],
          [-0.0271, -0.0302, -0.0345],
          [-0.0424, -0.0486, -0.0498]],

         [[-0.0759, -0.0647, -0.0512],
          [-0.0669, -0.0576, -0.0485],
          [-0.0759, -0.0624, -0.0470]],

         [[-0.0629, -0.0540, -0.0436],
          [-0.0555, -0.0473, -0.0368],
          [-0.0590, -0.0443, -0.0280]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0201, -0.0038,  0.0154],
          [-0.0197,  0.0089,  0.0383],
          [ 0.0299,  0.0523,  0.0557]],

         [[-0.0025,  0.0095,  0.0214],
          [-0.0010,  0.0217,  0.0481],
          [ 0.0334,  0.0397,  0.0360]],

         [[ 0.0017,  0.0100,  0.0177],
          [-0.0005,  0.0206,  0.0448],
          [ 0.0253,  0.0316,  0.0297]]],


        ...,


        [[[-0.0151, -0.0126, -0.0056],
          [-0.0011, -0.0024, -0.0020],
          [-0.0011, -0.0077, -0.0126]],

         [[-0.0146, -0.0104, -0.0016],
          [-0.0010, -0.0023,  0.0006],
          [ 0.0025, -0.0026, -0.0022]],

         [[-0.0098, -0.0057,  0.0031],
          [ 0.0024,  0.0005,  0.0034],
          [ 0.0064,  0.0016,  0.0022]]],


        [[[-0.0088, -0.0074, -0.0101],
          [-0.0098, -0.0111, -0.0170],
          [-0.0107, -0.0115, -0.0169]],

         [[-0.0006,  0.0032,  0.0019],
          [ 0.0022,  0.0035,  0.0005],
          [ 0.0071,  0.0075,  0.0039]],

         [[ 0.0038,  0.0078,  0.0078],
          [ 0.0072,  0.0099,  0.0085],
          [ 0.0137,  0.0152,  0.0128]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0082]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1763) | Acc: (92.00%) (118/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1794) | Acc: (93.00%) (1313/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.2008) | Acc: (92.00%) (2498/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.2142) | Acc: (92.00%) (3670/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.2234) | Acc: (92.00%) (4837/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.2253) | Acc: (92.00%) (6020/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.2226) | Acc: (92.00%) (7216/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.2228) | Acc: (92.00%) (8390/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.2235) | Acc: (92.00%) (9570/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.2213) | Acc: (92.00%) (10762/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.2185) | Acc: (92.00%) (11959/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.2171) | Acc: (92.00%) (13156/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.2152) | Acc: (92.00%) (14344/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.2134) | Acc: (92.00%) (15543/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.2147) | Acc: (92.00%) (16722/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.2142) | Acc: (92.00%) (17916/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.2117) | Acc: (92.00%) (19126/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.2088) | Acc: (92.00%) (20337/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.2063) | Acc: (93.00%) (21547/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.2048) | Acc: (93.00%) (22753/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.2022) | Acc: (93.00%) (23967/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.2027) | Acc: (93.00%) (25155/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.2023) | Acc: (93.00%) (26350/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.2023) | Acc: (93.00%) (27541/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.2010) | Acc: (93.00%) (28742/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1999) | Acc: (93.00%) (29943/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1998) | Acc: (93.00%) (31145/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1988) | Acc: (93.00%) (32357/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1971) | Acc: (93.00%) (33577/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1967) | Acc: (93.00%) (34782/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1963) | Acc: (93.00%) (35977/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1951) | Acc: (93.00%) (37190/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1942) | Acc: (93.00%) (38397/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1939) | Acc: (93.00%) (39601/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1937) | Acc: (93.00%) (40794/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1936) | Acc: (93.00%) (41989/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1932) | Acc: (93.00%) (43191/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1923) | Acc: (93.00%) (44411/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1921) | Acc: (93.00%) (45615/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1914) | Acc: (93.00%) (46779/50000)
# TEST : Loss: (0.2994) | Acc: (90.00%) (9022/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8979e-01, -1.9478e-01,  3.3685e-02],
          [-4.5148e-02,  3.7904e-01,  2.5605e-01],
          [ 1.1114e-01,  7.1777e-02, -5.1688e-02]],

         [[-1.9323e-01,  2.1776e-01,  1.8004e-01],
          [ 4.4276e-02,  4.2480e-01,  2.2976e-01],
          [ 2.0781e-01,  8.8170e-03,  8.3932e-02]],

         [[-2.1360e-01, -7.3439e-02, -8.6185e-02],
          [-2.9905e-01, -1.2212e-01, -1.1536e-01],
          [-2.3084e-01, -1.5022e-01, -1.9382e-01]]],


        [[[ 1.4623e-40, -1.3897e-40, -9.2870e-41],
          [ 1.6536e-40,  1.7597e-40, -2.6432e-40],
          [ 1.8004e-40,  9.1586e-41, -4.7484e-40]],

         [[-3.1341e-40, -2.2379e-41,  3.4311e-40],
          [-2.3786e-40, -2.7496e-40, -7.1730e-41],
          [-2.8699e-41, -1.0049e-40,  2.6946e-41]],

         [[ 3.6883e-40,  3.8774e-42,  5.5619e-40],
          [-2.6413e-40, -1.1589e-40, -3.9363e-40],
          [ 1.3731e-40, -2.5045e-40, -1.5559e-40]]],


        [[[ 3.2621e-02,  1.1294e-01, -2.8333e-02],
          [ 3.9686e-02,  2.0297e-01, -8.8451e-02],
          [ 1.4811e-01,  3.2357e-01,  3.4247e-01]],

         [[-2.1185e-01, -9.9119e-02, -1.6017e-01],
          [-3.9628e-01, -3.8154e-01, -3.1084e-01],
          [-2.5723e-01, -4.2877e-01,  3.6787e-02]],

         [[ 2.3423e-01,  1.4591e-01,  2.0807e-01],
          [ 2.0083e-01,  1.1902e-01,  2.1305e-02],
          [ 8.9276e-02,  9.1289e-02,  1.8929e-02]]],


        ...,


        [[[ 1.9624e-01,  3.9096e-02,  8.2509e-02],
          [ 1.2565e-01, -2.5180e-01, -5.3844e-02],
          [ 5.4502e-02, -1.0193e-01, -3.6260e-02]],

         [[-5.9826e-02, -4.1779e-02,  4.4119e-02],
          [-1.1037e-01, -2.5365e-01,  2.2187e-02],
          [ 3.4147e-02,  1.0783e-01,  1.8625e-01]],

         [[-9.6134e-02, -1.3343e-01,  3.9791e-02],
          [-9.3089e-02, -2.4305e-01, -1.2588e-01],
          [-4.3714e-02, -9.8281e-02, -4.8463e-02]]],


        [[[ 9.7553e-02,  2.1203e-01,  2.8528e-01],
          [ 1.3065e-01,  1.4054e-01,  3.6895e-02],
          [-2.4020e-01, -1.6664e-01, -6.4962e-02]],

         [[ 8.3865e-03,  2.9101e-02, -1.0634e-01],
          [-7.3460e-03, -8.9875e-02, -2.6289e-01],
          [-6.6189e-02,  4.7356e-02, -5.0399e-02]],

         [[-2.9749e-01, -1.3849e-01, -2.0436e-01],
          [-1.5621e-01,  4.5081e-02,  5.3118e-02],
          [ 7.5191e-02,  2.4249e-01,  1.9724e-01]]],


        [[[-3.2265e-41,  5.6510e-41, -2.6114e-40],
          [-3.7612e-40, -1.3337e-40,  5.1426e-40],
          [-9.1376e-41,  2.3400e-40, -1.9209e-40]],

         [[ 2.8529e-40, -4.7799e-40,  6.2223e-41],
          [-1.0123e-40, -1.7321e-40, -2.8467e-40],
          [ 2.5737e-40,  3.9535e-40,  1.7910e-40]],

         [[-2.3078e-40,  2.4258e-40, -2.9107e-40],
          [ 2.4555e-40,  1.2904e-40, -3.7410e-40],
          [ 3.2574e-40,  4.8100e-40, -1.4520e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0122]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0009]], device='cuda:0')

Epoch: 139 | Batch_idx: 0 |  Loss: (0.1321) | Acc: (96.00%) (123/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.2026) | Acc: (92.00%) (1306/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1843) | Acc: (93.00%) (2518/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1841) | Acc: (93.00%) (3726/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1809) | Acc: (93.00%) (4927/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1789) | Acc: (94.00%) (6145/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1770) | Acc: (94.00%) (7347/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1740) | Acc: (94.00%) (8557/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1741) | Acc: (94.00%) (9760/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1740) | Acc: (94.00%) (10961/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1724) | Acc: (94.00%) (12173/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1706) | Acc: (94.00%) (13380/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1704) | Acc: (94.00%) (14582/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1711) | Acc: (94.00%) (15789/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1700) | Acc: (94.00%) (17006/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1712) | Acc: (94.00%) (18194/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1703) | Acc: (94.00%) (19415/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1687) | Acc: (94.00%) (20636/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1694) | Acc: (94.00%) (21832/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1693) | Acc: (94.00%) (23046/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1688) | Acc: (94.00%) (24261/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1673) | Acc: (94.00%) (25487/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1674) | Acc: (94.00%) (26697/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1667) | Acc: (94.00%) (27905/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1662) | Acc: (94.00%) (29117/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1665) | Acc: (94.00%) (30328/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1670) | Acc: (94.00%) (31521/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1671) | Acc: (94.00%) (32728/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1669) | Acc: (94.00%) (33934/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1676) | Acc: (94.00%) (35133/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1680) | Acc: (94.00%) (36329/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1677) | Acc: (94.00%) (37540/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1670) | Acc: (94.00%) (38756/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1669) | Acc: (94.00%) (39962/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1670) | Acc: (94.00%) (41172/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1660) | Acc: (94.00%) (42394/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1658) | Acc: (94.00%) (43604/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1657) | Acc: (94.00%) (44824/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1650) | Acc: (94.00%) (46042/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1654) | Acc: (94.00%) (47198/50000)
# TEST : Loss: (0.2883) | Acc: (90.00%) (9060/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8902e-01, -1.9392e-01,  3.3531e-02],
          [-4.4955e-02,  3.7725e-01,  2.5480e-01],
          [ 1.1067e-01,  7.1449e-02, -5.1452e-02]],

         [[-1.9242e-01,  2.1678e-01,  1.7922e-01],
          [ 4.4085e-02,  4.2285e-01,  2.2868e-01],
          [ 2.0692e-01,  8.7778e-03,  8.3558e-02]],

         [[-2.1264e-01, -7.3102e-02, -8.5795e-02],
          [-2.9771e-01, -1.2157e-01, -1.1484e-01],
          [-2.2983e-01, -1.4957e-01, -1.9298e-01]]],


        [[[ 4.2647e-40,  1.1533e-42, -5.1323e-40],
          [ 3.0549e-40, -2.4439e-40,  1.5603e-40],
          [-1.0019e-40,  2.3171e-40,  8.5638e-41]],

         [[-3.3173e-41, -3.0262e-40,  3.4312e-40],
          [ 4.2378e-41,  2.8552e-40, -2.1185e-40],
          [-1.6882e-40,  3.9629e-41,  1.6707e-40]],

         [[ 8.8596e-41, -2.7636e-40,  4.1607e-40],
          [ 1.6104e-41, -1.1590e-40, -5.3375e-40],
          [ 2.7743e-40,  2.9786e-41, -5.7596e-40]]],


        [[[ 3.2556e-02,  1.1272e-01, -2.8276e-02],
          [ 3.9605e-02,  2.0256e-01, -8.8271e-02],
          [ 1.4780e-01,  3.2292e-01,  3.4177e-01]],

         [[-2.1139e-01, -9.8906e-02, -1.5983e-01],
          [-3.9539e-01, -3.8069e-01, -3.1016e-01],
          [-2.5666e-01, -4.2782e-01,  3.6707e-02]],

         [[ 2.3371e-01,  1.4559e-01,  2.0761e-01],
          [ 2.0037e-01,  1.1875e-01,  2.1257e-02],
          [ 8.9076e-02,  9.1084e-02,  1.8887e-02]]],


        ...,


        [[[ 1.9388e-01,  3.8608e-02,  8.1573e-02],
          [ 1.2397e-01, -2.4819e-01, -5.3153e-02],
          [ 5.3843e-02, -1.0064e-01, -3.5831e-02]],

         [[-5.8981e-02, -4.1124e-02,  4.3538e-02],
          [-1.0839e-01, -2.4813e-01,  2.1822e-02],
          [ 3.3666e-02,  1.0611e-01,  1.8367e-01]],

         [[-9.4437e-02, -1.3052e-01,  3.9151e-02],
          [-9.0612e-02, -2.3156e-01, -1.2297e-01],
          [-4.2942e-02, -9.6133e-02, -4.7638e-02]]],


        [[[ 9.6304e-02,  2.0895e-01,  2.8138e-01],
          [ 1.2896e-01,  1.3849e-01,  3.6389e-02],
          [-2.3694e-01, -1.6421e-01, -6.4044e-02]],

         [[ 8.2524e-03,  2.8623e-02, -1.0461e-01],
          [-7.2290e-03, -8.8428e-02, -2.5867e-01],
          [-6.5122e-02,  4.6621e-02, -4.9595e-02]],

         [[-2.9222e-01, -1.3612e-01, -2.0077e-01],
          [-1.5363e-01,  4.4377e-02,  5.2262e-02],
          [ 7.4012e-02,  2.3898e-01,  1.9425e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -5.4140e-40],
          [ 1.8440e-40, -1.3337e-40,  9.3869e-41],
          [-3.7164e-40,  2.3400e-40, -1.9209e-40]],

         [[-1.3510e-40, -3.3786e-40, -3.5817e-40],
          [-1.0123e-40,  1.0705e-40, -4.4057e-42],
          [ 3.9750e-40, -1.6517e-40,  3.8970e-41]],

         [[ 4.9483e-41,  2.4258e-40,  1.2932e-40],
          [ 1.0542e-40, -4.3148e-40, -2.3397e-40],
          [ 1.8561e-40,  3.4087e-40, -1.4520e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0125]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0096]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 140 | Batch_idx: 0 |  Loss: (0.2018) | Acc: (94.00%) (121/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1759) | Acc: (93.00%) (1323/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1896) | Acc: (93.00%) (2512/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.2063) | Acc: (92.00%) (3690/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.2161) | Acc: (92.00%) (4860/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.2208) | Acc: (92.00%) (6040/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.2207) | Acc: (92.00%) (7222/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.2204) | Acc: (92.00%) (8410/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.2271) | Acc: (92.00%) (9566/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.2278) | Acc: (92.00%) (10744/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.2307) | Acc: (92.00%) (11910/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.2292) | Acc: (92.00%) (13106/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.2324) | Acc: (92.00%) (14267/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.2362) | Acc: (91.00%) (15417/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.2365) | Acc: (91.00%) (16597/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.2354) | Acc: (91.00%) (17767/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.2345) | Acc: (91.00%) (18949/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.2353) | Acc: (91.00%) (20114/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.2352) | Acc: (91.00%) (21286/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.2332) | Acc: (91.00%) (22477/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.2347) | Acc: (91.00%) (23646/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.2356) | Acc: (91.00%) (24816/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.2353) | Acc: (91.00%) (25997/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.2346) | Acc: (91.00%) (27185/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.2337) | Acc: (91.00%) (28371/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.2339) | Acc: (91.00%) (29551/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.2346) | Acc: (91.00%) (30716/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.2342) | Acc: (91.00%) (31897/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.2340) | Acc: (91.00%) (33070/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.2341) | Acc: (91.00%) (34248/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.2349) | Acc: (91.00%) (35415/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.2342) | Acc: (91.00%) (36601/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.2338) | Acc: (91.00%) (37784/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.2330) | Acc: (91.00%) (38975/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.2329) | Acc: (91.00%) (40150/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.2326) | Acc: (91.00%) (41333/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.2332) | Acc: (91.00%) (42503/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.2332) | Acc: (91.00%) (43687/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.2328) | Acc: (92.00%) (44888/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.2331) | Acc: (92.00%) (46014/50000)
# TEST : Loss: (0.3733) | Acc: (88.00%) (8838/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8155e-01, -1.9355e-01,  2.9829e-02],
          [-3.5371e-02,  3.8443e-01,  2.5733e-01],
          [ 1.1525e-01,  6.9275e-02, -5.1758e-02]],

         [[-1.8663e-01,  2.1116e-01,  1.6823e-01],
          [ 4.9005e-02,  4.2406e-01,  2.2292e-01],
          [ 2.1003e-01,  7.3338e-03,  7.8332e-02]],

         [[-2.1476e-01, -8.4640e-02, -9.9284e-02],
          [-3.0451e-01, -1.3292e-01, -1.2901e-01],
          [-2.3432e-01, -1.6101e-01, -2.0403e-01]]],


        [[[ 2.8635e-40,  1.4127e-40, -3.7311e-40],
          [ 1.6537e-40, -3.8451e-40,  4.3628e-40],
          [-2.4032e-40,  9.1589e-41,  5.0600e-40]],

         [[ 2.4707e-40, -3.0262e-40,  6.2878e-41],
          [ 3.2262e-40,  5.6577e-40, -7.1735e-41],
          [-1.6882e-40,  1.7975e-40,  1.6707e-40]],

         [[-3.3177e-40, -2.7637e-40, -1.4441e-40],
          [ 2.9635e-40,  2.4227e-41, -1.1339e-40],
          [ 1.3731e-40,  3.1003e-40, -4.3584e-40]]],


        [[[ 2.9978e-02,  1.0874e-01, -2.7746e-02],
          [ 3.5772e-02,  1.9894e-01, -9.3652e-02],
          [ 1.5223e-01,  3.2556e-01,  3.4310e-01]],

         [[-2.0691e-01, -9.7681e-02, -1.5567e-01],
          [-3.9965e-01, -3.8726e-01, -3.1858e-01],
          [-2.5313e-01, -4.2768e-01,  3.7194e-02]],

         [[ 2.3750e-01,  1.5077e-01,  2.1289e-01],
          [ 2.0072e-01,  1.2060e-01,  1.9096e-02],
          [ 9.3918e-02,  9.3859e-02,  2.0853e-02]]],


        ...,


        [[[ 1.9693e-01,  3.8687e-02,  1.0337e-01],
          [ 1.3296e-01, -2.4729e-01, -3.6255e-02],
          [ 6.1757e-02, -1.0524e-01, -2.8609e-02]],

         [[-6.7567e-02, -6.2208e-02,  4.4863e-02],
          [-1.1015e-01, -2.7506e-01,  9.8178e-03],
          [ 3.6630e-02,  8.8268e-02,  1.7388e-01]],

         [[-8.3191e-02, -1.3419e-01,  5.3994e-02],
          [-6.1730e-02, -2.2764e-01, -1.1034e-01],
          [-1.9359e-02, -8.7353e-02, -3.5717e-02]]],


        [[[ 1.0372e-01,  2.2423e-01,  3.0698e-01],
          [ 1.2654e-01,  1.4798e-01,  5.7124e-02],
          [-2.4478e-01, -1.5868e-01, -5.5177e-02]],

         [[ 1.0983e-02,  3.8276e-02, -7.8563e-02],
          [-1.5735e-02, -8.2462e-02, -2.3384e-01],
          [-7.3594e-02,  5.1171e-02, -3.4837e-02]],

         [[-2.7281e-01, -1.1896e-01, -1.7150e-01],
          [-1.5040e-01,  5.2413e-02,  7.4297e-02],
          [ 7.1415e-02,  2.4440e-01,  2.0688e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -2.6114e-40],
          [ 6.0479e-40,  6.7571e-42, -4.6665e-40],
          [-2.3151e-40, -4.6258e-41, -5.1959e-41]],

         [[-4.1536e-40,  8.2529e-41, -3.5817e-40],
          [ 3.8896e-41,  2.4718e-40,  2.7585e-40],
          [ 1.1724e-40, -5.8556e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.7677e-41,  4.0958e-40],
          [-1.7484e-40, -5.7161e-40,  1.8641e-40],
          [-9.4647e-41, -7.9518e-41, -5.0727e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0251,  0.0246,  0.0193],
          [ 0.0277,  0.0211,  0.0154],
          [ 0.0178,  0.0150,  0.0151]],

         [[ 0.0309,  0.0329,  0.0283],
          [ 0.0324,  0.0289,  0.0244],
          [ 0.0246,  0.0252,  0.0243]],

         [[ 0.0258,  0.0270,  0.0252],
          [ 0.0272,  0.0234,  0.0213],
          [ 0.0202,  0.0210,  0.0228]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0536,  0.0505,  0.0434],
          [ 0.0608,  0.0511,  0.0617],
          [ 0.0500,  0.0517,  0.0538]],

         [[ 0.0464,  0.0418,  0.0289],
          [ 0.0484,  0.0386,  0.0442],
          [ 0.0329,  0.0350,  0.0354]],

         [[ 0.0350,  0.0265,  0.0121],
          [ 0.0419,  0.0286,  0.0262],
          [ 0.0293,  0.0272,  0.0182]]],


        ...,


        [[[ 0.0078,  0.0087,  0.0054],
          [ 0.0028,  0.0034,  0.0005],
          [ 0.0033,  0.0028, -0.0008]],

         [[ 0.0080,  0.0091,  0.0088],
          [ 0.0035,  0.0048,  0.0047],
          [ 0.0055,  0.0061,  0.0045]],

         [[ 0.0034,  0.0040,  0.0042],
          [-0.0007,  0.0003,  0.0008],
          [ 0.0021,  0.0025,  0.0018]]],


        [[[ 0.0019, -0.0008, -0.0006],
          [ 0.0016, -0.0011,  0.0002],
          [ 0.0014,  0.0003,  0.0019]],

         [[ 0.0018,  0.0007,  0.0014],
          [ 0.0023,  0.0013,  0.0026],
          [ 0.0032,  0.0030,  0.0041]],

         [[ 0.0018,  0.0029,  0.0038],
          [ 0.0023,  0.0034,  0.0050],
          [ 0.0041,  0.0053,  0.0066]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0148]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 141 | Batch_idx: 0 |  Loss: (0.1700) | Acc: (93.00%) (120/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1863) | Acc: (94.00%) (1324/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.2141) | Acc: (92.00%) (2492/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1970) | Acc: (93.00%) (3695/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.2000) | Acc: (92.00%) (4878/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1964) | Acc: (93.00%) (6082/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1936) | Acc: (93.00%) (7286/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1960) | Acc: (93.00%) (8470/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1955) | Acc: (93.00%) (9668/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1968) | Acc: (93.00%) (10862/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1982) | Acc: (93.00%) (12042/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1990) | Acc: (93.00%) (13221/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1983) | Acc: (93.00%) (14417/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1977) | Acc: (93.00%) (15609/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1984) | Acc: (93.00%) (16792/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1986) | Acc: (93.00%) (17991/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1993) | Acc: (93.00%) (19178/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1978) | Acc: (93.00%) (20381/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1975) | Acc: (93.00%) (21589/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1968) | Acc: (93.00%) (22788/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1992) | Acc: (93.00%) (23959/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1988) | Acc: (93.00%) (25159/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1986) | Acc: (93.00%) (26350/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1983) | Acc: (93.00%) (27561/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1990) | Acc: (93.00%) (28748/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1989) | Acc: (93.00%) (29940/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1989) | Acc: (93.00%) (31133/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1984) | Acc: (93.00%) (32338/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1976) | Acc: (93.00%) (33540/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1971) | Acc: (93.00%) (34740/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1969) | Acc: (93.00%) (35933/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1967) | Acc: (93.00%) (37127/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1966) | Acc: (93.00%) (38326/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1965) | Acc: (93.00%) (39520/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1956) | Acc: (93.00%) (40735/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1963) | Acc: (93.00%) (41925/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1967) | Acc: (93.00%) (43108/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1966) | Acc: (93.00%) (44301/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1962) | Acc: (93.00%) (45499/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1963) | Acc: (93.00%) (46639/50000)
# TEST : Loss: (0.3507) | Acc: (89.00%) (8931/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9218e-01, -2.0106e-01,  1.4443e-02],
          [-5.0572e-02,  3.8331e-01,  2.4891e-01],
          [ 9.1234e-02,  6.1725e-02, -6.4371e-02]],

         [[-1.9555e-01,  2.0737e-01,  1.5405e-01],
          [ 3.4808e-02,  4.2375e-01,  2.1386e-01],
          [ 1.8784e-01, -4.9956e-04,  6.5026e-02]],

         [[-2.2102e-01, -8.8715e-02, -1.1097e-01],
          [-3.1443e-01, -1.3566e-01, -1.3767e-01],
          [-2.4965e-01, -1.6817e-01, -2.1219e-01]]],


        [[[-1.3401e-40,  1.4128e-40,  1.8738e-40],
          [-1.1488e-40, -1.0427e-40,  2.9616e-40],
          [-1.0020e-40, -1.8866e-40,  3.6588e-40]],

         [[ 2.4707e-40, -2.2382e-41, -2.1737e-40],
          [ 3.2262e-40,  2.8552e-40,  2.0851e-40],
          [-2.8696e-41,  1.7975e-40,  2.6948e-41]],

         [[-4.7190e-40,  3.8788e-42, -5.6478e-40],
          [ 2.9635e-40,  1.6435e-40,  4.4710e-40],
          [-1.4293e-40,  3.1003e-40,  1.2465e-40]]],


        [[[ 2.8520e-02,  1.0152e-01, -3.8197e-02],
          [ 3.8108e-02,  1.9918e-01, -9.5993e-02],
          [ 1.5197e-01,  3.2199e-01,  3.4378e-01]],

         [[-2.0423e-01, -1.0358e-01, -1.6408e-01],
          [-3.9656e-01, -3.8838e-01, -3.2045e-01],
          [-2.5167e-01, -4.3046e-01,  4.0918e-02]],

         [[ 2.4526e-01,  1.5301e-01,  2.1023e-01],
          [ 2.0584e-01,  1.2359e-01,  1.7642e-02],
          [ 9.6308e-02,  9.1630e-02,  2.1491e-02]]],


        ...,


        [[[ 1.9289e-01,  3.6686e-02,  9.3625e-02],
          [ 1.2177e-01, -2.4765e-01, -4.0982e-02],
          [ 5.0330e-02, -1.0872e-01, -3.9103e-02]],

         [[-6.5089e-02, -5.7708e-02,  4.0853e-02],
          [-1.0876e-01, -2.5969e-01,  1.2497e-02],
          [ 3.0547e-02,  8.9905e-02,  1.6463e-01]],

         [[-9.7557e-02, -1.4667e-01,  3.1548e-02],
          [-8.3527e-02, -2.4406e-01, -1.3117e-01],
          [-4.1584e-02, -1.0693e-01, -6.6705e-02]]],


        [[[ 8.0666e-02,  2.0505e-01,  2.8389e-01],
          [ 1.1033e-01,  1.3619e-01,  3.6201e-02],
          [-2.4361e-01, -1.5447e-01, -6.4380e-02]],

         [[-2.0893e-02,  1.6174e-02, -1.0244e-01],
          [-3.7090e-02, -9.8992e-02, -2.5996e-01],
          [-8.3914e-02,  4.1729e-02, -5.7744e-02]],

         [[-3.0616e-01, -1.4815e-01, -2.0124e-01],
          [-1.7517e-01,  2.6311e-02,  3.9702e-02],
          [ 4.7469e-02,  2.2157e-01,  1.7621e-01]]],


        [[[-3.2265e-41,  5.6510e-41,  2.9938e-40],
          [ 4.6466e-40,  1.4689e-40, -6.0678e-40],
          [ 1.8888e-40, -3.2652e-40,  8.8171e-41]],

         [[-2.7523e-40,  3.6279e-40,  6.2223e-41],
          [ 1.7903e-40,  1.0705e-40,  2.7585e-40],
          [-3.0315e-40, -4.4543e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.1794e-40,  2.6945e-40],
          [-3.1497e-40, -1.5122e-40,  4.6667e-40],
          [-2.3478e-40, -3.5978e-40,  1.3506e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0147,  0.0019,  0.0063],
          [ 0.0204,  0.0143,  0.0209],
          [ 0.0269,  0.0299,  0.0324]],

         [[ 0.0153,  0.0022,  0.0080],
          [ 0.0157,  0.0079,  0.0157],
          [ 0.0192,  0.0186,  0.0243]],

         [[ 0.0123, -0.0022,  0.0036],
          [ 0.0112,  0.0030,  0.0130],
          [ 0.0162,  0.0149,  0.0229]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0029, -0.0118,  0.0191],
          [-0.0081, -0.0099,  0.0145],
          [-0.0031, -0.0011,  0.0278]],

         [[-0.0073, -0.0073,  0.0326],
          [-0.0124, -0.0067,  0.0228],
          [-0.0051,  0.0022,  0.0309]],

         [[-0.0074, -0.0066,  0.0265],
          [-0.0124, -0.0085,  0.0115],
          [-0.0107, -0.0051,  0.0180]]],


        ...,


        [[[-0.0020,  0.0021, -0.0028],
          [-0.0053, -0.0014, -0.0074],
          [-0.0064, -0.0039, -0.0099]],

         [[-0.0037, -0.0000, -0.0047],
          [-0.0051, -0.0012, -0.0072],
          [-0.0057, -0.0027, -0.0083]],

         [[-0.0019,  0.0013, -0.0025],
          [-0.0026,  0.0004, -0.0044],
          [-0.0026, -0.0003, -0.0045]]],


        [[[ 0.0027,  0.0021,  0.0016],
          [ 0.0030,  0.0027,  0.0015],
          [ 0.0024,  0.0021,  0.0002]],

         [[ 0.0011, -0.0002, -0.0005],
          [ 0.0016,  0.0007, -0.0001],
          [ 0.0021,  0.0014, -0.0000]],

         [[ 0.0024,  0.0013,  0.0010],
          [ 0.0029,  0.0021,  0.0013],
          [ 0.0028,  0.0022,  0.0009]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0147]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 142 | Batch_idx: 0 |  Loss: (0.2609) | Acc: (92.00%) (119/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1874) | Acc: (93.00%) (1322/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.2161) | Acc: (92.00%) (2497/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.2300) | Acc: (92.00%) (3662/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.2367) | Acc: (92.00%) (4839/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.2326) | Acc: (92.00%) (6020/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.2239) | Acc: (92.00%) (7222/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.2219) | Acc: (92.00%) (8409/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.2219) | Acc: (92.00%) (9580/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.2181) | Acc: (92.00%) (10779/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.2138) | Acc: (92.00%) (11978/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.2107) | Acc: (92.00%) (13186/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.2111) | Acc: (92.00%) (14383/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.2084) | Acc: (92.00%) (15587/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.2064) | Acc: (93.00%) (16795/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.2050) | Acc: (93.00%) (17994/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.2040) | Acc: (93.00%) (19192/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.2020) | Acc: (93.00%) (20401/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.2010) | Acc: (93.00%) (21594/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.2000) | Acc: (93.00%) (22795/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1998) | Acc: (93.00%) (23994/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1965) | Acc: (93.00%) (25217/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1971) | Acc: (93.00%) (26411/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1962) | Acc: (93.00%) (27609/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1943) | Acc: (93.00%) (28828/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1933) | Acc: (93.00%) (30041/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1918) | Acc: (93.00%) (31258/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1906) | Acc: (93.00%) (32474/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1903) | Acc: (93.00%) (33667/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1898) | Acc: (93.00%) (34864/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1889) | Acc: (93.00%) (36076/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1885) | Acc: (93.00%) (37280/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1892) | Acc: (93.00%) (38477/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1886) | Acc: (93.00%) (39680/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1877) | Acc: (93.00%) (40894/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1867) | Acc: (93.00%) (42096/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1862) | Acc: (93.00%) (43304/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1855) | Acc: (93.00%) (44504/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1850) | Acc: (93.00%) (45722/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1851) | Acc: (93.00%) (46877/50000)
# TEST : Loss: (0.3033) | Acc: (90.00%) (9037/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9467e-01, -2.0187e-01,  1.2652e-02],
          [-5.4166e-02,  3.7939e-01,  2.4452e-01],
          [ 8.6046e-02,  5.7263e-02, -6.8746e-02]],

         [[-1.9774e-01,  2.0552e-01,  1.5209e-01],
          [ 3.1188e-02,  4.2057e-01,  2.1053e-01],
          [ 1.8252e-01, -3.7882e-03,  6.0679e-02]],

         [[-2.2205e-01, -8.8544e-02, -1.1116e-01],
          [-3.1559e-01, -1.3585e-01, -1.3877e-01],
          [-2.5279e-01, -1.7015e-01, -2.1492e-01]]],


        [[[-4.1426e-40,  1.1561e-42,  6.0775e-40],
          [-2.5500e-40,  3.1610e-40, -1.2421e-40],
          [ 1.8005e-40, -3.2878e-40, -1.9461e-40]],

         [[-3.3174e-41,  2.5787e-40, -2.1737e-40],
          [ 4.2378e-41, -2.7497e-40,  2.0851e-40],
          [ 1.1143e-40,  3.9626e-41, -1.1318e-40]],

         [[-1.9165e-40,  2.8413e-40, -4.2466e-40],
          [ 1.6102e-41,  1.6436e-40,  5.8723e-40],
          [-2.8306e-40,  2.9785e-41,  5.4503e-40]]],


        [[[ 3.1188e-02,  1.0419e-01, -3.6132e-02],
          [ 4.1159e-02,  2.0283e-01, -9.2243e-02],
          [ 1.5371e-01,  3.2482e-01,  3.4643e-01]],

         [[-2.0190e-01, -1.0191e-01, -1.6398e-01],
          [-3.9343e-01, -3.8484e-01, -3.1791e-01],
          [-2.5028e-01, -4.2760e-01,  4.2643e-02]],

         [[ 2.4576e-01,  1.5294e-01,  2.0846e-01],
          [ 2.0687e-01,  1.2513e-01,  1.8661e-02],
          [ 9.6375e-02,  9.2624e-02,  2.2470e-02]]],


        ...,


        [[[ 1.9220e-01,  3.7260e-02,  9.3694e-02],
          [ 1.2069e-01, -2.4369e-01, -3.8834e-02],
          [ 4.9648e-02, -1.0681e-01, -3.6469e-02]],

         [[-6.1350e-02, -5.4908e-02,  4.1917e-02],
          [-1.0596e-01, -2.5332e-01,  1.3873e-02],
          [ 3.0213e-02,  8.8733e-02,  1.6415e-01]],

         [[-9.2939e-02, -1.4103e-01,  3.2473e-02],
          [-8.1889e-02, -2.3265e-01, -1.2715e-01],
          [-4.2070e-02, -1.0555e-01, -6.4899e-02]]],


        [[[ 8.1329e-02,  2.0391e-01,  2.8169e-01],
          [ 1.1057e-01,  1.3594e-01,  3.7237e-02],
          [-2.3968e-01, -1.5115e-01, -6.1790e-02]],

         [[-1.9625e-02,  1.6580e-02, -1.0064e-01],
          [-3.5555e-02, -9.6773e-02, -2.5584e-01],
          [-8.2436e-02,  4.1334e-02, -5.6524e-02]],

         [[-2.9986e-01, -1.4458e-01, -1.9710e-01],
          [-1.7148e-01,  2.6677e-02,  3.9421e-02],
          [ 4.7007e-02,  2.1870e-01,  1.7394e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  5.7964e-40],
          [-9.5863e-41,  1.4689e-40, -1.8639e-40],
          [ 4.6914e-40, -3.2652e-40,  8.8171e-41]],

         [[ 1.4516e-40,  2.2266e-40,  4.8261e-40],
          [ 1.7903e-40, -1.7321e-40, -4.4057e-42],
          [-4.4328e-40,  1.1509e-40,  3.8970e-41]],

         [[ 4.9483e-41, -3.1794e-40, -1.5094e-40],
          [-1.7484e-40,  4.0930e-40,  3.2654e-40],
          [-9.4647e-41, -2.1965e-40,  1.3506e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0017]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0002]], device='cuda:0')

Epoch: 143 | Batch_idx: 0 |  Loss: (0.1367) | Acc: (96.00%) (124/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1399) | Acc: (95.00%) (1343/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1428) | Acc: (95.00%) (2560/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1536) | Acc: (94.00%) (3768/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1583) | Acc: (94.00%) (4972/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1587) | Acc: (94.00%) (6184/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1562) | Acc: (94.00%) (7405/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1570) | Acc: (94.00%) (8616/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1571) | Acc: (94.00%) (9826/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1550) | Acc: (94.00%) (11049/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1576) | Acc: (94.00%) (12254/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1565) | Acc: (94.00%) (13473/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1568) | Acc: (94.00%) (14680/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1573) | Acc: (94.00%) (15889/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1567) | Acc: (94.00%) (17111/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1589) | Acc: (94.00%) (18303/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1588) | Acc: (94.00%) (19517/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1594) | Acc: (94.00%) (20723/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1607) | Acc: (94.00%) (21930/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1603) | Acc: (94.00%) (23143/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1604) | Acc: (94.00%) (24356/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1608) | Acc: (94.00%) (25565/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1596) | Acc: (94.00%) (26785/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1594) | Acc: (94.00%) (28001/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1599) | Acc: (94.00%) (29211/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1591) | Acc: (94.00%) (30437/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1597) | Acc: (94.00%) (31645/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1606) | Acc: (94.00%) (32844/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1613) | Acc: (94.00%) (34050/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1602) | Acc: (94.00%) (35273/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1602) | Acc: (94.00%) (36487/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1596) | Acc: (94.00%) (37705/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1600) | Acc: (94.00%) (38919/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1604) | Acc: (94.00%) (40120/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1607) | Acc: (94.00%) (41321/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1606) | Acc: (94.00%) (42531/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1606) | Acc: (94.00%) (43734/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1607) | Acc: (94.00%) (44943/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1613) | Acc: (94.00%) (46145/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1609) | Acc: (94.00%) (47330/50000)
# TEST : Loss: (0.2977) | Acc: (90.00%) (9043/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9392e-01, -2.0104e-01,  1.2599e-02],
          [-5.3943e-02,  3.7770e-01,  2.4340e-01],
          [ 8.5691e-02,  5.7009e-02, -6.8442e-02]],

         [[-1.9695e-01,  2.0466e-01,  1.5145e-01],
          [ 3.1057e-02,  4.1873e-01,  2.0960e-01],
          [ 1.8175e-01, -3.7715e-03,  6.0415e-02]],

         [[-2.2107e-01, -8.8160e-02, -1.1069e-01],
          [-3.1420e-01, -1.3525e-01, -1.3818e-01],
          [-2.5168e-01, -1.6940e-01, -2.1400e-01]]],


        [[[-2.7414e-40, -1.3897e-40,  4.6763e-40],
          [-1.1488e-40,  4.5623e-40, -4.0446e-40],
          [ 3.2018e-40, -1.8866e-40, -6.1499e-40]],

         [[-3.1343e-40,  2.5787e-40,  6.2880e-41],
          [-2.3787e-40, -5.5522e-40, -7.1737e-41],
          [ 1.1143e-40, -1.0050e-40, -1.1318e-40]],

         [[ 2.2872e-40,  2.8413e-40,  1.3584e-40],
          [-2.6415e-40,  2.4230e-41,  1.6686e-40],
          [-1.4293e-40, -2.5047e-40,  4.0491e-40]]],


        [[[ 3.1123e-02,  1.0397e-01, -3.6056e-02],
          [ 4.1073e-02,  2.0241e-01, -9.2051e-02],
          [ 1.5338e-01,  3.2414e-01,  3.4572e-01]],

         [[-2.0144e-01, -1.0167e-01, -1.6361e-01],
          [-3.9251e-01, -3.8394e-01, -3.1718e-01],
          [-2.4970e-01, -4.2663e-01,  4.2549e-02]],

         [[ 2.4520e-01,  1.5259e-01,  2.0799e-01],
          [ 2.0639e-01,  1.2484e-01,  1.8618e-02],
          [ 9.6150e-02,  9.2409e-02,  2.2419e-02]]],


        ...,


        [[[ 1.8944e-01,  3.6712e-02,  9.2370e-02],
          [ 1.1881e-01, -2.3955e-01, -3.8220e-02],
          [ 4.8918e-02, -1.0514e-01, -3.5927e-02]],

         [[-6.0241e-02, -5.3809e-02,  4.1200e-02],
          [-1.0368e-01, -2.4631e-01,  1.3587e-02],
          [ 2.9683e-02,  8.6916e-02,  1.6129e-01]],

         [[-9.0745e-02, -1.3694e-01,  3.1762e-02],
          [-7.9227e-02, -2.1787e-01, -1.2335e-01],
          [-4.1130e-02, -1.0255e-01, -6.3481e-02]]],


        [[[ 8.0260e-02,  2.0071e-01,  2.7726e-01],
          [ 1.0913e-01,  1.3390e-01,  3.6681e-02],
          [-2.3635e-01, -1.4881e-01, -6.0836e-02]],

         [[-1.9269e-02,  1.6265e-02, -9.8725e-02],
          [-3.4921e-02, -9.4994e-02, -2.5114e-01],
          [-8.0884e-02,  4.0563e-02, -5.5467e-02]],

         [[-2.9374e-01, -1.4170e-01, -1.9309e-01],
          [-1.6815e-01,  2.6178e-02,  3.8675e-02],
          [ 4.6091e-02,  2.1471e-01,  1.7072e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  2.9938e-40],
          [-5.1625e-40,  6.7571e-42,  3.7413e-40],
          [ 3.2901e-40, -4.6258e-41, -5.1959e-41]],

         [[ 4.2542e-40, -1.9773e-40,  4.8261e-40],
          [ 3.8896e-41, -3.1334e-40, -2.8467e-40],
          [-1.6302e-40,  5.3548e-40,  1.7910e-40]],

         [[-2.3078e-40, -3.7677e-41, -4.3120e-40],
          [ 1.0542e-40,  5.4943e-40, -9.3845e-41],
          [ 1.8561e-40,  2.0074e-40, -5.0727e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0014]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0189]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1615) | Acc: (96.00%) (123/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1768) | Acc: (93.00%) (1321/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1838) | Acc: (93.00%) (2521/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1965) | Acc: (93.00%) (3706/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.2024) | Acc: (93.00%) (4893/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.2074) | Acc: (93.00%) (6076/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.2184) | Acc: (92.00%) (7241/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.2299) | Acc: (92.00%) (8394/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.2331) | Acc: (92.00%) (9566/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.2400) | Acc: (92.00%) (10721/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.2395) | Acc: (92.00%) (11896/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.2443) | Acc: (91.00%) (13043/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.2451) | Acc: (91.00%) (14216/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.2451) | Acc: (91.00%) (15384/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.2447) | Acc: (91.00%) (16556/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.2436) | Acc: (91.00%) (17732/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.2453) | Acc: (91.00%) (18902/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.2444) | Acc: (91.00%) (20079/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.2452) | Acc: (91.00%) (21250/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.2432) | Acc: (91.00%) (22433/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.2410) | Acc: (91.00%) (23625/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.2421) | Acc: (91.00%) (24789/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.2413) | Acc: (91.00%) (25969/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.2417) | Acc: (91.00%) (27150/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.2420) | Acc: (91.00%) (28323/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.2412) | Acc: (91.00%) (29504/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.2411) | Acc: (91.00%) (30685/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.2411) | Acc: (91.00%) (31865/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.2418) | Acc: (91.00%) (33033/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.2412) | Acc: (91.00%) (34215/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.2406) | Acc: (91.00%) (35403/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.2396) | Acc: (91.00%) (36587/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.2398) | Acc: (91.00%) (37766/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.2389) | Acc: (91.00%) (38946/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.2387) | Acc: (91.00%) (40122/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.2388) | Acc: (91.00%) (41294/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.2382) | Acc: (91.00%) (42480/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.2380) | Acc: (91.00%) (43659/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.2376) | Acc: (91.00%) (44838/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.2371) | Acc: (91.00%) (45977/50000)
# TEST : Loss: (0.3523) | Acc: (89.00%) (8910/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9375e-01, -1.9305e-01,  3.4178e-02],
          [-4.0781e-02,  3.9349e-01,  2.6838e-01],
          [ 9.7288e-02,  6.0457e-02, -6.4786e-02]],

         [[-1.8883e-01,  2.2210e-01,  1.7912e-01],
          [ 4.7568e-02,  4.3784e-01,  2.3639e-01],
          [ 1.9651e-01,  6.7037e-03,  6.8030e-02]],

         [[-2.0686e-01, -6.5440e-02, -7.9785e-02],
          [-2.9629e-01, -1.1488e-01, -1.0979e-01],
          [-2.3838e-01, -1.5800e-01, -2.0316e-01]]],


        [[[ 1.4624e-40, -1.3897e-40, -9.2868e-41],
          [ 1.6537e-40,  1.7598e-40, -2.6434e-40],
          [ 1.8005e-40,  9.1594e-41, -4.7487e-40]],

         [[-3.1343e-40, -2.2379e-41,  3.4313e-40],
          [-2.3787e-40, -2.7497e-40, -2.1186e-40],
          [-2.8693e-41, -1.0050e-40,  2.6951e-41]],

         [[ 3.6885e-40,  3.8788e-42,  5.5622e-40],
          [-2.6415e-40, -1.1590e-40, -3.9364e-40],
          [ 1.3732e-40, -2.5047e-40, -1.5560e-40]]],


        [[[ 2.6765e-02,  1.0007e-01, -4.0337e-02],
          [ 3.4153e-02,  2.0076e-01, -9.6128e-02],
          [ 1.5339e-01,  3.2575e-01,  3.4314e-01]],

         [[-2.0004e-01, -1.0316e-01, -1.6393e-01],
          [-3.9746e-01, -3.9001e-01, -3.2358e-01],
          [-2.5031e-01, -4.3384e-01,  3.1627e-02]],

         [[ 2.5223e-01,  1.5823e-01,  2.1149e-01],
          [ 2.0544e-01,  1.2234e-01,  1.0987e-02],
          [ 9.5844e-02,  8.3835e-02,  6.1889e-03]]],


        ...,


        [[[ 2.0140e-01,  3.3885e-02,  1.0094e-01],
          [ 1.2761e-01, -2.4370e-01, -2.2726e-02],
          [ 4.6057e-02, -1.1876e-01, -2.7286e-02]],

         [[-3.8016e-02, -5.1206e-02,  5.2070e-02],
          [-8.7458e-02, -2.4324e-01,  3.4734e-02],
          [ 3.1775e-02,  7.8531e-02,  1.7629e-01]],

         [[-8.0591e-02, -1.3968e-01,  3.9831e-02],
          [-7.3642e-02, -2.2261e-01, -9.6646e-02],
          [-4.7753e-02, -1.1799e-01, -4.8267e-02]]],


        [[[ 8.9606e-02,  2.1569e-01,  2.8360e-01],
          [ 1.1905e-01,  1.4745e-01,  3.5568e-02],
          [-2.2945e-01, -1.4117e-01, -6.9407e-02]],

         [[ 1.3588e-02,  6.1667e-02, -6.0669e-02],
          [ 4.2467e-03, -4.7333e-02, -2.2476e-01],
          [-4.3149e-02,  8.4330e-02, -3.0454e-02]],

         [[-2.7754e-01, -1.1888e-01, -1.7901e-01],
          [-1.3833e-01,  6.1740e-02,  5.3675e-02],
          [ 8.8597e-02,  2.6370e-01,  2.0378e-01]]],


        [[[-3.2265e-41,  5.6510e-41, -2.6114e-40],
          [-3.7612e-40, -1.3337e-40,  5.1426e-40],
          [-9.1376e-41,  2.3400e-40, -1.9209e-40]],

         [[ 2.8529e-40, -4.7799e-40,  6.2223e-41],
          [-1.0123e-40, -1.7321e-40, -2.8467e-40],
          [ 2.5737e-40,  3.9535e-40,  1.7910e-40]],

         [[-2.3078e-40,  2.4258e-40, -2.9107e-40],
          [ 2.4555e-40,  1.2904e-40, -3.7410e-40],
          [ 3.2574e-40,  4.8100e-40, -1.4520e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0315, -0.0278, -0.0193],
          [-0.0267, -0.0219, -0.0169],
          [-0.0191, -0.0138, -0.0135]],

         [[-0.0231, -0.0217, -0.0137],
          [-0.0191, -0.0157, -0.0103],
          [-0.0131, -0.0082, -0.0078]],

         [[-0.0196, -0.0173, -0.0095],
          [-0.0180, -0.0129, -0.0072],
          [-0.0145, -0.0073, -0.0057]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0809, -0.0690, -0.0440],
          [-0.0771, -0.0724, -0.0389],
          [-0.0813, -0.0868, -0.0526]],

         [[-0.0330, -0.0268, -0.0120],
          [-0.0318, -0.0319, -0.0094],
          [-0.0481, -0.0534, -0.0268]],

         [[ 0.0073,  0.0107,  0.0166],
          [ 0.0037,  0.0023,  0.0162],
          [-0.0137, -0.0176,  0.0003]]],


        ...,


        [[[-0.0077, -0.0087, -0.0033],
          [ 0.0003, -0.0011,  0.0025],
          [ 0.0002, -0.0038,  0.0000]],

         [[-0.0069, -0.0076, -0.0016],
          [ 0.0006, -0.0005,  0.0038],
          [ 0.0008, -0.0029,  0.0016]],

         [[-0.0051, -0.0051,  0.0004],
          [ 0.0007,  0.0002,  0.0045],
          [ 0.0013, -0.0017,  0.0027]]],


        [[[ 0.0022,  0.0024,  0.0009],
          [ 0.0027,  0.0029,  0.0016],
          [ 0.0046,  0.0041,  0.0012]],

         [[ 0.0052,  0.0053,  0.0035],
          [ 0.0063,  0.0065,  0.0048],
          [ 0.0090,  0.0084,  0.0050]],

         [[ 0.0068,  0.0072,  0.0058],
          [ 0.0078,  0.0081,  0.0068],
          [ 0.0099,  0.0098,  0.0071]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0039]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 145 | Batch_idx: 0 |  Loss: (0.2137) | Acc: (90.00%) (116/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1969) | Acc: (92.00%) (1302/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.2015) | Acc: (92.00%) (2494/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.2037) | Acc: (92.00%) (3680/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.2044) | Acc: (92.00%) (4871/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.2040) | Acc: (92.00%) (6056/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.2000) | Acc: (92.00%) (7254/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.2005) | Acc: (92.00%) (8444/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1991) | Acc: (93.00%) (9648/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.2007) | Acc: (92.00%) (10828/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1992) | Acc: (93.00%) (12026/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1973) | Acc: (93.00%) (13233/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.2009) | Acc: (93.00%) (14406/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1981) | Acc: (93.00%) (15604/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1968) | Acc: (93.00%) (16798/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1968) | Acc: (93.00%) (17991/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1959) | Acc: (93.00%) (19179/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1955) | Acc: (93.00%) (20365/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1953) | Acc: (93.00%) (21552/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1960) | Acc: (92.00%) (22734/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1956) | Acc: (93.00%) (23934/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1946) | Acc: (93.00%) (25141/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1950) | Acc: (93.00%) (26321/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1947) | Acc: (93.00%) (27515/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1952) | Acc: (93.00%) (28714/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1940) | Acc: (93.00%) (29923/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1953) | Acc: (93.00%) (31110/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1951) | Acc: (93.00%) (32300/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1950) | Acc: (93.00%) (33489/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1944) | Acc: (93.00%) (34694/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1942) | Acc: (93.00%) (35892/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1949) | Acc: (93.00%) (37076/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1955) | Acc: (93.00%) (38258/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1960) | Acc: (93.00%) (39446/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1960) | Acc: (93.00%) (40644/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1967) | Acc: (93.00%) (41826/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1966) | Acc: (93.00%) (43025/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1972) | Acc: (93.00%) (44210/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1972) | Acc: (93.00%) (45408/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1980) | Acc: (93.00%) (46541/50000)
# TEST : Loss: (0.3800) | Acc: (88.00%) (8849/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9056e-01, -1.9703e-01,  2.4344e-02],
          [-3.3768e-02,  4.0036e-01,  2.7222e-01],
          [ 1.1110e-01,  8.1468e-02, -4.6489e-02]],

         [[-1.8359e-01,  2.2038e-01,  1.7173e-01],
          [ 5.0753e-02,  4.3893e-01,  2.3320e-01],
          [ 2.0483e-01,  2.1138e-02,  7.9661e-02]],

         [[-2.0502e-01, -7.0155e-02, -9.3545e-02],
          [-2.9914e-01, -1.1997e-01, -1.1998e-01],
          [-2.3416e-01, -1.4878e-01, -1.9598e-01]]],


        [[[ 4.2650e-40,  1.1575e-42, -5.1325e-40],
          [ 3.0550e-40, -2.4440e-40,  1.5605e-40],
          [-1.0020e-40,  2.3172e-40,  8.5636e-41]],

         [[-3.3174e-41, -3.0263e-40,  3.4313e-40],
          [ 4.2377e-41,  2.8553e-40, -7.1737e-41],
          [-1.6882e-40,  3.9625e-41,  1.6708e-40]],

         [[ 8.8598e-41, -2.7637e-40,  4.1609e-40],
          [ 1.6102e-41, -1.1590e-40, -5.3377e-40],
          [ 2.7745e-40,  2.9787e-41, -5.7598e-40]]],


        [[[ 3.2987e-02,  1.0496e-01, -3.7887e-02],
          [ 3.9609e-02,  2.0615e-01, -9.3221e-02],
          [ 1.5617e-01,  3.2998e-01,  3.4964e-01]],

         [[-1.8736e-01, -9.1841e-02, -1.5580e-01],
          [-3.8676e-01, -3.8048e-01, -3.1574e-01],
          [-2.4597e-01, -4.3100e-01,  3.6802e-02]],

         [[ 2.6625e-01,  1.7433e-01,  2.2378e-01],
          [ 2.1948e-01,  1.3908e-01,  2.6149e-02],
          [ 1.0668e-01,  9.3700e-02,  1.7151e-02]]],


        ...,


        [[[ 1.8890e-01,  3.3241e-02,  1.0881e-01],
          [ 1.2795e-01, -2.4358e-01, -1.6598e-02],
          [ 5.3628e-02, -1.2669e-01, -3.5938e-02]],

         [[-6.2950e-02, -6.1450e-02,  5.6485e-02],
          [-9.1372e-02, -2.4066e-01,  4.6515e-02],
          [ 4.1004e-02,  7.4658e-02,  1.7510e-01]],

         [[-1.1489e-01, -1.5675e-01,  3.4833e-02],
          [-8.5569e-02, -2.1520e-01, -8.3101e-02],
          [-4.6811e-02, -1.2012e-01, -4.3182e-02]]],


        [[[ 1.0415e-01,  2.2876e-01,  2.9050e-01],
          [ 1.3399e-01,  1.6115e-01,  5.5212e-02],
          [-2.1349e-01, -1.3589e-01, -5.7807e-02]],

         [[ 2.6903e-02,  5.8519e-02, -7.0442e-02],
          [ 1.3610e-02, -4.7643e-02, -2.2208e-01],
          [-3.8113e-02,  7.1900e-02, -3.9807e-02]],

         [[-2.7069e-01, -1.3128e-01, -1.9154e-01],
          [-1.3717e-01,  5.2472e-02,  4.9463e-02],
          [ 9.0495e-02,  2.5135e-01,  1.9329e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -5.4140e-40],
          [ 1.8440e-40, -1.3337e-40,  9.3869e-41],
          [-3.7164e-40,  2.3400e-40, -1.9209e-40]],

         [[-1.3510e-40, -3.3786e-40, -3.5817e-40],
          [-1.0123e-40,  1.0705e-40, -4.4057e-42],
          [ 3.9750e-40, -1.6517e-40,  3.8970e-41]],

         [[ 4.9483e-41,  2.4258e-40,  1.2932e-40],
          [ 1.0542e-40, -4.3148e-40, -2.3397e-40],
          [ 1.8561e-40,  3.4087e-40, -1.4520e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0111,  0.0049,  0.0041],
          [ 0.0045,  0.0177,  0.0059],
          [ 0.0088,  0.0136,  0.0009]],

         [[-0.0197, -0.0018, -0.0001],
          [-0.0075,  0.0103,  0.0001],
          [-0.0068,  0.0029, -0.0106]],

         [[-0.0040,  0.0127,  0.0200],
          [ 0.0070,  0.0234,  0.0208],
          [ 0.0094,  0.0210,  0.0124]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0735,  0.0776,  0.0858],
          [ 0.0515,  0.0698,  0.0862],
          [ 0.0217,  0.0442,  0.0569]],

         [[ 0.0682,  0.0728,  0.0748],
          [ 0.0450,  0.0645,  0.0751],
          [ 0.0058,  0.0303,  0.0381]],

         [[ 0.0560,  0.0632,  0.0649],
          [ 0.0291,  0.0481,  0.0563],
          [-0.0039,  0.0130,  0.0209]]],


        ...,


        [[[-0.0008, -0.0004,  0.0006],
          [-0.0017, -0.0011,  0.0004],
          [ 0.0044,  0.0064,  0.0059]],

         [[ 0.0008,  0.0015,  0.0032],
          [-0.0005,  0.0003,  0.0025],
          [ 0.0049,  0.0071,  0.0079]],

         [[ 0.0027,  0.0021,  0.0024],
          [ 0.0008,  0.0005,  0.0005],
          [ 0.0026,  0.0033,  0.0029]]],


        [[[-0.0023, -0.0021, -0.0021],
          [ 0.0002,  0.0019,  0.0024],
          [-0.0002,  0.0027,  0.0036]],

         [[-0.0035, -0.0031, -0.0033],
          [-0.0024, -0.0004,  0.0003],
          [-0.0028,  0.0001,  0.0013]],

         [[-0.0029, -0.0030, -0.0032],
          [-0.0035, -0.0022, -0.0016],
          [-0.0031, -0.0011, -0.0002]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0039]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 146 | Batch_idx: 0 |  Loss: (0.1877) | Acc: (92.00%) (119/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1804) | Acc: (93.00%) (1321/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.2045) | Acc: (92.00%) (2493/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.2102) | Acc: (92.00%) (3676/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.2147) | Acc: (92.00%) (4854/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.2137) | Acc: (92.00%) (6047/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.2132) | Acc: (92.00%) (7243/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.2113) | Acc: (92.00%) (8437/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.2141) | Acc: (92.00%) (9606/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.2151) | Acc: (92.00%) (10785/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.2145) | Acc: (92.00%) (11979/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.2143) | Acc: (92.00%) (13174/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.2139) | Acc: (92.00%) (14370/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.2125) | Acc: (92.00%) (15566/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.2125) | Acc: (92.00%) (16750/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.2107) | Acc: (92.00%) (17937/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.2073) | Acc: (92.00%) (19153/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.2066) | Acc: (92.00%) (20348/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.2051) | Acc: (93.00%) (21551/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.2044) | Acc: (93.00%) (22739/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.2037) | Acc: (93.00%) (23938/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.2016) | Acc: (93.00%) (25139/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.2011) | Acc: (93.00%) (26333/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.2012) | Acc: (93.00%) (27528/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1999) | Acc: (93.00%) (28736/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1999) | Acc: (93.00%) (29922/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1994) | Acc: (93.00%) (31118/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1994) | Acc: (93.00%) (32313/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1989) | Acc: (93.00%) (33511/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1987) | Acc: (93.00%) (34716/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1978) | Acc: (93.00%) (35916/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1979) | Acc: (93.00%) (37103/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1963) | Acc: (93.00%) (38325/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1960) | Acc: (93.00%) (39529/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1943) | Acc: (93.00%) (40744/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1935) | Acc: (93.00%) (41952/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1932) | Acc: (93.00%) (43152/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1932) | Acc: (93.00%) (44351/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1931) | Acc: (93.00%) (45544/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1926) | Acc: (93.00%) (46712/50000)
# TEST : Loss: (0.3124) | Acc: (90.00%) (9020/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9200e-01, -1.9979e-01,  2.2455e-02],
          [-3.6793e-02,  3.9457e-01,  2.6979e-01],
          [ 1.0819e-01,  7.8809e-02, -4.6669e-02]],

         [[-1.8494e-01,  2.1585e-01,  1.6836e-01],
          [ 4.7990e-02,  4.3304e-01,  2.3014e-01],
          [ 2.0271e-01,  1.9047e-02,  7.8672e-02]],

         [[-2.0773e-01, -7.4706e-02, -9.7638e-02],
          [-3.0163e-01, -1.2438e-01, -1.2327e-01],
          [-2.3582e-01, -1.5171e-01, -1.9848e-01]]],


        [[[ 2.8637e-40,  1.4128e-40, -3.7312e-40],
          [ 1.6538e-40, -3.8453e-40,  4.3630e-40],
          [-2.4033e-40,  9.1599e-41,  5.0602e-40]],

         [[ 2.4708e-40, -3.0263e-40,  6.2880e-41],
          [ 3.2263e-40,  5.6579e-40,  2.0852e-40],
          [-1.6882e-40,  1.7975e-40,  1.6708e-40]],

         [[-3.3178e-40, -2.7637e-40, -1.4442e-40],
          [ 2.9636e-40,  2.4231e-41, -1.1339e-40],
          [ 1.3732e-40,  3.1004e-40, -4.3585e-40]]],


        [[[ 3.1593e-02,  1.0404e-01, -3.9035e-02],
          [ 4.0145e-02,  2.0659e-01, -9.3747e-02],
          [ 1.5850e-01,  3.3155e-01,  3.5001e-01]],

         [[-1.8914e-01, -9.3125e-02, -1.5729e-01],
          [-3.8639e-01, -3.7979e-01, -3.1644e-01],
          [-2.4340e-01, -4.2844e-01,  3.7525e-02]],

         [[ 2.6344e-01,  1.7211e-01,  2.2113e-01],
          [ 2.1835e-01,  1.3847e-01,  2.4601e-02],
          [ 1.0783e-01,  9.4898e-02,  1.7609e-02]]],


        ...,


        [[[ 1.8697e-01,  3.3335e-02,  1.0976e-01],
          [ 1.2781e-01, -2.3988e-01, -1.4136e-02],
          [ 5.2601e-02, -1.2719e-01, -3.6363e-02]],

         [[-6.2965e-02, -6.1419e-02,  5.6449e-02],
          [-8.8630e-02, -2.3637e-01,  4.6849e-02],
          [ 4.0222e-02,  7.0378e-02,  1.7057e-01]],

         [[-1.1357e-01, -1.5336e-01,  3.6074e-02],
          [-8.1222e-02, -2.0290e-01, -7.7393e-02],
          [-4.3948e-02, -1.1766e-01, -4.1548e-02]]],


        [[[ 1.0198e-01,  2.2559e-01,  2.8667e-01],
          [ 1.3273e-01,  1.5972e-01,  5.4786e-02],
          [-2.1055e-01, -1.3345e-01, -5.7191e-02]],

         [[ 2.7476e-02,  6.0001e-02, -6.6956e-02],
          [ 1.6566e-02, -4.3418e-02, -2.1645e-01],
          [-3.3785e-02,  7.4230e-02, -3.8042e-02]],

         [[-2.6781e-01, -1.2929e-01, -1.8844e-01],
          [-1.3414e-01,  5.3445e-02,  5.0074e-02],
          [ 9.1123e-02,  2.5001e-01,  1.9137e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -2.6114e-40],
          [ 6.0479e-40,  6.7571e-42, -4.6665e-40],
          [-2.3151e-40, -4.6258e-41, -5.1959e-41]],

         [[-4.1536e-40,  8.2529e-41, -3.5817e-40],
          [ 3.8896e-41,  2.4718e-40,  2.7585e-40],
          [ 1.1724e-40, -5.8556e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.7677e-41,  4.0958e-40],
          [-1.7484e-40, -5.7161e-40,  1.8641e-40],
          [-9.4647e-41, -7.9518e-41, -5.0727e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0369]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0059]], device='cuda:0')

Epoch: 147 | Batch_idx: 0 |  Loss: (0.1970) | Acc: (92.00%) (119/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1806) | Acc: (93.00%) (1320/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1776) | Acc: (94.00%) (2529/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1821) | Acc: (93.00%) (3720/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1791) | Acc: (93.00%) (4920/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1770) | Acc: (93.00%) (6136/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1764) | Acc: (94.00%) (7345/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1759) | Acc: (94.00%) (8550/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1778) | Acc: (94.00%) (9751/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1770) | Acc: (94.00%) (10967/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1751) | Acc: (94.00%) (12178/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1738) | Acc: (94.00%) (13385/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1731) | Acc: (94.00%) (14594/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1721) | Acc: (94.00%) (15808/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1733) | Acc: (94.00%) (16995/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1728) | Acc: (94.00%) (18204/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1742) | Acc: (94.00%) (19392/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1745) | Acc: (94.00%) (20593/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1737) | Acc: (94.00%) (21820/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1726) | Acc: (94.00%) (23030/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1719) | Acc: (94.00%) (24241/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1712) | Acc: (94.00%) (25453/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1714) | Acc: (94.00%) (26660/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1706) | Acc: (94.00%) (27879/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1712) | Acc: (94.00%) (29085/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1709) | Acc: (94.00%) (30290/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1705) | Acc: (94.00%) (31492/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1703) | Acc: (94.00%) (32703/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1706) | Acc: (94.00%) (33907/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1716) | Acc: (94.00%) (35098/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1711) | Acc: (94.00%) (36310/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1712) | Acc: (94.00%) (37512/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1711) | Acc: (94.00%) (38723/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1709) | Acc: (94.00%) (39926/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1702) | Acc: (94.00%) (41149/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1704) | Acc: (94.00%) (42351/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1711) | Acc: (94.00%) (43538/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1721) | Acc: (94.00%) (44730/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1723) | Acc: (94.00%) (45934/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1725) | Acc: (94.00%) (47090/50000)
# TEST : Loss: (0.3024) | Acc: (90.00%) (9042/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9123e-01, -1.9893e-01,  2.2352e-02],
          [-3.6634e-02,  3.9272e-01,  2.6848e-01],
          [ 1.0771e-01,  7.8438e-02, -4.6450e-02]],

         [[-1.8417e-01,  2.1491e-01,  1.6761e-01],
          [ 4.7779e-02,  4.3106e-01,  2.2908e-01],
          [ 2.0180e-01,  1.8958e-02,  7.8314e-02]],

         [[-2.0679e-01, -7.4377e-02, -9.7212e-02],
          [-3.0024e-01, -1.2382e-01, -1.2273e-01],
          [-2.3472e-01, -1.5102e-01, -1.9760e-01]]],


        [[[-1.3401e-40,  1.4128e-40,  1.8739e-40],
          [-1.1488e-40, -1.0427e-40,  2.9618e-40],
          [-1.0020e-40, -1.8866e-40,  3.6589e-40]],

         [[ 2.4708e-40, -2.2377e-41, -2.1738e-40],
          [ 3.2263e-40,  2.8554e-40,  2.0852e-40],
          [-2.8694e-41,  1.7975e-40,  2.6951e-41]],

         [[-4.7191e-40,  3.8816e-42, -5.6480e-40],
          [ 2.9636e-40,  1.6436e-40,  4.4712e-40],
          [-1.4294e-40,  3.1004e-40,  1.2466e-40]]],


        [[[ 3.1528e-02,  1.0383e-01, -3.8954e-02],
          [ 4.0060e-02,  2.0617e-01, -9.3552e-02],
          [ 1.5817e-01,  3.3086e-01,  3.4928e-01]],

         [[-1.8872e-01, -9.2917e-02, -1.5694e-01],
          [-3.8549e-01, -3.7891e-01, -3.1571e-01],
          [-2.4285e-01, -4.2747e-01,  3.7440e-02]],

         [[ 2.6285e-01,  1.7172e-01,  2.2063e-01],
          [ 2.1784e-01,  1.3814e-01,  2.4543e-02],
          [ 1.0758e-01,  9.4678e-02,  1.7568e-02]]],


        ...,


        [[[ 1.8437e-01,  3.2855e-02,  1.0826e-01],
          [ 1.2591e-01, -2.3595e-01, -1.3925e-02],
          [ 5.1817e-02, -1.2518e-01, -3.5825e-02]],

         [[-6.1852e-02, -6.0229e-02,  5.5514e-02],
          [-8.6834e-02, -2.3047e-01,  4.5945e-02],
          [ 3.9481e-02,  6.8913e-02,  1.6758e-01]],

         [[-1.1089e-01, -1.4894e-01,  3.5311e-02],
          [-7.8654e-02, -1.9066e-01, -7.5229e-02],
          [-4.2852e-02, -1.1386e-01, -4.0607e-02]]],


        [[[ 1.0066e-01,  2.2181e-01,  2.8197e-01],
          [ 1.3103e-01,  1.5724e-01,  5.3973e-02],
          [-2.0784e-01, -1.3152e-01, -5.6358e-02]],

         [[ 2.7022e-02,  5.9011e-02, -6.5805e-02],
          [ 1.6295e-02, -4.2728e-02, -2.1295e-01],
          [-3.3226e-02,  7.3115e-02, -3.7453e-02]],

         [[-2.6250e-01, -1.2699e-01, -1.8491e-01],
          [-1.3165e-01,  5.2566e-02,  4.9220e-02],
          [ 8.9526e-02,  2.4632e-01,  1.8848e-01]]],


        [[[-3.2265e-41,  5.6510e-41,  2.9938e-40],
          [ 4.6466e-40,  1.4689e-40, -6.0678e-40],
          [ 1.8888e-40, -3.2652e-40,  8.8171e-41]],

         [[-2.7523e-40,  3.6279e-40,  6.2223e-41],
          [ 1.7903e-40,  1.0705e-40,  2.7585e-40],
          [-3.0315e-40, -4.4543e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.1794e-40,  2.6945e-40],
          [-3.1497e-40, -1.5122e-40,  4.6667e-40],
          [-2.3478e-40, -3.5978e-40,  1.3506e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0557]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0013]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 148 | Batch_idx: 0 |  Loss: (0.2304) | Acc: (90.00%) (116/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1687) | Acc: (94.00%) (1328/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1740) | Acc: (94.00%) (2536/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1832) | Acc: (93.00%) (3723/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1874) | Acc: (93.00%) (4912/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.2026) | Acc: (93.00%) (6082/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.2107) | Acc: (92.00%) (7248/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.2146) | Acc: (92.00%) (8428/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.2240) | Acc: (92.00%) (9575/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.2255) | Acc: (92.00%) (10760/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.2283) | Acc: (92.00%) (11932/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.2331) | Acc: (92.00%) (13080/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.2323) | Acc: (92.00%) (14251/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.2320) | Acc: (92.00%) (15430/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.2317) | Acc: (91.00%) (16599/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.2326) | Acc: (91.00%) (17757/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.2343) | Acc: (91.00%) (18927/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.2340) | Acc: (91.00%) (20094/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.2334) | Acc: (91.00%) (21277/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.2356) | Acc: (91.00%) (22428/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.2354) | Acc: (91.00%) (23605/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.2363) | Acc: (91.00%) (24772/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.2349) | Acc: (91.00%) (25969/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.2335) | Acc: (91.00%) (27161/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.2332) | Acc: (91.00%) (28348/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.2325) | Acc: (91.00%) (29533/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.2324) | Acc: (91.00%) (30705/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.2312) | Acc: (91.00%) (31895/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.2332) | Acc: (91.00%) (33056/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.2332) | Acc: (91.00%) (34232/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.2338) | Acc: (91.00%) (35403/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.2333) | Acc: (91.00%) (36590/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.2332) | Acc: (91.00%) (37777/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.2334) | Acc: (91.00%) (38948/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.2335) | Acc: (91.00%) (40125/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.2330) | Acc: (91.00%) (41311/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.2327) | Acc: (91.00%) (42498/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.2331) | Acc: (91.00%) (43674/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.2334) | Acc: (91.00%) (44843/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.2326) | Acc: (91.00%) (45984/50000)
# TEST : Loss: (0.3401) | Acc: (89.00%) (8962/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8465e-01, -1.9123e-01,  3.0169e-02],
          [-3.8450e-02,  3.8895e-01,  2.6144e-01],
          [ 1.0393e-01,  6.9800e-02, -5.4363e-02]],

         [[-1.8777e-01,  2.1441e-01,  1.6295e-01],
          [ 3.7653e-02,  4.2001e-01,  2.1564e-01],
          [ 1.8584e-01,  1.6190e-03,  6.5770e-02]],

         [[-2.1660e-01, -8.0361e-02, -1.0073e-01],
          [-3.1789e-01, -1.4244e-01, -1.3686e-01],
          [-2.5588e-01, -1.7544e-01, -2.1452e-01]]],


        [[[-4.1427e-40,  1.1561e-42,  6.0777e-40],
          [-2.5501e-40,  3.1611e-40, -1.2421e-40],
          [ 1.8005e-40, -3.2879e-40, -1.9462e-40]],

         [[-3.3177e-41,  2.5788e-40, -2.1738e-40],
          [ 4.2378e-41, -2.7498e-40, -7.1735e-41],
          [ 1.1143e-40,  3.9626e-41, -1.1318e-40]],

         [[-1.9166e-40,  2.8414e-40, -4.2467e-40],
          [ 1.6104e-41,  1.6436e-40,  5.8725e-40],
          [-2.8307e-40,  2.9790e-41,  5.4504e-40]]],


        [[[ 2.2972e-02,  1.0818e-01, -3.2662e-02],
          [ 3.6265e-02,  2.0375e-01, -9.7881e-02],
          [ 1.5410e-01,  3.2994e-01,  3.4837e-01]],

         [[-1.9543e-01, -8.6630e-02, -1.5005e-01],
          [-3.8937e-01, -3.8087e-01, -3.1864e-01],
          [-2.4645e-01, -4.2848e-01,  3.6875e-02]],

         [[ 2.6141e-01,  1.7805e-01,  2.2701e-01],
          [ 2.1904e-01,  1.4188e-01,  2.7063e-02],
          [ 1.0968e-01,  9.8597e-02,  2.1141e-02]]],


        ...,


        [[[ 1.7859e-01,  2.1794e-02,  1.0173e-01],
          [ 1.0930e-01, -2.4411e-01, -1.8669e-02],
          [ 3.5732e-02, -1.1880e-01, -2.9031e-02]],

         [[-6.5926e-02, -7.0425e-02,  5.4537e-02],
          [-1.0580e-01, -2.3549e-01,  4.7209e-02],
          [ 1.9702e-02,  7.6611e-02,  1.8127e-01]],

         [[-1.1876e-01, -1.6871e-01,  2.6266e-02],
          [-1.0501e-01, -2.1866e-01, -8.4975e-02],
          [-6.8156e-02, -1.1898e-01, -3.6412e-02]]],


        [[[ 1.1319e-01,  2.2239e-01,  2.7610e-01],
          [ 1.4566e-01,  1.6208e-01,  5.5672e-02],
          [-1.7922e-01, -1.0894e-01, -4.3508e-02]],

         [[ 2.0550e-02,  4.3905e-02, -7.9774e-02],
          [ 9.0886e-03, -5.6399e-02, -2.2810e-01],
          [-2.0354e-02,  7.6308e-02, -4.6424e-02]],

         [[-2.7845e-01, -1.5392e-01, -2.1077e-01],
          [-1.4524e-01,  3.1014e-02,  2.3440e-02],
          [ 9.5080e-02,  2.4383e-01,  1.7406e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  5.7964e-40],
          [-9.5863e-41,  1.4689e-40, -1.8639e-40],
          [ 4.6914e-40, -3.2652e-40,  8.8171e-41]],

         [[ 1.4516e-40,  2.2266e-40,  4.8261e-40],
          [ 1.7903e-40, -1.7321e-40, -4.4057e-42],
          [-4.4328e-40,  1.1509e-40,  3.8970e-41]],

         [[ 4.9483e-41, -3.1794e-40, -1.5094e-40],
          [-1.7484e-40,  4.0930e-40,  3.2654e-40],
          [-9.4647e-41, -2.1965e-40,  1.3506e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0110,  0.0102,  0.0041],
          [ 0.0082,  0.0151,  0.0087],
          [ 0.0004,  0.0126,  0.0059]],

         [[ 0.0069,  0.0095,  0.0067],
          [ 0.0007,  0.0116,  0.0088],
          [-0.0082,  0.0061,  0.0014]],

         [[ 0.0083,  0.0095,  0.0090],
          [ 0.0060,  0.0141,  0.0133],
          [-0.0019,  0.0099,  0.0065]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0343,  0.0450,  0.0535],
          [ 0.0357,  0.0416,  0.0491],
          [ 0.0297,  0.0284,  0.0332]],

         [[ 0.0272,  0.0416,  0.0549],
          [ 0.0251,  0.0344,  0.0496],
          [ 0.0191,  0.0211,  0.0342]],

         [[ 0.0201,  0.0349,  0.0507],
          [ 0.0160,  0.0240,  0.0394],
          [ 0.0097,  0.0117,  0.0245]]],


        ...,


        [[[-0.0040, -0.0016, -0.0023],
          [-0.0051, -0.0021, -0.0029],
          [-0.0047, -0.0020, -0.0036]],

         [[-0.0024, -0.0003, -0.0008],
          [-0.0035, -0.0016, -0.0025],
          [-0.0034, -0.0017, -0.0037]],

         [[-0.0004,  0.0013,  0.0008],
          [-0.0024, -0.0006, -0.0013],
          [-0.0033, -0.0018, -0.0034]]],


        [[[ 0.0014,  0.0011, -0.0016],
          [ 0.0045,  0.0056,  0.0019],
          [ 0.0059,  0.0080,  0.0044]],

         [[ 0.0034,  0.0035,  0.0012],
          [ 0.0063,  0.0076,  0.0044],
          [ 0.0066,  0.0093,  0.0066]],

         [[ 0.0040,  0.0038,  0.0012],
          [ 0.0069,  0.0080,  0.0043],
          [ 0.0066,  0.0095,  0.0063]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0583]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 149 | Batch_idx: 0 |  Loss: (0.1903) | Acc: (94.00%) (121/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1854) | Acc: (94.00%) (1324/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1747) | Acc: (94.00%) (2537/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1695) | Acc: (94.00%) (3752/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1741) | Acc: (94.00%) (4947/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1808) | Acc: (93.00%) (6133/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1813) | Acc: (93.00%) (7337/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1821) | Acc: (94.00%) (8543/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1846) | Acc: (93.00%) (9734/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1843) | Acc: (93.00%) (10938/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1903) | Acc: (93.00%) (12115/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1897) | Acc: (93.00%) (13314/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1904) | Acc: (93.00%) (14503/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1890) | Acc: (93.00%) (15704/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1872) | Acc: (93.00%) (16918/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1866) | Acc: (93.00%) (18120/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1860) | Acc: (93.00%) (19317/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1846) | Acc: (93.00%) (20520/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1858) | Acc: (93.00%) (21701/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1867) | Acc: (93.00%) (22898/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1865) | Acc: (93.00%) (24093/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1873) | Acc: (93.00%) (25279/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1886) | Acc: (93.00%) (26462/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1892) | Acc: (93.00%) (27655/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1907) | Acc: (93.00%) (28839/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1908) | Acc: (93.00%) (30033/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1904) | Acc: (93.00%) (31241/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1921) | Acc: (93.00%) (32415/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1930) | Acc: (93.00%) (33601/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1928) | Acc: (93.00%) (34790/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1930) | Acc: (93.00%) (35983/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1941) | Acc: (93.00%) (37160/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1945) | Acc: (93.00%) (38356/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1946) | Acc: (93.00%) (39545/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1940) | Acc: (93.00%) (40748/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1944) | Acc: (93.00%) (41937/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1937) | Acc: (93.00%) (43137/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1941) | Acc: (93.00%) (44318/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1948) | Acc: (93.00%) (45507/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1941) | Acc: (93.00%) (46670/50000)
# TEST : Loss: (0.3097) | Acc: (90.00%) (9017/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7868e-01, -1.8343e-01,  2.7807e-02],
          [-2.3246e-02,  4.0383e-01,  2.6268e-01],
          [ 1.1645e-01,  7.9248e-02, -5.2498e-02]],

         [[-1.8457e-01,  2.2006e-01,  1.6210e-01],
          [ 5.0644e-02,  4.3228e-01,  2.1909e-01],
          [ 1.9559e-01,  6.2770e-03,  6.7506e-02]],

         [[-2.1248e-01, -7.7325e-02, -1.0237e-01],
          [-3.0743e-01, -1.3763e-01, -1.3600e-01],
          [-2.4894e-01, -1.7582e-01, -2.0908e-01]]],


        [[[-2.7414e-40, -1.3897e-40,  4.6765e-40],
          [-1.1488e-40,  4.5624e-40, -4.0446e-40],
          [ 3.2018e-40, -1.8866e-40, -6.1500e-40]],

         [[-3.1343e-40,  2.5788e-40,  6.2879e-41],
          [-2.3788e-40, -5.5523e-40, -2.1186e-40],
          [ 1.1143e-40, -1.0050e-40, -1.1318e-40]],

         [[ 2.2873e-40,  2.8414e-40,  1.3584e-40],
          [-2.6415e-40,  2.4231e-41,  1.6687e-40],
          [-1.4294e-40, -2.5047e-40,  4.0492e-40]]],


        [[[ 2.7745e-02,  1.0922e-01, -2.9723e-02],
          [ 3.6336e-02,  2.0437e-01, -9.7925e-02],
          [ 1.6098e-01,  3.2943e-01,  3.4918e-01]],

         [[-1.9888e-01, -9.6252e-02, -1.5971e-01],
          [-3.9964e-01, -3.9178e-01, -3.3130e-01],
          [-2.4244e-01, -4.3478e-01,  3.1530e-02]],

         [[ 2.5034e-01,  1.6259e-01,  2.1061e-01],
          [ 2.0775e-01,  1.3113e-01,  1.2608e-02],
          [ 1.1261e-01,  9.1447e-02,  1.3544e-02]]],


        ...,


        [[[ 1.7685e-01,  2.2107e-02,  1.0056e-01],
          [ 1.1506e-01, -2.3969e-01, -2.1221e-02],
          [ 5.2644e-02, -1.0747e-01, -3.0626e-02]],

         [[-6.8666e-02, -7.3943e-02,  4.7122e-02],
          [-9.7517e-02, -2.3055e-01,  4.2574e-02],
          [ 4.0585e-02,  9.3391e-02,  1.8425e-01]],

         [[-1.2488e-01, -1.8217e-01,  3.8434e-03],
          [-9.3391e-02, -2.2273e-01, -1.0536e-01],
          [-4.1642e-02, -9.9441e-02, -4.2381e-02]]],


        [[[ 1.2359e-01,  2.3185e-01,  2.8448e-01],
          [ 1.4647e-01,  1.5869e-01,  5.3967e-02],
          [-1.7623e-01, -1.1202e-01, -5.2467e-02]],

         [[ 3.1928e-02,  4.8837e-02, -7.5252e-02],
          [ 1.1731e-02, -5.9659e-02, -2.2967e-01],
          [-2.4192e-02,  6.7519e-02, -5.6516e-02]],

         [[-2.5884e-01, -1.4216e-01, -1.9925e-01],
          [-1.3088e-01,  3.8566e-02,  3.1715e-02],
          [ 1.0659e-01,  2.5137e-01,  1.8258e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  2.9938e-40],
          [-5.1625e-40,  6.7571e-42,  3.7413e-40],
          [ 3.2901e-40, -4.6258e-41, -5.1959e-41]],

         [[ 4.2542e-40, -1.9773e-40,  4.8261e-40],
          [ 3.8896e-41, -3.1334e-40, -2.8467e-40],
          [-1.6302e-40,  5.3548e-40,  1.7910e-40]],

         [[-2.3078e-40, -3.7677e-41, -4.3120e-40],
          [ 1.0542e-40,  5.4943e-40, -9.3845e-41],
          [ 1.8561e-40,  2.0074e-40, -5.0727e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0165, -0.0166, -0.0175],
          [-0.0041, -0.0085, -0.0100],
          [ 0.0025, -0.0086, -0.0107]],

         [[-0.0139, -0.0126, -0.0132],
          [-0.0074, -0.0103, -0.0117],
          [-0.0050, -0.0131, -0.0136]],

         [[-0.0103, -0.0076, -0.0059],
          [-0.0077, -0.0079, -0.0058],
          [-0.0050, -0.0101, -0.0067]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0214, -0.0205, -0.0002],
          [-0.0193, -0.0187,  0.0021],
          [ 0.0059,  0.0140,  0.0301]],

         [[-0.0054, -0.0059,  0.0183],
          [-0.0019,  0.0010,  0.0223],
          [ 0.0171,  0.0277,  0.0436]],

         [[ 0.0060,  0.0034,  0.0257],
          [ 0.0057,  0.0058,  0.0234],
          [ 0.0182,  0.0246,  0.0373]]],


        ...,


        [[[-0.0004,  0.0003, -0.0024],
          [-0.0023, -0.0020, -0.0055],
          [-0.0030, -0.0025, -0.0071]],

         [[-0.0017, -0.0008, -0.0033],
          [-0.0030, -0.0024, -0.0055],
          [-0.0028, -0.0029, -0.0076]],

         [[ 0.0002,  0.0009, -0.0013],
          [-0.0010, -0.0008, -0.0032],
          [-0.0010, -0.0012, -0.0048]]],


        [[[ 0.0040,  0.0044,  0.0034],
          [ 0.0056,  0.0046,  0.0027],
          [ 0.0041,  0.0025,  0.0011]],

         [[ 0.0035,  0.0052,  0.0057],
          [ 0.0042,  0.0046,  0.0052],
          [ 0.0028,  0.0018,  0.0025]],

         [[ 0.0011,  0.0026,  0.0041],
          [ 0.0012,  0.0012,  0.0027],
          [ 0.0007, -0.0007,  0.0004]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0581]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 150 | Batch_idx: 0 |  Loss: (0.1704) | Acc: (93.00%) (120/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.1657) | Acc: (94.00%) (1336/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1764) | Acc: (94.00%) (2538/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1783) | Acc: (94.00%) (3736/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.1950) | Acc: (93.00%) (4903/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.1972) | Acc: (93.00%) (6101/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.1988) | Acc: (93.00%) (7293/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.1968) | Acc: (93.00%) (8488/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.1948) | Acc: (93.00%) (9687/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.1905) | Acc: (93.00%) (10898/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.1875) | Acc: (93.00%) (12111/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.1841) | Acc: (93.00%) (13325/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.1840) | Acc: (93.00%) (14534/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.1836) | Acc: (93.00%) (15741/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.1824) | Acc: (93.00%) (16958/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.1817) | Acc: (93.00%) (18165/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.1803) | Acc: (94.00%) (19375/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.1780) | Acc: (94.00%) (20599/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.1778) | Acc: (94.00%) (21798/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.1771) | Acc: (94.00%) (23009/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.1761) | Acc: (94.00%) (24220/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.1755) | Acc: (94.00%) (25427/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.1758) | Acc: (94.00%) (26636/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.1743) | Acc: (94.00%) (27855/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.1733) | Acc: (94.00%) (29073/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.1730) | Acc: (94.00%) (30282/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.1726) | Acc: (94.00%) (31492/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.1728) | Acc: (94.00%) (32691/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.1720) | Acc: (94.00%) (33900/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.1715) | Acc: (94.00%) (35111/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.1710) | Acc: (94.00%) (36323/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.1708) | Acc: (94.00%) (37532/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.1702) | Acc: (94.00%) (38737/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.1703) | Acc: (94.00%) (39941/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.1701) | Acc: (94.00%) (41147/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.1696) | Acc: (94.00%) (42363/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.1694) | Acc: (94.00%) (43578/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.1691) | Acc: (94.00%) (44786/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.1693) | Acc: (94.00%) (45993/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.1690) | Acc: (94.00%) (47164/50000)
# TEST : Loss: (0.2798) | Acc: (91.00%) (9111/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7648e-01, -1.8188e-01,  2.7603e-02],
          [-2.1663e-02,  4.0313e-01,  2.6198e-01],
          [ 1.1671e-01,  7.9503e-02, -5.0839e-02]],

         [[-1.8366e-01,  2.1872e-01,  1.6034e-01],
          [ 5.1368e-02,  4.3080e-01,  2.1802e-01],
          [ 1.9578e-01,  6.6391e-03,  6.8105e-02]],

         [[-2.1188e-01, -7.8157e-02, -1.0434e-01],
          [-3.0529e-01, -1.3738e-01, -1.3686e-01],
          [-2.4676e-01, -1.7507e-01, -2.0848e-01]]],


        [[[ 1.4625e-40, -1.3897e-40, -9.2868e-41],
          [ 1.6538e-40,  1.7598e-40, -2.6434e-40],
          [ 1.8005e-40,  9.1599e-41, -4.7488e-40]],

         [[-3.1343e-40, -2.2376e-41,  3.4314e-40],
          [-2.3788e-40, -2.7498e-40, -7.1735e-41],
          [-2.8694e-41, -1.0050e-40,  2.6951e-41]],

         [[ 3.6886e-40,  3.8844e-42,  5.5623e-40],
          [-2.6415e-40, -1.1590e-40, -3.9365e-40],
          [ 1.3732e-40, -2.5047e-40, -1.5560e-40]]],


        [[[ 2.7081e-02,  1.0801e-01, -3.1696e-02],
          [ 3.5071e-02,  2.0269e-01, -9.9435e-02],
          [ 1.6065e-01,  3.2778e-01,  3.4684e-01]],

         [[-1.9980e-01, -9.7743e-02, -1.6250e-01],
          [-4.0072e-01, -3.9310e-01, -3.3341e-01],
          [-2.4220e-01, -4.3551e-01,  2.8981e-02]],

         [[ 2.4790e-01,  1.6002e-01,  2.0671e-01],
          [ 2.0481e-01,  1.2829e-01,  9.9586e-03],
          [ 1.1142e-01,  8.9256e-02,  1.1210e-02]]],


        ...,


        [[[ 1.7685e-01,  2.3507e-02,  1.0140e-01],
          [ 1.1715e-01, -2.3383e-01, -1.7437e-02],
          [ 5.5758e-02, -1.0227e-01, -2.5706e-02]],

         [[-6.6683e-02, -7.2236e-02,  4.7315e-02],
          [-9.3605e-02, -2.2463e-01,  4.4200e-02],
          [ 4.2484e-02,  9.5206e-02,  1.8530e-01]],

         [[-1.2335e-01, -1.7957e-01,  2.7019e-03],
          [-9.0204e-02, -2.1363e-01, -1.0310e-01],
          [-3.9674e-02, -9.5516e-02, -4.0380e-02]]],


        [[[ 1.2216e-01,  2.2941e-01,  2.8052e-01],
          [ 1.4517e-01,  1.5763e-01,  5.2772e-02],
          [-1.7246e-01, -1.0846e-01, -5.1134e-02]],

         [[ 3.2307e-02,  4.9198e-02, -7.5386e-02],
          [ 1.2355e-02, -5.8221e-02, -2.2829e-01],
          [-2.1741e-02,  6.9089e-02, -5.5716e-02]],

         [[-2.5418e-01, -1.3953e-01, -1.9783e-01],
          [-1.2811e-01,  3.8973e-02,  3.0151e-02],
          [ 1.0791e-01,  2.5111e-01,  1.8091e-01]]],


        [[[-3.2265e-41,  5.6510e-41, -2.6114e-40],
          [-3.7612e-40, -1.3337e-40,  5.1426e-40],
          [-9.1376e-41,  2.3400e-40, -1.9209e-40]],

         [[ 2.8529e-40, -4.7799e-40,  6.2223e-41],
          [-1.0123e-40, -1.7321e-40, -2.8467e-40],
          [ 2.5737e-40,  3.9535e-40,  1.7910e-40]],

         [[-2.3078e-40,  2.4258e-40, -2.9107e-40],
          [ 2.4555e-40,  1.2904e-40, -3.7410e-40],
          [ 3.2574e-40,  4.8100e-40, -1.4520e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0809]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0156]], device='cuda:0')

Epoch: 151 | Batch_idx: 0 |  Loss: (0.2171) | Acc: (93.00%) (120/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.1444) | Acc: (94.00%) (1335/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.1617) | Acc: (94.00%) (2530/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.1587) | Acc: (94.00%) (3745/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.1562) | Acc: (94.00%) (4958/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.1570) | Acc: (94.00%) (6166/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.1561) | Acc: (94.00%) (7382/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.1581) | Acc: (94.00%) (8581/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.1570) | Acc: (94.00%) (9789/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.1561) | Acc: (94.00%) (11015/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.1586) | Acc: (94.00%) (12216/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.1582) | Acc: (94.00%) (13426/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.1583) | Acc: (94.00%) (14638/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.1587) | Acc: (94.00%) (15843/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.1589) | Acc: (94.00%) (17049/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.1574) | Acc: (94.00%) (18267/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.1573) | Acc: (94.00%) (19476/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.1561) | Acc: (94.00%) (20694/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.1548) | Acc: (94.00%) (21920/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.1549) | Acc: (94.00%) (23131/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.1545) | Acc: (94.00%) (24349/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.1542) | Acc: (94.00%) (25568/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.1541) | Acc: (94.00%) (26780/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.1538) | Acc: (94.00%) (27999/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.1534) | Acc: (94.00%) (29212/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.1529) | Acc: (94.00%) (30432/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.1531) | Acc: (94.00%) (31642/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.1532) | Acc: (94.00%) (32853/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.1531) | Acc: (94.00%) (34065/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.1530) | Acc: (94.00%) (35277/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.1538) | Acc: (94.00%) (36480/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.1534) | Acc: (94.00%) (37694/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.1537) | Acc: (94.00%) (38903/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.1533) | Acc: (94.00%) (40128/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.1531) | Acc: (94.00%) (41343/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.1528) | Acc: (94.00%) (42558/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.1527) | Acc: (94.00%) (43770/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.1528) | Acc: (94.00%) (44982/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.1528) | Acc: (94.00%) (46200/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.1527) | Acc: (94.00%) (47371/50000)
# TEST : Loss: (0.2732) | Acc: (91.00%) (9111/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7573e-01, -1.8105e-01,  2.7472e-02],
          [-2.1565e-02,  4.0114e-01,  2.6063e-01],
          [ 1.1618e-01,  7.9113e-02, -5.0587e-02]],

         [[-1.8284e-01,  2.1771e-01,  1.5960e-01],
          [ 5.1128e-02,  4.2868e-01,  2.1693e-01],
          [ 1.9486e-01,  6.6066e-03,  6.7773e-02]],

         [[-2.1087e-01, -7.7791e-02, -1.0386e-01],
          [-3.0382e-01, -1.3672e-01, -1.3622e-01],
          [-2.4557e-01, -1.7423e-01, -2.0748e-01]]],


        [[[ 4.2651e-40,  1.1561e-42, -5.1325e-40],
          [ 3.0551e-40, -2.4440e-40,  1.5605e-40],
          [-1.0020e-40,  2.3173e-40,  8.5639e-41]],

         [[-3.3179e-41, -3.0263e-40,  3.4314e-40],
          [ 4.2378e-41,  2.8554e-40,  2.0852e-40],
          [-1.6882e-40,  3.9626e-41,  1.6708e-40]],

         [[ 8.8601e-41, -2.7637e-40,  4.1610e-40],
          [ 1.6104e-41, -1.1590e-40, -5.3378e-40],
          [ 2.7745e-40,  2.9790e-41, -5.7599e-40]]],


        [[[ 2.7020e-02,  1.0777e-01, -3.1623e-02],
          [ 3.4991e-02,  2.0223e-01, -9.9208e-02],
          [ 1.6028e-01,  3.2704e-01,  3.4605e-01]],

         [[-1.9931e-01, -9.7498e-02, -1.6209e-01],
          [-3.9968e-01, -3.9209e-01, -3.3255e-01],
          [-2.4159e-01, -4.3443e-01,  2.8910e-02]],

         [[ 2.4727e-01,  1.5961e-01,  2.0617e-01],
          [ 2.0427e-01,  1.2795e-01,  9.9321e-03],
          [ 1.1113e-01,  8.9021e-02,  1.1180e-02]]],


        ...,


        [[[ 1.7471e-01,  2.3221e-02,  1.0023e-01],
          [ 1.1562e-01, -2.3069e-01, -1.7220e-02],
          [ 5.5018e-02, -1.0087e-01, -2.5374e-02]],

         [[-6.5649e-02, -7.1079e-02,  4.6660e-02],
          [-9.1953e-02, -2.2031e-01,  4.3515e-02],
          [ 4.1805e-02,  9.3543e-02,  1.8256e-01]],

         [[-1.2061e-01, -1.7482e-01,  2.6514e-03],
          [-8.7485e-02, -2.0322e-01, -1.0064e-01],
          [-3.8780e-02, -9.2736e-02, -3.9569e-02]]],


        [[[ 1.2065e-01,  2.2609e-01,  2.7668e-01],
          [ 1.4343e-01,  1.5555e-01,  5.2096e-02],
          [-1.7043e-01, -1.0712e-01, -5.0493e-02]],

         [[ 3.1885e-02,  4.8567e-02, -7.4390e-02],
          [ 1.2199e-02, -5.7518e-02, -2.2542e-01],
          [-2.1463e-02,  6.8289e-02, -5.5031e-02]],

         [[-2.5023e-01, -1.3756e-01, -1.9482e-01],
          [-1.2624e-01,  3.8473e-02,  2.9732e-02],
          [ 1.0641e-01,  2.4815e-01,  1.7860e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -5.4140e-40],
          [ 1.8440e-40, -1.3337e-40,  9.3869e-41],
          [-3.7164e-40,  2.3400e-40, -1.9209e-40]],

         [[-1.3510e-40, -3.3786e-40, -3.5817e-40],
          [-1.0123e-40,  1.0705e-40, -4.4057e-42],
          [ 3.9750e-40, -1.6517e-40,  3.8970e-41]],

         [[ 4.9483e-41,  2.4258e-40,  1.2932e-40],
          [ 1.0542e-40, -4.3148e-40, -2.3397e-40],
          [ 1.8561e-40,  3.4087e-40, -1.4520e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0761]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0179]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 152 | Batch_idx: 0 |  Loss: (0.1086) | Acc: (96.00%) (123/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1407) | Acc: (95.00%) (1343/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1627) | Acc: (94.00%) (2542/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1680) | Acc: (94.00%) (3746/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1772) | Acc: (94.00%) (4942/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1842) | Acc: (93.00%) (6127/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1953) | Acc: (93.00%) (7297/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.2030) | Acc: (93.00%) (8471/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.2085) | Acc: (93.00%) (9643/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.2112) | Acc: (92.00%) (10818/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.2140) | Acc: (92.00%) (11998/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.2159) | Acc: (92.00%) (13171/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.2165) | Acc: (92.00%) (14369/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.2178) | Acc: (92.00%) (15557/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.2188) | Acc: (92.00%) (16742/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.2206) | Acc: (92.00%) (17910/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.2202) | Acc: (92.00%) (19105/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.2207) | Acc: (92.00%) (20284/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.2220) | Acc: (92.00%) (21455/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.2226) | Acc: (92.00%) (22631/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.2237) | Acc: (92.00%) (23792/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.2246) | Acc: (92.00%) (24958/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.2263) | Acc: (92.00%) (26124/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.2263) | Acc: (92.00%) (27307/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.2271) | Acc: (92.00%) (28478/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.2269) | Acc: (92.00%) (29662/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.2288) | Acc: (92.00%) (30824/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.2284) | Acc: (92.00%) (32018/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.2286) | Acc: (92.00%) (33190/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.2298) | Acc: (92.00%) (34351/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.2299) | Acc: (92.00%) (35523/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.2296) | Acc: (92.00%) (36699/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.2294) | Acc: (92.00%) (37878/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.2299) | Acc: (92.00%) (39047/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.2292) | Acc: (92.00%) (40235/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.2287) | Acc: (92.00%) (41421/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.2280) | Acc: (92.00%) (42612/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.2274) | Acc: (92.00%) (43801/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.2270) | Acc: (92.00%) (44992/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.2263) | Acc: (92.00%) (46136/50000)
# TEST : Loss: (0.3527) | Acc: (88.00%) (8858/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7811e-01, -1.8952e-01,  7.6415e-03],
          [-2.3598e-02,  4.0519e-01,  2.5877e-01],
          [ 1.1279e-01,  7.5695e-02, -5.4021e-02]],

         [[-1.9078e-01,  2.0997e-01,  1.4410e-01],
          [ 4.3709e-02,  4.3381e-01,  2.1635e-01],
          [ 1.8936e-01,  3.2750e-03,  6.4169e-02]],

         [[-2.0945e-01, -7.9423e-02, -1.1539e-01],
          [-3.1086e-01, -1.3426e-01, -1.3684e-01],
          [-2.5454e-01, -1.8238e-01, -2.0924e-01]]],


        [[[ 2.8638e-40,  1.4128e-40, -3.7313e-40],
          [ 1.6538e-40, -3.8453e-40,  4.3631e-40],
          [-2.4033e-40,  9.1600e-41,  5.0603e-40]],

         [[ 2.4708e-40, -3.0263e-40,  6.2879e-41],
          [ 3.2264e-40,  5.6580e-40,  2.0852e-40],
          [-1.6882e-40,  1.7975e-40,  1.6708e-40]],

         [[-3.3179e-40, -2.7637e-40, -1.4442e-40],
          [ 2.9636e-40,  2.4230e-41, -1.1339e-40],
          [ 1.3732e-40,  3.1005e-40, -4.3586e-40]]],


        [[[ 2.8848e-02,  1.2300e-01, -2.0464e-02],
          [ 4.6643e-02,  2.1739e-01, -9.4557e-02],
          [ 1.8073e-01,  3.4132e-01,  3.4877e-01]],

         [[-2.0394e-01, -8.5330e-02, -1.4882e-01],
          [-3.9127e-01, -3.7963e-01, -3.2527e-01],
          [-2.2780e-01, -4.2823e-01,  2.9390e-02]],

         [[ 2.4257e-01,  1.7470e-01,  2.2064e-01],
          [ 2.1298e-01,  1.4486e-01,  2.1789e-02],
          [ 1.1922e-01,  9.4038e-02,  1.3018e-02]]],


        ...,


        [[[ 1.6874e-01,  2.6144e-02,  9.5967e-02],
          [ 9.9603e-02, -2.4031e-01, -2.6132e-02],
          [ 5.4402e-02, -1.0898e-01, -2.5397e-02]],

         [[-5.8491e-02, -5.2536e-02,  5.8221e-02],
          [-1.0013e-01, -2.1913e-01,  4.6399e-02],
          [ 4.9512e-02,  9.7785e-02,  1.9608e-01]],

         [[-1.1823e-01, -1.5977e-01, -8.9318e-05],
          [-9.9339e-02, -2.1711e-01, -1.1216e-01],
          [-2.0130e-02, -8.1533e-02, -2.8725e-02]]],


        [[[ 1.1352e-01,  2.2886e-01,  2.8035e-01],
          [ 1.3431e-01,  1.5574e-01,  5.7633e-02],
          [-1.6387e-01, -9.1554e-02, -2.9020e-02]],

         [[ 2.4416e-02,  4.7421e-02, -7.1210e-02],
          [ 6.8357e-03, -5.6627e-02, -2.1558e-01],
          [-1.1475e-02,  8.0017e-02, -3.3554e-02]],

         [[-2.3851e-01, -1.2407e-01, -1.7653e-01],
          [-1.1376e-01,  5.0100e-02,  4.8415e-02],
          [ 1.2753e-01,  2.6712e-01,  2.0586e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -2.6114e-40],
          [ 6.0479e-40,  6.7571e-42, -4.6665e-40],
          [-2.3151e-40, -4.6258e-41, -5.1959e-41]],

         [[-4.1536e-40,  8.2529e-41, -3.5817e-40],
          [ 3.8896e-41,  2.4718e-40,  2.7585e-40],
          [ 1.1724e-40, -5.8556e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.7677e-41,  4.0958e-40],
          [-1.7484e-40, -5.7161e-40,  1.8641e-40],
          [-9.4647e-41, -7.9518e-41, -5.0727e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0194,  0.0236,  0.0256],
          [ 0.0147,  0.0142,  0.0168],
          [ 0.0173,  0.0133,  0.0191]],

         [[ 0.0143,  0.0192,  0.0223],
          [ 0.0116,  0.0136,  0.0165],
          [ 0.0132,  0.0115,  0.0175]],

         [[ 0.0133,  0.0170,  0.0181],
          [ 0.0130,  0.0138,  0.0144],
          [ 0.0114,  0.0112,  0.0149]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0042,  0.0030,  0.0096],
          [-0.0062,  0.0031,  0.0065],
          [-0.0146, -0.0001,  0.0014]],

         [[-0.0023,  0.0031,  0.0087],
          [-0.0040,  0.0071,  0.0063],
          [-0.0032,  0.0104,  0.0068]],

         [[-0.0011,  0.0057,  0.0107],
          [ 0.0032,  0.0132,  0.0124],
          [ 0.0127,  0.0242,  0.0171]]],


        ...,


        [[[-0.0001, -0.0019,  0.0026],
          [-0.0001, -0.0025,  0.0002],
          [-0.0012, -0.0027,  0.0003]],

         [[ 0.0023,  0.0013,  0.0059],
          [ 0.0016, -0.0003,  0.0032],
          [ 0.0007,  0.0000,  0.0034]],

         [[ 0.0031,  0.0029,  0.0079],
          [ 0.0013,  0.0008,  0.0051],
          [ 0.0007,  0.0007,  0.0044]]],


        [[[ 0.0003,  0.0007,  0.0017],
          [ 0.0007,  0.0005,  0.0011],
          [ 0.0001, -0.0001,  0.0010]],

         [[-0.0002,  0.0010,  0.0023],
          [ 0.0002,  0.0010,  0.0021],
          [-0.0004,  0.0002,  0.0021]],

         [[ 0.0011,  0.0020,  0.0029],
          [ 0.0013,  0.0024,  0.0034],
          [-0.0000,  0.0006,  0.0027]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0768]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 153 | Batch_idx: 0 |  Loss: (0.1605) | Acc: (95.00%) (122/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1792) | Acc: (94.00%) (1325/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1874) | Acc: (93.00%) (2524/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1751) | Acc: (94.00%) (3746/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1839) | Acc: (94.00%) (4937/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1801) | Acc: (94.00%) (6145/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1826) | Acc: (93.00%) (7332/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1846) | Acc: (93.00%) (8515/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1864) | Acc: (93.00%) (9699/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1892) | Acc: (93.00%) (10876/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1902) | Acc: (93.00%) (12061/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1899) | Acc: (93.00%) (13265/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1890) | Acc: (93.00%) (14468/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1884) | Acc: (93.00%) (15665/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1860) | Acc: (93.00%) (16874/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1861) | Acc: (93.00%) (18079/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1865) | Acc: (93.00%) (19265/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1877) | Acc: (93.00%) (20453/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1886) | Acc: (93.00%) (21642/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1874) | Acc: (93.00%) (22845/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1883) | Acc: (93.00%) (24036/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1899) | Acc: (93.00%) (25223/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1903) | Acc: (93.00%) (26410/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1895) | Acc: (93.00%) (27613/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1898) | Acc: (93.00%) (28808/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1907) | Acc: (93.00%) (29982/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1910) | Acc: (93.00%) (31174/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1910) | Acc: (93.00%) (32366/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1911) | Acc: (93.00%) (33563/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1908) | Acc: (93.00%) (34767/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1912) | Acc: (93.00%) (35968/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1908) | Acc: (93.00%) (37171/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1913) | Acc: (93.00%) (38363/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1915) | Acc: (93.00%) (39553/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1917) | Acc: (93.00%) (40756/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1909) | Acc: (93.00%) (41957/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1913) | Acc: (93.00%) (43138/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1914) | Acc: (93.00%) (44328/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1916) | Acc: (93.00%) (45512/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1917) | Acc: (93.00%) (46669/50000)
# TEST : Loss: (0.3427) | Acc: (89.00%) (8907/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8283e-01, -1.8592e-01,  8.7881e-03],
          [-2.2981e-02,  4.0838e-01,  2.6008e-01],
          [ 1.1774e-01,  8.2425e-02, -5.3217e-02]],

         [[-1.7904e-01,  2.2910e-01,  1.5980e-01],
          [ 5.9915e-02,  4.5193e-01,  2.3118e-01],
          [ 2.0645e-01,  2.1537e-02,  7.6482e-02]],

         [[-2.0073e-01, -6.2834e-02, -1.0321e-01],
          [-2.9724e-01, -1.1968e-01, -1.2626e-01],
          [-2.3982e-01, -1.6802e-01, -1.9800e-01]]],


        [[[-1.3401e-40,  1.4128e-40,  1.8739e-40],
          [-1.1488e-40, -1.0427e-40,  2.9618e-40],
          [-1.0020e-40, -1.8866e-40,  3.6590e-40]],

         [[ 2.4708e-40, -2.2376e-41, -2.1738e-40],
          [ 3.2264e-40,  2.8554e-40, -7.1737e-41],
          [-2.8696e-41,  1.7976e-40,  2.6950e-41]],

         [[-4.7192e-40,  3.8844e-42, -5.6481e-40],
          [ 2.9636e-40,  1.6436e-40,  4.4712e-40],
          [-1.4294e-40,  3.1005e-40,  1.2466e-40]]],


        [[[ 3.6138e-02,  1.2063e-01, -2.9916e-02],
          [ 4.2977e-02,  2.1016e-01, -9.6819e-02],
          [ 1.7325e-01,  3.3162e-01,  3.4528e-01]],

         [[-1.9872e-01, -9.1425e-02, -1.6340e-01],
          [-3.9716e-01, -3.9188e-01, -3.3184e-01],
          [-2.3933e-01, -4.4328e-01,  1.9780e-02]],

         [[ 2.4444e-01,  1.7081e-01,  2.0908e-01],
          [ 2.0587e-01,  1.3831e-01,  1.7989e-02],
          [ 1.0596e-01,  8.1707e-02,  4.0319e-03]]],


        ...,


        [[[ 1.8234e-01,  4.2718e-02,  1.1911e-01],
          [ 1.0261e-01, -2.2968e-01, -5.8268e-03],
          [ 5.3533e-02, -1.0914e-01, -2.0382e-02]],

         [[-6.1364e-02, -5.4871e-02,  5.9329e-02],
          [-1.1599e-01, -2.2505e-01,  4.7892e-02],
          [ 2.9044e-02,  7.6677e-02,  1.8374e-01]],

         [[-1.1319e-01, -1.5110e-01,  3.0612e-03],
          [-1.1019e-01, -2.0762e-01, -1.0190e-01],
          [-3.5477e-02, -1.0332e-01, -3.9504e-02]]],


        [[[ 1.0020e-01,  2.0785e-01,  2.5648e-01],
          [ 1.2020e-01,  1.3710e-01,  3.0249e-02],
          [-1.7364e-01, -9.7676e-02, -4.6680e-02]],

         [[ 1.5799e-02,  3.5977e-02, -8.2660e-02],
          [ 1.4117e-03, -6.2434e-02, -2.2654e-01],
          [-1.5067e-02,  8.1224e-02, -3.8219e-02]],

         [[-2.3625e-01, -1.2422e-01, -1.7534e-01],
          [-1.0825e-01,  5.4826e-02,  4.9994e-02],
          [ 1.3522e-01,  2.7917e-01,  2.1387e-01]]],


        [[[-3.2265e-41,  5.6510e-41,  2.9938e-40],
          [ 4.6466e-40,  1.4689e-40, -6.0678e-40],
          [ 1.8888e-40, -3.2652e-40,  8.8171e-41]],

         [[-2.7523e-40,  3.6279e-40,  6.2223e-41],
          [ 1.7903e-40,  1.0705e-40,  2.7585e-40],
          [-3.0315e-40, -4.4543e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.1794e-40,  2.6945e-40],
          [-3.1497e-40, -1.5122e-40,  4.6667e-40],
          [-2.3478e-40, -3.5978e-40,  1.3506e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0210, -0.0072,  0.0038],
          [-0.0179, -0.0115, -0.0037],
          [-0.0190, -0.0101,  0.0065]],

         [[-0.0173, -0.0046,  0.0048],
          [-0.0197, -0.0097, -0.0027],
          [-0.0212, -0.0036,  0.0093]],

         [[-0.0138, -0.0023,  0.0040],
          [-0.0143, -0.0069, -0.0047],
          [-0.0145, -0.0014,  0.0066]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0006, -0.0293, -0.0440],
          [-0.0160, -0.0360, -0.0557],
          [-0.0127, -0.0320, -0.0635]],

         [[-0.0163, -0.0494, -0.0602],
          [-0.0212, -0.0473, -0.0722],
          [-0.0025, -0.0370, -0.0789]],

         [[-0.0266, -0.0566, -0.0619],
          [-0.0234, -0.0488, -0.0671],
          [ 0.0023, -0.0337, -0.0721]]],


        ...,


        [[[-0.0005,  0.0003, -0.0008],
          [ 0.0003,  0.0007, -0.0002],
          [-0.0016, -0.0029, -0.0052]],

         [[-0.0008, -0.0005, -0.0028],
          [ 0.0013,  0.0015, -0.0014],
          [-0.0016, -0.0023, -0.0058]],

         [[-0.0018, -0.0029, -0.0054],
          [ 0.0003, -0.0006, -0.0039],
          [-0.0028, -0.0038, -0.0068]]],


        [[[-0.0118, -0.0167, -0.0128],
          [-0.0163, -0.0196, -0.0142],
          [-0.0106, -0.0119, -0.0101]],

         [[-0.0144, -0.0192, -0.0150],
          [-0.0155, -0.0174, -0.0124],
          [-0.0059, -0.0062, -0.0059]],

         [[-0.0089, -0.0139, -0.0110],
          [-0.0086, -0.0106, -0.0068],
          [-0.0000, -0.0004, -0.0009]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0766]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 154 | Batch_idx: 0 |  Loss: (0.1720) | Acc: (94.00%) (121/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1757) | Acc: (94.00%) (1324/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.2027) | Acc: (93.00%) (2500/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.2046) | Acc: (93.00%) (3695/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.2008) | Acc: (93.00%) (4899/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1978) | Acc: (93.00%) (6094/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1930) | Acc: (93.00%) (7292/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1904) | Acc: (93.00%) (8504/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1921) | Acc: (93.00%) (9695/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1930) | Acc: (93.00%) (10886/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1906) | Acc: (93.00%) (12098/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1904) | Acc: (93.00%) (13299/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1904) | Acc: (93.00%) (14494/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1905) | Acc: (93.00%) (15688/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1920) | Acc: (93.00%) (16874/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1909) | Acc: (93.00%) (18080/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1894) | Acc: (93.00%) (19288/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1885) | Acc: (93.00%) (20495/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1874) | Acc: (93.00%) (21696/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1864) | Acc: (93.00%) (22910/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1860) | Acc: (93.00%) (24109/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1842) | Acc: (93.00%) (25326/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1834) | Acc: (93.00%) (26532/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1823) | Acc: (93.00%) (27745/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1818) | Acc: (93.00%) (28943/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1817) | Acc: (93.00%) (30157/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1816) | Acc: (93.00%) (31359/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1815) | Acc: (93.00%) (32562/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1812) | Acc: (93.00%) (33759/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1810) | Acc: (93.00%) (34958/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1805) | Acc: (93.00%) (36163/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1802) | Acc: (93.00%) (37371/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1794) | Acc: (93.00%) (38588/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1793) | Acc: (93.00%) (39799/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1791) | Acc: (93.00%) (41011/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1781) | Acc: (94.00%) (42233/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1776) | Acc: (94.00%) (43441/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1767) | Acc: (94.00%) (44655/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1762) | Acc: (94.00%) (45867/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1754) | Acc: (94.00%) (47038/50000)
# TEST : Loss: (0.3007) | Acc: (90.00%) (9030/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8220e-01, -1.8448e-01,  8.8044e-03],
          [-2.1729e-02,  4.0799e-01,  2.5898e-01],
          [ 1.1891e-01,  8.2808e-02, -5.4409e-02]],

         [[-1.7907e-01,  2.2852e-01,  1.5899e-01],
          [ 6.0730e-02,  4.5099e-01,  2.3004e-01],
          [ 2.0745e-01,  2.1536e-02,  7.4652e-02]],

         [[-1.9987e-01, -6.1542e-02, -1.0216e-01],
          [-2.9459e-01, -1.1783e-01, -1.2518e-01],
          [-2.3694e-01, -1.6680e-01, -1.9816e-01]]],


        [[[-4.1427e-40,  1.1547e-42,  6.0778e-40],
          [-2.5501e-40,  3.1611e-40, -1.2421e-40],
          [ 1.8006e-40, -3.2879e-40, -1.9462e-40]],

         [[-3.3179e-41,  2.5788e-40, -2.1738e-40],
          [ 4.2378e-41, -2.7498e-40, -2.1187e-40],
          [ 1.1143e-40,  3.9627e-41, -1.1318e-40]],

         [[-1.9166e-40,  2.8414e-40, -4.2468e-40],
          [ 1.6104e-41,  1.6436e-40,  5.8726e-40],
          [-2.8307e-40,  2.9790e-41,  5.4505e-40]]],


        [[[ 3.8038e-02,  1.2338e-01, -2.6049e-02],
          [ 4.5694e-02,  2.1419e-01, -9.1354e-02],
          [ 1.7600e-01,  3.3547e-01,  3.5070e-01]],

         [[-1.9648e-01, -8.7923e-02, -1.5884e-01],
          [-3.9405e-01, -3.8641e-01, -3.2505e-01],
          [-2.3688e-01, -4.3815e-01,  2.6272e-02]],

         [[ 2.4541e-01,  1.7340e-01,  2.1249e-01],
          [ 2.0716e-01,  1.4223e-01,  2.3376e-02],
          [ 1.0646e-01,  8.4924e-02,  9.8102e-03]]],


        ...,


        [[[ 1.8206e-01,  4.3798e-02,  1.1888e-01],
          [ 1.0090e-01, -2.2658e-01, -5.6754e-03],
          [ 4.9981e-02, -1.1020e-01, -2.2012e-02]],

         [[-6.0156e-02, -5.3100e-02,  5.9417e-02],
          [-1.1703e-01, -2.2268e-01,  4.6405e-02],
          [ 2.4201e-02,  7.1429e-02,  1.7866e-01]],

         [[-1.0970e-01, -1.4476e-01,  5.4380e-03],
          [-1.0993e-01, -1.9876e-01, -9.8666e-02],
          [-3.9177e-02, -1.0522e-01, -4.0600e-02]]],


        [[[ 1.0173e-01,  2.0848e-01,  2.5475e-01],
          [ 1.2293e-01,  1.4022e-01,  3.3493e-02],
          [-1.6908e-01, -9.4324e-02, -4.3886e-02]],

         [[ 1.8002e-02,  3.8792e-02, -7.8931e-02],
          [ 3.9642e-03, -5.8817e-02, -2.2100e-01],
          [-1.5097e-02,  7.9827e-02, -3.6987e-02]],

         [[-2.3304e-01, -1.2181e-01, -1.7281e-01],
          [-1.0685e-01,  5.4636e-02,  4.9546e-02],
          [ 1.3182e-01,  2.7435e-01,  2.1041e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  5.7964e-40],
          [-9.5863e-41,  1.4689e-40, -1.8639e-40],
          [ 4.6914e-40, -3.2652e-40,  8.8171e-41]],

         [[ 1.4516e-40,  2.2266e-40,  4.8261e-40],
          [ 1.7903e-40, -1.7321e-40, -4.4057e-42],
          [-4.4328e-40,  1.1509e-40,  3.8970e-41]],

         [[ 4.9483e-41, -3.1794e-40, -1.5094e-40],
          [-1.7484e-40,  4.0930e-40,  3.2654e-40],
          [-9.4647e-41, -2.1965e-40,  1.3506e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1291]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0423]], device='cuda:0')

Epoch: 155 | Batch_idx: 0 |  Loss: (0.0918) | Acc: (96.00%) (124/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.1652) | Acc: (94.00%) (1324/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1661) | Acc: (94.00%) (2539/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1677) | Acc: (94.00%) (3741/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1620) | Acc: (94.00%) (4960/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1670) | Acc: (94.00%) (6159/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1674) | Acc: (94.00%) (7366/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1650) | Acc: (94.00%) (8584/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1658) | Acc: (94.00%) (9789/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1672) | Acc: (94.00%) (10989/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1658) | Acc: (94.00%) (12208/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1647) | Acc: (94.00%) (13424/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1644) | Acc: (94.00%) (14638/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1641) | Acc: (94.00%) (15850/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1652) | Acc: (94.00%) (17060/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1638) | Acc: (94.00%) (18277/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1630) | Acc: (94.00%) (19490/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1630) | Acc: (94.00%) (20700/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1625) | Acc: (94.00%) (21912/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1627) | Acc: (94.00%) (23121/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1618) | Acc: (94.00%) (24347/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1618) | Acc: (94.00%) (25555/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1618) | Acc: (94.00%) (26766/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1632) | Acc: (94.00%) (27954/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1619) | Acc: (94.00%) (29179/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1620) | Acc: (94.00%) (30390/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1611) | Acc: (94.00%) (31610/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1609) | Acc: (94.00%) (32832/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1605) | Acc: (94.00%) (34045/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1608) | Acc: (94.00%) (35237/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1606) | Acc: (94.00%) (36445/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1597) | Acc: (94.00%) (37668/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1603) | Acc: (94.00%) (38874/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1602) | Acc: (94.00%) (40089/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1600) | Acc: (94.00%) (41309/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1594) | Acc: (94.00%) (42530/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1596) | Acc: (94.00%) (43743/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1598) | Acc: (94.00%) (44952/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1598) | Acc: (94.00%) (46160/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1595) | Acc: (94.00%) (47328/50000)
# TEST : Loss: (0.2928) | Acc: (90.00%) (9027/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8143e-01, -1.8364e-01,  8.7628e-03],
          [-2.1631e-02,  4.0601e-01,  2.5768e-01],
          [ 1.1838e-01,  8.2408e-02, -5.4141e-02]],

         [[-1.7829e-01,  2.2748e-01,  1.5825e-01],
          [ 6.0459e-02,  4.4888e-01,  2.2895e-01],
          [ 2.0654e-01,  2.1436e-02,  7.4298e-02]],

         [[-1.9892e-01, -6.1253e-02, -1.0169e-01],
          [-2.9322e-01, -1.1729e-01, -1.2461e-01],
          [-2.3586e-01, -1.6604e-01, -1.9725e-01]]],


        [[[-2.7414e-40, -1.3898e-40,  4.6765e-40],
          [-1.1488e-40,  4.5624e-40, -4.0447e-40],
          [ 3.2019e-40, -1.8866e-40, -6.1501e-40]],

         [[-3.1344e-40,  2.5788e-40,  6.2879e-41],
          [-2.3788e-40, -5.5523e-40, -7.1737e-41],
          [ 1.1143e-40, -1.0050e-40, -1.1318e-40]],

         [[ 2.2873e-40,  2.8414e-40,  1.3584e-40],
          [-2.6415e-40,  2.4230e-41,  1.6687e-40],
          [-1.4294e-40, -2.5047e-40,  4.0492e-40]]],


        [[[ 3.7954e-02,  1.2311e-01, -2.5989e-02],
          [ 4.5592e-02,  2.1372e-01, -9.1148e-02],
          [ 1.7561e-01,  3.3472e-01,  3.4991e-01]],

         [[-1.9601e-01, -8.7708e-02, -1.5844e-01],
          [-3.9307e-01, -3.8544e-01, -3.2422e-01],
          [-2.3630e-01, -4.3708e-01,  2.6208e-02]],

         [[ 2.4480e-01,  1.7297e-01,  2.1194e-01],
          [ 2.0662e-01,  1.4185e-01,  2.3313e-02],
          [ 1.0618e-01,  8.4705e-02,  9.7850e-03]]],


        ...,


        [[[ 1.7958e-01,  4.3190e-02,  1.1734e-01],
          [ 9.9404e-02, -2.2317e-01, -5.5980e-03],
          [ 4.9268e-02, -1.0860e-01, -2.1720e-02]],

         [[-5.9131e-02, -5.2133e-02,  5.8497e-02],
          [-1.1467e-01, -2.1778e-01,  4.5604e-02],
          [ 2.3797e-02,  7.0142e-02,  1.7596e-01]],

         [[-1.0710e-01, -1.4058e-01,  5.3285e-03],
          [-1.0631e-01, -1.8796e-01, -9.6194e-02],
          [-3.8331e-02, -1.0247e-01, -3.9835e-02]]],


        [[[ 9.9643e-02,  2.0367e-01,  2.4911e-01],
          [ 1.2049e-01,  1.3729e-01,  3.2799e-02],
          [-1.6592e-01, -9.2528e-02, -4.3023e-02]],

         [[ 1.7692e-02,  3.8158e-02, -7.7573e-02],
          [ 3.8985e-03, -5.7899e-02, -2.1734e-01],
          [-1.4847e-02,  7.8601e-02, -3.6377e-02]],

         [[-2.2935e-01, -1.2003e-01, -1.7011e-01],
          [-1.0522e-01,  5.3873e-02,  4.8798e-02],
          [ 1.2983e-01,  2.7059e-01,  2.0730e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  2.9938e-40],
          [-5.1625e-40,  6.7571e-42,  3.7413e-40],
          [ 3.2901e-40, -4.6258e-41, -5.1959e-41]],

         [[ 4.2542e-40, -1.9773e-40,  4.8261e-40],
          [ 3.8896e-41, -3.1334e-40, -2.8467e-40],
          [-1.6302e-40,  5.3548e-40,  1.7910e-40]],

         [[-2.3078e-40, -3.7677e-41, -4.3120e-40],
          [ 1.0542e-40,  5.4943e-40, -9.3845e-41],
          [ 1.8561e-40,  2.0074e-40, -5.0727e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1102]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0378]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 156 | Batch_idx: 0 |  Loss: (0.0774) | Acc: (97.00%) (125/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1586) | Acc: (94.00%) (1328/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1620) | Acc: (94.00%) (2531/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1803) | Acc: (93.00%) (3719/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1913) | Acc: (93.00%) (4894/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1971) | Acc: (93.00%) (6073/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.2059) | Acc: (92.00%) (7249/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.2095) | Acc: (92.00%) (8423/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.2208) | Acc: (92.00%) (9574/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.2226) | Acc: (92.00%) (10753/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.2285) | Acc: (92.00%) (11911/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.2305) | Acc: (92.00%) (13080/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.2300) | Acc: (92.00%) (14261/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.2288) | Acc: (92.00%) (15443/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.2300) | Acc: (92.00%) (16621/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.2293) | Acc: (92.00%) (17806/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.2291) | Acc: (92.00%) (18989/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.2285) | Acc: (92.00%) (20175/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.2282) | Acc: (92.00%) (21356/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.2273) | Acc: (92.00%) (22540/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.2270) | Acc: (92.00%) (23721/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.2267) | Acc: (92.00%) (24908/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.2265) | Acc: (92.00%) (26091/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.2256) | Acc: (92.00%) (27283/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.2254) | Acc: (92.00%) (28478/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.2268) | Acc: (92.00%) (29643/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.2276) | Acc: (92.00%) (30807/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.2277) | Acc: (92.00%) (31979/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.2278) | Acc: (92.00%) (33169/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.2281) | Acc: (92.00%) (34335/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.2287) | Acc: (92.00%) (35507/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.2290) | Acc: (92.00%) (36685/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.2304) | Acc: (92.00%) (37852/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.2304) | Acc: (92.00%) (39031/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.2295) | Acc: (92.00%) (40227/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.2288) | Acc: (92.00%) (41415/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.2281) | Acc: (92.00%) (42607/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.2273) | Acc: (92.00%) (43799/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.2272) | Acc: (92.00%) (44977/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.2263) | Acc: (92.00%) (46127/50000)
# TEST : Loss: (0.3873) | Acc: (88.00%) (8803/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8222e-01, -1.8742e-01,  1.1602e-02],
          [-1.9440e-02,  4.1506e-01,  2.7437e-01],
          [ 1.1404e-01,  9.1936e-02, -3.1265e-02]],

         [[-1.8430e-01,  2.1816e-01,  1.5383e-01],
          [ 5.5323e-02,  4.4666e-01,  2.3076e-01],
          [ 1.9261e-01,  1.7219e-02,  8.1360e-02]],

         [[-1.9964e-01, -6.0241e-02, -9.6946e-02],
          [-2.9728e-01, -1.1617e-01, -1.1758e-01],
          [-2.5064e-01, -1.7185e-01, -1.8919e-01]]],


        [[[ 1.4625e-40, -1.3898e-40, -9.2870e-41],
          [ 1.6538e-40,  1.7598e-40, -2.6434e-40],
          [ 1.8006e-40,  9.1601e-41, -4.7488e-40]],

         [[-3.1344e-40, -2.2376e-41,  3.4314e-40],
          [-2.3788e-40, -2.7497e-40,  2.0852e-40],
          [-2.8696e-41, -1.0050e-40,  2.6950e-41]],

         [[ 3.6886e-40,  3.8858e-42,  5.5623e-40],
          [-2.6416e-40, -1.1590e-40, -3.9365e-40],
          [ 1.3732e-40, -2.5047e-40, -1.5560e-40]]],


        [[[ 2.4641e-02,  1.2425e-01, -1.0869e-02],
          [ 4.1910e-02,  2.1441e-01, -8.3357e-02],
          [ 1.8332e-01,  3.3888e-01,  3.5954e-01]],

         [[-2.1705e-01, -9.6592e-02, -1.5430e-01],
          [-4.0605e-01, -3.9624e-01, -3.2697e-01],
          [-2.3516e-01, -4.4145e-01,  2.6173e-02]],

         [[ 2.2252e-01,  1.6501e-01,  2.1466e-01],
          [ 1.9029e-01,  1.3061e-01,  1.7443e-02],
          [ 9.6606e-02,  7.2229e-02,  1.3977e-03]]],


        ...,


        [[[ 1.6385e-01,  2.8702e-02,  9.8391e-02],
          [ 8.4200e-02, -2.3299e-01, -2.0487e-02],
          [ 3.2808e-02, -1.1660e-01, -3.3964e-02]],

         [[-7.3793e-02, -6.4311e-02,  3.7979e-02],
          [-1.2720e-01, -2.2253e-01,  3.2230e-02],
          [ 1.1423e-02,  6.6873e-02,  1.6591e-01]],

         [[-1.2011e-01, -1.5026e-01, -1.7740e-02],
          [-1.1174e-01, -1.7913e-01, -1.0931e-01],
          [-4.7752e-02, -9.8542e-02, -5.1616e-02]]],


        [[[ 1.0850e-01,  2.1226e-01,  2.5871e-01],
          [ 1.2262e-01,  1.3054e-01,  3.2257e-02],
          [-1.5467e-01, -9.4324e-02, -4.6575e-02]],

         [[ 1.3107e-02,  3.1913e-02, -7.7004e-02],
          [-4.5226e-03, -7.2444e-02, -2.2304e-01],
          [-1.7343e-02,  6.3350e-02, -5.2235e-02]],

         [[-2.5807e-01, -1.4750e-01, -1.8951e-01],
          [-1.3101e-01,  2.2534e-02,  2.3663e-02],
          [ 1.1299e-01,  2.4496e-01,  1.8039e-01]]],


        [[[-3.2265e-41,  5.6510e-41, -2.6114e-40],
          [-3.7612e-40, -1.3337e-40,  5.1426e-40],
          [-9.1376e-41,  2.3400e-40, -1.9209e-40]],

         [[ 2.8529e-40, -4.7799e-40,  6.2223e-41],
          [-1.0123e-40, -1.7321e-40, -2.8467e-40],
          [ 2.5737e-40,  3.9535e-40,  1.7910e-40]],

         [[-2.3078e-40,  2.4258e-40, -2.9107e-40],
          [ 2.4555e-40,  1.2904e-40, -3.7410e-40],
          [ 3.2574e-40,  4.8100e-40, -1.4520e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0266,  0.0162,  0.0090],
          [ 0.0339,  0.0186,  0.0084],
          [ 0.0402,  0.0340,  0.0162]],

         [[ 0.0308,  0.0193,  0.0156],
          [ 0.0355,  0.0209,  0.0126],
          [ 0.0463,  0.0381,  0.0227]],

         [[ 0.0215,  0.0129,  0.0127],
          [ 0.0269,  0.0162,  0.0118],
          [ 0.0366,  0.0308,  0.0183]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0109,  0.0073,  0.0172],
          [-0.0188,  0.0060,  0.0221],
          [-0.0098,  0.0024,  0.0110]],

         [[-0.0159,  0.0066,  0.0212],
          [-0.0287,  0.0034,  0.0215],
          [-0.0329, -0.0101,  0.0018]],

         [[-0.0253, -0.0031,  0.0097],
          [-0.0375, -0.0075,  0.0098],
          [-0.0401, -0.0175, -0.0076]]],


        ...,


        [[[ 0.0067,  0.0045,  0.0033],
          [ 0.0065,  0.0056,  0.0048],
          [ 0.0057,  0.0055,  0.0056]],

         [[ 0.0003, -0.0019, -0.0033],
          [ 0.0011, -0.0000, -0.0011],
          [ 0.0011,  0.0005,  0.0006]],

         [[ 0.0003, -0.0014, -0.0024],
          [ 0.0008,  0.0000, -0.0003],
          [ 0.0009,  0.0005,  0.0012]]],


        [[[-0.0036, -0.0010, -0.0010],
          [-0.0041, -0.0004, -0.0015],
          [ 0.0009,  0.0047,  0.0034]],

         [[ 0.0004,  0.0034,  0.0046],
          [-0.0008,  0.0028,  0.0024],
          [ 0.0033,  0.0070,  0.0068]],

         [[-0.0013,  0.0012,  0.0033],
          [-0.0018,  0.0015,  0.0025],
          [ 0.0032,  0.0064,  0.0073]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1116]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 157 | Batch_idx: 0 |  Loss: (0.1320) | Acc: (97.00%) (125/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.1980) | Acc: (93.00%) (1320/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.2014) | Acc: (93.00%) (2511/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1969) | Acc: (93.00%) (3703/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1935) | Acc: (93.00%) (4906/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1894) | Acc: (93.00%) (6111/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1931) | Acc: (93.00%) (7298/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1873) | Acc: (93.00%) (8515/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1913) | Acc: (93.00%) (9697/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1891) | Acc: (93.00%) (10902/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1916) | Acc: (93.00%) (12092/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1923) | Acc: (93.00%) (13279/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1951) | Acc: (93.00%) (14457/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1959) | Acc: (93.00%) (15644/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1959) | Acc: (93.00%) (16837/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1959) | Acc: (93.00%) (18025/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1944) | Acc: (93.00%) (19228/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1948) | Acc: (93.00%) (20421/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1958) | Acc: (93.00%) (21598/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1955) | Acc: (93.00%) (22794/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1958) | Acc: (93.00%) (23993/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1974) | Acc: (93.00%) (25185/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1975) | Acc: (93.00%) (26375/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1962) | Acc: (93.00%) (27581/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1954) | Acc: (93.00%) (28778/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1943) | Acc: (93.00%) (29981/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1956) | Acc: (93.00%) (31164/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1952) | Acc: (93.00%) (32365/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1957) | Acc: (93.00%) (33555/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1972) | Acc: (93.00%) (34734/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1979) | Acc: (93.00%) (35921/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1974) | Acc: (93.00%) (37110/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1975) | Acc: (93.00%) (38305/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1980) | Acc: (93.00%) (39492/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1972) | Acc: (93.00%) (40701/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1973) | Acc: (93.00%) (41892/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1965) | Acc: (93.00%) (43097/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1973) | Acc: (93.00%) (44277/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1973) | Acc: (93.00%) (45458/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1965) | Acc: (93.00%) (46617/50000)
# TEST : Loss: (0.3283) | Acc: (89.00%) (8949/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9123e-01, -1.9656e-01,  4.5548e-04],
          [-2.6808e-02,  4.0938e-01,  2.7110e-01],
          [ 1.1180e-01,  8.4907e-02, -3.4774e-02]],

         [[-1.8413e-01,  2.1917e-01,  1.5138e-01],
          [ 5.7062e-02,  4.4960e-01,  2.3330e-01],
          [ 2.0103e-01,  2.1749e-02,  8.6468e-02]],

         [[-2.0115e-01, -6.2936e-02, -1.0500e-01],
          [-2.9882e-01, -1.1976e-01, -1.2046e-01],
          [-2.4442e-01, -1.7259e-01, -1.8840e-01]]],


        [[[ 4.2651e-40,  1.1547e-42, -5.1326e-40],
          [ 3.0551e-40, -2.4440e-40,  1.5605e-40],
          [-1.0020e-40,  2.3173e-40,  8.5640e-41]],

         [[-3.3180e-41, -3.0264e-40,  3.4314e-40],
          [ 4.2378e-41,  2.8554e-40,  2.0852e-40],
          [-1.6883e-40,  3.9627e-41,  1.6708e-40]],

         [[ 8.8601e-41, -2.7637e-40,  4.1610e-40],
          [ 1.6104e-41, -1.1590e-40, -5.3378e-40],
          [ 2.7745e-40,  2.9790e-41, -5.7599e-40]]],


        [[[ 1.8827e-02,  1.2051e-01, -1.6500e-02],
          [ 3.7335e-02,  2.1275e-01, -8.5509e-02],
          [ 1.7503e-01,  3.3179e-01,  3.5755e-01]],

         [[-2.1604e-01, -9.5825e-02, -1.5531e-01],
          [-4.0901e-01, -3.9687e-01, -3.2392e-01],
          [-2.4573e-01, -4.5010e-01,  2.7340e-02]],

         [[ 2.2767e-01,  1.7345e-01,  2.2137e-01],
          [ 1.9292e-01,  1.4027e-01,  2.7020e-02],
          [ 8.8712e-02,  6.9538e-02,  4.0898e-03]]],


        ...,


        [[[ 1.7408e-01,  3.3298e-02,  1.0986e-01],
          [ 8.5544e-02, -2.2771e-01, -1.2208e-02],
          [ 3.0486e-02, -1.1000e-01, -1.8393e-02]],

         [[-5.4795e-02, -5.6321e-02,  5.5159e-02],
          [-1.1462e-01, -2.0677e-01,  5.1205e-02],
          [ 1.8820e-02,  8.1814e-02,  1.8955e-01]],

         [[-1.0331e-01, -1.4664e-01, -7.9929e-03],
          [-1.0812e-01, -1.7475e-01, -9.7928e-02],
          [-4.7612e-02, -9.2076e-02, -3.4344e-02]]],


        [[[ 6.3489e-02,  1.6733e-01,  2.2040e-01],
          [ 7.7900e-02,  8.7263e-02, -2.4394e-03],
          [-1.9884e-01, -1.3293e-01, -8.2465e-02]],

         [[-2.5605e-02,  2.5008e-03, -9.6477e-02],
          [-4.3383e-02, -9.8767e-02, -2.3859e-01],
          [-5.3227e-02,  4.1819e-02, -6.7020e-02]],

         [[-2.8198e-01, -1.6317e-01, -1.9778e-01],
          [-1.5397e-01,  8.1685e-03,  1.3772e-02],
          [ 9.2501e-02,  2.3580e-01,  1.7451e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -5.4140e-40],
          [ 1.8440e-40, -1.3337e-40,  9.3869e-41],
          [-3.7164e-40,  2.3400e-40, -1.9209e-40]],

         [[-1.3510e-40, -3.3786e-40, -3.5817e-40],
          [-1.0123e-40,  1.0705e-40, -4.4057e-42],
          [ 3.9750e-40, -1.6517e-40,  3.8970e-41]],

         [[ 4.9483e-41,  2.4258e-40,  1.2932e-40],
          [ 1.0542e-40, -4.3148e-40, -2.3397e-40],
          [ 1.8561e-40,  3.4087e-40, -1.4520e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0317,  0.0229,  0.0278],
          [ 0.0289,  0.0214,  0.0189],
          [ 0.0174,  0.0175,  0.0168]],

         [[ 0.0109,  0.0060,  0.0113],
          [ 0.0083,  0.0060,  0.0053],
          [-0.0010,  0.0037,  0.0061]],

         [[ 0.0083,  0.0089,  0.0131],
          [ 0.0075,  0.0102,  0.0062],
          [ 0.0017,  0.0098,  0.0069]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0245,  0.0404,  0.0395],
          [ 0.0216,  0.0303,  0.0207],
          [ 0.0239,  0.0340,  0.0295]],

         [[ 0.0076,  0.0229,  0.0271],
          [ 0.0064,  0.0134,  0.0044],
          [ 0.0108,  0.0169,  0.0080]],

         [[-0.0057, -0.0010, -0.0020],
          [-0.0125, -0.0133, -0.0207],
          [-0.0133, -0.0098, -0.0151]]],


        ...,


        [[[ 0.0009, -0.0012, -0.0011],
          [ 0.0003, -0.0008, -0.0002],
          [ 0.0033,  0.0027,  0.0033]],

         [[-0.0001, -0.0020, -0.0019],
          [-0.0003, -0.0011, -0.0008],
          [ 0.0025,  0.0017,  0.0022]],

         [[ 0.0027,  0.0006,  0.0005],
          [ 0.0010,  0.0002,  0.0003],
          [ 0.0017,  0.0010,  0.0019]]],


        [[[-0.0001,  0.0004,  0.0009],
          [ 0.0005,  0.0008,  0.0012],
          [ 0.0014,  0.0012,  0.0011]],

         [[-0.0011, -0.0008, -0.0005],
          [-0.0004,  0.0000,  0.0004],
          [ 0.0009,  0.0009,  0.0008]],

         [[ 0.0005,  0.0008,  0.0011],
          [ 0.0006,  0.0011,  0.0014],
          [ 0.0014,  0.0016,  0.0017]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1113]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 158 | Batch_idx: 0 |  Loss: (0.1750) | Acc: (94.00%) (121/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.1932) | Acc: (93.00%) (1316/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.2051) | Acc: (93.00%) (2515/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.2001) | Acc: (93.00%) (3705/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.2059) | Acc: (93.00%) (4888/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.2040) | Acc: (93.00%) (6075/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.2038) | Acc: (92.00%) (7261/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.2016) | Acc: (93.00%) (8457/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.2013) | Acc: (93.00%) (9647/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1997) | Acc: (93.00%) (10840/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1950) | Acc: (93.00%) (12055/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1919) | Acc: (93.00%) (13267/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1912) | Acc: (93.00%) (14469/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1898) | Acc: (93.00%) (15665/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1882) | Acc: (93.00%) (16873/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1874) | Acc: (93.00%) (18074/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1855) | Acc: (93.00%) (19284/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1842) | Acc: (93.00%) (20496/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1847) | Acc: (93.00%) (21694/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1843) | Acc: (93.00%) (22896/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1838) | Acc: (93.00%) (24097/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1842) | Acc: (93.00%) (25285/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1838) | Acc: (93.00%) (26495/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1828) | Acc: (93.00%) (27706/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1838) | Acc: (93.00%) (28900/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1832) | Acc: (93.00%) (30113/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1824) | Acc: (93.00%) (31325/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1808) | Acc: (93.00%) (32544/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1802) | Acc: (93.00%) (33757/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1800) | Acc: (93.00%) (34959/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1791) | Acc: (93.00%) (36172/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1784) | Acc: (93.00%) (37378/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1783) | Acc: (93.00%) (38580/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1779) | Acc: (93.00%) (39787/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1772) | Acc: (93.00%) (41003/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1765) | Acc: (93.00%) (42213/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1767) | Acc: (93.00%) (43411/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1765) | Acc: (93.00%) (44616/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1759) | Acc: (93.00%) (45830/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1752) | Acc: (93.00%) (46997/50000)
# TEST : Loss: (0.2980) | Acc: (90.00%) (9035/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9172e-01, -1.9607e-01,  7.6064e-05],
          [-2.9197e-02,  4.0685e-01,  2.7002e-01],
          [ 1.1072e-01,  8.4632e-02, -3.4815e-02]],

         [[-1.8243e-01,  2.2012e-01,  1.5220e-01],
          [ 5.6202e-02,  4.4854e-01,  2.3362e-01],
          [ 2.0101e-01,  2.2771e-02,  8.6584e-02]],

         [[-1.9907e-01, -6.1274e-02, -1.0382e-01],
          [-2.9786e-01, -1.1889e-01, -1.1908e-01],
          [-2.4278e-01, -1.7129e-01, -1.8757e-01]]],


        [[[ 2.8638e-40,  1.4128e-40, -3.7313e-40],
          [ 1.6538e-40, -3.8453e-40,  4.3631e-40],
          [-2.4033e-40,  9.1601e-41,  5.0603e-40]],

         [[ 2.4708e-40, -3.0264e-40,  6.2879e-41],
          [ 3.2264e-40,  5.6580e-40, -7.1737e-41],
          [-1.6883e-40,  1.7976e-40,  1.6708e-40]],

         [[-3.3179e-40, -2.7637e-40, -1.4442e-40],
          [ 2.9636e-40,  2.4230e-41, -1.1339e-40],
          [ 1.3732e-40,  3.1005e-40, -4.3586e-40]]],


        [[[ 1.9306e-02,  1.2148e-01, -1.4764e-02],
          [ 3.7533e-02,  2.1344e-01, -8.3679e-02],
          [ 1.7475e-01,  3.3138e-01,  3.5755e-01]],

         [[-2.1427e-01, -9.3787e-02, -1.5243e-01],
          [-4.0721e-01, -3.9445e-01, -3.2049e-01],
          [-2.4467e-01, -4.4845e-01,  2.8981e-02]],

         [[ 2.2900e-01,  1.7574e-01,  2.2443e-01],
          [ 1.9462e-01,  1.4316e-01,  3.1209e-02],
          [ 9.0746e-02,  7.1938e-02,  7.2748e-03]]],


        ...,


        [[[ 1.7394e-01,  3.6893e-02,  1.1157e-01],
          [ 8.6253e-02, -2.2055e-01, -9.9315e-03],
          [ 3.0869e-02, -1.0642e-01, -1.7302e-02]],

         [[-5.1990e-02, -5.1094e-02,  5.7031e-02],
          [-1.1088e-01, -1.9846e-01,  5.1536e-02],
          [ 1.8042e-02,  8.0681e-02,  1.8621e-01]],

         [[-1.0224e-01, -1.4033e-01, -7.5135e-03],
          [-1.0627e-01, -1.6192e-01, -9.5768e-02],
          [-4.8498e-02, -8.9709e-02, -3.4863e-02]]],


        [[[ 6.2441e-02,  1.6413e-01,  2.1607e-01],
          [ 7.6505e-02,  8.5486e-02, -3.1915e-03],
          [-1.9607e-01, -1.3114e-01, -8.1586e-02]],

         [[-2.5012e-02,  2.3415e-03, -9.5234e-02],
          [-4.2818e-02, -9.7491e-02, -2.3525e-01],
          [-5.2652e-02,  4.0705e-02, -6.6289e-02]],

         [[-2.7712e-01, -1.6103e-01, -1.9506e-01],
          [-1.5194e-01,  7.0549e-03,  1.2291e-02],
          [ 9.0107e-02,  2.3120e-01,  1.7063e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -2.6114e-40],
          [ 6.0479e-40,  6.7571e-42, -4.6665e-40],
          [-2.3151e-40, -4.6258e-41, -5.1959e-41]],

         [[-4.1536e-40,  8.2529e-41, -3.5817e-40],
          [ 3.8896e-41,  2.4718e-40,  2.7585e-40],
          [ 1.1724e-40, -5.8556e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.7677e-41,  4.0958e-40],
          [-1.7484e-40, -5.7161e-40,  1.8641e-40],
          [-9.4647e-41, -7.9518e-41, -5.0727e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1768]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0347]], device='cuda:0')

Epoch: 159 | Batch_idx: 0 |  Loss: (0.1477) | Acc: (94.00%) (121/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1683) | Acc: (94.00%) (1330/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.1637) | Acc: (94.00%) (2542/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.1603) | Acc: (94.00%) (3754/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.1598) | Acc: (94.00%) (4968/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.1579) | Acc: (94.00%) (6185/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.1566) | Acc: (94.00%) (7401/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.1554) | Acc: (94.00%) (8624/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.1564) | Acc: (94.00%) (9834/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1582) | Acc: (94.00%) (11033/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1587) | Acc: (94.00%) (12232/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1580) | Acc: (94.00%) (13455/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.1593) | Acc: (94.00%) (14656/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.1570) | Acc: (94.00%) (15883/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.1573) | Acc: (94.00%) (17096/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1591) | Acc: (94.00%) (18296/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1585) | Acc: (94.00%) (19514/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1577) | Acc: (94.00%) (20729/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1577) | Acc: (94.00%) (21941/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1573) | Acc: (94.00%) (23154/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1576) | Acc: (94.00%) (24366/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1573) | Acc: (94.00%) (25581/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1576) | Acc: (94.00%) (26797/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1570) | Acc: (94.00%) (28013/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1563) | Acc: (94.00%) (29240/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1564) | Acc: (94.00%) (30449/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1573) | Acc: (94.00%) (31647/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1580) | Acc: (94.00%) (32857/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1576) | Acc: (94.00%) (34079/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1577) | Acc: (94.00%) (35295/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1579) | Acc: (94.00%) (36505/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1580) | Acc: (94.00%) (37713/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1575) | Acc: (94.00%) (38935/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1572) | Acc: (94.00%) (40149/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1572) | Acc: (94.00%) (41360/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1577) | Acc: (94.00%) (42561/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1580) | Acc: (94.00%) (43763/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1581) | Acc: (94.00%) (44976/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1586) | Acc: (94.00%) (46187/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1582) | Acc: (94.00%) (47360/50000)
# TEST : Loss: (0.2895) | Acc: (90.00%) (9050/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9093e-01, -1.9521e-01,  7.5716e-05],
          [-2.9071e-02,  4.0496e-01,  2.6872e-01],
          [ 1.1025e-01,  8.4245e-02, -3.4655e-02]],

         [[-1.8166e-01,  2.1916e-01,  1.5152e-01],
          [ 5.5958e-02,  4.4652e-01,  2.3255e-01],
          [ 2.0016e-01,  2.2669e-02,  8.6197e-02]],

         [[-1.9814e-01, -6.0993e-02, -1.0335e-01],
          [-2.9649e-01, -1.1835e-01, -1.1854e-01],
          [-2.4169e-01, -1.7052e-01, -1.8673e-01]]],


        [[[-1.3401e-40,  1.4128e-40,  1.8739e-40],
          [-1.1488e-40, -1.0427e-40,  2.9618e-40],
          [-1.0020e-40, -1.8866e-40,  3.6590e-40]],

         [[ 2.4708e-40, -2.2376e-41, -2.1738e-40],
          [ 3.2264e-40,  2.8554e-40, -2.1187e-40],
          [-2.8696e-41,  1.7976e-40,  2.6950e-41]],

         [[-4.7192e-40,  3.8858e-42, -5.6481e-40],
          [ 2.9636e-40,  1.6436e-40,  4.4713e-40],
          [-1.4294e-40,  3.1005e-40,  1.2466e-40]]],


        [[[ 1.9264e-02,  1.2121e-01, -1.4731e-02],
          [ 3.7451e-02,  2.1299e-01, -8.3498e-02],
          [ 1.7436e-01,  3.3066e-01,  3.5675e-01]],

         [[-2.1375e-01, -9.3561e-02, -1.5205e-01],
          [-4.0621e-01, -3.9349e-01, -3.1970e-01],
          [-2.4407e-01, -4.4736e-01,  2.8911e-02]],

         [[ 2.2842e-01,  1.7529e-01,  2.2385e-01],
          [ 1.9411e-01,  1.4279e-01,  3.1127e-02],
          [ 9.0509e-02,  7.1751e-02,  7.2560e-03]]],


        ...,


        [[[ 1.7076e-01,  3.6214e-02,  1.0970e-01],
          [ 8.4489e-02, -2.1598e-01, -9.7495e-03],
          [ 3.0256e-02, -1.0426e-01, -1.6991e-02]],

         [[-5.0772e-02, -4.9814e-02,  5.5867e-02],
          [-1.0764e-01, -1.9200e-01,  5.0297e-02],
          [ 1.7602e-02,  7.8531e-02,  1.8224e-01]],

         [[-9.8873e-02, -1.3472e-01, -7.3105e-03],
          [-1.0101e-01, -1.4803e-01, -9.2403e-02],
          [-4.6939e-02, -8.6222e-02, -3.3934e-02]]],


        [[[ 6.1349e-02,  1.6101e-01,  2.1215e-01],
          [ 7.5176e-02,  8.3896e-02, -3.1343e-03],
          [-1.9231e-01, -1.2856e-01, -7.9985e-02]],

         [[-2.4510e-02,  2.2945e-03, -9.3315e-02],
          [-4.1966e-02, -9.5566e-02, -2.3053e-01],
          [-5.1534e-02,  3.9898e-02, -6.4903e-02]],

         [[-2.7063e-01, -1.5748e-01, -1.9057e-01],
          [-1.4861e-01,  6.9100e-03,  1.2021e-02],
          [ 8.8198e-02,  2.2683e-01,  1.6717e-01]]],


        [[[-3.2265e-41,  5.6510e-41,  2.9938e-40],
          [ 4.6466e-40,  1.4689e-40, -6.0678e-40],
          [ 1.8888e-40, -3.2652e-40,  8.8171e-41]],

         [[-2.7523e-40,  3.6279e-40,  6.2223e-41],
          [ 1.7903e-40,  1.0705e-40,  2.7585e-40],
          [-3.0315e-40, -4.4543e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.1794e-40,  2.6945e-40],
          [-3.1497e-40, -1.5122e-40,  4.6667e-40],
          [-2.3478e-40, -3.5978e-40,  1.3506e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1872]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0152]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 160 | Batch_idx: 0 |  Loss: (0.1458) | Acc: (94.00%) (121/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.1505) | Acc: (94.00%) (1329/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.1582) | Acc: (94.00%) (2537/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1779) | Acc: (93.00%) (3720/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1862) | Acc: (93.00%) (4914/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.2021) | Acc: (93.00%) (6073/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.2002) | Acc: (93.00%) (7274/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.2050) | Acc: (93.00%) (8453/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.2046) | Acc: (93.00%) (9644/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.2073) | Acc: (92.00%) (10824/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.2157) | Acc: (92.00%) (11984/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.2223) | Acc: (92.00%) (13135/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.2269) | Acc: (92.00%) (14296/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.2301) | Acc: (92.00%) (15460/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.2299) | Acc: (92.00%) (16640/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.2326) | Acc: (92.00%) (17804/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.2335) | Acc: (92.00%) (18979/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.2325) | Acc: (92.00%) (20154/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.2327) | Acc: (92.00%) (21327/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.2336) | Acc: (92.00%) (22499/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.2330) | Acc: (92.00%) (23673/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.2325) | Acc: (92.00%) (24848/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.2332) | Acc: (91.00%) (26017/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.2326) | Acc: (92.00%) (27207/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.2320) | Acc: (92.00%) (28397/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.2312) | Acc: (92.00%) (29585/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.2300) | Acc: (92.00%) (30784/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.2290) | Acc: (92.00%) (31970/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.2292) | Acc: (92.00%) (33160/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.2291) | Acc: (92.00%) (34339/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.2284) | Acc: (92.00%) (35539/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.2280) | Acc: (92.00%) (36718/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.2287) | Acc: (92.00%) (37901/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.2279) | Acc: (92.00%) (39090/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.2273) | Acc: (92.00%) (40283/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.2274) | Acc: (92.00%) (41462/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.2268) | Acc: (92.00%) (42654/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.2272) | Acc: (92.00%) (43831/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.2269) | Acc: (92.00%) (45010/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.2270) | Acc: (92.00%) (46139/50000)
# TEST : Loss: (0.4608) | Acc: (86.00%) (8631/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9639e-01, -2.0370e-01, -9.2349e-03],
          [-3.2138e-02,  4.0259e-01,  2.6201e-01],
          [ 1.1509e-01,  8.7583e-02, -4.3296e-02]],

         [[-1.8655e-01,  2.1062e-01,  1.4057e-01],
          [ 5.6427e-02,  4.4881e-01,  2.2786e-01],
          [ 2.0987e-01,  3.3460e-02,  8.1698e-02]],

         [[-1.9864e-01, -6.7877e-02, -1.1758e-01],
          [-3.0081e-01, -1.2227e-01, -1.2882e-01],
          [-2.4187e-01, -1.6928e-01, -1.9440e-01]]],


        [[[-4.1427e-40,  1.1547e-42,  6.0778e-40],
          [-2.5501e-40,  3.1612e-40, -1.2421e-40],
          [ 1.8006e-40, -3.2879e-40, -1.9462e-40]],

         [[-3.3180e-41,  2.5788e-40, -2.1738e-40],
          [ 4.2378e-41, -2.7497e-40, -7.1737e-41],
          [ 1.1143e-40,  3.9627e-41, -1.1318e-40]],

         [[-1.9166e-40,  2.8415e-40, -4.2468e-40],
          [ 1.6104e-41,  1.6436e-40,  5.8726e-40],
          [-2.8307e-40,  2.9790e-41,  5.4505e-40]]],


        [[[ 1.8051e-02,  1.1745e-01, -1.6956e-02],
          [ 3.3663e-02,  2.1240e-01, -8.6182e-02],
          [ 1.7506e-01,  3.2790e-01,  3.5209e-01]],

         [[-2.1800e-01, -9.6862e-02, -1.5152e-01],
          [-4.1436e-01, -3.9653e-01, -3.2015e-01],
          [-2.4705e-01, -4.5198e-01,  2.8725e-02]],

         [[ 2.3332e-01,  1.8380e-01,  2.3336e-01],
          [ 1.9384e-01,  1.4969e-01,  3.6590e-02],
          [ 9.3947e-02,  7.5373e-02,  1.1257e-02]]],


        ...,


        [[[ 1.7674e-01,  2.6129e-02,  9.3020e-02],
          [ 8.6090e-02, -2.2304e-01, -2.5467e-02],
          [ 3.0924e-02, -1.1482e-01, -3.8492e-02]],

         [[-4.6264e-02, -7.1103e-02,  2.6978e-02],
          [-1.1328e-01, -2.1759e-01,  1.8300e-02],
          [ 8.4156e-03,  4.6436e-02,  1.4442e-01]],

         [[-9.0352e-02, -1.5346e-01, -3.2225e-02],
          [-9.5003e-02, -1.8306e-01, -1.1936e-01],
          [-4.3602e-02, -1.1210e-01, -7.0205e-02]]],


        [[[ 9.8258e-02,  2.1159e-01,  2.5287e-01],
          [ 9.4517e-02,  1.1212e-01,  2.9288e-02],
          [-1.7520e-01, -1.0461e-01, -4.9728e-02]],

         [[ 1.6931e-02,  5.3288e-02, -5.2281e-02],
          [-1.1748e-02, -5.8715e-02, -1.9264e-01],
          [-2.5609e-02,  6.8369e-02, -3.0225e-02]],

         [[-2.1650e-01, -1.0184e-01, -1.4059e-01],
          [-1.0572e-01,  4.7978e-02,  5.4364e-02],
          [ 1.2220e-01,  2.5971e-01,  2.0185e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  5.7964e-40],
          [-9.5863e-41,  1.4689e-40, -1.8639e-40],
          [ 4.6914e-40, -3.2652e-40,  8.8171e-41]],

         [[ 1.4516e-40,  2.2266e-40,  4.8261e-40],
          [ 1.7903e-40, -1.7321e-40, -4.4057e-42],
          [-4.4328e-40,  1.1509e-40,  3.8970e-41]],

         [[ 4.9483e-41, -3.1794e-40, -1.5094e-40],
          [-1.7484e-40,  4.0930e-40,  3.2654e-40],
          [-9.4647e-41, -2.1965e-40,  1.3506e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0256,  0.0231,  0.0239],
          [ 0.0227,  0.0170,  0.0148],
          [ 0.0178,  0.0104,  0.0065]],

         [[ 0.0235,  0.0213,  0.0239],
          [ 0.0207,  0.0142,  0.0124],
          [ 0.0151,  0.0075,  0.0039]],

         [[ 0.0201,  0.0184,  0.0198],
          [ 0.0166,  0.0121,  0.0102],
          [ 0.0125,  0.0067,  0.0035]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0444, -0.0197, -0.0156],
          [-0.0336, -0.0134, -0.0193],
          [-0.0270, -0.0130, -0.0259]],

         [[-0.0436, -0.0174, -0.0127],
          [-0.0294, -0.0071, -0.0118],
          [-0.0240, -0.0072, -0.0214]],

         [[-0.0352, -0.0101, -0.0102],
          [-0.0169,  0.0025, -0.0079],
          [-0.0155, -0.0011, -0.0193]]],


        ...,


        [[[-0.0004, -0.0018, -0.0026],
          [-0.0019, -0.0027, -0.0032],
          [-0.0008, -0.0005, -0.0008]],

         [[ 0.0014, -0.0007, -0.0021],
          [-0.0003, -0.0016, -0.0025],
          [-0.0004, -0.0004, -0.0007]],

         [[ 0.0026,  0.0007, -0.0001],
          [ 0.0004, -0.0005, -0.0006],
          [-0.0002,  0.0007,  0.0011]]],


        [[[ 0.0009,  0.0010,  0.0002],
          [-0.0001,  0.0000, -0.0004],
          [-0.0004, -0.0006, -0.0008]],

         [[ 0.0007,  0.0009,  0.0003],
          [-0.0002,  0.0002, -0.0002],
          [-0.0008, -0.0008, -0.0010]],

         [[ 0.0014,  0.0016,  0.0010],
          [ 0.0008,  0.0011,  0.0006],
          [ 0.0001,  0.0001, -0.0002]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1860]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 161 | Batch_idx: 0 |  Loss: (0.2140) | Acc: (92.00%) (118/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.2082) | Acc: (92.00%) (1308/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.1836) | Acc: (93.00%) (2522/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.1755) | Acc: (94.00%) (3730/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.1774) | Acc: (93.00%) (4930/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1770) | Acc: (93.00%) (6131/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1741) | Acc: (94.00%) (7342/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1734) | Acc: (94.00%) (8544/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1767) | Acc: (93.00%) (9731/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1765) | Acc: (93.00%) (10937/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1781) | Acc: (93.00%) (12138/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1791) | Acc: (93.00%) (13337/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1781) | Acc: (93.00%) (14539/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1793) | Acc: (93.00%) (15730/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1817) | Acc: (93.00%) (16920/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1811) | Acc: (93.00%) (18124/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1830) | Acc: (93.00%) (19302/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1852) | Acc: (93.00%) (20494/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1851) | Acc: (93.00%) (21691/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1851) | Acc: (93.00%) (22883/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1860) | Acc: (93.00%) (24074/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1870) | Acc: (93.00%) (25269/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1873) | Acc: (93.00%) (26466/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1863) | Acc: (93.00%) (27677/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1863) | Acc: (93.00%) (28870/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1866) | Acc: (93.00%) (30060/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1873) | Acc: (93.00%) (31248/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1881) | Acc: (93.00%) (32437/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1876) | Acc: (93.00%) (33633/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1878) | Acc: (93.00%) (34837/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1880) | Acc: (93.00%) (36022/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1882) | Acc: (93.00%) (37219/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1881) | Acc: (93.00%) (38408/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1875) | Acc: (93.00%) (39612/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1874) | Acc: (93.00%) (40811/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1874) | Acc: (93.00%) (42004/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1868) | Acc: (93.00%) (43205/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1870) | Acc: (93.00%) (44401/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1874) | Acc: (93.00%) (45597/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1874) | Acc: (93.00%) (46750/50000)
# TEST : Loss: (0.3254) | Acc: (89.00%) (8988/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8978e-01, -2.0078e-01, -3.6256e-03],
          [-3.0645e-02,  3.9884e-01,  2.6227e-01],
          [ 1.1142e-01,  7.8524e-02, -4.4580e-02]],

         [[-1.8591e-01,  2.0757e-01,  1.4106e-01],
          [ 5.4175e-02,  4.4263e-01,  2.2467e-01],
          [ 2.0291e-01,  2.3068e-02,  7.8916e-02]],

         [[-2.0544e-01, -7.3940e-02, -1.1620e-01],
          [-3.1039e-01, -1.3280e-01, -1.3188e-01],
          [-2.5683e-01, -1.8343e-01, -1.9656e-01]]],


        [[[-2.7414e-40, -1.3898e-40,  4.6765e-40],
          [-1.1488e-40,  4.5625e-40, -4.0447e-40],
          [ 3.2019e-40, -1.8866e-40, -6.1501e-40]],

         [[-3.1344e-40,  2.5788e-40,  6.2879e-41],
          [-2.3788e-40, -5.5523e-40,  2.0852e-40],
          [ 1.1143e-40, -1.0050e-40, -1.1318e-40]],

         [[ 2.2873e-40,  2.8415e-40,  1.3584e-40],
          [-2.6416e-40,  2.4230e-41,  1.6687e-40],
          [-1.4294e-40, -2.5047e-40,  4.0492e-40]]],


        [[[ 2.3929e-02,  1.1347e-01, -3.0233e-02],
          [ 4.1822e-02,  2.1423e-01, -9.2253e-02],
          [ 1.8244e-01,  3.3420e-01,  3.5477e-01]],

         [[-2.0710e-01, -9.9759e-02, -1.6698e-01],
          [-4.0607e-01, -3.9827e-01, -3.3207e-01],
          [-2.3857e-01, -4.4525e-01,  2.9237e-02]],

         [[ 2.4143e-01,  1.8165e-01,  2.2029e-01],
          [ 2.0045e-01,  1.4821e-01,  2.5824e-02],
          [ 1.0464e-01,  8.3419e-02,  1.2335e-02]]],


        ...,


        [[[ 1.9088e-01,  3.3928e-02,  9.9043e-02],
          [ 9.8169e-02, -2.2000e-01, -2.2313e-02],
          [ 4.8270e-02, -1.0402e-01, -3.2101e-02]],

         [[-1.7596e-02, -5.1755e-02,  3.7295e-02],
          [-8.2694e-02, -1.9850e-01,  2.5457e-02],
          [ 3.7470e-02,  6.7694e-02,  1.5631e-01]],

         [[-7.5772e-02, -1.4998e-01, -3.8106e-02],
          [-9.1000e-02, -1.9893e-01, -1.2784e-01],
          [-4.3113e-02, -1.1320e-01, -6.9488e-02]]],


        [[[ 1.2178e-01,  2.3002e-01,  2.6109e-01],
          [ 1.1065e-01,  1.2112e-01,  3.2227e-02],
          [-1.5173e-01, -8.7754e-02, -4.0934e-02]],

         [[ 2.4105e-02,  5.7894e-02, -4.7329e-02],
          [-8.7209e-03, -5.7720e-02, -1.9195e-01],
          [-1.9068e-02,  7.2360e-02, -2.9688e-02]],

         [[-2.2163e-01, -1.1227e-01, -1.5150e-01],
          [-1.1527e-01,  3.1690e-02,  3.4634e-02],
          [ 1.1548e-01,  2.4718e-01,  1.8461e-01]]],


        [[[-1.7239e-40, -2.2375e-40,  2.9938e-40],
          [-5.1625e-40,  6.7571e-42,  3.7413e-40],
          [ 3.2901e-40, -4.6258e-41, -5.1959e-41]],

         [[ 4.2542e-40, -1.9773e-40,  4.8261e-40],
          [ 3.8896e-41, -3.1334e-40, -2.8467e-40],
          [-1.6302e-40,  5.3548e-40,  1.7910e-40]],

         [[-2.3078e-40, -3.7677e-41, -4.3120e-40],
          [ 1.0542e-40,  5.4943e-40, -9.3845e-41],
          [ 1.8561e-40,  2.0074e-40, -5.0727e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0254,  0.0284,  0.0202],
          [ 0.0342,  0.0409,  0.0355],
          [ 0.0140,  0.0282,  0.0341]],

         [[ 0.0407,  0.0454,  0.0368],
          [ 0.0505,  0.0585,  0.0536],
          [ 0.0295,  0.0474,  0.0525]],

         [[ 0.0385,  0.0415,  0.0342],
          [ 0.0499,  0.0576,  0.0525],
          [ 0.0369,  0.0556,  0.0571]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0448, -0.0501, -0.0613],
          [-0.0463, -0.0495, -0.0578],
          [-0.0611, -0.0667, -0.0553]],

         [[-0.0048, -0.0102, -0.0194],
          [-0.0157, -0.0209, -0.0240],
          [-0.0388, -0.0453, -0.0273]],

         [[ 0.0267,  0.0169,  0.0111],
          [ 0.0059, -0.0039, -0.0030],
          [-0.0180, -0.0241, -0.0021]]],


        ...,


        [[[ 0.0043,  0.0049,  0.0078],
          [ 0.0029,  0.0025,  0.0059],
          [ 0.0036,  0.0019,  0.0047]],

         [[ 0.0016,  0.0022,  0.0046],
          [-0.0010, -0.0008,  0.0020],
          [-0.0018, -0.0026,  0.0002]],

         [[ 0.0015,  0.0021,  0.0045],
          [ 0.0006,  0.0006,  0.0032],
          [ 0.0002, -0.0005,  0.0022]]],


        [[[ 0.0020,  0.0018,  0.0023],
          [ 0.0032,  0.0013,  0.0010],
          [ 0.0036,  0.0012,  0.0011]],

         [[ 0.0017,  0.0016,  0.0026],
          [ 0.0024,  0.0007,  0.0009],
          [ 0.0022, -0.0001,  0.0003]],

         [[ 0.0042,  0.0036,  0.0042],
          [ 0.0046,  0.0029,  0.0031],
          [ 0.0039,  0.0021,  0.0027]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1856]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 162 | Batch_idx: 0 |  Loss: (0.1547) | Acc: (94.00%) (121/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.1910) | Acc: (92.00%) (1308/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.2024) | Acc: (92.00%) (2495/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.2096) | Acc: (92.00%) (3672/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.2077) | Acc: (92.00%) (4869/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.2110) | Acc: (92.00%) (6050/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.2131) | Acc: (92.00%) (7222/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.2134) | Acc: (92.00%) (8413/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.2108) | Acc: (92.00%) (9608/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.2058) | Acc: (92.00%) (10816/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.2042) | Acc: (92.00%) (12019/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.2024) | Acc: (93.00%) (13223/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.1999) | Acc: (93.00%) (14434/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.1981) | Acc: (93.00%) (15640/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.1968) | Acc: (93.00%) (16840/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.1961) | Acc: (93.00%) (18043/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.1942) | Acc: (93.00%) (19252/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.1937) | Acc: (93.00%) (20454/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.1931) | Acc: (93.00%) (21644/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.1929) | Acc: (93.00%) (22839/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.1922) | Acc: (93.00%) (24043/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.1908) | Acc: (93.00%) (25251/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.1899) | Acc: (93.00%) (26461/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.1877) | Acc: (93.00%) (27675/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.1867) | Acc: (93.00%) (28884/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.1861) | Acc: (93.00%) (30088/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.1849) | Acc: (93.00%) (31294/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.1845) | Acc: (93.00%) (32503/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.1836) | Acc: (93.00%) (33711/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.1831) | Acc: (93.00%) (34918/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.1824) | Acc: (93.00%) (36129/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.1815) | Acc: (93.00%) (37337/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.1805) | Acc: (93.00%) (38557/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.1794) | Acc: (93.00%) (39777/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.1786) | Acc: (93.00%) (40995/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.1788) | Acc: (93.00%) (42197/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.1797) | Acc: (93.00%) (43383/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.1786) | Acc: (93.00%) (44604/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.1782) | Acc: (93.00%) (45814/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.1774) | Acc: (93.00%) (46983/50000)
# TEST : Loss: (0.2975) | Acc: (90.00%) (9065/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9270e-01, -2.0433e-01, -7.1254e-03],
          [-3.4637e-02,  3.9201e-01,  2.5607e-01],
          [ 1.0867e-01,  7.3903e-02, -5.0012e-02]],

         [[-1.9131e-01,  1.9993e-01,  1.3483e-01],
          [ 4.7562e-02,  4.3354e-01,  2.1692e-01],
          [ 1.9756e-01,  1.6388e-02,  7.1239e-02]],

         [[-2.1050e-01, -7.9879e-02, -1.2083e-01],
          [-3.1543e-01, -1.3907e-01, -1.3730e-01],
          [-2.6109e-01, -1.8949e-01, -2.0260e-01]]],


        [[[ 1.4625e-40, -1.3898e-40, -9.2870e-41],
          [ 1.6538e-40,  1.7599e-40, -2.6434e-40],
          [ 1.8006e-40,  9.1601e-41, -4.7488e-40]],

         [[-3.1344e-40, -2.2376e-41,  3.4314e-40],
          [-2.3788e-40, -2.7497e-40,  2.0852e-40],
          [-2.8696e-41, -1.0050e-40,  2.6950e-41]],

         [[ 3.6886e-40,  3.8858e-42,  5.5623e-40],
          [-2.6416e-40, -1.1590e-40, -3.9365e-40],
          [ 1.3732e-40, -2.5047e-40, -1.5560e-40]]],


        [[[ 2.5235e-02,  1.1456e-01, -2.8854e-02],
          [ 4.2458e-02,  2.1473e-01, -9.1659e-02],
          [ 1.8365e-01,  3.3495e-01,  3.5449e-01]],

         [[-2.0696e-01, -9.9963e-02, -1.6727e-01],
          [-4.0595e-01, -3.9815e-01, -3.3308e-01],
          [-2.3724e-01, -4.4404e-01,  2.7650e-02]],

         [[ 2.3878e-01,  1.7921e-01,  2.1760e-01],
          [ 1.9785e-01,  1.4589e-01,  2.2712e-02],
          [ 1.0386e-01,  8.2161e-02,  9.2796e-03]]],


        ...,


        [[[ 1.8547e-01,  3.2691e-02,  9.6647e-02],
          [ 9.3388e-02, -2.1720e-01, -2.3720e-02],
          [ 4.3740e-02, -1.0346e-01, -3.4058e-02]],

         [[-1.9135e-02, -4.9848e-02,  3.7460e-02],
          [-8.3687e-02, -1.9276e-01,  2.4391e-02],
          [ 3.3227e-02,  6.6050e-02,  1.5165e-01]],

         [[-7.6699e-02, -1.4496e-01, -3.7889e-02],
          [-9.2971e-02, -1.8336e-01, -1.2650e-01],
          [-4.7947e-02, -1.1130e-01, -7.1493e-02]]],


        [[[ 1.1887e-01,  2.2408e-01,  2.5450e-01],
          [ 1.0766e-01,  1.1777e-01,  3.0536e-02],
          [-1.5107e-01, -8.8142e-02, -4.2161e-02]],

         [[ 2.2653e-02,  5.5312e-02, -4.8211e-02],
          [-9.7381e-03, -5.7695e-02, -1.8956e-01],
          [-2.0388e-02,  6.9899e-02, -3.0442e-02]],

         [[-2.1902e-01, -1.1214e-01, -1.5062e-01],
          [-1.1503e-01,  2.9723e-02,  3.2422e-02],
          [ 1.1169e-01,  2.4205e-01,  1.8000e-01]]],


        [[[-3.2265e-41,  5.6510e-41, -2.6114e-40],
          [-3.7612e-40, -1.3337e-40,  5.1426e-40],
          [-9.1376e-41,  2.3400e-40, -1.9209e-40]],

         [[ 2.8529e-40, -4.7799e-40,  6.2223e-41],
          [-1.0123e-40, -1.7321e-40, -2.8467e-40],
          [ 2.5737e-40,  3.9535e-40,  1.7910e-40]],

         [[-2.3078e-40,  2.4258e-40, -2.9107e-40],
          [ 2.4555e-40,  1.2904e-40, -3.7410e-40],
          [ 3.2574e-40,  4.8100e-40, -1.4520e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1984]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0018]], device='cuda:0')

Epoch: 163 | Batch_idx: 0 |  Loss: (0.1491) | Acc: (94.00%) (121/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.1549) | Acc: (94.00%) (1329/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.1573) | Acc: (94.00%) (2535/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.1590) | Acc: (94.00%) (3742/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.1597) | Acc: (94.00%) (4952/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.1568) | Acc: (94.00%) (6171/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.1538) | Acc: (94.00%) (7385/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.1522) | Acc: (94.00%) (8603/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.1512) | Acc: (94.00%) (9824/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1535) | Acc: (94.00%) (11034/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.1549) | Acc: (94.00%) (12241/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1574) | Acc: (94.00%) (13447/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.1569) | Acc: (94.00%) (14662/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.1578) | Acc: (94.00%) (15876/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.1566) | Acc: (94.00%) (17096/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.1572) | Acc: (94.00%) (18311/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.1553) | Acc: (94.00%) (19544/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1536) | Acc: (94.00%) (20777/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1552) | Acc: (94.00%) (21984/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1547) | Acc: (94.00%) (23204/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1559) | Acc: (94.00%) (24402/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1554) | Acc: (94.00%) (25621/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1564) | Acc: (94.00%) (26813/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1564) | Acc: (94.00%) (28022/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1565) | Acc: (94.00%) (29234/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1564) | Acc: (94.00%) (30443/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1568) | Acc: (94.00%) (31649/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1571) | Acc: (94.00%) (32861/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1567) | Acc: (94.00%) (34078/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1568) | Acc: (94.00%) (35293/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1572) | Acc: (94.00%) (36500/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1563) | Acc: (94.00%) (37733/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1564) | Acc: (94.00%) (38952/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1557) | Acc: (94.00%) (40174/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1561) | Acc: (94.00%) (41381/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1560) | Acc: (94.00%) (42590/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1556) | Acc: (94.00%) (43808/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1558) | Acc: (94.00%) (45020/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1556) | Acc: (94.00%) (46233/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1557) | Acc: (94.00%) (47395/50000)
# TEST : Loss: (0.2872) | Acc: (91.00%) (9100/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9185e-01, -2.0337e-01, -7.0906e-03],
          [-3.4476e-02,  3.9004e-01,  2.5474e-01],
          [ 1.0816e-01,  7.3533e-02, -4.9762e-02]],

         [[-1.9046e-01,  1.9900e-01,  1.3419e-01],
          [ 4.7343e-02,  4.3148e-01,  2.1588e-01],
          [ 1.9666e-01,  1.6310e-02,  7.0903e-02]],

         [[-2.0949e-01, -7.9500e-02, -1.2026e-01],
          [-3.1392e-01, -1.3842e-01, -1.3667e-01],
          [-2.5985e-01, -1.8861e-01, -2.0168e-01]]],


        [[[ 4.2651e-40,  1.1547e-42, -5.1326e-40],
          [ 3.0551e-40, -2.4440e-40,  1.5605e-40],
          [-1.0020e-40,  2.3173e-40,  8.5642e-41]],

         [[-3.3180e-41, -3.0264e-40,  3.4314e-40],
          [ 4.2378e-41,  2.8555e-40, -7.1737e-41],
          [-1.6883e-40,  3.9627e-41,  1.6708e-40]],

         [[ 8.8601e-41, -2.7637e-40,  4.1610e-40],
          [ 1.6104e-41, -1.1590e-40, -5.3378e-40],
          [ 2.7745e-40,  2.9790e-41, -5.7599e-40]]],


        [[[ 2.5178e-02,  1.1431e-01, -2.8789e-02],
          [ 4.2363e-02,  2.1426e-01, -9.1457e-02],
          [ 1.8323e-01,  3.3421e-01,  3.5370e-01]],

         [[-2.0645e-01, -9.9716e-02, -1.6685e-01],
          [-4.0490e-01, -3.9714e-01, -3.3224e-01],
          [-2.3665e-01, -4.4294e-01,  2.7583e-02]],

         [[ 2.3814e-01,  1.7874e-01,  2.1703e-01],
          [ 1.9730e-01,  1.4549e-01,  2.2651e-02],
          [ 1.0358e-01,  8.1943e-02,  9.2555e-03]]],


        ...,


        [[[ 1.8216e-01,  3.2087e-02,  9.5005e-02],
          [ 9.1532e-02, -2.1258e-01, -2.3271e-02],
          [ 4.2911e-02, -1.0135e-01, -3.3423e-02]],

         [[-1.8710e-02, -4.8623e-02,  3.6686e-02],
          [-8.1323e-02, -1.8624e-01,  2.3779e-02],
          [ 3.2421e-02,  6.4199e-02,  1.4819e-01]],

         [[-7.4295e-02, -1.3925e-01, -3.6812e-02],
          [-8.8522e-02, -1.6382e-01, -1.2146e-01],
          [-4.6364e-02, -1.0647e-01, -6.9312e-02]]],


        [[[ 1.1617e-01,  2.1845e-01,  2.4834e-01],
          [ 1.0533e-01,  1.1499e-01,  2.9835e-02],
          [-1.4763e-01, -8.6067e-02, -4.1156e-02]],

         [[ 2.2129e-02,  5.4027e-02, -4.7037e-02],
          [-9.5202e-03, -5.6414e-02, -1.8513e-01],
          [-1.9934e-02,  6.8429e-02, -2.9749e-02]],

         [[-2.1370e-01, -1.0961e-01, -1.4702e-01],
          [-1.1236e-01,  2.9087e-02,  3.1679e-02],
          [ 1.0927e-01,  2.3733e-01,  1.7620e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -5.4140e-40],
          [ 1.8440e-40, -1.3337e-40,  9.3869e-41],
          [-3.7164e-40,  2.3400e-40, -1.9209e-40]],

         [[-1.3510e-40, -3.3786e-40, -3.5817e-40],
          [-1.0123e-40,  1.0705e-40, -4.4057e-42],
          [ 3.9750e-40, -1.6517e-40,  3.8970e-41]],

         [[ 4.9483e-41,  2.4258e-40,  1.2932e-40],
          [ 1.0542e-40, -4.3148e-40, -2.3397e-40],
          [ 1.8561e-40,  3.4087e-40, -1.4520e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2258]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0022]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 164 | Batch_idx: 0 |  Loss: (0.1202) | Acc: (96.00%) (123/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1596) | Acc: (95.00%) (1339/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.1688) | Acc: (94.00%) (2535/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.1748) | Acc: (94.00%) (3737/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.1869) | Acc: (93.00%) (4926/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.1985) | Acc: (93.00%) (6099/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.2104) | Acc: (93.00%) (7268/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.2155) | Acc: (92.00%) (8436/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.2167) | Acc: (92.00%) (9610/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.2168) | Acc: (92.00%) (10792/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.2192) | Acc: (92.00%) (11970/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.2183) | Acc: (92.00%) (13155/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.2200) | Acc: (92.00%) (14330/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.2190) | Acc: (92.00%) (15519/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.2197) | Acc: (92.00%) (16701/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.2215) | Acc: (92.00%) (17881/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.2232) | Acc: (92.00%) (19057/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.2257) | Acc: (92.00%) (20207/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.2268) | Acc: (92.00%) (21381/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.2273) | Acc: (92.00%) (22557/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.2265) | Acc: (92.00%) (23746/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.2260) | Acc: (92.00%) (24934/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.2280) | Acc: (92.00%) (26098/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.2282) | Acc: (92.00%) (27268/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.2280) | Acc: (92.00%) (28447/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.2284) | Acc: (92.00%) (29630/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.2274) | Acc: (92.00%) (30826/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.2274) | Acc: (92.00%) (32010/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.2264) | Acc: (92.00%) (33205/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.2261) | Acc: (92.00%) (34392/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.2261) | Acc: (92.00%) (35578/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.2270) | Acc: (92.00%) (36747/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.2269) | Acc: (92.00%) (37933/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.2263) | Acc: (92.00%) (39114/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.2260) | Acc: (92.00%) (40295/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.2256) | Acc: (92.00%) (41484/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.2256) | Acc: (92.00%) (42664/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.2252) | Acc: (92.00%) (43847/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.2248) | Acc: (92.00%) (45038/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.2249) | Acc: (92.00%) (46174/50000)
# TEST : Loss: (0.3351) | Acc: (89.00%) (8903/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8548e-01, -1.9442e-01, -4.6414e-03],
          [-2.2336e-02,  4.0320e-01,  2.6100e-01],
          [ 1.2142e-01,  8.4975e-02, -4.0438e-02]],

         [[-1.7886e-01,  2.0810e-01,  1.3373e-01],
          [ 6.2822e-02,  4.4429e-01,  2.1708e-01],
          [ 2.1102e-01,  2.7360e-02,  7.2103e-02]],

         [[-1.9961e-01, -7.5334e-02, -1.2432e-01],
          [-3.0423e-01, -1.3475e-01, -1.4133e-01],
          [-2.4880e-01, -1.8319e-01, -2.0376e-01]]],


        [[[ 2.8638e-40,  1.4128e-40, -3.7313e-40],
          [ 1.6538e-40, -3.8453e-40,  4.3631e-40],
          [-2.4033e-40,  9.1601e-41,  5.0603e-40]],

         [[ 2.4708e-40, -3.0264e-40,  6.2879e-41],
          [ 3.2264e-40,  5.6581e-40, -2.1187e-40],
          [-1.6883e-40,  1.7976e-40,  1.6708e-40]],

         [[-3.3179e-40, -2.7637e-40, -1.4442e-40],
          [ 2.9636e-40,  2.4230e-41, -1.1339e-40],
          [ 1.3732e-40,  3.1005e-40, -4.3586e-40]]],


        [[[ 2.9560e-02,  1.1417e-01, -2.9158e-02],
          [ 4.4448e-02,  2.1302e-01, -9.9087e-02],
          [ 1.7347e-01,  3.3289e-01,  3.5271e-01]],

         [[-1.9912e-01, -1.0282e-01, -1.7340e-01],
          [-4.0432e-01, -4.0467e-01, -3.4388e-01],
          [-2.4671e-01, -4.4572e-01,  2.7814e-02]],

         [[ 2.4897e-01,  1.7955e-01,  2.0901e-01],
          [ 1.9897e-01,  1.4359e-01,  1.2611e-02],
          [ 9.7332e-02,  8.3070e-02,  8.0283e-03]]],


        ...,


        [[[ 1.9041e-01,  4.5026e-02,  1.0503e-01],
          [ 1.0520e-01, -1.9795e-01, -1.9637e-02],
          [ 5.3185e-02, -8.8311e-02, -3.1346e-02]],

         [[-2.1595e-02, -4.3534e-02,  4.0365e-02],
          [-8.4382e-02, -1.8490e-01,  1.3918e-02],
          [ 3.1336e-02,  6.7653e-02,  1.3996e-01]],

         [[-7.7399e-02, -1.3635e-01, -3.2931e-02],
          [-1.0172e-01, -1.8787e-01, -1.3789e-01],
          [-5.2161e-02, -1.0163e-01, -7.3397e-02]]],


        [[[ 1.1194e-01,  2.0365e-01,  2.4167e-01],
          [ 1.0086e-01,  1.0136e-01,  2.8561e-02],
          [-1.5556e-01, -1.0523e-01, -5.1618e-02]],

         [[ 1.9052e-02,  3.2541e-02, -6.1259e-02],
          [-1.2729e-02, -7.0521e-02, -1.8702e-01],
          [-3.0866e-02,  4.8270e-02, -3.6930e-02]],

         [[-2.3802e-01, -1.4901e-01, -1.7726e-01],
          [-1.2995e-01, -6.2460e-04,  1.4805e-02],
          [ 9.0971e-02,  2.1268e-01,  1.6643e-01]]],


        [[[ 1.0786e-40,  3.3677e-40, -2.6114e-40],
          [ 6.0479e-40,  6.7571e-42, -4.6665e-40],
          [-2.3151e-40, -4.6258e-41, -5.1959e-41]],

         [[-4.1536e-40,  8.2529e-41, -3.5817e-40],
          [ 3.8896e-41,  2.4718e-40,  2.7585e-40],
          [ 1.1724e-40, -5.8556e-40, -1.0116e-40]],

         [[ 3.2974e-40, -3.7677e-41,  4.0958e-40],
          [-1.7484e-40, -5.7161e-40,  1.8641e-40],
          [-9.4647e-41, -7.9518e-41, -5.0727e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0178,  0.0163,  0.0175],
          [ 0.0153,  0.0188,  0.0205],
          [ 0.0247,  0.0328,  0.0332]],

         [[ 0.0132,  0.0137,  0.0135],
          [ 0.0113,  0.0170,  0.0179],
          [ 0.0237,  0.0333,  0.0319]],

         [[ 0.0171,  0.0190,  0.0172],
          [ 0.0126,  0.0181,  0.0180],
          [ 0.0218,  0.0311,  0.0314]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0094, -0.0039, -0.0006],
          [-0.0112,  0.0096,  0.0122],
          [-0.0020,  0.0132,  0.0112]],

         [[-0.0128,  0.0022,  0.0136],
          [-0.0125,  0.0185,  0.0264],
          [ 0.0003,  0.0209,  0.0224]],

         [[-0.0024,  0.0128,  0.0208],
          [-0.0030,  0.0268,  0.0336],
          [ 0.0057,  0.0252,  0.0274]]],


        ...,


        [[[ 0.0068,  0.0075,  0.0094],
          [ 0.0023,  0.0020,  0.0025],
          [ 0.0031,  0.0027,  0.0031]],

         [[ 0.0068,  0.0075,  0.0094],
          [ 0.0029,  0.0020,  0.0024],
          [ 0.0043,  0.0035,  0.0034]],

         [[ 0.0050,  0.0058,  0.0079],
          [ 0.0014,  0.0006,  0.0016],
          [ 0.0029,  0.0021,  0.0023]]],


        [[[ 0.0022,  0.0038,  0.0052],
          [-0.0003,  0.0024,  0.0055],
          [ 0.0009,  0.0045,  0.0081]],

         [[ 0.0030,  0.0048,  0.0071],
          [ 0.0004,  0.0034,  0.0072],
          [ 0.0015,  0.0054,  0.0097]],

         [[ 0.0034,  0.0052,  0.0077],
          [ 0.0009,  0.0035,  0.0071],
          [ 0.0025,  0.0062,  0.0098]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2254]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

3 hours 50 mins 45 secs for training