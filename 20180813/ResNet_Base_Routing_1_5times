Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to drive/app/cifar10/cifar-10-python.tar.gz
USE 1 GPUs!
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3112) | Acc: (5.00%) (7/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.1580) | Acc: (19.00%) (277/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.0383) | Acc: (23.00%) (631/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (1.9942) | Acc: (24.00%) (963/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (1.9484) | Acc: (25.00%) (1339/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (1.9196) | Acc: (26.00%) (1722/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (1.9009) | Acc: (27.00%) (2136/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (1.8801) | Acc: (28.00%) (2547/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (1.8619) | Acc: (28.00%) (2965/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (1.8505) | Acc: (29.00%) (3378/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (1.8342) | Acc: (29.00%) (3818/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (1.8236) | Acc: (29.00%) (4247/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (1.8148) | Acc: (30.00%) (4693/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (1.7993) | Acc: (30.00%) (5153/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (1.7900) | Acc: (31.00%) (5636/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (1.7784) | Acc: (31.00%) (6108/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (1.7671) | Acc: (32.00%) (6617/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (1.7564) | Acc: (32.00%) (7115/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (1.7459) | Acc: (32.00%) (7636/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (1.7372) | Acc: (33.00%) (8168/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (1.7271) | Acc: (33.00%) (8718/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (1.7173) | Acc: (34.00%) (9264/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (1.7100) | Acc: (34.00%) (9797/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (1.7007) | Acc: (35.00%) (10363/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (1.6927) | Acc: (35.00%) (10903/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (1.6846) | Acc: (35.00%) (11476/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (1.6755) | Acc: (36.00%) (12081/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (1.6638) | Acc: (36.00%) (12722/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (1.6548) | Acc: (37.00%) (13358/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (1.6465) | Acc: (37.00%) (13976/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (1.6384) | Acc: (37.00%) (14575/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (1.6288) | Acc: (38.00%) (15213/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (1.6192) | Acc: (38.00%) (15871/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (1.6099) | Acc: (38.00%) (16522/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (1.6010) | Acc: (39.00%) (17199/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (1.5912) | Acc: (39.00%) (17901/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (1.5808) | Acc: (40.00%) (18615/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (1.5731) | Acc: (40.00%) (19267/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (1.5640) | Acc: (40.00%) (19985/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (1.5564) | Acc: (41.00%) (20666/50000)
# TEST : Loss: (1.3807) | Acc: (50.00%) (5025/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0780, -0.0831, -0.0565],
          [ 0.0617,  0.0062,  0.1182],
          [ 0.0526, -0.0766, -0.2095]],

         [[ 0.0626, -0.0355,  0.0544],
          [-0.1932, -0.0749,  0.0378],
          [ 0.0380,  0.0813, -0.0561]],

         [[-0.0299,  0.0989, -0.2052],
          [ 0.1931,  0.2307,  0.0721],
          [-0.1138,  0.1241,  0.0894]]],


        [[[ 0.1551, -0.1990,  0.0829],
          [ 0.1223, -0.0802,  0.0470],
          [-0.1992,  0.0379, -0.0503]],

         [[ 0.1242, -0.1135,  0.0997],
          [-0.0937,  0.1889, -0.1020],
          [ 0.0774,  0.0192,  0.1864]],

         [[-0.1287, -0.0975, -0.1082],
          [-0.1240,  0.0884, -0.0238],
          [-0.1305,  0.0953,  0.1281]]],


        [[[-0.0964, -0.0016, -0.1201],
          [ 0.1283,  0.0381, -0.1031],
          [ 0.0148, -0.1635, -0.1778]],

         [[ 0.0571,  0.1917, -0.0302],
          [-0.0713, -0.1102, -0.0766],
          [-0.1722,  0.0886, -0.1155]],

         [[-0.1479,  0.0505,  0.1422],
          [ 0.0645, -0.1244,  0.1440],
          [-0.1314,  0.0770, -0.0583]]],


        ...,


        [[[ 0.1146,  0.0893, -0.0723],
          [ 0.1537,  0.1361,  0.0247],
          [-0.1882,  0.0833,  0.0943]],

         [[-0.1551, -0.2240,  0.0886],
          [ 0.1264, -0.0367, -0.1654],
          [ 0.0864, -0.1705,  0.0406]],

         [[-0.0561,  0.0151,  0.0760],
          [ 0.1774,  0.1413, -0.0808],
          [ 0.1759,  0.1761,  0.0809]]],


        [[[ 0.1833,  0.0887, -0.0266],
          [-0.0011, -0.0208, -0.0992],
          [-0.1066,  0.1578, -0.1192]],

         [[-0.1833, -0.1816,  0.0128],
          [ 0.0122, -0.1131, -0.1502],
          [ 0.0488,  0.0558, -0.1010]],

         [[ 0.1371, -0.0363, -0.0500],
          [ 0.0006,  0.0732,  0.1423],
          [-0.1423,  0.0024,  0.1116]]],


        [[[-0.0702,  0.0372, -0.1396],
          [-0.1062, -0.1660, -0.1256],
          [ 0.2359, -0.0651, -0.1371]],

         [[ 0.0388, -0.1861, -0.0258],
          [-0.0344, -0.1642,  0.0726],
          [ 0.1865,  0.2011, -0.1506]],

         [[ 0.0764, -0.1032,  0.1813],
          [ 0.1805,  0.0670,  0.0936],
          [-0.1110, -0.0410,  0.0174]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0240, -0.0293, -0.0240],
          [-0.0170, -0.0215, -0.0126],
          [-0.0159, -0.0153, -0.0032]],

         [[-0.0289, -0.0350, -0.0307],
          [-0.0229, -0.0279, -0.0199],
          [-0.0212, -0.0209, -0.0091]],

         [[-0.0147, -0.0221, -0.0210],
          [-0.0116, -0.0178, -0.0130],
          [-0.0128, -0.0140, -0.0055]]],


        [[[-0.0823, -0.0768, -0.0549],
          [-0.1017, -0.0910, -0.0703],
          [-0.1172, -0.0963, -0.0734]],

         [[-0.0269, -0.0244, -0.0076],
          [-0.0397, -0.0317, -0.0172],
          [-0.0484, -0.0290, -0.0116]],

         [[ 0.0294,  0.0379,  0.0573],
          [ 0.0255,  0.0394,  0.0570],
          [ 0.0260,  0.0491,  0.0680]]],


        [[[ 0.0006, -0.0010, -0.0034],
          [-0.0011, -0.0015, -0.0025],
          [-0.0011,  0.0008,  0.0021]],

         [[-0.0032, -0.0058, -0.0088],
          [-0.0044, -0.0053, -0.0068],
          [-0.0044, -0.0027, -0.0015]],

         [[-0.0030, -0.0053, -0.0082],
          [-0.0055, -0.0062, -0.0078],
          [-0.0066, -0.0051, -0.0043]]],


        ...,


        [[[ 0.0082,  0.0056,  0.0068],
          [ 0.0090,  0.0080,  0.0119],
          [ 0.0063,  0.0078,  0.0121]],

         [[-0.0013, -0.0044, -0.0039],
          [ 0.0003, -0.0012,  0.0022],
          [-0.0022, -0.0007,  0.0036]],

         [[-0.0040, -0.0082, -0.0093],
          [-0.0038, -0.0063, -0.0049],
          [-0.0080, -0.0075, -0.0049]]],


        [[[-0.0120, -0.0066, -0.0020],
          [-0.0034,  0.0037,  0.0064],
          [ 0.0008,  0.0067,  0.0084]],

         [[-0.0240, -0.0194, -0.0143],
          [-0.0134, -0.0074, -0.0035],
          [-0.0050, -0.0002,  0.0024]],

         [[-0.0347, -0.0305, -0.0260],
          [-0.0268, -0.0212, -0.0173],
          [-0.0166, -0.0117, -0.0089]]],


        [[[-0.0128, -0.0159, -0.0136],
          [-0.0166, -0.0141, -0.0058],
          [-0.0121, -0.0074,  0.0090]],

         [[-0.0177, -0.0215, -0.0185],
          [-0.0226, -0.0214, -0.0128],
          [-0.0163, -0.0143,  0.0016]],

         [[-0.0098, -0.0133, -0.0112],
          [-0.0154, -0.0149, -0.0077],
          [-0.0096, -0.0088,  0.0047]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.]], device='cuda:0')

percentage_weight_grad None

Epoch: 1 | Batch_idx: 0 |  Loss: (1.2901) | Acc: (53.00%) (68/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.2322) | Acc: (54.00%) (770/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.2232) | Acc: (54.00%) (1477/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.2166) | Acc: (55.00%) (2214/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.2112) | Acc: (56.00%) (2942/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.2101) | Acc: (56.00%) (3672/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.2063) | Acc: (56.00%) (4409/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.1932) | Acc: (56.00%) (5171/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.1887) | Acc: (56.00%) (5907/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.1817) | Acc: (57.00%) (6660/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.1770) | Acc: (57.00%) (7422/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.1701) | Acc: (57.00%) (8178/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.1695) | Acc: (57.00%) (8923/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.1668) | Acc: (57.00%) (9682/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.1676) | Acc: (57.00%) (10423/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.1659) | Acc: (57.00%) (11147/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.1634) | Acc: (57.00%) (11911/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.1628) | Acc: (57.00%) (12678/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.1602) | Acc: (58.00%) (13438/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.1543) | Acc: (58.00%) (14238/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.1489) | Acc: (58.00%) (15042/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.1451) | Acc: (58.00%) (15841/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.1398) | Acc: (58.00%) (16642/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.1352) | Acc: (58.00%) (17441/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.1316) | Acc: (59.00%) (18238/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.1275) | Acc: (59.00%) (19034/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.1251) | Acc: (59.00%) (19806/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.1206) | Acc: (59.00%) (20649/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.1161) | Acc: (59.00%) (21479/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.1138) | Acc: (59.00%) (22279/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.1099) | Acc: (59.00%) (23098/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.1065) | Acc: (60.00%) (23921/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.1032) | Acc: (60.00%) (24763/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.0998) | Acc: (60.00%) (25597/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.0953) | Acc: (60.00%) (26458/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.0901) | Acc: (60.00%) (27328/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.0855) | Acc: (61.00%) (28198/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.0840) | Acc: (61.00%) (29003/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.0814) | Acc: (61.00%) (29819/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.0797) | Acc: (61.00%) (30612/50000)
# TEST : Loss: (1.1294) | Acc: (61.00%) (6129/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0800, -0.0845, -0.0600],
          [ 0.0549,  0.0022,  0.1108],
          [ 0.0430, -0.0837, -0.2166]],

         [[ 0.0591, -0.0344,  0.0522],
          [-0.1950, -0.0698,  0.0368],
          [ 0.0331,  0.0823, -0.0578]],

         [[-0.0418,  0.0941, -0.2129],
          [ 0.1907,  0.2395,  0.0711],
          [-0.1240,  0.1220,  0.0799]]],


        [[[ 0.1675, -0.1992,  0.0773],
          [ 0.1258, -0.0790,  0.0349],
          [-0.2079,  0.0310, -0.0677]],

         [[ 0.1295, -0.1173,  0.0948],
          [-0.0964,  0.1913, -0.1092],
          [ 0.0662,  0.0190,  0.1771]],

         [[-0.1224, -0.1051, -0.1127],
          [-0.1260,  0.0883, -0.0278],
          [-0.1352,  0.0999,  0.1300]]],


        [[[-0.0956, -0.0217, -0.1297],
          [ 0.1305,  0.0187, -0.1110],
          [ 0.0261, -0.1720, -0.1737]],

         [[ 0.0696,  0.1874, -0.0273],
          [-0.0589, -0.1120, -0.0767],
          [-0.1690,  0.0725, -0.1233]],

         [[-0.1520,  0.0361,  0.1356],
          [ 0.0569, -0.1359,  0.1363],
          [-0.1439,  0.0564, -0.0694]]],


        ...,


        [[[ 0.1111,  0.0827, -0.0827],
          [ 0.1507,  0.1266,  0.0081],
          [-0.2008,  0.0637,  0.0718]],

         [[-0.1441, -0.2137,  0.0926],
          [ 0.1390, -0.0286, -0.1675],
          [ 0.0852, -0.1757,  0.0291]],

         [[-0.0384,  0.0335,  0.0882],
          [ 0.2138,  0.1705, -0.0692],
          [ 0.1890,  0.1785,  0.0700]]],


        [[[ 0.1949,  0.0985, -0.0115],
          [ 0.0144, -0.0077, -0.0846],
          [-0.0888,  0.1738, -0.0984]],

         [[-0.1881, -0.2019, -0.0019],
          [ 0.0190, -0.1225, -0.1593],
          [ 0.0703,  0.0679, -0.0844]],

         [[ 0.1268, -0.0494, -0.0546],
          [-0.0082,  0.0605,  0.1333],
          [-0.1484, -0.0055,  0.1074]]],


        [[[-0.0665,  0.0368, -0.1318],
          [-0.0971, -0.1708, -0.1339],
          [ 0.2557, -0.0551, -0.1387]],

         [[ 0.0466, -0.1802, -0.0172],
          [-0.0236, -0.1632,  0.0677],
          [ 0.2037,  0.2099, -0.1533]],

         [[ 0.0685, -0.1101,  0.1774],
          [ 0.1714,  0.0524,  0.0757],
          [-0.1163, -0.0523, -0.0034]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0074, -0.0104, -0.0225],
          [-0.0144, -0.0139, -0.0241],
          [-0.0177, -0.0139, -0.0222]],

         [[-0.0009, -0.0024, -0.0090],
          [-0.0084, -0.0087, -0.0163],
          [-0.0112, -0.0087, -0.0159]],

         [[-0.0079, -0.0097, -0.0153],
          [-0.0111, -0.0129, -0.0198],
          [-0.0113, -0.0123, -0.0191]]],


        [[[-0.0165, -0.0201, -0.0266],
          [ 0.0192,  0.0216,  0.0106],
          [ 0.0231,  0.0312,  0.0167]],

         [[-0.0613, -0.0608, -0.0696],
          [-0.0257, -0.0230, -0.0365],
          [-0.0215, -0.0192, -0.0365]],

         [[-0.0754, -0.0713, -0.0867],
          [-0.0679, -0.0745, -0.0923],
          [-0.0775, -0.0908, -0.1106]]],


        [[[-0.0084, -0.0054, -0.0045],
          [-0.0054, -0.0020, -0.0018],
          [-0.0025,  0.0003, -0.0002]],

         [[-0.0083, -0.0053, -0.0048],
          [-0.0047, -0.0011, -0.0010],
          [-0.0016,  0.0016,  0.0011]],

         [[-0.0039, -0.0024, -0.0035],
          [-0.0017,  0.0001, -0.0010],
          [-0.0000,  0.0019,  0.0007]]],


        ...,


        [[[ 0.0112,  0.0145,  0.0156],
          [ 0.0024,  0.0078,  0.0090],
          [ 0.0056,  0.0102,  0.0085]],

         [[ 0.0067,  0.0115,  0.0147],
          [-0.0033,  0.0025,  0.0057],
          [ 0.0001,  0.0048,  0.0041]],

         [[ 0.0041,  0.0071,  0.0090],
          [-0.0027,  0.0015,  0.0031],
          [ 0.0009,  0.0043,  0.0032]]],


        [[[ 0.0025,  0.0133,  0.0219],
          [ 0.0003,  0.0121,  0.0184],
          [ 0.0087,  0.0138,  0.0142]],

         [[-0.0074,  0.0066,  0.0158],
          [-0.0074,  0.0059,  0.0121],
          [-0.0002,  0.0037,  0.0033]],

         [[ 0.0165,  0.0259,  0.0321],
          [ 0.0149,  0.0212,  0.0242],
          [ 0.0130,  0.0113,  0.0096]]],


        [[[-0.0680, -0.0525, -0.0462],
          [-0.0680, -0.0449, -0.0312],
          [-0.0713, -0.0509, -0.0398]],

         [[-0.0753, -0.0573, -0.0490],
          [-0.0746, -0.0505, -0.0352],
          [-0.0755, -0.0551, -0.0432]],

         [[-0.0562, -0.0502, -0.0439],
          [-0.0546, -0.0437, -0.0341],
          [-0.0509, -0.0435, -0.0380]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.]], device='cuda:0')

percentage_weight_grad None

Epoch: 2 | Batch_idx: 0 |  Loss: (0.7539) | Acc: (67.00%) (86/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (0.9253) | Acc: (67.00%) (950/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (0.9237) | Acc: (67.00%) (1811/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (0.9416) | Acc: (67.00%) (2659/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (0.9450) | Acc: (66.00%) (3493/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (0.9346) | Acc: (66.00%) (4366/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (0.9389) | Acc: (66.00%) (5218/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (0.9387) | Acc: (66.00%) (6067/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (0.9329) | Acc: (66.00%) (6939/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (0.9271) | Acc: (67.00%) (7813/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (0.9282) | Acc: (67.00%) (8672/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (0.9302) | Acc: (66.00%) (9517/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (0.9291) | Acc: (67.00%) (10377/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (0.9256) | Acc: (67.00%) (11253/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (0.9230) | Acc: (67.00%) (12129/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (0.9205) | Acc: (67.00%) (13000/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (0.9212) | Acc: (67.00%) (13865/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (0.9192) | Acc: (67.00%) (14737/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (0.9142) | Acc: (67.00%) (15647/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (0.9090) | Acc: (67.00%) (16558/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (0.9069) | Acc: (67.00%) (17431/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (0.9041) | Acc: (67.00%) (18313/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (0.9002) | Acc: (67.00%) (19223/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (0.8957) | Acc: (68.00%) (20144/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (0.8937) | Acc: (68.00%) (21046/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (0.8928) | Acc: (68.00%) (21928/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (0.8921) | Acc: (68.00%) (22801/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (0.8895) | Acc: (68.00%) (23707/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (0.8875) | Acc: (68.00%) (24623/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (0.8867) | Acc: (68.00%) (25513/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (0.8835) | Acc: (68.00%) (26434/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (0.8808) | Acc: (68.00%) (27356/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (0.8775) | Acc: (68.00%) (28271/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (0.8747) | Acc: (68.00%) (29199/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (0.8733) | Acc: (68.00%) (30094/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (0.8723) | Acc: (68.00%) (30989/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (0.8723) | Acc: (69.00%) (31892/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (0.8683) | Acc: (69.00%) (32845/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (0.8660) | Acc: (69.00%) (33759/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (0.8628) | Acc: (69.00%) (34676/50000)
# TEST : Loss: (0.8350) | Acc: (71.00%) (7109/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0851, -0.0866, -0.0588],
          [ 0.0514,  0.0034,  0.1096],
          [ 0.0462, -0.0778, -0.2108]],

         [[ 0.0533, -0.0364,  0.0506],
          [-0.1955, -0.0642,  0.0371],
          [ 0.0388,  0.0931, -0.0495]],

         [[-0.0484,  0.0902, -0.2173],
          [ 0.1952,  0.2501,  0.0736],
          [-0.1105,  0.1390,  0.0898]]],


        [[[ 0.1704, -0.2031,  0.0732],
          [ 0.1298, -0.0800,  0.0261],
          [-0.2103,  0.0237, -0.0820]],

         [[ 0.1332, -0.1172,  0.0971],
          [-0.0881,  0.1994, -0.1070],
          [ 0.0707,  0.0246,  0.1760]],

         [[-0.1206, -0.1066, -0.1081],
          [-0.1188,  0.0959, -0.0215],
          [-0.1264,  0.1095,  0.1367]]],


        [[[-0.1204, -0.0445, -0.1396],
          [ 0.1110,  0.0027, -0.1129],
          [ 0.0323, -0.1519, -0.1369]],

         [[ 0.0707,  0.1939, -0.0103],
          [-0.0528, -0.0967, -0.0552],
          [-0.1502,  0.0982, -0.0876]],

         [[-0.1505,  0.0485,  0.1611],
          [ 0.0582, -0.1176,  0.1643],
          [-0.1384,  0.0768, -0.0347]]],


        ...,


        [[[ 0.1018,  0.0763, -0.0889],
          [ 0.1505,  0.1253,  0.0032],
          [-0.2017,  0.0607,  0.0678]],

         [[-0.1542, -0.2230,  0.0786],
          [ 0.1381, -0.0334, -0.1814],
          [ 0.0805, -0.1822,  0.0164]],

         [[-0.0413,  0.0276,  0.0741],
          [ 0.2241,  0.1698, -0.0871],
          [ 0.1858,  0.1675,  0.0490]]],


        [[[ 0.1964,  0.1014, -0.0017],
          [ 0.0223, -0.0014, -0.0739],
          [-0.0861,  0.1775, -0.0912]],

         [[-0.1977, -0.2182, -0.0066],
          [ 0.0139, -0.1364, -0.1641],
          [ 0.0665,  0.0636, -0.0836]],

         [[ 0.1188, -0.0568, -0.0549],
          [-0.0165,  0.0503,  0.1261],
          [-0.1600, -0.0145,  0.0998]]],


        [[[-0.0660,  0.0285, -0.1335],
          [-0.1013, -0.1858, -0.1438],
          [ 0.2527, -0.0582, -0.1412]],

         [[ 0.0547, -0.1765, -0.0115],
          [-0.0167, -0.1617,  0.0701],
          [ 0.2095,  0.2172, -0.1469]],

         [[ 0.0653, -0.1142,  0.1766],
          [ 0.1659,  0.0456,  0.0714],
          [-0.1234, -0.0556, -0.0071]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0104,  0.0013, -0.0068],
          [ 0.0002,  0.0011, -0.0064],
          [-0.0090, -0.0043, -0.0108]],

         [[ 0.0061, -0.0038, -0.0120],
          [-0.0050, -0.0043, -0.0112],
          [-0.0140, -0.0094, -0.0141]],

         [[ 0.0085,  0.0017, -0.0039],
          [-0.0025, -0.0005, -0.0046],
          [-0.0112, -0.0067, -0.0096]]],


        [[[-0.0407, -0.0357, -0.0319],
          [-0.0651, -0.0578, -0.0525],
          [-0.0806, -0.0737, -0.0655]],

         [[-0.0536, -0.0490, -0.0505],
          [-0.0683, -0.0630, -0.0675],
          [-0.0851, -0.0790, -0.0774]],

         [[-0.0556, -0.0450, -0.0431],
          [-0.0601, -0.0514, -0.0527],
          [-0.0675, -0.0604, -0.0567]]],


        [[[ 0.0027,  0.0061,  0.0081],
          [ 0.0019,  0.0032,  0.0032],
          [ 0.0022,  0.0032,  0.0015]],

         [[ 0.0029,  0.0063,  0.0086],
          [ 0.0009,  0.0024,  0.0032],
          [ 0.0013,  0.0027,  0.0018]],

         [[ 0.0067,  0.0101,  0.0119],
          [ 0.0045,  0.0065,  0.0071],
          [ 0.0048,  0.0068,  0.0064]]],


        ...,


        [[[-0.0162, -0.0191, -0.0229],
          [-0.0242, -0.0258, -0.0307],
          [-0.0268, -0.0267, -0.0323]],

         [[-0.0006, -0.0031, -0.0058],
          [-0.0089, -0.0097, -0.0124],
          [-0.0109, -0.0099, -0.0137]],

         [[ 0.0151,  0.0124,  0.0102],
          [ 0.0065,  0.0051,  0.0027],
          [ 0.0042,  0.0039,  0.0001]]],


        [[[-0.0020, -0.0021,  0.0020],
          [-0.0090, -0.0096, -0.0057],
          [-0.0093, -0.0112, -0.0082]],

         [[ 0.0021, -0.0001,  0.0047],
          [-0.0059, -0.0084, -0.0043],
          [-0.0065, -0.0101, -0.0085]],

         [[ 0.0046,  0.0029,  0.0073],
          [-0.0049, -0.0064, -0.0026],
          [-0.0066, -0.0089, -0.0079]]],


        [[[-0.0075, -0.0058,  0.0066],
          [-0.0013, -0.0041,  0.0040],
          [ 0.0158,  0.0116,  0.0145]],

         [[-0.0128, -0.0109,  0.0016],
          [-0.0124, -0.0134, -0.0038],
          [ 0.0014, -0.0002,  0.0046]],

         [[-0.0210, -0.0184, -0.0067],
          [-0.0232, -0.0221, -0.0132],
          [-0.0128, -0.0118, -0.0066]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.]], device='cuda:0')

percentage_weight_grad None

Epoch: 3 | Batch_idx: 0 |  Loss: (0.7608) | Acc: (76.00%) (98/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (0.7211) | Acc: (74.00%) (1047/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (0.7374) | Acc: (74.00%) (1995/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (0.7477) | Acc: (73.00%) (2925/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (0.7605) | Acc: (73.00%) (3857/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (0.7648) | Acc: (73.00%) (4787/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (0.7571) | Acc: (73.00%) (5737/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (0.7566) | Acc: (73.00%) (6680/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (0.7519) | Acc: (73.00%) (7635/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (0.7462) | Acc: (73.00%) (8603/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (0.7437) | Acc: (74.00%) (9581/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (0.7418) | Acc: (74.00%) (10552/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (0.7458) | Acc: (74.00%) (11485/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (0.7440) | Acc: (74.00%) (12452/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (0.7411) | Acc: (74.00%) (13409/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (0.7367) | Acc: (74.00%) (14391/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (0.7370) | Acc: (74.00%) (15318/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (0.7354) | Acc: (74.00%) (16287/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (0.7314) | Acc: (74.00%) (17273/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (0.7302) | Acc: (74.00%) (18222/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (0.7277) | Acc: (74.00%) (19207/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (0.7268) | Acc: (74.00%) (20179/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (0.7238) | Acc: (74.00%) (21174/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (0.7231) | Acc: (74.00%) (22146/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (0.7201) | Acc: (74.00%) (23127/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (0.7191) | Acc: (74.00%) (24086/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (0.7185) | Acc: (74.00%) (25049/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (0.7157) | Acc: (75.00%) (26064/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (0.7158) | Acc: (75.00%) (27016/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (0.7129) | Acc: (75.00%) (28003/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (0.7134) | Acc: (75.00%) (28951/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (0.7140) | Acc: (75.00%) (29898/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (0.7128) | Acc: (75.00%) (30900/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (0.7140) | Acc: (75.00%) (31857/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (0.7124) | Acc: (75.00%) (32845/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (0.7124) | Acc: (75.00%) (33811/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (0.7114) | Acc: (75.00%) (34791/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (0.7095) | Acc: (75.00%) (35789/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (0.7097) | Acc: (75.00%) (36742/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (0.7082) | Acc: (75.00%) (37685/50000)
# TEST : Loss: (0.7977) | Acc: (72.00%) (7225/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0862, -0.0877, -0.0592],
          [ 0.0492,  0.0036,  0.1100],
          [ 0.0506, -0.0711, -0.2020]],

         [[ 0.0541, -0.0338,  0.0517],
          [-0.1936, -0.0580,  0.0409],
          [ 0.0460,  0.1044, -0.0378]],

         [[-0.0490,  0.0904, -0.2193],
          [ 0.1977,  0.2573,  0.0772],
          [-0.1020,  0.1520,  0.1014]]],


        [[[ 0.1743, -0.2021,  0.0724],
          [ 0.1331, -0.0775,  0.0212],
          [-0.2128,  0.0215, -0.0883]],

         [[ 0.1316, -0.1194,  0.0951],
          [-0.0855,  0.2047, -0.1078],
          [ 0.0719,  0.0302,  0.1768]],

         [[-0.1249, -0.1121, -0.1099],
          [-0.1180,  0.0974, -0.0231],
          [-0.1247,  0.1129,  0.1384]]],


        [[[-0.1329, -0.0638, -0.1590],
          [ 0.0927, -0.0185, -0.1318],
          [ 0.0187, -0.1643, -0.1433]],

         [[ 0.0580,  0.1781, -0.0243],
          [-0.0597, -0.1034, -0.0643],
          [-0.1459,  0.0984, -0.0854]],

         [[-0.1611,  0.0385,  0.1543],
          [ 0.0543, -0.1167,  0.1650],
          [-0.1284,  0.0860, -0.0233]]],


        ...,


        [[[ 0.0943,  0.0660, -0.0994],
          [ 0.1465,  0.1215, -0.0031],
          [-0.2071,  0.0553,  0.0619]],

         [[-0.1505, -0.2224,  0.0754],
          [ 0.1480, -0.0244, -0.1795],
          [ 0.0880, -0.1744,  0.0190]],

         [[-0.0384,  0.0260,  0.0697],
          [ 0.2393,  0.1828, -0.0839],
          [ 0.1950,  0.1754,  0.0509]]],


        [[[ 0.1942,  0.0970, -0.0026],
          [ 0.0244, -0.0035, -0.0773],
          [-0.0874,  0.1733, -0.0963]],

         [[-0.2005, -0.2316, -0.0136],
          [ 0.0173, -0.1441, -0.1745],
          [ 0.0729,  0.0656, -0.0841]],

         [[ 0.1166, -0.0620, -0.0537],
          [-0.0140,  0.0486,  0.1231],
          [-0.1595, -0.0148,  0.0975]]],


        [[[-0.0549,  0.0335, -0.1325],
          [-0.0977, -0.1899, -0.1516],
          [ 0.2506, -0.0610, -0.1502]],

         [[ 0.0637, -0.1719, -0.0105],
          [-0.0112, -0.1608,  0.0673],
          [ 0.2088,  0.2168, -0.1530]],

         [[ 0.0685, -0.1126,  0.1773],
          [ 0.1650,  0.0428,  0.0687],
          [-0.1295, -0.0601, -0.0150]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0136,  0.0119, -0.0007],
          [ 0.0133,  0.0064, -0.0091],
          [ 0.0102,  0.0020, -0.0158]],

         [[ 0.0127,  0.0096, -0.0044],
          [ 0.0139,  0.0065, -0.0109],
          [ 0.0106,  0.0021, -0.0176]],

         [[ 0.0078,  0.0050, -0.0079],
          [ 0.0105,  0.0039, -0.0127],
          [ 0.0059, -0.0018, -0.0210]]],


        [[[ 0.0157,  0.0425,  0.0932],
          [ 0.0096,  0.0410,  0.1006],
          [ 0.0240,  0.0501,  0.0967]],

         [[ 0.0107,  0.0345,  0.0851],
          [ 0.0094,  0.0347,  0.0904],
          [ 0.0314,  0.0476,  0.0866]],

         [[ 0.0406,  0.0562,  0.0966],
          [ 0.0551,  0.0698,  0.1149],
          [ 0.0874,  0.0889,  0.1161]]],


        [[[-0.0019,  0.0019,  0.0045],
          [-0.0014,  0.0018,  0.0037],
          [-0.0045, -0.0009,  0.0007]],

         [[-0.0006,  0.0026,  0.0048],
          [ 0.0007,  0.0033,  0.0050],
          [-0.0021,  0.0011,  0.0029]],

         [[-0.0014,  0.0013,  0.0032],
          [-0.0012,  0.0012,  0.0029],
          [-0.0047, -0.0016,  0.0005]]],


        ...,


        [[[ 0.0069,  0.0090,  0.0126],
          [ 0.0041,  0.0038,  0.0062],
          [ 0.0056,  0.0044,  0.0068]],

         [[ 0.0101,  0.0118,  0.0143],
          [ 0.0076,  0.0069,  0.0084],
          [ 0.0088,  0.0074,  0.0094]],

         [[ 0.0045,  0.0079,  0.0121],
          [ 0.0035,  0.0044,  0.0063],
          [ 0.0036,  0.0026,  0.0051]]],


        [[[ 0.0141,  0.0061,  0.0022],
          [ 0.0183,  0.0098,  0.0047],
          [ 0.0233,  0.0137,  0.0100]],

         [[ 0.0085,  0.0019, -0.0011],
          [ 0.0159,  0.0078,  0.0039],
          [ 0.0220,  0.0130,  0.0092]],

         [[-0.0012, -0.0046, -0.0047],
          [ 0.0068,  0.0026,  0.0020],
          [ 0.0120,  0.0070,  0.0058]]],


        [[[ 0.0360,  0.0233,  0.0235],
          [ 0.0433,  0.0285,  0.0251],
          [ 0.0501,  0.0347,  0.0297]],

         [[ 0.0381,  0.0249,  0.0253],
          [ 0.0474,  0.0323,  0.0285],
          [ 0.0549,  0.0397,  0.0337]],

         [[ 0.0208,  0.0094,  0.0118],
          [ 0.0267,  0.0145,  0.0130],
          [ 0.0328,  0.0209,  0.0174]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.]], device='cuda:0')

percentage_weight_grad None

Epoch: 4 | Batch_idx: 0 |  Loss: (0.5560) | Acc: (84.00%) (108/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (0.5984) | Acc: (78.00%) (1104/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (0.6305) | Acc: (77.00%) (2084/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (0.6271) | Acc: (77.00%) (3089/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (0.6316) | Acc: (77.00%) (4091/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (0.6371) | Acc: (78.00%) (5096/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (0.6298) | Acc: (78.00%) (6095/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (0.6250) | Acc: (78.00%) (7107/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (0.6279) | Acc: (78.00%) (8096/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (0.6274) | Acc: (78.00%) (9104/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (0.6261) | Acc: (78.00%) (10114/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (0.6258) | Acc: (78.00%) (11108/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (0.6230) | Acc: (78.00%) (12136/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (0.6230) | Acc: (78.00%) (13143/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (0.6236) | Acc: (78.00%) (14146/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (0.6255) | Acc: (78.00%) (15132/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (0.6284) | Acc: (78.00%) (16102/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (0.6279) | Acc: (78.00%) (17090/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (0.6273) | Acc: (78.00%) (18108/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (0.6260) | Acc: (78.00%) (19126/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (0.6249) | Acc: (78.00%) (20137/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (0.6235) | Acc: (78.00%) (21150/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (0.6218) | Acc: (78.00%) (22176/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (0.6215) | Acc: (78.00%) (23188/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (0.6209) | Acc: (78.00%) (24213/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (0.6202) | Acc: (78.00%) (25238/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (0.6186) | Acc: (78.00%) (26260/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (0.6193) | Acc: (78.00%) (27252/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (0.6193) | Acc: (78.00%) (28277/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (0.6181) | Acc: (78.00%) (29292/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (0.6179) | Acc: (78.00%) (30297/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (0.6183) | Acc: (78.00%) (31313/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (0.6179) | Acc: (78.00%) (32335/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (0.6169) | Acc: (78.00%) (33372/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (0.6158) | Acc: (78.00%) (34403/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (0.6161) | Acc: (78.00%) (35419/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (0.6156) | Acc: (78.00%) (36424/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (0.6153) | Acc: (78.00%) (37444/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (0.6143) | Acc: (78.00%) (38474/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (0.6118) | Acc: (78.00%) (39479/50000)
# TEST : Loss: (0.6684) | Acc: (77.00%) (7772/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1013, -0.0933, -0.0589],
          [ 0.0334, -0.0056,  0.1070],
          [ 0.0424, -0.0762, -0.2013]],

         [[ 0.0413, -0.0369,  0.0502],
          [-0.2047, -0.0616,  0.0404],
          [ 0.0412,  0.1035, -0.0354]],

         [[-0.0582,  0.0892, -0.2192],
          [ 0.1904,  0.2580,  0.0810],
          [-0.1003,  0.1577,  0.1096]]],


        [[[ 0.1728, -0.2076,  0.0674],
          [ 0.1324, -0.0821,  0.0113],
          [-0.2155,  0.0147, -0.0983]],

         [[ 0.1278, -0.1253,  0.0902],
          [-0.0833,  0.2054, -0.1132],
          [ 0.0753,  0.0315,  0.1735]],

         [[-0.1288, -0.1188, -0.1111],
          [-0.1154,  0.0975, -0.0243],
          [-0.1172,  0.1179,  0.1420]]],


        [[[-0.1295, -0.0628, -0.1493],
          [ 0.0791, -0.0308, -0.1210],
          [-0.0081, -0.1815, -0.1317]],

         [[ 0.0620,  0.1805, -0.0146],
          [-0.0654, -0.1077, -0.0586],
          [-0.1594,  0.0859, -0.0835]],

         [[-0.1536,  0.0453,  0.1655],
          [ 0.0567, -0.1118,  0.1760],
          [-0.1277,  0.0885, -0.0094]]],


        ...,


        [[[ 0.0976,  0.0737, -0.0951],
          [ 0.1530,  0.1294,  0.0006],
          [-0.2062,  0.0567,  0.0607]],

         [[-0.1460, -0.2152,  0.0771],
          [ 0.1618, -0.0119, -0.1749],
          [ 0.0959, -0.1666,  0.0203]],

         [[-0.0393,  0.0291,  0.0684],
          [ 0.2473,  0.1909, -0.0830],
          [ 0.1907,  0.1721,  0.0448]]],


        [[[ 0.1972,  0.1064,  0.0129],
          [ 0.0305,  0.0035, -0.0675],
          [-0.0827,  0.1772, -0.0846]],

         [[-0.2091, -0.2407, -0.0058],
          [ 0.0108, -0.1548, -0.1746],
          [ 0.0734,  0.0631, -0.0736]],

         [[ 0.1149, -0.0610, -0.0449],
          [-0.0142,  0.0463,  0.1235],
          [-0.1593, -0.0163,  0.1034]]],


        [[[-0.0575,  0.0274, -0.1371],
          [-0.1084, -0.2039, -0.1637],
          [ 0.2441, -0.0665, -0.1521]],

         [[ 0.0632, -0.1745, -0.0131],
          [-0.0163, -0.1668,  0.0621],
          [ 0.2055,  0.2141, -0.1523]],

         [[ 0.0691, -0.1135,  0.1763],
          [ 0.1624,  0.0397,  0.0679],
          [-0.1311, -0.0620, -0.0138]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0008, -0.0102, -0.0066],
          [ 0.0043, -0.0050, -0.0055],
          [-0.0014, -0.0110, -0.0120]],

         [[ 0.0092, -0.0017,  0.0008],
          [ 0.0066, -0.0039, -0.0037],
          [-0.0004, -0.0113, -0.0104]],

         [[ 0.0108,  0.0009,  0.0034],
          [ 0.0077, -0.0015, -0.0008],
          [ 0.0009, -0.0089, -0.0063]]],


        [[[ 0.0096, -0.0177, -0.0144],
          [-0.0184, -0.0467, -0.0358],
          [-0.0349, -0.0625, -0.0512]],

         [[ 0.0360,  0.0186,  0.0255],
          [ 0.0053, -0.0127,  0.0033],
          [-0.0146, -0.0370, -0.0204]],

         [[ 0.0222,  0.0031,  0.0083],
          [-0.0022, -0.0201, -0.0077],
          [-0.0211, -0.0430, -0.0295]]],


        [[[-0.0009,  0.0014,  0.0017],
          [-0.0001,  0.0011,  0.0009],
          [-0.0006,  0.0002, -0.0011]],

         [[-0.0018, -0.0004, -0.0004],
          [-0.0016, -0.0006, -0.0011],
          [-0.0025, -0.0018, -0.0032]],

         [[-0.0021, -0.0013, -0.0020],
          [-0.0023, -0.0017, -0.0027],
          [-0.0031, -0.0028, -0.0044]]],


        ...,


        [[[-0.0137, -0.0105, -0.0058],
          [-0.0076, -0.0048, -0.0008],
          [-0.0090, -0.0051, -0.0005]],

         [[-0.0101, -0.0075, -0.0035],
          [-0.0050, -0.0024,  0.0012],
          [-0.0061, -0.0017,  0.0027]],

         [[-0.0043, -0.0022,  0.0011],
          [-0.0007,  0.0013,  0.0044],
          [-0.0016,  0.0023,  0.0061]]],


        [[[ 0.0018,  0.0166,  0.0233],
          [ 0.0084,  0.0170,  0.0245],
          [ 0.0071,  0.0102,  0.0176]],

         [[-0.0113,  0.0026,  0.0108],
          [-0.0068,  0.0039,  0.0138],
          [-0.0084, -0.0009,  0.0112]],

         [[-0.0093,  0.0026,  0.0086],
          [-0.0094, -0.0001,  0.0081],
          [-0.0119, -0.0056,  0.0055]]],


        [[[-0.0071, -0.0066, -0.0019],
          [-0.0025, -0.0064, -0.0048],
          [-0.0114, -0.0157, -0.0134]],

         [[-0.0096, -0.0090, -0.0044],
          [-0.0089, -0.0124, -0.0095],
          [-0.0172, -0.0215, -0.0176]],

         [[-0.0129, -0.0113, -0.0056],
          [-0.0144, -0.0165, -0.0116],
          [-0.0184, -0.0225, -0.0181]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.]], device='cuda:0')

percentage_weight_grad None

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 5 | Batch_idx: 0 |  Loss: (0.5904) | Acc: (82.00%) (105/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (0.6863) | Acc: (76.00%) (1075/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (0.8067) | Acc: (72.00%) (1960/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (0.8653) | Acc: (70.00%) (2799/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (0.8801) | Acc: (69.00%) (3672/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (0.8708) | Acc: (70.00%) (4584/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (0.8641) | Acc: (70.00%) (5497/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (0.8589) | Acc: (70.00%) (6414/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (0.8525) | Acc: (70.00%) (7328/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (0.8418) | Acc: (71.00%) (8280/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (0.8293) | Acc: (71.00%) (9242/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (0.8169) | Acc: (71.00%) (10217/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (0.8057) | Acc: (72.00%) (11205/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (0.7944) | Acc: (72.00%) (12187/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (0.7835) | Acc: (73.00%) (13191/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (0.7744) | Acc: (73.00%) (14191/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (0.7670) | Acc: (73.00%) (15163/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (0.7598) | Acc: (73.00%) (16140/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (0.7524) | Acc: (74.00%) (17145/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (0.7461) | Acc: (74.00%) (18153/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (0.7404) | Acc: (74.00%) (19157/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (0.7342) | Acc: (74.00%) (20171/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (0.7287) | Acc: (74.00%) (21168/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (0.7236) | Acc: (75.00%) (22188/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (0.7193) | Acc: (75.00%) (23175/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (0.7166) | Acc: (75.00%) (24154/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (0.7143) | Acc: (75.00%) (25141/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (0.7101) | Acc: (75.00%) (26150/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (0.7066) | Acc: (75.00%) (27163/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (0.7018) | Acc: (75.00%) (28208/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (0.6976) | Acc: (75.00%) (29236/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (0.6931) | Acc: (76.00%) (30272/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (0.6905) | Acc: (76.00%) (31277/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (0.6882) | Acc: (76.00%) (32285/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (0.6857) | Acc: (76.00%) (33298/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (0.6827) | Acc: (76.00%) (34323/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (0.6812) | Acc: (76.00%) (35329/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (0.6791) | Acc: (76.00%) (36350/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (0.6784) | Acc: (76.00%) (37343/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (0.6754) | Acc: (76.00%) (38335/50000)
# TEST : Loss: (0.5957) | Acc: (79.00%) (7973/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1021, -0.0937, -0.0596],
          [ 0.0319, -0.0066,  0.1060],
          [ 0.0418, -0.0759, -0.2006]],

         [[ 0.0396, -0.0380,  0.0486],
          [-0.2060, -0.0627,  0.0392],
          [ 0.0402,  0.1031, -0.0355]],

         [[-0.0596,  0.0879, -0.2198],
          [ 0.1881,  0.2561,  0.0799],
          [-0.1005,  0.1575,  0.1093]]],


        [[[ 0.1746, -0.2050,  0.0700],
          [ 0.1343, -0.0792,  0.0141],
          [-0.2130,  0.0179, -0.0948]],

         [[ 0.1299, -0.1224,  0.0928],
          [-0.0806,  0.2087, -0.1100],
          [ 0.0784,  0.0355,  0.1773]],

         [[-0.1257, -0.1153, -0.1079],
          [-0.1122,  0.1011, -0.0209],
          [-0.1135,  0.1220,  0.1459]]],


        [[[-0.1297, -0.0633, -0.1488],
          [ 0.0771, -0.0298, -0.1186],
          [-0.0089, -0.1764, -0.1289]],

         [[ 0.0606,  0.1782, -0.0153],
          [-0.0638, -0.1056, -0.0577],
          [-0.1563,  0.0855, -0.0821]],

         [[-0.1525,  0.0449,  0.1643],
          [ 0.0577, -0.1094,  0.1754],
          [-0.1246,  0.0891, -0.0082]]],


        ...,


        [[[ 0.0972,  0.0726, -0.0964],
          [ 0.1524,  0.1283, -0.0006],
          [-0.2059,  0.0552,  0.0588]],

         [[-0.1460, -0.2157,  0.0745],
          [ 0.1605, -0.0131, -0.1759],
          [ 0.0940, -0.1678,  0.0176]],

         [[-0.0402,  0.0271,  0.0655],
          [ 0.2440,  0.1877, -0.0843],
          [ 0.1868,  0.1679,  0.0418]]],


        [[[ 0.1963,  0.1048,  0.0110],
          [ 0.0301,  0.0026, -0.0687],
          [-0.0838,  0.1755, -0.0856]],

         [[-0.2082, -0.2414, -0.0090],
          [ 0.0111, -0.1553, -0.1763],
          [ 0.0721,  0.0612, -0.0752]],

         [[ 0.1134, -0.0637, -0.0486],
          [-0.0152,  0.0438,  0.1196],
          [-0.1612, -0.0191,  0.0997]]],


        [[[-0.0573,  0.0276, -0.1367],
          [-0.1082, -0.2027, -0.1627],
          [ 0.2436, -0.0659, -0.1516]],

         [[ 0.0629, -0.1742, -0.0138],
          [-0.0160, -0.1659,  0.0619],
          [ 0.2056,  0.2143, -0.1520]],

         [[ 0.0694, -0.1129,  0.1758],
          [ 0.1630,  0.0406,  0.0683],
          [-0.1297, -0.0606, -0.0132]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0635]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0443]], device='cuda:0')

Epoch: 6 | Batch_idx: 0 |  Loss: (0.6080) | Acc: (79.00%) (102/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (0.5664) | Acc: (80.00%) (1133/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (0.5768) | Acc: (79.00%) (2147/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (0.5821) | Acc: (80.00%) (3178/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (0.5820) | Acc: (79.00%) (4191/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (0.5740) | Acc: (80.00%) (5240/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (0.5758) | Acc: (80.00%) (6260/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (0.5775) | Acc: (80.00%) (7292/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (0.5794) | Acc: (80.00%) (8321/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (0.5812) | Acc: (80.00%) (9351/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (0.5782) | Acc: (80.00%) (10395/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (0.5786) | Acc: (80.00%) (11418/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (0.5768) | Acc: (80.00%) (12453/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (0.5772) | Acc: (80.00%) (13476/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (0.5760) | Acc: (80.00%) (14517/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (0.5764) | Acc: (80.00%) (15542/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (0.5771) | Acc: (80.00%) (16555/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (0.5762) | Acc: (80.00%) (17601/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (0.5754) | Acc: (80.00%) (18646/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (0.5755) | Acc: (80.00%) (19678/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (0.5739) | Acc: (80.00%) (20716/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (0.5728) | Acc: (80.00%) (21766/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (0.5726) | Acc: (80.00%) (22796/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (0.5744) | Acc: (80.00%) (23819/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (0.5747) | Acc: (80.00%) (24855/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (0.5737) | Acc: (80.00%) (25894/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (0.5747) | Acc: (80.00%) (26908/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (0.5765) | Acc: (80.00%) (27914/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (0.5751) | Acc: (80.00%) (28964/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (0.5747) | Acc: (80.00%) (30000/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (0.5759) | Acc: (80.00%) (31005/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (0.5749) | Acc: (80.00%) (32046/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (0.5753) | Acc: (80.00%) (33073/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (0.5755) | Acc: (80.00%) (34103/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (0.5772) | Acc: (80.00%) (35108/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (0.5772) | Acc: (80.00%) (36129/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (0.5771) | Acc: (80.00%) (37163/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (0.5782) | Acc: (80.00%) (38184/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (0.5774) | Acc: (80.00%) (39228/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (0.5768) | Acc: (80.00%) (40221/50000)
# TEST : Loss: (0.5685) | Acc: (80.00%) (8061/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1018, -0.0935, -0.0594],
          [ 0.0318, -0.0066,  0.1057],
          [ 0.0416, -0.0757, -0.2000]],

         [[ 0.0395, -0.0379,  0.0485],
          [-0.2054, -0.0625,  0.0391],
          [ 0.0401,  0.1028, -0.0354]],

         [[-0.0594,  0.0876, -0.2190],
          [ 0.1874,  0.2551,  0.0796],
          [-0.1001,  0.1569,  0.1089]]],


        [[[ 0.1745, -0.2048,  0.0699],
          [ 0.1342, -0.0791,  0.0141],
          [-0.2129,  0.0179, -0.0947]],

         [[ 0.1298, -0.1223,  0.0927],
          [-0.0805,  0.2085, -0.1099],
          [ 0.0783,  0.0355,  0.1772]],

         [[-0.1256, -0.1152, -0.1078],
          [-0.1121,  0.1010, -0.0209],
          [-0.1133,  0.1219,  0.1457]]],


        [[[-0.1279, -0.0624, -0.1468],
          [ 0.0753, -0.0290, -0.1156],
          [-0.0087, -0.1701, -0.1249]],

         [[ 0.0600,  0.1763, -0.0151],
          [-0.0629, -0.1040, -0.0568],
          [-0.1537,  0.0840, -0.0808]],

         [[-0.1511,  0.0445,  0.1628],
          [ 0.0570, -0.1081,  0.1735],
          [-0.1230,  0.0879, -0.0081]]],


        ...,


        [[[ 0.0967,  0.0722, -0.0960],
          [ 0.1515,  0.1276, -0.0006],
          [-0.2048,  0.0549,  0.0585]],

         [[-0.1451, -0.2144,  0.0741],
          [ 0.1592, -0.0130, -0.1748],
          [ 0.0933, -0.1667,  0.0175]],

         [[-0.0398,  0.0269,  0.0651],
          [ 0.2403,  0.1852, -0.0835],
          [ 0.1840,  0.1658,  0.0414]]],


        [[[ 0.1958,  0.1045,  0.0109],
          [ 0.0300,  0.0026, -0.0685],
          [-0.0836,  0.1750, -0.0853]],

         [[-0.2074, -0.2401, -0.0090],
          [ 0.0111, -0.1544, -0.1753],
          [ 0.0718,  0.0610, -0.0749]],

         [[ 0.1130, -0.0635, -0.0484],
          [-0.0151,  0.0436,  0.1191],
          [-0.1606, -0.0191,  0.0993]]],


        [[[-0.0571,  0.0275, -0.1361],
          [-0.1079, -0.2019, -0.1620],
          [ 0.2430, -0.0657, -0.1511]],

         [[ 0.0627, -0.1737, -0.0137],
          [-0.0160, -0.1653,  0.0617],
          [ 0.2051,  0.2137, -0.1515]],

         [[ 0.0692, -0.1126,  0.1753],
          [ 0.1625,  0.0405,  0.0681],
          [-0.1294, -0.0605, -0.0131]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0410]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0730]], device='cuda:0')

Epoch: 7 | Batch_idx: 0 |  Loss: (0.6179) | Acc: (78.00%) (101/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (0.5485) | Acc: (81.00%) (1147/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (0.5587) | Acc: (81.00%) (2180/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (0.5574) | Acc: (81.00%) (3221/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (0.5610) | Acc: (80.00%) (4239/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (0.5571) | Acc: (81.00%) (5290/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (0.5633) | Acc: (80.00%) (6322/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (0.5620) | Acc: (81.00%) (7364/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (0.5566) | Acc: (81.00%) (8433/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (0.5565) | Acc: (81.00%) (9478/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (0.5551) | Acc: (81.00%) (10526/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (0.5579) | Acc: (81.00%) (11567/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (0.5568) | Acc: (81.00%) (12593/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (0.5604) | Acc: (81.00%) (13628/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (0.5629) | Acc: (81.00%) (14669/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (0.5606) | Acc: (81.00%) (15736/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (0.5595) | Acc: (81.00%) (16789/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (0.5607) | Acc: (81.00%) (17814/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (0.5601) | Acc: (81.00%) (18854/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (0.5600) | Acc: (81.00%) (19902/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (0.5594) | Acc: (81.00%) (20946/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (0.5618) | Acc: (81.00%) (21964/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (0.5626) | Acc: (81.00%) (22994/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (0.5640) | Acc: (81.00%) (24019/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (0.5636) | Acc: (81.00%) (25064/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (0.5641) | Acc: (81.00%) (26098/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (0.5643) | Acc: (81.00%) (27134/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (0.5646) | Acc: (81.00%) (28157/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (0.5641) | Acc: (81.00%) (29207/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (0.5633) | Acc: (81.00%) (30260/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (0.5644) | Acc: (81.00%) (31272/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (0.5659) | Acc: (81.00%) (32302/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (0.5660) | Acc: (81.00%) (33320/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (0.5671) | Acc: (81.00%) (34351/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (0.5670) | Acc: (81.00%) (35383/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (0.5667) | Acc: (81.00%) (36418/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (0.5664) | Acc: (81.00%) (37458/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (0.5683) | Acc: (81.00%) (38479/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (0.5679) | Acc: (81.00%) (39526/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (0.5685) | Acc: (81.00%) (40504/50000)
# TEST : Loss: (0.5666) | Acc: (80.00%) (8082/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1014, -0.0931, -0.0592],
          [ 0.0317, -0.0066,  0.1053],
          [ 0.0415, -0.0754, -0.1993]],

         [[ 0.0393, -0.0377,  0.0483],
          [-0.2046, -0.0623,  0.0389],
          [ 0.0400,  0.1024, -0.0353]],

         [[-0.0591,  0.0872, -0.2181],
          [ 0.1865,  0.2539,  0.0792],
          [-0.0996,  0.1562,  0.1084]]],


        [[[ 0.1743, -0.2046,  0.0699],
          [ 0.1340, -0.0790,  0.0141],
          [-0.2126,  0.0179, -0.0946]],

         [[ 0.1297, -0.1222,  0.0926],
          [-0.0804,  0.2082, -0.1097],
          [ 0.0782,  0.0354,  0.1770]],

         [[-0.1254, -0.1150, -0.1076],
          [-0.1119,  0.1009, -0.0209],
          [-0.1132,  0.1218,  0.1456]]],


        [[[-0.1258, -0.0613, -0.1443],
          [ 0.0733, -0.0281, -0.1121],
          [-0.0084, -0.1625, -0.1201]],

         [[ 0.0592,  0.1739, -0.0149],
          [-0.0617, -0.1021, -0.0558],
          [-0.1506,  0.0822, -0.0792]],

         [[-0.1493,  0.0440,  0.1611],
          [ 0.0562, -0.1066,  0.1711],
          [-0.1210,  0.0865, -0.0080]]],


        ...,


        [[[ 0.0960,  0.0718, -0.0954],
          [ 0.1504,  0.1267, -0.0006],
          [-0.2034,  0.0546,  0.0581]],

         [[-0.1440, -0.2129,  0.0737],
          [ 0.1577, -0.0129, -0.1735],
          [ 0.0925, -0.1652,  0.0174]],

         [[-0.0394,  0.0266,  0.0645],
          [ 0.2359,  0.1823, -0.0826],
          [ 0.1806,  0.1631,  0.0409]]],


        [[[ 0.1951,  0.1041,  0.0109],
          [ 0.0299,  0.0026, -0.0683],
          [-0.0833,  0.1744, -0.0851]],

         [[-0.2064, -0.2385, -0.0089],
          [ 0.0110, -0.1533, -0.1740],
          [ 0.0715,  0.0607, -0.0745]],

         [[ 0.1125, -0.0632, -0.0481],
          [-0.0150,  0.0434,  0.1185],
          [-0.1599, -0.0190,  0.0988]]],


        [[[-0.0569,  0.0274, -0.1354],
          [-0.1075, -0.2009, -0.1611],
          [ 0.2422, -0.0654, -0.1504]],

         [[ 0.0625, -0.1730, -0.0137],
          [-0.0159, -0.1647,  0.0615],
          [ 0.2045,  0.2130, -0.1510]],

         [[ 0.0689, -0.1122,  0.1747],
          [ 0.1620,  0.0404,  0.0679],
          [-0.1290, -0.0603, -0.0131]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0316]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0132]], device='cuda:0')

Epoch: 8 | Batch_idx: 0 |  Loss: (0.4791) | Acc: (85.00%) (109/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (0.6066) | Acc: (79.00%) (1123/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (0.5613) | Acc: (81.00%) (2186/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (0.5699) | Acc: (80.00%) (3210/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (0.5714) | Acc: (80.00%) (4243/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (0.5710) | Acc: (81.00%) (5293/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (0.5751) | Acc: (80.00%) (6322/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (0.5780) | Acc: (80.00%) (7350/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (0.5786) | Acc: (80.00%) (8382/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (0.5771) | Acc: (80.00%) (9424/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (0.5782) | Acc: (80.00%) (10444/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (0.5818) | Acc: (80.00%) (11449/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (0.5772) | Acc: (80.00%) (12506/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (0.5764) | Acc: (80.00%) (13543/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (0.5776) | Acc: (80.00%) (14563/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (0.5770) | Acc: (80.00%) (15597/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (0.5774) | Acc: (80.00%) (16620/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (0.5794) | Acc: (80.00%) (17639/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (0.5781) | Acc: (80.00%) (18691/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (0.5769) | Acc: (80.00%) (19749/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (0.5772) | Acc: (80.00%) (20791/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (0.5789) | Acc: (80.00%) (21811/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (0.5783) | Acc: (80.00%) (22855/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (0.5793) | Acc: (80.00%) (23880/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (0.5801) | Acc: (80.00%) (24902/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (0.5799) | Acc: (80.00%) (25945/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (0.5811) | Acc: (80.00%) (26972/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (0.5832) | Acc: (80.00%) (27986/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (0.5831) | Acc: (80.00%) (29022/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (0.5832) | Acc: (80.00%) (30055/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (0.5831) | Acc: (80.00%) (31095/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (0.5821) | Acc: (80.00%) (32143/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (0.5829) | Acc: (80.00%) (33169/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (0.5837) | Acc: (80.00%) (34189/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (0.5830) | Acc: (80.00%) (35241/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (0.5830) | Acc: (80.00%) (36283/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (0.5832) | Acc: (80.00%) (37317/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (0.5831) | Acc: (80.00%) (38350/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (0.5839) | Acc: (80.00%) (39365/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (0.5853) | Acc: (80.00%) (40330/50000)
# TEST : Loss: (0.5855) | Acc: (80.00%) (8046/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1010, -0.0927, -0.0589],
          [ 0.0315, -0.0066,  0.1049],
          [ 0.0413, -0.0751, -0.1984]],

         [[ 0.0391, -0.0375,  0.0481],
          [-0.2036, -0.0620,  0.0387],
          [ 0.0398,  0.1019, -0.0351]],

         [[-0.0588,  0.0867, -0.2170],
          [ 0.1855,  0.2525,  0.0788],
          [-0.0991,  0.1553,  0.1078]]],


        [[[ 0.1740, -0.2043,  0.0698],
          [ 0.1339, -0.0789,  0.0140],
          [-0.2124,  0.0178, -0.0945]],

         [[ 0.1295, -0.1220,  0.0925],
          [-0.0803,  0.2080, -0.1096],
          [ 0.0781,  0.0354,  0.1767]],

         [[-0.1252, -0.1149, -0.1075],
          [-0.1118,  0.1007, -0.0209],
          [-0.1130,  0.1216,  0.1454]]],


        [[[-0.1232, -0.0599, -0.1413],
          [ 0.0708, -0.0270, -0.1078],
          [-0.0080, -0.1538, -0.1145]],

         [[ 0.0582,  0.1711, -0.0147],
          [-0.0604, -0.0998, -0.0546],
          [-0.1468,  0.0801, -0.0773]],

         [[-0.1472,  0.0434,  0.1589],
          [ 0.0552, -0.1047,  0.1683],
          [-0.1187,  0.0849, -0.0079]]],


        ...,


        [[[ 0.0953,  0.0712, -0.0948],
          [ 0.1491,  0.1256, -0.0006],
          [-0.2017,  0.0541,  0.0577]],

         [[-0.1426, -0.2111,  0.0731],
          [ 0.1559, -0.0128, -0.1719],
          [ 0.0914, -0.1635,  0.0173]],

         [[-0.0389,  0.0263,  0.0639],
          [ 0.2305,  0.1787, -0.0815],
          [ 0.1765,  0.1600,  0.0404]]],


        [[[ 0.1944,  0.1037,  0.0109],
          [ 0.0298,  0.0025, -0.0680],
          [-0.0830,  0.1737, -0.0847]],

         [[-0.2051, -0.2365, -0.0088],
          [ 0.0109, -0.1520, -0.1725],
          [ 0.0711,  0.0603, -0.0740]],

         [[ 0.1119, -0.0628, -0.0478],
          [-0.0149,  0.0431,  0.1177],
          [-0.1591, -0.0189,  0.0983]]],


        [[[-0.0567,  0.0272, -0.1346],
          [-0.1070, -0.1996, -0.1600],
          [ 0.2413, -0.0651, -0.1497]],

         [[ 0.0623, -0.1722, -0.0136],
          [-0.0159, -0.1639,  0.0612],
          [ 0.2037,  0.2121, -0.1504]],

         [[ 0.0687, -0.1117,  0.1739],
          [ 0.1614,  0.0402,  0.0676],
          [-0.1285, -0.0600, -0.0130]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0209]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0410]], device='cuda:0')

Epoch: 9 | Batch_idx: 0 |  Loss: (0.6988) | Acc: (75.00%) (97/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (0.5954) | Acc: (80.00%) (1128/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (0.5951) | Acc: (80.00%) (2163/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (0.6089) | Acc: (79.00%) (3166/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (0.6085) | Acc: (79.00%) (4192/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (0.6069) | Acc: (80.00%) (5228/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (0.6048) | Acc: (80.00%) (6253/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (0.6067) | Acc: (80.00%) (7276/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (0.6047) | Acc: (80.00%) (8318/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (0.6020) | Acc: (80.00%) (9353/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (0.6016) | Acc: (80.00%) (10384/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (0.6035) | Acc: (80.00%) (11400/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (0.6069) | Acc: (80.00%) (12403/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (0.6060) | Acc: (80.00%) (13425/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (0.6075) | Acc: (79.00%) (14436/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (0.6084) | Acc: (79.00%) (15455/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (0.6067) | Acc: (80.00%) (16496/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (0.6077) | Acc: (80.00%) (17522/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (0.6077) | Acc: (80.00%) (18553/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (0.6068) | Acc: (80.00%) (19595/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (0.6064) | Acc: (80.00%) (20643/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (0.6062) | Acc: (80.00%) (21678/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (0.6053) | Acc: (80.00%) (22729/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (0.6058) | Acc: (80.00%) (23744/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (0.6056) | Acc: (80.00%) (24784/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (0.6066) | Acc: (80.00%) (25818/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (0.6060) | Acc: (80.00%) (26866/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (0.6067) | Acc: (80.00%) (27897/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (0.6086) | Acc: (80.00%) (28916/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (0.6092) | Acc: (80.00%) (29933/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (0.6097) | Acc: (80.00%) (30962/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (0.6119) | Acc: (80.00%) (31960/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (0.6132) | Acc: (80.00%) (32990/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (0.6131) | Acc: (80.00%) (34029/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (0.6140) | Acc: (80.00%) (35054/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (0.6147) | Acc: (80.00%) (36085/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (0.6148) | Acc: (80.00%) (37112/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (0.6150) | Acc: (80.00%) (38152/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (0.6164) | Acc: (80.00%) (39160/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (0.6166) | Acc: (80.00%) (40153/50000)
# TEST : Loss: (0.6304) | Acc: (79.00%) (7982/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1004, -0.0922, -0.0586],
          [ 0.0313, -0.0065,  0.1043],
          [ 0.0411, -0.0747, -0.1973]],

         [[ 0.0389, -0.0373,  0.0478],
          [-0.2024, -0.0616,  0.0385],
          [ 0.0395,  0.1013, -0.0349]],

         [[-0.0584,  0.0862, -0.2156],
          [ 0.1842,  0.2507,  0.0782],
          [-0.0984,  0.1542,  0.1071]]],


        [[[ 0.1738, -0.2040,  0.0697],
          [ 0.1337, -0.0788,  0.0140],
          [-0.2120,  0.0178, -0.0943]],

         [[ 0.1293, -0.1218,  0.0924],
          [-0.0802,  0.2076, -0.1094],
          [ 0.0780,  0.0353,  0.1764]],

         [[-0.1250, -0.1146, -0.1073],
          [-0.1116,  0.1006, -0.0208],
          [-0.1128,  0.1214,  0.1451]]],


        [[[-0.1201, -0.0583, -0.1377],
          [ 0.0679, -0.0257, -0.1029],
          [-0.0076, -0.1437, -0.1081]],

         [[ 0.0571,  0.1677, -0.0144],
          [-0.0588, -0.0970, -0.0532],
          [-0.1424,  0.0775, -0.0750]],

         [[-0.1446,  0.0426,  0.1563],
          [ 0.0540, -0.1025,  0.1649],
          [-0.1159,  0.0828, -0.0077]]],


        ...,


        [[[ 0.0943,  0.0706, -0.0940],
          [ 0.1475,  0.1243, -0.0006],
          [-0.1996,  0.0536,  0.0572]],

         [[-0.1409, -0.2088,  0.0724],
          [ 0.1537, -0.0126, -0.1700],
          [ 0.0902, -0.1614,  0.0171]],

         [[-0.0383,  0.0259,  0.0631],
          [ 0.2241,  0.1744, -0.0802],
          [ 0.1717,  0.1562,  0.0397]]],


        [[[ 0.1935,  0.1032,  0.0108],
          [ 0.0296,  0.0025, -0.0677],
          [-0.0826,  0.1729, -0.0843]],

         [[-0.2035, -0.2341, -0.0087],
          [ 0.0109, -0.1504, -0.1706],
          [ 0.0706,  0.0598, -0.0734]],

         [[ 0.1112, -0.0623, -0.0474],
          [-0.0148,  0.0427,  0.1167],
          [-0.1581, -0.0187,  0.0976]]],


        [[[-0.0563,  0.0270, -0.1335],
          [-0.1064, -0.1981, -0.1587],
          [ 0.2402, -0.0647, -0.1487]],

         [[ 0.0620, -0.1711, -0.0135],
          [-0.0158, -0.1629,  0.0608],
          [ 0.2028,  0.2110, -0.1496]],

         [[ 0.0683, -0.1111,  0.1730],
          [ 0.1606,  0.0400,  0.0672],
          [-0.1280, -0.0597, -0.0130]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0048]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0080]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 10 | Batch_idx: 0 |  Loss: (0.6715) | Acc: (81.00%) (104/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (1.4054) | Acc: (48.00%) (689/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (1.3186) | Acc: (51.00%) (1387/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (1.2526) | Acc: (54.00%) (2169/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (1.1954) | Acc: (56.00%) (2988/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (1.1472) | Acc: (58.00%) (3841/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (1.1171) | Acc: (60.00%) (4720/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (1.0925) | Acc: (61.00%) (5588/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (1.0716) | Acc: (62.00%) (6454/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (1.0605) | Acc: (62.00%) (7305/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (1.0440) | Acc: (63.00%) (8163/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (1.0306) | Acc: (63.00%) (9044/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (1.0147) | Acc: (64.00%) (9943/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (0.9995) | Acc: (64.00%) (10866/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (0.9867) | Acc: (65.00%) (11766/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (0.9780) | Acc: (65.00%) (12661/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (0.9666) | Acc: (65.00%) (13597/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (0.9544) | Acc: (66.00%) (14526/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (0.9435) | Acc: (66.00%) (15471/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (0.9333) | Acc: (67.00%) (16410/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (0.9236) | Acc: (67.00%) (17360/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (0.9150) | Acc: (67.00%) (18316/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (0.9072) | Acc: (68.00%) (19280/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (0.8992) | Acc: (68.00%) (20224/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (0.8947) | Acc: (68.00%) (21171/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (0.8886) | Acc: (68.00%) (22118/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (0.8827) | Acc: (69.00%) (23090/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (0.8752) | Acc: (69.00%) (24061/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (0.8699) | Acc: (69.00%) (25014/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (0.8627) | Acc: (69.00%) (26015/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (0.8560) | Acc: (70.00%) (27019/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (0.8497) | Acc: (70.00%) (28008/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (0.8443) | Acc: (70.00%) (28989/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (0.8400) | Acc: (70.00%) (29950/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (0.8346) | Acc: (70.00%) (30934/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (0.8293) | Acc: (71.00%) (31936/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (0.8259) | Acc: (71.00%) (32883/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (0.8233) | Acc: (71.00%) (33846/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (0.8190) | Acc: (71.00%) (34843/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (0.8155) | Acc: (71.00%) (35790/50000)
# TEST : Loss: (0.8298) | Acc: (72.00%) (7213/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1154, -0.1102, -0.0721],
          [ 0.0111, -0.0261,  0.0846],
          [ 0.0231, -0.0928, -0.2137]],

         [[ 0.0335, -0.0429,  0.0440],
          [-0.2063, -0.0596,  0.0391],
          [ 0.0326,  0.0999, -0.0347]],

         [[-0.0645,  0.0776, -0.2229],
          [ 0.1882,  0.2615,  0.0868],
          [-0.0940,  0.1643,  0.1159]]],


        [[[ 0.1816, -0.2062,  0.0646],
          [ 0.1407, -0.0760,  0.0001],
          [-0.2182,  0.0028, -0.1143]],

         [[ 0.1286, -0.1352,  0.0755],
          [-0.0711,  0.2162, -0.1203],
          [ 0.0777,  0.0347,  0.1665]],

         [[-0.1310, -0.1300, -0.1149],
          [-0.1139,  0.0997, -0.0263],
          [-0.1183,  0.1161,  0.1426]]],


        [[[-0.1283, -0.0531, -0.1187],
          [ 0.0492, -0.0053, -0.0536],
          [-0.0358, -0.1314, -0.0840]],

         [[ 0.0460,  0.1689, -0.0008],
          [-0.0836, -0.0938, -0.0312],
          [-0.1867,  0.0530, -0.0797]],

         [[-0.1637,  0.0351,  0.1542],
          [ 0.0221, -0.1083,  0.1699],
          [-0.1561,  0.0617, -0.0141]]],


        ...,


        [[[ 0.0791,  0.0587, -0.1006],
          [ 0.1276,  0.1093, -0.0089],
          [-0.2177,  0.0398,  0.0529]],

         [[-0.1530, -0.2164,  0.0682],
          [ 0.1409, -0.0197, -0.1717],
          [ 0.0773, -0.1680,  0.0151]],

         [[-0.0284,  0.0428,  0.0796],
          [ 0.2661,  0.2244, -0.0436],
          [ 0.1989,  0.1913,  0.0687]]],


        [[[ 0.1838,  0.0858,  0.0057],
          [ 0.0231, -0.0186, -0.0807],
          [-0.0964,  0.1459, -0.1036]],

         [[-0.2105, -0.2737, -0.0331],
          [ 0.0183, -0.1821, -0.2007],
          [ 0.0823,  0.0486, -0.0867]],

         [[ 0.1145, -0.0637, -0.0314],
          [ 0.0024,  0.0479,  0.1273],
          [-0.1361, -0.0071,  0.1085]]],


        [[[-0.0535,  0.0046, -0.1303],
          [-0.1222, -0.2415, -0.1785],
          [ 0.2366, -0.0764, -0.1453]],

         [[ 0.0715, -0.1795, -0.0127],
          [-0.0171, -0.1754,  0.0589],
          [ 0.2070,  0.2134, -0.1375]],

         [[ 0.0639, -0.1285,  0.1661],
          [ 0.1483,  0.0198,  0.0595],
          [-0.1315, -0.0669, -0.0125]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0007, -0.0019, -0.0060],
          [ 0.0005, -0.0002, -0.0055],
          [ 0.0037,  0.0015, -0.0049]],

         [[-0.0040, -0.0049, -0.0079],
          [-0.0033, -0.0040, -0.0085],
          [ 0.0001, -0.0022, -0.0078]],

         [[-0.0046, -0.0061, -0.0078],
          [-0.0023, -0.0040, -0.0073],
          [ 0.0018, -0.0013, -0.0059]]],


        [[[-0.0117, -0.0212, -0.0095],
          [-0.0006, -0.0037, -0.0078],
          [ 0.0023,  0.0053, -0.0092]],

         [[-0.0033, -0.0191, -0.0082],
          [ 0.0002, -0.0062, -0.0133],
          [-0.0034, -0.0010, -0.0192]],

         [[ 0.0021, -0.0099,  0.0032],
          [ 0.0021, -0.0020, -0.0017],
          [-0.0011,  0.0021, -0.0092]]],


        [[[-0.0007, -0.0023, -0.0054],
          [-0.0005, -0.0015, -0.0043],
          [-0.0007, -0.0007, -0.0027]],

         [[-0.0015, -0.0035, -0.0069],
          [-0.0011, -0.0026, -0.0055],
          [-0.0011, -0.0016, -0.0039]],

         [[-0.0021, -0.0045, -0.0081],
          [-0.0020, -0.0040, -0.0072],
          [-0.0023, -0.0037, -0.0063]]],


        ...,


        [[[-0.0030, -0.0063, -0.0045],
          [-0.0019, -0.0056, -0.0047],
          [-0.0015, -0.0055, -0.0058]],

         [[-0.0109, -0.0142, -0.0118],
          [-0.0105, -0.0137, -0.0120],
          [-0.0091, -0.0122, -0.0119]],

         [[-0.0060, -0.0076, -0.0046],
          [-0.0051, -0.0060, -0.0032],
          [-0.0038, -0.0044, -0.0026]]],


        [[[-0.0063, -0.0024,  0.0013],
          [-0.0046, -0.0023, -0.0002],
          [ 0.0013,  0.0028,  0.0053]],

         [[-0.0065, -0.0021,  0.0020],
          [-0.0038, -0.0010,  0.0014],
          [ 0.0039,  0.0060,  0.0090]],

         [[-0.0003,  0.0034,  0.0055],
          [ 0.0001,  0.0024,  0.0028],
          [ 0.0061,  0.0074,  0.0090]]],


        [[[-0.0089, -0.0038, -0.0023],
          [-0.0082, -0.0023, -0.0023],
          [-0.0045,  0.0019,  0.0011]],

         [[-0.0089, -0.0026, -0.0013],
          [-0.0076, -0.0008, -0.0008],
          [-0.0042,  0.0028,  0.0021]],

         [[-0.0024,  0.0024,  0.0034],
          [-0.0017,  0.0024,  0.0017],
          [ 0.0032,  0.0065,  0.0037]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0092]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 11 | Batch_idx: 0 |  Loss: (0.5519) | Acc: (80.00%) (103/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (0.6476) | Acc: (76.00%) (1084/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (0.6426) | Acc: (77.00%) (2091/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (0.6327) | Acc: (78.00%) (3105/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (0.6448) | Acc: (78.00%) (4100/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (0.6478) | Acc: (78.00%) (5101/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (0.6434) | Acc: (78.00%) (6108/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (0.6350) | Acc: (78.00%) (7141/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (0.6321) | Acc: (78.00%) (8147/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (0.6272) | Acc: (78.00%) (9166/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (0.6302) | Acc: (78.00%) (10168/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (0.6286) | Acc: (78.00%) (11172/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (0.6294) | Acc: (78.00%) (12176/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (0.6261) | Acc: (78.00%) (13196/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (0.6251) | Acc: (78.00%) (14204/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (0.6265) | Acc: (78.00%) (15199/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (0.6230) | Acc: (78.00%) (16232/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (0.6221) | Acc: (78.00%) (17254/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (0.6206) | Acc: (78.00%) (18281/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (0.6187) | Acc: (78.00%) (19306/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (0.6167) | Acc: (79.00%) (20337/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (0.6160) | Acc: (79.00%) (21364/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (0.6159) | Acc: (79.00%) (22376/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (0.6136) | Acc: (79.00%) (23414/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (0.6116) | Acc: (79.00%) (24462/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (0.6094) | Acc: (79.00%) (25505/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (0.6071) | Acc: (79.00%) (26544/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (0.6068) | Acc: (79.00%) (27554/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (0.6048) | Acc: (79.00%) (28574/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (0.6035) | Acc: (79.00%) (29604/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (0.6028) | Acc: (79.00%) (30631/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (0.6007) | Acc: (79.00%) (31664/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (0.6000) | Acc: (79.00%) (32694/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (0.5994) | Acc: (79.00%) (33726/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (0.5986) | Acc: (79.00%) (34763/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (0.5981) | Acc: (79.00%) (35782/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (0.5961) | Acc: (79.00%) (36825/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (0.5947) | Acc: (79.00%) (37849/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (0.5939) | Acc: (79.00%) (38897/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (0.5935) | Acc: (79.00%) (39885/50000)
# TEST : Loss: (0.6046) | Acc: (78.00%) (7832/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1067, -0.1005, -0.0684],
          [ 0.0208, -0.0176,  0.0880],
          [ 0.0263, -0.0919, -0.2151]],

         [[ 0.0423, -0.0329,  0.0440],
          [-0.1927, -0.0470,  0.0425],
          [ 0.0400,  0.1049, -0.0363]],

         [[-0.0514,  0.0908, -0.2226],
          [ 0.2064,  0.2796,  0.0934],
          [-0.0837,  0.1718,  0.1151]]],


        [[[ 0.1903, -0.2032,  0.0664],
          [ 0.1434, -0.0716, -0.0039],
          [-0.2229, -0.0021, -0.1155]],

         [[ 0.1342, -0.1334,  0.0786],
          [-0.0644,  0.2275, -0.1177],
          [ 0.0813,  0.0415,  0.1728]],

         [[-0.1279, -0.1310, -0.1079],
          [-0.1113,  0.1062, -0.0202],
          [-0.1116,  0.1239,  0.1541]]],


        [[[-0.1411, -0.0626, -0.1179],
          [ 0.0094, -0.0345, -0.0622],
          [-0.0357, -0.1277, -0.0842]],

         [[ 0.0530,  0.1777,  0.0139],
          [-0.0952, -0.0981, -0.0262],
          [-0.1826,  0.0545, -0.0745]],

         [[-0.1461,  0.0529,  0.1728],
          [ 0.0276, -0.0969,  0.1817],
          [-0.1359,  0.0774, -0.0008]]],


        ...,


        [[[ 0.0688,  0.0495, -0.1031],
          [ 0.1177,  0.1024, -0.0114],
          [-0.2280,  0.0330,  0.0554]],

         [[-0.1472, -0.2114,  0.0751],
          [ 0.1479, -0.0121, -0.1630],
          [ 0.0831, -0.1610,  0.0284]],

         [[-0.0147,  0.0540,  0.0908],
          [ 0.2963,  0.2495, -0.0270],
          [ 0.2231,  0.2088,  0.0881]]],


        [[[ 0.1996,  0.1078,  0.0298],
          [ 0.0418,  0.0027, -0.0583],
          [-0.0881,  0.1541, -0.0933]],

         [[-0.2234, -0.2812, -0.0325],
          [ 0.0036, -0.1922, -0.2028],
          [ 0.0681,  0.0332, -0.0970]],

         [[ 0.1020, -0.0715, -0.0356],
          [-0.0027,  0.0439,  0.1229],
          [-0.1426, -0.0187,  0.0929]]],


        [[[-0.0525,  0.0044, -0.1241],
          [-0.1299, -0.2544, -0.1879],
          [ 0.2330, -0.0781, -0.1450]],

         [[ 0.0826, -0.1693, -0.0049],
          [-0.0116, -0.1705,  0.0604],
          [ 0.2135,  0.2218, -0.1295]],

         [[ 0.0718, -0.1194,  0.1741],
          [ 0.1525,  0.0249,  0.0646],
          [-0.1252, -0.0595, -0.0053]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0208, -0.0233, -0.0234],
          [-0.0226, -0.0247, -0.0246],
          [-0.0183, -0.0200, -0.0209]],

         [[-0.0163, -0.0188, -0.0182],
          [-0.0170, -0.0190, -0.0177],
          [-0.0143, -0.0152, -0.0150]],

         [[-0.0185, -0.0194, -0.0181],
          [-0.0194, -0.0193, -0.0175],
          [-0.0181, -0.0159, -0.0152]]],


        [[[-0.0471, -0.0316, -0.0295],
          [-0.0616, -0.0550, -0.0439],
          [-0.0702, -0.0722, -0.0651]],

         [[-0.0684, -0.0462, -0.0396],
          [-0.0715, -0.0594, -0.0522],
          [-0.0778, -0.0740, -0.0682]],

         [[-0.0802, -0.0590, -0.0462],
          [-0.0768, -0.0638, -0.0527],
          [-0.0833, -0.0739, -0.0642]]],


        [[[ 0.0026,  0.0016,  0.0021],
          [-0.0011, -0.0019, -0.0019],
          [ 0.0003,  0.0001, -0.0004]],

         [[-0.0034, -0.0045, -0.0048],
          [-0.0068, -0.0077, -0.0084],
          [-0.0048, -0.0051, -0.0060]],

         [[-0.0057, -0.0065, -0.0064],
          [-0.0083, -0.0086, -0.0086],
          [-0.0064, -0.0061, -0.0062]]],


        ...,


        [[[-0.0038, -0.0023, -0.0020],
          [-0.0025, -0.0010,  0.0014],
          [ 0.0000,  0.0022,  0.0044]],

         [[ 0.0038,  0.0054,  0.0053],
          [ 0.0030,  0.0047,  0.0067],
          [ 0.0047,  0.0067,  0.0086]],

         [[ 0.0014,  0.0041,  0.0042],
          [ 0.0002,  0.0028,  0.0043],
          [ 0.0013,  0.0039,  0.0048]]],


        [[[-0.0097, -0.0030,  0.0060],
          [-0.0167, -0.0066,  0.0023],
          [-0.0160, -0.0085,  0.0040]],

         [[-0.0060, -0.0019,  0.0057],
          [-0.0131, -0.0048,  0.0027],
          [-0.0132, -0.0063,  0.0055]],

         [[-0.0002,  0.0061,  0.0126],
          [-0.0061,  0.0038,  0.0105],
          [-0.0073,  0.0016,  0.0131]]],


        [[[ 0.0092,  0.0076,  0.0093],
          [ 0.0213,  0.0167,  0.0124],
          [ 0.0378,  0.0310,  0.0253]],

         [[ 0.0034,  0.0004,  0.0022],
          [ 0.0142,  0.0097,  0.0065],
          [ 0.0322,  0.0275,  0.0234]],

         [[ 0.0087,  0.0083,  0.0112],
          [ 0.0190,  0.0182,  0.0167],
          [ 0.0346,  0.0348,  0.0331]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0092]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 12 | Batch_idx: 0 |  Loss: (0.4779) | Acc: (80.00%) (103/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.5131) | Acc: (82.00%) (1156/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.5230) | Acc: (82.00%) (2210/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.5185) | Acc: (82.00%) (3279/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.5205) | Acc: (82.00%) (4331/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.5198) | Acc: (82.00%) (5393/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.5181) | Acc: (82.00%) (6471/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.5212) | Acc: (82.00%) (7524/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.5247) | Acc: (82.00%) (8561/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.5286) | Acc: (82.00%) (9594/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.5271) | Acc: (82.00%) (10660/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.5268) | Acc: (82.00%) (11715/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.5218) | Acc: (82.00%) (12809/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.5203) | Acc: (82.00%) (13863/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.5198) | Acc: (82.00%) (14924/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.5180) | Acc: (82.00%) (15979/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.5158) | Acc: (82.00%) (17051/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.5135) | Acc: (82.00%) (18117/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.5114) | Acc: (82.00%) (19191/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.5128) | Acc: (82.00%) (20226/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.5110) | Acc: (82.00%) (21296/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.5131) | Acc: (82.00%) (22345/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.5127) | Acc: (82.00%) (23397/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.5125) | Acc: (82.00%) (24460/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.5125) | Acc: (82.00%) (25513/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.5120) | Acc: (82.00%) (26567/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.5129) | Acc: (82.00%) (27616/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.5123) | Acc: (82.00%) (28684/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.5121) | Acc: (82.00%) (29750/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.5129) | Acc: (82.00%) (30806/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.5123) | Acc: (82.00%) (31878/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.5114) | Acc: (82.00%) (32950/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.5110) | Acc: (82.00%) (34003/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.5109) | Acc: (82.00%) (35049/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.5105) | Acc: (82.00%) (36101/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.5108) | Acc: (82.00%) (37151/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.5111) | Acc: (82.00%) (38203/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.5106) | Acc: (82.00%) (39264/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.5105) | Acc: (82.00%) (40322/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.5119) | Acc: (82.00%) (41312/50000)
# TEST : Loss: (0.6833) | Acc: (78.00%) (7892/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1111, -0.1006, -0.0690],
          [ 0.0119, -0.0219,  0.0862],
          [ 0.0173, -0.0933, -0.2117]],

         [[ 0.0332, -0.0345,  0.0411],
          [-0.2035, -0.0490,  0.0433],
          [ 0.0297,  0.1064, -0.0294]],

         [[-0.0546,  0.0952, -0.2220],
          [ 0.1993,  0.2834,  0.0997],
          [-0.0933,  0.1768,  0.1258]]],


        [[[ 0.1957, -0.1994,  0.0675],
          [ 0.1464, -0.0681, -0.0090],
          [-0.2218, -0.0092, -0.1198]],

         [[ 0.1298, -0.1387,  0.0731],
          [-0.0651,  0.2302, -0.1221],
          [ 0.0852,  0.0392,  0.1707]],

         [[-0.1329, -0.1398, -0.1137],
          [-0.1145,  0.1052, -0.0234],
          [-0.1077,  0.1235,  0.1587]]],


        [[[-0.1576, -0.0885, -0.1410],
          [-0.0003, -0.0500, -0.0753],
          [-0.0470, -0.1270, -0.0851]],

         [[ 0.0457,  0.1616,  0.0008],
          [-0.0980, -0.1047, -0.0329],
          [-0.1938,  0.0474, -0.0763]],

         [[-0.1417,  0.0513,  0.1704],
          [ 0.0303, -0.0944,  0.1800],
          [-0.1369,  0.0778, -0.0004]]],


        ...,


        [[[ 0.0716,  0.0546, -0.0935],
          [ 0.1165,  0.1059, -0.0024],
          [-0.2288,  0.0371,  0.0641]],

         [[-0.1488, -0.2109,  0.0785],
          [ 0.1469, -0.0083, -0.1560],
          [ 0.0845, -0.1546,  0.0361]],

         [[-0.0145,  0.0531,  0.0913],
          [ 0.3012,  0.2569, -0.0204],
          [ 0.2249,  0.2117,  0.0906]]],


        [[[ 0.2063,  0.1152,  0.0401],
          [ 0.0492,  0.0064, -0.0557],
          [-0.0836,  0.1535, -0.0946]],

         [[-0.2208, -0.2888, -0.0353],
          [ 0.0082, -0.2025, -0.2118],
          [ 0.0719,  0.0262, -0.1027]],

         [[ 0.0977, -0.0816, -0.0411],
          [-0.0036,  0.0319,  0.1111],
          [-0.1417, -0.0266,  0.0824]]],


        [[[-0.0464, -0.0008, -0.1243],
          [-0.1360, -0.2756, -0.2041],
          [ 0.2223, -0.0879, -0.1492]],

         [[ 0.0919, -0.1674, -0.0019],
          [-0.0086, -0.1747,  0.0587],
          [ 0.2091,  0.2186, -0.1274]],

         [[ 0.0698, -0.1240,  0.1693],
          [ 0.1442,  0.0144,  0.0560],
          [-0.1405, -0.0704, -0.0133]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0110, -0.0086, -0.0060],
          [ 0.0054, -0.0016, -0.0031],
          [ 0.0081,  0.0007, -0.0050]],

         [[-0.0123, -0.0095, -0.0067],
          [ 0.0038, -0.0036, -0.0042],
          [ 0.0072, -0.0005, -0.0050]],

         [[-0.0141, -0.0100, -0.0085],
          [-0.0009, -0.0063, -0.0073],
          [ 0.0027, -0.0027, -0.0070]]],


        [[[-0.0194, -0.0090, -0.0069],
          [-0.0073, -0.0113, -0.0084],
          [-0.0598, -0.0676, -0.0609]],

         [[-0.0147, -0.0006,  0.0033],
          [-0.0012, -0.0073, -0.0041],
          [-0.0452, -0.0576, -0.0533]],

         [[-0.0481, -0.0373, -0.0383],
          [-0.0393, -0.0457, -0.0421],
          [-0.0812, -0.0921, -0.0920]]],


        [[[-0.0094, -0.0149, -0.0190],
          [-0.0004, -0.0055, -0.0108],
          [ 0.0027, -0.0009, -0.0053]],

         [[-0.0056, -0.0112, -0.0153],
          [ 0.0042, -0.0008, -0.0062],
          [ 0.0068,  0.0033, -0.0011]],

         [[-0.0049, -0.0099, -0.0140],
          [ 0.0039, -0.0006, -0.0059],
          [ 0.0071,  0.0037, -0.0007]]],


        ...,


        [[[ 0.0145,  0.0105,  0.0116],
          [ 0.0109,  0.0067,  0.0080],
          [ 0.0092,  0.0054,  0.0049]],

         [[ 0.0082,  0.0046,  0.0068],
          [ 0.0051,  0.0010,  0.0036],
          [ 0.0049,  0.0012,  0.0016]],

         [[ 0.0030,  0.0010,  0.0041],
          [ 0.0007, -0.0017,  0.0021],
          [ 0.0017, -0.0010,  0.0004]]],


        [[[ 0.0354,  0.0253,  0.0279],
          [ 0.0468,  0.0359,  0.0360],
          [ 0.0684,  0.0640,  0.0606]],

         [[ 0.0110,  0.0021,  0.0059],
          [ 0.0220,  0.0121,  0.0145],
          [ 0.0462,  0.0426,  0.0412]],

         [[-0.0007, -0.0077, -0.0027],
          [ 0.0081, -0.0004,  0.0024],
          [ 0.0310,  0.0260,  0.0250]]],


        [[[ 0.0053,  0.0032,  0.0051],
          [ 0.0134,  0.0065,  0.0040],
          [ 0.0318,  0.0287,  0.0226]],

         [[ 0.0042,  0.0026,  0.0039],
          [ 0.0126,  0.0061,  0.0040],
          [ 0.0312,  0.0288,  0.0232]],

         [[-0.0047, -0.0054, -0.0055],
          [ 0.0036, -0.0012, -0.0045],
          [ 0.0210,  0.0188,  0.0131]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0092]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 13 | Batch_idx: 0 |  Loss: (0.3973) | Acc: (85.00%) (109/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.4606) | Acc: (84.00%) (1187/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.4742) | Acc: (84.00%) (2262/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.4645) | Acc: (84.00%) (3348/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.4687) | Acc: (84.00%) (4432/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.4697) | Acc: (84.00%) (5517/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.4722) | Acc: (84.00%) (6579/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.4701) | Acc: (84.00%) (7662/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.4686) | Acc: (84.00%) (8749/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.4674) | Acc: (84.00%) (9832/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.4674) | Acc: (84.00%) (10899/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.4710) | Acc: (84.00%) (11958/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.4737) | Acc: (84.00%) (13013/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.4759) | Acc: (83.00%) (14077/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.4764) | Acc: (84.00%) (15162/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.4741) | Acc: (84.00%) (16263/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.4739) | Acc: (84.00%) (17330/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.4723) | Acc: (84.00%) (18409/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.4695) | Acc: (84.00%) (19503/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.4697) | Acc: (84.00%) (20588/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.4677) | Acc: (84.00%) (21691/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.4655) | Acc: (84.00%) (22793/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.4650) | Acc: (84.00%) (23884/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.4632) | Acc: (84.00%) (24981/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.4639) | Acc: (84.00%) (26043/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.4643) | Acc: (84.00%) (27117/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.4629) | Acc: (84.00%) (28216/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.4624) | Acc: (84.00%) (29293/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.4616) | Acc: (84.00%) (30395/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.4623) | Acc: (84.00%) (31467/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.4615) | Acc: (84.00%) (32557/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.4623) | Acc: (84.00%) (33632/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.4619) | Acc: (84.00%) (34708/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.4606) | Acc: (84.00%) (35813/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.4607) | Acc: (84.00%) (36907/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.4611) | Acc: (84.00%) (37976/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.4609) | Acc: (84.00%) (39058/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.4611) | Acc: (84.00%) (40131/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.4605) | Acc: (84.00%) (41209/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.4610) | Acc: (84.00%) (42243/50000)
# TEST : Loss: (0.5338) | Acc: (82.00%) (8257/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1196, -0.1082, -0.0766],
          [ 0.0055, -0.0288,  0.0755],
          [ 0.0100, -0.1044, -0.2233]],

         [[ 0.0266, -0.0408,  0.0324],
          [-0.2033, -0.0497,  0.0364],
          [ 0.0279,  0.1010, -0.0372]],

         [[-0.0610,  0.0888, -0.2316],
          [ 0.1997,  0.2846,  0.0928],
          [-0.0935,  0.1733,  0.1168]]],


        [[[ 0.1997, -0.1996,  0.0664],
          [ 0.1462, -0.0685, -0.0179],
          [-0.2231, -0.0128, -0.1268]],

         [[ 0.1296, -0.1407,  0.0718],
          [-0.0642,  0.2338, -0.1268],
          [ 0.0890,  0.0435,  0.1703]],

         [[-0.1261, -0.1335, -0.1013],
          [-0.1098,  0.1138, -0.0156],
          [-0.0998,  0.1332,  0.1684]]],


        [[[-0.1524, -0.0828, -0.1408],
          [-0.0113, -0.0571, -0.0843],
          [-0.0603, -0.1413, -0.1035]],

         [[ 0.0515,  0.1693,  0.0055],
          [-0.1096, -0.1116, -0.0391],
          [-0.2080,  0.0304, -0.0904]],

         [[-0.1214,  0.0704,  0.1808],
          [ 0.0372, -0.0869,  0.1797],
          [-0.1310,  0.0776, -0.0067]]],


        ...,


        [[[ 0.0554,  0.0408, -0.1010],
          [ 0.0969,  0.0905, -0.0080],
          [-0.2477,  0.0210,  0.0576]],

         [[-0.1563, -0.2144,  0.0785],
          [ 0.1359, -0.0118, -0.1493],
          [ 0.0710, -0.1607,  0.0403]],

         [[-0.0133,  0.0597,  0.1008],
          [ 0.3026,  0.2715,  0.0026],
          [ 0.2170,  0.2133,  0.1059]]],


        [[[ 0.2105,  0.1176,  0.0411],
          [ 0.0481,  0.0025, -0.0595],
          [-0.0875,  0.1488, -0.0968]],

         [[-0.2191, -0.2915, -0.0327],
          [-0.0010, -0.2180, -0.2171],
          [ 0.0645,  0.0194, -0.1018]],

         [[ 0.1036, -0.0750, -0.0324],
          [ 0.0013,  0.0346,  0.1149],
          [-0.1357, -0.0208,  0.0881]]],


        [[[-0.0412, -0.0025, -0.1219],
          [-0.1379, -0.2863, -0.2122],
          [ 0.2181, -0.0897, -0.1482]],

         [[ 0.1014, -0.1613,  0.0044],
          [-0.0014, -0.1691,  0.0653],
          [ 0.2130,  0.2251, -0.1164]],

         [[ 0.0798, -0.1176,  0.1727],
          [ 0.1518,  0.0187,  0.0589],
          [-0.1365, -0.0667, -0.0094]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0030, -0.0049, -0.0028],
          [-0.0067, -0.0104, -0.0056],
          [-0.0053, -0.0093, -0.0028]],

         [[ 0.0007, -0.0008,  0.0008],
          [-0.0033, -0.0065, -0.0024],
          [-0.0014, -0.0043,  0.0020]],

         [[ 0.0009, -0.0017, -0.0001],
          [-0.0021, -0.0062, -0.0023],
          [-0.0002, -0.0038,  0.0024]]],


        [[[ 0.0635,  0.0708,  0.0671],
          [ 0.0552,  0.0551,  0.0633],
          [ 0.0525,  0.0512,  0.0437]],

         [[ 0.0489,  0.0570,  0.0582],
          [ 0.0451,  0.0483,  0.0569],
          [ 0.0535,  0.0569,  0.0471]],

         [[ 0.0461,  0.0548,  0.0543],
          [ 0.0473,  0.0513,  0.0572],
          [ 0.0602,  0.0634,  0.0510]]],


        [[[-0.0003, -0.0016, -0.0031],
          [ 0.0001,  0.0004,  0.0002],
          [-0.0014,  0.0006,  0.0015]],

         [[-0.0019, -0.0027, -0.0038],
          [-0.0017, -0.0010, -0.0010],
          [-0.0028, -0.0007,  0.0004]],

         [[-0.0014, -0.0027, -0.0041],
          [-0.0012, -0.0013, -0.0016],
          [-0.0028, -0.0016, -0.0009]]],


        ...,


        [[[ 0.0005,  0.0002,  0.0003],
          [-0.0054, -0.0030, -0.0013],
          [-0.0043, -0.0011,  0.0019]],

         [[ 0.0024,  0.0024,  0.0032],
          [-0.0035, -0.0010,  0.0015],
          [-0.0014,  0.0020,  0.0057]],

         [[ 0.0051,  0.0044,  0.0045],
          [-0.0018,  0.0001,  0.0019],
          [-0.0005,  0.0024,  0.0054]]],


        [[[ 0.0004,  0.0047,  0.0027],
          [ 0.0033,  0.0086,  0.0049],
          [ 0.0039,  0.0061,  0.0039]],

         [[-0.0047, -0.0001,  0.0003],
          [-0.0010,  0.0045,  0.0026],
          [-0.0023, -0.0001, -0.0011]],

         [[-0.0109, -0.0061, -0.0046],
          [-0.0076, -0.0017, -0.0021],
          [-0.0065, -0.0049, -0.0048]]],


        [[[ 0.0030, -0.0073, -0.0039],
          [ 0.0067, -0.0009,  0.0052],
          [ 0.0080,  0.0022,  0.0116]],

         [[-0.0034, -0.0170, -0.0137],
          [-0.0020, -0.0127, -0.0069],
          [-0.0014, -0.0093, -0.0006]],

         [[ 0.0008, -0.0106, -0.0084],
          [ 0.0026, -0.0058, -0.0008],
          [ 0.0030, -0.0035,  0.0049]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0092]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 14 | Batch_idx: 0 |  Loss: (0.4688) | Acc: (84.00%) (108/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.4240) | Acc: (85.00%) (1205/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.4399) | Acc: (84.00%) (2279/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.4302) | Acc: (85.00%) (3383/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.4242) | Acc: (85.00%) (4489/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.4221) | Acc: (85.00%) (5600/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.4211) | Acc: (85.00%) (6708/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.4209) | Acc: (85.00%) (7805/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.4190) | Acc: (85.00%) (8911/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.4171) | Acc: (86.00%) (10019/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.4189) | Acc: (86.00%) (11122/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.4201) | Acc: (85.00%) (12216/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.4184) | Acc: (85.00%) (13315/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.4165) | Acc: (86.00%) (14425/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.4162) | Acc: (86.00%) (15532/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.4173) | Acc: (85.00%) (16619/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.4161) | Acc: (85.00%) (17714/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.4178) | Acc: (85.00%) (18797/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.4186) | Acc: (85.00%) (19889/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.4205) | Acc: (85.00%) (20981/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.4205) | Acc: (85.00%) (22081/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.4196) | Acc: (85.00%) (23184/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.4200) | Acc: (85.00%) (24270/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.4206) | Acc: (85.00%) (25356/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.4206) | Acc: (85.00%) (26456/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.4210) | Acc: (85.00%) (27561/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.4219) | Acc: (85.00%) (28640/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.4233) | Acc: (85.00%) (29727/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.4227) | Acc: (85.00%) (30834/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.4224) | Acc: (85.00%) (31923/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.4210) | Acc: (85.00%) (33045/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.4208) | Acc: (85.00%) (34145/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.4199) | Acc: (85.00%) (35246/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.4198) | Acc: (85.00%) (36350/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.4194) | Acc: (85.00%) (37448/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.4201) | Acc: (85.00%) (38528/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.4206) | Acc: (85.00%) (39624/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.4218) | Acc: (85.00%) (40702/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.4228) | Acc: (85.00%) (41785/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.4230) | Acc: (85.00%) (42822/50000)
# TEST : Loss: (0.5854) | Acc: (80.00%) (8095/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1117, -0.1035, -0.0753],
          [ 0.0074, -0.0301,  0.0710],
          [ 0.0130, -0.1025, -0.2215]],

         [[ 0.0340, -0.0347,  0.0324],
          [-0.1962, -0.0444,  0.0366],
          [ 0.0360,  0.1096, -0.0300]],

         [[-0.0538,  0.0982, -0.2260],
          [ 0.2098,  0.2976,  0.1007],
          [-0.0789,  0.1897,  0.1284]]],


        [[[ 0.2038, -0.2015,  0.0612],
          [ 0.1446, -0.0717, -0.0284],
          [-0.2230, -0.0226, -0.1359]],

         [[ 0.1264, -0.1475,  0.0655],
          [-0.0649,  0.2348, -0.1330],
          [ 0.0935,  0.0427,  0.1683]],

         [[-0.1275, -0.1412, -0.1071],
          [-0.1162,  0.1087, -0.0214],
          [-0.0999,  0.1284,  0.1647]]],


        [[[-0.1454, -0.0718, -0.1213],
          [-0.0109, -0.0458, -0.0595],
          [-0.0584, -0.1196, -0.0766]],

         [[ 0.0583,  0.1807,  0.0271],
          [-0.1091, -0.1014, -0.0154],
          [-0.2031,  0.0465, -0.0633]],

         [[-0.1113,  0.0872,  0.2060],
          [ 0.0383, -0.0739,  0.2032],
          [-0.1265,  0.0948,  0.0193]]],


        ...,


        [[[ 0.0642,  0.0433, -0.0979],
          [ 0.1002,  0.0909, -0.0076],
          [-0.2453,  0.0251,  0.0614]],

         [[-0.1474, -0.2148,  0.0774],
          [ 0.1394, -0.0142, -0.1510],
          [ 0.0700, -0.1590,  0.0418]],

         [[-0.0042,  0.0574,  0.0964],
          [ 0.3103,  0.2700,  0.0003],
          [ 0.2146,  0.2157,  0.1073]]],


        [[[ 0.2186,  0.1171,  0.0389],
          [ 0.0614,  0.0053, -0.0592],
          [-0.0728,  0.1570, -0.0924]],

         [[-0.2100, -0.3051, -0.0463],
          [ 0.0139, -0.2245, -0.2237],
          [ 0.0828,  0.0280, -0.0976]],

         [[ 0.1062, -0.0902, -0.0490],
          [ 0.0083,  0.0204,  0.0993],
          [-0.1263, -0.0256,  0.0776]]],


        [[[-0.0550, -0.0212, -0.1357],
          [-0.1502, -0.2982, -0.2175],
          [ 0.2095, -0.0891, -0.1421]],

         [[ 0.1018, -0.1594,  0.0074],
          [ 0.0027, -0.1589,  0.0798],
          [ 0.2159,  0.2370, -0.0987]],

         [[ 0.0761, -0.1203,  0.1689],
          [ 0.1517,  0.0220,  0.0643],
          [-0.1345, -0.0596, -0.0007]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0124, -0.0081, -0.0128],
          [-0.0136, -0.0090, -0.0115],
          [-0.0110, -0.0045, -0.0041]],

         [[-0.0067, -0.0022, -0.0064],
          [-0.0095, -0.0038, -0.0059],
          [-0.0096, -0.0016, -0.0008]],

         [[-0.0051, -0.0018, -0.0062],
          [-0.0105, -0.0067, -0.0090],
          [-0.0141, -0.0077, -0.0064]]],


        [[[ 0.0322,  0.0364,  0.0493],
          [ 0.0118,  0.0244,  0.0247],
          [ 0.0159,  0.0209,  0.0145]],

         [[ 0.0103,  0.0113,  0.0299],
          [-0.0092,  0.0005,  0.0095],
          [ 0.0036,  0.0025,  0.0043]],

         [[-0.0068, -0.0057,  0.0154],
          [-0.0188, -0.0070,  0.0059],
          [ 0.0009,  0.0017,  0.0048]]],


        [[[ 0.0024,  0.0077,  0.0163],
          [ 0.0022,  0.0054,  0.0131],
          [ 0.0014,  0.0030,  0.0089]],

         [[ 0.0039,  0.0087,  0.0151],
          [ 0.0040,  0.0069,  0.0121],
          [ 0.0017,  0.0035,  0.0076]],

         [[ 0.0076,  0.0106,  0.0140],
          [ 0.0061,  0.0078,  0.0106],
          [ 0.0023,  0.0031,  0.0049]]],


        ...,


        [[[ 0.0206,  0.0201,  0.0150],
          [ 0.0206,  0.0211,  0.0160],
          [ 0.0171,  0.0201,  0.0174]],

         [[ 0.0153,  0.0161,  0.0120],
          [ 0.0135,  0.0151,  0.0117],
          [ 0.0071,  0.0114,  0.0099]],

         [[ 0.0093,  0.0096,  0.0053],
          [ 0.0055,  0.0062,  0.0031],
          [-0.0030,  0.0003, -0.0010]]],


        [[[ 0.0180,  0.0116,  0.0127],
          [ 0.0088,  0.0040,  0.0070],
          [ 0.0077,  0.0042,  0.0063]],

         [[ 0.0121,  0.0067,  0.0072],
          [ 0.0025, -0.0001,  0.0029],
          [ 0.0027,  0.0015,  0.0041]],

         [[ 0.0162,  0.0083,  0.0078],
          [ 0.0113,  0.0052,  0.0065],
          [ 0.0140,  0.0097,  0.0098]]],


        [[[ 0.0418,  0.0214,  0.0214],
          [ 0.0409,  0.0138,  0.0135],
          [ 0.0585,  0.0340,  0.0309]],

         [[ 0.0365,  0.0183,  0.0161],
          [ 0.0353,  0.0094,  0.0067],
          [ 0.0525,  0.0275,  0.0219]],

         [[ 0.0182,  0.0047,  0.0031],
          [ 0.0161, -0.0065, -0.0100],
          [ 0.0323,  0.0086,  0.0004]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[-0.0091]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 15 | Batch_idx: 0 |  Loss: (0.3969) | Acc: (82.00%) (106/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.4428) | Acc: (84.00%) (1185/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.5317) | Acc: (81.00%) (2196/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.5389) | Acc: (81.00%) (3220/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.5285) | Acc: (81.00%) (4285/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.5271) | Acc: (81.00%) (5337/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.5233) | Acc: (81.00%) (6401/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.5284) | Acc: (81.00%) (7436/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.5153) | Acc: (82.00%) (8543/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.5094) | Acc: (82.00%) (9631/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.5055) | Acc: (82.00%) (10700/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.4989) | Acc: (82.00%) (11777/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.4946) | Acc: (83.00%) (12857/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.4890) | Acc: (83.00%) (13949/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.4861) | Acc: (83.00%) (15035/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.4833) | Acc: (83.00%) (16125/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.4809) | Acc: (83.00%) (17214/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.4768) | Acc: (83.00%) (18314/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.4738) | Acc: (83.00%) (19401/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.4728) | Acc: (83.00%) (20482/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.4698) | Acc: (83.00%) (21595/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.4686) | Acc: (83.00%) (22683/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.4665) | Acc: (84.00%) (23775/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.4637) | Acc: (84.00%) (24879/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.4613) | Acc: (84.00%) (25991/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.4596) | Acc: (84.00%) (27086/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.4589) | Acc: (84.00%) (28174/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.4564) | Acc: (84.00%) (29289/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.4539) | Acc: (84.00%) (30406/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.4527) | Acc: (84.00%) (31514/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.4519) | Acc: (84.00%) (32609/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.4510) | Acc: (84.00%) (33703/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.4499) | Acc: (84.00%) (34789/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.4481) | Acc: (84.00%) (35900/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.4459) | Acc: (84.00%) (37021/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.4445) | Acc: (84.00%) (38125/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.4424) | Acc: (84.00%) (39244/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.4406) | Acc: (84.00%) (40357/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.4391) | Acc: (85.00%) (41469/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.4376) | Acc: (85.00%) (42548/50000)
# TEST : Loss: (0.4298) | Acc: (85.00%) (8568/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1099, -0.1019, -0.0738],
          [ 0.0079, -0.0296,  0.0712],
          [ 0.0131, -0.1020, -0.2205]],

         [[ 0.0344, -0.0343,  0.0325],
          [-0.1953, -0.0442,  0.0362],
          [ 0.0358,  0.1092, -0.0301]],

         [[-0.0529,  0.0985, -0.2247],
          [ 0.2097,  0.2972,  0.1007],
          [-0.0780,  0.1898,  0.1286]]],


        [[[ 0.2028, -0.2029,  0.0588],
          [ 0.1446, -0.0720, -0.0295],
          [-0.2219, -0.0226, -0.1358]],

         [[ 0.1259, -0.1485,  0.0632],
          [-0.0639,  0.2348, -0.1337],
          [ 0.0947,  0.0432,  0.1684]],

         [[-0.1263, -0.1409, -0.1082],
          [-0.1141,  0.1096, -0.0215],
          [-0.0979,  0.1292,  0.1652]]],


        [[[-0.1402, -0.0690, -0.1197],
          [-0.0088, -0.0438, -0.0585],
          [-0.0554, -0.1146, -0.0735]],

         [[ 0.0610,  0.1815,  0.0286],
          [-0.1061, -0.0988, -0.0140],
          [-0.1987,  0.0477, -0.0601]],

         [[-0.1079,  0.0886,  0.2063],
          [ 0.0391, -0.0719,  0.2031],
          [-0.1236,  0.0959,  0.0221]]],


        ...,


        [[[ 0.0621,  0.0410, -0.0986],
          [ 0.0964,  0.0872, -0.0095],
          [-0.2472,  0.0219,  0.0591]],

         [[-0.1486, -0.2161,  0.0755],
          [ 0.1344, -0.0184, -0.1525],
          [ 0.0660, -0.1614,  0.0396]],

         [[-0.0049,  0.0553,  0.0957],
          [ 0.3013,  0.2623,  0.0004],
          [ 0.2102,  0.2121,  0.1080]]],


        [[[ 0.2179,  0.1171,  0.0386],
          [ 0.0613,  0.0056, -0.0590],
          [-0.0732,  0.1560, -0.0928]],

         [[-0.2085, -0.3023, -0.0466],
          [ 0.0141, -0.2229, -0.2230],
          [ 0.0811,  0.0262, -0.0990]],

         [[ 0.1048, -0.0900, -0.0496],
          [ 0.0069,  0.0191,  0.0972],
          [-0.1285, -0.0282,  0.0746]]],


        [[[-0.0575, -0.0237, -0.1375],
          [-0.1522, -0.2989, -0.2180],
          [ 0.2060, -0.0915, -0.1435]],

         [[ 0.0999, -0.1599,  0.0064],
          [ 0.0011, -0.1591,  0.0794],
          [ 0.2129,  0.2343, -0.0992]],

         [[ 0.0742, -0.1212,  0.1671],
          [ 0.1496,  0.0210,  0.0640],
          [-0.1366, -0.0612, -0.0013]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1698]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0506]], device='cuda:0')

Epoch: 16 | Batch_idx: 0 |  Loss: (0.3506) | Acc: (86.00%) (111/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.3508) | Acc: (88.00%) (1243/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.3562) | Acc: (88.00%) (2369/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.3702) | Acc: (87.00%) (3478/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.3647) | Acc: (87.00%) (4610/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.3695) | Acc: (87.00%) (5719/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.3711) | Acc: (87.00%) (6843/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.3738) | Acc: (87.00%) (7953/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.3774) | Acc: (87.00%) (9049/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.3775) | Acc: (87.00%) (10176/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.3821) | Acc: (87.00%) (11267/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.3864) | Acc: (87.00%) (12373/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.3857) | Acc: (87.00%) (13488/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.3828) | Acc: (87.00%) (14617/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.3795) | Acc: (87.00%) (15751/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.3811) | Acc: (87.00%) (16852/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.3813) | Acc: (87.00%) (17964/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.3819) | Acc: (87.00%) (19076/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.3812) | Acc: (87.00%) (20198/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.3809) | Acc: (87.00%) (21306/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.3828) | Acc: (87.00%) (22397/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.3825) | Acc: (87.00%) (23504/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.3843) | Acc: (86.00%) (24606/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.3847) | Acc: (86.00%) (25724/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.3861) | Acc: (86.00%) (26823/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.3859) | Acc: (86.00%) (27939/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.3860) | Acc: (86.00%) (29048/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.3864) | Acc: (86.00%) (30153/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.3856) | Acc: (86.00%) (31273/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.3856) | Acc: (86.00%) (32392/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.3858) | Acc: (86.00%) (33501/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.3858) | Acc: (86.00%) (34614/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.3855) | Acc: (86.00%) (35724/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.3849) | Acc: (86.00%) (36841/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.3844) | Acc: (86.00%) (37956/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.3852) | Acc: (86.00%) (39054/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.3856) | Acc: (86.00%) (40162/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.3858) | Acc: (86.00%) (41271/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.3843) | Acc: (86.00%) (42417/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.3836) | Acc: (87.00%) (43501/50000)
# TEST : Loss: (0.4234) | Acc: (86.00%) (8609/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1093, -0.1014, -0.0734],
          [ 0.0079, -0.0294,  0.0709],
          [ 0.0130, -0.1016, -0.2196]],

         [[ 0.0342, -0.0341,  0.0323],
          [-0.1945, -0.0440,  0.0360],
          [ 0.0357,  0.1087, -0.0299]],

         [[-0.0527,  0.0980, -0.2236],
          [ 0.2087,  0.2958,  0.1002],
          [-0.0776,  0.1889,  0.1280]]],


        [[[ 0.2025, -0.2027,  0.0587],
          [ 0.1445, -0.0719, -0.0295],
          [-0.2216, -0.0226, -0.1356]],

         [[ 0.1258, -0.1483,  0.0631],
          [-0.0638,  0.2345, -0.1336],
          [ 0.0946,  0.0431,  0.1681]],

         [[-0.1261, -0.1407, -0.1080],
          [-0.1139,  0.1095, -0.0215],
          [-0.0977,  0.1290,  0.1650]]],


        [[[-0.1381, -0.0680, -0.1184],
          [-0.0086, -0.0428, -0.0576],
          [-0.0536, -0.1114, -0.0723]],

         [[ 0.0602,  0.1793,  0.0283],
          [-0.1042, -0.0971, -0.0138],
          [-0.1947,  0.0469, -0.0593]],

         [[-0.1067,  0.0876,  0.2044],
          [ 0.0385, -0.0710,  0.2009],
          [-0.1218,  0.0946,  0.0218]]],


        ...,


        [[[ 0.0617,  0.0408, -0.0980],
          [ 0.0958,  0.0866, -0.0095],
          [-0.2457,  0.0217,  0.0587]],

         [[-0.1474, -0.2145,  0.0750],
          [ 0.1332, -0.0182, -0.1512],
          [ 0.0654, -0.1600,  0.0393]],

         [[-0.0049,  0.0547,  0.0948],
          [ 0.2946,  0.2570,  0.0004],
          [ 0.2060,  0.2082,  0.1066]]],


        [[[ 0.2170,  0.1166,  0.0384],
          [ 0.0610,  0.0056, -0.0587],
          [-0.0730,  0.1553, -0.0925]],

         [[-0.2071, -0.2998, -0.0462],
          [ 0.0140, -0.2210, -0.2210],
          [ 0.0806,  0.0260, -0.0983]],

         [[ 0.1041, -0.0893, -0.0493],
          [ 0.0068,  0.0190,  0.0965],
          [-0.1278, -0.0280,  0.0741]]],


        [[[-0.0572, -0.0236, -0.1367],
          [-0.1515, -0.2970, -0.2164],
          [ 0.2052, -0.0911, -0.1427]],

         [[ 0.0995, -0.1592,  0.0064],
          [ 0.0011, -0.1584,  0.0790],
          [ 0.2121,  0.2334, -0.0988]],

         [[ 0.0739, -0.1208,  0.1664],
          [ 0.1491,  0.0209,  0.0637],
          [-0.1362, -0.0610, -0.0013]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1909]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0422]], device='cuda:0')

Epoch: 17 | Batch_idx: 0 |  Loss: (0.3649) | Acc: (86.00%) (111/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.3633) | Acc: (87.00%) (1234/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.3665) | Acc: (87.00%) (2352/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.3676) | Acc: (87.00%) (3481/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.3654) | Acc: (87.00%) (4610/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.3640) | Acc: (87.00%) (5744/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.3663) | Acc: (87.00%) (6862/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.3646) | Acc: (87.00%) (7995/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.3671) | Acc: (87.00%) (9103/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.3677) | Acc: (87.00%) (10229/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.3691) | Acc: (87.00%) (11343/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.3716) | Acc: (87.00%) (12455/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.3702) | Acc: (87.00%) (13587/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.3696) | Acc: (87.00%) (14718/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.3680) | Acc: (87.00%) (15856/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.3698) | Acc: (87.00%) (16970/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.3687) | Acc: (87.00%) (18086/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.3705) | Acc: (87.00%) (19191/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.3708) | Acc: (87.00%) (20308/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.3702) | Acc: (87.00%) (21432/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.3717) | Acc: (87.00%) (22543/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.3716) | Acc: (87.00%) (23653/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.3720) | Acc: (87.00%) (24775/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.3732) | Acc: (87.00%) (25881/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.3735) | Acc: (87.00%) (26989/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.3736) | Acc: (87.00%) (28103/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.3754) | Acc: (87.00%) (29209/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.3755) | Acc: (87.00%) (30332/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.3762) | Acc: (87.00%) (31440/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.3758) | Acc: (87.00%) (32560/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.3771) | Acc: (87.00%) (33663/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.3760) | Acc: (87.00%) (34806/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.3760) | Acc: (87.00%) (35934/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.3764) | Acc: (87.00%) (37040/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.3774) | Acc: (87.00%) (38149/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.3774) | Acc: (87.00%) (39275/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.3782) | Acc: (87.00%) (40381/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.3779) | Acc: (87.00%) (41500/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.3779) | Acc: (87.00%) (42616/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.3787) | Acc: (87.00%) (43684/50000)
# TEST : Loss: (0.4220) | Acc: (85.00%) (8598/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1087, -0.1008, -0.0730],
          [ 0.0078, -0.0293,  0.0705],
          [ 0.0130, -0.1011, -0.2184]],

         [[ 0.0340, -0.0340,  0.0321],
          [-0.1935, -0.0438,  0.0358],
          [ 0.0355,  0.1082, -0.0298]],

         [[-0.0524,  0.0975, -0.2224],
          [ 0.2075,  0.2941,  0.0996],
          [-0.0772,  0.1878,  0.1272]]],


        [[[ 0.2022, -0.2023,  0.0586],
          [ 0.1442, -0.0718, -0.0294],
          [-0.2212, -0.0225, -0.1354]],

         [[ 0.1256, -0.1481,  0.0630],
          [-0.0637,  0.2341, -0.1334],
          [ 0.0944,  0.0430,  0.1679]],

         [[-0.1259, -0.1405, -0.1078],
          [-0.1137,  0.1093, -0.0215],
          [-0.0976,  0.1288,  0.1647]]],


        [[[-0.1356, -0.0669, -0.1167],
          [-0.0083, -0.0416, -0.0566],
          [-0.0514, -0.1077, -0.0708]],

         [[ 0.0593,  0.1768,  0.0280],
          [-0.1019, -0.0952, -0.0136],
          [-0.1900,  0.0458, -0.0583]],

         [[-0.1053,  0.0865,  0.2021],
          [ 0.0379, -0.0699,  0.1983],
          [-0.1197,  0.0930,  0.0215]]],


        ...,


        [[[ 0.0612,  0.0405, -0.0973],
          [ 0.0950,  0.0860, -0.0094],
          [-0.2438,  0.0216,  0.0583]],

         [[-0.1460, -0.2126,  0.0743],
          [ 0.1317, -0.0180, -0.1497],
          [ 0.0648, -0.1584,  0.0389]],

         [[-0.0048,  0.0540,  0.0937],
          [ 0.2867,  0.2507,  0.0004],
          [ 0.2010,  0.2036,  0.1049]]],


        [[[ 0.2160,  0.1160,  0.0382],
          [ 0.0607,  0.0056, -0.0584],
          [-0.0726,  0.1546, -0.0920]],

         [[-0.2054, -0.2967, -0.0457],
          [ 0.0139, -0.2187, -0.2185],
          [ 0.0801,  0.0258, -0.0975]],

         [[ 0.1034, -0.0886, -0.0489],
          [ 0.0068,  0.0188,  0.0956],
          [-0.1270, -0.0278,  0.0735]]],


        [[[-0.0569, -0.0234, -0.1356],
          [-0.1507, -0.2946, -0.2145],
          [ 0.2043, -0.0906, -0.1418]],

         [[ 0.0991, -0.1583,  0.0064],
          [ 0.0011, -0.1575,  0.0785],
          [ 0.2112,  0.2322, -0.0983]],

         [[ 0.0736, -0.1202,  0.1656],
          [ 0.1484,  0.0208,  0.0634],
          [-0.1356, -0.0607, -0.0013]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2102]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0107]], device='cuda:0')

Epoch: 18 | Batch_idx: 0 |  Loss: (0.4058) | Acc: (87.00%) (112/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.3540) | Acc: (87.00%) (1237/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.3701) | Acc: (87.00%) (2347/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.3702) | Acc: (87.00%) (3472/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.3745) | Acc: (87.00%) (4581/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.3738) | Acc: (87.00%) (5690/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.3723) | Acc: (87.00%) (6823/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.3724) | Acc: (87.00%) (7947/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.3758) | Acc: (87.00%) (9057/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.3783) | Acc: (87.00%) (10173/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.3783) | Acc: (87.00%) (11291/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.3804) | Acc: (87.00%) (12401/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.3830) | Acc: (87.00%) (13505/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.3827) | Acc: (87.00%) (14617/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.3805) | Acc: (87.00%) (15748/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.3816) | Acc: (87.00%) (16859/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.3838) | Acc: (87.00%) (17963/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.3842) | Acc: (87.00%) (19096/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.3846) | Acc: (87.00%) (20206/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.3853) | Acc: (87.00%) (21318/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.3861) | Acc: (87.00%) (22428/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.3866) | Acc: (87.00%) (23542/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.3876) | Acc: (87.00%) (24637/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.3875) | Acc: (87.00%) (25742/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.3856) | Acc: (87.00%) (26877/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.3848) | Acc: (87.00%) (28010/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.3842) | Acc: (87.00%) (29148/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.3843) | Acc: (87.00%) (30257/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.3845) | Acc: (87.00%) (31381/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.3849) | Acc: (87.00%) (32489/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.3847) | Acc: (87.00%) (33615/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.3853) | Acc: (87.00%) (34720/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.3864) | Acc: (87.00%) (35810/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.3852) | Acc: (87.00%) (36952/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.3843) | Acc: (87.00%) (38074/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.3867) | Acc: (87.00%) (39146/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.3867) | Acc: (87.00%) (40258/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.3868) | Acc: (87.00%) (41374/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.3862) | Acc: (87.00%) (42509/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.3855) | Acc: (87.00%) (43602/50000)
# TEST : Loss: (0.4256) | Acc: (85.00%) (8593/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1080, -0.1001, -0.0725],
          [ 0.0078, -0.0291,  0.0700],
          [ 0.0129, -0.1004, -0.2171]],

         [[ 0.0338, -0.0337,  0.0319],
          [-0.1922, -0.0435,  0.0356],
          [ 0.0353,  0.1075, -0.0296]],

         [[-0.0520,  0.0968, -0.2208],
          [ 0.2061,  0.2920,  0.0989],
          [-0.0766,  0.1865,  0.1264]]],


        [[[ 0.2018, -0.2020,  0.0585],
          [ 0.1440, -0.0717, -0.0294],
          [-0.2208, -0.0225, -0.1352]],

         [[ 0.1253, -0.1478,  0.0629],
          [-0.0636,  0.2336, -0.1331],
          [ 0.0942,  0.0430,  0.1676]],

         [[-0.1256, -0.1402, -0.1076],
          [-0.1135,  0.1091, -0.0214],
          [-0.0974,  0.1286,  0.1644]]],


        [[[-0.1327, -0.0655, -0.1148],
          [-0.0079, -0.0401, -0.0553],
          [-0.0488, -0.1033, -0.0691]],

         [[ 0.0582,  0.1737,  0.0276],
          [-0.0992, -0.0929, -0.0134],
          [-0.1844,  0.0446, -0.0572]],

         [[-0.1036,  0.0852,  0.1993],
          [ 0.0372, -0.0686,  0.1951],
          [-0.1171,  0.0912,  0.0212]]],


        ...,


        [[[ 0.0607,  0.0401, -0.0964],
          [ 0.0941,  0.0852, -0.0093],
          [-0.2415,  0.0214,  0.0578]],

         [[-0.1444, -0.2102,  0.0735],
          [ 0.1300, -0.0178, -0.1479],
          [ 0.0639, -0.1564,  0.0385]],

         [[-0.0047,  0.0532,  0.0924],
          [ 0.2773,  0.2432,  0.0004],
          [ 0.1950,  0.1980,  0.1029]]],


        [[[ 0.2147,  0.1153,  0.0380],
          [ 0.0604,  0.0056, -0.0581],
          [-0.0722,  0.1537, -0.0914]],

         [[-0.2034, -0.2930, -0.0452],
          [ 0.0137, -0.2160, -0.2156],
          [ 0.0794,  0.0256, -0.0965]],

         [[ 0.1024, -0.0876, -0.0483],
          [ 0.0067,  0.0186,  0.0945],
          [-0.1259, -0.0276,  0.0728]]],


        [[[-0.0566, -0.0232, -0.1344],
          [-0.1498, -0.2917, -0.2122],
          [ 0.2032, -0.0899, -0.1407]],

         [[ 0.0985, -0.1572,  0.0063],
          [ 0.0011, -0.1564,  0.0780],
          [ 0.2102,  0.2308, -0.0976]],

         [[ 0.0732, -0.1195,  0.1646],
          [ 0.1476,  0.0207,  0.0630],
          [-0.1349, -0.0604, -0.0013]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2017]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0272]], device='cuda:0')

Epoch: 19 | Batch_idx: 0 |  Loss: (0.4807) | Acc: (82.00%) (106/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.4016) | Acc: (86.00%) (1221/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.3857) | Acc: (87.00%) (2347/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.3726) | Acc: (88.00%) (3493/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.3707) | Acc: (88.00%) (4626/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.3773) | Acc: (87.00%) (5742/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.3806) | Acc: (87.00%) (6847/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.3870) | Acc: (87.00%) (7941/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.3916) | Acc: (87.00%) (9032/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.3919) | Acc: (87.00%) (10154/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.3912) | Acc: (87.00%) (11271/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.3893) | Acc: (87.00%) (12389/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.3940) | Acc: (87.00%) (13478/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.3961) | Acc: (87.00%) (14590/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.3946) | Acc: (87.00%) (15706/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.3933) | Acc: (87.00%) (16838/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.3932) | Acc: (87.00%) (17966/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.3934) | Acc: (87.00%) (19074/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.3941) | Acc: (87.00%) (20178/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.3948) | Acc: (87.00%) (21289/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.3962) | Acc: (87.00%) (22404/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.3965) | Acc: (87.00%) (23506/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.3960) | Acc: (87.00%) (24647/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.3951) | Acc: (87.00%) (25779/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.3936) | Acc: (87.00%) (26916/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.3935) | Acc: (87.00%) (28036/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.3931) | Acc: (87.00%) (29146/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.3934) | Acc: (87.00%) (30257/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.3935) | Acc: (87.00%) (31389/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.3937) | Acc: (87.00%) (32508/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.3942) | Acc: (87.00%) (33626/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.3953) | Acc: (87.00%) (34722/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.3953) | Acc: (87.00%) (35840/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.3957) | Acc: (87.00%) (36955/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.3951) | Acc: (87.00%) (38075/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.3961) | Acc: (87.00%) (39184/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.3971) | Acc: (87.00%) (40287/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.3979) | Acc: (87.00%) (41386/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.3992) | Acc: (87.00%) (42490/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.4005) | Acc: (87.00%) (43532/50000)
# TEST : Loss: (0.4445) | Acc: (85.00%) (8543/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1071, -0.0993, -0.0719],
          [ 0.0077, -0.0289,  0.0695],
          [ 0.0128, -0.0997, -0.2154]],

         [[ 0.0335, -0.0334,  0.0317],
          [-0.1907, -0.0431,  0.0353],
          [ 0.0350,  0.1067, -0.0294]],

         [[-0.0516,  0.0960, -0.2189],
          [ 0.2043,  0.2895,  0.0981],
          [-0.0760,  0.1849,  0.1253]]],


        [[[ 0.2014, -0.2015,  0.0584],
          [ 0.1436, -0.0715, -0.0293],
          [-0.2203, -0.0224, -0.1349]],

         [[ 0.1251, -0.1474,  0.0628],
          [-0.0634,  0.2331, -0.1328],
          [ 0.0940,  0.0429,  0.1672]],

         [[-0.1253, -0.1399, -0.1074],
          [-0.1132,  0.1088, -0.0214],
          [-0.0971,  0.1283,  0.1640]]],


        [[[-0.1291, -0.0639, -0.1124],
          [-0.0076, -0.0385, -0.0538],
          [-0.0459, -0.0982, -0.0670]],

         [[ 0.0569,  0.1701,  0.0271],
          [-0.0960, -0.0901, -0.0131],
          [-0.1778,  0.0432, -0.0558]],

         [[-0.1016,  0.0836,  0.1960],
          [ 0.0363, -0.0670,  0.1912],
          [-0.1141,  0.0890,  0.0207]]],


        ...,


        [[[ 0.0600,  0.0397, -0.0954],
          [ 0.0931,  0.0842, -0.0092],
          [-0.2388,  0.0211,  0.0571]],

         [[-0.1424, -0.2074,  0.0726],
          [ 0.1279, -0.0175, -0.1458],
          [ 0.0629, -0.1541,  0.0379]],

         [[-0.0046,  0.0521,  0.0909],
          [ 0.2663,  0.2343,  0.0004],
          [ 0.1880,  0.1915,  0.1005]]],


        [[[ 0.2132,  0.1145,  0.0377],
          [ 0.0600,  0.0055, -0.0576],
          [-0.0717,  0.1525, -0.0907]],

         [[-0.2010, -0.2886, -0.0445],
          [ 0.0136, -0.2127, -0.2120],
          [ 0.0786,  0.0253, -0.0952]],

         [[ 0.1013, -0.0865, -0.0477],
          [ 0.0066,  0.0184,  0.0932],
          [-0.1247, -0.0272,  0.0719]]],


        [[[-0.0561, -0.0229, -0.1329],
          [-0.1486, -0.2883, -0.2094],
          [ 0.2019, -0.0892, -0.1393]],

         [[ 0.0978, -0.1559,  0.0063],
          [ 0.0011, -0.1550,  0.0773],
          [ 0.2089,  0.2291, -0.0969]],

         [[ 0.0727, -0.1186,  0.1634],
          [ 0.1467,  0.0206,  0.0625],
          [-0.1341, -0.0599, -0.0013]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1951]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0233]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 20 | Batch_idx: 0 |  Loss: (0.4299) | Acc: (89.00%) (114/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7663) | Acc: (74.00%) (1051/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.8105) | Acc: (72.00%) (1960/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.8068) | Acc: (73.00%) (2909/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.8042) | Acc: (73.00%) (3838/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.7864) | Acc: (73.00%) (4800/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.7636) | Acc: (74.00%) (5810/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.7567) | Acc: (74.00%) (6792/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.7592) | Acc: (74.00%) (7739/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.7484) | Acc: (74.00%) (8728/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.7393) | Acc: (75.00%) (9723/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.7285) | Acc: (75.00%) (10732/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.7208) | Acc: (75.00%) (11730/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.7142) | Acc: (75.00%) (12728/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.7056) | Acc: (76.00%) (13747/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.6977) | Acc: (76.00%) (14776/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.6920) | Acc: (76.00%) (15800/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.6877) | Acc: (76.00%) (16811/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.6805) | Acc: (77.00%) (17849/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.6737) | Acc: (77.00%) (18891/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.6700) | Acc: (77.00%) (19914/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.6644) | Acc: (77.00%) (20968/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.6593) | Acc: (77.00%) (21999/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.6527) | Acc: (77.00%) (23053/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.6481) | Acc: (78.00%) (24092/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.6432) | Acc: (78.00%) (25139/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.6397) | Acc: (78.00%) (26174/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.6345) | Acc: (78.00%) (27238/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.6300) | Acc: (78.00%) (28293/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.6254) | Acc: (78.00%) (29354/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.6229) | Acc: (78.00%) (30409/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.6202) | Acc: (79.00%) (31452/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.6179) | Acc: (79.00%) (32499/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.6161) | Acc: (79.00%) (33531/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.6124) | Acc: (79.00%) (34596/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.6097) | Acc: (79.00%) (35642/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.6073) | Acc: (79.00%) (36709/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.6046) | Acc: (79.00%) (37767/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.6023) | Acc: (79.00%) (38823/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.5997) | Acc: (79.00%) (39848/50000)
# TEST : Loss: (0.5494) | Acc: (81.00%) (8135/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1135, -0.0934, -0.0556],
          [ 0.0040, -0.0275,  0.0793],
          [ 0.0061, -0.1053, -0.2133]],

         [[ 0.0137, -0.0397,  0.0328],
          [-0.2010, -0.0459,  0.0380],
          [ 0.0226,  0.0959, -0.0355]],

         [[-0.0580,  0.1038, -0.2084],
          [ 0.2126,  0.3115,  0.1215],
          [-0.0663,  0.2015,  0.1412]]],


        [[[ 0.2329, -0.1826,  0.0896],
          [ 0.1651, -0.0407, -0.0266],
          [-0.2214, -0.0304, -0.1403]],

         [[ 0.1221, -0.1620,  0.0705],
          [-0.0590,  0.2550, -0.1364],
          [ 0.0943,  0.0448,  0.1650]],

         [[-0.1213, -0.1458, -0.0891],
          [-0.1148,  0.1236, -0.0217],
          [-0.0949,  0.1288,  0.1651]]],


        [[[-0.1256, -0.0425, -0.0796],
          [-0.0479, -0.0545, -0.0409],
          [-0.0716, -0.1115, -0.0531]],

         [[ 0.0543,  0.1873,  0.0578],
          [-0.1236, -0.1013, -0.0037],
          [-0.2081,  0.0178, -0.0541]],

         [[-0.1143,  0.0865,  0.2049],
          [ 0.0035, -0.0859,  0.1823],
          [-0.1450,  0.0619,  0.0107]]],


        ...,


        [[[ 0.0531,  0.0263, -0.0964],
          [ 0.0831,  0.0680, -0.0178],
          [-0.2553,  0.0038,  0.0514]],

         [[-0.1436, -0.2174,  0.0725],
          [ 0.1279, -0.0269, -0.1521],
          [ 0.0495, -0.1642,  0.0354]],

         [[ 0.0014,  0.0461,  0.0955],
          [ 0.3053,  0.2466,  0.0086],
          [ 0.2004,  0.2025,  0.1156]]],


        [[[ 0.2093,  0.1115,  0.0324],
          [ 0.0537, -0.0022, -0.0655],
          [-0.0716,  0.1531, -0.0856]],

         [[-0.2171, -0.3054, -0.0599],
          [-0.0089, -0.2358, -0.2297],
          [ 0.0765,  0.0278, -0.0846]],

         [[ 0.1008, -0.0836, -0.0427],
          [ 0.0065,  0.0178,  0.0921],
          [-0.1141, -0.0128,  0.0865]]],


        [[[-0.0543, -0.0340, -0.1277],
          [-0.1560, -0.3144, -0.2318],
          [ 0.2015, -0.0947, -0.1358]],

         [[ 0.1041, -0.1570,  0.0125],
          [ 0.0053, -0.1608,  0.0686],
          [ 0.2156,  0.2266, -0.0972]],

         [[ 0.0734, -0.1213,  0.1655],
          [ 0.1450,  0.0113,  0.0540],
          [-0.1311, -0.0672, -0.0078]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0408, -0.0377, -0.0399],
          [-0.0398, -0.0339, -0.0375],
          [-0.0388, -0.0340, -0.0383]],

         [[-0.0412, -0.0373, -0.0394],
          [-0.0422, -0.0353, -0.0383],
          [-0.0418, -0.0364, -0.0402]],

         [[-0.0363, -0.0329, -0.0352],
          [-0.0378, -0.0315, -0.0345],
          [-0.0383, -0.0338, -0.0372]]],


        [[[-0.0477, -0.0611, -0.0594],
          [-0.0345, -0.0292, -0.0299],
          [-0.0249, -0.0297, -0.0307]],

         [[-0.0314, -0.0460, -0.0466],
          [-0.0169, -0.0219, -0.0267],
          [-0.0107, -0.0248, -0.0313]],

         [[-0.0223, -0.0273, -0.0270],
          [-0.0114, -0.0118, -0.0108],
          [-0.0077, -0.0164, -0.0125]]],


        [[[-0.0014,  0.0005,  0.0018],
          [-0.0030, -0.0001,  0.0015],
          [-0.0013,  0.0029,  0.0044]],

         [[-0.0002,  0.0011,  0.0014],
          [-0.0013,  0.0010,  0.0015],
          [ 0.0005,  0.0042,  0.0049]],

         [[ 0.0001,  0.0008,  0.0005],
          [-0.0007,  0.0009,  0.0007],
          [ 0.0012,  0.0040,  0.0042]]],


        ...,


        [[[-0.0264, -0.0288, -0.0281],
          [-0.0157, -0.0176, -0.0182],
          [-0.0150, -0.0189, -0.0183]],

         [[-0.0214, -0.0232, -0.0215],
          [-0.0112, -0.0128, -0.0127],
          [-0.0110, -0.0144, -0.0133]],

         [[-0.0149, -0.0165, -0.0147],
          [-0.0067, -0.0079, -0.0075],
          [-0.0064, -0.0092, -0.0076]]],


        [[[ 0.0091,  0.0047,  0.0001],
          [ 0.0021,  0.0011, -0.0018],
          [ 0.0011,  0.0040,  0.0023]],

         [[ 0.0089,  0.0047,  0.0013],
          [ 0.0013,  0.0006, -0.0013],
          [-0.0012,  0.0018,  0.0010]],

         [[ 0.0063,  0.0015, -0.0021],
          [-0.0011, -0.0024, -0.0045],
          [-0.0047, -0.0022, -0.0030]]],


        [[[ 0.0040,  0.0009, -0.0016],
          [-0.0001,  0.0003, -0.0007],
          [ 0.0007,  0.0019,  0.0032]],

         [[ 0.0066,  0.0026, -0.0015],
          [ 0.0020,  0.0010, -0.0012],
          [ 0.0023,  0.0018,  0.0018]],

         [[ 0.0040,  0.0009, -0.0029],
          [ 0.0006, -0.0001, -0.0031],
          [-0.0001, -0.0006, -0.0018]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1959]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 21 | Batch_idx: 0 |  Loss: (0.3910) | Acc: (85.00%) (110/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.4580) | Acc: (84.00%) (1188/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.4556) | Acc: (84.00%) (2268/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.4565) | Acc: (84.00%) (3345/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.4499) | Acc: (84.00%) (4446/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.4491) | Acc: (84.00%) (5538/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.4497) | Acc: (84.00%) (6631/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.4503) | Acc: (84.00%) (7716/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.4472) | Acc: (85.00%) (8823/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.4524) | Acc: (84.00%) (9884/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.4518) | Acc: (84.00%) (10964/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.4502) | Acc: (84.00%) (12046/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.4553) | Acc: (84.00%) (13110/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.4544) | Acc: (84.00%) (14195/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.4583) | Acc: (84.00%) (15261/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.4574) | Acc: (84.00%) (16346/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.4566) | Acc: (84.00%) (17449/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.4550) | Acc: (84.00%) (18542/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.4541) | Acc: (84.00%) (19631/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.4547) | Acc: (84.00%) (20709/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.4565) | Acc: (84.00%) (21784/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.4542) | Acc: (84.00%) (22876/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.4559) | Acc: (84.00%) (23953/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.4558) | Acc: (84.00%) (25037/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.4548) | Acc: (84.00%) (26125/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.4530) | Acc: (84.00%) (27233/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.4523) | Acc: (84.00%) (28320/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.4509) | Acc: (84.00%) (29427/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.4490) | Acc: (84.00%) (30535/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.4482) | Acc: (84.00%) (31636/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.4497) | Acc: (84.00%) (32716/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.4491) | Acc: (84.00%) (33817/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.4476) | Acc: (85.00%) (34925/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.4469) | Acc: (85.00%) (36034/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.4467) | Acc: (85.00%) (37127/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.4468) | Acc: (85.00%) (38216/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.4477) | Acc: (85.00%) (39279/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.4488) | Acc: (84.00%) (40360/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.4479) | Acc: (85.00%) (41463/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.4480) | Acc: (85.00%) (42518/50000)
# TEST : Loss: (0.5443) | Acc: (81.00%) (8197/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1240, -0.1005, -0.0596],
          [-0.0062, -0.0349,  0.0725],
          [ 0.0017, -0.1117, -0.2193]],

         [[-0.0020, -0.0496,  0.0251],
          [-0.2064, -0.0463,  0.0364],
          [ 0.0254,  0.0986, -0.0334]],

         [[-0.0742,  0.0923, -0.2194],
          [ 0.2059,  0.3118,  0.1192],
          [-0.0631,  0.2067,  0.1422]]],


        [[[ 0.2316, -0.1828,  0.0969],
          [ 0.1600, -0.0414, -0.0390],
          [-0.2183, -0.0340, -0.1460]],

         [[ 0.1166, -0.1664,  0.0727],
          [-0.0627,  0.2632, -0.1405],
          [ 0.1012,  0.0523,  0.1685]],

         [[-0.1267, -0.1503, -0.0807],
          [-0.1215,  0.1266, -0.0214],
          [-0.0889,  0.1344,  0.1704]]],


        [[[-0.1348, -0.0565, -0.0907],
          [-0.0588, -0.0724, -0.0450],
          [-0.0685, -0.1151, -0.0523]],

         [[ 0.0561,  0.1843,  0.0573],
          [-0.1159, -0.0984,  0.0065],
          [-0.1923,  0.0297, -0.0379]],

         [[-0.1069,  0.0924,  0.2107],
          [ 0.0093, -0.0771,  0.1966],
          [-0.1354,  0.0755,  0.0301]]],


        ...,


        [[[ 0.0526,  0.0290, -0.0876],
          [ 0.0908,  0.0784, -0.0025],
          [-0.2406,  0.0171,  0.0656]],

         [[-0.1388, -0.2119,  0.0798],
          [ 0.1501, -0.0054, -0.1303],
          [ 0.0766, -0.1386,  0.0565]],

         [[-0.0089,  0.0380,  0.0884],
          [ 0.3265,  0.2696,  0.0274],
          [ 0.2308,  0.2281,  0.1308]]],


        [[[ 0.1989,  0.1040,  0.0275],
          [ 0.0499, -0.0092, -0.0759],
          [-0.0777,  0.1457, -0.0946]],

         [[-0.2366, -0.3215, -0.0681],
          [-0.0244, -0.2522, -0.2463],
          [ 0.0616,  0.0180, -0.0914]],

         [[ 0.0983, -0.0746, -0.0351],
          [ 0.0131,  0.0287,  0.0931],
          [-0.1058,  0.0033,  0.0972]]],


        [[[-0.0681, -0.0479, -0.1301],
          [-0.1638, -0.3288, -0.2444],
          [ 0.1957, -0.0947, -0.1330]],

         [[ 0.0994, -0.1588,  0.0119],
          [ 0.0100, -0.1541,  0.0744],
          [ 0.2180,  0.2354, -0.0842]],

         [[ 0.0656, -0.1240,  0.1652],
          [ 0.1481,  0.0162,  0.0610],
          [-0.1246, -0.0555,  0.0072]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0028, -0.0042, -0.0083],
          [ 0.0024, -0.0051, -0.0043],
          [ 0.0010, -0.0038, -0.0004]],

         [[ 0.0134,  0.0082,  0.0059],
          [ 0.0119,  0.0065,  0.0087],
          [ 0.0089,  0.0057,  0.0101]],

         [[ 0.0075,  0.0029,  0.0032],
          [ 0.0044,  0.0002,  0.0048],
          [ 0.0014, -0.0001,  0.0064]]],


        [[[-0.0316, -0.0779, -0.0991],
          [-0.0098, -0.0481, -0.0614],
          [-0.0198,  0.0039, -0.0349]],

         [[-0.0624, -0.1085, -0.1296],
          [-0.0468, -0.0837, -0.0949],
          [-0.0624, -0.0424, -0.0776]],

         [[-0.0542, -0.0972, -0.1153],
          [-0.0359, -0.0729, -0.0797],
          [-0.0515, -0.0338, -0.0681]]],


        [[[ 0.0031, -0.0023, -0.0051],
          [ 0.0026, -0.0008, -0.0049],
          [-0.0030, -0.0054, -0.0063]],

         [[ 0.0030, -0.0018, -0.0037],
          [ 0.0022, -0.0006, -0.0043],
          [-0.0035, -0.0055, -0.0061]],

         [[ 0.0039, -0.0007, -0.0020],
          [ 0.0037,  0.0007, -0.0025],
          [-0.0014, -0.0033, -0.0036]]],


        ...,


        [[[ 0.0356,  0.0310,  0.0283],
          [ 0.0396,  0.0356,  0.0308],
          [ 0.0420,  0.0372,  0.0320]],

         [[ 0.0265,  0.0216,  0.0180],
          [ 0.0280,  0.0235,  0.0182],
          [ 0.0288,  0.0234,  0.0181]],

         [[ 0.0084,  0.0039,  0.0014],
          [ 0.0073,  0.0032, -0.0009],
          [ 0.0078,  0.0033, -0.0009]]],


        [[[-0.0118, -0.0071, -0.0060],
          [-0.0124, -0.0089, -0.0073],
          [-0.0098, -0.0074, -0.0060]],

         [[-0.0062, -0.0010, -0.0000],
          [-0.0094, -0.0047, -0.0023],
          [-0.0084, -0.0050, -0.0020]],

         [[-0.0082, -0.0033, -0.0022],
          [-0.0114, -0.0067, -0.0037],
          [-0.0109, -0.0068, -0.0034]]],


        [[[ 0.0116,  0.0008, -0.0029],
          [ 0.0061, -0.0016, -0.0009],
          [ 0.0056, -0.0028, -0.0014]],

         [[ 0.0064, -0.0032, -0.0068],
          [ 0.0009, -0.0056, -0.0045],
          [-0.0009, -0.0086, -0.0065]],

         [[-0.0018, -0.0091, -0.0113],
          [-0.0069, -0.0116, -0.0095],
          [-0.0092, -0.0150, -0.0122]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1954]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 22 | Batch_idx: 0 |  Loss: (0.4099) | Acc: (86.00%) (111/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.3982) | Acc: (86.00%) (1216/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.4222) | Acc: (85.00%) (2294/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.4209) | Acc: (85.00%) (3389/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.4264) | Acc: (85.00%) (4485/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.4327) | Acc: (85.00%) (5560/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.4240) | Acc: (85.00%) (6678/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.4165) | Acc: (85.00%) (7792/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.4123) | Acc: (85.00%) (8902/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.4096) | Acc: (85.00%) (10010/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.4070) | Acc: (85.00%) (11114/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.4035) | Acc: (86.00%) (12233/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.4053) | Acc: (86.00%) (13321/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.4041) | Acc: (86.00%) (14433/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.4076) | Acc: (85.00%) (15519/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.4078) | Acc: (86.00%) (16631/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.4136) | Acc: (85.00%) (17703/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.4152) | Acc: (85.00%) (18797/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.4145) | Acc: (85.00%) (19903/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.4148) | Acc: (85.00%) (21004/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.4144) | Acc: (85.00%) (22112/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.4146) | Acc: (85.00%) (23220/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.4127) | Acc: (86.00%) (24332/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.4114) | Acc: (86.00%) (25447/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.4112) | Acc: (86.00%) (26552/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.4107) | Acc: (86.00%) (27665/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.4111) | Acc: (86.00%) (28772/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.4123) | Acc: (86.00%) (29856/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.4125) | Acc: (86.00%) (30957/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.4118) | Acc: (86.00%) (32078/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.4125) | Acc: (86.00%) (33171/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.4122) | Acc: (86.00%) (34275/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.4116) | Acc: (86.00%) (35380/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.4104) | Acc: (86.00%) (36503/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.4092) | Acc: (86.00%) (37614/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.4088) | Acc: (86.00%) (38726/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.4091) | Acc: (86.00%) (39820/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.4089) | Acc: (86.00%) (40917/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.4080) | Acc: (86.00%) (42034/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.4072) | Acc: (86.00%) (43098/50000)
# TEST : Loss: (0.5046) | Acc: (82.00%) (8293/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1226, -0.1025, -0.0633],
          [-0.0089, -0.0372,  0.0671],
          [ 0.0004, -0.1155, -0.2241]],

         [[ 0.0019, -0.0480,  0.0240],
          [-0.2036, -0.0418,  0.0360],
          [ 0.0271,  0.0998, -0.0352]],

         [[-0.0713,  0.0942, -0.2217],
          [ 0.2088,  0.3193,  0.1192],
          [-0.0601,  0.2099,  0.1391]]],


        [[[ 0.2311, -0.1853,  0.1004],
          [ 0.1520, -0.0479, -0.0576],
          [-0.2296, -0.0471, -0.1594]],

         [[ 0.1096, -0.1720,  0.0746],
          [-0.0649,  0.2646, -0.1523],
          [ 0.1020,  0.0521,  0.1619]],

         [[-0.1292, -0.1498, -0.0675],
          [-0.1248,  0.1297, -0.0257],
          [-0.0868,  0.1360,  0.1681]]],


        [[[-0.1443, -0.0682, -0.1027],
          [-0.0752, -0.0891, -0.0587],
          [-0.0821, -0.1219, -0.0579]],

         [[ 0.0511,  0.1776,  0.0523],
          [-0.1238, -0.1066,  0.0001],
          [-0.1982,  0.0270, -0.0377]],

         [[-0.1190,  0.0806,  0.2020],
          [-0.0094, -0.0925,  0.1840],
          [-0.1516,  0.0640,  0.0213]]],


        ...,


        [[[ 0.0656,  0.0376, -0.0802],
          [ 0.0940,  0.0793, -0.0023],
          [-0.2421,  0.0117,  0.0626]],

         [[-0.1280, -0.2048,  0.0840],
          [ 0.1497, -0.0068, -0.1325],
          [ 0.0692, -0.1462,  0.0509]],

         [[ 0.0129,  0.0542,  0.0992],
          [ 0.3380,  0.2783,  0.0312],
          [ 0.2256,  0.2178,  0.1246]]],


        [[[ 0.2054,  0.1051,  0.0304],
          [ 0.0622, -0.0049, -0.0722],
          [-0.0736,  0.1477, -0.0927]],

         [[-0.2323, -0.3315, -0.0779],
          [-0.0103, -0.2494, -0.2458],
          [ 0.0703,  0.0258, -0.0875]],

         [[ 0.0967, -0.0882, -0.0515],
          [ 0.0254,  0.0275,  0.0839],
          [-0.0949,  0.0126,  0.0962]]],


        [[[-0.0774, -0.0553, -0.1383],
          [-0.1809, -0.3407, -0.2557],
          [ 0.1778, -0.1067, -0.1536]],

         [[ 0.1023, -0.1584,  0.0056],
          [ 0.0070, -0.1535,  0.0711],
          [ 0.2069,  0.2280, -0.0965]],

         [[ 0.0688, -0.1218,  0.1610],
          [ 0.1477,  0.0197,  0.0602],
          [-0.1334, -0.0603, -0.0042]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0100,  0.0090,  0.0068],
          [ 0.0072,  0.0041,  0.0042],
          [ 0.0040,  0.0026,  0.0042]],

         [[ 0.0109,  0.0102,  0.0090],
          [ 0.0079,  0.0051,  0.0063],
          [ 0.0041,  0.0029,  0.0055]],

         [[ 0.0124,  0.0121,  0.0105],
          [ 0.0096,  0.0079,  0.0084],
          [ 0.0059,  0.0057,  0.0076]]],


        [[[ 0.0790,  0.0734,  0.0200],
          [ 0.0438,  0.0633,  0.0438],
          [ 0.0299,  0.0262,  0.0150]],

         [[ 0.0804,  0.0802,  0.0313],
          [ 0.0462,  0.0714,  0.0575],
          [ 0.0325,  0.0345,  0.0269]],

         [[ 0.0804,  0.0771,  0.0343],
          [ 0.0607,  0.0797,  0.0706],
          [ 0.0508,  0.0531,  0.0508]]],


        [[[ 0.0001,  0.0020,  0.0055],
          [-0.0010,  0.0019,  0.0052],
          [ 0.0010,  0.0038,  0.0076]],

         [[ 0.0001,  0.0017,  0.0050],
          [-0.0007,  0.0019,  0.0051],
          [ 0.0013,  0.0041,  0.0076]],

         [[ 0.0004,  0.0020,  0.0050],
          [-0.0006,  0.0020,  0.0048],
          [ 0.0008,  0.0034,  0.0064]]],


        ...,


        [[[ 0.0098,  0.0110,  0.0096],
          [ 0.0107,  0.0107,  0.0090],
          [ 0.0084,  0.0080,  0.0061]],

         [[ 0.0077,  0.0093,  0.0084],
          [ 0.0079,  0.0081,  0.0067],
          [ 0.0048,  0.0045,  0.0026]],

         [[ 0.0035,  0.0049,  0.0039],
          [ 0.0026,  0.0027,  0.0014],
          [-0.0007, -0.0010, -0.0028]]],


        [[[-0.0080, -0.0021,  0.0009],
          [-0.0036, -0.0009,  0.0016],
          [ 0.0013,  0.0013,  0.0030]],

         [[-0.0087, -0.0029, -0.0002],
          [-0.0039, -0.0013,  0.0007],
          [ 0.0014,  0.0011,  0.0022]],

         [[-0.0103, -0.0053, -0.0022],
          [-0.0060, -0.0040, -0.0017],
          [-0.0003, -0.0008,  0.0003]]],


        [[[ 0.0008,  0.0027,  0.0027],
          [ 0.0050,  0.0027,  0.0021],
          [ 0.0104,  0.0041,  0.0009]],

         [[-0.0008,  0.0007,  0.0010],
          [ 0.0027,  0.0003,  0.0003],
          [ 0.0079,  0.0015, -0.0010]],

         [[ 0.0019,  0.0029,  0.0033],
          [ 0.0045,  0.0023,  0.0025],
          [ 0.0089,  0.0034,  0.0009]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1949]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 23 | Batch_idx: 0 |  Loss: (0.2167) | Acc: (92.00%) (118/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.3496) | Acc: (87.00%) (1236/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.3545) | Acc: (87.00%) (2361/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.3511) | Acc: (88.00%) (3496/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.3484) | Acc: (88.00%) (4624/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.3532) | Acc: (87.00%) (5740/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.3591) | Acc: (87.00%) (6857/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.3567) | Acc: (87.00%) (7983/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.3591) | Acc: (87.00%) (9108/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.3592) | Acc: (87.00%) (10219/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.3605) | Acc: (87.00%) (11331/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.3625) | Acc: (87.00%) (12459/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.3639) | Acc: (87.00%) (13580/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.3657) | Acc: (87.00%) (14676/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.3661) | Acc: (87.00%) (15785/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.3689) | Acc: (87.00%) (16886/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.3690) | Acc: (87.00%) (18002/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.3712) | Acc: (87.00%) (19104/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.3716) | Acc: (87.00%) (20214/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.3720) | Acc: (87.00%) (21323/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.3718) | Acc: (87.00%) (22450/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.3706) | Acc: (87.00%) (23588/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.3702) | Acc: (87.00%) (24717/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.3700) | Acc: (87.00%) (25841/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.3691) | Acc: (87.00%) (26975/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.3682) | Acc: (87.00%) (28104/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.3677) | Acc: (87.00%) (29219/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.3677) | Acc: (87.00%) (30344/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.3665) | Acc: (87.00%) (31484/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.3661) | Acc: (87.00%) (32612/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.3660) | Acc: (87.00%) (33735/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.3658) | Acc: (87.00%) (34868/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.3657) | Acc: (87.00%) (35995/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.3651) | Acc: (87.00%) (37129/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.3653) | Acc: (87.00%) (38244/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.3654) | Acc: (87.00%) (39359/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.3660) | Acc: (87.00%) (40465/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.3673) | Acc: (87.00%) (41583/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.3670) | Acc: (87.00%) (42711/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.3669) | Acc: (87.00%) (43793/50000)
# TEST : Loss: (0.4234) | Acc: (85.00%) (8595/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1191, -0.1083, -0.0725],
          [-0.0133, -0.0461,  0.0585],
          [-0.0057, -0.1266, -0.2340]],

         [[ 0.0108, -0.0466,  0.0194],
          [-0.2001, -0.0413,  0.0342],
          [ 0.0277,  0.0954, -0.0407]],

         [[-0.0623,  0.0971, -0.2245],
          [ 0.2124,  0.3218,  0.1180],
          [-0.0583,  0.2065,  0.1311]]],


        [[[ 0.2419, -0.1769,  0.1011],
          [ 0.1543, -0.0398, -0.0533],
          [-0.2279, -0.0596, -0.1600]],

         [[ 0.1105, -0.1691,  0.0719],
          [-0.0634,  0.2796, -0.1443],
          [ 0.1118,  0.0512,  0.1657]],

         [[-0.1353, -0.1548, -0.0763],
          [-0.1303,  0.1353, -0.0245],
          [-0.0820,  0.1281,  0.1644]]],


        [[[-0.1275, -0.0535, -0.0923],
          [-0.0685, -0.0938, -0.0636],
          [-0.0882, -0.1304, -0.0666]],

         [[ 0.0636,  0.1890,  0.0609],
          [-0.1209, -0.1084, -0.0032],
          [-0.2087,  0.0184, -0.0432]],

         [[-0.1147,  0.0865,  0.2067],
          [-0.0152, -0.0965,  0.1794],
          [-0.1616,  0.0587,  0.0185]]],


        ...,


        [[[ 0.0516,  0.0170, -0.0983],
          [ 0.0822,  0.0636, -0.0182],
          [-0.2473, -0.0005,  0.0472]],

         [[-0.1278, -0.2151,  0.0739],
          [ 0.1512, -0.0131, -0.1412],
          [ 0.0751, -0.1497,  0.0419]],

         [[ 0.0135,  0.0418,  0.0923],
          [ 0.3456,  0.2716,  0.0277],
          [ 0.2372,  0.2115,  0.1150]]],


        [[[ 0.2038,  0.0960,  0.0291],
          [ 0.0674, -0.0072, -0.0704],
          [-0.0648,  0.1523, -0.0858]],

         [[-0.2347, -0.3531, -0.0800],
          [-0.0020, -0.2517, -0.2378],
          [ 0.0827,  0.0359, -0.0731]],

         [[ 0.0960, -0.1030, -0.0522],
          [ 0.0322,  0.0232,  0.0852],
          [-0.0880,  0.0154,  0.0977]]],


        [[[-0.0764, -0.0514, -0.1248],
          [-0.1784, -0.3375, -0.2465],
          [ 0.1863, -0.0927, -0.1406]],

         [[ 0.1168, -0.1418,  0.0260],
          [ 0.0228, -0.1361,  0.0907],
          [ 0.2235,  0.2481, -0.0762]],

         [[ 0.0699, -0.1216,  0.1649],
          [ 0.1498,  0.0197,  0.0632],
          [-0.1284, -0.0573, -0.0027]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0082, -0.0029, -0.0044],
          [-0.0125, -0.0078, -0.0072],
          [-0.0132, -0.0101, -0.0081]],

         [[-0.0078, -0.0015, -0.0019],
          [-0.0128, -0.0072, -0.0055],
          [-0.0140, -0.0096, -0.0069]],

         [[-0.0065, -0.0009, -0.0019],
          [-0.0122, -0.0067, -0.0049],
          [-0.0148, -0.0100, -0.0065]]],


        [[[ 0.0426,  0.0757,  0.1031],
          [ 0.0416,  0.0677,  0.0819],
          [ 0.0352,  0.0741,  0.0850]],

         [[ 0.0103,  0.0388,  0.0725],
          [ 0.0133,  0.0336,  0.0554],
          [ 0.0131,  0.0486,  0.0653]],

         [[-0.0018,  0.0128,  0.0416],
          [-0.0018,  0.0033,  0.0219],
          [-0.0181,  0.0106,  0.0371]]],


        [[[ 0.0038,  0.0045,  0.0066],
          [ 0.0026,  0.0028,  0.0044],
          [ 0.0020,  0.0017,  0.0013]],

         [[ 0.0041,  0.0046,  0.0071],
          [ 0.0028,  0.0033,  0.0054],
          [ 0.0025,  0.0028,  0.0027]],

         [[ 0.0077,  0.0081,  0.0103],
          [ 0.0061,  0.0068,  0.0086],
          [ 0.0056,  0.0060,  0.0061]]],


        ...,


        [[[ 0.0247,  0.0230,  0.0227],
          [ 0.0184,  0.0188,  0.0179],
          [ 0.0144,  0.0157,  0.0130]],

         [[ 0.0255,  0.0242,  0.0237],
          [ 0.0160,  0.0165,  0.0161],
          [ 0.0092,  0.0104,  0.0085]],

         [[ 0.0219,  0.0200,  0.0191],
          [ 0.0087,  0.0090,  0.0093],
          [-0.0014,  0.0002,  0.0002]]],


        [[[-0.0029, -0.0058, -0.0062],
          [-0.0064, -0.0052, -0.0025],
          [-0.0102, -0.0074, -0.0043]],

         [[ 0.0009, -0.0032, -0.0039],
          [-0.0040, -0.0034, -0.0010],
          [-0.0088, -0.0060, -0.0032]],

         [[-0.0028, -0.0051, -0.0048],
          [-0.0046, -0.0043, -0.0033],
          [-0.0087, -0.0076, -0.0065]]],


        [[[ 0.0170,  0.0044,  0.0006],
          [ 0.0079,  0.0023, -0.0023],
          [ 0.0013, -0.0013, -0.0052]],

         [[ 0.0157,  0.0030, -0.0005],
          [ 0.0055, -0.0004, -0.0037],
          [-0.0005, -0.0040, -0.0073]],

         [[ 0.0178,  0.0053,  0.0006],
          [ 0.0083,  0.0020, -0.0020],
          [ 0.0036,  0.0001, -0.0036]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1942]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 24 | Batch_idx: 0 |  Loss: (0.2947) | Acc: (88.00%) (113/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.3474) | Acc: (88.00%) (1250/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.3276) | Acc: (88.00%) (2384/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.3372) | Acc: (88.00%) (3504/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.3239) | Acc: (88.00%) (4650/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.3268) | Acc: (88.00%) (5773/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.3378) | Acc: (88.00%) (6879/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.3375) | Acc: (88.00%) (8025/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.3370) | Acc: (88.00%) (9156/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.3363) | Acc: (88.00%) (10284/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.3366) | Acc: (88.00%) (11413/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.3347) | Acc: (88.00%) (12552/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.3350) | Acc: (88.00%) (13691/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.3344) | Acc: (88.00%) (14829/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.3393) | Acc: (88.00%) (15938/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.3380) | Acc: (88.00%) (17083/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.3390) | Acc: (88.00%) (18204/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.3401) | Acc: (88.00%) (19335/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.3404) | Acc: (88.00%) (20470/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.3393) | Acc: (88.00%) (21621/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.3407) | Acc: (88.00%) (22737/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.3424) | Acc: (88.00%) (23851/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.3431) | Acc: (88.00%) (24971/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.3430) | Acc: (88.00%) (26100/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.3439) | Acc: (88.00%) (27208/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.3438) | Acc: (88.00%) (28331/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.3434) | Acc: (88.00%) (29455/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.3427) | Acc: (88.00%) (30595/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.3430) | Acc: (88.00%) (31716/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.3421) | Acc: (88.00%) (32852/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.3420) | Acc: (88.00%) (33997/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.3427) | Acc: (88.00%) (35129/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.3431) | Acc: (88.00%) (36261/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.3441) | Acc: (88.00%) (37383/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.3454) | Acc: (88.00%) (38501/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.3455) | Acc: (88.00%) (39630/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.3441) | Acc: (88.00%) (40784/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.3439) | Acc: (88.00%) (41918/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.3445) | Acc: (88.00%) (43039/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.3447) | Acc: (88.00%) (44121/50000)
# TEST : Loss: (0.3963) | Acc: (86.00%) (8663/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1276, -0.1120, -0.0710],
          [-0.0174, -0.0451,  0.0598],
          [-0.0009, -0.1189, -0.2278]],

         [[ 0.0006, -0.0519,  0.0157],
          [-0.2056, -0.0408,  0.0332],
          [ 0.0302,  0.1024, -0.0357]],

         [[-0.0731,  0.0926, -0.2266],
          [ 0.2082,  0.3249,  0.1191],
          [-0.0517,  0.2176,  0.1385]]],


        [[[ 0.2498, -0.1683,  0.1069],
          [ 0.1540, -0.0365, -0.0529],
          [-0.2268, -0.0697, -0.1597]],

         [[ 0.1091, -0.1691,  0.0684],
          [-0.0678,  0.2843, -0.1447],
          [ 0.1098,  0.0441,  0.1671]],

         [[-0.1366, -0.1548, -0.0747],
          [-0.1381,  0.1396, -0.0195],
          [-0.0822,  0.1231,  0.1712]]],


        [[[-0.1412, -0.0725, -0.1050],
          [-0.0811, -0.1054, -0.0686],
          [-0.0821, -0.1215, -0.0615]],

         [[ 0.0509,  0.1743,  0.0529],
          [-0.1264, -0.1121, -0.0036],
          [-0.2010,  0.0270, -0.0358]],

         [[-0.1189,  0.0814,  0.2057],
          [-0.0165, -0.0942,  0.1836],
          [-0.1545,  0.0685,  0.0289]]],


        ...,


        [[[ 0.0577,  0.0264, -0.0875],
          [ 0.0936,  0.0773, -0.0024],
          [-0.2348,  0.0131,  0.0659]],

         [[-0.1282, -0.2146,  0.0742],
          [ 0.1579, -0.0074, -0.1344],
          [ 0.0850, -0.1399,  0.0543]],

         [[ 0.0058,  0.0377,  0.0903],
          [ 0.3465,  0.2731,  0.0310],
          [ 0.2467,  0.2193,  0.1249]]],


        [[[ 0.2143,  0.0990,  0.0234],
          [ 0.0730, -0.0094, -0.0769],
          [-0.0682,  0.1443, -0.0937]],

         [[-0.2150, -0.3433, -0.0898],
          [ 0.0067, -0.2550, -0.2493],
          [ 0.0775,  0.0277, -0.0813]],

         [[ 0.1136, -0.0987, -0.0574],
          [ 0.0418,  0.0225,  0.0829],
          [-0.0927,  0.0106,  0.0928]]],


        [[[-0.0724, -0.0684, -0.1324],
          [-0.1759, -0.3478, -0.2446],
          [ 0.1823, -0.1045, -0.1437]],

         [[ 0.1263, -0.1484,  0.0228],
          [ 0.0303, -0.1394,  0.0914],
          [ 0.2215,  0.2379, -0.0798]],

         [[ 0.0776, -0.1259,  0.1636],
          [ 0.1588,  0.0198,  0.0665],
          [-0.1235, -0.0605, -0.0027]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0132,  0.0188,  0.0200],
          [ 0.0134,  0.0174,  0.0189],
          [ 0.0158,  0.0188,  0.0145]],

         [[ 0.0156,  0.0214,  0.0218],
          [ 0.0144,  0.0187,  0.0201],
          [ 0.0153,  0.0184,  0.0150]],

         [[ 0.0144,  0.0194,  0.0182],
          [ 0.0147,  0.0178,  0.0174],
          [ 0.0159,  0.0183,  0.0133]]],


        [[[ 0.1139,  0.1068,  0.1096],
          [ 0.0635,  0.0911,  0.1174],
          [ 0.1020,  0.1285,  0.1217]],

         [[ 0.1248,  0.1152,  0.1009],
          [ 0.0678,  0.0895,  0.1024],
          [ 0.1078,  0.1270,  0.1063]],

         [[ 0.1248,  0.1038,  0.0645],
          [ 0.0709,  0.0873,  0.0844],
          [ 0.0976,  0.1176,  0.0955]]],


        [[[-0.0064, -0.0052, -0.0061],
          [-0.0017, -0.0009, -0.0029],
          [ 0.0001,  0.0010, -0.0005]],

         [[-0.0072, -0.0058, -0.0064],
          [-0.0033, -0.0022, -0.0038],
          [-0.0017, -0.0006, -0.0017]],

         [[-0.0078, -0.0066, -0.0074],
          [-0.0041, -0.0034, -0.0054],
          [-0.0021, -0.0017, -0.0031]]],


        ...,


        [[[-0.0019,  0.0010, -0.0011],
          [ 0.0039,  0.0030, -0.0027],
          [ 0.0016, -0.0023, -0.0070]],

         [[ 0.0015,  0.0043,  0.0011],
          [ 0.0054,  0.0044, -0.0018],
          [ 0.0010, -0.0031, -0.0079]],

         [[ 0.0001,  0.0023, -0.0001],
          [ 0.0040,  0.0025, -0.0038],
          [ 0.0006, -0.0040, -0.0094]]],


        [[[ 0.0099,  0.0081,  0.0078],
          [ 0.0151,  0.0149,  0.0155],
          [ 0.0213,  0.0204,  0.0194]],

         [[ 0.0038,  0.0004, -0.0011],
          [ 0.0092,  0.0067,  0.0054],
          [ 0.0146,  0.0116,  0.0089]],

         [[ 0.0007, -0.0018, -0.0027],
          [ 0.0067,  0.0045,  0.0026],
          [ 0.0112,  0.0084,  0.0052]]],


        [[[ 0.0020, -0.0057, -0.0089],
          [ 0.0059,  0.0024, -0.0007],
          [ 0.0100,  0.0063,  0.0019]],

         [[-0.0000, -0.0083, -0.0124],
          [ 0.0032, -0.0013, -0.0053],
          [ 0.0075,  0.0028, -0.0019]],

         [[-0.0067, -0.0170, -0.0235],
          [-0.0027, -0.0094, -0.0166],
          [ 0.0011, -0.0038, -0.0106]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1935]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 25 | Batch_idx: 0 |  Loss: (0.2972) | Acc: (86.00%) (111/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.3557) | Acc: (87.00%) (1233/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.4272) | Acc: (85.00%) (2291/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.4201) | Acc: (85.00%) (3381/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.4365) | Acc: (84.00%) (4441/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.4399) | Acc: (84.00%) (5516/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.4399) | Acc: (84.00%) (6599/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.4253) | Acc: (85.00%) (7725/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.4224) | Acc: (85.00%) (8820/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.4184) | Acc: (85.00%) (9945/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.4147) | Acc: (85.00%) (11064/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.4108) | Acc: (85.00%) (12172/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.4078) | Acc: (85.00%) (13283/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.4032) | Acc: (85.00%) (14411/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.4017) | Acc: (86.00%) (15530/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.3997) | Acc: (86.00%) (16647/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.3950) | Acc: (86.00%) (17788/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.3924) | Acc: (86.00%) (18918/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.3896) | Acc: (86.00%) (20052/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.3885) | Acc: (86.00%) (21179/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.3860) | Acc: (86.00%) (22323/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.3846) | Acc: (86.00%) (23446/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.3827) | Acc: (86.00%) (24571/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.3819) | Acc: (86.00%) (25690/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.3810) | Acc: (86.00%) (26806/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.3779) | Acc: (87.00%) (27954/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.3760) | Acc: (87.00%) (29090/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.3732) | Acc: (87.00%) (30243/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.3714) | Acc: (87.00%) (31380/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.3703) | Acc: (87.00%) (32504/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.3687) | Acc: (87.00%) (33645/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.3665) | Acc: (87.00%) (34798/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.3639) | Acc: (87.00%) (35955/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.3632) | Acc: (87.00%) (37085/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.3629) | Acc: (87.00%) (38224/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.3622) | Acc: (87.00%) (39346/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.3612) | Acc: (87.00%) (40488/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.3609) | Acc: (87.00%) (41617/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.3599) | Acc: (87.00%) (42760/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.3591) | Acc: (87.00%) (43869/50000)
# TEST : Loss: (0.3784) | Acc: (87.00%) (8737/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1287, -0.1132, -0.0729],
          [-0.0187, -0.0464,  0.0575],
          [-0.0033, -0.1208, -0.2288]],

         [[-0.0017, -0.0538,  0.0134],
          [-0.2067, -0.0426,  0.0308],
          [ 0.0274,  0.0994, -0.0377]],

         [[-0.0747,  0.0906, -0.2269],
          [ 0.2057,  0.3219,  0.1171],
          [-0.0541,  0.2141,  0.1361]]],


        [[[ 0.2474, -0.1699,  0.1043],
          [ 0.1522, -0.0383, -0.0568],
          [-0.2309, -0.0746, -0.1648]],

         [[ 0.1065, -0.1708,  0.0660],
          [-0.0697,  0.2821, -0.1483],
          [ 0.1050,  0.0386,  0.1613]],

         [[-0.1409, -0.1581, -0.0776],
          [-0.1421,  0.1356, -0.0242],
          [-0.0885,  0.1163,  0.1642]]],


        [[[-0.1371, -0.0681, -0.0996],
          [-0.0798, -0.1011, -0.0630],
          [-0.0781, -0.1157, -0.0558]],

         [[ 0.0521,  0.1751,  0.0560],
          [-0.1244, -0.1090,  0.0001],
          [-0.1961,  0.0285, -0.0318]],

         [[-0.1153,  0.0835,  0.2077],
          [-0.0153, -0.0910,  0.1856],
          [-0.1502,  0.0702,  0.0326]]],


        ...,


        [[[ 0.0591,  0.0279, -0.0850],
          [ 0.0938,  0.0780, -0.0005],
          [-0.2329,  0.0144,  0.0681]],

         [[-0.1263, -0.2122,  0.0756],
          [ 0.1566, -0.0068, -0.1314],
          [ 0.0849, -0.1371,  0.0574]],

         [[ 0.0064,  0.0384,  0.0917],
          [ 0.3376,  0.2682,  0.0335],
          [ 0.2418,  0.2181,  0.1286]]],


        [[[ 0.2146,  0.0986,  0.0228],
          [ 0.0733, -0.0106, -0.0781],
          [-0.0685,  0.1417, -0.0950]],

         [[-0.2103, -0.3370, -0.0884],
          [ 0.0090, -0.2518, -0.2463],
          [ 0.0774,  0.0266, -0.0810]],

         [[ 0.1155, -0.0963, -0.0566],
          [ 0.0432,  0.0221,  0.0816],
          [-0.0922,  0.0095,  0.0915]]],


        [[[-0.0701, -0.0662, -0.1278],
          [-0.1738, -0.3451, -0.2409],
          [ 0.1840, -0.1013, -0.1395]],

         [[ 0.1269, -0.1472,  0.0245],
          [ 0.0311, -0.1390,  0.0916],
          [ 0.2226,  0.2386, -0.0776]],

         [[ 0.0780, -0.1248,  0.1647],
          [ 0.1590,  0.0201,  0.0675],
          [-0.1214, -0.0585, -0.0008]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2533]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0221]], device='cuda:0')

Epoch: 26 | Batch_idx: 0 |  Loss: (0.2433) | Acc: (92.00%) (119/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.3060) | Acc: (89.00%) (1262/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.2999) | Acc: (89.00%) (2406/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.3162) | Acc: (89.00%) (3535/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.3146) | Acc: (89.00%) (4686/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.3167) | Acc: (89.00%) (5821/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.3144) | Acc: (89.00%) (6977/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.3159) | Acc: (89.00%) (8115/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.3210) | Acc: (89.00%) (9247/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.3158) | Acc: (89.00%) (10401/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.3188) | Acc: (89.00%) (11530/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.3185) | Acc: (89.00%) (12675/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.3170) | Acc: (89.00%) (13820/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.3162) | Acc: (89.00%) (14970/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.3171) | Acc: (89.00%) (16110/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.3168) | Acc: (89.00%) (17251/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.3174) | Acc: (89.00%) (18381/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.3177) | Acc: (89.00%) (19524/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.3160) | Acc: (89.00%) (20684/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.3168) | Acc: (89.00%) (21824/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.3182) | Acc: (89.00%) (22947/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.3185) | Acc: (89.00%) (24085/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.3164) | Acc: (89.00%) (25233/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.3166) | Acc: (89.00%) (26378/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.3177) | Acc: (89.00%) (27507/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.3180) | Acc: (89.00%) (28654/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.3181) | Acc: (89.00%) (29784/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.3177) | Acc: (89.00%) (30936/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.3173) | Acc: (89.00%) (32089/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.3155) | Acc: (89.00%) (33255/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.3147) | Acc: (89.00%) (34416/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.3139) | Acc: (89.00%) (35588/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.3142) | Acc: (89.00%) (36732/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.3142) | Acc: (89.00%) (37876/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.3155) | Acc: (89.00%) (38994/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.3149) | Acc: (89.00%) (40146/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.3146) | Acc: (89.00%) (41295/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.3151) | Acc: (89.00%) (42422/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.3152) | Acc: (89.00%) (43561/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.3154) | Acc: (89.00%) (44666/50000)
# TEST : Loss: (0.3664) | Acc: (87.00%) (8785/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1281, -0.1126, -0.0725],
          [-0.0186, -0.0462,  0.0572],
          [-0.0033, -0.1202, -0.2277]],

         [[-0.0017, -0.0535,  0.0133],
          [-0.2057, -0.0424,  0.0307],
          [ 0.0272,  0.0989, -0.0375]],

         [[-0.0743,  0.0901, -0.2258],
          [ 0.2047,  0.3203,  0.1165],
          [-0.0539,  0.2130,  0.1354]]],


        [[[ 0.2472, -0.1697,  0.1042],
          [ 0.1520, -0.0383, -0.0567],
          [-0.2307, -0.0745, -0.1646]],

         [[ 0.1064, -0.1706,  0.0659],
          [-0.0696,  0.2818, -0.1481],
          [ 0.1049,  0.0386,  0.1611]],

         [[-0.1407, -0.1579, -0.0775],
          [-0.1419,  0.1354, -0.0242],
          [-0.0883,  0.1161,  0.1640]]],


        [[[-0.1348, -0.0671, -0.0984],
          [-0.0773, -0.0988, -0.0620],
          [-0.0753, -0.1128, -0.0550]],

         [[ 0.0514,  0.1729,  0.0554],
          [-0.1217, -0.1071,  0.0001],
          [-0.1914,  0.0280, -0.0314]],

         [[-0.1137,  0.0825,  0.2055],
          [-0.0150, -0.0897,  0.1834],
          [-0.1475,  0.0691,  0.0322]]],


        ...,


        [[[ 0.0588,  0.0277, -0.0844],
          [ 0.0932,  0.0775, -0.0005],
          [-0.2314,  0.0143,  0.0676]],

         [[-0.1253, -0.2105,  0.0750],
          [ 0.1551, -0.0067, -0.1302],
          [ 0.0841, -0.1359,  0.0569]],

         [[ 0.0064,  0.0379,  0.0907],
          [ 0.3300,  0.2623,  0.0330],
          [ 0.2370,  0.2138,  0.1266]]],


        [[[ 0.2133,  0.0979,  0.0227],
          [ 0.0729, -0.0106, -0.0775],
          [-0.0681,  0.1408, -0.0944]],

         [[-0.2081, -0.3314, -0.0870],
          [ 0.0089, -0.2478, -0.2418],
          [ 0.0768,  0.0263, -0.0802]],

         [[ 0.1144, -0.0951, -0.0559],
          [ 0.0428,  0.0218,  0.0805],
          [-0.0915,  0.0095,  0.0906]]],


        [[[-0.0697, -0.0656, -0.1268],
          [-0.1728, -0.3418, -0.2386],
          [ 0.1832, -0.1007, -0.1386]],

         [[ 0.1263, -0.1464,  0.0243],
          [ 0.0309, -0.1383,  0.0911],
          [ 0.2217,  0.2375, -0.0772]],

         [[ 0.0777, -0.1242,  0.1639],
          [ 0.1584,  0.0200,  0.0672],
          [-0.1209, -0.0583, -0.0008]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2291]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0059]], device='cuda:0')

Epoch: 27 | Batch_idx: 0 |  Loss: (0.3344) | Acc: (86.00%) (111/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.3001) | Acc: (89.00%) (1258/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.2961) | Acc: (89.00%) (2409/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.3061) | Acc: (89.00%) (3547/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.3078) | Acc: (89.00%) (4692/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.3077) | Acc: (89.00%) (5844/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.3028) | Acc: (89.00%) (7005/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.3042) | Acc: (89.00%) (8155/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.3019) | Acc: (89.00%) (9307/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.3017) | Acc: (89.00%) (10455/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.2999) | Acc: (89.00%) (11626/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.3017) | Acc: (89.00%) (12766/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.3009) | Acc: (89.00%) (13916/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.3015) | Acc: (89.00%) (15072/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.3045) | Acc: (89.00%) (16200/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.3058) | Acc: (89.00%) (17343/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.3052) | Acc: (89.00%) (18496/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.3076) | Acc: (89.00%) (19632/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.3078) | Acc: (89.00%) (20779/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.3072) | Acc: (89.00%) (21929/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.3077) | Acc: (89.00%) (23074/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.3081) | Acc: (89.00%) (24229/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.3083) | Acc: (89.00%) (25374/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.3080) | Acc: (89.00%) (26520/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.3072) | Acc: (89.00%) (27686/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.3076) | Acc: (89.00%) (28829/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.3085) | Acc: (89.00%) (29976/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.3075) | Acc: (89.00%) (31141/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.3076) | Acc: (89.00%) (32291/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.3075) | Acc: (89.00%) (33433/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.3072) | Acc: (89.00%) (34579/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.3073) | Acc: (89.00%) (35717/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.3078) | Acc: (89.00%) (36870/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.3084) | Acc: (89.00%) (38002/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.3080) | Acc: (89.00%) (39159/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.3087) | Acc: (89.00%) (40289/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.3091) | Acc: (89.00%) (41431/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.3087) | Acc: (89.00%) (42581/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.3082) | Acc: (89.00%) (43750/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.3081) | Acc: (89.00%) (44851/50000)
# TEST : Loss: (0.3629) | Acc: (88.00%) (8805/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1273, -0.1119, -0.0721],
          [-0.0185, -0.0459,  0.0569],
          [-0.0032, -0.1196, -0.2264]],

         [[-0.0017, -0.0532,  0.0132],
          [-0.2045, -0.0422,  0.0305],
          [ 0.0271,  0.0983, -0.0373]],

         [[-0.0738,  0.0895, -0.2243],
          [ 0.2034,  0.3183,  0.1158],
          [-0.0535,  0.2116,  0.1345]]],


        [[[ 0.2468, -0.1695,  0.1040],
          [ 0.1518, -0.0382, -0.0567],
          [-0.2304, -0.0744, -0.1644]],

         [[ 0.1063, -0.1704,  0.0658],
          [-0.0695,  0.2814, -0.1479],
          [ 0.1047,  0.0385,  0.1609]],

         [[-0.1405, -0.1577, -0.0774],
          [-0.1417,  0.1352, -0.0241],
          [-0.0882,  0.1159,  0.1637]]],


        [[[-0.1320, -0.0659, -0.0970],
          [-0.0745, -0.0961, -0.0609],
          [-0.0721, -0.1094, -0.0540]],

         [[ 0.0505,  0.1702,  0.0547],
          [-0.1185, -0.1048,  0.0001],
          [-0.1860,  0.0273, -0.0309]],

         [[-0.1119,  0.0813,  0.2029],
          [-0.0147, -0.0880,  0.1807],
          [-0.1443,  0.0678,  0.0317]]],


        ...,


        [[[ 0.0583,  0.0275, -0.0838],
          [ 0.0924,  0.0769, -0.0005],
          [-0.2295,  0.0142,  0.0671]],

         [[-0.1241, -0.2085,  0.0743],
          [ 0.1534, -0.0066, -0.1289],
          [ 0.0832, -0.1344,  0.0564]],

         [[ 0.0063,  0.0374,  0.0896],
          [ 0.3210,  0.2552,  0.0323],
          [ 0.2313,  0.2087,  0.1243]]],


        [[[ 0.2117,  0.0971,  0.0225],
          [ 0.0723, -0.0105, -0.0768],
          [-0.0676,  0.1397, -0.0936]],

         [[-0.2056, -0.3247, -0.0853],
          [ 0.0088, -0.2430, -0.2365],
          [ 0.0761,  0.0260, -0.0792]],

         [[ 0.1131, -0.0937, -0.0551],
          [ 0.0423,  0.0215,  0.0793],
          [-0.0907,  0.0094,  0.0896]]],


        [[[-0.0692, -0.0649, -0.1255],
          [-0.1715, -0.3378, -0.2359],
          [ 0.1821, -0.0999, -0.1376]],

         [[ 0.1256, -0.1454,  0.0242],
          [ 0.0307, -0.1373,  0.0905],
          [ 0.2206,  0.2361, -0.0767]],

         [[ 0.0773, -0.1235,  0.1630],
          [ 0.1575,  0.0199,  0.0668],
          [-0.1203, -0.0579, -0.0008]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2473]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0625]], device='cuda:0')

Epoch: 28 | Batch_idx: 0 |  Loss: (0.2096) | Acc: (92.00%) (119/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.2914) | Acc: (90.00%) (1277/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.3061) | Acc: (89.00%) (2410/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.2994) | Acc: (89.00%) (3568/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.2962) | Acc: (90.00%) (4729/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.3025) | Acc: (89.00%) (5871/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.3045) | Acc: (89.00%) (7010/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.3050) | Acc: (89.00%) (8159/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.3097) | Acc: (89.00%) (9296/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.3068) | Acc: (89.00%) (10461/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.3088) | Acc: (89.00%) (11591/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.3130) | Acc: (89.00%) (12722/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.3150) | Acc: (89.00%) (13864/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.3147) | Acc: (89.00%) (15012/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.3148) | Acc: (89.00%) (16154/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.3162) | Acc: (89.00%) (17286/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.3166) | Acc: (89.00%) (18417/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.3156) | Acc: (89.00%) (19564/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.3159) | Acc: (89.00%) (20698/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.3161) | Acc: (89.00%) (21843/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.3174) | Acc: (89.00%) (22971/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.3168) | Acc: (89.00%) (24128/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.3163) | Acc: (89.00%) (25272/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.3164) | Acc: (89.00%) (26425/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.3156) | Acc: (89.00%) (27586/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.3166) | Acc: (89.00%) (28727/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.3155) | Acc: (89.00%) (29886/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.3158) | Acc: (89.00%) (31026/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.3153) | Acc: (89.00%) (32182/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.3161) | Acc: (89.00%) (33319/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.3153) | Acc: (89.00%) (34483/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.3150) | Acc: (89.00%) (35624/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.3156) | Acc: (89.00%) (36768/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.3155) | Acc: (89.00%) (37912/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.3154) | Acc: (89.00%) (39065/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.3156) | Acc: (89.00%) (40209/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.3154) | Acc: (89.00%) (41356/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.3151) | Acc: (89.00%) (42510/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.3161) | Acc: (89.00%) (43640/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.3161) | Acc: (89.00%) (44752/50000)
# TEST : Loss: (0.3677) | Acc: (87.00%) (8783/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1263, -0.1110, -0.0715],
          [-0.0184, -0.0456,  0.0565],
          [-0.0032, -0.1187, -0.2248]],

         [[-0.0016, -0.0528,  0.0131],
          [-0.2031, -0.0419,  0.0303],
          [ 0.0269,  0.0977, -0.0371]],

         [[-0.0733,  0.0888, -0.2226],
          [ 0.2019,  0.3159,  0.1149],
          [-0.0531,  0.2100,  0.1335]]],


        [[[ 0.2464, -0.1692,  0.1039],
          [ 0.1516, -0.0382, -0.0566],
          [-0.2300, -0.0743, -0.1641]],

         [[ 0.1061, -0.1701,  0.0657],
          [-0.0694,  0.2809, -0.1477],
          [ 0.1045,  0.0385,  0.1606]],

         [[-0.1403, -0.1574, -0.0773],
          [-0.1415,  0.1349, -0.0241],
          [-0.0881,  0.1157,  0.1634]]],


        [[[-0.1287, -0.0645, -0.0953],
          [-0.0711, -0.0929, -0.0596],
          [-0.0684, -0.1054, -0.0527]],

         [[ 0.0494,  0.1669,  0.0538],
          [-0.1147, -0.1020,  0.0001],
          [-0.1795,  0.0266, -0.0303]],

         [[-0.1097,  0.0798,  0.1997],
          [-0.0144, -0.0861,  0.1775],
          [-0.1405,  0.0662,  0.0311]]],


        ...,


        [[[ 0.0577,  0.0272, -0.0830],
          [ 0.0915,  0.0761, -0.0005],
          [-0.2273,  0.0141,  0.0664]],

         [[-0.1226, -0.2061,  0.0735],
          [ 0.1513, -0.0065, -0.1272],
          [ 0.0821, -0.1327,  0.0556]],

         [[ 0.0061,  0.0367,  0.0882],
          [ 0.3104,  0.2470,  0.0316],
          [ 0.2245,  0.2026,  0.1216]]],


        [[[ 0.2097,  0.0961,  0.0222],
          [ 0.0716, -0.0104, -0.0760],
          [-0.0670,  0.1384, -0.0927]],

         [[-0.2025, -0.3168, -0.0832],
          [ 0.0086, -0.2372, -0.2301],
          [ 0.0752,  0.0257, -0.0780]],

         [[ 0.1115, -0.0920, -0.0541],
          [ 0.0417,  0.0211,  0.0778],
          [-0.0896,  0.0092,  0.0883]]],


        [[[-0.0686, -0.0641, -0.1240],
          [-0.1700, -0.3331, -0.2326],
          [ 0.1808, -0.0990, -0.1362]],

         [[ 0.1247, -0.1442,  0.0240],
          [ 0.0305, -0.1362,  0.0898],
          [ 0.2193,  0.2344, -0.0762]],

         [[ 0.0768, -0.1226,  0.1619],
          [ 0.1565,  0.0198,  0.0663],
          [-0.1196, -0.0576, -0.0008]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2583]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0214]], device='cuda:0')

Epoch: 29 | Batch_idx: 0 |  Loss: (0.2829) | Acc: (91.00%) (117/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.2837) | Acc: (90.00%) (1270/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.3054) | Acc: (89.00%) (2407/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.3033) | Acc: (90.00%) (3580/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.3065) | Acc: (90.00%) (4726/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.3130) | Acc: (89.00%) (5866/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.3137) | Acc: (89.00%) (7025/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.3152) | Acc: (89.00%) (8175/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.3171) | Acc: (89.00%) (9312/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.3155) | Acc: (89.00%) (10466/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.3166) | Acc: (89.00%) (11607/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.3197) | Acc: (89.00%) (12741/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.3167) | Acc: (89.00%) (13902/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.3159) | Acc: (89.00%) (15057/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.3164) | Acc: (89.00%) (16196/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.3148) | Acc: (89.00%) (17366/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.3177) | Acc: (89.00%) (18493/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.3189) | Acc: (89.00%) (19623/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.3195) | Acc: (89.00%) (20762/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.3226) | Acc: (89.00%) (21880/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.3225) | Acc: (89.00%) (23037/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.3231) | Acc: (89.00%) (24184/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.3244) | Acc: (89.00%) (25324/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.3235) | Acc: (89.00%) (26483/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.3237) | Acc: (89.00%) (27617/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.3242) | Acc: (89.00%) (28755/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.3242) | Acc: (89.00%) (29910/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.3243) | Acc: (89.00%) (31065/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.3255) | Acc: (89.00%) (32187/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.3262) | Acc: (89.00%) (33321/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.3259) | Acc: (89.00%) (34474/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.3258) | Acc: (89.00%) (35616/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.3257) | Acc: (89.00%) (36762/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.3265) | Acc: (89.00%) (37899/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.3271) | Acc: (89.00%) (39024/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.3273) | Acc: (89.00%) (40175/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.3275) | Acc: (89.00%) (41319/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.3275) | Acc: (89.00%) (42465/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.3275) | Acc: (89.00%) (43611/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.3283) | Acc: (89.00%) (44708/50000)
# TEST : Loss: (0.3822) | Acc: (87.00%) (8750/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1251, -0.1100, -0.0708],
          [-0.0182, -0.0452,  0.0560],
          [-0.0032, -0.1177, -0.2229]],

         [[-0.0016, -0.0524,  0.0130],
          [-0.2014, -0.0415,  0.0300],
          [ 0.0267,  0.0968, -0.0368]],

         [[-0.0726,  0.0880, -0.2205],
          [ 0.2000,  0.3130,  0.1138],
          [-0.0526,  0.2081,  0.1323]]],


        [[[ 0.2460, -0.1689,  0.1037],
          [ 0.1513, -0.0381, -0.0565],
          [-0.2295, -0.0741, -0.1638]],

         [[ 0.1059, -0.1698,  0.0656],
          [-0.0693,  0.2803, -0.1474],
          [ 0.1043,  0.0384,  0.1603]],

         [[-0.1400, -0.1570, -0.0771],
          [-0.1411,  0.1346, -0.0240],
          [-0.0879,  0.1155,  0.1631]]],


        [[[-0.1249, -0.0628, -0.0934],
          [-0.0672, -0.0892, -0.0581],
          [-0.0642, -0.1007, -0.0513]],

         [[ 0.0481,  0.1631,  0.0528],
          [-0.1103, -0.0988,  0.0001],
          [-0.1720,  0.0257, -0.0296]],

         [[-0.1071,  0.0781,  0.1960],
          [-0.0139, -0.0838,  0.1736],
          [-0.1359,  0.0643,  0.0304]]],


        ...,


        [[[ 0.0571,  0.0269, -0.0821],
          [ 0.0904,  0.0752, -0.0005],
          [-0.2246,  0.0139,  0.0657]],

         [[-0.1208, -0.2032,  0.0725],
          [ 0.1488, -0.0064, -0.1252],
          [ 0.0808, -0.1306,  0.0548]],

         [[ 0.0060,  0.0360,  0.0865],
          [ 0.2980,  0.2372,  0.0307],
          [ 0.2166,  0.1955,  0.1183]]],


        [[[ 0.2074,  0.0949,  0.0220],
          [ 0.0708, -0.0102, -0.0750],
          [-0.0663,  0.1368, -0.0916]],

         [[-0.1989, -0.3074, -0.0808],
          [ 0.0085, -0.2304, -0.2227],
          [ 0.0742,  0.0252, -0.0765]],

         [[ 0.1096, -0.0899, -0.0529],
          [ 0.0410,  0.0206,  0.0760],
          [-0.0884,  0.0091,  0.0868]]],


        [[[-0.0679, -0.0631, -0.1223],
          [-0.1681, -0.3273, -0.2287],
          [ 0.1793, -0.0979, -0.1347]],

         [[ 0.1237, -0.1428,  0.0238],
          [ 0.0303, -0.1348,  0.0889],
          [ 0.2177,  0.2324, -0.0755]],

         [[ 0.0761, -0.1216,  0.1605],
          [ 0.1552,  0.0196,  0.0658],
          [-0.1187, -0.0571, -0.0008]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2615]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0011]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 30 | Batch_idx: 0 |  Loss: (0.3102) | Acc: (88.00%) (113/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.4831) | Acc: (83.00%) (1170/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.5838) | Acc: (79.00%) (2141/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.6334) | Acc: (78.00%) (3119/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.6485) | Acc: (78.00%) (4101/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.6348) | Acc: (78.00%) (5120/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.6360) | Acc: (78.00%) (6128/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.6385) | Acc: (78.00%) (7124/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.6368) | Acc: (78.00%) (8139/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.6259) | Acc: (78.00%) (9194/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.6242) | Acc: (79.00%) (10218/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.6193) | Acc: (79.00%) (11245/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.6085) | Acc: (79.00%) (12312/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.6004) | Acc: (79.00%) (13369/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.5985) | Acc: (79.00%) (14394/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.5963) | Acc: (79.00%) (15427/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.5924) | Acc: (79.00%) (16483/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.5869) | Acc: (80.00%) (17534/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.5830) | Acc: (80.00%) (18592/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.5755) | Acc: (80.00%) (19676/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.5694) | Acc: (80.00%) (20771/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.5650) | Acc: (80.00%) (21853/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.5595) | Acc: (81.00%) (22938/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.5559) | Acc: (81.00%) (23999/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.5524) | Acc: (81.00%) (25079/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.5485) | Acc: (81.00%) (26142/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.5473) | Acc: (81.00%) (27200/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.5459) | Acc: (81.00%) (28259/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.5427) | Acc: (81.00%) (29343/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.5401) | Acc: (81.00%) (30428/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.5369) | Acc: (81.00%) (31516/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.5360) | Acc: (81.00%) (32585/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.5338) | Acc: (81.00%) (33663/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.5306) | Acc: (82.00%) (34752/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.5293) | Acc: (82.00%) (35813/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.5269) | Acc: (82.00%) (36902/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.5240) | Acc: (82.00%) (38001/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.5217) | Acc: (82.00%) (39103/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.5187) | Acc: (82.00%) (40207/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.5163) | Acc: (82.00%) (41263/50000)
# TEST : Loss: (0.5248) | Acc: (83.00%) (8300/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1268, -0.1046, -0.0631],
          [-0.0266, -0.0497,  0.0549],
          [-0.0133, -0.1269, -0.2266]],

         [[-0.0123, -0.0525,  0.0133],
          [-0.2086, -0.0415,  0.0318],
          [ 0.0164,  0.0905, -0.0384]],

         [[-0.0653,  0.1046, -0.2092],
          [ 0.2130,  0.3357,  0.1308],
          [-0.0462,  0.2198,  0.1401]]],


        [[[ 0.2464, -0.1687,  0.1088],
          [ 0.1410, -0.0374, -0.0705],
          [-0.2434, -0.0945, -0.1654]],

         [[ 0.1004, -0.1828,  0.0585],
          [-0.0643,  0.2956, -0.1523],
          [ 0.1148,  0.0466,  0.1802]],

         [[-0.1289, -0.1550, -0.0656],
          [-0.1368,  0.1462, -0.0229],
          [-0.0816,  0.1176,  0.1773]]],


        [[[-0.1102, -0.0639, -0.1026],
          [-0.0744, -0.1089, -0.0726],
          [-0.0727, -0.1153, -0.0599]],

         [[ 0.0601,  0.1623,  0.0464],
          [-0.1206, -0.1156, -0.0119],
          [-0.1849,  0.0042, -0.0356]],

         [[-0.1009,  0.0734,  0.1826],
          [-0.0355, -0.1052,  0.1534],
          [-0.1649,  0.0335,  0.0141]]],


        ...,


        [[[ 0.0579,  0.0133, -0.1007],
          [ 0.0861,  0.0651, -0.0153],
          [-0.2235,  0.0082,  0.0555]],

         [[-0.1261, -0.2225,  0.0494],
          [ 0.1450, -0.0161, -0.1371],
          [ 0.0885, -0.1251,  0.0551]],

         [[ 0.0088,  0.0249,  0.0759],
          [ 0.3102,  0.2505,  0.0438],
          [ 0.2444,  0.2195,  0.1328]]],


        [[[ 0.2202,  0.1172,  0.0502],
          [ 0.0735, -0.0014, -0.0614],
          [-0.0713,  0.1399, -0.0879]],

         [[-0.2183, -0.3185, -0.0736],
          [-0.0041, -0.2311, -0.2241],
          [ 0.0701,  0.0315, -0.0836]],

         [[ 0.0904, -0.1079, -0.0602],
          [ 0.0288,  0.0064,  0.0581],
          [-0.0972, -0.0007,  0.0611]]],


        [[[-0.0679, -0.0960, -0.1510],
          [-0.1842, -0.3631, -0.2643],
          [ 0.1773, -0.0991, -0.1303]],

         [[ 0.1153, -0.1677, -0.0052],
          [ 0.0208, -0.1515,  0.0669],
          [ 0.2175,  0.2295, -0.0751]],

         [[ 0.0577, -0.1504,  0.1245],
          [ 0.1413,  0.0029,  0.0408],
          [-0.1209, -0.0609, -0.0078]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0041, -0.0049, -0.0055],
          [-0.0151, -0.0139, -0.0165],
          [-0.0199, -0.0192, -0.0213]],

         [[-0.0049, -0.0050, -0.0058],
          [-0.0169, -0.0153, -0.0176],
          [-0.0217, -0.0205, -0.0216]],

         [[ 0.0016,  0.0015,  0.0007],
          [-0.0106, -0.0087, -0.0110],
          [-0.0166, -0.0149, -0.0167]]],


        [[[-0.0439, -0.0561, -0.0391],
          [ 0.0238, -0.0184,  0.0045],
          [ 0.0601,  0.0074,  0.0317]],

         [[-0.0622, -0.0738, -0.0632],
          [ 0.0043, -0.0387, -0.0259],
          [ 0.0459, -0.0087,  0.0032]],

         [[-0.0665, -0.0797, -0.0536],
          [-0.0058, -0.0301, -0.0071],
          [ 0.0274, -0.0088,  0.0191]]],


        [[[ 0.0065,  0.0053,  0.0047],
          [ 0.0029,  0.0019,  0.0011],
          [ 0.0003, -0.0001, -0.0010]],

         [[ 0.0064,  0.0054,  0.0054],
          [ 0.0022,  0.0017,  0.0017],
          [-0.0007, -0.0005, -0.0004]],

         [[ 0.0061,  0.0053,  0.0052],
          [ 0.0019,  0.0015,  0.0016],
          [-0.0007, -0.0006, -0.0007]]],


        ...,


        [[[-0.0079, -0.0060, -0.0039],
          [-0.0183, -0.0168, -0.0151],
          [-0.0246, -0.0228, -0.0196]],

         [[ 0.0005,  0.0020,  0.0038],
          [-0.0102, -0.0084, -0.0067],
          [-0.0158, -0.0130, -0.0093]],

         [[ 0.0087,  0.0097,  0.0106],
          [-0.0003,  0.0007,  0.0014],
          [-0.0053, -0.0029, -0.0004]]],


        [[[-0.0009,  0.0022, -0.0005],
          [-0.0013,  0.0052,  0.0073],
          [-0.0010,  0.0052,  0.0102]],

         [[-0.0016,  0.0009, -0.0026],
          [-0.0060, -0.0006, -0.0005],
          [-0.0086, -0.0040, -0.0007]],

         [[-0.0071, -0.0055, -0.0074],
          [-0.0099, -0.0062, -0.0050],
          [-0.0118, -0.0076, -0.0037]]],


        [[[ 0.0016,  0.0035,  0.0006],
          [-0.0047, -0.0001,  0.0016],
          [-0.0032, -0.0039,  0.0011]],

         [[ 0.0080,  0.0108,  0.0107],
          [ 0.0031,  0.0084,  0.0120],
          [ 0.0041,  0.0037,  0.0099]],

         [[ 0.0051,  0.0080,  0.0096],
          [-0.0003,  0.0049,  0.0097],
          [-0.0007,  0.0004,  0.0069]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2617]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 31 | Batch_idx: 0 |  Loss: (0.3288) | Acc: (90.00%) (116/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.4042) | Acc: (86.00%) (1212/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.4107) | Acc: (86.00%) (2317/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.4029) | Acc: (86.00%) (3418/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.3955) | Acc: (86.00%) (4543/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.3790) | Acc: (86.00%) (5675/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.3785) | Acc: (86.00%) (6792/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.3864) | Acc: (86.00%) (7894/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.3875) | Acc: (86.00%) (9003/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.3897) | Acc: (86.00%) (10109/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.3870) | Acc: (86.00%) (11228/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.3904) | Acc: (86.00%) (12316/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.3933) | Acc: (86.00%) (13425/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.3963) | Acc: (86.00%) (14517/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.3973) | Acc: (86.00%) (15622/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.3970) | Acc: (86.00%) (16740/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.3966) | Acc: (86.00%) (17851/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.3966) | Acc: (86.00%) (18970/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.3982) | Acc: (86.00%) (20067/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.3980) | Acc: (86.00%) (21151/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.3979) | Acc: (86.00%) (22261/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.3989) | Acc: (86.00%) (23362/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.3995) | Acc: (86.00%) (24455/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.3980) | Acc: (86.00%) (25578/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.3978) | Acc: (86.00%) (26684/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.3982) | Acc: (86.00%) (27781/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.3983) | Acc: (86.00%) (28886/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.3975) | Acc: (86.00%) (29985/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.3971) | Acc: (86.00%) (31085/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.3966) | Acc: (86.00%) (32199/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.3958) | Acc: (86.00%) (33303/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.3948) | Acc: (86.00%) (34425/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.3946) | Acc: (86.00%) (35544/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.3945) | Acc: (86.00%) (36656/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.3938) | Acc: (86.00%) (37779/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.3945) | Acc: (86.00%) (38889/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.3934) | Acc: (86.00%) (40012/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.3933) | Acc: (86.00%) (41126/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.3932) | Acc: (86.00%) (42241/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.3920) | Acc: (86.00%) (43315/50000)
# TEST : Loss: (0.3888) | Acc: (87.00%) (8705/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1179, -0.0971, -0.0554],
          [-0.0206, -0.0427,  0.0629],
          [-0.0022, -0.1184, -0.2162]],

         [[-0.0069, -0.0459,  0.0211],
          [-0.2021, -0.0314,  0.0436],
          [ 0.0272,  0.1000, -0.0280]],

         [[-0.0593,  0.1105, -0.2054],
          [ 0.2208,  0.3497,  0.1448],
          [-0.0312,  0.2363,  0.1544]]],


        [[[ 0.2637, -0.1456,  0.1300],
          [ 0.1535, -0.0283, -0.0730],
          [-0.2323, -0.1082, -0.1698]],

         [[ 0.0992, -0.1754,  0.0675],
          [-0.0605,  0.3032, -0.1555],
          [ 0.1236,  0.0393,  0.1794]],

         [[-0.1366, -0.1540, -0.0614],
          [-0.1415,  0.1484, -0.0262],
          [-0.0754,  0.1107,  0.1768]]],


        [[[-0.0937, -0.0644, -0.1009],
          [-0.0695, -0.1085, -0.0637],
          [-0.0786, -0.1088, -0.0488]],

         [[ 0.0703,  0.1604,  0.0495],
          [-0.1126, -0.1098,  0.0011],
          [-0.1829,  0.0110, -0.0187]],

         [[-0.0925,  0.0786,  0.1904],
          [-0.0331, -0.0927,  0.1700],
          [-0.1657,  0.0441,  0.0330]]],


        ...,


        [[[ 0.0573,  0.0135, -0.0941],
          [ 0.0805,  0.0584, -0.0194],
          [-0.2223,  0.0021,  0.0446]],

         [[-0.1218, -0.2178,  0.0595],
          [ 0.1450, -0.0189, -0.1388],
          [ 0.0944, -0.1286,  0.0403]],

         [[ 0.0106,  0.0298,  0.0897],
          [ 0.3249,  0.2632,  0.0551],
          [ 0.2799,  0.2289,  0.1232]]],


        [[[ 0.2174,  0.1157,  0.0613],
          [ 0.0762, -0.0080, -0.0501],
          [-0.0643,  0.1404, -0.0729]],

         [[-0.2332, -0.3424, -0.0656],
          [-0.0132, -0.2580, -0.2095],
          [ 0.0686,  0.0223, -0.0752]],

         [[ 0.0673, -0.1314, -0.0526],
          [ 0.0150, -0.0181,  0.0641],
          [-0.1007, -0.0088,  0.0665]]],


        [[[-0.0719, -0.0962, -0.1318],
          [-0.1920, -0.3827, -0.2668],
          [ 0.1682, -0.1084, -0.1310]],

         [[ 0.1235, -0.1512,  0.0197],
          [ 0.0259, -0.1463,  0.0803],
          [ 0.2160,  0.2295, -0.0660]],

         [[ 0.0727, -0.1254,  0.1621],
          [ 0.1566,  0.0204,  0.0707],
          [-0.1126, -0.0480,  0.0167]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0167,  0.0153,  0.0132],
          [ 0.0118,  0.0136,  0.0119],
          [ 0.0139,  0.0152,  0.0147]],

         [[ 0.0170,  0.0157,  0.0131],
          [ 0.0112,  0.0126,  0.0116],
          [ 0.0131,  0.0140,  0.0153]],

         [[ 0.0139,  0.0131,  0.0120],
          [ 0.0092,  0.0109,  0.0109],
          [ 0.0119,  0.0136,  0.0148]]],


        [[[-0.0105, -0.0294, -0.0275],
          [-0.0113, -0.0288, -0.0229],
          [-0.0040, -0.0149,  0.0106]],

         [[-0.0042, -0.0293, -0.0416],
          [-0.0095, -0.0374, -0.0449],
          [-0.0037, -0.0284, -0.0162]],

         [[ 0.0078, -0.0172, -0.0188],
          [ 0.0001, -0.0129, -0.0013],
          [ 0.0089,  0.0041,  0.0360]]],


        [[[ 0.0018,  0.0031,  0.0025],
          [ 0.0015,  0.0024,  0.0013],
          [ 0.0008,  0.0009, -0.0008]],

         [[-0.0002,  0.0013,  0.0013],
          [-0.0004,  0.0010,  0.0003],
          [-0.0016, -0.0010, -0.0020]],

         [[ 0.0015,  0.0027,  0.0031],
          [ 0.0012,  0.0024,  0.0015],
          [-0.0003,  0.0004, -0.0007]]],


        ...,


        [[[ 0.0117,  0.0076,  0.0017],
          [ 0.0105,  0.0063, -0.0025],
          [ 0.0103,  0.0079,  0.0007]],

         [[ 0.0114,  0.0057,  0.0001],
          [ 0.0086,  0.0033, -0.0046],
          [ 0.0080,  0.0048, -0.0013]],

         [[ 0.0062,  0.0017, -0.0034],
          [ 0.0037, -0.0007, -0.0084],
          [ 0.0044,  0.0009, -0.0056]]],


        [[[-0.0071, -0.0069, -0.0070],
          [-0.0105, -0.0100, -0.0112],
          [-0.0102, -0.0097, -0.0122]],

         [[-0.0022, -0.0013, -0.0013],
          [-0.0058, -0.0045, -0.0055],
          [-0.0058, -0.0043, -0.0067]],

         [[ 0.0045,  0.0054,  0.0047],
          [ 0.0009,  0.0023,  0.0011],
          [ 0.0014,  0.0030,  0.0013]]],


        [[[-0.0108, -0.0107, -0.0072],
          [-0.0134, -0.0098, -0.0063],
          [-0.0141, -0.0114, -0.0097]],

         [[-0.0204, -0.0179, -0.0128],
          [-0.0242, -0.0178, -0.0121],
          [-0.0250, -0.0196, -0.0153]],

         [[-0.0197, -0.0175, -0.0131],
          [-0.0248, -0.0185, -0.0134],
          [-0.0262, -0.0198, -0.0153]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2610]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 32 | Batch_idx: 0 |  Loss: (0.3152) | Acc: (90.00%) (116/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.3347) | Acc: (88.00%) (1249/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.3280) | Acc: (88.00%) (2386/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.3426) | Acc: (88.00%) (3504/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.3487) | Acc: (88.00%) (4624/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.3471) | Acc: (88.00%) (5763/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.3409) | Acc: (88.00%) (6910/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.3418) | Acc: (88.00%) (8027/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.3392) | Acc: (88.00%) (9171/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.3394) | Acc: (88.00%) (10308/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.3388) | Acc: (88.00%) (11446/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.3442) | Acc: (88.00%) (12549/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.3453) | Acc: (88.00%) (13668/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.3452) | Acc: (88.00%) (14803/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.3416) | Acc: (88.00%) (15950/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.3412) | Acc: (88.00%) (17086/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.3418) | Acc: (88.00%) (18218/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.3406) | Acc: (88.00%) (19352/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.3409) | Acc: (88.00%) (20481/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.3427) | Acc: (88.00%) (21610/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.3425) | Acc: (88.00%) (22747/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.3416) | Acc: (88.00%) (23887/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.3430) | Acc: (88.00%) (25004/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.3437) | Acc: (88.00%) (26121/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.3439) | Acc: (88.00%) (27260/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.3452) | Acc: (88.00%) (28381/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.3440) | Acc: (88.00%) (29516/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.3453) | Acc: (88.00%) (30629/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.3459) | Acc: (88.00%) (31754/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.3454) | Acc: (88.00%) (32898/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.3457) | Acc: (88.00%) (34018/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.3452) | Acc: (88.00%) (35151/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.3436) | Acc: (88.00%) (36303/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.3446) | Acc: (88.00%) (37408/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.3451) | Acc: (88.00%) (38529/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.3451) | Acc: (88.00%) (39667/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.3465) | Acc: (88.00%) (40770/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.3465) | Acc: (88.00%) (41900/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.3467) | Acc: (88.00%) (43018/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.3474) | Acc: (88.00%) (44100/50000)
# TEST : Loss: (0.4112) | Acc: (86.00%) (8689/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1107, -0.0899, -0.0481],
          [-0.0115, -0.0371,  0.0658],
          [ 0.0010, -0.1154, -0.2123]],

         [[-0.0054, -0.0419,  0.0231],
          [-0.1949, -0.0261,  0.0424],
          [ 0.0288,  0.1022, -0.0284]],

         [[-0.0562,  0.1174, -0.1982],
          [ 0.2294,  0.3598,  0.1496],
          [-0.0259,  0.2446,  0.1596]]],


        [[[ 0.2649, -0.1442,  0.1273],
          [ 0.1574, -0.0216, -0.0734],
          [-0.2224, -0.1076, -0.1693]],

         [[ 0.0873, -0.1868,  0.0580],
          [-0.0613,  0.3115, -0.1542],
          [ 0.1310,  0.0454,  0.1819]],

         [[-0.1487, -0.1649, -0.0699],
          [-0.1441,  0.1510, -0.0296],
          [-0.0668,  0.1122,  0.1742]]],


        [[[-0.0821, -0.0622, -0.1014],
          [-0.0627, -0.1043, -0.0671],
          [-0.0799, -0.1050, -0.0508]],

         [[ 0.0745,  0.1584,  0.0477],
          [-0.1217, -0.1154, -0.0064],
          [-0.2012, -0.0005, -0.0257]],

         [[-0.0942,  0.0755,  0.1871],
          [-0.0504, -0.1000,  0.1597],
          [-0.1872,  0.0326,  0.0248]]],


        ...,


        [[[ 0.0623,  0.0173, -0.0871],
          [ 0.0751,  0.0489, -0.0219],
          [-0.2251, -0.0116,  0.0391]],

         [[-0.1058, -0.2074,  0.0669],
          [ 0.1511, -0.0222, -0.1373],
          [ 0.1028, -0.1361,  0.0384]],

         [[ 0.0320,  0.0428,  0.0994],
          [ 0.3407,  0.2595,  0.0608],
          [ 0.3020,  0.2158,  0.1271]]],


        [[[ 0.2185,  0.1183,  0.0689],
          [ 0.0772, -0.0019, -0.0368],
          [-0.0686,  0.1431, -0.0590]],

         [[-0.2326, -0.3473, -0.0602],
          [-0.0203, -0.2622, -0.1999],
          [ 0.0549,  0.0143, -0.0708]],

         [[ 0.0654, -0.1352, -0.0542],
          [ 0.0122, -0.0223,  0.0608],
          [-0.1084, -0.0150,  0.0630]]],


        [[[-0.0940, -0.1211, -0.1509],
          [-0.2017, -0.3970, -0.2706],
          [ 0.1642, -0.1165, -0.1350]],

         [[ 0.1056, -0.1684,  0.0041],
          [ 0.0172, -0.1546,  0.0792],
          [ 0.2073,  0.2190, -0.0687]],

         [[ 0.0538, -0.1432,  0.1452],
          [ 0.1476,  0.0116,  0.0672],
          [-0.1195, -0.0561,  0.0126]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0049, -0.0099, -0.0098],
          [-0.0061, -0.0105, -0.0137],
          [-0.0052, -0.0114, -0.0153]],

         [[-0.0027, -0.0075, -0.0080],
          [-0.0037, -0.0083, -0.0124],
          [-0.0034, -0.0092, -0.0137]],

         [[ 0.0016, -0.0028, -0.0041],
          [-0.0004, -0.0048, -0.0092],
          [-0.0014, -0.0065, -0.0100]]],


        [[[ 0.0065,  0.0226,  0.0429],
          [ 0.0687,  0.0748,  0.0889],
          [ 0.0954,  0.0967,  0.0580]],

         [[ 0.0204,  0.0369,  0.0603],
          [ 0.0894,  0.0821,  0.1014],
          [ 0.1141,  0.1075,  0.0717]],

         [[ 0.0193,  0.0415,  0.0639],
          [ 0.0869,  0.0832,  0.0892],
          [ 0.0986,  0.1012,  0.0620]]],


        [[[ 0.0016,  0.0013, -0.0012],
          [ 0.0024,  0.0034,  0.0001],
          [ 0.0012,  0.0030, -0.0004]],

         [[ 0.0029,  0.0035,  0.0016],
          [ 0.0024,  0.0042,  0.0023],
          [ 0.0012,  0.0035,  0.0012]],

         [[ 0.0042,  0.0066,  0.0061],
          [ 0.0032,  0.0059,  0.0054],
          [ 0.0020,  0.0046,  0.0034]]],


        ...,


        [[[ 0.0156,  0.0133,  0.0096],
          [ 0.0214,  0.0179,  0.0135],
          [ 0.0163,  0.0133,  0.0072]],

         [[ 0.0083,  0.0056,  0.0022],
          [ 0.0140,  0.0101,  0.0063],
          [ 0.0103,  0.0073,  0.0015]],

         [[-0.0001, -0.0022, -0.0046],
          [ 0.0043,  0.0013, -0.0012],
          [ 0.0025,  0.0008, -0.0036]]],


        [[[-0.0024,  0.0004, -0.0048],
          [-0.0066, -0.0049, -0.0093],
          [-0.0119, -0.0122, -0.0114]],

         [[-0.0019,  0.0014, -0.0008],
          [-0.0057, -0.0029, -0.0031],
          [-0.0099, -0.0081, -0.0041]],

         [[ 0.0019,  0.0043,  0.0031],
          [-0.0003,  0.0021,  0.0033],
          [-0.0023,  0.0000,  0.0049]]],


        [[[ 0.0048, -0.0004, -0.0030],
          [ 0.0034, -0.0026, -0.0029],
          [ 0.0029,  0.0009,  0.0011]],

         [[-0.0041, -0.0094, -0.0097],
          [-0.0039, -0.0105, -0.0086],
          [-0.0031, -0.0057, -0.0039]],

         [[-0.0176, -0.0235, -0.0191],
          [-0.0185, -0.0258, -0.0200],
          [-0.0171, -0.0209, -0.0170]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2603]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 33 | Batch_idx: 0 |  Loss: (0.2594) | Acc: (92.00%) (119/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.3289) | Acc: (89.00%) (1266/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.3105) | Acc: (89.00%) (2410/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.3199) | Acc: (89.00%) (3550/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.3077) | Acc: (89.00%) (4714/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.3098) | Acc: (89.00%) (5844/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.3119) | Acc: (89.00%) (6985/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.3143) | Acc: (89.00%) (8119/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.3148) | Acc: (89.00%) (9267/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.3126) | Acc: (89.00%) (10414/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.3118) | Acc: (89.00%) (11557/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.3122) | Acc: (89.00%) (12700/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.3125) | Acc: (89.00%) (13843/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.3131) | Acc: (89.00%) (14979/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.3133) | Acc: (89.00%) (16124/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.3178) | Acc: (89.00%) (17231/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.3164) | Acc: (89.00%) (18388/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.3166) | Acc: (89.00%) (19521/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.3163) | Acc: (89.00%) (20662/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.3177) | Acc: (89.00%) (21795/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.3179) | Acc: (89.00%) (22938/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.3190) | Acc: (89.00%) (24068/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.3191) | Acc: (89.00%) (25205/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.3187) | Acc: (89.00%) (26342/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.3190) | Acc: (89.00%) (27486/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.3192) | Acc: (89.00%) (28620/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.3188) | Acc: (89.00%) (29768/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.3184) | Acc: (89.00%) (30915/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.3180) | Acc: (89.00%) (32067/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.3177) | Acc: (89.00%) (33211/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.3181) | Acc: (89.00%) (34342/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.3186) | Acc: (89.00%) (35469/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.3195) | Acc: (89.00%) (36590/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.3208) | Acc: (88.00%) (37704/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.3212) | Acc: (88.00%) (38841/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.3220) | Acc: (88.00%) (39963/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.3219) | Acc: (88.00%) (41101/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.3219) | Acc: (88.00%) (42251/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.3215) | Acc: (88.00%) (43401/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.3210) | Acc: (89.00%) (44505/50000)
# TEST : Loss: (0.3706) | Acc: (87.00%) (8773/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1243, -0.1036, -0.0580],
          [-0.0266, -0.0506,  0.0552],
          [-0.0121, -0.1281, -0.2246]],

         [[-0.0165, -0.0521,  0.0177],
          [-0.2079, -0.0353,  0.0371],
          [ 0.0161,  0.0927, -0.0372]],

         [[-0.0694,  0.1055, -0.2057],
          [ 0.2137,  0.3514,  0.1451],
          [-0.0400,  0.2365,  0.1507]]],


        [[[ 0.2654, -0.1364,  0.1406],
          [ 0.1496, -0.0230, -0.0796],
          [-0.2221, -0.1136, -0.1738]],

         [[ 0.0830, -0.1830,  0.0662],
          [-0.0708,  0.3124, -0.1560],
          [ 0.1333,  0.0476,  0.1845]],

         [[-0.1504, -0.1643, -0.0656],
          [-0.1565,  0.1478, -0.0331],
          [-0.0653,  0.1129,  0.1784]]],


        [[[-0.0710, -0.0608, -0.1036],
          [-0.0479, -0.1052, -0.0738],
          [-0.0862, -0.1103, -0.0555]],

         [[ 0.0816,  0.1569,  0.0438],
          [-0.1117, -0.1166, -0.0146],
          [-0.2077, -0.0109, -0.0327]],

         [[-0.0828,  0.0798,  0.1849],
          [-0.0417, -0.0955,  0.1537],
          [-0.1878,  0.0288,  0.0214]]],


        ...,


        [[[ 0.0529,  0.0138, -0.0881],
          [ 0.0671,  0.0496, -0.0195],
          [-0.2240, -0.0056,  0.0450]],

         [[-0.1161, -0.2083,  0.0667],
          [ 0.1422, -0.0157, -0.1291],
          [ 0.1079, -0.1199,  0.0532]],

         [[ 0.0187,  0.0438,  0.1043],
          [ 0.3199,  0.2778,  0.0796],
          [ 0.3045,  0.2373,  0.1446]]],


        [[[ 0.2328,  0.1334,  0.0856],
          [ 0.0889,  0.0005, -0.0346],
          [-0.0522,  0.1493, -0.0590]],

         [[-0.2254, -0.3307, -0.0396],
          [-0.0122, -0.2676, -0.2044],
          [ 0.0737,  0.0230, -0.0710]],

         [[ 0.0643, -0.1309, -0.0413],
          [ 0.0135, -0.0362,  0.0501],
          [-0.0928, -0.0071,  0.0639]]],


        [[[-0.0762, -0.1113, -0.1488],
          [-0.1922, -0.3928, -0.2738],
          [ 0.1681, -0.1114, -0.1353]],

         [[ 0.1240, -0.1553,  0.0098],
          [ 0.0288, -0.1457,  0.0827],
          [ 0.2156,  0.2269, -0.0653]],

         [[ 0.0724, -0.1304,  0.1530],
          [ 0.1593,  0.0195,  0.0724],
          [-0.1077, -0.0457,  0.0191]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0167, -0.0147, -0.0129],
          [-0.0154, -0.0133, -0.0138],
          [-0.0129, -0.0118, -0.0145]],

         [[-0.0177, -0.0152, -0.0134],
          [-0.0158, -0.0135, -0.0142],
          [-0.0131, -0.0119, -0.0150]],

         [[-0.0184, -0.0158, -0.0137],
          [-0.0167, -0.0142, -0.0146],
          [-0.0142, -0.0128, -0.0155]]],


        [[[ 0.0272,  0.0417,  0.0722],
          [ 0.0202,  0.0477,  0.0721],
          [ 0.0355,  0.0426,  0.0482]],

         [[ 0.0254,  0.0437,  0.0671],
          [ 0.0186,  0.0475,  0.0673],
          [ 0.0373,  0.0418,  0.0455]],

         [[ 0.0441,  0.0557,  0.0734],
          [ 0.0392,  0.0640,  0.0839],
          [ 0.0641,  0.0678,  0.0723]]],


        [[[-0.0003,  0.0004,  0.0002],
          [ 0.0002,  0.0004,  0.0004],
          [-0.0000, -0.0001,  0.0002]],

         [[-0.0009, -0.0001, -0.0002],
          [-0.0005, -0.0002, -0.0001],
          [-0.0003, -0.0004,  0.0000]],

         [[-0.0012, -0.0004, -0.0004],
          [-0.0007, -0.0004, -0.0004],
          [-0.0005, -0.0006, -0.0003]]],


        ...,


        [[[ 0.0023,  0.0040,  0.0049],
          [ 0.0015,  0.0029,  0.0035],
          [ 0.0015,  0.0030,  0.0038]],

         [[ 0.0024,  0.0039,  0.0050],
          [ 0.0016,  0.0030,  0.0037],
          [ 0.0019,  0.0031,  0.0040]],

         [[ 0.0005,  0.0016,  0.0027],
          [ 0.0001,  0.0009,  0.0015],
          [ 0.0003,  0.0008,  0.0013]]],


        [[[ 0.0040,  0.0047,  0.0039],
          [ 0.0059,  0.0065,  0.0033],
          [ 0.0060,  0.0061,  0.0022]],

         [[ 0.0010,  0.0021,  0.0019],
          [ 0.0038,  0.0047,  0.0018],
          [ 0.0043,  0.0046,  0.0012]],

         [[ 0.0002,  0.0004,  0.0004],
          [ 0.0029,  0.0029,  0.0003],
          [ 0.0038,  0.0034,  0.0001]]],


        [[[-0.0043, -0.0050, -0.0002],
          [ 0.0008,  0.0010,  0.0045],
          [ 0.0071,  0.0066,  0.0086]],

         [[-0.0058, -0.0063, -0.0008],
          [-0.0007, -0.0004,  0.0032],
          [ 0.0063,  0.0063,  0.0080]],

         [[-0.0079, -0.0105, -0.0059],
          [-0.0009, -0.0031, -0.0013],
          [ 0.0068,  0.0045,  0.0040]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2594]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 34 | Batch_idx: 0 |  Loss: (0.1873) | Acc: (93.00%) (120/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.2842) | Acc: (90.00%) (1272/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.2917) | Acc: (90.00%) (2426/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.2954) | Acc: (90.00%) (3577/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.2920) | Acc: (90.00%) (4730/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.2915) | Acc: (90.00%) (5882/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.2915) | Acc: (90.00%) (7033/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.2936) | Acc: (90.00%) (8193/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.2922) | Acc: (90.00%) (9355/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.2930) | Acc: (90.00%) (10509/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.2918) | Acc: (90.00%) (11674/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.2890) | Acc: (90.00%) (12843/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.2918) | Acc: (90.00%) (13978/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.2940) | Acc: (90.00%) (15115/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.2956) | Acc: (90.00%) (16268/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.2974) | Acc: (90.00%) (17402/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.2977) | Acc: (89.00%) (18547/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.2976) | Acc: (89.00%) (19692/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.2993) | Acc: (89.00%) (20841/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.3017) | Acc: (89.00%) (21966/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.3022) | Acc: (89.00%) (23107/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.3017) | Acc: (89.00%) (24260/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.3007) | Acc: (89.00%) (25414/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.3021) | Acc: (89.00%) (26552/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.3024) | Acc: (89.00%) (27691/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.3002) | Acc: (89.00%) (28859/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.3003) | Acc: (89.00%) (29993/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.2995) | Acc: (89.00%) (31154/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.2996) | Acc: (89.00%) (32305/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.2998) | Acc: (89.00%) (33451/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.3000) | Acc: (89.00%) (34593/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.3004) | Acc: (89.00%) (35743/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.3004) | Acc: (89.00%) (36893/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.3002) | Acc: (89.00%) (38047/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.2999) | Acc: (89.00%) (39197/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.2999) | Acc: (89.00%) (40337/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.2999) | Acc: (89.00%) (41492/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.2998) | Acc: (89.00%) (42644/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.2994) | Acc: (89.00%) (43806/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.2997) | Acc: (89.00%) (44907/50000)
# TEST : Loss: (0.3751) | Acc: (87.00%) (8761/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1241, -0.1069, -0.0611],
          [-0.0257, -0.0525,  0.0539],
          [-0.0071, -0.1274, -0.2218]],

         [[-0.0131, -0.0528,  0.0154],
          [-0.2017, -0.0334,  0.0387],
          [ 0.0238,  0.0950, -0.0323]],

         [[-0.0633,  0.1068, -0.2064],
          [ 0.2201,  0.3553,  0.1490],
          [-0.0314,  0.2409,  0.1573]]],


        [[[ 0.2632, -0.1439,  0.1323],
          [ 0.1506, -0.0262, -0.0929],
          [-0.2182, -0.1179, -0.1804]],

         [[ 0.0813, -0.1900,  0.0596],
          [-0.0676,  0.3157, -0.1636],
          [ 0.1409,  0.0537,  0.1817]],

         [[-0.1488, -0.1670, -0.0677],
          [-0.1530,  0.1492, -0.0378],
          [-0.0588,  0.1163,  0.1770]]],


        [[[-0.0610, -0.0584, -0.1033],
          [-0.0463, -0.1062, -0.0740],
          [-0.0864, -0.0975, -0.0414]],

         [[ 0.1013,  0.1688,  0.0548],
          [-0.0995, -0.1052, -0.0033],
          [-0.1950,  0.0080, -0.0076]],

         [[-0.0619,  0.0941,  0.1972],
          [-0.0357, -0.0851,  0.1655],
          [-0.1803,  0.0433,  0.0450]]],


        ...,


        [[[ 0.0584,  0.0161, -0.0865],
          [ 0.0745,  0.0595, -0.0109],
          [-0.2192,  0.0001,  0.0508]],

         [[-0.1136, -0.2099,  0.0602],
          [ 0.1485, -0.0062, -0.1233],
          [ 0.1073, -0.1170,  0.0542]],

         [[ 0.0206,  0.0408,  0.0955],
          [ 0.3311,  0.2978,  0.0866],
          [ 0.2927,  0.2329,  0.1390]]],


        [[[ 0.2361,  0.1392,  0.0884],
          [ 0.0875,  0.0003, -0.0349],
          [-0.0541,  0.1484, -0.0579]],

         [[-0.2276, -0.3290, -0.0401],
          [-0.0232, -0.2784, -0.2110],
          [ 0.0666,  0.0174, -0.0726]],

         [[ 0.0719, -0.1224, -0.0371],
          [ 0.0173, -0.0334,  0.0539],
          [-0.0861,  0.0008,  0.0725]]],


        [[[-0.0714, -0.1251, -0.1426],
          [-0.1986, -0.4127, -0.2653],
          [ 0.1493, -0.1292, -0.1342]],

         [[ 0.1286, -0.1613,  0.0150],
          [ 0.0272, -0.1555,  0.0863],
          [ 0.2016,  0.2110, -0.0679]],

         [[ 0.0796, -0.1319,  0.1587],
          [ 0.1627,  0.0170,  0.0796],
          [-0.1134, -0.0531,  0.0211]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0196, -0.0200, -0.0186],
          [-0.0225, -0.0214, -0.0203],
          [-0.0196, -0.0158, -0.0149]],

         [[-0.0189, -0.0184, -0.0175],
          [-0.0216, -0.0205, -0.0207],
          [-0.0190, -0.0162, -0.0168]],

         [[-0.0162, -0.0150, -0.0142],
          [-0.0186, -0.0170, -0.0176],
          [-0.0163, -0.0139, -0.0150]]],


        [[[-0.0112,  0.0244,  0.0285],
          [-0.0102, -0.0267, -0.0091],
          [ 0.0181, -0.0146,  0.0053]],

         [[ 0.0224,  0.0611,  0.0753],
          [ 0.0439,  0.0323,  0.0493],
          [ 0.0762,  0.0418,  0.0521]],

         [[ 0.0406,  0.0795,  0.0973],
          [ 0.0692,  0.0616,  0.0842],
          [ 0.1014,  0.0772,  0.0923]]],


        [[[-0.0037, -0.0050, -0.0092],
          [-0.0005, -0.0024, -0.0055],
          [-0.0002, -0.0016, -0.0043]],

         [[-0.0001, -0.0016, -0.0060],
          [ 0.0027,  0.0006, -0.0024],
          [ 0.0019,  0.0007, -0.0016]],

         [[ 0.0032,  0.0020, -0.0018],
          [ 0.0049,  0.0029,  0.0006],
          [ 0.0038,  0.0026,  0.0009]]],


        ...,


        [[[-0.0041, -0.0058, -0.0083],
          [ 0.0012, -0.0003, -0.0024],
          [ 0.0017,  0.0017, -0.0003]],

         [[-0.0043, -0.0050, -0.0067],
          [ 0.0004, -0.0008, -0.0020],
          [ 0.0018,  0.0016,  0.0004]],

         [[-0.0057, -0.0063, -0.0087],
          [-0.0006, -0.0017, -0.0042],
          [ 0.0018,  0.0015, -0.0010]]],


        [[[ 0.0341,  0.0502,  0.0483],
          [ 0.0325,  0.0491,  0.0428],
          [ 0.0259,  0.0337,  0.0285]],

         [[ 0.0068,  0.0234,  0.0251],
          [ 0.0059,  0.0232,  0.0192],
          [ 0.0016,  0.0102,  0.0070]],

         [[-0.0030,  0.0126,  0.0150],
          [-0.0040,  0.0131,  0.0107],
          [-0.0071,  0.0014, -0.0009]]],


        [[[ 0.0046,  0.0014, -0.0062],
          [ 0.0053,  0.0023, -0.0051],
          [ 0.0108,  0.0024,  0.0010]],

         [[-0.0008, -0.0015, -0.0067],
          [-0.0018, -0.0020, -0.0065],
          [ 0.0062, -0.0004,  0.0001]],

         [[-0.0001, -0.0014, -0.0053],
          [-0.0031, -0.0033, -0.0056],
          [ 0.0032, -0.0034, -0.0011]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2583]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 35 | Batch_idx: 0 |  Loss: (0.1763) | Acc: (93.00%) (120/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.3550) | Acc: (87.00%) (1237/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.3501) | Acc: (88.00%) (2374/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.3736) | Acc: (87.00%) (3471/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.3644) | Acc: (87.00%) (4603/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.3701) | Acc: (87.00%) (5706/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.3611) | Acc: (87.00%) (6856/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.3538) | Acc: (88.00%) (8005/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.3485) | Acc: (88.00%) (9155/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.3451) | Acc: (88.00%) (10302/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.3434) | Acc: (88.00%) (11432/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.3407) | Acc: (88.00%) (12581/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.3374) | Acc: (88.00%) (13731/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.3332) | Acc: (88.00%) (14877/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.3301) | Acc: (88.00%) (16031/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.3259) | Acc: (88.00%) (17200/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.3222) | Acc: (89.00%) (18372/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.3214) | Acc: (89.00%) (19520/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.3226) | Acc: (89.00%) (20657/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.3214) | Acc: (89.00%) (21801/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.3190) | Acc: (89.00%) (22964/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.3176) | Acc: (89.00%) (24120/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.3155) | Acc: (89.00%) (25277/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.3149) | Acc: (89.00%) (26423/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.3129) | Acc: (89.00%) (27583/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.3105) | Acc: (89.00%) (28749/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.3100) | Acc: (89.00%) (29901/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.3086) | Acc: (89.00%) (31067/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.3086) | Acc: (89.00%) (32205/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.3078) | Acc: (89.00%) (33353/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.3065) | Acc: (89.00%) (34523/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.3055) | Acc: (89.00%) (35683/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.3048) | Acc: (89.00%) (36831/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.3054) | Acc: (89.00%) (37967/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.3035) | Acc: (89.00%) (39153/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.3017) | Acc: (89.00%) (40321/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.3011) | Acc: (89.00%) (41480/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.2998) | Acc: (89.00%) (42644/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.2991) | Acc: (89.00%) (43812/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.2986) | Acc: (89.00%) (44924/50000)
# TEST : Loss: (0.3492) | Acc: (88.00%) (8819/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1227, -0.1062, -0.0610],
          [-0.0239, -0.0513,  0.0541],
          [-0.0057, -0.1261, -0.2204]],

         [[-0.0123, -0.0524,  0.0155],
          [-0.1990, -0.0323,  0.0393],
          [ 0.0250,  0.0950, -0.0315]],

         [[-0.0623,  0.1060, -0.2052],
          [ 0.2204,  0.3540,  0.1487],
          [-0.0298,  0.2399,  0.1569]]],


        [[[ 0.2595, -0.1491,  0.1263],
          [ 0.1478, -0.0291, -0.0973],
          [-0.2201, -0.1196, -0.1835]],

         [[ 0.0767, -0.1958,  0.0531],
          [-0.0720,  0.3112, -0.1689],
          [ 0.1366,  0.0500,  0.1765]],

         [[-0.1535, -0.1728, -0.0741],
          [-0.1575,  0.1445, -0.0435],
          [-0.0634,  0.1118,  0.1710]]],


        [[[-0.0593, -0.0561, -0.0993],
          [-0.0444, -0.1014, -0.0698],
          [-0.0797, -0.0912, -0.0373]],

         [[ 0.0993,  0.1668,  0.0564],
          [-0.0976, -0.1018, -0.0007],
          [-0.1875,  0.0094, -0.0048]],

         [[-0.0607,  0.0936,  0.1967],
          [-0.0353, -0.0821,  0.1655],
          [-0.1750,  0.0437,  0.0467]]],


        ...,


        [[[ 0.0563,  0.0142, -0.0872],
          [ 0.0730,  0.0579, -0.0115],
          [-0.2185, -0.0010,  0.0498]],

         [[-0.1140, -0.2103,  0.0582],
          [ 0.1470, -0.0071, -0.1232],
          [ 0.1065, -0.1170,  0.0528]],

         [[ 0.0191,  0.0381,  0.0929],
          [ 0.3252,  0.2901,  0.0842],
          [ 0.2880,  0.2264,  0.1355]]],


        [[[ 0.2325,  0.1342,  0.0834],
          [ 0.0857, -0.0033, -0.0391],
          [-0.0555,  0.1445, -0.0617]],

         [[-0.2257, -0.3293, -0.0452],
          [-0.0215, -0.2780, -0.2134],
          [ 0.0661,  0.0148, -0.0761]],

         [[ 0.0710, -0.1248, -0.0422],
          [ 0.0182, -0.0362,  0.0479],
          [-0.0860, -0.0021,  0.0675]]],


        [[[-0.0716, -0.1228, -0.1409],
          [-0.1976, -0.4089, -0.2635],
          [ 0.1472, -0.1304, -0.1371]],

         [[ 0.1280, -0.1596,  0.0155],
          [ 0.0275, -0.1542,  0.0859],
          [ 0.2000,  0.2092, -0.0698]],

         [[ 0.0799, -0.1298,  0.1594],
          [ 0.1634,  0.0184,  0.0803],
          [-0.1122, -0.0519,  0.0207]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2475]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0108]], device='cuda:0')

Epoch: 36 | Batch_idx: 0 |  Loss: (0.2364) | Acc: (88.00%) (113/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.2973) | Acc: (90.00%) (1268/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.2834) | Acc: (90.00%) (2429/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.2756) | Acc: (90.00%) (3608/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.2743) | Acc: (90.00%) (4773/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.2778) | Acc: (90.00%) (5925/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.2737) | Acc: (90.00%) (7090/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.2718) | Acc: (90.00%) (8258/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.2736) | Acc: (90.00%) (9412/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.2723) | Acc: (90.00%) (10578/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.2737) | Acc: (90.00%) (11726/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.2738) | Acc: (90.00%) (12889/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.2745) | Acc: (90.00%) (14048/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.2742) | Acc: (90.00%) (15206/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.2731) | Acc: (90.00%) (16379/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.2712) | Acc: (90.00%) (17552/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.2721) | Acc: (90.00%) (18709/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.2722) | Acc: (90.00%) (19876/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.2727) | Acc: (90.00%) (21037/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.2729) | Acc: (90.00%) (22200/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.2728) | Acc: (90.00%) (23365/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.2721) | Acc: (90.00%) (24534/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.2726) | Acc: (90.00%) (25695/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.2740) | Acc: (90.00%) (26844/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.2727) | Acc: (90.00%) (28023/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.2721) | Acc: (90.00%) (29192/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.2710) | Acc: (90.00%) (30362/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.2718) | Acc: (90.00%) (31521/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.2713) | Acc: (90.00%) (32686/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.2706) | Acc: (90.00%) (33861/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.2707) | Acc: (90.00%) (35021/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.2702) | Acc: (90.00%) (36186/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.2712) | Acc: (90.00%) (37341/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.2709) | Acc: (90.00%) (38509/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.2710) | Acc: (90.00%) (39672/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.2713) | Acc: (90.00%) (40828/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.2720) | Acc: (90.00%) (41970/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.2713) | Acc: (90.00%) (43136/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.2716) | Acc: (90.00%) (44294/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.2709) | Acc: (90.00%) (45429/50000)
# TEST : Loss: (0.3400) | Acc: (88.00%) (8835/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1219, -0.1055, -0.0606],
          [-0.0238, -0.0510,  0.0538],
          [-0.0057, -0.1254, -0.2191]],

         [[-0.0122, -0.0521,  0.0154],
          [-0.1978, -0.0321,  0.0390],
          [ 0.0249,  0.0945, -0.0313]],

         [[-0.0619,  0.1053, -0.2038],
          [ 0.2188,  0.3514,  0.1476],
          [-0.0296,  0.2382,  0.1558]]],


        [[[ 0.2592, -0.1489,  0.1262],
          [ 0.1476, -0.0291, -0.0971],
          [-0.2199, -0.1194, -0.1833]],

         [[ 0.0766, -0.1955,  0.0531],
          [-0.0719,  0.3108, -0.1687],
          [ 0.1364,  0.0500,  0.1763]],

         [[-0.1533, -0.1726, -0.0740],
          [-0.1573,  0.1443, -0.0435],
          [-0.0633,  0.1117,  0.1707]]],


        [[[-0.0579, -0.0549, -0.0977],
          [-0.0424, -0.0979, -0.0683],
          [-0.0752, -0.0874, -0.0365]],

         [[ 0.0972,  0.1636,  0.0555],
          [-0.0942, -0.0989, -0.0007],
          [-0.1801,  0.0091, -0.0047]],

         [[-0.0595,  0.0918,  0.1935],
          [-0.0343, -0.0801,  0.1624],
          [-0.1696,  0.0425,  0.0457]]],


        ...,


        [[[ 0.0559,  0.0141, -0.0866],
          [ 0.0725,  0.0575, -0.0114],
          [-0.2168, -0.0010,  0.0494]],

         [[-0.1129, -0.2084,  0.0577],
          [ 0.1455, -0.0071, -0.1220],
          [ 0.1053, -0.1157,  0.0523]],

         [[ 0.0188,  0.0377,  0.0918],
          [ 0.3171,  0.2827,  0.0828],
          [ 0.2807,  0.2209,  0.1332]]],


        [[[ 0.2310,  0.1333,  0.0828],
          [ 0.0852, -0.0033, -0.0388],
          [-0.0552,  0.1436, -0.0613]],

         [[-0.2235, -0.3248, -0.0446],
          [-0.0212, -0.2744, -0.2105],
          [ 0.0655,  0.0147, -0.0754]],

         [[ 0.0702, -0.1230, -0.0416],
          [ 0.0180, -0.0357,  0.0472],
          [-0.0852, -0.0020,  0.0668]]],


        [[[-0.0711, -0.1215, -0.1395],
          [-0.1962, -0.4044, -0.2607],
          [ 0.1464, -0.1295, -0.1362]],

         [[ 0.1273, -0.1587,  0.0154],
          [ 0.0274, -0.1534,  0.0854],
          [ 0.1991,  0.2082, -0.0695]],

         [[ 0.0795, -0.1292,  0.1587],
          [ 0.1626,  0.0183,  0.0799],
          [-0.1117, -0.0517,  0.0206]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2696]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0321]], device='cuda:0')

Epoch: 37 | Batch_idx: 0 |  Loss: (0.3182) | Acc: (89.00%) (114/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.2667) | Acc: (91.00%) (1283/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.2757) | Acc: (90.00%) (2441/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.2888) | Acc: (89.00%) (3570/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.2812) | Acc: (90.00%) (4732/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.2826) | Acc: (90.00%) (5889/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.2874) | Acc: (90.00%) (7036/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.2847) | Acc: (90.00%) (8195/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.2828) | Acc: (90.00%) (9351/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.2799) | Acc: (90.00%) (10520/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.2796) | Acc: (90.00%) (11679/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.2774) | Acc: (90.00%) (12851/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.2775) | Acc: (90.00%) (14013/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.2755) | Acc: (90.00%) (15180/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.2768) | Acc: (90.00%) (16337/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.2757) | Acc: (90.00%) (17509/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.2740) | Acc: (90.00%) (18678/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.2733) | Acc: (90.00%) (19845/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.2727) | Acc: (90.00%) (21015/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.2731) | Acc: (90.00%) (22181/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.2739) | Acc: (90.00%) (23332/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.2746) | Acc: (90.00%) (24479/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.2740) | Acc: (90.00%) (25632/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.2723) | Acc: (90.00%) (26822/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.2714) | Acc: (90.00%) (28000/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.2716) | Acc: (90.00%) (29158/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.2706) | Acc: (90.00%) (30343/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.2699) | Acc: (90.00%) (31515/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.2704) | Acc: (90.00%) (32684/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.2693) | Acc: (90.00%) (33864/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.2685) | Acc: (90.00%) (35043/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.2691) | Acc: (90.00%) (36201/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.2686) | Acc: (90.00%) (37372/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.2683) | Acc: (90.00%) (38539/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.2681) | Acc: (90.00%) (39705/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.2682) | Acc: (90.00%) (40870/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.2679) | Acc: (90.00%) (42036/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.2682) | Acc: (90.00%) (43198/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.2685) | Acc: (90.00%) (44354/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.2687) | Acc: (90.00%) (45473/50000)
# TEST : Loss: (0.3353) | Acc: (88.00%) (8848/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1210, -0.1047, -0.0601],
          [-0.0236, -0.0506,  0.0534],
          [-0.0056, -0.1245, -0.2175]],

         [[-0.0121, -0.0517,  0.0153],
          [-0.1963, -0.0319,  0.0387],
          [ 0.0247,  0.0938, -0.0310]],

         [[-0.0614,  0.1044, -0.2020],
          [ 0.2169,  0.3483,  0.1463],
          [-0.0294,  0.2361,  0.1545]]],


        [[[ 0.2588, -0.1487,  0.1260],
          [ 0.1474, -0.0290, -0.0970],
          [-0.2195, -0.1192, -0.1830]],

         [[ 0.0765, -0.1952,  0.0530],
          [-0.0718,  0.3103, -0.1684],
          [ 0.1362,  0.0499,  0.1760]],

         [[-0.1531, -0.1723, -0.0739],
          [-0.1571,  0.1440, -0.0434],
          [-0.0632,  0.1115,  0.1705]]],


        [[[-0.0562, -0.0535, -0.0957],
          [-0.0401, -0.0938, -0.0665],
          [-0.0702, -0.0830, -0.0354]],

         [[ 0.0947,  0.1598,  0.0545],
          [-0.0903, -0.0955, -0.0006],
          [-0.1714,  0.0087, -0.0046]],

         [[-0.0580,  0.0897,  0.1898],
          [-0.0332, -0.0777,  0.1587],
          [-0.1633,  0.0411,  0.0446]]],


        ...,


        [[[ 0.0554,  0.0139, -0.0858],
          [ 0.0718,  0.0570, -0.0113],
          [-0.2148, -0.0010,  0.0490]],

         [[-0.1117, -0.2062,  0.0571],
          [ 0.1436, -0.0070, -0.1205],
          [ 0.1040, -0.1143,  0.0517]],

         [[ 0.0185,  0.0371,  0.0906],
          [ 0.3074,  0.2741,  0.0811],
          [ 0.2720,  0.2144,  0.1305]]],


        [[[ 0.2293,  0.1322,  0.0821],
          [ 0.0846, -0.0032, -0.0385],
          [-0.0548,  0.1425, -0.0609]],

         [[-0.2208, -0.3195, -0.0439],
          [-0.0210, -0.2701, -0.2070],
          [ 0.0649,  0.0145, -0.0745]],

         [[ 0.0693, -0.1208, -0.0409],
          [ 0.0177, -0.0351,  0.0463],
          [-0.0842, -0.0020,  0.0659]]],


        [[[-0.0705, -0.1200, -0.1380],
          [-0.1946, -0.3991, -0.2573],
          [ 0.1455, -0.1285, -0.1350]],

         [[ 0.1266, -0.1576,  0.0153],
          [ 0.0272, -0.1523,  0.0848],
          [ 0.1981,  0.2070, -0.0691]],

         [[ 0.0791, -0.1285,  0.1578],
          [ 0.1618,  0.0182,  0.0795],
          [-0.1111, -0.0514,  0.0205]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2838]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0223]], device='cuda:0')

Epoch: 38 | Batch_idx: 0 |  Loss: (0.2809) | Acc: (90.00%) (116/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.2621) | Acc: (91.00%) (1282/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.2578) | Acc: (90.00%) (2446/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.2715) | Acc: (90.00%) (3609/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.2719) | Acc: (90.00%) (4773/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.2741) | Acc: (90.00%) (5926/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.2768) | Acc: (90.00%) (7098/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.2741) | Acc: (90.00%) (8263/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.2730) | Acc: (90.00%) (9433/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.2730) | Acc: (91.00%) (10601/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.2732) | Acc: (91.00%) (11771/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.2731) | Acc: (91.00%) (12937/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.2701) | Acc: (91.00%) (14130/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.2700) | Acc: (91.00%) (15302/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.2715) | Acc: (91.00%) (16451/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.2736) | Acc: (91.00%) (17599/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.2754) | Acc: (90.00%) (18747/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.2742) | Acc: (91.00%) (19922/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.2723) | Acc: (91.00%) (21090/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.2725) | Acc: (91.00%) (22258/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.2717) | Acc: (91.00%) (23435/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.2716) | Acc: (91.00%) (24601/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.2731) | Acc: (91.00%) (25747/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.2724) | Acc: (91.00%) (26915/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.2715) | Acc: (91.00%) (28087/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.2717) | Acc: (91.00%) (29250/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.2721) | Acc: (91.00%) (30412/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.2721) | Acc: (91.00%) (31574/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.2743) | Acc: (90.00%) (32715/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.2738) | Acc: (90.00%) (33887/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.2739) | Acc: (90.00%) (35048/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.2740) | Acc: (90.00%) (36212/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.2744) | Acc: (90.00%) (37364/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.2742) | Acc: (90.00%) (38544/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.2739) | Acc: (91.00%) (39720/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.2741) | Acc: (90.00%) (40881/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.2741) | Acc: (90.00%) (42049/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.2733) | Acc: (91.00%) (43235/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.2737) | Acc: (91.00%) (44391/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.2730) | Acc: (91.00%) (45523/50000)
# TEST : Loss: (0.3347) | Acc: (88.00%) (8872/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1198, -0.1037, -0.0595],
          [-0.0234, -0.0501,  0.0529],
          [-0.0056, -0.1234, -0.2156]],

         [[-0.0120, -0.0512,  0.0151],
          [-0.1944, -0.0316,  0.0384],
          [ 0.0244,  0.0929, -0.0308]],

         [[-0.0607,  0.1033, -0.1999],
          [ 0.2146,  0.3445,  0.1448],
          [-0.0291,  0.2336,  0.1528]]],


        [[[ 0.2583, -0.1484,  0.1258],
          [ 0.1471, -0.0290, -0.0968],
          [-0.2191, -0.1190, -0.1827]],

         [[ 0.0764, -0.1949,  0.0529],
          [-0.0716,  0.3097, -0.1681],
          [ 0.1359,  0.0498,  0.1756]],

         [[-0.1528, -0.1720, -0.0738],
          [-0.1568,  0.1438, -0.0433],
          [-0.0631,  0.1113,  0.1701]]],


        [[[-0.0543, -0.0518, -0.0933],
          [-0.0374, -0.0891, -0.0644],
          [-0.0645, -0.0780, -0.0342]],

         [[ 0.0918,  0.1553,  0.0532],
          [-0.0858, -0.0915, -0.0006],
          [-0.1614,  0.0083, -0.0045]],

         [[-0.0563,  0.0872,  0.1853],
          [-0.0319, -0.0749,  0.1543],
          [-0.1559,  0.0395,  0.0432]]],


        ...,


        [[[ 0.0548,  0.0138, -0.0850],
          [ 0.0710,  0.0563, -0.0112],
          [-0.2124, -0.0010,  0.0485]],

         [[-0.1102, -0.2035,  0.0564],
          [ 0.1413, -0.0069, -0.1187],
          [ 0.1023, -0.1125,  0.0509]],

         [[ 0.0182,  0.0364,  0.0891],
          [ 0.2961,  0.2639,  0.0790],
          [ 0.2618,  0.2067,  0.1272]]],


        [[[ 0.2271,  0.1309,  0.0813],
          [ 0.0838, -0.0032, -0.0381],
          [-0.0543,  0.1412, -0.0603]],

         [[-0.2175, -0.3132, -0.0431],
          [-0.0207, -0.2649, -0.2029],
          [ 0.0641,  0.0143, -0.0734]],

         [[ 0.0682, -0.1182, -0.0401],
          [ 0.0174, -0.0343,  0.0453],
          [-0.0831, -0.0020,  0.0649]]],


        [[[-0.0698, -0.1182, -0.1361],
          [-0.1926, -0.3926, -0.2532],
          [ 0.1443, -0.1272, -0.1336]],

         [[ 0.1256, -0.1562,  0.0152],
          [ 0.0270, -0.1510,  0.0841],
          [ 0.1968,  0.2055, -0.0686]],

         [[ 0.0786, -0.1276,  0.1567],
          [ 0.1607,  0.0181,  0.0789],
          [-0.1104, -0.0511,  0.0204]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2814]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0178]], device='cuda:0')

Epoch: 39 | Batch_idx: 0 |  Loss: (0.1773) | Acc: (95.00%) (122/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.2780) | Acc: (91.00%) (1287/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.2980) | Acc: (90.00%) (2425/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.2909) | Acc: (90.00%) (3586/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.2848) | Acc: (90.00%) (4758/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.2800) | Acc: (90.00%) (5932/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.2787) | Acc: (90.00%) (7098/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.2793) | Acc: (90.00%) (8267/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.2779) | Acc: (91.00%) (9441/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.2777) | Acc: (91.00%) (10610/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.2773) | Acc: (91.00%) (11765/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.2769) | Acc: (91.00%) (12933/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.2767) | Acc: (91.00%) (14101/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.2778) | Acc: (91.00%) (15261/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.2759) | Acc: (91.00%) (16434/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.2775) | Acc: (90.00%) (17587/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.2771) | Acc: (91.00%) (18769/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.2788) | Acc: (90.00%) (19917/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.2792) | Acc: (91.00%) (21083/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.2803) | Acc: (90.00%) (22245/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.2799) | Acc: (90.00%) (23411/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.2807) | Acc: (90.00%) (24566/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.2798) | Acc: (90.00%) (25734/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.2797) | Acc: (90.00%) (26902/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.2814) | Acc: (90.00%) (28056/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.2819) | Acc: (90.00%) (29211/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.2828) | Acc: (90.00%) (30366/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.2827) | Acc: (90.00%) (31542/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.2822) | Acc: (90.00%) (32719/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.2831) | Acc: (90.00%) (33869/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.2829) | Acc: (90.00%) (35037/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.2832) | Acc: (90.00%) (36195/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.2842) | Acc: (90.00%) (37340/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.2859) | Acc: (90.00%) (38476/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.2859) | Acc: (90.00%) (39648/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.2858) | Acc: (90.00%) (40814/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.2861) | Acc: (90.00%) (41982/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.2860) | Acc: (90.00%) (43159/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.2864) | Acc: (90.00%) (44320/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.2869) | Acc: (90.00%) (45439/50000)
# TEST : Loss: (0.3498) | Acc: (88.00%) (8828/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1185, -0.1025, -0.0589],
          [-0.0231, -0.0496,  0.0523],
          [-0.0055, -0.1221, -0.2133]],

         [[-0.0118, -0.0506,  0.0149],
          [-0.1923, -0.0312,  0.0380],
          [ 0.0242,  0.0919, -0.0304]],

         [[-0.0600,  0.1020, -0.1973],
          [ 0.2119,  0.3400,  0.1429],
          [-0.0287,  0.2305,  0.1509]]],


        [[[ 0.2578, -0.1481,  0.1255],
          [ 0.1468, -0.0289, -0.0966],
          [-0.2186, -0.1188, -0.1823]],

         [[ 0.0762, -0.1944,  0.0528],
          [-0.0715,  0.3089, -0.1677],
          [ 0.1356,  0.0497,  0.1752]],

         [[-0.1524, -0.1716, -0.0736],
          [-0.1564,  0.1434, -0.0432],
          [-0.0629,  0.1110,  0.1697]]],


        [[[-0.0520, -0.0498, -0.0905],
          [-0.0345, -0.0837, -0.0620],
          [-0.0582, -0.0722, -0.0328]],

         [[ 0.0883,  0.1499,  0.0517],
          [-0.0806, -0.0869, -0.0006],
          [-0.1500,  0.0078, -0.0043]],

         [[-0.0542,  0.0843,  0.1799],
          [-0.0303, -0.0717,  0.1491],
          [-0.1474,  0.0375,  0.0416]]],


        ...,


        [[[ 0.0541,  0.0136, -0.0839],
          [ 0.0700,  0.0556, -0.0110],
          [-0.2095, -0.0010,  0.0478]],

         [[-0.1084, -0.2002,  0.0555],
          [ 0.1386, -0.0067, -0.1166],
          [ 0.1003, -0.1103,  0.0500]],

         [[ 0.0178,  0.0356,  0.0873],
          [ 0.2829,  0.2520,  0.0766],
          [ 0.2500,  0.1978,  0.1233]]],


        [[[ 0.2246,  0.1294,  0.0804],
          [ 0.0828, -0.0032, -0.0377],
          [-0.0537,  0.1397, -0.0596]],

         [[-0.2137, -0.3057, -0.0421],
          [-0.0203, -0.2587, -0.1980],
          [ 0.0631,  0.0141, -0.0721]],

         [[ 0.0668, -0.1151, -0.0391],
          [ 0.0171, -0.0334,  0.0441],
          [-0.0817, -0.0019,  0.0636]]],


        [[[-0.0689, -0.1160, -0.1338],
          [-0.1902, -0.3849, -0.2483],
          [ 0.1430, -0.1257, -0.1319]],

         [[ 0.1245, -0.1546,  0.0150],
          [ 0.0268, -0.1494,  0.0832],
          [ 0.1953,  0.2037, -0.0679]],

         [[ 0.0779, -0.1265,  0.1553],
          [ 0.1594,  0.0179,  0.0782],
          [-0.1096, -0.0507,  0.0202]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2601]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0701]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 40 | Batch_idx: 0 |  Loss: (0.4287) | Acc: (83.00%) (107/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.4752) | Acc: (83.00%) (1182/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.5287) | Acc: (81.00%) (2193/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.5560) | Acc: (81.00%) (3221/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.5650) | Acc: (80.00%) (4247/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.5608) | Acc: (81.00%) (5299/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.5632) | Acc: (80.00%) (6316/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.5553) | Acc: (81.00%) (7374/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.5500) | Acc: (81.00%) (8421/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.5468) | Acc: (81.00%) (9485/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.5422) | Acc: (81.00%) (10542/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.5383) | Acc: (81.00%) (11614/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.5379) | Acc: (81.00%) (12651/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.5312) | Acc: (81.00%) (13735/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.5277) | Acc: (82.00%) (14812/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.5234) | Acc: (82.00%) (15891/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.5204) | Acc: (82.00%) (16973/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.5175) | Acc: (82.00%) (18057/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.5144) | Acc: (82.00%) (19119/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.5128) | Acc: (82.00%) (20186/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.5077) | Acc: (82.00%) (21277/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.5052) | Acc: (82.00%) (22346/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.5013) | Acc: (82.00%) (23439/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.4977) | Acc: (82.00%) (24526/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.4946) | Acc: (83.00%) (25618/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.4911) | Acc: (83.00%) (26708/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.4877) | Acc: (83.00%) (27823/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.4841) | Acc: (83.00%) (28935/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.4805) | Acc: (83.00%) (30054/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.4772) | Acc: (83.00%) (31178/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.4741) | Acc: (83.00%) (32283/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.4701) | Acc: (83.00%) (33404/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.4672) | Acc: (84.00%) (34514/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.4653) | Acc: (84.00%) (35622/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.4639) | Acc: (84.00%) (36723/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.4629) | Acc: (84.00%) (37814/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.4625) | Acc: (84.00%) (38907/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.4621) | Acc: (84.00%) (39989/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.4605) | Acc: (84.00%) (41091/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.4590) | Acc: (84.00%) (42153/50000)
# TEST : Loss: (0.5216) | Acc: (83.00%) (8315/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1139, -0.1080, -0.0609],
          [-0.0221, -0.0512,  0.0535],
          [-0.0068, -0.1221, -0.2068]],

         [[-0.0264, -0.0716, -0.0065],
          [-0.1989, -0.0361,  0.0308],
          [ 0.0174,  0.0880, -0.0320]],

         [[-0.0680,  0.0880, -0.2131],
          [ 0.2145,  0.3490,  0.1479],
          [-0.0240,  0.2411,  0.1609]]],


        [[[ 0.2636, -0.1333,  0.1393],
          [ 0.1543, -0.0069, -0.0946],
          [-0.2243, -0.1363, -0.1914]],

         [[ 0.0569, -0.2017,  0.0523],
          [-0.0749,  0.3294, -0.1626],
          [ 0.1284,  0.0464,  0.1752]],

         [[-0.1585, -0.1670, -0.0557],
          [-0.1570,  0.1654, -0.0247],
          [-0.0588,  0.1164,  0.1837]]],


        [[[-0.0577, -0.0490, -0.0767],
          [-0.0611, -0.1075, -0.0685],
          [-0.0695, -0.0761, -0.0199]],

         [[ 0.0690,  0.1391,  0.0573],
          [-0.1122, -0.1144, -0.0088],
          [-0.1642,  0.0009,  0.0117]],

         [[-0.0705,  0.0738,  0.1785],
          [-0.0610, -0.0972,  0.1360],
          [-0.1637,  0.0253,  0.0515]]],


        ...,


        [[[ 0.0473, -0.0006, -0.0919],
          [ 0.0542,  0.0367, -0.0274],
          [-0.2237, -0.0193,  0.0263]],

         [[-0.1204, -0.2196,  0.0416],
          [ 0.1218, -0.0274, -0.1316],
          [ 0.0914, -0.1249,  0.0286]],

         [[ 0.0373,  0.0489,  0.1092],
          [ 0.3029,  0.2671,  0.1003],
          [ 0.2613,  0.1923,  0.1120]]],


        [[[ 0.2115,  0.1185,  0.0694],
          [ 0.0738, -0.0174, -0.0523],
          [-0.0594,  0.1300, -0.0651]],

         [[-0.2244, -0.3212, -0.0666],
          [-0.0355, -0.2861, -0.2351],
          [ 0.0560,  0.0042, -0.0800]],

         [[ 0.0793, -0.0876, -0.0090],
          [ 0.0306, -0.0213,  0.0567],
          [-0.0595,  0.0188,  0.0845]]],


        [[[-0.0860, -0.1697, -0.1434],
          [-0.1964, -0.4098, -0.2327],
          [ 0.1467, -0.1176, -0.0991]],

         [[ 0.0999, -0.1964, -0.0031],
          [ 0.0179, -0.1669,  0.0867],
          [ 0.1928,  0.2034, -0.0464]],

         [[ 0.0580, -0.1517,  0.1512],
          [ 0.1507,  0.0084,  0.0905],
          [-0.1067, -0.0424,  0.0487]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0006,  0.0016,  0.0036],
          [ 0.0053,  0.0057,  0.0059],
          [ 0.0034,  0.0043,  0.0063]],

         [[ 0.0004,  0.0011,  0.0038],
          [ 0.0045,  0.0053,  0.0070],
          [ 0.0023,  0.0039,  0.0076]],

         [[ 0.0009,  0.0002,  0.0024],
          [ 0.0038,  0.0030,  0.0046],
          [ 0.0018,  0.0016,  0.0055]]],


        [[[-0.0402, -0.0230, -0.0074],
          [ 0.0177,  0.0283,  0.0130],
          [ 0.0128,  0.0437,  0.0474]],

         [[ 0.0423,  0.0539,  0.0586],
          [ 0.0710,  0.0796,  0.0529],
          [ 0.0363,  0.0591,  0.0645]],

         [[ 0.0613,  0.0725,  0.0740],
          [ 0.0843,  0.0951,  0.0778],
          [ 0.0703,  0.0938,  0.0969]]],


        [[[ 0.0001, -0.0001,  0.0002],
          [ 0.0003,  0.0004,  0.0011],
          [ 0.0002,  0.0006,  0.0011]],

         [[ 0.0004,  0.0003,  0.0007],
          [ 0.0005,  0.0006,  0.0015],
          [ 0.0003,  0.0007,  0.0014]],

         [[ 0.0010,  0.0008,  0.0013],
          [ 0.0010,  0.0010,  0.0017],
          [ 0.0006,  0.0008,  0.0014]]],


        ...,


        [[[ 0.0404,  0.0375,  0.0364],
          [ 0.0387,  0.0361,  0.0353],
          [ 0.0324,  0.0328,  0.0334]],

         [[ 0.0381,  0.0342,  0.0328],
          [ 0.0339,  0.0306,  0.0293],
          [ 0.0279,  0.0278,  0.0279]],

         [[ 0.0196,  0.0145,  0.0132],
          [ 0.0150,  0.0101,  0.0089],
          [ 0.0113,  0.0096,  0.0095]]],


        [[[ 0.0052,  0.0040,  0.0035],
          [-0.0011, -0.0029, -0.0030],
          [-0.0018, -0.0035, -0.0027]],

         [[ 0.0068,  0.0041,  0.0014],
          [ 0.0008, -0.0015, -0.0026],
          [ 0.0007, -0.0016, -0.0015]],

         [[ 0.0059,  0.0029,  0.0006],
          [ 0.0013, -0.0009, -0.0022],
          [ 0.0017, -0.0004, -0.0006]]],


        [[[-0.0103, -0.0018, -0.0002],
          [-0.0096, -0.0020,  0.0007],
          [-0.0085, -0.0027,  0.0019]],

         [[-0.0056,  0.0009,  0.0005],
          [-0.0060, -0.0007, -0.0002],
          [-0.0026,  0.0013,  0.0037]],

         [[-0.0036, -0.0014, -0.0034],
          [-0.0050, -0.0031, -0.0040],
          [-0.0004,  0.0008,  0.0021]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2604]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 41 | Batch_idx: 0 |  Loss: (0.2770) | Acc: (90.00%) (116/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.3196) | Acc: (89.00%) (1258/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.3290) | Acc: (88.00%) (2382/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.3266) | Acc: (88.00%) (3522/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.3312) | Acc: (88.00%) (4654/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.3335) | Acc: (88.00%) (5778/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.3382) | Acc: (88.00%) (6897/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.3379) | Acc: (88.00%) (8038/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.3423) | Acc: (88.00%) (9153/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.3455) | Acc: (88.00%) (10269/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.3483) | Acc: (88.00%) (11387/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.3496) | Acc: (88.00%) (12513/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.3519) | Acc: (87.00%) (13621/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.3521) | Acc: (87.00%) (14738/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.3532) | Acc: (87.00%) (15852/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.3522) | Acc: (87.00%) (16991/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.3515) | Acc: (87.00%) (18121/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.3499) | Acc: (87.00%) (19252/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.3499) | Acc: (87.00%) (20378/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.3506) | Acc: (87.00%) (21498/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.3500) | Acc: (87.00%) (22632/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.3495) | Acc: (88.00%) (23775/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.3487) | Acc: (88.00%) (24916/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.3504) | Acc: (88.00%) (26050/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.3503) | Acc: (88.00%) (27189/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.3510) | Acc: (88.00%) (28293/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.3527) | Acc: (87.00%) (29396/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.3535) | Acc: (87.00%) (30511/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.3531) | Acc: (87.00%) (31643/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.3530) | Acc: (87.00%) (32774/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.3539) | Acc: (87.00%) (33891/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.3536) | Acc: (88.00%) (35035/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.3526) | Acc: (88.00%) (36170/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.3525) | Acc: (88.00%) (37304/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.3526) | Acc: (88.00%) (38438/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.3525) | Acc: (88.00%) (39572/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.3524) | Acc: (88.00%) (40703/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.3529) | Acc: (88.00%) (41825/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.3523) | Acc: (88.00%) (42956/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.3517) | Acc: (88.00%) (44048/50000)
# TEST : Loss: (0.4104) | Acc: (86.00%) (8665/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1134, -0.1073, -0.0533],
          [-0.0292, -0.0573,  0.0533],
          [-0.0213, -0.1333, -0.2070]],

         [[-0.0247, -0.0706, -0.0008],
          [-0.2002, -0.0387,  0.0319],
          [ 0.0050,  0.0772, -0.0338]],

         [[-0.0587,  0.0965, -0.2007],
          [ 0.2233,  0.3583,  0.1573],
          [-0.0253,  0.2416,  0.1658]]],


        [[[ 0.2810, -0.1241,  0.1465],
          [ 0.1554, -0.0067, -0.0964],
          [-0.2246, -0.1499, -0.1975]],

         [[ 0.0750, -0.1908,  0.0588],
          [-0.0649,  0.3413, -0.1589],
          [ 0.1435,  0.0507,  0.1800]],

         [[-0.1440, -0.1570, -0.0431],
          [-0.1478,  0.1718, -0.0222],
          [-0.0444,  0.1170,  0.1866]]],


        [[[-0.0495, -0.0519, -0.0797],
          [-0.0542, -0.1072, -0.0723],
          [-0.0716, -0.0792, -0.0234]],

         [[ 0.0742,  0.1338,  0.0541],
          [-0.1041, -0.1127, -0.0114],
          [-0.1657, -0.0069,  0.0069]],

         [[-0.0647,  0.0706,  0.1732],
          [-0.0569, -0.0958,  0.1298],
          [-0.1655,  0.0183,  0.0450]]],


        ...,


        [[[ 0.0500,  0.0101, -0.0840],
          [ 0.0646,  0.0581, -0.0136],
          [-0.2099,  0.0040,  0.0484]],

         [[-0.1188, -0.2092,  0.0423],
          [ 0.1368, -0.0006, -0.1211],
          [ 0.1057, -0.0985,  0.0477]],

         [[ 0.0331,  0.0579,  0.1064],
          [ 0.3211,  0.3069,  0.1089],
          [ 0.2641,  0.2135,  0.1229]]],


        [[[ 0.2222,  0.1209,  0.0767],
          [ 0.0851, -0.0091, -0.0400],
          [-0.0519,  0.1389, -0.0501]],

         [[-0.2174, -0.3232, -0.0702],
          [-0.0301, -0.2770, -0.2363],
          [ 0.0521,  0.0037, -0.0832]],

         [[ 0.0749, -0.0955, -0.0241],
          [ 0.0274, -0.0170,  0.0429],
          [-0.0733,  0.0110,  0.0707]]],


        [[[-0.0716, -0.1761, -0.1586],
          [-0.1980, -0.4131, -0.2393],
          [ 0.1384, -0.1091, -0.0929]],

         [[ 0.1165, -0.1904, -0.0051],
          [ 0.0278, -0.1543,  0.0936],
          [ 0.1938,  0.2173, -0.0349]],

         [[ 0.0698, -0.1486,  0.1430],
          [ 0.1568,  0.0175,  0.0917],
          [-0.1114, -0.0383,  0.0466]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0055, -0.0026, -0.0031],
          [-0.0095, -0.0042, -0.0041],
          [-0.0113, -0.0050, -0.0055]],

         [[-0.0056, -0.0025, -0.0024],
          [-0.0094, -0.0045, -0.0042],
          [-0.0107, -0.0050, -0.0060]],

         [[-0.0062, -0.0025, -0.0028],
          [-0.0099, -0.0045, -0.0049],
          [-0.0092, -0.0035, -0.0056]]],


        [[[ 0.0363,  0.0358,  0.0241],
          [ 0.0208,  0.0133,  0.0078],
          [-0.0191, -0.0481, -0.0377]],

         [[ 0.0309,  0.0407,  0.0287],
          [ 0.0158,  0.0131, -0.0007],
          [-0.0140, -0.0438, -0.0482]],

         [[ 0.0290,  0.0466,  0.0392],
          [ 0.0241,  0.0354,  0.0231],
          [-0.0031, -0.0260, -0.0186]]],


        [[[ 0.0020,  0.0012,  0.0012],
          [ 0.0012,  0.0005,  0.0010],
          [ 0.0016,  0.0014,  0.0019]],

         [[ 0.0014,  0.0012,  0.0015],
          [ 0.0004,  0.0002,  0.0012],
          [ 0.0003,  0.0007,  0.0018]],

         [[ 0.0014,  0.0017,  0.0019],
          [ 0.0003,  0.0004,  0.0012],
          [ 0.0002,  0.0005,  0.0012]]],


        ...,


        [[[-0.0078, -0.0131, -0.0136],
          [-0.0018, -0.0085, -0.0105],
          [-0.0021, -0.0054, -0.0085]],

         [[-0.0051, -0.0092, -0.0095],
          [ 0.0003, -0.0067, -0.0079],
          [-0.0019, -0.0064, -0.0086]],

         [[-0.0015, -0.0054, -0.0067],
          [ 0.0030, -0.0034, -0.0056],
          [ 0.0003, -0.0039, -0.0067]]],


        [[[-0.0109, -0.0205, -0.0160],
          [-0.0207, -0.0267, -0.0191],
          [-0.0255, -0.0286, -0.0179]],

         [[-0.0035, -0.0093, -0.0020],
          [-0.0078, -0.0114, -0.0034],
          [-0.0116, -0.0140, -0.0048]],

         [[-0.0017, -0.0065,  0.0005],
          [-0.0043, -0.0079, -0.0018],
          [-0.0052, -0.0090, -0.0025]]],


        [[[ 0.0047,  0.0032, -0.0045],
          [-0.0043, -0.0029, -0.0021],
          [-0.0011,  0.0027,  0.0117]],

         [[-0.0011, -0.0016, -0.0071],
          [-0.0075, -0.0054, -0.0019],
          [-0.0042,  0.0001,  0.0128]],

         [[ 0.0030,  0.0044,  0.0003],
          [-0.0036, -0.0008,  0.0021],
          [-0.0003,  0.0036,  0.0139]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2599]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 42 | Batch_idx: 0 |  Loss: (0.3265) | Acc: (88.00%) (113/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.3384) | Acc: (88.00%) (1241/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.3100) | Acc: (89.00%) (2402/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.3159) | Acc: (89.00%) (3543/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.3199) | Acc: (89.00%) (4684/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.3170) | Acc: (89.00%) (5828/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.3090) | Acc: (89.00%) (6982/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.3052) | Acc: (89.00%) (8144/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.3045) | Acc: (89.00%) (9300/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.3040) | Acc: (89.00%) (10444/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.3101) | Acc: (89.00%) (11572/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.3095) | Acc: (89.00%) (12712/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.3091) | Acc: (89.00%) (13849/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.3080) | Acc: (89.00%) (14998/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.3093) | Acc: (89.00%) (16130/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.3086) | Acc: (89.00%) (17280/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.3082) | Acc: (89.00%) (18418/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.3087) | Acc: (89.00%) (19564/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.3106) | Acc: (89.00%) (20702/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.3114) | Acc: (89.00%) (21846/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.3120) | Acc: (89.00%) (22994/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.3127) | Acc: (89.00%) (24145/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.3121) | Acc: (89.00%) (25286/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.3105) | Acc: (89.00%) (26452/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.3107) | Acc: (89.00%) (27588/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.3092) | Acc: (89.00%) (28750/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.3101) | Acc: (89.00%) (29877/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.3108) | Acc: (89.00%) (31018/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.3118) | Acc: (89.00%) (32152/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.3114) | Acc: (89.00%) (33301/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.3110) | Acc: (89.00%) (34451/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.3118) | Acc: (89.00%) (35593/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.3112) | Acc: (89.00%) (36739/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.3112) | Acc: (89.00%) (37880/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.3111) | Acc: (89.00%) (39028/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.3104) | Acc: (89.00%) (40183/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.3101) | Acc: (89.00%) (41319/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.3092) | Acc: (89.00%) (42473/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.3098) | Acc: (89.00%) (43613/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.3100) | Acc: (89.00%) (44704/50000)
# TEST : Loss: (0.4451) | Acc: (85.00%) (8519/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1234, -0.1143, -0.0544],
          [-0.0366, -0.0637,  0.0485],
          [-0.0246, -0.1383, -0.2113]],

         [[-0.0321, -0.0749, -0.0022],
          [-0.2023, -0.0400,  0.0288],
          [ 0.0062,  0.0768, -0.0371]],

         [[-0.0663,  0.0931, -0.1976],
          [ 0.2205,  0.3596,  0.1598],
          [-0.0266,  0.2401,  0.1630]]],


        [[[ 0.2846, -0.1232,  0.1460],
          [ 0.1507, -0.0043, -0.0978],
          [-0.2250, -0.1554, -0.1971]],

         [[ 0.0768, -0.1925,  0.0569],
          [-0.0703,  0.3465, -0.1598],
          [ 0.1438,  0.0522,  0.1854]],

         [[-0.1469, -0.1636, -0.0464],
          [-0.1655,  0.1631, -0.0287],
          [-0.0568,  0.1047,  0.1837]]],


        [[[-0.0499, -0.0467, -0.0638],
          [-0.0525, -0.0973, -0.0535],
          [-0.0601, -0.0610, -0.0022]],

         [[ 0.0623,  0.1261,  0.0605],
          [-0.1133, -0.1120, -0.0006],
          [-0.1657, -0.0007,  0.0209]],

         [[-0.0699,  0.0650,  0.1763],
          [-0.0669, -0.0971,  0.1357],
          [-0.1673,  0.0226,  0.0574]]],


        ...,


        [[[ 0.0485,  0.0029, -0.0942],
          [ 0.0562,  0.0483, -0.0256],
          [-0.2098, -0.0012,  0.0365]],

         [[-0.1161, -0.2135,  0.0335],
          [ 0.1303, -0.0091, -0.1322],
          [ 0.1127, -0.0978,  0.0379]],

         [[ 0.0423,  0.0615,  0.1047],
          [ 0.3203,  0.3075,  0.1076],
          [ 0.2838,  0.2206,  0.1170]]],


        [[[ 0.2213,  0.1202,  0.0822],
          [ 0.0842, -0.0056, -0.0324],
          [-0.0446,  0.1544, -0.0313]],

         [[-0.2237, -0.3321, -0.0589],
          [-0.0416, -0.2787, -0.2217],
          [ 0.0575,  0.0264, -0.0554]],

         [[ 0.0666, -0.1064, -0.0093],
          [ 0.0216, -0.0122,  0.0638],
          [-0.0584,  0.0440,  0.1075]]],


        [[[-0.0682, -0.1813, -0.1425],
          [-0.2073, -0.4379, -0.2442],
          [ 0.1276, -0.1189, -0.1017]],

         [[ 0.1155, -0.1985, -0.0043],
          [ 0.0164, -0.1731,  0.0849],
          [ 0.1802,  0.2037, -0.0433]],

         [[ 0.0611, -0.1652,  0.1336],
          [ 0.1435, -0.0010,  0.0824],
          [-0.1226, -0.0489,  0.0400]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-6.8151e-03, -3.4420e-03, -4.3629e-03],
          [-7.8272e-03, -6.3518e-03, -6.0846e-03],
          [-7.9507e-03, -7.7355e-03, -6.4021e-03]],

         [[-6.8562e-03, -2.9880e-03, -3.6022e-03],
          [-7.5234e-03, -5.4641e-03, -5.3172e-03],
          [-7.6658e-03, -7.1791e-03, -5.6950e-03]],

         [[-8.9219e-03, -4.3420e-03, -3.5850e-03],
          [-8.6398e-03, -5.7181e-03, -4.3595e-03],
          [-8.8701e-03, -7.4820e-03, -5.1024e-03]]],


        [[[ 8.3114e-02,  8.4645e-02,  5.4493e-02],
          [ 4.0412e-02,  5.4149e-02,  5.3169e-02],
          [ 9.4092e-03,  2.6353e-02,  2.2968e-02]],

         [[ 4.5580e-02,  4.7606e-02,  2.3676e-02],
          [ 1.0849e-02,  1.4938e-02,  1.5885e-02],
          [-1.5399e-02, -7.1980e-03, -7.3099e-03]],

         [[ 5.4179e-04,  5.8376e-04, -1.6086e-02],
          [-2.6927e-02, -2.1588e-02, -1.4433e-02],
          [-4.4262e-02, -3.5808e-02, -2.9499e-02]]],


        [[[ 9.4163e-04,  1.0418e-03,  2.0540e-03],
          [ 8.9543e-04,  7.5924e-04,  1.4803e-03],
          [ 6.9698e-04,  8.0285e-04,  1.3048e-03]],

         [[ 1.1909e-03,  1.3389e-03,  2.4522e-03],
          [ 1.0862e-03,  1.1487e-03,  1.9902e-03],
          [ 7.9039e-04,  1.1091e-03,  1.6935e-03]],

         [[ 8.9105e-04,  1.0107e-03,  2.0747e-03],
          [ 8.8393e-04,  1.0327e-03,  1.8910e-03],
          [ 6.9662e-04,  1.1190e-03,  1.7258e-03]]],


        ...,


        [[[ 9.8199e-03,  7.7491e-03,  7.3468e-03],
          [ 1.0914e-02,  7.2503e-03,  7.2706e-03],
          [ 1.0613e-02,  7.2587e-03,  9.2845e-03]],

         [[ 5.0718e-03,  4.0214e-03,  3.3282e-03],
          [ 6.9687e-03,  4.1984e-03,  3.8042e-03],
          [ 6.4185e-03,  3.4824e-03,  5.2339e-03]],

         [[ 5.1273e-04,  2.0146e-04,  9.5511e-06],
          [ 2.7379e-03,  7.8389e-04,  3.7843e-04],
          [ 1.7318e-03, -5.5980e-04,  1.0250e-03]]],


        [[[ 1.4403e-03,  9.2366e-03,  8.4407e-03],
          [-8.7616e-03, -3.7159e-04,  4.3861e-03],
          [-1.5655e-02, -1.2767e-02, -5.6024e-03]],

         [[-4.0824e-03,  3.7129e-03,  4.0005e-03],
          [-1.3858e-02, -5.0743e-03,  1.1782e-03],
          [-2.0949e-02, -1.6892e-02, -8.1119e-03]],

         [[ 1.8036e-03,  7.2240e-03,  6.8974e-03],
          [-7.1836e-03,  4.7081e-04,  6.5054e-03],
          [-1.4140e-02, -9.9222e-03, -1.4984e-03]]],


        [[[-4.4181e-04,  1.7801e-03, -1.5071e-03],
          [-4.8347e-03, -2.1732e-03, -2.2803e-03],
          [-1.1754e-02, -9.3838e-03, -8.0896e-03]],

         [[-1.6195e-05,  2.4688e-03,  1.0629e-03],
          [-5.0648e-03, -2.2538e-03, -8.0835e-04],
          [-1.0710e-02, -8.3826e-03, -5.7987e-03]],

         [[ 3.6435e-03,  5.6682e-03,  4.6046e-03],
          [-2.4510e-03, -1.7116e-04,  9.6809e-04],
          [-8.1942e-03, -6.1856e-03, -4.6173e-03]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2592]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 43 | Batch_idx: 0 |  Loss: (0.3032) | Acc: (87.00%) (112/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.2837) | Acc: (90.00%) (1274/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.2881) | Acc: (90.00%) (2430/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.2833) | Acc: (90.00%) (3591/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.2838) | Acc: (90.00%) (4744/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.2887) | Acc: (90.00%) (5898/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.2839) | Acc: (90.00%) (7061/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.2789) | Acc: (90.00%) (8239/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.2832) | Acc: (90.00%) (9385/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.2861) | Acc: (90.00%) (10534/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.2869) | Acc: (90.00%) (11677/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.2881) | Acc: (90.00%) (12830/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.2899) | Acc: (90.00%) (13969/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.2893) | Acc: (90.00%) (15128/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.2902) | Acc: (90.00%) (16272/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.2883) | Acc: (90.00%) (17434/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.2897) | Acc: (90.00%) (18574/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.2893) | Acc: (90.00%) (19725/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.2889) | Acc: (90.00%) (20865/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.2902) | Acc: (89.00%) (22003/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.2906) | Acc: (89.00%) (23142/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.2911) | Acc: (89.00%) (24285/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.2905) | Acc: (89.00%) (25445/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.2903) | Acc: (89.00%) (26596/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.2904) | Acc: (89.00%) (27751/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.2910) | Acc: (89.00%) (28894/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.2911) | Acc: (89.00%) (30049/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.2907) | Acc: (89.00%) (31201/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.2899) | Acc: (89.00%) (32366/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.2888) | Acc: (90.00%) (33538/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.2894) | Acc: (90.00%) (34688/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.2904) | Acc: (90.00%) (35835/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.2903) | Acc: (90.00%) (36987/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.2908) | Acc: (90.00%) (38137/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.2905) | Acc: (90.00%) (39294/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.2897) | Acc: (90.00%) (40459/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.2899) | Acc: (90.00%) (41606/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.2895) | Acc: (90.00%) (42766/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.2909) | Acc: (90.00%) (43899/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.2919) | Acc: (90.00%) (45007/50000)
# TEST : Loss: (0.4749) | Acc: (84.00%) (8490/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1165, -0.1066, -0.0530],
          [-0.0342, -0.0634,  0.0490],
          [-0.0223, -0.1375, -0.2055]],

         [[-0.0248, -0.0636,  0.0048],
          [-0.1956, -0.0328,  0.0374],
          [ 0.0107,  0.0812, -0.0268]],

         [[-0.0614,  0.1037, -0.1877],
          [ 0.2240,  0.3668,  0.1714],
          [-0.0226,  0.2450,  0.1752]]],


        [[[ 0.2841, -0.1308,  0.1397],
          [ 0.1571, -0.0056, -0.0997],
          [-0.2154, -0.1518, -0.1929]],

         [[ 0.0730, -0.2053,  0.0437],
          [-0.0627,  0.3462, -0.1640],
          [ 0.1563,  0.0602,  0.1906]],

         [[-0.1496, -0.1761, -0.0567],
          [-0.1601,  0.1610, -0.0320],
          [-0.0420,  0.1094,  0.1877]]],


        [[[-0.0567, -0.0530, -0.0584],
          [-0.0508, -0.0940, -0.0433],
          [-0.0597, -0.0540,  0.0064]],

         [[ 0.0530,  0.1174,  0.0651],
          [-0.1114, -0.1075,  0.0099],
          [-0.1646,  0.0015,  0.0286]],

         [[-0.0655,  0.0660,  0.1819],
          [-0.0546, -0.0844,  0.1460],
          [-0.1543,  0.0338,  0.0686]]],


        ...,


        [[[ 0.0479,  0.0052, -0.0869],
          [ 0.0531,  0.0486, -0.0179],
          [-0.2048,  0.0049,  0.0474]],

         [[-0.1107, -0.2040,  0.0460],
          [ 0.1313, -0.0047, -0.1194],
          [ 0.1219, -0.0864,  0.0531]],

         [[ 0.0480,  0.0733,  0.1212],
          [ 0.3146,  0.3103,  0.1262],
          [ 0.2896,  0.2303,  0.1351]]],


        [[[ 0.2201,  0.1149,  0.0709],
          [ 0.0795, -0.0174, -0.0445],
          [-0.0574,  0.1363, -0.0458]],

         [[-0.2194, -0.3363, -0.0802],
          [-0.0466, -0.2982, -0.2479],
          [ 0.0442,  0.0050, -0.0770]],

         [[ 0.0605, -0.1261, -0.0450],
          [ 0.0112, -0.0391,  0.0279],
          [-0.0697,  0.0263,  0.0896]]],


        [[[-0.0580, -0.1861, -0.1347],
          [-0.1956, -0.4325, -0.2324],
          [ 0.1445, -0.1040, -0.0886]],

         [[ 0.1263, -0.1992, -0.0013],
          [ 0.0297, -0.1674,  0.0918],
          [ 0.1954,  0.2143, -0.0342]],

         [[ 0.0682, -0.1684,  0.1299],
          [ 0.1531,  0.0026,  0.0868],
          [-0.1095, -0.0398,  0.0487]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0031,  0.0010,  0.0017],
          [-0.0058, -0.0065, -0.0045],
          [-0.0097, -0.0117, -0.0091]],

         [[ 0.0022, -0.0002,  0.0004],
          [-0.0062, -0.0074, -0.0058],
          [-0.0102, -0.0128, -0.0103]],

         [[ 0.0064,  0.0044,  0.0045],
          [-0.0006, -0.0016, -0.0007],
          [-0.0043, -0.0064, -0.0044]]],


        [[[ 0.1584,  0.1758,  0.1677],
          [ 0.1835,  0.1595,  0.1421],
          [ 0.1030,  0.0907,  0.0928]],

         [[ 0.1593,  0.1836,  0.1808],
          [ 0.1927,  0.1739,  0.1582],
          [ 0.1150,  0.1010,  0.0991]],

         [[ 0.1632,  0.1796,  0.1722],
          [ 0.1767,  0.1579,  0.1399],
          [ 0.1006,  0.0797,  0.0795]]],


        [[[ 0.0030,  0.0035,  0.0028],
          [ 0.0010,  0.0014,  0.0017],
          [ 0.0010,  0.0012,  0.0019]],

         [[ 0.0026,  0.0032,  0.0023],
          [ 0.0009,  0.0014,  0.0016],
          [ 0.0012,  0.0013,  0.0020]],

         [[ 0.0031,  0.0037,  0.0029],
          [ 0.0015,  0.0019,  0.0020],
          [ 0.0015,  0.0016,  0.0022]]],


        ...,


        [[[ 0.0038,  0.0051,  0.0061],
          [-0.0009,  0.0005,  0.0004],
          [-0.0027, -0.0033, -0.0038]],

         [[ 0.0036,  0.0046,  0.0052],
          [ 0.0008,  0.0016,  0.0005],
          [-0.0009, -0.0018, -0.0033]],

         [[ 0.0019,  0.0038,  0.0050],
          [ 0.0005,  0.0020,  0.0014],
          [-0.0009, -0.0010, -0.0019]]],


        [[[ 0.0056,  0.0059,  0.0032],
          [ 0.0018,  0.0023,  0.0014],
          [ 0.0019,  0.0009,  0.0030]],

         [[ 0.0016,  0.0027,  0.0006],
          [-0.0014,  0.0004,  0.0006],
          [-0.0009, -0.0003,  0.0028]],

         [[ 0.0047,  0.0047,  0.0013],
          [ 0.0024,  0.0024,  0.0008],
          [ 0.0029,  0.0019,  0.0027]]],


        [[[-0.0009,  0.0031,  0.0054],
          [-0.0115, -0.0049, -0.0039],
          [-0.0062, -0.0005, -0.0011]],

         [[-0.0009,  0.0025,  0.0045],
          [-0.0106, -0.0043, -0.0038],
          [-0.0067, -0.0007, -0.0018]],

         [[-0.0021,  0.0013,  0.0022],
          [-0.0127, -0.0066, -0.0067],
          [-0.0128, -0.0066, -0.0074]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2584]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 44 | Batch_idx: 0 |  Loss: (0.1508) | Acc: (95.00%) (122/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.2566) | Acc: (91.00%) (1288/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.2763) | Acc: (90.00%) (2430/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.2731) | Acc: (90.00%) (3597/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.2717) | Acc: (90.00%) (4755/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.2631) | Acc: (90.00%) (5929/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.2662) | Acc: (90.00%) (7092/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.2690) | Acc: (90.00%) (8237/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.2687) | Acc: (90.00%) (9401/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.2672) | Acc: (90.00%) (10578/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.2699) | Acc: (90.00%) (11730/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.2686) | Acc: (90.00%) (12892/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.2687) | Acc: (90.00%) (14051/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.2687) | Acc: (90.00%) (15203/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.2680) | Acc: (90.00%) (16370/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.2692) | Acc: (90.00%) (17518/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.2677) | Acc: (90.00%) (18689/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.2683) | Acc: (90.00%) (19838/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.2696) | Acc: (90.00%) (20992/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.2694) | Acc: (90.00%) (22150/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.2678) | Acc: (90.00%) (23327/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.2678) | Acc: (90.00%) (24481/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.2673) | Acc: (90.00%) (25650/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.2674) | Acc: (90.00%) (26816/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.2670) | Acc: (90.00%) (27983/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.2684) | Acc: (90.00%) (29126/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.2685) | Acc: (90.00%) (30299/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.2684) | Acc: (90.00%) (31461/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.2685) | Acc: (90.00%) (32617/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.2685) | Acc: (90.00%) (33774/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.2680) | Acc: (90.00%) (34948/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.2689) | Acc: (90.00%) (36105/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.2682) | Acc: (90.00%) (37267/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.2681) | Acc: (90.00%) (38419/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.2693) | Acc: (90.00%) (39565/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.2693) | Acc: (90.00%) (40729/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.2691) | Acc: (90.00%) (41885/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.2686) | Acc: (90.00%) (43057/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.2690) | Acc: (90.00%) (44205/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.2697) | Acc: (90.00%) (45310/50000)
# TEST : Loss: (0.3569) | Acc: (88.00%) (8813/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1203, -0.1109, -0.0654],
          [-0.0336, -0.0660,  0.0371],
          [-0.0164, -0.1349, -0.2120]],

         [[-0.0255, -0.0665, -0.0066],
          [-0.1894, -0.0312,  0.0283],
          [ 0.0214,  0.0870, -0.0324]],

         [[-0.0635,  0.1010, -0.1960],
          [ 0.2275,  0.3678,  0.1623],
          [-0.0111,  0.2512,  0.1679]]],


        [[[ 0.2848, -0.1303,  0.1432],
          [ 0.1505, -0.0083, -0.1053],
          [-0.2224, -0.1592, -0.2002]],

         [[ 0.0692, -0.2093,  0.0398],
          [-0.0704,  0.3464, -0.1674],
          [ 0.1516,  0.0594,  0.1908]],

         [[-0.1530, -0.1763, -0.0528],
          [-0.1685,  0.1586, -0.0314],
          [-0.0439,  0.1082,  0.1858]]],


        [[[-0.0618, -0.0718, -0.0829],
          [-0.0548, -0.1049, -0.0560],
          [-0.0598, -0.0553,  0.0037]],

         [[ 0.0520,  0.1040,  0.0462],
          [-0.1079, -0.1105,  0.0029],
          [-0.1630, -0.0032,  0.0270]],

         [[-0.0625,  0.0600,  0.1652],
          [-0.0556, -0.0844,  0.1386],
          [-0.1537,  0.0298,  0.0671]]],


        ...,


        [[[ 0.0356, -0.0053, -0.1027],
          [ 0.0339,  0.0333, -0.0405],
          [-0.2248, -0.0147,  0.0173]],

         [[-0.1171, -0.2078,  0.0326],
          [ 0.1193, -0.0106, -0.1379],
          [ 0.1061, -0.0986,  0.0237]],

         [[ 0.0450,  0.0751,  0.1117],
          [ 0.3120,  0.3222,  0.1116],
          [ 0.2817,  0.2265,  0.1039]]],


        [[[ 0.2270,  0.1114,  0.0764],
          [ 0.0914, -0.0148, -0.0417],
          [-0.0457,  0.1405, -0.0447]],

         [[-0.2139, -0.3508, -0.0762],
          [-0.0367, -0.2957, -0.2417],
          [ 0.0522,  0.0109, -0.0695]],

         [[ 0.0712, -0.1300, -0.0410],
          [ 0.0288, -0.0257,  0.0348],
          [-0.0593,  0.0349,  0.0939]]],


        [[[-0.0618, -0.1916, -0.1426],
          [-0.2090, -0.4530, -0.2514],
          [ 0.1204, -0.1281, -0.1069]],

         [[ 0.1353, -0.1885,  0.0057],
          [ 0.0290, -0.1682,  0.0888],
          [ 0.1815,  0.2013, -0.0440]],

         [[ 0.0681, -0.1693,  0.1253],
          [ 0.1436, -0.0086,  0.0730],
          [-0.1285, -0.0591,  0.0281]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0030, -0.0006,  0.0005],
          [-0.0042, -0.0007, -0.0007],
          [-0.0029,  0.0005, -0.0004]],

         [[-0.0051, -0.0019, -0.0008],
          [-0.0057, -0.0015, -0.0015],
          [-0.0040,  0.0002, -0.0006]],

         [[-0.0048, -0.0015, -0.0007],
          [-0.0055, -0.0015, -0.0019],
          [-0.0044, -0.0000, -0.0009]]],


        [[[ 0.0072, -0.0046, -0.0150],
          [-0.0424, -0.0087, -0.0069],
          [-0.0220, -0.0000,  0.0404]],

         [[-0.0349, -0.0477, -0.0564],
          [-0.0787, -0.0533, -0.0565],
          [-0.0606, -0.0468, -0.0177]],

         [[-0.0365, -0.0342, -0.0405],
          [-0.0767, -0.0338, -0.0367],
          [-0.0598, -0.0296, -0.0021]]],


        [[[-0.0007, -0.0008, -0.0003],
          [-0.0001, -0.0002,  0.0001],
          [-0.0001, -0.0004, -0.0006]],

         [[-0.0011, -0.0013, -0.0007],
          [-0.0004, -0.0006, -0.0004],
          [-0.0004, -0.0008, -0.0010]],

         [[-0.0011, -0.0011, -0.0006],
          [-0.0004, -0.0006, -0.0004],
          [-0.0004, -0.0007, -0.0009]]],


        ...,


        [[[-0.0099, -0.0116, -0.0113],
          [-0.0106, -0.0113, -0.0104],
          [-0.0120, -0.0124, -0.0109]],

         [[-0.0051, -0.0072, -0.0077],
          [-0.0042, -0.0052, -0.0051],
          [-0.0044, -0.0049, -0.0037]],

         [[-0.0031, -0.0045, -0.0044],
          [-0.0030, -0.0036, -0.0026],
          [-0.0036, -0.0035, -0.0016]]],


        [[[-0.0038, -0.0059, -0.0059],
          [-0.0062, -0.0074, -0.0081],
          [-0.0146, -0.0182, -0.0194]],

         [[ 0.0001, -0.0021, -0.0025],
          [-0.0032, -0.0048, -0.0056],
          [-0.0127, -0.0166, -0.0178]],

         [[ 0.0052,  0.0021,  0.0015],
          [ 0.0007, -0.0014, -0.0023],
          [-0.0083, -0.0116, -0.0124]]],


        [[[-0.0063, -0.0055,  0.0012],
          [-0.0019, -0.0014,  0.0033],
          [-0.0123, -0.0116, -0.0049]],

         [[-0.0074, -0.0065, -0.0002],
          [-0.0033, -0.0027,  0.0019],
          [-0.0134, -0.0127, -0.0060]],

         [[-0.0094, -0.0087, -0.0031],
          [-0.0062, -0.0057, -0.0023],
          [-0.0152, -0.0145, -0.0096]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2575]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 45 | Batch_idx: 0 |  Loss: (0.1927) | Acc: (92.00%) (119/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.2364) | Acc: (91.00%) (1282/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.2838) | Acc: (89.00%) (2408/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.3191) | Acc: (88.00%) (3506/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.3274) | Acc: (88.00%) (4627/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.3260) | Acc: (88.00%) (5766/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.3316) | Acc: (88.00%) (6889/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.3304) | Acc: (88.00%) (8023/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.3285) | Acc: (88.00%) (9169/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.3259) | Acc: (88.00%) (10323/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.3226) | Acc: (88.00%) (11480/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.3205) | Acc: (88.00%) (12642/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.3174) | Acc: (89.00%) (13792/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.3156) | Acc: (89.00%) (14939/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.3104) | Acc: (89.00%) (16113/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.3084) | Acc: (89.00%) (17280/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.3065) | Acc: (89.00%) (18440/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.3039) | Acc: (89.00%) (19603/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.3021) | Acc: (89.00%) (20757/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.3005) | Acc: (89.00%) (21922/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.2987) | Acc: (89.00%) (23093/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.2967) | Acc: (89.00%) (24266/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.2960) | Acc: (89.00%) (25417/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.2942) | Acc: (89.00%) (26572/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.2926) | Acc: (89.00%) (27737/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.2909) | Acc: (89.00%) (28915/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.2890) | Acc: (90.00%) (30090/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.2890) | Acc: (90.00%) (31242/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.2885) | Acc: (90.00%) (32386/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.2867) | Acc: (90.00%) (33564/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.2858) | Acc: (90.00%) (34726/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.2843) | Acc: (90.00%) (35900/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.2833) | Acc: (90.00%) (37071/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.2814) | Acc: (90.00%) (38256/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.2810) | Acc: (90.00%) (39427/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.2800) | Acc: (90.00%) (40607/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.2788) | Acc: (90.00%) (41782/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.2780) | Acc: (90.00%) (42950/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.2766) | Acc: (90.00%) (44130/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.2751) | Acc: (90.00%) (45276/50000)
# TEST : Loss: (0.3355) | Acc: (88.00%) (8886/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1188, -0.1101, -0.0648],
          [-0.0320, -0.0647,  0.0380],
          [-0.0158, -0.1335, -0.2097]],

         [[-0.0235, -0.0650, -0.0056],
          [-0.1859, -0.0292,  0.0300],
          [ 0.0227,  0.0878, -0.0306]],

         [[-0.0618,  0.1006, -0.1949],
          [ 0.2275,  0.3663,  0.1620],
          [-0.0106,  0.2501,  0.1674]]],


        [[[ 0.2881, -0.1276,  0.1443],
          [ 0.1526, -0.0069, -0.1047],
          [-0.2208, -0.1576, -0.2008]],

         [[ 0.0736, -0.2056,  0.0421],
          [-0.0673,  0.3489, -0.1649],
          [ 0.1534,  0.0622,  0.1916]],

         [[-0.1492, -0.1732, -0.0512],
          [-0.1666,  0.1597, -0.0302],
          [-0.0426,  0.1091,  0.1851]]],


        [[[-0.0589, -0.0688, -0.0799],
          [-0.0507, -0.1002, -0.0536],
          [-0.0552, -0.0524,  0.0041]],

         [[ 0.0517,  0.1021,  0.0466],
          [-0.1006, -0.1049,  0.0041],
          [-0.1523, -0.0020,  0.0272]],

         [[-0.0591,  0.0596,  0.1626],
          [-0.0517, -0.0802,  0.1358],
          [-0.1448,  0.0294,  0.0657]]],


        ...,


        [[[ 0.0376, -0.0031, -0.1001],
          [ 0.0360,  0.0355, -0.0385],
          [-0.2207, -0.0119,  0.0195]],

         [[-0.1143, -0.2043,  0.0344],
          [ 0.1201, -0.0087, -0.1359],
          [ 0.1074, -0.0961,  0.0245]],

         [[ 0.0469,  0.0767,  0.1126],
          [ 0.3088,  0.3189,  0.1105],
          [ 0.2793,  0.2244,  0.1028]]],


        [[[ 0.2257,  0.1097,  0.0735],
          [ 0.0909, -0.0157, -0.0448],
          [-0.0438,  0.1411, -0.0445]],

         [[-0.2109, -0.3454, -0.0762],
          [-0.0355, -0.2917, -0.2416],
          [ 0.0544,  0.0140, -0.0669]],

         [[ 0.0693, -0.1299, -0.0429],
          [ 0.0277, -0.0265,  0.0302],
          [-0.0576,  0.0365,  0.0941]]],


        [[[-0.0611, -0.1872, -0.1414],
          [-0.2085, -0.4476, -0.2516],
          [ 0.1195, -0.1272, -0.1081]],

         [[ 0.1346, -0.1863,  0.0059],
          [ 0.0281, -0.1673,  0.0872],
          [ 0.1805,  0.2006, -0.0450]],

         [[ 0.0684, -0.1670,  0.1257],
          [ 0.1426, -0.0084,  0.0721],
          [-0.1284, -0.0587,  0.0273]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2828]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0039]], device='cuda:0')

Epoch: 46 | Batch_idx: 0 |  Loss: (0.2363) | Acc: (92.00%) (118/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.2517) | Acc: (91.00%) (1291/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.2457) | Acc: (91.00%) (2467/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.2500) | Acc: (91.00%) (3643/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.2473) | Acc: (91.00%) (4818/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.2556) | Acc: (91.00%) (5971/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.2613) | Acc: (91.00%) (7120/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.2590) | Acc: (91.00%) (8297/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.2618) | Acc: (91.00%) (9467/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.2575) | Acc: (91.00%) (10647/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.2559) | Acc: (91.00%) (11815/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.2536) | Acc: (91.00%) (12991/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.2502) | Acc: (91.00%) (14183/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.2506) | Acc: (91.00%) (15353/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.2509) | Acc: (91.00%) (16526/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.2485) | Acc: (91.00%) (17725/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.2488) | Acc: (91.00%) (18894/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.2491) | Acc: (91.00%) (20061/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.2475) | Acc: (91.00%) (21238/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.2475) | Acc: (91.00%) (22412/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.2471) | Acc: (91.00%) (23584/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.2462) | Acc: (91.00%) (24767/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.2454) | Acc: (91.00%) (25942/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.2452) | Acc: (91.00%) (27125/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.2452) | Acc: (91.00%) (28306/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.2446) | Acc: (91.00%) (29489/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.2458) | Acc: (91.00%) (30644/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.2444) | Acc: (91.00%) (31829/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.2443) | Acc: (91.00%) (33002/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.2445) | Acc: (91.00%) (34170/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.2452) | Acc: (91.00%) (35337/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.2453) | Acc: (91.00%) (36513/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.2452) | Acc: (91.00%) (37687/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.2445) | Acc: (91.00%) (38871/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.2437) | Acc: (91.00%) (40061/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.2438) | Acc: (91.00%) (41235/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.2434) | Acc: (91.00%) (42415/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.2426) | Acc: (91.00%) (43598/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.2435) | Acc: (91.00%) (44762/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.2435) | Acc: (91.00%) (45901/50000)
# TEST : Loss: (0.3245) | Acc: (89.00%) (8906/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1178, -0.1092, -0.0643],
          [-0.0318, -0.0642,  0.0377],
          [-0.0157, -0.1326, -0.2081]],

         [[-0.0233, -0.0645, -0.0056],
          [-0.1845, -0.0290,  0.0297],
          [ 0.0225,  0.0872, -0.0303]],

         [[-0.0613,  0.0998, -0.1933],
          [ 0.2256,  0.3633,  0.1606],
          [-0.0105,  0.2480,  0.1660]]],


        [[[ 0.2878, -0.1274,  0.1442],
          [ 0.1524, -0.0069, -0.1046],
          [-0.2206, -0.1574, -0.2006]],

         [[ 0.0736, -0.2054,  0.0421],
          [-0.0672,  0.3485, -0.1647],
          [ 0.1532,  0.0621,  0.1914]],

         [[-0.1490, -0.1730, -0.0511],
          [-0.1664,  0.1595, -0.0301],
          [-0.0425,  0.1090,  0.1848]]],


        [[[-0.0563, -0.0662, -0.0774],
          [-0.0473, -0.0948, -0.0516],
          [-0.0513, -0.0495,  0.0040]],

         [[ 0.0495,  0.0983,  0.0451],
          [-0.0942, -0.0996,  0.0039],
          [-0.1420, -0.0019,  0.0262]],

         [[-0.0567,  0.0574,  0.1575],
          [-0.0488, -0.0764,  0.1309],
          [-0.1362,  0.0279,  0.0633]]],


        ...,


        [[[ 0.0374, -0.0031, -0.0995],
          [ 0.0357,  0.0352, -0.0382],
          [-0.2191, -0.0118,  0.0193]],

         [[-0.1133, -0.2026,  0.0342],
          [ 0.1189, -0.0086, -0.1347],
          [ 0.1064, -0.0952,  0.0243]],

         [[ 0.0463,  0.0758,  0.1115],
          [ 0.3019,  0.3120,  0.1088],
          [ 0.2732,  0.2196,  0.1012]]],


        [[[ 0.2241,  0.1089,  0.0729],
          [ 0.0902, -0.0156, -0.0444],
          [-0.0435,  0.1402, -0.0442]],

         [[-0.2085, -0.3394, -0.0750],
          [-0.0351, -0.2871, -0.2375],
          [ 0.0540,  0.0139, -0.0662]],

         [[ 0.0685, -0.1276, -0.0422],
          [ 0.0274, -0.0260,  0.0297],
          [-0.0571,  0.0361,  0.0930]]],


        [[[-0.0606, -0.1845, -0.1398],
          [-0.2068, -0.4408, -0.2486],
          [ 0.1187, -0.1263, -0.1073]],

         [[ 0.1338, -0.1849,  0.0059],
          [ 0.0280, -0.1661,  0.0866],
          [ 0.1796,  0.1995, -0.0447]],

         [[ 0.0680, -0.1661,  0.1250],
          [ 0.1418, -0.0084,  0.0717],
          [-0.1278, -0.0584,  0.0272]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2823]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0229]], device='cuda:0')

Epoch: 47 | Batch_idx: 0 |  Loss: (0.3503) | Acc: (87.00%) (112/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.2625) | Acc: (91.00%) (1283/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.2544) | Acc: (91.00%) (2470/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.2534) | Acc: (91.00%) (3640/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.2462) | Acc: (91.00%) (4826/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.2505) | Acc: (91.00%) (5980/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.2489) | Acc: (91.00%) (7146/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.2463) | Acc: (91.00%) (8333/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.2465) | Acc: (91.00%) (9518/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.2429) | Acc: (91.00%) (10706/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.2423) | Acc: (91.00%) (11884/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.2419) | Acc: (91.00%) (13058/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.2400) | Acc: (91.00%) (14246/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.2422) | Acc: (91.00%) (15419/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.2408) | Acc: (92.00%) (16607/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.2411) | Acc: (91.00%) (17774/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.2408) | Acc: (91.00%) (18950/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.2407) | Acc: (91.00%) (20135/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.2404) | Acc: (92.00%) (21323/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.2395) | Acc: (92.00%) (22506/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.2389) | Acc: (92.00%) (23693/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.2392) | Acc: (92.00%) (24863/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.2391) | Acc: (92.00%) (26034/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.2404) | Acc: (91.00%) (27192/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.2406) | Acc: (91.00%) (28369/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.2416) | Acc: (91.00%) (29539/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.2424) | Acc: (91.00%) (30713/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.2424) | Acc: (91.00%) (31886/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.2425) | Acc: (91.00%) (33067/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.2423) | Acc: (91.00%) (34259/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.2426) | Acc: (91.00%) (35433/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.2420) | Acc: (91.00%) (36623/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.2414) | Acc: (92.00%) (37813/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.2409) | Acc: (92.00%) (38997/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.2402) | Acc: (92.00%) (40195/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.2411) | Acc: (92.00%) (41360/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.2411) | Acc: (92.00%) (42534/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.2415) | Acc: (92.00%) (43694/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.2416) | Acc: (92.00%) (44872/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.2418) | Acc: (92.00%) (46004/50000)
# TEST : Loss: (0.3221) | Acc: (89.00%) (8916/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1167, -0.1081, -0.0637],
          [-0.0315, -0.0636,  0.0373],
          [-0.0156, -0.1314, -0.2063]],

         [[-0.0231, -0.0639, -0.0055],
          [-0.1827, -0.0287,  0.0295],
          [ 0.0223,  0.0864, -0.0300]],

         [[-0.0607,  0.0988, -0.1913],
          [ 0.2233,  0.3596,  0.1590],
          [-0.0104,  0.2455,  0.1643]]],


        [[[ 0.2874, -0.1273,  0.1440],
          [ 0.1522, -0.0069, -0.1045],
          [-0.2203, -0.1572, -0.2003]],

         [[ 0.0735, -0.2051,  0.0420],
          [-0.0671,  0.3480, -0.1645],
          [ 0.1530,  0.0620,  0.1911]],

         [[-0.1488, -0.1728, -0.0511],
          [-0.1662,  0.1593, -0.0301],
          [-0.0425,  0.1088,  0.1846]]],


        [[[-0.0534, -0.0631, -0.0744],
          [-0.0434, -0.0887, -0.0493],
          [-0.0469, -0.0462,  0.0038]],

         [[ 0.0470,  0.0938,  0.0435],
          [-0.0870, -0.0936,  0.0038],
          [-0.1304, -0.0017,  0.0251]],

         [[-0.0539,  0.0548,  0.1514],
          [-0.0456, -0.0720,  0.1251],
          [-0.1265,  0.0262,  0.0604]]],


        ...,


        [[[ 0.0371, -0.0031, -0.0987],
          [ 0.0354,  0.0349, -0.0379],
          [-0.2173, -0.0117,  0.0192]],

         [[-0.1122, -0.2006,  0.0339],
          [ 0.1175, -0.0085, -0.1333],
          [ 0.1051, -0.0941,  0.0241]],

         [[ 0.0457,  0.0747,  0.1101],
          [ 0.2938,  0.3038,  0.1068],
          [ 0.2660,  0.2139,  0.0993]]],


        [[[ 0.2221,  0.1078,  0.0722],
          [ 0.0895, -0.0155, -0.0440],
          [-0.0432,  0.1390, -0.0438]],

         [[-0.2056, -0.3324, -0.0735],
          [-0.0347, -0.2816, -0.2326],
          [ 0.0534,  0.0137, -0.0654]],

         [[ 0.0675, -0.1249, -0.0414],
          [ 0.0270, -0.0255,  0.0290],
          [-0.0565,  0.0356,  0.0917]]],


        [[[-0.0599, -0.1813, -0.1379],
          [-0.2046, -0.4326, -0.2450],
          [ 0.1179, -0.1251, -0.1064]],

         [[ 0.1328, -0.1833,  0.0058],
          [ 0.0277, -0.1646,  0.0859],
          [ 0.1786,  0.1981, -0.0444]],

         [[ 0.0675, -0.1649,  0.1241],
          [ 0.1409, -0.0083,  0.0712],
          [-0.1270, -0.0580,  0.0270]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2718]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0252]], device='cuda:0')

Epoch: 48 | Batch_idx: 0 |  Loss: (0.2869) | Acc: (89.00%) (115/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.2429) | Acc: (92.00%) (1299/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.2386) | Acc: (92.00%) (2493/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.2357) | Acc: (92.00%) (3674/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.2470) | Acc: (92.00%) (4836/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.2468) | Acc: (92.00%) (6007/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.2491) | Acc: (91.00%) (7173/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.2462) | Acc: (92.00%) (8366/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.2474) | Acc: (91.00%) (9538/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.2475) | Acc: (91.00%) (10703/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.2466) | Acc: (91.00%) (11880/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.2444) | Acc: (91.00%) (13061/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.2440) | Acc: (91.00%) (14244/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.2441) | Acc: (91.00%) (15419/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.2436) | Acc: (91.00%) (16598/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.2420) | Acc: (92.00%) (17787/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.2416) | Acc: (91.00%) (18955/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.2411) | Acc: (91.00%) (20131/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.2427) | Acc: (91.00%) (21307/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.2440) | Acc: (91.00%) (22465/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.2444) | Acc: (91.00%) (23635/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.2445) | Acc: (91.00%) (24811/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.2457) | Acc: (91.00%) (25976/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.2469) | Acc: (91.00%) (27142/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.2468) | Acc: (91.00%) (28327/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.2461) | Acc: (91.00%) (29507/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.2461) | Acc: (91.00%) (30675/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.2456) | Acc: (91.00%) (31863/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.2453) | Acc: (91.00%) (33047/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.2457) | Acc: (91.00%) (34214/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.2458) | Acc: (91.00%) (35389/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.2454) | Acc: (91.00%) (36566/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.2455) | Acc: (91.00%) (37748/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.2459) | Acc: (91.00%) (38927/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.2457) | Acc: (91.00%) (40109/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.2456) | Acc: (91.00%) (41279/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.2458) | Acc: (91.00%) (42457/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.2459) | Acc: (91.00%) (43637/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.2466) | Acc: (91.00%) (44802/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.2470) | Acc: (91.00%) (45936/50000)
# TEST : Loss: (0.3196) | Acc: (89.00%) (8914/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1153, -0.1069, -0.0629],
          [-0.0312, -0.0629,  0.0369],
          [-0.0154, -0.1300, -0.2041]],

         [[-0.0228, -0.0631, -0.0054],
          [-0.1807, -0.0284,  0.0291],
          [ 0.0220,  0.0854, -0.0297]],

         [[-0.0600,  0.0976, -0.1890],
          [ 0.2206,  0.3552,  0.1570],
          [-0.0103,  0.2425,  0.1623]]],


        [[[ 0.2869, -0.1271,  0.1437],
          [ 0.1520, -0.0069, -0.1043],
          [-0.2199, -0.1570, -0.2000]],

         [[ 0.0733, -0.2047,  0.0420],
          [-0.0670,  0.3473, -0.1642],
          [ 0.1527,  0.0619,  0.1908]],

         [[-0.1485, -0.1724, -0.0510],
          [-0.1659,  0.1590, -0.0300],
          [-0.0424,  0.1086,  0.1842]]],


        [[[-0.0500, -0.0596, -0.0710],
          [-0.0392, -0.0819, -0.0467],
          [-0.0420, -0.0425,  0.0036]],

         [[ 0.0441,  0.0887,  0.0415],
          [-0.0790, -0.0867,  0.0036],
          [-0.1175, -0.0016,  0.0238]],

         [[-0.0506,  0.0518,  0.1444],
          [-0.0420, -0.0671,  0.1185],
          [-0.1156,  0.0242,  0.0571]]],


        ...,


        [[[ 0.0367, -0.0030, -0.0978],
          [ 0.0351,  0.0346, -0.0375],
          [-0.2150, -0.0116,  0.0190]],

         [[-0.1108, -0.1982,  0.0335],
          [ 0.1158, -0.0084, -0.1315],
          [ 0.1036, -0.0928,  0.0237]],

         [[ 0.0449,  0.0734,  0.1084],
          [ 0.2842,  0.2941,  0.1044],
          [ 0.2575,  0.2072,  0.0971]]],


        [[[ 0.2198,  0.1066,  0.0714],
          [ 0.0886, -0.0153, -0.0435],
          [-0.0428,  0.1376, -0.0434]],

         [[-0.2022, -0.3240, -0.0717],
          [-0.0341, -0.2751, -0.2267],
          [ 0.0528,  0.0135, -0.0644]],

         [[ 0.0663, -0.1217, -0.0404],
          [ 0.0265, -0.0249,  0.0283],
          [-0.0557,  0.0351,  0.0902]]],


        [[[-0.0592, -0.1775, -0.1357],
          [-0.2021, -0.4229, -0.2407],
          [ 0.1169, -0.1237, -0.1052]],

         [[ 0.1316, -0.1813,  0.0058],
          [ 0.0275, -0.1628,  0.0850],
          [ 0.1772,  0.1965, -0.0440]],

         [[ 0.0670, -0.1635,  0.1231],
          [ 0.1398, -0.0082,  0.0706],
          [-0.1261, -0.0576,  0.0268]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2841]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0456]], device='cuda:0')

Epoch: 49 | Batch_idx: 0 |  Loss: (0.3613) | Acc: (89.00%) (115/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.2575) | Acc: (91.00%) (1291/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.2570) | Acc: (91.00%) (2461/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.2605) | Acc: (91.00%) (3630/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.2619) | Acc: (91.00%) (4792/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.2573) | Acc: (91.00%) (5978/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.2533) | Acc: (91.00%) (7165/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.2533) | Acc: (91.00%) (8329/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.2581) | Acc: (91.00%) (9480/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.2552) | Acc: (91.00%) (10659/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.2539) | Acc: (91.00%) (11839/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.2551) | Acc: (91.00%) (13000/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.2541) | Acc: (91.00%) (14181/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.2554) | Acc: (91.00%) (15356/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.2543) | Acc: (91.00%) (16530/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.2542) | Acc: (91.00%) (17715/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.2526) | Acc: (91.00%) (18911/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.2529) | Acc: (91.00%) (20080/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.2551) | Acc: (91.00%) (21233/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.2559) | Acc: (91.00%) (22397/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.2549) | Acc: (91.00%) (23580/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.2545) | Acc: (91.00%) (24760/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.2560) | Acc: (91.00%) (25921/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.2571) | Acc: (91.00%) (27084/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.2577) | Acc: (91.00%) (28261/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.2572) | Acc: (91.00%) (29453/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.2568) | Acc: (91.00%) (30628/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.2567) | Acc: (91.00%) (31806/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.2577) | Acc: (91.00%) (32987/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.2577) | Acc: (91.00%) (34157/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.2576) | Acc: (91.00%) (35330/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.2569) | Acc: (91.00%) (36517/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.2572) | Acc: (91.00%) (37675/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.2573) | Acc: (91.00%) (38838/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.2570) | Acc: (91.00%) (40015/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.2563) | Acc: (91.00%) (41204/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.2563) | Acc: (91.00%) (42380/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.2569) | Acc: (91.00%) (43552/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.2576) | Acc: (91.00%) (44714/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.2571) | Acc: (91.00%) (45856/50000)
# TEST : Loss: (0.3241) | Acc: (89.00%) (8908/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1136, -0.1053, -0.0620],
          [-0.0307, -0.0621,  0.0364],
          [-0.0152, -0.1283, -0.2014]],

         [[-0.0225, -0.0622, -0.0054],
          [-0.1781, -0.0280,  0.0287],
          [ 0.0217,  0.0843, -0.0293]],

         [[-0.0591,  0.0962, -0.1862],
          [ 0.2173,  0.3499,  0.1547],
          [-0.0101,  0.2388,  0.1598]]],


        [[[ 0.2864, -0.1268,  0.1435],
          [ 0.1517, -0.0069, -0.1041],
          [-0.2194, -0.1566, -0.1996]],

         [[ 0.0732, -0.2043,  0.0419],
          [-0.0669,  0.3466, -0.1639],
          [ 0.1524,  0.0618,  0.1903]],

         [[-0.1482, -0.1721, -0.0509],
          [-0.1655,  0.1586, -0.0300],
          [-0.0423,  0.1084,  0.1838]]],


        [[[-0.0462, -0.0555, -0.0671],
          [-0.0345, -0.0742, -0.0436],
          [-0.0367, -0.0383,  0.0034]],

         [[ 0.0408,  0.0829,  0.0392],
          [-0.0703, -0.0790,  0.0034],
          [-0.1036, -0.0015,  0.0222]],

         [[-0.0470,  0.0484,  0.1363],
          [-0.0379, -0.0615,  0.1109],
          [-0.1036,  0.0221,  0.0533]]],


        ...,


        [[[ 0.0363, -0.0030, -0.0967],
          [ 0.0346,  0.0341, -0.0371],
          [-0.2123, -0.0115,  0.0187]],

         [[-0.1091, -0.1953,  0.0330],
          [ 0.1138, -0.0083, -0.1294],
          [ 0.1018, -0.0912,  0.0234]],

         [[ 0.0439,  0.0719,  0.1065],
          [ 0.2730,  0.2827,  0.1016],
          [ 0.2475,  0.1993,  0.0944]]],


        [[[ 0.2169,  0.1051,  0.0704],
          [ 0.0875, -0.0151, -0.0429],
          [-0.0423,  0.1360, -0.0428]],

         [[-0.1981, -0.3140, -0.0696],
          [-0.0334, -0.2673, -0.2198],
          [ 0.0520,  0.0133, -0.0632]],

         [[ 0.0649, -0.1180, -0.0392],
          [ 0.0259, -0.0241,  0.0274],
          [-0.0548,  0.0344,  0.0884]]],


        [[[-0.0583, -0.1730, -0.1330],
          [-0.1991, -0.4113, -0.2356],
          [ 0.1156, -0.1220, -0.1039]],

         [[ 0.1302, -0.1790,  0.0057],
          [ 0.0272, -0.1607,  0.0840],
          [ 0.1757,  0.1945, -0.0436]],

         [[ 0.0664, -0.1618,  0.1219],
          [ 0.1385, -0.0081,  0.0699],
          [-0.1250, -0.0571,  0.0266]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2857]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0286]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 50 | Batch_idx: 0 |  Loss: (0.2554) | Acc: (90.00%) (116/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.3766) | Acc: (86.00%) (1219/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.4187) | Acc: (86.00%) (2314/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.4587) | Acc: (84.00%) (3361/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.4861) | Acc: (83.00%) (4393/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.4949) | Acc: (83.00%) (5459/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.4949) | Acc: (83.00%) (6520/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.4980) | Acc: (83.00%) (7569/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.4975) | Acc: (83.00%) (8636/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.4968) | Acc: (83.00%) (9707/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.4964) | Acc: (83.00%) (10770/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.4978) | Acc: (83.00%) (11824/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.4901) | Acc: (83.00%) (12930/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.4909) | Acc: (83.00%) (14011/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.4858) | Acc: (83.00%) (15114/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.4814) | Acc: (83.00%) (16214/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.4788) | Acc: (83.00%) (17309/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.4767) | Acc: (84.00%) (18410/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.4781) | Acc: (84.00%) (19476/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.4779) | Acc: (84.00%) (20563/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.4758) | Acc: (84.00%) (21661/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.4737) | Acc: (84.00%) (22753/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.4714) | Acc: (84.00%) (23854/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.4680) | Acc: (84.00%) (24968/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.4647) | Acc: (84.00%) (26080/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.4617) | Acc: (84.00%) (27179/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.4586) | Acc: (84.00%) (28308/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4548) | Acc: (84.00%) (29441/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4546) | Acc: (84.00%) (30526/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4534) | Acc: (84.00%) (31623/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4507) | Acc: (84.00%) (32745/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4490) | Acc: (85.00%) (33860/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4457) | Acc: (85.00%) (34999/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4427) | Acc: (85.00%) (36134/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4413) | Acc: (85.00%) (37236/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.4394) | Acc: (85.00%) (38363/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4363) | Acc: (85.00%) (39504/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4349) | Acc: (85.00%) (40612/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4334) | Acc: (85.00%) (41719/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4302) | Acc: (85.00%) (42819/50000)
# TEST : Loss: (0.4319) | Acc: (85.00%) (8545/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1134, -0.1094, -0.0753],
          [-0.0294, -0.0694,  0.0196],
          [-0.0085, -0.1321, -0.2125]],

         [[-0.0287, -0.0728, -0.0255],
          [-0.1764, -0.0334,  0.0128],
          [ 0.0284,  0.0843, -0.0380]],

         [[-0.0611,  0.0988, -0.1938],
          [ 0.2233,  0.3617,  0.1562],
          [ 0.0048,  0.2572,  0.1682]]],


        [[[ 0.2887, -0.1247,  0.1511],
          [ 0.1511, -0.0136, -0.1116],
          [-0.2110, -0.1717, -0.2041]],

         [[ 0.0605, -0.2170,  0.0337],
          [-0.0721,  0.3461, -0.1733],
          [ 0.1697,  0.0660,  0.1936]],

         [[-0.1619, -0.1836, -0.0563],
          [-0.1813,  0.1490, -0.0324],
          [-0.0298,  0.1049,  0.1886]]],


        [[[-0.0372, -0.0647, -0.0682],
          [-0.0432, -0.0803, -0.0551],
          [-0.0567, -0.0539, -0.0108]],

         [[ 0.0543,  0.0707,  0.0358],
          [-0.0607, -0.0783, -0.0067],
          [-0.1063, -0.0133,  0.0121]],

         [[-0.0279,  0.0461,  0.1382],
          [-0.0399, -0.0587,  0.1039],
          [-0.1215,  0.0017,  0.0403]]],


        ...,


        [[[ 0.0551,  0.0074, -0.0887],
          [ 0.0582,  0.0489, -0.0348],
          [-0.1823,  0.0101,  0.0222]],

         [[-0.0986, -0.1925,  0.0261],
          [ 0.1269, -0.0025, -0.1438],
          [ 0.1167, -0.0814,  0.0053]],

         [[ 0.0550,  0.0864,  0.1188],
          [ 0.3023,  0.3211,  0.1182],
          [ 0.2775,  0.2327,  0.0938]]],


        [[[ 0.2103,  0.0907,  0.0631],
          [ 0.0768, -0.0434, -0.0669],
          [-0.0355,  0.1255, -0.0519]],

         [[-0.2082, -0.3277, -0.0647],
          [-0.0523, -0.3102, -0.2526],
          [ 0.0575,  0.0040, -0.0713]],

         [[ 0.0703, -0.1137, -0.0100],
          [ 0.0179, -0.0554,  0.0140],
          [-0.0372,  0.0369,  0.0958]]],


        [[[-0.0449, -0.1710, -0.1483],
          [-0.1921, -0.4177, -0.2583],
          [ 0.1333, -0.0957, -0.0953]],

         [[ 0.1630, -0.1553,  0.0041],
          [ 0.0565, -0.1423,  0.0811],
          [ 0.2015,  0.2226, -0.0294]],

         [[ 0.0811, -0.1546,  0.1118],
          [ 0.1498, -0.0036,  0.0630],
          [-0.1117, -0.0412,  0.0329]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0048,  0.0051,  0.0049],
          [ 0.0073,  0.0085,  0.0076],
          [ 0.0091,  0.0099,  0.0082]],

         [[ 0.0018,  0.0020,  0.0022],
          [ 0.0047,  0.0058,  0.0052],
          [ 0.0064,  0.0071,  0.0060]],

         [[ 0.0008,  0.0014,  0.0017],
          [ 0.0036,  0.0052,  0.0050],
          [ 0.0051,  0.0066,  0.0058]]],


        [[[-0.1107, -0.1433, -0.1257],
          [-0.0831, -0.1049, -0.0699],
          [-0.0379, -0.0683, -0.0741]],

         [[-0.0863, -0.1201, -0.1051],
          [-0.0642, -0.0871, -0.0531],
          [-0.0327, -0.0589, -0.0619]],

         [[-0.0622, -0.0870, -0.0784],
          [-0.0363, -0.0544, -0.0345],
          [-0.0036, -0.0265, -0.0330]]],


        [[[ 0.0006,  0.0006,  0.0009],
          [ 0.0004,  0.0003,  0.0007],
          [ 0.0002,  0.0000,  0.0005]],

         [[ 0.0008,  0.0007,  0.0011],
          [ 0.0004,  0.0003,  0.0008],
          [ 0.0003,  0.0002,  0.0007]],

         [[ 0.0003,  0.0002,  0.0008],
          [ 0.0001, -0.0000,  0.0005],
          [ 0.0000, -0.0001,  0.0003]]],


        ...,


        [[[ 0.0213,  0.0208,  0.0222],
          [ 0.0210,  0.0212,  0.0228],
          [ 0.0179,  0.0190,  0.0193]],

         [[ 0.0133,  0.0119,  0.0132],
          [ 0.0122,  0.0120,  0.0131],
          [ 0.0095,  0.0097,  0.0092]],

         [[ 0.0048,  0.0032,  0.0044],
          [ 0.0044,  0.0034,  0.0045],
          [ 0.0017,  0.0017,  0.0012]]],


        [[[ 0.0110,  0.0048,  0.0083],
          [ 0.0065, -0.0020, -0.0008],
          [ 0.0098,  0.0009, -0.0010]],

         [[ 0.0100,  0.0050,  0.0077],
          [ 0.0066, -0.0007,  0.0000],
          [ 0.0115,  0.0039,  0.0019]],

         [[ 0.0068,  0.0033,  0.0061],
          [ 0.0038, -0.0015, -0.0002],
          [ 0.0075,  0.0019,  0.0011]]],


        [[[ 0.0018, -0.0023, -0.0002],
          [-0.0021, -0.0072, -0.0056],
          [-0.0110, -0.0141, -0.0133]],

         [[-0.0060, -0.0087, -0.0075],
          [-0.0084, -0.0123, -0.0107],
          [-0.0148, -0.0173, -0.0165]],

         [[-0.0121, -0.0132, -0.0116],
          [-0.0139, -0.0154, -0.0130],
          [-0.0190, -0.0199, -0.0182]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2883]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 51 | Batch_idx: 0 |  Loss: (0.3918) | Acc: (87.00%) (112/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.3456) | Acc: (88.00%) (1252/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.3430) | Acc: (88.00%) (2375/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.3349) | Acc: (88.00%) (3514/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.3300) | Acc: (88.00%) (4662/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.3280) | Acc: (88.00%) (5798/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.3288) | Acc: (88.00%) (6922/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.3317) | Acc: (88.00%) (8048/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.3358) | Acc: (88.00%) (9165/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.3384) | Acc: (88.00%) (10290/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.3431) | Acc: (88.00%) (11412/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.3431) | Acc: (88.00%) (12533/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.3414) | Acc: (88.00%) (13672/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.3437) | Acc: (88.00%) (14785/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.3435) | Acc: (88.00%) (15914/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.3410) | Acc: (88.00%) (17053/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.3412) | Acc: (88.00%) (18187/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.3409) | Acc: (88.00%) (19310/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.3417) | Acc: (88.00%) (20447/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.3399) | Acc: (88.00%) (21600/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.3403) | Acc: (88.00%) (22727/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.3379) | Acc: (88.00%) (23875/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.3374) | Acc: (88.00%) (25015/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.3364) | Acc: (88.00%) (26167/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.3347) | Acc: (88.00%) (27328/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.3330) | Acc: (88.00%) (28478/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.3324) | Acc: (88.00%) (29621/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.3323) | Acc: (88.00%) (30763/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.3322) | Acc: (88.00%) (31907/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.3322) | Acc: (88.00%) (33044/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.3311) | Acc: (88.00%) (34188/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.3315) | Acc: (88.00%) (35325/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.3316) | Acc: (88.00%) (36459/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.3305) | Acc: (88.00%) (37620/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.3296) | Acc: (88.00%) (38765/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.3289) | Acc: (88.00%) (39917/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.3278) | Acc: (88.00%) (41072/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.3268) | Acc: (88.00%) (42227/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.3263) | Acc: (88.00%) (43387/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.3266) | Acc: (88.00%) (44486/50000)
# TEST : Loss: (0.3632) | Acc: (88.00%) (8832/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1161, -0.1160, -0.0815],
          [-0.0343, -0.0744,  0.0196],
          [-0.0096, -0.1327, -0.2041]],

         [[-0.0316, -0.0783, -0.0314],
          [-0.1778, -0.0354,  0.0152],
          [ 0.0263,  0.0840, -0.0288]],

         [[-0.0619,  0.0937, -0.1985],
          [ 0.2224,  0.3605,  0.1605],
          [ 0.0048,  0.2588,  0.1789]]],


        [[[ 0.2949, -0.1071,  0.1732],
          [ 0.1528, -0.0098, -0.1067],
          [-0.2115, -0.1717, -0.2010]],

         [[ 0.0587, -0.2085,  0.0450],
          [-0.0679,  0.3510, -0.1684],
          [ 0.1747,  0.0729,  0.2001]],

         [[-0.1711, -0.1866, -0.0541],
          [-0.1850,  0.1437, -0.0360],
          [-0.0309,  0.1069,  0.1905]]],


        [[[-0.0393, -0.0696, -0.0746],
          [-0.0570, -0.0817, -0.0576],
          [-0.0669, -0.0463, -0.0010]],

         [[ 0.0373,  0.0531,  0.0214],
          [-0.0779, -0.0829, -0.0156],
          [-0.1110, -0.0095,  0.0156]],

         [[-0.0328,  0.0372,  0.1239],
          [-0.0480, -0.0573,  0.0925],
          [-0.1151,  0.0112,  0.0441]]],


        ...,


        [[[ 0.0360, -0.0070, -0.0912],
          [ 0.0406,  0.0385, -0.0341],
          [-0.1902,  0.0059,  0.0242]],

         [[-0.1173, -0.2090,  0.0192],
          [ 0.1125, -0.0139, -0.1476],
          [ 0.1140, -0.0873, -0.0014]],

         [[ 0.0396,  0.0735,  0.1172],
          [ 0.2960,  0.3202,  0.1269],
          [ 0.2942,  0.2421,  0.1007]]],


        [[[ 0.2162,  0.0900,  0.0774],
          [ 0.0919, -0.0395, -0.0574],
          [-0.0336,  0.1127, -0.0488]],

         [[-0.2028, -0.3444, -0.0610],
          [-0.0374, -0.3158, -0.2540],
          [ 0.0503, -0.0260, -0.0834]],

         [[ 0.0706, -0.1370, -0.0161],
          [ 0.0319, -0.0577,  0.0128],
          [-0.0418,  0.0095,  0.0823]]],


        [[[-0.0592, -0.1985, -0.1404],
          [-0.2062, -0.4368, -0.2490],
          [ 0.1214, -0.1098, -0.1005]],

         [[ 0.1493, -0.1733,  0.0077],
          [ 0.0455, -0.1531,  0.0877],
          [ 0.1896,  0.2116, -0.0275]],

         [[ 0.0556, -0.1833,  0.1003],
          [ 0.1290, -0.0258,  0.0566],
          [-0.1295, -0.0603,  0.0269]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0006,  0.0017,  0.0017],
          [ 0.0005,  0.0002, -0.0001],
          [-0.0003, -0.0019, -0.0027]],

         [[ 0.0014,  0.0026,  0.0027],
          [ 0.0008,  0.0008,  0.0007],
          [ 0.0003, -0.0012, -0.0018]],

         [[ 0.0020,  0.0027,  0.0035],
          [ 0.0012,  0.0010,  0.0017],
          [ 0.0009, -0.0004, -0.0004]]],


        [[[ 0.0297,  0.0372,  0.0212],
          [ 0.0262,  0.0268,  0.0097],
          [ 0.0184,  0.0167,  0.0162]],

         [[ 0.0188,  0.0319,  0.0149],
          [ 0.0207,  0.0195,  0.0074],
          [ 0.0216,  0.0217,  0.0231]],

         [[ 0.0491,  0.0548,  0.0326],
          [ 0.0395,  0.0351,  0.0251],
          [ 0.0423,  0.0468,  0.0490]]],


        [[[ 0.0009,  0.0008,  0.0004],
          [ 0.0002,  0.0002, -0.0001],
          [-0.0002, -0.0002, -0.0004]],

         [[ 0.0011,  0.0009,  0.0006],
          [ 0.0003,  0.0002,  0.0000],
          [-0.0002, -0.0002, -0.0004]],

         [[ 0.0010,  0.0008,  0.0005],
          [ 0.0003,  0.0003, -0.0001],
          [-0.0002, -0.0002, -0.0005]]],


        ...,


        [[[-0.0107, -0.0124, -0.0164],
          [-0.0094, -0.0094, -0.0139],
          [-0.0040, -0.0056, -0.0107]],

         [[-0.0042, -0.0059, -0.0104],
          [-0.0047, -0.0049, -0.0102],
          [-0.0003, -0.0019, -0.0077]],

         [[-0.0007, -0.0018, -0.0049],
          [-0.0031, -0.0023, -0.0061],
          [-0.0004, -0.0009, -0.0056]]],


        [[[-0.0018, -0.0020,  0.0035],
          [-0.0023, -0.0020,  0.0027],
          [-0.0016, -0.0008,  0.0037]],

         [[ 0.0001, -0.0015,  0.0028],
          [-0.0006, -0.0014,  0.0014],
          [ 0.0008,  0.0002,  0.0029]],

         [[-0.0014, -0.0033,  0.0001],
          [-0.0017, -0.0028, -0.0006],
          [-0.0004, -0.0010,  0.0012]]],


        [[[ 0.0004, -0.0008, -0.0007],
          [-0.0046, -0.0032,  0.0002],
          [-0.0065,  0.0004,  0.0045]],

         [[ 0.0007, -0.0016, -0.0037],
          [-0.0046, -0.0043, -0.0030],
          [-0.0069, -0.0017,  0.0012]],

         [[ 0.0064,  0.0045,  0.0009],
          [ 0.0009,  0.0009,  0.0001],
          [-0.0023,  0.0028,  0.0032]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2876]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 52 | Batch_idx: 0 |  Loss: (0.3041) | Acc: (89.00%) (115/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.2938) | Acc: (90.00%) (1277/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.2881) | Acc: (90.00%) (2428/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.2886) | Acc: (90.00%) (3574/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.2895) | Acc: (90.00%) (4728/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.2916) | Acc: (90.00%) (5889/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.2835) | Acc: (90.00%) (7066/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.2875) | Acc: (90.00%) (8199/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.2941) | Acc: (89.00%) (9318/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.2959) | Acc: (89.00%) (10469/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.2934) | Acc: (89.00%) (11635/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.2939) | Acc: (89.00%) (12778/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.2931) | Acc: (89.00%) (13935/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.2932) | Acc: (89.00%) (15086/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.2929) | Acc: (89.00%) (16239/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.2924) | Acc: (90.00%) (17397/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.2938) | Acc: (89.00%) (18542/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.2911) | Acc: (90.00%) (19712/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.2903) | Acc: (90.00%) (20873/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.2896) | Acc: (90.00%) (22039/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.2887) | Acc: (90.00%) (23204/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.2877) | Acc: (90.00%) (24373/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.2877) | Acc: (90.00%) (25529/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.2871) | Acc: (90.00%) (26682/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.2864) | Acc: (90.00%) (27849/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.2871) | Acc: (90.00%) (28996/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.2883) | Acc: (90.00%) (30139/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.2886) | Acc: (90.00%) (31283/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.2891) | Acc: (90.00%) (32440/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.2892) | Acc: (90.00%) (33600/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.2895) | Acc: (90.00%) (34752/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.2887) | Acc: (90.00%) (35915/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.2892) | Acc: (90.00%) (37057/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.2892) | Acc: (90.00%) (38218/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.2893) | Acc: (90.00%) (39375/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.2896) | Acc: (90.00%) (40521/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.2895) | Acc: (90.00%) (41674/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.2896) | Acc: (90.00%) (42830/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.2891) | Acc: (90.00%) (43989/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.2887) | Acc: (90.00%) (45102/50000)
# TEST : Loss: (0.4076) | Acc: (86.00%) (8668/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1110, -0.1165, -0.0775],
          [-0.0341, -0.0791,  0.0200],
          [-0.0101, -0.1350, -0.2023]],

         [[-0.0297, -0.0800, -0.0259],
          [-0.1795, -0.0402,  0.0182],
          [ 0.0225,  0.0816, -0.0251]],

         [[-0.0576,  0.0962, -0.1880],
          [ 0.2229,  0.3622,  0.1707],
          [ 0.0034,  0.2617,  0.1867]]],


        [[[ 0.2784, -0.1142,  0.1674],
          [ 0.1465, -0.0120, -0.1169],
          [-0.2249, -0.1839, -0.2157]],

         [[ 0.0443, -0.2165,  0.0410],
          [-0.0674,  0.3569, -0.1712],
          [ 0.1708,  0.0732,  0.1913]],

         [[-0.1786, -0.1878, -0.0523],
          [-0.1822,  0.1518, -0.0361],
          [-0.0317,  0.1115,  0.1873]]],


        [[[-0.0284, -0.0622, -0.0683],
          [-0.0401, -0.0707, -0.0490],
          [-0.0649, -0.0494, -0.0013]],

         [[ 0.0405,  0.0546,  0.0250],
          [-0.0658, -0.0693, -0.0089],
          [-0.1068, -0.0115,  0.0160]],

         [[-0.0248,  0.0430,  0.1244],
          [-0.0445, -0.0460,  0.0951],
          [-0.1131,  0.0090,  0.0462]]],


        ...,


        [[[ 0.0320, -0.0057, -0.0882],
          [ 0.0378,  0.0421, -0.0300],
          [-0.2057, -0.0014,  0.0218]],

         [[-0.1224, -0.2102,  0.0183],
          [ 0.1100, -0.0108, -0.1439],
          [ 0.0984, -0.0923, -0.0014]],

         [[ 0.0332,  0.0780,  0.1244],
          [ 0.2939,  0.3336,  0.1374],
          [ 0.2706,  0.2367,  0.1029]]],


        [[[ 0.2222,  0.0924,  0.0728],
          [ 0.0882, -0.0455, -0.0623],
          [-0.0342,  0.1165, -0.0403]],

         [[-0.1980, -0.3371, -0.0564],
          [-0.0482, -0.3279, -0.2566],
          [ 0.0482, -0.0198, -0.0712]],

         [[ 0.0780, -0.1258, -0.0067],
          [ 0.0320, -0.0547,  0.0186],
          [-0.0317,  0.0297,  0.1020]]],


        [[[-0.0473, -0.1777, -0.1414],
          [-0.2050, -0.4265, -0.2594],
          [ 0.1308, -0.0937, -0.0955]],

         [[ 0.1669, -0.1509,  0.0213],
          [ 0.0592, -0.1315,  0.0995],
          [ 0.2070,  0.2363, -0.0073]],

         [[ 0.0605, -0.1766,  0.1008],
          [ 0.1340, -0.0149,  0.0622],
          [-0.1189, -0.0433,  0.0387]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0060,  0.0086,  0.0069],
          [ 0.0066,  0.0095,  0.0081],
          [ 0.0069,  0.0095,  0.0083]],

         [[ 0.0033,  0.0046,  0.0026],
          [ 0.0044,  0.0059,  0.0048],
          [ 0.0048,  0.0065,  0.0059]],

         [[ 0.0044,  0.0056,  0.0033],
          [ 0.0048,  0.0064,  0.0053],
          [ 0.0047,  0.0068,  0.0064]]],


        [[[-0.0496, -0.0498, -0.0587],
          [-0.0450, -0.0524, -0.0618],
          [-0.0424, -0.0399, -0.0682]],

         [[-0.0403, -0.0477, -0.0565],
          [-0.0352, -0.0485, -0.0521],
          [-0.0402, -0.0388, -0.0566]],

         [[-0.0307, -0.0395, -0.0544],
          [-0.0241, -0.0388, -0.0525],
          [-0.0229, -0.0218, -0.0494]]],


        [[[ 0.0006,  0.0011,  0.0018],
          [ 0.0002,  0.0007,  0.0016],
          [ 0.0002,  0.0007,  0.0014]],

         [[ 0.0007,  0.0012,  0.0017],
          [ 0.0003,  0.0007,  0.0015],
          [ 0.0003,  0.0006,  0.0013]],

         [[ 0.0007,  0.0012,  0.0017],
          [ 0.0004,  0.0008,  0.0014],
          [ 0.0003,  0.0007,  0.0013]]],


        ...,


        [[[ 0.0144,  0.0159,  0.0177],
          [ 0.0130,  0.0132,  0.0138],
          [ 0.0122,  0.0106,  0.0114]],

         [[ 0.0104,  0.0107,  0.0122],
          [ 0.0094,  0.0084,  0.0093],
          [ 0.0082,  0.0059,  0.0070]],

         [[ 0.0070,  0.0059,  0.0074],
          [ 0.0053,  0.0031,  0.0046],
          [ 0.0038,  0.0005,  0.0023]]],


        [[[-0.0010, -0.0054, -0.0036],
          [ 0.0008, -0.0046, -0.0041],
          [-0.0021, -0.0055, -0.0050]],

         [[ 0.0026, -0.0017,  0.0004],
          [ 0.0043, -0.0010, -0.0002],
          [ 0.0013, -0.0021, -0.0012]],

         [[ 0.0038, -0.0003,  0.0017],
          [ 0.0051, -0.0002,  0.0011],
          [ 0.0022, -0.0013,  0.0001]]],


        [[[ 0.0252,  0.0139,  0.0246],
          [ 0.0252,  0.0119,  0.0211],
          [ 0.0238,  0.0155,  0.0200]],

         [[ 0.0344,  0.0265,  0.0369],
          [ 0.0363,  0.0273,  0.0356],
          [ 0.0359,  0.0314,  0.0349]],

         [[ 0.0382,  0.0306,  0.0394],
          [ 0.0379,  0.0292,  0.0366],
          [ 0.0349,  0.0304,  0.0340]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2869]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 53 | Batch_idx: 0 |  Loss: (0.1795) | Acc: (95.00%) (122/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.2386) | Acc: (92.00%) (1299/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.2603) | Acc: (91.00%) (2459/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.2604) | Acc: (91.00%) (3622/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.2649) | Acc: (91.00%) (4777/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.2591) | Acc: (91.00%) (5946/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.2581) | Acc: (91.00%) (7109/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.2601) | Acc: (90.00%) (8262/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.2556) | Acc: (91.00%) (9453/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.2584) | Acc: (91.00%) (10605/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.2599) | Acc: (90.00%) (11761/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.2628) | Acc: (90.00%) (12917/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.2620) | Acc: (90.00%) (14085/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.2651) | Acc: (90.00%) (15233/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.2653) | Acc: (90.00%) (16394/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.2629) | Acc: (90.00%) (17566/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.2624) | Acc: (90.00%) (18735/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.2639) | Acc: (90.00%) (19883/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.2657) | Acc: (90.00%) (21040/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.2649) | Acc: (90.00%) (22217/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.2649) | Acc: (90.00%) (23382/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.2656) | Acc: (90.00%) (24538/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.2649) | Acc: (90.00%) (25714/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.2648) | Acc: (90.00%) (26877/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.2634) | Acc: (90.00%) (28054/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.2634) | Acc: (90.00%) (29214/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.2638) | Acc: (90.00%) (30377/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.2646) | Acc: (90.00%) (31529/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.2649) | Acc: (90.00%) (32685/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.2637) | Acc: (90.00%) (33867/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.2648) | Acc: (90.00%) (35020/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.2641) | Acc: (90.00%) (36190/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.2639) | Acc: (90.00%) (37348/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.2633) | Acc: (90.00%) (38509/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.2633) | Acc: (90.00%) (39675/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.2634) | Acc: (90.00%) (40832/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.2636) | Acc: (90.00%) (41994/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.2633) | Acc: (90.00%) (43168/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.2633) | Acc: (90.00%) (44325/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.2626) | Acc: (90.00%) (45460/50000)
# TEST : Loss: (0.3638) | Acc: (87.00%) (8751/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1001, -0.1111, -0.0768],
          [-0.0253, -0.0724,  0.0204],
          [-0.0058, -0.1304, -0.2015]],

         [[-0.0175, -0.0704, -0.0211],
          [-0.1666, -0.0272,  0.0246],
          [ 0.0271,  0.0889, -0.0207]],

         [[-0.0463,  0.1057, -0.1817],
          [ 0.2334,  0.3753,  0.1773],
          [ 0.0073,  0.2682,  0.1888]]],


        [[[ 0.2945, -0.1058,  0.1792],
          [ 0.1483, -0.0091, -0.1081],
          [-0.2264, -0.1845, -0.2127]],

         [[ 0.0467, -0.2180,  0.0454],
          [-0.0749,  0.3563, -0.1651],
          [ 0.1643,  0.0724,  0.1921]],

         [[-0.1771, -0.1912, -0.0506],
          [-0.1905,  0.1484, -0.0313],
          [-0.0321,  0.1129,  0.1914]]],


        [[[-0.0388, -0.0699, -0.0716],
          [-0.0462, -0.0724, -0.0505],
          [-0.0603, -0.0540, -0.0071]],

         [[ 0.0265,  0.0375,  0.0128],
          [-0.0663, -0.0747, -0.0176],
          [-0.1022, -0.0256,  0.0036]],

         [[-0.0286,  0.0312,  0.1098],
          [-0.0434, -0.0493,  0.0818],
          [-0.1020, -0.0009,  0.0348]]],


        ...,


        [[[ 0.0407, -0.0011, -0.0794],
          [ 0.0379,  0.0415, -0.0287],
          [-0.2067, -0.0042,  0.0225]],

         [[-0.1067, -0.1976,  0.0336],
          [ 0.1185, -0.0025, -0.1345],
          [ 0.1064, -0.0850,  0.0065]],

         [[ 0.0551,  0.0928,  0.1388],
          [ 0.3091,  0.3408,  0.1411],
          [ 0.2762,  0.2337,  0.0993]]],


        [[[ 0.2381,  0.1103,  0.0947],
          [ 0.1040, -0.0277, -0.0441],
          [-0.0207,  0.1276, -0.0274]],

         [[-0.1879, -0.3189, -0.0416],
          [-0.0486, -0.3215, -0.2497],
          [ 0.0480, -0.0211, -0.0730]],

         [[ 0.0736, -0.1296, -0.0061],
          [ 0.0216, -0.0582,  0.0220],
          [-0.0368,  0.0299,  0.1053]]],


        [[[-0.0583, -0.1898, -0.1371],
          [-0.2055, -0.4217, -0.2518],
          [ 0.1405, -0.0726, -0.0768]],

         [[ 0.1608, -0.1557,  0.0208],
          [ 0.0611, -0.1269,  0.1058],
          [ 0.2171,  0.2527,  0.0107]],

         [[ 0.0552, -0.1812,  0.0973],
          [ 0.1295, -0.0156,  0.0639],
          [-0.1168, -0.0342,  0.0500]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0045, -0.0030, -0.0021],
          [-0.0016, -0.0016, -0.0012],
          [ 0.0000, -0.0025, -0.0022]],

         [[-0.0044, -0.0032, -0.0028],
          [-0.0013, -0.0015, -0.0015],
          [ 0.0003, -0.0024, -0.0024]],

         [[-0.0047, -0.0043, -0.0044],
          [-0.0015, -0.0021, -0.0026],
          [-0.0000, -0.0026, -0.0028]]],


        [[[-0.0094,  0.0233, -0.0028],
          [ 0.0473,  0.0293,  0.0215],
          [ 0.0850,  0.0675,  0.0446]],

         [[-0.0510, -0.0203, -0.0451],
          [ 0.0031, -0.0063, -0.0135],
          [ 0.0414,  0.0239,  0.0117]],

         [[-0.0817, -0.0637, -0.0781],
          [-0.0338, -0.0367, -0.0343],
          [ 0.0025, -0.0046, -0.0010]]],


        [[[-0.0005, -0.0006, -0.0004],
          [ 0.0001,  0.0001,  0.0002],
          [-0.0000, -0.0000,  0.0001]],

         [[-0.0007, -0.0007, -0.0006],
          [-0.0000, -0.0001,  0.0000],
          [-0.0001, -0.0002, -0.0001]],

         [[-0.0006, -0.0006, -0.0005],
          [-0.0001, -0.0001, -0.0000],
          [-0.0001, -0.0002, -0.0001]]],


        ...,


        [[[-0.0058, -0.0021,  0.0013],
          [ 0.0003,  0.0035,  0.0079],
          [ 0.0007,  0.0015,  0.0056]],

         [[-0.0074, -0.0043, -0.0003],
          [-0.0015,  0.0010,  0.0057],
          [-0.0021, -0.0024,  0.0020]],

         [[-0.0065, -0.0040, -0.0001],
          [-0.0009,  0.0010,  0.0052],
          [-0.0009, -0.0013,  0.0025]]],


        [[[ 0.0187,  0.0061, -0.0046],
          [ 0.0217,  0.0086,  0.0011],
          [ 0.0157,  0.0026, -0.0052]],

         [[ 0.0143,  0.0033, -0.0067],
          [ 0.0189,  0.0089,  0.0015],
          [ 0.0129,  0.0041, -0.0029]],

         [[ 0.0061, -0.0027, -0.0107],
          [ 0.0092,  0.0026, -0.0037],
          [ 0.0037, -0.0010, -0.0060]]],


        [[[ 0.0101, -0.0042, -0.0061],
          [ 0.0040, -0.0112, -0.0131],
          [-0.0011, -0.0144, -0.0204]],

         [[-0.0026, -0.0160, -0.0162],
          [-0.0113, -0.0261, -0.0268],
          [-0.0181, -0.0309, -0.0345]],

         [[-0.0071, -0.0176, -0.0181],
          [-0.0173, -0.0285, -0.0290],
          [-0.0253, -0.0359, -0.0377]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2860]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 54 | Batch_idx: 0 |  Loss: (0.1972) | Acc: (95.00%) (122/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.2153) | Acc: (93.00%) (1312/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.2294) | Acc: (92.00%) (2487/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.2429) | Acc: (91.00%) (3649/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.2494) | Acc: (91.00%) (4804/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.2532) | Acc: (91.00%) (5970/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.2521) | Acc: (91.00%) (7151/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.2485) | Acc: (91.00%) (8326/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.2496) | Acc: (91.00%) (9490/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.2477) | Acc: (91.00%) (10658/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.2470) | Acc: (91.00%) (11824/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.2467) | Acc: (91.00%) (12995/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.2492) | Acc: (91.00%) (14145/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.2495) | Acc: (91.00%) (15321/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.2498) | Acc: (91.00%) (16485/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.2495) | Acc: (91.00%) (17656/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.2507) | Acc: (91.00%) (18816/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.2520) | Acc: (91.00%) (19984/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.2519) | Acc: (91.00%) (21154/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.2513) | Acc: (91.00%) (22330/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.2509) | Acc: (91.00%) (23501/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.2501) | Acc: (91.00%) (24680/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.2507) | Acc: (91.00%) (25844/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.2503) | Acc: (91.00%) (27017/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.2508) | Acc: (91.00%) (28185/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.2519) | Acc: (91.00%) (29343/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.2510) | Acc: (91.00%) (30525/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.2512) | Acc: (91.00%) (31696/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.2509) | Acc: (91.00%) (32871/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.2512) | Acc: (91.00%) (34030/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.2509) | Acc: (91.00%) (35198/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.2501) | Acc: (91.00%) (36380/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.2510) | Acc: (91.00%) (37547/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.2506) | Acc: (91.00%) (38721/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.2515) | Acc: (91.00%) (39871/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.2521) | Acc: (91.00%) (41035/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.2525) | Acc: (91.00%) (42193/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.2520) | Acc: (91.00%) (43359/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.2511) | Acc: (91.00%) (44532/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.2508) | Acc: (91.00%) (45663/50000)
# TEST : Loss: (0.3605) | Acc: (88.00%) (8855/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1108, -0.1208, -0.0912],
          [-0.0358, -0.0828,  0.0105],
          [-0.0145, -0.1372, -0.2046]],

         [[-0.0250, -0.0786, -0.0367],
          [-0.1715, -0.0347,  0.0151],
          [ 0.0220,  0.0845, -0.0228]],

         [[-0.0536,  0.0970, -0.1974],
          [ 0.2264,  0.3668,  0.1667],
          [ 0.0015,  0.2636,  0.1855]]],


        [[[ 0.2878, -0.1101,  0.1655],
          [ 0.1438, -0.0161, -0.1272],
          [-0.2234, -0.1907, -0.2263]],

         [[ 0.0466, -0.2147,  0.0361],
          [-0.0715,  0.3605, -0.1761],
          [ 0.1770,  0.0783,  0.1855]],

         [[-0.1765, -0.1883, -0.0556],
          [-0.1903,  0.1495, -0.0368],
          [-0.0216,  0.1210,  0.1909]]],


        [[[-0.0415, -0.0719, -0.0780],
          [-0.0539, -0.0707, -0.0519],
          [-0.0663, -0.0472, -0.0016]],

         [[ 0.0280,  0.0319,  0.0010],
          [-0.0608, -0.0703, -0.0230],
          [-0.0997, -0.0256,  0.0042]],

         [[-0.0151,  0.0331,  0.0970],
          [-0.0302, -0.0361,  0.0768],
          [-0.0889,  0.0079,  0.0410]]],


        ...,


        [[[ 0.0395, -0.0007, -0.0823],
          [ 0.0397,  0.0441, -0.0303],
          [-0.1994,  0.0014,  0.0274]],

         [[-0.1029, -0.1920,  0.0344],
          [ 0.1282,  0.0058, -0.1328],
          [ 0.1228, -0.0748,  0.0124]],

         [[ 0.0549,  0.0959,  0.1360],
          [ 0.3137,  0.3461,  0.1332],
          [ 0.2869,  0.2318,  0.0903]]],


        [[[ 0.2332,  0.0929,  0.0932],
          [ 0.0935, -0.0485, -0.0524],
          [-0.0268,  0.1231, -0.0223]],

         [[-0.1805, -0.3281, -0.0289],
          [-0.0514, -0.3395, -0.2548],
          [ 0.0482, -0.0216, -0.0685]],

         [[ 0.0871, -0.1263,  0.0173],
          [ 0.0246, -0.0648,  0.0313],
          [-0.0312,  0.0361,  0.1175]]],


        [[[-0.0631, -0.1970, -0.1379],
          [-0.2139, -0.4434, -0.2720],
          [ 0.1249, -0.0961, -0.0959]],

         [[ 0.1544, -0.1584,  0.0223],
          [ 0.0528, -0.1360,  0.0956],
          [ 0.2058,  0.2373, -0.0019]],

         [[ 0.0523, -0.1772,  0.1046],
          [ 0.1243, -0.0175,  0.0636],
          [-0.1239, -0.0425,  0.0438]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-1.3544e-03, -2.7540e-03, -3.5011e-03],
          [-2.9558e-03, -4.1990e-03, -4.1667e-03],
          [-2.3981e-03, -3.5398e-03, -2.5157e-03]],

         [[-1.6600e-03, -2.9278e-03, -3.8619e-03],
          [-2.7134e-03, -3.7887e-03, -3.9061e-03],
          [-1.9086e-03, -2.9066e-03, -1.9980e-03]],

         [[-1.4892e-03, -2.5417e-03, -3.6641e-03],
          [-2.5381e-03, -3.2168e-03, -3.7287e-03],
          [-1.9734e-03, -2.6964e-03, -2.3147e-03]]],


        [[[ 6.9966e-02,  8.2012e-02,  8.3707e-02],
          [ 6.4838e-02,  6.9762e-02,  6.5329e-02],
          [ 8.3631e-02,  7.5907e-02,  7.0657e-02]],

         [[ 5.2452e-02,  6.0553e-02,  6.1885e-02],
          [ 5.3578e-02,  5.0968e-02,  4.5290e-02],
          [ 7.6552e-02,  5.5701e-02,  4.6623e-02]],

         [[ 1.8122e-02,  2.3990e-02,  3.0815e-02],
          [ 3.2103e-02,  2.9911e-02,  2.9845e-02],
          [ 5.7522e-02,  4.3858e-02,  3.8626e-02]]],


        [[[ 8.7660e-05, -1.3038e-05, -2.8785e-04],
          [ 6.6914e-05, -2.4024e-06, -3.0137e-04],
          [ 1.5567e-06, -1.8611e-04, -4.6477e-04]],

         [[ 1.2093e-04, -1.5628e-05, -2.9884e-04],
          [ 9.0307e-05, -1.6179e-05, -3.3427e-04],
          [-1.0571e-05, -2.2180e-04, -5.2102e-04]],

         [[ 9.9111e-05,  5.2034e-05, -1.8116e-04],
          [ 6.2143e-05,  3.5526e-05, -2.1114e-04],
          [ 2.1039e-05, -8.8925e-05, -3.1111e-04]]],


        ...,


        [[[ 2.1166e-04, -3.5574e-04,  2.9908e-04],
          [-8.8146e-05, -2.1713e-06, -7.7120e-04],
          [ 2.5756e-03,  1.4489e-03, -2.9485e-04]],

         [[ 1.3737e-03,  3.0462e-04,  5.4816e-04],
          [ 2.2047e-04,  3.0759e-04, -5.4559e-04],
          [ 2.1044e-03,  1.2988e-03, -1.7611e-04]],

         [[ 1.4042e-03,  6.7919e-04,  7.4484e-04],
          [-2.6717e-04,  1.3704e-04, -7.3773e-04],
          [ 9.6222e-04,  5.4505e-04, -8.4670e-04]]],


        [[[ 8.4937e-03,  5.1579e-03,  9.1748e-03],
          [ 4.8519e-03,  1.7057e-03,  5.3333e-03],
          [ 1.3702e-03,  4.8338e-03,  1.0278e-02]],

         [[ 6.4630e-03,  5.1994e-03,  9.0937e-03],
          [ 3.7893e-03,  4.2557e-05,  2.6521e-03],
          [ 1.4285e-04,  1.2393e-03,  5.3729e-03]],

         [[ 4.0885e-03,  3.8425e-03,  7.1689e-03],
          [ 1.1807e-03, -8.4484e-04,  2.3528e-03],
          [-1.1142e-03,  3.2369e-04,  4.2220e-03]]],


        [[[ 2.6147e-03, -9.9787e-04, -1.0199e-03],
          [ 9.2218e-03,  3.4922e-03,  1.6259e-03],
          [ 4.0829e-03, -1.5961e-03, -3.1541e-03]],

         [[ 3.4957e-03, -9.8296e-04, -2.9408e-03],
          [ 1.0703e-02,  4.2631e-03,  1.0080e-03],
          [ 6.5194e-03, -1.6394e-04, -2.4348e-03]],

         [[-3.9833e-03, -8.1313e-03, -8.3275e-03],
          [-5.3300e-05, -5.0694e-03, -5.7168e-03],
          [-5.7064e-03, -1.0692e-02, -1.0498e-02]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2849]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 55 | Batch_idx: 0 |  Loss: (0.2322) | Acc: (92.00%) (118/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.2220) | Acc: (92.00%) (1301/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.2453) | Acc: (91.00%) (2466/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.2502) | Acc: (91.00%) (3642/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.2578) | Acc: (91.00%) (4795/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.2610) | Acc: (91.00%) (5953/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.2671) | Acc: (90.00%) (7103/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.2698) | Acc: (90.00%) (8263/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.2747) | Acc: (90.00%) (9406/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.2733) | Acc: (90.00%) (10565/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.2717) | Acc: (90.00%) (11740/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.2668) | Acc: (90.00%) (12923/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.2642) | Acc: (91.00%) (14098/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.2631) | Acc: (91.00%) (15279/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.2625) | Acc: (91.00%) (16444/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.2609) | Acc: (91.00%) (17627/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.2616) | Acc: (91.00%) (18787/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.2611) | Acc: (91.00%) (19960/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.2608) | Acc: (91.00%) (21129/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.2582) | Acc: (91.00%) (22313/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.2580) | Acc: (91.00%) (23479/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.2577) | Acc: (91.00%) (24647/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.2566) | Acc: (91.00%) (25837/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.2564) | Acc: (91.00%) (27009/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.2546) | Acc: (91.00%) (28191/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.2541) | Acc: (91.00%) (29366/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.2531) | Acc: (91.00%) (30541/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.2515) | Acc: (91.00%) (31730/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.2510) | Acc: (91.00%) (32902/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.2505) | Acc: (91.00%) (34080/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.2495) | Acc: (91.00%) (35273/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.2497) | Acc: (91.00%) (36443/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.2497) | Acc: (91.00%) (37613/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.2484) | Acc: (91.00%) (38801/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.2479) | Acc: (91.00%) (39975/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.2474) | Acc: (91.00%) (41149/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.2469) | Acc: (91.00%) (42329/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.2464) | Acc: (91.00%) (43515/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.2461) | Acc: (91.00%) (44697/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.2450) | Acc: (91.00%) (45839/50000)
# TEST : Loss: (0.3222) | Acc: (89.00%) (8947/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1093, -0.1181, -0.0890],
          [-0.0346, -0.0805,  0.0121],
          [-0.0139, -0.1353, -0.2022]],

         [[-0.0256, -0.0776, -0.0362],
          [-0.1705, -0.0341,  0.0154],
          [ 0.0211,  0.0836, -0.0228]],

         [[-0.0535,  0.0970, -0.1948],
          [ 0.2248,  0.3648,  0.1665],
          [ 0.0017,  0.2622,  0.1850]]],


        [[[ 0.2861, -0.1107,  0.1647],
          [ 0.1418, -0.0172, -0.1280],
          [-0.2239, -0.1909, -0.2275]],

         [[ 0.0447, -0.2159,  0.0347],
          [-0.0736,  0.3586, -0.1778],
          [ 0.1755,  0.0779,  0.1838]],

         [[-0.1780, -0.1898, -0.0576],
          [-0.1926,  0.1474, -0.0392],
          [-0.0232,  0.1202,  0.1887]]],


        [[[-0.0391, -0.0670, -0.0729],
          [-0.0434, -0.0609, -0.0469],
          [-0.0531, -0.0398, -0.0004]],

         [[ 0.0235,  0.0275,  0.0003],
          [-0.0516, -0.0623, -0.0208],
          [-0.0826, -0.0221,  0.0047]],

         [[-0.0147,  0.0291,  0.0897],
          [-0.0256, -0.0321,  0.0711],
          [-0.0754,  0.0076,  0.0386]]],


        ...,


        [[[ 0.0388, -0.0011, -0.0820],
          [ 0.0398,  0.0439, -0.0298],
          [-0.1981,  0.0010,  0.0274]],

         [[-0.1031, -0.1914,  0.0343],
          [ 0.1276,  0.0058, -0.1313],
          [ 0.1224, -0.0744,  0.0129]],

         [[ 0.0525,  0.0937,  0.1347],
          [ 0.3085,  0.3404,  0.1326],
          [ 0.2836,  0.2279,  0.0902]]],


        [[[ 0.2360,  0.0941,  0.0930],
          [ 0.0970, -0.0457, -0.0511],
          [-0.0233,  0.1243, -0.0220]],

         [[-0.1742, -0.3227, -0.0296],
          [-0.0458, -0.3305, -0.2500],
          [ 0.0520, -0.0181, -0.0668]],

         [[ 0.0912, -0.1228,  0.0170],
          [ 0.0301, -0.0592,  0.0327],
          [-0.0265,  0.0395,  0.1185]]],


        [[[-0.0593, -0.1917, -0.1356],
          [-0.2116, -0.4394, -0.2702],
          [ 0.1245, -0.0958, -0.0958]],

         [[ 0.1568, -0.1551,  0.0240],
          [ 0.0540, -0.1345,  0.0961],
          [ 0.2056,  0.2371, -0.0009]],

         [[ 0.0575, -0.1709,  0.1091],
          [ 0.1281, -0.0130,  0.0679],
          [-0.1199, -0.0383,  0.0480]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2311]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0059]], device='cuda:0')

Epoch: 56 | Batch_idx: 0 |  Loss: (0.1765) | Acc: (95.00%) (122/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.2233) | Acc: (93.00%) (1320/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.2239) | Acc: (92.00%) (2495/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.2281) | Acc: (92.00%) (3669/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.2227) | Acc: (92.00%) (4861/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.2209) | Acc: (92.00%) (6042/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.2171) | Acc: (92.00%) (7238/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.2231) | Acc: (92.00%) (8394/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.2239) | Acc: (92.00%) (9581/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.2321) | Acc: (92.00%) (10722/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.2313) | Acc: (92.00%) (11906/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.2305) | Acc: (92.00%) (13087/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.2301) | Acc: (92.00%) (14276/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.2310) | Acc: (92.00%) (15447/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.2321) | Acc: (92.00%) (16621/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.2317) | Acc: (92.00%) (17808/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.2297) | Acc: (92.00%) (19011/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.2295) | Acc: (92.00%) (20199/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.2276) | Acc: (92.00%) (21404/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.2295) | Acc: (92.00%) (22568/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.2288) | Acc: (92.00%) (23746/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.2262) | Acc: (92.00%) (24957/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.2271) | Acc: (92.00%) (26131/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.2255) | Acc: (92.00%) (27329/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.2234) | Acc: (92.00%) (28535/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.2241) | Acc: (92.00%) (29708/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.2238) | Acc: (92.00%) (30898/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.2234) | Acc: (92.00%) (32087/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.2227) | Acc: (92.00%) (33271/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.2232) | Acc: (92.00%) (34444/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.2232) | Acc: (92.00%) (35626/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.2237) | Acc: (92.00%) (36801/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.2239) | Acc: (92.00%) (37980/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.2229) | Acc: (92.00%) (39180/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.2225) | Acc: (92.00%) (40371/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.2216) | Acc: (92.00%) (41571/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.2213) | Acc: (92.00%) (42767/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.2206) | Acc: (92.00%) (43960/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.2199) | Acc: (92.00%) (45153/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.2201) | Acc: (92.00%) (46280/50000)
# TEST : Loss: (0.3133) | Acc: (89.00%) (8952/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1082, -0.1169, -0.0881],
          [-0.0342, -0.0798,  0.0120],
          [-0.0138, -0.1341, -0.2004]],

         [[-0.0253, -0.0768, -0.0359],
          [-0.1688, -0.0338,  0.0152],
          [ 0.0209,  0.0828, -0.0225]],

         [[-0.0529,  0.0960, -0.1929],
          [ 0.2224,  0.3610,  0.1648],
          [ 0.0016,  0.2594,  0.1831]]],


        [[[ 0.2858, -0.1106,  0.1646],
          [ 0.1416, -0.0172, -0.1279],
          [-0.2237, -0.1906, -0.2272]],

         [[ 0.0446, -0.2156,  0.0347],
          [-0.0736,  0.3581, -0.1776],
          [ 0.1753,  0.0778,  0.1836]],

         [[-0.1778, -0.1895, -0.0575],
          [-0.1924,  0.1472, -0.0391],
          [-0.0232,  0.1200,  0.1884]]],


        [[[-0.0342, -0.0596, -0.0668],
          [-0.0331, -0.0503, -0.0422],
          [-0.0405, -0.0328, -0.0004]],

         [[ 0.0208,  0.0247,  0.0003],
          [-0.0417, -0.0529, -0.0188],
          [-0.0656, -0.0186,  0.0043]],

         [[-0.0131,  0.0261,  0.0823],
          [-0.0216, -0.0278,  0.0643],
          [-0.0626,  0.0065,  0.0347]]],


        ...,


        [[[ 0.0386, -0.0011, -0.0815],
          [ 0.0396,  0.0436, -0.0296],
          [-0.1969,  0.0010,  0.0272]],

         [[-0.1023, -0.1899,  0.0340],
          [ 0.1265,  0.0058, -0.1302],
          [ 0.1214, -0.0738,  0.0128]],

         [[ 0.0519,  0.0927,  0.1333],
          [ 0.3025,  0.3342,  0.1307],
          [ 0.2784,  0.2238,  0.0889]]],


        [[[ 0.2343,  0.0933,  0.0923],
          [ 0.0963, -0.0454, -0.0506],
          [-0.0232,  0.1234, -0.0218]],

         [[-0.1724, -0.3175, -0.0291],
          [-0.0453, -0.3249, -0.2456],
          [ 0.0516, -0.0179, -0.0661]],

         [[ 0.0902, -0.1207,  0.0168],
          [ 0.0298, -0.0581,  0.0321],
          [-0.0263,  0.0390,  0.1172]]],


        [[[-0.0589, -0.1894, -0.1343],
          [-0.2103, -0.4343, -0.2676],
          [ 0.1239, -0.0953, -0.0952]],

         [[ 0.1560, -0.1540,  0.0239],
          [ 0.0537, -0.1336,  0.0955],
          [ 0.2048,  0.2359, -0.0009]],

         [[ 0.0573, -0.1700,  0.1085],
          [ 0.1275, -0.0130,  0.0675],
          [-0.1194, -0.0381,  0.0477]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2385]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0268]], device='cuda:0')

Epoch: 57 | Batch_idx: 0 |  Loss: (0.2393) | Acc: (92.00%) (118/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.2173) | Acc: (92.00%) (1302/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.2128) | Acc: (92.00%) (2498/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.2056) | Acc: (93.00%) (3697/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.2132) | Acc: (92.00%) (4870/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.2147) | Acc: (92.00%) (6049/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.2195) | Acc: (92.00%) (7223/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.2185) | Acc: (92.00%) (8404/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.2193) | Acc: (92.00%) (9578/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.2223) | Acc: (92.00%) (10748/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.2199) | Acc: (92.00%) (11943/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.2201) | Acc: (92.00%) (13125/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.2208) | Acc: (92.00%) (14303/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.2222) | Acc: (92.00%) (15489/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.2213) | Acc: (92.00%) (16679/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.2214) | Acc: (92.00%) (17861/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.2205) | Acc: (92.00%) (19059/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.2208) | Acc: (92.00%) (20246/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.2217) | Acc: (92.00%) (21419/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.2223) | Acc: (92.00%) (22600/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.2218) | Acc: (92.00%) (23797/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.2236) | Acc: (92.00%) (24958/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.2235) | Acc: (92.00%) (26150/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.2220) | Acc: (92.00%) (27358/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.2227) | Acc: (92.00%) (28545/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.2218) | Acc: (92.00%) (29732/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.2218) | Acc: (92.00%) (30924/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.2214) | Acc: (92.00%) (32113/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.2215) | Acc: (92.00%) (33308/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.2210) | Acc: (92.00%) (34504/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.2208) | Acc: (92.00%) (35692/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.2207) | Acc: (92.00%) (36879/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.2213) | Acc: (92.00%) (38049/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.2209) | Acc: (92.00%) (39243/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.2207) | Acc: (92.00%) (40431/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.2198) | Acc: (92.00%) (41647/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.2200) | Acc: (92.00%) (42827/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.2202) | Acc: (92.00%) (44018/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.2201) | Acc: (92.00%) (45209/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.2193) | Acc: (92.00%) (46367/50000)
# TEST : Loss: (0.3070) | Acc: (89.00%) (8957/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1069, -0.1155, -0.0871],
          [-0.0338, -0.0789,  0.0119],
          [-0.0137, -0.1327, -0.1982]],

         [[-0.0250, -0.0759, -0.0355],
          [-0.1669, -0.0334,  0.0151],
          [ 0.0206,  0.0819, -0.0223]],

         [[-0.0523,  0.0948, -0.1905],
          [ 0.2196,  0.3564,  0.1627],
          [ 0.0016,  0.2562,  0.1808]]],


        [[[ 0.2854, -0.1105,  0.1643],
          [ 0.1414, -0.0171, -0.1277],
          [-0.2233, -0.1904, -0.2269]],

         [[ 0.0446, -0.2153,  0.0346],
          [-0.0735,  0.3576, -0.1774],
          [ 0.1750,  0.0777,  0.1833]],

         [[-0.1776, -0.1892, -0.0574],
          [-0.1921,  0.1470, -0.0391],
          [-0.0231,  0.1198,  0.1881]]],


        [[[-0.0291, -0.0517, -0.0599],
          [-0.0238, -0.0399, -0.0371],
          [-0.0291, -0.0260, -0.0003]],

         [[ 0.0180,  0.0217,  0.0003],
          [-0.0321, -0.0435, -0.0167],
          [-0.0495, -0.0151,  0.0038]],

         [[-0.0113,  0.0230,  0.0740],
          [-0.0176, -0.0233,  0.0568],
          [-0.0500,  0.0054,  0.0306]]],


        ...,


        [[[ 0.0383, -0.0011, -0.0810],
          [ 0.0393,  0.0433, -0.0294],
          [-0.1954,  0.0010,  0.0270]],

         [[-0.1014, -0.1882,  0.0337],
          [ 0.1252,  0.0057, -0.1290],
          [ 0.1201, -0.0731,  0.0127]],

         [[ 0.0512,  0.0915,  0.1317],
          [ 0.2954,  0.3268,  0.1285],
          [ 0.2722,  0.2190,  0.0875]]],


        [[[ 0.2322,  0.0924,  0.0914],
          [ 0.0954, -0.0449, -0.0501],
          [-0.0230,  0.1224, -0.0216]],

         [[-0.1702, -0.3113, -0.0286],
          [-0.0447, -0.3182, -0.2403],
          [ 0.0511, -0.0177, -0.0653]],

         [[ 0.0890, -0.1183,  0.0165],
          [ 0.0294, -0.0569,  0.0314],
          [-0.0260,  0.0385,  0.1156]]],


        [[[-0.0585, -0.1868, -0.1328],
          [-0.2086, -0.4281, -0.2643],
          [ 0.1232, -0.0946, -0.0945]],

         [[ 0.1550, -0.1528,  0.0237],
          [ 0.0534, -0.1326,  0.0948],
          [ 0.2037,  0.2345, -0.0009]],

         [[ 0.0569, -0.1688,  0.1078],
          [ 0.1267, -0.0129,  0.0671],
          [-0.1188, -0.0378,  0.0475]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2669]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0003]], device='cuda:0')

Epoch: 58 | Batch_idx: 0 |  Loss: (0.1414) | Acc: (95.00%) (122/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.2154) | Acc: (92.00%) (1303/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.2210) | Acc: (92.00%) (2492/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.2241) | Acc: (92.00%) (3670/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.2236) | Acc: (92.00%) (4862/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.2239) | Acc: (92.00%) (6044/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.2230) | Acc: (92.00%) (7230/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.2240) | Acc: (92.00%) (8412/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.2265) | Acc: (92.00%) (9583/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.2292) | Acc: (92.00%) (10763/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.2268) | Acc: (92.00%) (11955/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.2280) | Acc: (92.00%) (13132/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.2273) | Acc: (92.00%) (14327/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.2260) | Acc: (92.00%) (15516/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.2249) | Acc: (92.00%) (16708/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.2243) | Acc: (92.00%) (17905/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.2240) | Acc: (92.00%) (19097/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.2243) | Acc: (92.00%) (20283/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.2237) | Acc: (92.00%) (21473/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.2231) | Acc: (92.00%) (22660/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.2230) | Acc: (92.00%) (23846/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.2235) | Acc: (92.00%) (25026/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.2230) | Acc: (92.00%) (26210/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.2235) | Acc: (92.00%) (27402/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.2236) | Acc: (92.00%) (28587/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.2224) | Acc: (92.00%) (29791/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.2219) | Acc: (92.00%) (30990/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.2221) | Acc: (92.00%) (32178/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.2223) | Acc: (92.00%) (33377/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.2224) | Acc: (92.00%) (34563/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.2217) | Acc: (92.00%) (35759/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.2211) | Acc: (92.00%) (36956/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.2209) | Acc: (92.00%) (38156/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.2218) | Acc: (92.00%) (39336/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.2219) | Acc: (92.00%) (40527/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.2214) | Acc: (92.00%) (41727/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.2216) | Acc: (92.00%) (42910/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.2216) | Acc: (92.00%) (44098/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.2214) | Acc: (92.00%) (45285/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.2212) | Acc: (92.00%) (46431/50000)
# TEST : Loss: (0.3103) | Acc: (89.00%) (8953/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1054, -0.1138, -0.0858],
          [-0.0334, -0.0778,  0.0117],
          [-0.0135, -0.1309, -0.1956]],

         [[-0.0246, -0.0748, -0.0350],
          [-0.1645, -0.0329,  0.0149],
          [ 0.0203,  0.0807, -0.0220]],

         [[-0.0515,  0.0934, -0.1876],
          [ 0.2162,  0.3509,  0.1602],
          [ 0.0016,  0.2522,  0.1780]]],


        [[[ 0.2849, -0.1103,  0.1641],
          [ 0.1412, -0.0171, -0.1275],
          [-0.2230, -0.1900, -0.2265]],

         [[ 0.0445, -0.2149,  0.0346],
          [-0.0733,  0.3569, -0.1770],
          [ 0.1747,  0.0775,  0.1830]],

         [[-0.1772, -0.1889, -0.0573],
          [-0.1917,  0.1467, -0.0390],
          [-0.0231,  0.1196,  0.1878]]],


        [[[-0.0239, -0.0435, -0.0526],
          [-0.0159, -0.0301, -0.0316],
          [-0.0195, -0.0195, -0.0003]],

         [[ 0.0151,  0.0185,  0.0002],
          [-0.0234, -0.0342, -0.0144],
          [-0.0352, -0.0117,  0.0033]],

         [[-0.0095,  0.0196,  0.0650],
          [-0.0137, -0.0188,  0.0489],
          [-0.0380,  0.0043,  0.0262]]],


        ...,


        [[[ 0.0380, -0.0010, -0.0803],
          [ 0.0389,  0.0429, -0.0292],
          [-0.1936,  0.0010,  0.0268]],

         [[-0.1002, -0.1861,  0.0334],
          [ 0.1236,  0.0057, -0.1274],
          [ 0.1186, -0.0722,  0.0126]],

         [[ 0.0503,  0.0900,  0.1298],
          [ 0.2870,  0.3180,  0.1259],
          [ 0.2648,  0.2133,  0.0857]]],


        [[[ 0.2297,  0.0912,  0.0902],
          [ 0.0944, -0.0444, -0.0495],
          [-0.0228,  0.1211, -0.0214]],

         [[-0.1676, -0.3039, -0.0280],
          [-0.0441, -0.3103, -0.2341],
          [ 0.0505, -0.0175, -0.0643]],

         [[ 0.0875, -0.1154,  0.0161],
          [ 0.0289, -0.0554,  0.0306],
          [-0.0256,  0.0379,  0.1137]]],


        [[[-0.0579, -0.1836, -0.1310],
          [-0.2066, -0.4208, -0.2605],
          [ 0.1223, -0.0937, -0.0937]],

         [[ 0.1538, -0.1513,  0.0235],
          [ 0.0530, -0.1313,  0.0939],
          [ 0.2024,  0.2328, -0.0009]],

         [[ 0.0565, -0.1675,  0.1070],
          [ 0.1258, -0.0128,  0.0665],
          [-0.1180, -0.0376,  0.0471]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2625]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0216]], device='cuda:0')

Epoch: 59 | Batch_idx: 0 |  Loss: (0.2227) | Acc: (92.00%) (118/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.2253) | Acc: (93.00%) (1313/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.2259) | Acc: (92.00%) (2499/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.2235) | Acc: (93.00%) (3694/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.2288) | Acc: (92.00%) (4874/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.2289) | Acc: (92.00%) (6066/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.2290) | Acc: (92.00%) (7260/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.2281) | Acc: (92.00%) (8444/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.2267) | Acc: (92.00%) (9635/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.2269) | Acc: (92.00%) (10826/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.2266) | Acc: (92.00%) (12012/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.2266) | Acc: (92.00%) (13193/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.2246) | Acc: (92.00%) (14400/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.2247) | Acc: (92.00%) (15585/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.2252) | Acc: (92.00%) (16776/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.2254) | Acc: (92.00%) (17961/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.2252) | Acc: (92.00%) (19150/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.2250) | Acc: (92.00%) (20347/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.2244) | Acc: (92.00%) (21539/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.2242) | Acc: (92.00%) (22729/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.2234) | Acc: (93.00%) (23928/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.2235) | Acc: (92.00%) (25115/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.2241) | Acc: (92.00%) (26298/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.2244) | Acc: (92.00%) (27471/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.2243) | Acc: (92.00%) (28653/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.2254) | Acc: (92.00%) (29829/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.2262) | Acc: (92.00%) (31007/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.2264) | Acc: (92.00%) (32190/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.2273) | Acc: (92.00%) (33368/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.2282) | Acc: (92.00%) (34548/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.2285) | Acc: (92.00%) (35738/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.2293) | Acc: (92.00%) (36914/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.2299) | Acc: (92.00%) (38093/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.2296) | Acc: (92.00%) (39273/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.2303) | Acc: (92.00%) (40440/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.2301) | Acc: (92.00%) (41625/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.2298) | Acc: (92.00%) (42822/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.2296) | Acc: (92.00%) (44017/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.2302) | Acc: (92.00%) (45193/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.2306) | Acc: (92.00%) (46325/50000)
# TEST : Loss: (0.3129) | Acc: (89.00%) (8943/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1035, -0.1118, -0.0843],
          [-0.0328, -0.0765,  0.0115],
          [-0.0133, -0.1288, -0.1925]],

         [[-0.0242, -0.0735, -0.0344],
          [-0.1616, -0.0324,  0.0146],
          [ 0.0200,  0.0794, -0.0216]],

         [[-0.0505,  0.0917, -0.1842],
          [ 0.2121,  0.3444,  0.1573],
          [ 0.0016,  0.2475,  0.1748]]],


        [[[ 0.2844, -0.1101,  0.1637],
          [ 0.1409, -0.0171, -0.1272],
          [-0.2225, -0.1897, -0.2261]],

         [[ 0.0444, -0.2145,  0.0345],
          [-0.0732,  0.3561, -0.1767],
          [ 0.1744,  0.0774,  0.1826]],

         [[-0.1768, -0.1885, -0.0572],
          [-0.1913,  0.1463, -0.0389],
          [-0.0230,  0.1193,  0.1874]]],


        [[[-0.0188, -0.0353, -0.0448],
          [-0.0098, -0.0214, -0.0261],
          [-0.0120, -0.0138, -0.0002]],

         [[ 0.0121,  0.0153,  0.0002],
          [-0.0159, -0.0255, -0.0120],
          [-0.0232, -0.0086,  0.0027]],

         [[-0.0077,  0.0162,  0.0556],
          [-0.0101, -0.0145,  0.0407],
          [-0.0272,  0.0032,  0.0217]]],


        ...,


        [[[ 0.0375, -0.0010, -0.0794],
          [ 0.0384,  0.0425, -0.0288],
          [-0.1914,  0.0010,  0.0265]],

         [[-0.0988, -0.1836,  0.0329],
          [ 0.1217,  0.0056, -0.1256],
          [ 0.1168, -0.0712,  0.0124]],

         [[ 0.0493,  0.0882,  0.1275],
          [ 0.2771,  0.3076,  0.1228],
          [ 0.2561,  0.2065,  0.0837]]],


        [[[ 0.2267,  0.0899,  0.0889],
          [ 0.0932, -0.0437, -0.0487],
          [-0.0225,  0.1196, -0.0211]],

         [[-0.1645, -0.2952, -0.0273],
          [-0.0432, -0.3009, -0.2267],
          [ 0.0498, -0.0171, -0.0631]],

         [[ 0.0857, -0.1119,  0.0157],
          [ 0.0283, -0.0536,  0.0296],
          [-0.0252,  0.0371,  0.1115]]],


        [[[-0.0572, -0.1798, -0.1288],
          [-0.2042, -0.4120, -0.2559],
          [ 0.1213, -0.0927, -0.0927]],

         [[ 0.1523, -0.1496,  0.0232],
          [ 0.0525, -0.1298,  0.0929],
          [ 0.2008,  0.2307, -0.0009]],

         [[ 0.0560, -0.1658,  0.1059],
          [ 0.1247, -0.0126,  0.0659],
          [-0.1171, -0.0373,  0.0467]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2670]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0092]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.1750) | Acc: (93.00%) (120/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.2635) | Acc: (90.00%) (1277/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3411) | Acc: (88.00%) (2372/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3805) | Acc: (87.00%) (3456/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.4254) | Acc: (85.00%) (4488/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.4437) | Acc: (85.00%) (5549/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.4531) | Acc: (84.00%) (6616/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.4625) | Acc: (84.00%) (7671/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.4601) | Acc: (84.00%) (8755/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.4566) | Acc: (84.00%) (9845/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.4576) | Acc: (84.00%) (10933/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.4532) | Acc: (84.00%) (12034/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.4532) | Acc: (84.00%) (13115/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.4519) | Acc: (84.00%) (14220/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.4490) | Acc: (84.00%) (15328/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.4447) | Acc: (85.00%) (16446/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.4430) | Acc: (85.00%) (17540/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.4391) | Acc: (85.00%) (18666/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.4361) | Acc: (85.00%) (19778/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.4319) | Acc: (85.00%) (20901/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.4276) | Acc: (85.00%) (22032/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.4252) | Acc: (85.00%) (23146/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.4227) | Acc: (85.00%) (24263/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.4209) | Acc: (85.00%) (25375/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.4192) | Acc: (85.00%) (26485/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.4160) | Acc: (85.00%) (27618/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.4127) | Acc: (86.00%) (28744/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.4094) | Acc: (86.00%) (29880/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.4082) | Acc: (86.00%) (30998/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.4077) | Acc: (86.00%) (32108/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.4060) | Acc: (86.00%) (33234/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.4046) | Acc: (86.00%) (34353/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.4022) | Acc: (86.00%) (35494/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.4010) | Acc: (86.00%) (36613/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.4002) | Acc: (86.00%) (37731/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3994) | Acc: (86.00%) (38849/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3982) | Acc: (86.00%) (39970/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3953) | Acc: (86.00%) (41118/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3946) | Acc: (86.00%) (42243/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3938) | Acc: (86.00%) (43323/50000)
# TEST : Loss: (0.4728) | Acc: (84.00%) (8435/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0924, -0.1166, -0.0796],
          [-0.0143, -0.0698,  0.0245],
          [ 0.0047, -0.1174, -0.1737]],

         [[-0.0187, -0.0799, -0.0365],
          [-0.1409, -0.0201,  0.0301],
          [ 0.0365,  0.0936, -0.0012]],

         [[-0.0386,  0.0917, -0.1803],
          [ 0.2370,  0.3619,  0.1776],
          [ 0.0262,  0.2685,  0.2000]]],


        [[[ 0.2977, -0.0936,  0.1788],
          [ 0.1499, -0.0041, -0.1298],
          [-0.2162, -0.1891, -0.2166]],

         [[ 0.0394, -0.2125,  0.0380],
          [-0.0716,  0.3689, -0.1822],
          [ 0.1797,  0.0870,  0.1940]],

         [[-0.1814, -0.1816, -0.0475],
          [-0.1919,  0.1572, -0.0350],
          [-0.0181,  0.1276,  0.2026]]],


        [[[ 0.0355,  0.0132, -0.0023],
          [ 0.0211,  0.0143,  0.0100],
          [-0.0148, -0.0122,  0.0132]],

         [[ 0.0579,  0.0581,  0.0405],
          [ 0.0021,  0.0028,  0.0216],
          [-0.0368, -0.0207,  0.0097]],

         [[ 0.0323,  0.0567,  0.0855],
          [-0.0012,  0.0097,  0.0643],
          [-0.0440, -0.0144,  0.0221]]],


        ...,


        [[[ 0.0468,  0.0068, -0.0808],
          [ 0.0656,  0.0608, -0.0211],
          [-0.1704,  0.0124,  0.0270]],

         [[-0.0958, -0.1842,  0.0181],
          [ 0.1488,  0.0219, -0.1237],
          [ 0.1326, -0.0620,  0.0051]],

         [[ 0.0527,  0.0861,  0.1067],
          [ 0.3320,  0.3440,  0.1262],
          [ 0.2747,  0.2111,  0.0665]]],


        [[[ 0.2253,  0.0778,  0.0739],
          [ 0.0865, -0.0562, -0.0559],
          [-0.0294,  0.1151, -0.0193]],

         [[-0.1788, -0.3319, -0.0514],
          [-0.0627, -0.3280, -0.2372],
          [ 0.0386, -0.0185, -0.0562]],

         [[ 0.0465, -0.1683, -0.0308],
          [-0.0117, -0.0926, -0.0038],
          [-0.0477,  0.0305,  0.1091]]],


        [[[-0.0300, -0.1894, -0.1218],
          [-0.1919, -0.4383, -0.2812],
          [ 0.1218, -0.1116, -0.1176]],

         [[ 0.1610, -0.1660,  0.0172],
          [ 0.0609, -0.1452,  0.0741],
          [ 0.1988,  0.2133, -0.0208]],

         [[ 0.0586, -0.1814,  0.1013],
          [ 0.1279, -0.0248,  0.0569],
          [-0.1168, -0.0443,  0.0390]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-4.7029e-03, -4.6146e-03, -1.8561e-03],
          [-4.7774e-03, -4.3545e-03, -1.2551e-03],
          [-4.9622e-03, -6.8406e-03, -3.1804e-03]],

         [[-1.0387e-03, -5.0069e-04,  1.7362e-03],
          [-1.9283e-03, -1.1459e-03,  1.6705e-03],
          [-2.3539e-03, -4.3199e-03, -9.8656e-04]],

         [[-5.0613e-04, -3.9349e-05,  2.0685e-03],
          [-1.8393e-03, -1.5981e-03,  1.5081e-03],
          [-2.1496e-03, -4.8199e-03, -1.0623e-03]]],


        [[[ 5.2956e-02,  4.2212e-02,  4.3051e-02],
          [ 5.6106e-02,  2.0495e-02,  1.6596e-02],
          [ 3.7122e-02, -8.2776e-03, -3.1197e-02]],

         [[ 5.1306e-02,  4.9198e-02,  2.6156e-02],
          [ 6.3426e-02,  2.8288e-02,  1.8292e-02],
          [ 4.2747e-02, -9.8576e-04, -1.9961e-02]],

         [[ 3.2614e-02,  2.7018e-02,  6.6908e-03],
          [ 3.7765e-02,  9.3687e-03, -1.7809e-03],
          [ 1.5839e-02, -2.0227e-02, -2.6686e-02]]],


        [[[-2.4471e-05, -1.3335e-04, -4.7146e-05],
          [-1.2415e-04, -3.1951e-04, -2.0760e-04],
          [-2.7102e-04, -4.6412e-04, -3.5551e-04]],

         [[ 5.6897e-06, -1.1503e-04,  7.4133e-06],
          [-1.1212e-04, -3.6284e-04, -2.4071e-04],
          [-2.6232e-04, -5.3451e-04, -4.4990e-04]],

         [[ 1.5366e-04, -8.9277e-06,  6.7808e-05],
          [ 5.8477e-06, -2.5394e-04, -1.6764e-04],
          [-1.6953e-04, -4.3751e-04, -3.7485e-04]]],


        ...,


        [[[ 9.8716e-03,  1.1647e-02,  1.8144e-02],
          [ 1.2152e-02,  1.5746e-02,  2.0981e-02],
          [ 1.3919e-02,  1.5631e-02,  1.8092e-02]],

         [[ 5.6299e-03,  6.4939e-03,  1.3722e-02],
          [ 5.7566e-03,  8.3126e-03,  1.4451e-02],
          [ 5.3256e-03,  6.0747e-03,  9.3917e-03]],

         [[ 1.7265e-03,  1.3673e-03,  8.1051e-03],
          [ 4.9917e-04,  1.8516e-03,  8.7361e-03],
          [-5.2077e-04, -2.5876e-04,  4.2476e-03]]],


        [[[-1.1033e-02, -3.5517e-03,  3.2885e-04],
          [-1.2922e-02, -7.2189e-03, -6.4574e-03],
          [-1.3664e-02, -1.1427e-02, -9.8928e-03]],

         [[-7.7840e-03, -1.3049e-03,  1.5987e-03],
          [-7.2534e-03, -2.2988e-03, -3.2178e-03],
          [-6.7599e-03, -4.9355e-03, -5.1132e-03]],

         [[-7.6482e-03, -2.0096e-03,  8.3159e-04],
          [-6.4693e-03, -2.1106e-03, -2.7094e-03],
          [-5.7880e-03, -4.1202e-03, -4.1814e-03]]],


        [[[ 4.3898e-03,  8.8089e-03,  1.1075e-02],
          [-9.7077e-04,  2.9531e-03,  3.2051e-03],
          [ 1.1185e-03, -6.3232e-04, -3.2649e-04]],

         [[ 1.5057e-02,  1.7132e-02,  1.9324e-02],
          [ 1.1383e-02,  1.2343e-02,  1.1344e-02],
          [ 1.4884e-02,  1.1934e-02,  9.9819e-03]],

         [[ 2.0430e-02,  2.0636e-02,  2.3508e-02],
          [ 1.8034e-02,  1.7097e-02,  1.5979e-02],
          [ 2.2462e-02,  1.7745e-02,  1.5178e-02]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2653]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 61 | Batch_idx: 0 |  Loss: (0.3950) | Acc: (88.00%) (113/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3132) | Acc: (89.00%) (1254/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3288) | Acc: (88.00%) (2391/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3153) | Acc: (89.00%) (3538/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3117) | Acc: (89.00%) (4692/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3090) | Acc: (89.00%) (5834/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3153) | Acc: (89.00%) (6972/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3141) | Acc: (89.00%) (8118/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3152) | Acc: (89.00%) (9252/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3150) | Acc: (89.00%) (10397/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3131) | Acc: (89.00%) (11536/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3119) | Acc: (89.00%) (12691/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3095) | Acc: (89.00%) (13845/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3099) | Acc: (89.00%) (14981/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3092) | Acc: (89.00%) (16138/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3067) | Acc: (89.00%) (17300/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3061) | Acc: (89.00%) (18445/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3075) | Acc: (89.00%) (19578/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3069) | Acc: (89.00%) (20714/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3079) | Acc: (89.00%) (21864/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3093) | Acc: (89.00%) (22998/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3082) | Acc: (89.00%) (24152/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3084) | Acc: (89.00%) (25291/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3073) | Acc: (89.00%) (26443/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3077) | Acc: (89.00%) (27596/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3069) | Acc: (89.00%) (28750/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3064) | Acc: (89.00%) (29898/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3076) | Acc: (89.00%) (31031/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3077) | Acc: (89.00%) (32170/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3061) | Acc: (89.00%) (33338/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3052) | Acc: (89.00%) (34497/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3048) | Acc: (89.00%) (35651/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3047) | Acc: (89.00%) (36808/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3042) | Acc: (89.00%) (37967/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3042) | Acc: (89.00%) (39117/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3040) | Acc: (89.00%) (40273/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3041) | Acc: (89.00%) (41412/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3037) | Acc: (89.00%) (42561/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3036) | Acc: (89.00%) (43703/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3040) | Acc: (89.00%) (44801/50000)
# TEST : Loss: (0.3906) | Acc: (87.00%) (8720/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1004, -0.1164, -0.0794],
          [-0.0280, -0.0791,  0.0134],
          [-0.0038, -0.1250, -0.1801]],

         [[-0.0194, -0.0714, -0.0292],
          [-0.1491, -0.0223,  0.0244],
          [ 0.0287,  0.0899, -0.0040]],

         [[-0.0395,  0.1006, -0.1721],
          [ 0.2302,  0.3662,  0.1795],
          [ 0.0259,  0.2759,  0.2069]]],


        [[[ 0.2877, -0.0971,  0.1893],
          [ 0.1417, -0.0019, -0.1250],
          [-0.2181, -0.2008, -0.2210]],

         [[ 0.0254, -0.2215,  0.0478],
          [-0.0823,  0.3696, -0.1767],
          [ 0.1782,  0.0812,  0.1906]],

         [[-0.1977, -0.1935, -0.0407],
          [-0.2082,  0.1539, -0.0277],
          [-0.0193,  0.1215,  0.2036]]],


        [[[ 0.0308,  0.0152, -0.0042],
          [ 0.0254,  0.0185,  0.0080],
          [ 0.0024,  0.0015,  0.0190]],

         [[ 0.0438,  0.0520,  0.0306],
          [ 0.0035,  0.0063,  0.0155],
          [-0.0210, -0.0082,  0.0141]],

         [[ 0.0310,  0.0610,  0.0771],
          [ 0.0092,  0.0257,  0.0623],
          [-0.0203,  0.0076,  0.0356]]],


        ...,


        [[[ 0.0359,  0.0019, -0.0708],
          [ 0.0533,  0.0520, -0.0181],
          [-0.1781,  0.0050,  0.0273]],

         [[-0.1107, -0.1935,  0.0261],
          [ 0.1313,  0.0088, -0.1183],
          [ 0.1210, -0.0684,  0.0113]],

         [[ 0.0461,  0.0860,  0.1215],
          [ 0.3311,  0.3562,  0.1522],
          [ 0.2847,  0.2296,  0.0903]]],


        [[[ 0.2373,  0.0842,  0.0821],
          [ 0.0955, -0.0545, -0.0564],
          [-0.0171,  0.1279, -0.0126]],

         [[-0.1590, -0.3241, -0.0455],
          [-0.0496, -0.3276, -0.2407],
          [ 0.0497, -0.0059, -0.0502]],

         [[ 0.0668, -0.1598, -0.0227],
          [ 0.0090, -0.0779,  0.0048],
          [-0.0289,  0.0534,  0.1218]]],


        [[[-0.0237, -0.1999, -0.1191],
          [-0.1962, -0.4506, -0.2823],
          [ 0.1293, -0.0995, -0.1052]],

         [[ 0.1546, -0.1869,  0.0086],
          [ 0.0471, -0.1628,  0.0696],
          [ 0.1954,  0.2120, -0.0140]],

         [[ 0.0620, -0.1875,  0.0995],
          [ 0.1261, -0.0263,  0.0613],
          [-0.1110, -0.0362,  0.0515]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0124, -0.0079, -0.0045],
          [-0.0112, -0.0063, -0.0043],
          [-0.0084, -0.0045, -0.0022]],

         [[-0.0105, -0.0055, -0.0004],
          [-0.0090, -0.0042, -0.0005],
          [-0.0054, -0.0021,  0.0013]],

         [[-0.0108, -0.0068, -0.0034],
          [-0.0092, -0.0058, -0.0033],
          [-0.0059, -0.0037, -0.0015]]],


        [[[-0.1060, -0.0889, -0.0010],
          [-0.1248, -0.0874, -0.0266],
          [-0.1472, -0.1573, -0.0871]],

         [[-0.1098, -0.0982, -0.0274],
          [-0.1152, -0.0901, -0.0408],
          [-0.1456, -0.1583, -0.0890]],

         [[-0.0445, -0.0340,  0.0103],
          [-0.0467, -0.0301, -0.0000],
          [-0.0884, -0.0811, -0.0219]]],


        [[[ 0.0002,  0.0001, -0.0000],
          [ 0.0002,  0.0001,  0.0001],
          [ 0.0003,  0.0003,  0.0004]],

         [[ 0.0002, -0.0000, -0.0002],
          [ 0.0002, -0.0000, -0.0000],
          [ 0.0003,  0.0002,  0.0002]],

         [[ 0.0002, -0.0001, -0.0003],
          [ 0.0002, -0.0001, -0.0001],
          [ 0.0002,  0.0002,  0.0001]]],


        ...,


        [[[-0.0063, -0.0058, -0.0030],
          [-0.0087, -0.0100, -0.0091],
          [-0.0089, -0.0125, -0.0148]],

         [[-0.0063, -0.0067, -0.0047],
          [-0.0070, -0.0081, -0.0081],
          [-0.0039, -0.0061, -0.0084]],

         [[-0.0026, -0.0024, -0.0011],
          [-0.0023, -0.0015, -0.0017],
          [-0.0002,  0.0007, -0.0012]]],


        [[[-0.0108, -0.0104, -0.0140],
          [-0.0135, -0.0110, -0.0066],
          [-0.0196, -0.0174, -0.0109]],

         [[-0.0063, -0.0056, -0.0117],
          [-0.0070, -0.0051, -0.0034],
          [-0.0110, -0.0107, -0.0069]],

         [[-0.0078, -0.0077, -0.0135],
          [-0.0089, -0.0071, -0.0045],
          [-0.0096, -0.0094, -0.0058]]],


        [[[-0.0034, -0.0020, -0.0075],
          [-0.0067, -0.0036, -0.0011],
          [-0.0128, -0.0101, -0.0036]],

         [[-0.0037, -0.0028, -0.0093],
          [-0.0051, -0.0020, -0.0013],
          [-0.0107, -0.0083, -0.0034]],

         [[-0.0010, -0.0016, -0.0081],
          [-0.0031, -0.0020, -0.0010],
          [-0.0045, -0.0042, -0.0013]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2648]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 62 | Batch_idx: 0 |  Loss: (0.2455) | Acc: (92.00%) (119/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.2795) | Acc: (91.00%) (1288/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.2918) | Acc: (90.00%) (2432/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.2842) | Acc: (90.00%) (3597/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.2814) | Acc: (90.00%) (4766/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.2822) | Acc: (90.00%) (5915/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.2800) | Acc: (90.00%) (7083/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.2762) | Acc: (90.00%) (8255/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.2751) | Acc: (90.00%) (9422/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.2755) | Acc: (90.00%) (10579/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.2761) | Acc: (90.00%) (11747/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.2783) | Acc: (90.00%) (12898/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.2753) | Acc: (90.00%) (14077/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.2743) | Acc: (90.00%) (15242/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.2729) | Acc: (90.00%) (16410/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.2728) | Acc: (90.00%) (17571/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.2736) | Acc: (90.00%) (18722/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.2731) | Acc: (90.00%) (19887/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.2718) | Acc: (90.00%) (21057/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.2709) | Acc: (90.00%) (22229/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.2722) | Acc: (90.00%) (23383/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.2730) | Acc: (90.00%) (24524/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.2751) | Acc: (90.00%) (25656/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.2744) | Acc: (90.00%) (26817/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.2744) | Acc: (90.00%) (27974/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.2733) | Acc: (90.00%) (29138/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.2726) | Acc: (90.00%) (30307/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.2728) | Acc: (90.00%) (31462/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.2732) | Acc: (90.00%) (32619/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.2728) | Acc: (90.00%) (33786/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.2721) | Acc: (90.00%) (34958/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.2722) | Acc: (90.00%) (36120/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.2706) | Acc: (90.00%) (37309/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.2703) | Acc: (90.00%) (38478/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.2709) | Acc: (90.00%) (39638/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.2704) | Acc: (90.00%) (40802/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.2715) | Acc: (90.00%) (41941/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.2716) | Acc: (90.00%) (43098/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.2724) | Acc: (90.00%) (44249/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.2719) | Acc: (90.00%) (45372/50000)
# TEST : Loss: (0.3971) | Acc: (86.00%) (8681/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1298, -0.1434, -0.1024],
          [-0.0544, -0.1039, -0.0105],
          [-0.0350, -0.1573, -0.2110]],

         [[-0.0499, -0.0988, -0.0561],
          [-0.1737, -0.0462, -0.0024],
          [-0.0017,  0.0578, -0.0384]],

         [[-0.0703,  0.0705, -0.2033],
          [ 0.2039,  0.3415,  0.1494],
          [-0.0019,  0.2468,  0.1727]]],


        [[[ 0.2952, -0.0966,  0.1886],
          [ 0.1459, -0.0026, -0.1274],
          [-0.2185, -0.2051, -0.2158]],

         [[ 0.0277, -0.2260,  0.0405],
          [-0.0830,  0.3681, -0.1786],
          [ 0.1780,  0.0824,  0.1993]],

         [[-0.1917, -0.1947, -0.0452],
          [-0.2071,  0.1503, -0.0300],
          [-0.0174,  0.1215,  0.2087]]],


        [[[ 0.0325,  0.0145, -0.0076],
          [ 0.0233,  0.0141,  0.0037],
          [-0.0010, -0.0013,  0.0130]],

         [[ 0.0429,  0.0454,  0.0223],
          [ 0.0059,  0.0035,  0.0103],
          [-0.0173, -0.0062,  0.0115]],

         [[ 0.0341,  0.0513,  0.0592],
          [ 0.0141,  0.0216,  0.0503],
          [-0.0117,  0.0122,  0.0342]]],


        ...,


        [[[ 0.0127, -0.0206, -0.0821],
          [ 0.0298,  0.0289, -0.0338],
          [-0.1994, -0.0192,  0.0094]],

         [[-0.1366, -0.2198,  0.0129],
          [ 0.1082, -0.0145, -0.1309],
          [ 0.1067, -0.0863,  0.0016]],

         [[ 0.0322,  0.0722,  0.1230],
          [ 0.3103,  0.3380,  0.1561],
          [ 0.2798,  0.2164,  0.0950]]],


        [[[ 0.2380,  0.0838,  0.0923],
          [ 0.1013, -0.0581, -0.0566],
          [-0.0142,  0.1217, -0.0093]],

         [[-0.1580, -0.3292, -0.0412],
          [-0.0468, -0.3411, -0.2529],
          [ 0.0489, -0.0173, -0.0545]],

         [[ 0.0729, -0.1568, -0.0193],
          [ 0.0189, -0.0779,  0.0014],
          [-0.0228,  0.0514,  0.1235]]],


        [[[-0.0287, -0.2100, -0.0858],
          [-0.2083, -0.4653, -0.2458],
          [ 0.1277, -0.0907, -0.0731]],

         [[ 0.1512, -0.1913,  0.0276],
          [ 0.0413, -0.1659,  0.0919],
          [ 0.1979,  0.2211,  0.0123]],

         [[ 0.0657, -0.1851,  0.1155],
          [ 0.1249, -0.0229,  0.0812],
          [-0.1055, -0.0241,  0.0751]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 9.9322e-04, -5.8489e-04, -1.2709e-03],
          [-5.6891e-04, -1.6386e-03, -1.3008e-03],
          [-2.8991e-04, -1.7456e-03, -1.2030e-03]],

         [[ 1.4790e-03, -4.4453e-05, -8.0026e-04],
          [-7.0993e-05, -1.0345e-03, -7.3205e-04],
          [ 1.8120e-04, -1.1055e-03, -6.2713e-04]],

         [[ 9.9606e-04,  1.7494e-04, -5.2695e-04],
          [-7.2912e-04, -7.3609e-04, -8.7478e-05],
          [-6.6326e-04, -1.5248e-03, -5.5365e-04]]],


        [[[-4.7712e-02, -4.4473e-02, -2.6755e-02],
          [-7.0213e-02, -4.8760e-02, -4.5879e-02],
          [-5.7374e-02, -3.7170e-02, -8.9874e-03]],

         [[-2.8582e-02, -1.7758e-02,  2.4417e-03],
          [-4.7208e-02, -2.1479e-02, -1.4884e-02],
          [-4.2563e-02, -1.6414e-02,  6.4569e-03]],

         [[ 8.6543e-03,  2.9177e-02,  3.6580e-02],
          [-9.2098e-03,  2.7770e-02,  2.8552e-02],
          [-8.0027e-03,  7.9653e-03,  2.5699e-02]]],


        [[[-4.3548e-05,  3.3676e-05,  3.7669e-05],
          [-1.1185e-04, -7.9977e-06, -8.9536e-06],
          [-6.4842e-05, -2.1896e-05, -6.9206e-06]],

         [[-4.6681e-05,  3.0177e-05,  5.8308e-05],
          [-1.6109e-04, -4.7899e-05, -1.0774e-05],
          [-1.1602e-04, -6.9047e-05, -9.8468e-06]],

         [[-2.2506e-05,  3.3070e-05,  6.4903e-05],
          [-1.4176e-04, -5.3228e-05, -2.2968e-06],
          [-9.9133e-05, -7.0400e-05,  6.8837e-06]]],


        ...,


        [[[-2.7066e-03, -2.0048e-03, -4.0052e-03],
          [ 1.5668e-03,  2.1705e-03,  3.4392e-04],
          [ 4.7503e-03,  4.7304e-03,  6.3867e-04]],

         [[-4.1704e-03, -3.0055e-03, -4.6255e-03],
          [-4.9267e-04,  5.3298e-04, -9.8441e-04],
          [ 1.3739e-03,  1.9323e-03, -1.9588e-03]],

         [[-4.2925e-03, -2.9064e-03, -4.4942e-03],
          [-9.5068e-04,  8.2371e-04, -5.4541e-04],
          [ 5.6848e-04,  1.6149e-03, -1.4298e-03]]],


        [[[ 7.5306e-03,  1.2063e-02,  1.8410e-02],
          [ 9.9620e-03,  1.5101e-02,  1.7440e-02],
          [ 7.3211e-03,  1.6328e-02,  1.7326e-02]],

         [[-6.2326e-04,  3.7670e-03,  6.5562e-03],
          [ 5.5286e-04,  5.1762e-03,  4.6671e-03],
          [-3.3264e-03,  4.8523e-03,  4.5535e-03]],

         [[-4.4439e-03,  3.4743e-04,  2.2579e-03],
          [-4.0101e-03,  1.1843e-03,  4.0490e-04],
          [-8.4632e-03,  7.4016e-05, -6.7886e-04]]],


        [[[-1.3820e-03,  4.8399e-03,  1.5096e-03],
          [-4.8518e-03, -1.2518e-03, -5.9853e-03],
          [-7.9396e-03, -2.4891e-03, -9.9692e-03]],

         [[ 4.1439e-03,  1.0469e-02,  6.1385e-03],
          [ 5.8877e-04,  4.7756e-03,  8.3656e-04],
          [-4.8451e-03,  1.6345e-03, -3.6895e-03]],

         [[ 1.3007e-02,  1.6095e-02,  1.0612e-02],
          [ 8.2293e-03,  1.2592e-02,  7.4037e-03],
          [-3.3730e-04,  8.5005e-03,  4.6763e-03]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2641]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 63 | Batch_idx: 0 |  Loss: (0.2474) | Acc: (93.00%) (120/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.2315) | Acc: (92.00%) (1301/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.2323) | Acc: (92.00%) (2480/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.2398) | Acc: (92.00%) (3654/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.2444) | Acc: (92.00%) (4830/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.2464) | Acc: (91.00%) (5994/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.2465) | Acc: (91.00%) (7160/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.2431) | Acc: (91.00%) (8350/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.2414) | Acc: (91.00%) (9525/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.2425) | Acc: (91.00%) (10693/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.2425) | Acc: (91.00%) (11862/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.2425) | Acc: (91.00%) (13044/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.2416) | Acc: (91.00%) (14231/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.2433) | Acc: (91.00%) (15383/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.2428) | Acc: (91.00%) (16568/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.2431) | Acc: (91.00%) (17744/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.2425) | Acc: (91.00%) (18917/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.2453) | Acc: (91.00%) (20064/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.2462) | Acc: (91.00%) (21221/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.2458) | Acc: (91.00%) (22399/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.2471) | Acc: (91.00%) (23554/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.2481) | Acc: (91.00%) (24713/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.2482) | Acc: (91.00%) (25881/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.2486) | Acc: (91.00%) (27051/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.2476) | Acc: (91.00%) (28237/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.2476) | Acc: (91.00%) (29412/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.2482) | Acc: (91.00%) (30572/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.2490) | Acc: (91.00%) (31736/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.2488) | Acc: (91.00%) (32919/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.2479) | Acc: (91.00%) (34103/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.2494) | Acc: (91.00%) (35259/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.2507) | Acc: (91.00%) (36401/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.2515) | Acc: (91.00%) (37565/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.2518) | Acc: (91.00%) (38734/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.2518) | Acc: (91.00%) (39890/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.2515) | Acc: (91.00%) (41065/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.2511) | Acc: (91.00%) (42232/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.2519) | Acc: (91.00%) (43391/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.2514) | Acc: (91.00%) (44560/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.2523) | Acc: (91.00%) (45662/50000)
# TEST : Loss: (0.4093) | Acc: (87.00%) (8706/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1225, -0.1325, -0.0951],
          [-0.0475, -0.0915,  0.0022],
          [-0.0337, -0.1484, -0.1978]],

         [[-0.0448, -0.0902, -0.0522],
          [-0.1683, -0.0361,  0.0072],
          [-0.0031,  0.0631, -0.0294]],

         [[-0.0614,  0.0820, -0.1938],
          [ 0.2120,  0.3544,  0.1643],
          [ 0.0035,  0.2570,  0.1866]]],


        [[[ 0.3063, -0.0902,  0.1918],
          [ 0.1600,  0.0052, -0.1234],
          [-0.2112, -0.2105, -0.2256]],

         [[ 0.0326, -0.2242,  0.0372],
          [-0.0738,  0.3762, -0.1760],
          [ 0.1850,  0.0816,  0.1900]],

         [[-0.1908, -0.1943, -0.0497],
          [-0.2009,  0.1521, -0.0308],
          [-0.0109,  0.1181,  0.1979]]],


        [[[ 0.0236,  0.0182, -0.0050],
          [ 0.0099,  0.0160,  0.0027],
          [-0.0103,  0.0027,  0.0085]],

         [[ 0.0278,  0.0431,  0.0196],
          [-0.0061,  0.0085,  0.0089],
          [-0.0210,  0.0023,  0.0089]],

         [[ 0.0277,  0.0531,  0.0523],
          [ 0.0131,  0.0337,  0.0475],
          [-0.0049,  0.0269,  0.0335]]],


        ...,


        [[[ 0.0338, -0.0057, -0.0787],
          [ 0.0455,  0.0338, -0.0356],
          [-0.1890, -0.0144,  0.0110]],

         [[-0.1209, -0.2086,  0.0094],
          [ 0.1206, -0.0153, -0.1405],
          [ 0.1120, -0.0866, -0.0046]],

         [[ 0.0456,  0.0859,  0.1198],
          [ 0.3328,  0.3428,  0.1491],
          [ 0.2905,  0.2190,  0.0921]]],


        [[[ 0.2424,  0.0837,  0.0908],
          [ 0.1024, -0.0613, -0.0620],
          [-0.0143,  0.1213, -0.0085]],

         [[-0.1473, -0.3239, -0.0384],
          [-0.0462, -0.3472, -0.2571],
          [ 0.0492, -0.0157, -0.0502]],

         [[ 0.0835, -0.1442, -0.0060],
          [ 0.0214, -0.0753,  0.0084],
          [-0.0175,  0.0590,  0.1349]]],


        [[[-0.0140, -0.2132, -0.0782],
          [-0.1984, -0.4712, -0.2451],
          [ 0.1320, -0.0855, -0.0682]],

         [[ 0.1540, -0.2004,  0.0277],
          [ 0.0427, -0.1738,  0.0912],
          [ 0.1954,  0.2189,  0.0146]],

         [[ 0.0666, -0.1895,  0.1165],
          [ 0.1207, -0.0298,  0.0814],
          [-0.1091, -0.0244,  0.0793]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-1.4468e-03, -1.2820e-04, -1.5909e-03],
          [-1.3488e-03,  5.8656e-04, -2.8963e-03],
          [-2.0199e-03,  8.9578e-04, -1.2502e-03]],

         [[-1.4996e-03, -1.8256e-03, -4.0956e-03],
          [-1.2743e-03, -8.5255e-04, -4.7532e-03],
          [-2.2767e-03, -6.4098e-04, -2.9971e-03]],

         [[ 2.8503e-04, -1.1590e-03, -3.8910e-03],
          [ 3.7298e-04, -8.2090e-04, -4.9306e-03],
          [-7.2415e-04, -8.9317e-04, -3.4281e-03]]],


        [[[ 6.2825e-02,  4.1564e-02,  2.4253e-02],
          [ 7.6907e-02,  3.3003e-02,  5.3918e-02],
          [ 1.7106e-01,  1.0425e-01,  1.0895e-01]],

         [[ 2.6236e-02,  1.6366e-02, -3.8027e-04],
          [ 5.3437e-02,  2.4065e-02,  4.6216e-02],
          [ 1.4156e-01,  9.3130e-02,  1.0100e-01]],

         [[ 4.5240e-02,  3.5927e-02,  1.7137e-02],
          [ 6.3896e-02,  4.1456e-02,  6.6623e-02],
          [ 1.3344e-01,  9.8673e-02,  1.1823e-01]]],


        [[[-3.3583e-05,  1.6966e-06, -3.5661e-05],
          [-2.6618e-05,  5.1721e-06, -3.8157e-05],
          [-9.1936e-05, -6.2676e-05, -8.2563e-05]],

         [[-3.2408e-05,  6.7271e-06, -2.8140e-05],
          [-3.9088e-05,  7.4452e-06, -2.7284e-05],
          [-1.0997e-04, -6.0183e-05, -7.3936e-05]],

         [[-1.4177e-05,  3.0752e-05, -2.1340e-06],
          [-2.5816e-05,  3.6040e-05, -2.7171e-07],
          [-1.0175e-04, -3.1701e-05, -3.9490e-05]]],


        ...,


        [[[ 1.3785e-02,  1.8569e-02,  2.1748e-02],
          [ 1.2062e-02,  1.5369e-02,  1.5985e-02],
          [ 9.8944e-03,  8.6935e-03,  6.1631e-03]],

         [[ 6.0459e-03,  7.5792e-03,  9.2407e-03],
          [ 4.9460e-03,  5.6690e-03,  4.4540e-03],
          [ 4.1104e-03,  1.8968e-04, -4.1066e-03]],

         [[ 4.1606e-03,  6.0697e-03,  7.6976e-03],
          [ 3.0849e-03,  4.3298e-03,  2.6319e-03],
          [ 2.0777e-03, -3.7957e-04, -4.7188e-03]]],


        [[[-1.3515e-02, -1.1546e-02, -1.7090e-03],
          [-9.8167e-03, -8.7716e-03, -2.9429e-03],
          [-1.5527e-02, -2.0519e-02, -1.1393e-02]],

         [[-1.1960e-02, -9.2654e-03, -2.2621e-03],
          [-9.6150e-03, -7.7347e-03, -4.5639e-03],
          [-1.8333e-02, -2.3863e-02, -1.7456e-02]],

         [[-1.0869e-02, -6.1051e-03,  3.6633e-04],
          [-1.0370e-02, -6.2319e-03, -2.4669e-03],
          [-1.8818e-02, -2.1389e-02, -1.4467e-02]]],


        [[[-2.5559e-04, -4.2314e-03, -2.1220e-03],
          [ 6.7476e-03,  7.2533e-04, -7.5891e-04],
          [-2.4813e-04, -1.2119e-02, -1.1797e-02]],

         [[-7.9497e-03, -1.4534e-02, -1.2479e-02],
          [ 1.3620e-03, -6.5715e-03, -7.1146e-03],
          [-7.5021e-03, -2.0372e-02, -1.8400e-02]],

         [[ 4.7373e-03, -1.1602e-03,  3.3086e-03],
          [ 1.3001e-02,  6.7601e-03,  8.3926e-03],
          [-2.8380e-03, -1.1636e-02, -8.0378e-03]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2633]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 64 | Batch_idx: 0 |  Loss: (0.2124) | Acc: (92.00%) (119/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.2323) | Acc: (91.00%) (1284/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.2263) | Acc: (91.00%) (2463/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.2217) | Acc: (91.00%) (3643/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.2213) | Acc: (91.00%) (4824/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.2174) | Acc: (92.00%) (6015/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.2175) | Acc: (92.00%) (7198/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.2201) | Acc: (92.00%) (8372/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.2239) | Acc: (92.00%) (9542/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.2249) | Acc: (92.00%) (10720/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.2268) | Acc: (92.00%) (11899/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.2282) | Acc: (92.00%) (13073/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.2277) | Acc: (92.00%) (14257/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.2275) | Acc: (92.00%) (15439/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.2289) | Acc: (91.00%) (16602/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.2300) | Acc: (91.00%) (17772/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.2280) | Acc: (92.00%) (18965/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.2281) | Acc: (92.00%) (20146/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.2297) | Acc: (91.00%) (21310/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.2298) | Acc: (92.00%) (22501/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.2285) | Acc: (92.00%) (23689/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.2306) | Acc: (91.00%) (24846/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.2299) | Acc: (92.00%) (26025/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.2301) | Acc: (91.00%) (27194/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.2311) | Acc: (91.00%) (28366/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.2323) | Acc: (91.00%) (29538/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.2327) | Acc: (91.00%) (30715/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.2337) | Acc: (91.00%) (31883/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.2350) | Acc: (91.00%) (33058/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.2344) | Acc: (91.00%) (34248/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.2352) | Acc: (91.00%) (35428/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.2352) | Acc: (91.00%) (36597/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.2350) | Acc: (91.00%) (37785/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.2357) | Acc: (91.00%) (38961/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.2356) | Acc: (91.00%) (40141/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.2361) | Acc: (91.00%) (41320/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.2357) | Acc: (91.00%) (42498/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.2358) | Acc: (91.00%) (43678/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.2363) | Acc: (91.00%) (44837/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.2363) | Acc: (91.00%) (45969/50000)
# TEST : Loss: (0.3681) | Acc: (87.00%) (8799/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1203, -0.1308, -0.0951],
          [-0.0471, -0.0889,  0.0044],
          [-0.0279, -0.1412, -0.1893]],

         [[-0.0445, -0.0874, -0.0510],
          [-0.1662, -0.0297,  0.0135],
          [ 0.0037,  0.0731, -0.0185]],

         [[-0.0668,  0.0813, -0.1903],
          [ 0.2059,  0.3568,  0.1713],
          [ 0.0056,  0.2642,  0.1970]]],


        [[[ 0.3002, -0.0944,  0.1875],
          [ 0.1479, -0.0027, -0.1322],
          [-0.2204, -0.2202, -0.2283]],

         [[ 0.0271, -0.2310,  0.0301],
          [-0.0830,  0.3698, -0.1821],
          [ 0.1792,  0.0780,  0.1916]],

         [[-0.1937, -0.2029, -0.0525],
          [-0.2091,  0.1457, -0.0340],
          [-0.0107,  0.1194,  0.2032]]],


        [[[ 0.0183,  0.0136, -0.0058],
          [ 0.0060,  0.0118,  0.0015],
          [-0.0106,  0.0014,  0.0072]],

         [[ 0.0218,  0.0338,  0.0157],
          [-0.0053,  0.0069,  0.0081],
          [-0.0179,  0.0028,  0.0094]],

         [[ 0.0211,  0.0383,  0.0395],
          [ 0.0085,  0.0236,  0.0363],
          [-0.0058,  0.0208,  0.0280]]],


        ...,


        [[[ 0.0282, -0.0043, -0.0678],
          [ 0.0401,  0.0368, -0.0267],
          [-0.1899, -0.0103,  0.0203]],

         [[-0.1241, -0.2077,  0.0170],
          [ 0.1210, -0.0072, -0.1290],
          [ 0.1206, -0.0732,  0.0106]],

         [[ 0.0378,  0.0803,  0.1221],
          [ 0.3289,  0.3513,  0.1615],
          [ 0.3033,  0.2369,  0.1089]]],


        [[[ 0.2508,  0.0883,  0.0807],
          [ 0.1093, -0.0540, -0.0692],
          [-0.0151,  0.1204, -0.0167]],

         [[-0.1454, -0.3230, -0.0575],
          [-0.0457, -0.3372, -0.2690],
          [ 0.0439, -0.0166, -0.0606]],

         [[ 0.0820, -0.1526, -0.0355],
          [ 0.0266, -0.0619, -0.0044],
          [-0.0147,  0.0648,  0.1297]]],


        [[[-0.0514, -0.2375, -0.0995],
          [-0.2198, -0.4778, -0.2716],
          [ 0.1216, -0.0874, -0.0883]],

         [[ 0.1375, -0.1983,  0.0217],
          [ 0.0394, -0.1608,  0.0847],
          [ 0.1946,  0.2257,  0.0058]],

         [[ 0.0522, -0.1897,  0.1028],
          [ 0.1167, -0.0210,  0.0674],
          [-0.1085, -0.0172,  0.0652]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 2.7337e-03,  1.7835e-03,  1.3598e-06],
          [ 3.0146e-03,  5.3904e-04, -8.4401e-04],
          [ 1.8871e-03,  1.0516e-04,  1.3944e-04]],

         [[ 4.5733e-03,  4.1723e-03,  1.9653e-03],
          [ 4.8322e-03,  2.9714e-03,  1.2566e-03],
          [ 3.3536e-03,  2.0928e-03,  1.9980e-03]],

         [[ 3.2584e-03,  3.2535e-03,  1.5183e-03],
          [ 3.5859e-03,  2.1704e-03,  1.0464e-03],
          [ 2.3648e-03,  1.5819e-03,  1.9041e-03]]],


        [[[-6.9075e-02, -8.0571e-02, -1.0782e-01],
          [-8.2755e-02, -1.1168e-01, -1.4028e-01],
          [-6.7271e-02, -9.6265e-02, -9.1757e-02]],

         [[-3.0026e-02, -3.9548e-02, -7.2837e-02],
          [-4.7514e-02, -7.6258e-02, -1.1599e-01],
          [-4.4776e-02, -7.6514e-02, -7.8956e-02]],

         [[-2.2132e-02, -2.6887e-02, -5.7699e-02],
          [-3.9014e-02, -5.6206e-02, -9.2203e-02],
          [-3.8787e-02, -6.2479e-02, -6.1835e-02]]],


        [[[-1.1292e-05, -3.6052e-06, -4.3909e-06],
          [ 2.8879e-06,  2.1346e-06, -4.9333e-06],
          [ 1.7075e-05,  9.4509e-06, -6.0738e-06]],

         [[-6.1124e-06,  2.2008e-06,  1.9130e-06],
          [ 4.3690e-06,  5.9512e-06,  1.9929e-07],
          [ 1.2748e-05,  9.3991e-06, -3.4000e-06]],

         [[-3.2532e-06,  4.0629e-06,  2.8092e-06],
          [ 6.8103e-06,  7.0828e-06,  9.2371e-07],
          [ 1.6240e-05,  1.3135e-05,  3.6304e-07]]],


        ...,


        [[[-1.1187e-02, -1.3211e-02, -1.6837e-02],
          [-2.8211e-03, -6.9210e-03, -1.1825e-02],
          [ 1.1269e-03, -3.7307e-03, -8.4911e-03]],

         [[-5.3321e-03, -6.0112e-03, -9.7784e-03],
          [ 3.6508e-03,  6.8768e-04, -4.5581e-03],
          [ 7.7734e-03,  3.4637e-03, -1.9743e-03]],

         [[-7.7717e-03, -8.0122e-03, -1.1238e-02],
          [-1.0520e-04, -2.6576e-03, -7.3240e-03],
          [ 3.7554e-03, -1.2334e-04, -5.2144e-03]]],


        [[[ 6.8429e-04,  1.1067e-03,  2.7823e-03],
          [-1.3613e-04,  6.9441e-04,  8.1715e-04],
          [-9.5723e-04, -1.1297e-03, -9.9770e-06]],

         [[-6.4107e-04, -2.4276e-04,  1.5166e-03],
          [ 2.3695e-04,  1.0440e-03,  9.0251e-04],
          [ 2.8536e-04,  5.4042e-05,  9.9536e-05]],

         [[-9.1938e-04, -4.3651e-05,  1.6231e-03],
          [ 9.8520e-04,  2.7312e-03,  3.3334e-03],
          [ 1.7513e-03,  2.3802e-03,  3.1574e-03]]],


        [[[ 2.1436e-03,  1.8567e-03,  8.4458e-03],
          [-6.3422e-04,  4.8030e-04,  8.7109e-03],
          [-6.7835e-03, -5.2427e-03,  1.0469e-03]],

         [[ 1.1721e-02,  1.1581e-02,  1.9108e-02],
          [ 9.2125e-03,  1.0285e-02,  1.8924e-02],
          [ 2.1036e-03,  3.8726e-03,  1.0095e-02]],

         [[ 1.3980e-02,  1.4347e-02,  2.0958e-02],
          [ 1.2372e-02,  1.3443e-02,  2.1092e-02],
          [ 5.4492e-03,  6.8643e-03,  1.3034e-02]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2624]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 65 | Batch_idx: 0 |  Loss: (0.2923) | Acc: (89.00%) (115/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.2425) | Acc: (91.00%) (1286/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.2419) | Acc: (91.00%) (2457/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.2385) | Acc: (91.00%) (3636/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.2384) | Acc: (91.00%) (4809/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.2375) | Acc: (91.00%) (5986/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.2365) | Acc: (91.00%) (7169/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.2375) | Acc: (91.00%) (8341/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.2352) | Acc: (91.00%) (9522/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.2315) | Acc: (91.00%) (10704/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.2291) | Acc: (92.00%) (11903/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.2291) | Acc: (92.00%) (13089/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.2293) | Acc: (92.00%) (14273/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.2301) | Acc: (92.00%) (15452/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.2304) | Acc: (92.00%) (16633/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.2299) | Acc: (92.00%) (17821/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.2274) | Acc: (92.00%) (19016/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.2261) | Acc: (92.00%) (20209/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.2255) | Acc: (92.00%) (21389/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.2253) | Acc: (92.00%) (22574/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.2246) | Acc: (92.00%) (23765/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.2255) | Acc: (92.00%) (24935/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.2257) | Acc: (92.00%) (26115/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.2255) | Acc: (92.00%) (27297/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.2258) | Acc: (92.00%) (28476/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.2258) | Acc: (92.00%) (29652/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.2246) | Acc: (92.00%) (30846/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.2247) | Acc: (92.00%) (32021/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.2239) | Acc: (92.00%) (33213/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.2235) | Acc: (92.00%) (34403/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.2228) | Acc: (92.00%) (35593/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.2224) | Acc: (92.00%) (36773/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.2215) | Acc: (92.00%) (37970/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.2199) | Acc: (92.00%) (39179/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.2189) | Acc: (92.00%) (40382/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.2180) | Acc: (92.00%) (41575/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.2188) | Acc: (92.00%) (42748/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.2192) | Acc: (92.00%) (43924/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.2200) | Acc: (92.00%) (45101/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.2195) | Acc: (92.00%) (46246/50000)
# TEST : Loss: (0.3194) | Acc: (89.00%) (8971/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1210, -0.1305, -0.0938],
          [-0.0498, -0.0897,  0.0035],
          [-0.0297, -0.1408, -0.1886]],

         [[-0.0455, -0.0874, -0.0502],
          [-0.1673, -0.0308,  0.0125],
          [ 0.0021,  0.0721, -0.0192]],

         [[-0.0674,  0.0801, -0.1878],
          [ 0.2016,  0.3524,  0.1691],
          [ 0.0042,  0.2614,  0.1945]]],


        [[[ 0.2994, -0.0942,  0.1890],
          [ 0.1447, -0.0042, -0.1321],
          [-0.2241, -0.2232, -0.2298]],

         [[ 0.0247, -0.2321,  0.0309],
          [-0.0875,  0.3669, -0.1825],
          [ 0.1738,  0.0739,  0.1894]],

         [[-0.1960, -0.2040, -0.0516],
          [-0.2135,  0.1427, -0.0348],
          [-0.0155,  0.1155,  0.2010]]],


        [[[ 0.0142,  0.0109, -0.0047],
          [ 0.0047,  0.0093,  0.0013],
          [-0.0087,  0.0012,  0.0062]],

         [[ 0.0157,  0.0253,  0.0120],
          [-0.0040,  0.0050,  0.0062],
          [-0.0145,  0.0021,  0.0076]],

         [[ 0.0148,  0.0259,  0.0278],
          [ 0.0059,  0.0155,  0.0252],
          [-0.0050,  0.0154,  0.0212]]],


        ...,


        [[[ 0.0287, -0.0034, -0.0674],
          [ 0.0385,  0.0358, -0.0278],
          [-0.1910, -0.0121,  0.0185]],

         [[-0.1222, -0.2052,  0.0169],
          [ 0.1192, -0.0074, -0.1291],
          [ 0.1182, -0.0740,  0.0095]],

         [[ 0.0396,  0.0815,  0.1216],
          [ 0.3243,  0.3474,  0.1596],
          [ 0.2980,  0.2330,  0.1076]]],


        [[[ 0.2530,  0.0914,  0.0827],
          [ 0.1124, -0.0510, -0.0664],
          [-0.0120,  0.1217, -0.0146]],

         [[-0.1422, -0.3162, -0.0556],
          [-0.0432, -0.3322, -0.2648],
          [ 0.0451, -0.0163, -0.0597]],

         [[ 0.0837, -0.1473, -0.0337],
          [ 0.0280, -0.0602, -0.0038],
          [-0.0141,  0.0639,  0.1285]]],


        [[[-0.0526, -0.2346, -0.1003],
          [-0.2203, -0.4741, -0.2731],
          [ 0.1203, -0.0868, -0.0894]],

         [[ 0.1352, -0.1977,  0.0199],
          [ 0.0376, -0.1609,  0.0817],
          [ 0.1932,  0.2250,  0.0046]],

         [[ 0.0506, -0.1892,  0.1008],
          [ 0.1148, -0.0215,  0.0650],
          [-0.1087, -0.0166,  0.0641]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3153]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0420]], device='cuda:0')

Epoch: 66 | Batch_idx: 0 |  Loss: (0.2818) | Acc: (89.00%) (114/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.2143) | Acc: (92.00%) (1306/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.2109) | Acc: (93.00%) (2515/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.2060) | Acc: (93.00%) (3709/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.2052) | Acc: (93.00%) (4894/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.2046) | Acc: (93.00%) (6090/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.2045) | Acc: (93.00%) (7281/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.2081) | Acc: (93.00%) (8460/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.2058) | Acc: (93.00%) (9665/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.2072) | Acc: (93.00%) (10853/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.2069) | Acc: (93.00%) (12043/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.2098) | Acc: (92.00%) (13209/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.2110) | Acc: (92.00%) (14384/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.2118) | Acc: (92.00%) (15568/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.2107) | Acc: (92.00%) (16762/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.2114) | Acc: (92.00%) (17944/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.2103) | Acc: (92.00%) (19148/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.2102) | Acc: (92.00%) (20335/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.2082) | Acc: (92.00%) (21532/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.2076) | Acc: (92.00%) (22731/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.2063) | Acc: (93.00%) (23937/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.2057) | Acc: (93.00%) (25130/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.2054) | Acc: (93.00%) (26321/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.2059) | Acc: (93.00%) (27511/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.2061) | Acc: (93.00%) (28703/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.2063) | Acc: (93.00%) (29897/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.2066) | Acc: (93.00%) (31091/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.2083) | Acc: (93.00%) (32261/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.2082) | Acc: (92.00%) (33447/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.2084) | Acc: (92.00%) (34635/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.2091) | Acc: (92.00%) (35812/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.2092) | Acc: (92.00%) (37005/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.2089) | Acc: (92.00%) (38201/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.2081) | Acc: (92.00%) (39395/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.2081) | Acc: (92.00%) (40586/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.2076) | Acc: (93.00%) (41785/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.2067) | Acc: (93.00%) (42992/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.2062) | Acc: (93.00%) (44198/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.2055) | Acc: (93.00%) (45395/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.2049) | Acc: (93.00%) (46550/50000)
# TEST : Loss: (0.3043) | Acc: (90.00%) (9002/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1195, -0.1290, -0.0927],
          [-0.0492, -0.0887,  0.0034],
          [-0.0294, -0.1393, -0.1866]],

         [[-0.0450, -0.0864, -0.0496],
          [-0.1654, -0.0304,  0.0124],
          [ 0.0021,  0.0713, -0.0190]],

         [[-0.0666,  0.0792, -0.1857],
          [ 0.1993,  0.3485,  0.1672],
          [ 0.0042,  0.2585,  0.1924]]],


        [[[ 0.2990, -0.0941,  0.1888],
          [ 0.1445, -0.0041, -0.1319],
          [-0.2239, -0.2230, -0.2296]],

         [[ 0.0247, -0.2318,  0.0309],
          [-0.0874,  0.3665, -0.1823],
          [ 0.1736,  0.0738,  0.1892]],

         [[-0.1957, -0.2037, -0.0516],
          [-0.2133,  0.1426, -0.0347],
          [-0.0154,  0.1153,  0.2007]]],


        [[[ 0.0103,  0.0083, -0.0036],
          [ 0.0034,  0.0069,  0.0010],
          [-0.0068,  0.0009,  0.0048]],

         [[ 0.0106,  0.0179,  0.0088],
          [-0.0027,  0.0034,  0.0044],
          [-0.0110,  0.0015,  0.0056]],

         [[ 0.0097,  0.0162,  0.0182],
          [ 0.0039,  0.0094,  0.0161],
          [-0.0037,  0.0108,  0.0150]]],


        ...,


        [[[ 0.0285, -0.0033, -0.0670],
          [ 0.0382,  0.0356, -0.0276],
          [-0.1899, -0.0120,  0.0184]],

         [[-0.1213, -0.2037,  0.0167],
          [ 0.1182, -0.0073, -0.1280],
          [ 0.1172, -0.0734,  0.0095]],

         [[ 0.0391,  0.0807,  0.1204],
          [ 0.3187,  0.3412,  0.1574],
          [ 0.2929,  0.2291,  0.1062]]],


        [[[ 0.2516,  0.0908,  0.0822],
          [ 0.1118, -0.0507, -0.0660],
          [-0.0120,  0.1210, -0.0145]],

         [[-0.1411, -0.3125, -0.0550],
          [-0.0429, -0.3280, -0.2614],
          [ 0.0448, -0.0162, -0.0593]],

         [[ 0.0830, -0.1455, -0.0333],
          [ 0.0278, -0.0594, -0.0038],
          [-0.0140,  0.0634,  0.1275]]],


        [[[-0.0523, -0.2318, -0.0995],
          [-0.2188, -0.4686, -0.2706],
          [ 0.1197, -0.0863, -0.0889]],

         [[ 0.1345, -0.1965,  0.0198],
          [ 0.0374, -0.1599,  0.0812],
          [ 0.1924,  0.2239,  0.0046]],

         [[ 0.0504, -0.1882,  0.1003],
          [ 0.1143, -0.0214,  0.0647],
          [-0.1082, -0.0166,  0.0638]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3099]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0008]], device='cuda:0')

Epoch: 67 | Batch_idx: 0 |  Loss: (0.1177) | Acc: (95.00%) (122/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.2470) | Acc: (91.00%) (1289/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.2254) | Acc: (92.00%) (2483/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.2236) | Acc: (92.00%) (3668/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.2218) | Acc: (92.00%) (4865/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.2200) | Acc: (92.00%) (6043/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.2155) | Acc: (92.00%) (7230/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.2082) | Acc: (92.00%) (8444/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.2066) | Acc: (92.00%) (9640/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.2046) | Acc: (93.00%) (10834/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.2042) | Acc: (93.00%) (12028/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.2042) | Acc: (93.00%) (13223/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.2030) | Acc: (93.00%) (14426/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.2031) | Acc: (93.00%) (15619/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.2038) | Acc: (93.00%) (16805/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.2030) | Acc: (93.00%) (18009/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.2036) | Acc: (93.00%) (19200/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.2032) | Acc: (93.00%) (20396/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.2047) | Acc: (93.00%) (21574/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.2033) | Acc: (93.00%) (22779/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.2026) | Acc: (93.00%) (23977/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.2039) | Acc: (93.00%) (25143/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.2037) | Acc: (93.00%) (26330/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.2038) | Acc: (93.00%) (27514/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.2037) | Acc: (93.00%) (28702/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.2044) | Acc: (93.00%) (29884/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.2043) | Acc: (93.00%) (31081/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.2043) | Acc: (93.00%) (32271/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.2040) | Acc: (93.00%) (33468/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.2038) | Acc: (93.00%) (34658/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.2032) | Acc: (93.00%) (35855/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.2034) | Acc: (93.00%) (37041/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.2040) | Acc: (93.00%) (38226/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.2048) | Acc: (93.00%) (39405/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.2045) | Acc: (93.00%) (40604/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.2051) | Acc: (93.00%) (41789/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.2047) | Acc: (93.00%) (42981/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.2054) | Acc: (92.00%) (44158/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.2050) | Acc: (93.00%) (45356/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.2052) | Acc: (92.00%) (46499/50000)
# TEST : Loss: (0.3035) | Acc: (90.00%) (9012/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1177, -0.1271, -0.0913],
          [-0.0486, -0.0875,  0.0034],
          [-0.0290, -0.1376, -0.1842]],

         [[-0.0444, -0.0852, -0.0489],
          [-0.1632, -0.0300,  0.0122],
          [ 0.0020,  0.0704, -0.0188]],

         [[-0.0657,  0.0781, -0.1832],
          [ 0.1966,  0.3437,  0.1649],
          [ 0.0041,  0.2551,  0.1898]]],


        [[[ 0.2986, -0.0940,  0.1885],
          [ 0.1443, -0.0041, -0.1318],
          [-0.2236, -0.2227, -0.2292]],

         [[ 0.0246, -0.2315,  0.0308],
          [-0.0873,  0.3659, -0.1820],
          [ 0.1734,  0.0737,  0.1889]],

         [[-0.1954, -0.2034, -0.0515],
          [-0.2129,  0.1423, -0.0347],
          [-0.0154,  0.1152,  0.2004]]],


        [[[ 0.0070,  0.0059, -0.0026],
          [ 0.0023,  0.0048,  0.0007],
          [-0.0050,  0.0006,  0.0035]],

         [[ 0.0065,  0.0118,  0.0060],
          [-0.0017,  0.0021,  0.0029],
          [-0.0078,  0.0010,  0.0039]],

         [[ 0.0058,  0.0092,  0.0109],
          [ 0.0024,  0.0051,  0.0094],
          [-0.0026,  0.0070,  0.0099]]],


        ...,


        [[[ 0.0283, -0.0033, -0.0665],
          [ 0.0380,  0.0354, -0.0274],
          [-0.1885, -0.0120,  0.0182]],

         [[-0.1202, -0.2018,  0.0166],
          [ 0.1171, -0.0072, -0.1268],
          [ 0.1161, -0.0727,  0.0094]],

         [[ 0.0386,  0.0796,  0.1190],
          [ 0.3121,  0.3337,  0.1549],
          [ 0.2868,  0.2244,  0.1045]]],


        [[[ 0.2499,  0.0901,  0.0815],
          [ 0.1110, -0.0503, -0.0655],
          [-0.0119,  0.1201, -0.0144]],

         [[-0.1398, -0.3079, -0.0543],
          [-0.0424, -0.3229, -0.2574],
          [ 0.0444, -0.0161, -0.0587]],

         [[ 0.0822, -0.1432, -0.0329],
          [ 0.0275, -0.0584, -0.0037],
          [-0.0139,  0.0628,  0.1262]]],


        [[[-0.0518, -0.2285, -0.0984],
          [-0.2171, -0.4619, -0.2676],
          [ 0.1190, -0.0857, -0.0883]],

         [[ 0.1337, -0.1949,  0.0196],
          [ 0.0371, -0.1587,  0.0806],
          [ 0.1914,  0.2226,  0.0045]],

         [[ 0.0501, -0.1870,  0.0997],
          [ 0.1136, -0.0213,  0.0643],
          [-0.1077, -0.0165,  0.0635]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2887]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0489]], device='cuda:0')

Epoch: 68 | Batch_idx: 0 |  Loss: (0.1718) | Acc: (94.00%) (121/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.2008) | Acc: (93.00%) (1317/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.2090) | Acc: (93.00%) (2504/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.2081) | Acc: (93.00%) (3700/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.2120) | Acc: (93.00%) (4884/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.2116) | Acc: (93.00%) (6080/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.2136) | Acc: (93.00%) (7271/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.2136) | Acc: (93.00%) (8457/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.2109) | Acc: (93.00%) (9659/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.2090) | Acc: (93.00%) (10854/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.2090) | Acc: (93.00%) (12040/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.2095) | Acc: (93.00%) (13224/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.2110) | Acc: (93.00%) (14405/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.2120) | Acc: (92.00%) (15579/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.2104) | Acc: (92.00%) (16780/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.2102) | Acc: (92.00%) (17973/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.2097) | Acc: (93.00%) (19170/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.2095) | Acc: (93.00%) (20360/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.2098) | Acc: (93.00%) (21555/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.2105) | Acc: (93.00%) (22740/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.2096) | Acc: (93.00%) (23933/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.2098) | Acc: (93.00%) (25124/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.2099) | Acc: (93.00%) (26326/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.2099) | Acc: (93.00%) (27515/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.2090) | Acc: (93.00%) (28719/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.2088) | Acc: (93.00%) (29924/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.2086) | Acc: (93.00%) (31116/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.2087) | Acc: (93.00%) (32304/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.2084) | Acc: (93.00%) (33502/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.2089) | Acc: (93.00%) (34688/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.2088) | Acc: (93.00%) (35884/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.2094) | Acc: (93.00%) (37071/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.2097) | Acc: (93.00%) (38253/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.2090) | Acc: (93.00%) (39448/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.2090) | Acc: (93.00%) (40640/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.2093) | Acc: (93.00%) (41824/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.2097) | Acc: (93.00%) (43016/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.2097) | Acc: (93.00%) (44204/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.2092) | Acc: (93.00%) (45404/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.2088) | Acc: (93.00%) (46556/50000)
# TEST : Loss: (0.2986) | Acc: (90.00%) (9016/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1156, -0.1248, -0.0897],
          [-0.0478, -0.0861,  0.0033],
          [-0.0286, -0.1354, -0.1814]],

         [[-0.0436, -0.0838, -0.0481],
          [-0.1606, -0.0296,  0.0120],
          [ 0.0020,  0.0693, -0.0185]],

         [[-0.0646,  0.0768, -0.1801],
          [ 0.1934,  0.3381,  0.1622],
          [ 0.0040,  0.2510,  0.1867]]],


        [[[ 0.2981, -0.0938,  0.1882],
          [ 0.1441, -0.0041, -0.1315],
          [-0.2232, -0.2223, -0.2288]],

         [[ 0.0246, -0.2311,  0.0308],
          [-0.0871,  0.3652, -0.1817],
          [ 0.1731,  0.0736,  0.1886]],

         [[-0.1951, -0.2030, -0.0514],
          [-0.2125,  0.1421, -0.0346],
          [-0.0154,  0.1149,  0.2001]]],


        [[[ 0.0044,  0.0039, -0.0018],
          [ 0.0014,  0.0031,  0.0005],
          [-0.0034,  0.0004,  0.0024]],

         [[ 0.0036,  0.0071,  0.0038],
          [-0.0009,  0.0012,  0.0018],
          [-0.0051,  0.0006,  0.0025]],

         [[ 0.0031,  0.0046,  0.0058],
          [ 0.0013,  0.0024,  0.0048],
          [-0.0017,  0.0041,  0.0059]]],


        ...,


        [[[ 0.0281, -0.0033, -0.0660],
          [ 0.0376,  0.0350, -0.0272],
          [-0.1868, -0.0118,  0.0181]],

         [[-0.1189, -0.1996,  0.0164],
          [ 0.1157, -0.0071, -0.1253],
          [ 0.1147, -0.0718,  0.0093]],

         [[ 0.0380,  0.0783,  0.1173],
          [ 0.3042,  0.3249,  0.1518],
          [ 0.2795,  0.2188,  0.1026]]],


        [[[ 0.2478,  0.0893,  0.0808],
          [ 0.1101, -0.0498, -0.0648],
          [-0.0118,  0.1192, -0.0143]],

         [[-0.1382, -0.3025, -0.0534],
          [-0.0419, -0.3169, -0.2525],
          [ 0.0440, -0.0159, -0.0581]],

         [[ 0.0812, -0.1406, -0.0323],
          [ 0.0271, -0.0573, -0.0036],
          [-0.0138,  0.0620,  0.1248]]],


        [[[-0.0513, -0.2245, -0.0972],
          [-0.2149, -0.4539, -0.2639],
          [ 0.1182, -0.0849, -0.0875]],

         [[ 0.1326, -0.1931,  0.0195],
          [ 0.0369, -0.1573,  0.0799],
          [ 0.1902,  0.2210,  0.0045]],

         [[ 0.0497, -0.1855,  0.0989],
          [ 0.1129, -0.0211,  0.0638],
          [-0.1070, -0.0163,  0.0630]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3068]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0238]], device='cuda:0')

Epoch: 69 | Batch_idx: 0 |  Loss: (0.2576) | Acc: (91.00%) (117/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.2292) | Acc: (91.00%) (1295/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.2172) | Acc: (92.00%) (2489/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.2231) | Acc: (92.00%) (3674/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.2240) | Acc: (92.00%) (4856/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.2165) | Acc: (92.00%) (6061/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.2113) | Acc: (93.00%) (7270/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.2126) | Acc: (93.00%) (8453/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.2137) | Acc: (92.00%) (9642/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.2113) | Acc: (93.00%) (10838/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.2121) | Acc: (93.00%) (12026/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.2122) | Acc: (93.00%) (13225/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.2121) | Acc: (93.00%) (14423/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.2127) | Acc: (93.00%) (15610/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.2139) | Acc: (92.00%) (16784/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.2124) | Acc: (93.00%) (17996/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.2145) | Acc: (93.00%) (19169/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.2131) | Acc: (93.00%) (20382/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.2138) | Acc: (93.00%) (21574/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.2148) | Acc: (93.00%) (22764/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.2170) | Acc: (93.00%) (23941/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.2161) | Acc: (93.00%) (25143/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.2159) | Acc: (93.00%) (26340/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.2158) | Acc: (93.00%) (27535/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.2156) | Acc: (93.00%) (28723/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.2165) | Acc: (93.00%) (29898/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.2175) | Acc: (93.00%) (31087/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.2183) | Acc: (93.00%) (32272/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.2178) | Acc: (93.00%) (33473/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.2173) | Acc: (93.00%) (34677/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.2179) | Acc: (93.00%) (35865/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.2183) | Acc: (93.00%) (37053/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.2184) | Acc: (93.00%) (38232/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.2186) | Acc: (93.00%) (39420/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.2179) | Acc: (93.00%) (40619/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.2182) | Acc: (93.00%) (41813/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.2182) | Acc: (93.00%) (43006/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.2179) | Acc: (93.00%) (44209/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.2174) | Acc: (93.00%) (45416/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.2173) | Acc: (93.00%) (46563/50000)
# TEST : Loss: (0.3017) | Acc: (90.00%) (9000/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1131, -0.1221, -0.0877],
          [-0.0468, -0.0844,  0.0033],
          [-0.0280, -0.1329, -0.1779]],

         [[-0.0427, -0.0821, -0.0471],
          [-0.1574, -0.0290,  0.0118],
          [ 0.0020,  0.0680, -0.0181]],

         [[-0.0633,  0.0753, -0.1765],
          [ 0.1895,  0.3314,  0.1590],
          [ 0.0039,  0.2461,  0.1830]]],


        [[[ 0.2975, -0.0936,  0.1878],
          [ 0.1437, -0.0041, -0.1313],
          [-0.2227, -0.2218, -0.2284]],

         [[ 0.0245, -0.2306,  0.0307],
          [-0.0869,  0.3644, -0.1813],
          [ 0.1727,  0.0734,  0.1882]],

         [[-0.1946, -0.2026, -0.0513],
          [-0.2120,  0.1417, -0.0345],
          [-0.0154,  0.1147,  0.1996]]],


        [[[ 0.0025,  0.0024, -0.0011],
          [ 0.0008,  0.0018,  0.0003],
          [-0.0021,  0.0003,  0.0015]],

         [[ 0.0018,  0.0038,  0.0021],
          [-0.0005,  0.0006,  0.0009],
          [-0.0031,  0.0004,  0.0014]],

         [[ 0.0014,  0.0020,  0.0027],
          [ 0.0006,  0.0010,  0.0022],
          [-0.0010,  0.0022,  0.0032]]],


        ...,


        [[[ 0.0278, -0.0033, -0.0653],
          [ 0.0372,  0.0346, -0.0269],
          [-0.1848, -0.0117,  0.0179]],

         [[-0.1173, -0.1970,  0.0162],
          [ 0.1140, -0.0070, -0.1236],
          [ 0.1130, -0.0708,  0.0091]],

         [[ 0.0373,  0.0768,  0.1153],
          [ 0.2949,  0.3145,  0.1482],
          [ 0.2709,  0.2122,  0.1002]]],


        [[[ 0.2453,  0.0883,  0.0798],
          [ 0.1090, -0.0493, -0.0641],
          [-0.0117,  0.1180, -0.0141]],

         [[-0.1364, -0.2961, -0.0523],
          [-0.0413, -0.3097, -0.2468],
          [ 0.0435, -0.0157, -0.0573]],

         [[ 0.0800, -0.1374, -0.0316],
          [ 0.0267, -0.0560, -0.0036],
          [-0.0136,  0.0611,  0.1230]]],


        [[[-0.0507, -0.2198, -0.0957],
          [-0.2123, -0.4443, -0.2596],
          [ 0.1172, -0.0840, -0.0866]],

         [[ 0.1314, -0.1909,  0.0193],
          [ 0.0365, -0.1555,  0.0791],
          [ 0.1887,  0.2192,  0.0045]],

         [[ 0.0493, -0.1838,  0.0981],
          [ 0.1119, -0.0209,  0.0632],
          [-0.1062, -0.0162,  0.0625]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2980]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0113]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 70 | Batch_idx: 0 |  Loss: (0.2986) | Acc: (90.00%) (116/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.2890) | Acc: (90.00%) (1268/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.3352) | Acc: (88.00%) (2383/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.3711) | Acc: (87.00%) (3481/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.4089) | Acc: (86.00%) (4518/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.4283) | Acc: (85.00%) (5573/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.4304) | Acc: (85.00%) (6670/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.4278) | Acc: (85.00%) (7772/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.4344) | Acc: (85.00%) (8842/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.4384) | Acc: (85.00%) (9927/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.4428) | Acc: (85.00%) (10997/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.4375) | Acc: (85.00%) (12114/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.4364) | Acc: (85.00%) (13205/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.4333) | Acc: (85.00%) (14311/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.4313) | Acc: (85.00%) (15415/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.4291) | Acc: (85.00%) (16516/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.4235) | Acc: (85.00%) (17641/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.4198) | Acc: (85.00%) (18762/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.4158) | Acc: (85.00%) (19888/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.4136) | Acc: (85.00%) (21011/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.4117) | Acc: (86.00%) (22137/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.4116) | Acc: (86.00%) (23231/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.4113) | Acc: (86.00%) (24339/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.4099) | Acc: (86.00%) (25455/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.4062) | Acc: (86.00%) (26605/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.4044) | Acc: (86.00%) (27729/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.4009) | Acc: (86.00%) (28871/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3985) | Acc: (86.00%) (30002/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3959) | Acc: (86.00%) (31147/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3939) | Acc: (86.00%) (32273/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3926) | Acc: (86.00%) (33409/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3918) | Acc: (86.00%) (34533/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3898) | Acc: (86.00%) (35672/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3879) | Acc: (86.00%) (36807/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3860) | Acc: (86.00%) (37937/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3844) | Acc: (86.00%) (39073/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3832) | Acc: (87.00%) (40201/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3823) | Acc: (87.00%) (41319/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3805) | Acc: (87.00%) (42457/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3791) | Acc: (87.00%) (43557/50000)
# TEST : Loss: (0.4154) | Acc: (86.00%) (8687/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1100, -0.1118, -0.0837],
          [-0.0472, -0.0777,  0.0062],
          [-0.0306, -0.1348, -0.1813]],

         [[-0.0463, -0.0811, -0.0555],
          [-0.1605, -0.0279,  0.0064],
          [ 0.0008,  0.0644, -0.0284]],

         [[-0.0660,  0.0814, -0.1764],
          [ 0.1911,  0.3446,  0.1678],
          [ 0.0143,  0.2596,  0.1892]]],


        [[[ 0.3262, -0.0795,  0.1940],
          [ 0.1621,  0.0048, -0.1272],
          [-0.2057, -0.2368, -0.2320]],

         [[ 0.0351, -0.2363,  0.0233],
          [-0.0744,  0.3751, -0.1736],
          [ 0.1956,  0.0728,  0.1961]],

         [[-0.1760, -0.1949, -0.0446],
          [-0.1955,  0.1631, -0.0139],
          [ 0.0137,  0.1211,  0.2195]]],


        [[[-0.0039, -0.0092, -0.0224],
          [-0.0184, -0.0245, -0.0323],
          [-0.0383, -0.0439, -0.0431]],

         [[ 0.0096,  0.0106, -0.0047],
          [ 0.0013, -0.0029, -0.0179],
          [-0.0188, -0.0240, -0.0298]],

         [[ 0.0261,  0.0320,  0.0129],
          [ 0.0079,  0.0064, -0.0085],
          [-0.0125, -0.0167, -0.0210]]],


        ...,


        [[[ 0.0117, -0.0138, -0.0824],
          [ 0.0230,  0.0240, -0.0425],
          [-0.1976, -0.0237,  0.0067]],

         [[-0.1277, -0.2023,  0.0035],
          [ 0.1060, -0.0145, -0.1361],
          [ 0.1117, -0.0753,  0.0030]],

         [[ 0.0242,  0.0789,  0.1125],
          [ 0.2891,  0.3232,  0.1524],
          [ 0.2815,  0.2212,  0.1063]]],


        [[[ 0.2530,  0.0787,  0.0729],
          [ 0.0978, -0.0717, -0.0759],
          [-0.0250,  0.0971, -0.0189]],

         [[-0.1157, -0.2984, -0.0663],
          [-0.0487, -0.3423, -0.2785],
          [ 0.0315, -0.0403, -0.0709]],

         [[ 0.1019, -0.1283, -0.0301],
          [ 0.0179, -0.0790, -0.0119],
          [-0.0256,  0.0432,  0.1281]]],


        [[[-0.0068, -0.2369, -0.0962],
          [-0.1797, -0.4644, -0.2639],
          [ 0.1273, -0.0977, -0.0956]],

         [[ 0.1523, -0.2107,  0.0046],
          [ 0.0526, -0.1755,  0.0653],
          [ 0.1893,  0.1992, -0.0091]],

         [[ 0.0719, -0.1871,  0.0992],
          [ 0.1334, -0.0217,  0.0679],
          [-0.0932, -0.0158,  0.0658]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0057,  0.0022,  0.0012],
          [ 0.0072,  0.0029,  0.0011],
          [ 0.0062,  0.0026, -0.0011]],

         [[ 0.0055,  0.0029,  0.0021],
          [ 0.0059,  0.0025,  0.0014],
          [ 0.0051,  0.0021, -0.0008]],

         [[ 0.0058,  0.0042,  0.0037],
          [ 0.0058,  0.0036,  0.0030],
          [ 0.0054,  0.0033,  0.0010]]],


        [[[ 0.0281,  0.0010,  0.0031],
          [ 0.0396,  0.0192,  0.0384],
          [ 0.0760,  0.0296,  0.0480]],

         [[ 0.0149, -0.0054, -0.0062],
          [ 0.0085, -0.0050,  0.0170],
          [ 0.0597,  0.0095,  0.0277]],

         [[-0.0087, -0.0237, -0.0156],
          [-0.0090, -0.0175,  0.0171],
          [ 0.0347, -0.0069,  0.0151]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0125, -0.0205, -0.0279],
          [-0.0085, -0.0165, -0.0254],
          [-0.0081, -0.0136, -0.0232]],

         [[-0.0082, -0.0163, -0.0231],
          [-0.0057, -0.0141, -0.0229],
          [-0.0059, -0.0114, -0.0214]],

         [[-0.0005, -0.0093, -0.0181],
          [ 0.0007, -0.0086, -0.0190],
          [-0.0007, -0.0065, -0.0176]]],


        [[[ 0.0053,  0.0074, -0.0012],
          [ 0.0047,  0.0084,  0.0022],
          [ 0.0070,  0.0146,  0.0088]],

         [[-0.0051,  0.0010, -0.0031],
          [-0.0031,  0.0051,  0.0027],
          [ 0.0018,  0.0122,  0.0085]],

         [[-0.0050, -0.0014, -0.0063],
          [-0.0045,  0.0023, -0.0005],
          [-0.0026,  0.0064,  0.0023]]],


        [[[-0.0070, -0.0086, -0.0120],
          [-0.0037, -0.0044, -0.0060],
          [-0.0043, -0.0049, -0.0081]],

         [[-0.0199, -0.0169, -0.0184],
          [-0.0162, -0.0135, -0.0143],
          [-0.0173, -0.0147, -0.0183]],

         [[-0.0280, -0.0259, -0.0262],
          [-0.0270, -0.0247, -0.0243],
          [-0.0275, -0.0264, -0.0293]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2947]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 71 | Batch_idx: 0 |  Loss: (0.2652) | Acc: (88.00%) (113/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.2862) | Acc: (90.00%) (1273/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.2996) | Acc: (90.00%) (2425/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.3040) | Acc: (89.00%) (3570/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.2993) | Acc: (89.00%) (4720/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.3008) | Acc: (89.00%) (5866/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.2983) | Acc: (89.00%) (7026/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.2982) | Acc: (90.00%) (8181/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.2979) | Acc: (90.00%) (9335/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.2976) | Acc: (90.00%) (10490/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.2977) | Acc: (89.00%) (11634/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.2981) | Acc: (89.00%) (12782/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.2969) | Acc: (90.00%) (13945/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.2961) | Acc: (90.00%) (15108/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.2957) | Acc: (90.00%) (16267/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.2956) | Acc: (90.00%) (17415/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.2946) | Acc: (90.00%) (18572/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.2946) | Acc: (90.00%) (19732/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.2948) | Acc: (90.00%) (20876/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.2941) | Acc: (90.00%) (22031/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.2959) | Acc: (90.00%) (23179/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.2967) | Acc: (90.00%) (24317/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.2982) | Acc: (89.00%) (25447/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.2978) | Acc: (89.00%) (26601/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.2980) | Acc: (89.00%) (27752/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.2969) | Acc: (89.00%) (28899/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.2961) | Acc: (89.00%) (30063/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.2954) | Acc: (89.00%) (31215/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.2954) | Acc: (90.00%) (32374/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.2947) | Acc: (90.00%) (33536/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.2964) | Acc: (89.00%) (34657/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.2966) | Acc: (89.00%) (35799/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.2966) | Acc: (89.00%) (36947/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.2958) | Acc: (89.00%) (38112/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.2959) | Acc: (89.00%) (39267/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.2958) | Acc: (89.00%) (40415/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.2950) | Acc: (89.00%) (41571/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.2952) | Acc: (89.00%) (42719/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.2949) | Acc: (89.00%) (43876/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.2942) | Acc: (89.00%) (44989/50000)
# TEST : Loss: (0.3668) | Acc: (87.00%) (8796/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1145, -0.1163, -0.0832],
          [-0.0526, -0.0778,  0.0109],
          [-0.0349, -0.1362, -0.1746]],

         [[-0.0460, -0.0813, -0.0546],
          [-0.1615, -0.0224,  0.0144],
          [-0.0033,  0.0657, -0.0193]],

         [[-0.0670,  0.0779, -0.1797],
          [ 0.1893,  0.3487,  0.1724],
          [ 0.0119,  0.2619,  0.1970]]],


        [[[ 0.3179, -0.0829,  0.1908],
          [ 0.1535, -0.0092, -0.1465],
          [-0.2112, -0.2458, -0.2375]],

         [[ 0.0229, -0.2433,  0.0158],
          [-0.0825,  0.3670, -0.1872],
          [ 0.1949,  0.0756,  0.1999]],

         [[-0.1822, -0.2040, -0.0526],
          [-0.2010,  0.1513, -0.0312],
          [ 0.0154,  0.1260,  0.2198]]],


        [[[-0.0027, -0.0065, -0.0159],
          [-0.0127, -0.0172, -0.0233],
          [-0.0272, -0.0305, -0.0306]],

         [[ 0.0066,  0.0073, -0.0032],
          [ 0.0008, -0.0019, -0.0119],
          [-0.0131, -0.0161, -0.0201]],

         [[ 0.0178,  0.0212,  0.0083],
          [ 0.0054,  0.0042, -0.0057],
          [-0.0089, -0.0113, -0.0146]]],


        ...,


        [[[ 0.0326,  0.0031, -0.0678],
          [ 0.0405,  0.0401, -0.0261],
          [-0.1840, -0.0116,  0.0257]],

         [[-0.1037, -0.1840,  0.0162],
          [ 0.1251,  0.0005, -0.1221],
          [ 0.1217, -0.0698,  0.0163]],

         [[ 0.0425,  0.0938,  0.1197],
          [ 0.3178,  0.3501,  0.1680],
          [ 0.2896,  0.2235,  0.1184]]],


        [[[ 0.2388,  0.0561,  0.0590],
          [ 0.0846, -0.0861, -0.0798],
          [-0.0328,  0.0899, -0.0145]],

         [[-0.1260, -0.3232, -0.0718],
          [-0.0615, -0.3578, -0.2725],
          [ 0.0253, -0.0451, -0.0599]],

         [[ 0.0822, -0.1625, -0.0396],
          [-0.0027, -0.1031, -0.0143],
          [-0.0358,  0.0352,  0.1342]]],


        [[[ 0.0092, -0.2369, -0.0918],
          [-0.1622, -0.4600, -0.2554],
          [ 0.1438, -0.0811, -0.0789]],

         [[ 0.1619, -0.2160,  0.0050],
          [ 0.0663, -0.1760,  0.0675],
          [ 0.1991,  0.2053, -0.0002]],

         [[ 0.0722, -0.1985,  0.0952],
          [ 0.1352, -0.0324,  0.0634],
          [-0.0940, -0.0203,  0.0643]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0060, -0.0048, -0.0049],
          [-0.0046, -0.0043, -0.0043],
          [-0.0032, -0.0040, -0.0040]],

         [[-0.0057, -0.0036, -0.0035],
          [-0.0047, -0.0038, -0.0038],
          [-0.0041, -0.0039, -0.0037]],

         [[-0.0048, -0.0036, -0.0034],
          [-0.0051, -0.0048, -0.0046],
          [-0.0048, -0.0049, -0.0042]]],


        [[[-0.0324, -0.0323, -0.0395],
          [-0.0302, -0.0202, -0.0420],
          [-0.0158, -0.0132, -0.0406]],

         [[-0.0247, -0.0269, -0.0235],
          [-0.0159, -0.0126, -0.0240],
          [-0.0160, -0.0011, -0.0202]],

         [[-0.0126, -0.0131, -0.0134],
          [-0.0170, -0.0146, -0.0250],
          [-0.0344, -0.0213, -0.0319]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0273, -0.0297, -0.0296],
          [-0.0100, -0.0117, -0.0121],
          [-0.0028, -0.0030, -0.0056]],

         [[-0.0183, -0.0216, -0.0220],
          [-0.0010, -0.0035, -0.0044],
          [ 0.0059,  0.0056,  0.0018]],

         [[-0.0170, -0.0201, -0.0200],
          [-0.0027, -0.0056, -0.0061],
          [ 0.0037,  0.0024, -0.0009]]],


        [[[ 0.0104,  0.0083,  0.0053],
          [ 0.0098,  0.0103,  0.0088],
          [ 0.0111,  0.0128,  0.0127]],

         [[ 0.0085,  0.0027, -0.0033],
          [ 0.0074,  0.0030,  0.0001],
          [ 0.0056,  0.0045,  0.0043]],

         [[ 0.0062,  0.0021, -0.0041],
          [ 0.0057,  0.0029,  0.0002],
          [ 0.0036,  0.0034,  0.0037]]],


        [[[-0.0125, -0.0061, -0.0158],
          [-0.0084,  0.0041, -0.0029],
          [-0.0067,  0.0034, -0.0024]],

         [[-0.0034,  0.0029, -0.0057],
          [ 0.0016,  0.0111,  0.0048],
          [ 0.0024,  0.0094,  0.0032]],

         [[-0.0031,  0.0059, -0.0027],
          [ 0.0052,  0.0161,  0.0088],
          [ 0.0119,  0.0195,  0.0123]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2941]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 72 | Batch_idx: 0 |  Loss: (0.2865) | Acc: (89.00%) (115/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.2686) | Acc: (91.00%) (1291/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.2549) | Acc: (91.00%) (2461/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.2501) | Acc: (91.00%) (3633/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.2577) | Acc: (91.00%) (4790/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.2600) | Acc: (91.00%) (5952/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.2650) | Acc: (91.00%) (7109/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.2658) | Acc: (90.00%) (8262/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.2659) | Acc: (90.00%) (9433/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.2631) | Acc: (91.00%) (10608/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.2626) | Acc: (91.00%) (11775/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.2624) | Acc: (91.00%) (12942/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.2597) | Acc: (91.00%) (14122/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.2579) | Acc: (91.00%) (15300/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.2583) | Acc: (91.00%) (16469/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.2603) | Acc: (91.00%) (17622/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.2607) | Acc: (91.00%) (18769/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.2598) | Acc: (91.00%) (19949/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.2591) | Acc: (91.00%) (21130/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.2587) | Acc: (91.00%) (22299/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.2597) | Acc: (91.00%) (23449/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.2616) | Acc: (91.00%) (24597/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.2618) | Acc: (91.00%) (25751/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.2619) | Acc: (91.00%) (26918/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.2613) | Acc: (91.00%) (28095/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.2613) | Acc: (91.00%) (29262/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.2612) | Acc: (91.00%) (30432/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.2607) | Acc: (91.00%) (31599/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.2618) | Acc: (91.00%) (32743/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.2619) | Acc: (91.00%) (33910/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.2620) | Acc: (91.00%) (35077/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.2620) | Acc: (91.00%) (36234/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.2629) | Acc: (90.00%) (37387/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.2618) | Acc: (91.00%) (38574/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.2625) | Acc: (91.00%) (39734/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.2623) | Acc: (91.00%) (40900/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.2618) | Acc: (91.00%) (42071/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.2625) | Acc: (91.00%) (43219/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.2633) | Acc: (90.00%) (44374/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.2625) | Acc: (91.00%) (45504/50000)
# TEST : Loss: (0.3690) | Acc: (87.00%) (8779/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1174, -0.1260, -0.0939],
          [-0.0526, -0.0865,  0.0011],
          [-0.0329, -0.1445, -0.1863]],

         [[-0.0441, -0.0860, -0.0630],
          [-0.1542, -0.0248,  0.0086],
          [ 0.0022,  0.0596, -0.0307]],

         [[-0.0677,  0.0740, -0.1880],
          [ 0.1930,  0.3473,  0.1673],
          [ 0.0190,  0.2592,  0.1876]]],


        [[[ 0.3282, -0.0718,  0.1975],
          [ 0.1525, -0.0019, -0.1421],
          [-0.2138, -0.2443, -0.2335]],

         [[ 0.0334, -0.2335,  0.0189],
          [-0.0786,  0.3789, -0.1829],
          [ 0.2007,  0.0870,  0.2074]],

         [[-0.1737, -0.1963, -0.0546],
          [-0.2038,  0.1571, -0.0308],
          [ 0.0168,  0.1287,  0.2178]]],


        [[[-0.0018, -0.0044, -0.0105],
          [-0.0081, -0.0112, -0.0157],
          [-0.0179, -0.0196, -0.0201]],

         [[ 0.0042,  0.0046, -0.0019],
          [ 0.0005, -0.0011, -0.0072],
          [-0.0085, -0.0098, -0.0124]],

         [[ 0.0111,  0.0129,  0.0049],
          [ 0.0034,  0.0025, -0.0035],
          [-0.0058, -0.0070, -0.0093]]],


        ...,


        [[[ 0.0244,  0.0018, -0.0695],
          [ 0.0276,  0.0366, -0.0305],
          [-0.2007, -0.0212,  0.0158]],

         [[-0.1100, -0.1842,  0.0119],
          [ 0.1150,  0.0002, -0.1276],
          [ 0.1045, -0.0789,  0.0041]],

         [[ 0.0394,  0.1016,  0.1231],
          [ 0.3129,  0.3703,  0.1725],
          [ 0.2716,  0.2206,  0.1082]]],


        [[[ 0.2503,  0.0692,  0.0827],
          [ 0.1015, -0.0673, -0.0560],
          [-0.0091,  0.1156,  0.0096]],

         [[-0.1242, -0.3253, -0.0511],
          [-0.0554, -0.3456, -0.2373],
          [ 0.0403, -0.0236, -0.0369]],

         [[ 0.0829, -0.1635, -0.0200],
          [ 0.0072, -0.0876,  0.0145],
          [-0.0168,  0.0610,  0.1576]]],


        [[[ 0.0074, -0.2283, -0.0824],
          [-0.1749, -0.4771, -0.2626],
          [ 0.1342, -0.0782, -0.0817]],

         [[ 0.1612, -0.2116,  0.0075],
          [ 0.0586, -0.1819,  0.0621],
          [ 0.1930,  0.2109, -0.0009]],

         [[ 0.0672, -0.2005,  0.0944],
          [ 0.1230, -0.0435,  0.0550],
          [-0.1030, -0.0196,  0.0592]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0010, -0.0018, -0.0005],
          [-0.0036, -0.0049, -0.0041],
          [-0.0025, -0.0039, -0.0021]],

         [[-0.0017, -0.0024, -0.0010],
          [-0.0040, -0.0050, -0.0045],
          [-0.0026, -0.0040, -0.0027]],

         [[-0.0004, -0.0009,  0.0009],
          [-0.0022, -0.0030, -0.0026],
          [-0.0007, -0.0020, -0.0013]]],


        [[[-0.0254, -0.0286, -0.0180],
          [-0.0330, -0.0599, -0.0279],
          [-0.0282, -0.0847, -0.0501]],

         [[-0.0265, -0.0333, -0.0277],
          [-0.0375, -0.0604, -0.0345],
          [-0.0209, -0.0719, -0.0485]],

         [[-0.0214, -0.0298, -0.0193],
          [-0.0260, -0.0456, -0.0226],
          [-0.0006, -0.0395, -0.0204]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0074, -0.0035, -0.0044],
          [-0.0075, -0.0033, -0.0033],
          [-0.0026, -0.0001,  0.0003]],

         [[-0.0070, -0.0024, -0.0033],
          [-0.0070, -0.0025, -0.0028],
          [-0.0029, -0.0006, -0.0000]],

         [[-0.0049,  0.0008,  0.0005],
          [-0.0044,  0.0006,  0.0005],
          [-0.0013,  0.0014,  0.0026]]],


        [[[-0.0075, -0.0081, -0.0067],
          [-0.0045, -0.0045, -0.0059],
          [ 0.0019, -0.0030, -0.0097]],

         [[-0.0035, -0.0043, -0.0029],
          [-0.0014, -0.0016, -0.0032],
          [ 0.0047, -0.0008, -0.0076]],

         [[-0.0060, -0.0072, -0.0058],
          [-0.0044, -0.0051, -0.0061],
          [ 0.0021, -0.0037, -0.0096]]],


        [[[-0.0062, -0.0070, -0.0138],
          [ 0.0019,  0.0049, -0.0047],
          [ 0.0013, -0.0001, -0.0085]],

         [[-0.0074, -0.0080, -0.0145],
          [ 0.0014,  0.0040, -0.0056],
          [ 0.0003, -0.0017, -0.0102]],

         [[-0.0108, -0.0125, -0.0190],
          [-0.0026, -0.0020, -0.0110],
          [-0.0029, -0.0062, -0.0139]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2933]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 73 | Batch_idx: 0 |  Loss: (0.2743) | Acc: (91.00%) (117/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.2006) | Acc: (93.00%) (1313/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.2185) | Acc: (92.00%) (2481/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.2242) | Acc: (92.00%) (3656/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.2225) | Acc: (92.00%) (4834/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.2280) | Acc: (91.00%) (5993/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.2292) | Acc: (91.00%) (7166/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.2290) | Acc: (91.00%) (8354/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.2282) | Acc: (91.00%) (9537/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.2308) | Acc: (91.00%) (10707/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.2323) | Acc: (91.00%) (11886/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.2336) | Acc: (91.00%) (13059/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.2331) | Acc: (91.00%) (14227/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.2357) | Acc: (91.00%) (15399/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.2350) | Acc: (91.00%) (16580/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.2364) | Acc: (91.00%) (17747/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.2356) | Acc: (91.00%) (18933/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.2364) | Acc: (91.00%) (20105/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.2361) | Acc: (91.00%) (21284/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.2361) | Acc: (91.00%) (22458/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.2353) | Acc: (91.00%) (23642/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.2335) | Acc: (91.00%) (24837/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.2332) | Acc: (91.00%) (26022/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.2324) | Acc: (92.00%) (27213/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.2335) | Acc: (91.00%) (28375/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.2328) | Acc: (91.00%) (29555/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.2329) | Acc: (91.00%) (30729/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.2322) | Acc: (92.00%) (31913/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.2329) | Acc: (91.00%) (33087/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.2330) | Acc: (91.00%) (34268/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.2341) | Acc: (91.00%) (35431/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.2345) | Acc: (91.00%) (36598/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.2356) | Acc: (91.00%) (37768/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.2365) | Acc: (91.00%) (38931/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.2369) | Acc: (91.00%) (40088/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.2371) | Acc: (91.00%) (41259/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.2373) | Acc: (91.00%) (42437/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.2375) | Acc: (91.00%) (43609/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.2375) | Acc: (91.00%) (44793/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.2385) | Acc: (91.00%) (45910/50000)
# TEST : Loss: (0.3958) | Acc: (87.00%) (8758/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1141, -0.1222, -0.0856],
          [-0.0460, -0.0789,  0.0088],
          [-0.0198, -0.1313, -0.1748]],

         [[-0.0465, -0.0867, -0.0580],
          [-0.1518, -0.0198,  0.0154],
          [ 0.0083,  0.0683, -0.0222]],

         [[-0.0696,  0.0764, -0.1794],
          [ 0.1929,  0.3547,  0.1775],
          [ 0.0234,  0.2692,  0.1976]]],


        [[[ 0.3182, -0.0760,  0.1917],
          [ 0.1513, -0.0101, -0.1574],
          [-0.2159, -0.2585, -0.2507]],

         [[ 0.0202, -0.2403,  0.0135],
          [-0.0785,  0.3753, -0.1932],
          [ 0.2011,  0.0824,  0.1967]],

         [[-0.1772, -0.1914, -0.0462],
          [-0.1973,  0.1647, -0.0246],
          [ 0.0237,  0.1376,  0.2213]]],


        [[[-0.0010, -0.0027, -0.0063],
          [-0.0047, -0.0067, -0.0096],
          [-0.0108, -0.0114, -0.0121]],

         [[ 0.0024,  0.0026, -0.0011],
          [ 0.0003, -0.0006, -0.0039],
          [-0.0050, -0.0054, -0.0069]],

         [[ 0.0063,  0.0070,  0.0026],
          [ 0.0019,  0.0013, -0.0019],
          [-0.0035, -0.0039, -0.0054]]],


        ...,


        [[[ 0.0174, -0.0087, -0.0818],
          [ 0.0307,  0.0331, -0.0350],
          [-0.1949, -0.0221,  0.0155]],

         [[-0.1155, -0.1936, -0.0000],
          [ 0.1207, -0.0029, -0.1335],
          [ 0.1111, -0.0802,  0.0000]],

         [[ 0.0334,  0.0919,  0.1137],
          [ 0.3185,  0.3618,  0.1626],
          [ 0.2816,  0.2157,  0.0997]]],


        [[[ 0.2352,  0.0526,  0.0614],
          [ 0.0973, -0.0790, -0.0817],
          [-0.0127,  0.1027, -0.0110]],

         [[-0.1379, -0.3408, -0.0770],
          [-0.0542, -0.3471, -0.2660],
          [ 0.0355, -0.0315, -0.0551]],

         [[ 0.0707, -0.1760, -0.0420],
          [ 0.0117, -0.0806,  0.0013],
          [-0.0213,  0.0572,  0.1480]]],


        [[[ 0.0061, -0.2407, -0.0717],
          [-0.1781, -0.4894, -0.2477],
          [ 0.1278, -0.0869, -0.0801]],

         [[ 0.1517, -0.2261,  0.0067],
          [ 0.0534, -0.1897,  0.0691],
          [ 0.1848,  0.2031,  0.0018]],

         [[ 0.0599, -0.2086,  0.0967],
          [ 0.1219, -0.0442,  0.0673],
          [-0.1052, -0.0204,  0.0672]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0116, -0.0110, -0.0074],
          [-0.0091, -0.0113, -0.0080],
          [-0.0068, -0.0089, -0.0064]],

         [[-0.0129, -0.0125, -0.0088],
          [-0.0109, -0.0135, -0.0103],
          [-0.0090, -0.0114, -0.0088]],

         [[-0.0109, -0.0107, -0.0067],
          [-0.0088, -0.0116, -0.0082],
          [-0.0069, -0.0098, -0.0072]]],


        [[[-0.0585, -0.0981, -0.1077],
          [-0.0417, -0.0576, -0.0518],
          [-0.0595, -0.0727, -0.0845]],

         [[-0.0753, -0.1052, -0.1101],
          [-0.0547, -0.0669, -0.0582],
          [-0.0630, -0.0806, -0.1030]],

         [[-0.0719, -0.0900, -0.1064],
          [-0.0496, -0.0698, -0.0632],
          [-0.0396, -0.0706, -0.0953]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0074, -0.0068, -0.0094],
          [-0.0048, -0.0073, -0.0091],
          [ 0.0008, -0.0050, -0.0049]],

         [[-0.0049, -0.0042, -0.0073],
          [-0.0037, -0.0063, -0.0084],
          [ 0.0004, -0.0059, -0.0057]],

         [[-0.0040, -0.0029, -0.0061],
          [-0.0011, -0.0031, -0.0048],
          [ 0.0033, -0.0023, -0.0018]]],


        [[[ 0.0022,  0.0031, -0.0024],
          [-0.0014,  0.0033, -0.0019],
          [ 0.0011,  0.0052,  0.0004]],

         [[ 0.0011,  0.0024, -0.0029],
          [-0.0060, -0.0002, -0.0045],
          [-0.0062, -0.0014, -0.0054]],

         [[ 0.0057,  0.0069,  0.0006],
          [-0.0003,  0.0038, -0.0025],
          [-0.0019,  0.0007, -0.0049]]],


        [[[ 0.0149,  0.0099,  0.0087],
          [-0.0060, -0.0045, -0.0033],
          [ 0.0075,  0.0071,  0.0135]],

         [[ 0.0055,  0.0007,  0.0001],
          [-0.0151, -0.0132, -0.0120],
          [-0.0012, -0.0019,  0.0032]],

         [[-0.0020, -0.0066, -0.0062],
          [-0.0216, -0.0201, -0.0181],
          [-0.0090, -0.0100, -0.0047]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2924]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 74 | Batch_idx: 0 |  Loss: (0.1181) | Acc: (94.00%) (121/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.2259) | Acc: (91.00%) (1293/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2295) | Acc: (91.00%) (2465/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2286) | Acc: (91.00%) (3646/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2264) | Acc: (92.00%) (4836/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2218) | Acc: (92.00%) (6025/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2232) | Acc: (92.00%) (7217/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2246) | Acc: (92.00%) (8382/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2251) | Acc: (92.00%) (9552/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2243) | Acc: (92.00%) (10729/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2283) | Acc: (92.00%) (11911/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2278) | Acc: (92.00%) (13097/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2274) | Acc: (92.00%) (14285/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2258) | Acc: (92.00%) (15471/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2282) | Acc: (92.00%) (16639/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2279) | Acc: (92.00%) (17812/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2265) | Acc: (92.00%) (19003/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2253) | Acc: (92.00%) (20195/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2257) | Acc: (92.00%) (21370/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2259) | Acc: (92.00%) (22556/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2264) | Acc: (92.00%) (23730/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2263) | Acc: (92.00%) (24907/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2257) | Acc: (92.00%) (26096/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2253) | Acc: (92.00%) (27285/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2238) | Acc: (92.00%) (28483/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2245) | Acc: (92.00%) (29660/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2241) | Acc: (92.00%) (30846/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2239) | Acc: (92.00%) (32023/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2240) | Acc: (92.00%) (33208/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2255) | Acc: (92.00%) (34371/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2253) | Acc: (92.00%) (35552/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2251) | Acc: (92.00%) (36740/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2251) | Acc: (92.00%) (37921/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2255) | Acc: (92.00%) (39090/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2265) | Acc: (92.00%) (40256/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2268) | Acc: (92.00%) (41429/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2270) | Acc: (92.00%) (42607/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2287) | Acc: (92.00%) (43778/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2292) | Acc: (92.00%) (44947/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2304) | Acc: (92.00%) (46063/50000)
# TEST : Loss: (0.3527) | Acc: (88.00%) (8877/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1164, -0.1253, -0.0869],
          [-0.0505, -0.0861,  0.0033],
          [-0.0236, -0.1373, -0.1770]],

         [[-0.0465, -0.0878, -0.0593],
          [-0.1517, -0.0231,  0.0114],
          [ 0.0083,  0.0647, -0.0247]],

         [[-0.0665,  0.0769, -0.1789],
          [ 0.1928,  0.3516,  0.1735],
          [ 0.0236,  0.2653,  0.1943]]],


        [[[ 0.3290, -0.0683,  0.1885],
          [ 0.1582, -0.0082, -0.1602],
          [-0.2138, -0.2617, -0.2541]],

         [[ 0.0250, -0.2388,  0.0077],
          [-0.0749,  0.3756, -0.1959],
          [ 0.2026,  0.0812,  0.1933]],

         [[-0.1744, -0.1985, -0.0594],
          [-0.1978,  0.1592, -0.0338],
          [ 0.0224,  0.1345,  0.2181]]],


        [[[-0.0005, -0.0014, -0.0034],
          [-0.0024, -0.0035, -0.0053],
          [-0.0058, -0.0059, -0.0065]],

         [[ 0.0012,  0.0013, -0.0005],
          [ 0.0001, -0.0003, -0.0018],
          [-0.0026, -0.0026, -0.0034]],

         [[ 0.0031,  0.0033,  0.0012],
          [ 0.0010,  0.0006, -0.0009],
          [-0.0019, -0.0019, -0.0028]]],


        ...,


        [[[ 0.0104, -0.0098, -0.0780],
          [ 0.0176,  0.0301, -0.0361],
          [-0.2023, -0.0259,  0.0085]],

         [[-0.1249, -0.1910,  0.0071],
          [ 0.1071,  0.0002, -0.1293],
          [ 0.1055, -0.0807, -0.0072]],

         [[ 0.0276,  0.1022,  0.1267],
          [ 0.3046,  0.3832,  0.1766],
          [ 0.2741,  0.2174,  0.0904]]],


        [[[ 0.2483,  0.0697,  0.0783],
          [ 0.1046, -0.0674, -0.0760],
          [ 0.0029,  0.1113, -0.0071]],

         [[-0.1263, -0.3148, -0.0603],
          [-0.0597, -0.3460, -0.2803],
          [ 0.0374, -0.0377, -0.0687]],

         [[ 0.0748, -0.1625, -0.0385],
          [-0.0004, -0.0889, -0.0208],
          [-0.0228,  0.0501,  0.1317]]],


        [[[ 0.0111, -0.2273, -0.0440],
          [-0.1758, -0.5003, -0.2501],
          [ 0.1355, -0.0897, -0.0758]],

         [[ 0.1655, -0.2111,  0.0258],
          [ 0.0606, -0.1901,  0.0697],
          [ 0.1954,  0.2032,  0.0092]],

         [[ 0.0641, -0.2068,  0.1022],
          [ 0.1205, -0.0516,  0.0606],
          [-0.0988, -0.0223,  0.0698]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0037, -0.0042, -0.0058],
          [-0.0003, -0.0008, -0.0041],
          [ 0.0030,  0.0007, -0.0028]],

         [[-0.0055, -0.0057, -0.0070],
          [-0.0021, -0.0026, -0.0056],
          [ 0.0009, -0.0014, -0.0048]],

         [[-0.0061, -0.0077, -0.0098],
          [-0.0019, -0.0037, -0.0077],
          [ 0.0006, -0.0025, -0.0070]]],


        [[[-0.0657, -0.0682, -0.0427],
          [-0.0774, -0.0662, -0.0481],
          [-0.0361, -0.0138, -0.0052]],

         [[-0.0350, -0.0271,  0.0019],
          [-0.0483, -0.0363, -0.0214],
          [-0.0176,  0.0049,  0.0089]],

         [[-0.0181, -0.0269, -0.0171],
          [-0.0207, -0.0243, -0.0179],
          [ 0.0069,  0.0196,  0.0218]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0083, -0.0112, -0.0154],
          [-0.0000, -0.0017, -0.0044],
          [ 0.0006, -0.0032, -0.0040]],

         [[-0.0090, -0.0131, -0.0173],
          [ 0.0012, -0.0021, -0.0051],
          [ 0.0043, -0.0016, -0.0032]],

         [[-0.0110, -0.0160, -0.0206],
          [ 0.0016, -0.0027, -0.0069],
          [ 0.0047, -0.0029, -0.0065]]],


        [[[ 0.0070,  0.0087,  0.0077],
          [ 0.0019,  0.0042,  0.0030],
          [ 0.0079,  0.0102,  0.0087]],

         [[ 0.0041,  0.0068,  0.0060],
          [-0.0017,  0.0016,  0.0012],
          [ 0.0038,  0.0073,  0.0071]],

         [[-0.0044, -0.0010, -0.0014],
          [-0.0060, -0.0026, -0.0034],
          [ 0.0009,  0.0036,  0.0023]]],


        [[[ 0.0059, -0.0000, -0.0022],
          [ 0.0056, -0.0015,  0.0004],
          [-0.0020, -0.0114, -0.0120]],

         [[ 0.0065,  0.0021,  0.0006],
          [ 0.0037, -0.0014,  0.0022],
          [-0.0031, -0.0108, -0.0095]],

         [[ 0.0178,  0.0078, -0.0002],
          [ 0.0126,  0.0045,  0.0041],
          [ 0.0075, -0.0025, -0.0043]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2913]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 75 | Batch_idx: 0 |  Loss: (0.1765) | Acc: (94.00%) (121/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2378) | Acc: (91.00%) (1285/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.2462) | Acc: (91.00%) (2451/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.2596) | Acc: (91.00%) (3619/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.2636) | Acc: (91.00%) (4776/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.2613) | Acc: (90.00%) (5929/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.2588) | Acc: (90.00%) (7098/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.2555) | Acc: (91.00%) (8276/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.2555) | Acc: (91.00%) (9445/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.2503) | Acc: (91.00%) (10637/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.2470) | Acc: (91.00%) (11829/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.2418) | Acc: (91.00%) (13025/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.2389) | Acc: (91.00%) (14212/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.2381) | Acc: (91.00%) (15399/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.2366) | Acc: (91.00%) (16600/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.2346) | Acc: (92.00%) (17784/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.2331) | Acc: (92.00%) (18979/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.2306) | Acc: (92.00%) (20184/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.2304) | Acc: (92.00%) (21379/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.2299) | Acc: (92.00%) (22565/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.2296) | Acc: (92.00%) (23747/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.2296) | Acc: (92.00%) (24933/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.2284) | Acc: (92.00%) (26137/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.2271) | Acc: (92.00%) (27321/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.2259) | Acc: (92.00%) (28518/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.2250) | Acc: (92.00%) (29704/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.2236) | Acc: (92.00%) (30899/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.2241) | Acc: (92.00%) (32079/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.2237) | Acc: (92.00%) (33267/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.2231) | Acc: (92.00%) (34465/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.2222) | Acc: (92.00%) (35655/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.2214) | Acc: (92.00%) (36851/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.2209) | Acc: (92.00%) (38034/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.2190) | Acc: (92.00%) (39249/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.2188) | Acc: (92.00%) (40434/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.2185) | Acc: (92.00%) (41626/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.2177) | Acc: (92.00%) (42824/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.2174) | Acc: (92.00%) (44015/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.2166) | Acc: (92.00%) (45213/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.2159) | Acc: (92.00%) (46367/50000)
# TEST : Loss: (0.3104) | Acc: (89.00%) (8998/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1143, -0.1230, -0.0845],
          [-0.0499, -0.0848,  0.0047],
          [-0.0243, -0.1364, -0.1751]],

         [[-0.0446, -0.0855, -0.0568],
          [-0.1494, -0.0217,  0.0135],
          [ 0.0081,  0.0645, -0.0233]],

         [[-0.0645,  0.0777, -0.1750],
          [ 0.1918,  0.3496,  0.1742],
          [ 0.0230,  0.2633,  0.1939]]],


        [[[ 0.3303, -0.0660,  0.1894],
          [ 0.1601, -0.0065, -0.1592],
          [-0.2119, -0.2602, -0.2545]],

         [[ 0.0251, -0.2377,  0.0076],
          [-0.0741,  0.3758, -0.1955],
          [ 0.2032,  0.0816,  0.1920]],

         [[-0.1752, -0.1976, -0.0588],
          [-0.1978,  0.1596, -0.0332],
          [ 0.0224,  0.1344,  0.2169]]],


        [[[-0.0002, -0.0007, -0.0016],
          [-0.0011, -0.0016, -0.0026],
          [-0.0027, -0.0026, -0.0030]],

         [[ 0.0005,  0.0006, -0.0002],
          [ 0.0001, -0.0001, -0.0007],
          [-0.0012, -0.0011, -0.0014]],

         [[ 0.0013,  0.0013,  0.0005],
          [ 0.0004,  0.0002, -0.0004],
          [-0.0009, -0.0008, -0.0012]]],


        ...,


        [[[ 0.0136, -0.0059, -0.0739],
          [ 0.0212,  0.0340, -0.0322],
          [-0.1980, -0.0219,  0.0113]],

         [[-0.1198, -0.1850,  0.0114],
          [ 0.1111,  0.0053, -0.1242],
          [ 0.1086, -0.0752, -0.0041]],

         [[ 0.0301,  0.1054,  0.1292],
          [ 0.3032,  0.3820,  0.1777],
          [ 0.2717,  0.2188,  0.0908]]],


        [[[ 0.2472,  0.0685,  0.0760],
          [ 0.1039, -0.0682, -0.0779],
          [ 0.0009,  0.1070, -0.0118]],

         [[-0.1237, -0.3106, -0.0618],
          [-0.0582, -0.3412, -0.2795],
          [ 0.0358, -0.0410, -0.0735]],

         [[ 0.0770, -0.1574, -0.0371],
          [ 0.0017, -0.0855, -0.0202],
          [-0.0230,  0.0477,  0.1275]]],


        [[[ 0.0120, -0.2218, -0.0443],
          [-0.1745, -0.4945, -0.2516],
          [ 0.1363, -0.0877, -0.0761]],

         [[ 0.1657, -0.2077,  0.0255],
          [ 0.0611, -0.1881,  0.0675],
          [ 0.1962,  0.2042,  0.0088]],

         [[ 0.0641, -0.2036,  0.1030],
          [ 0.1206, -0.0499,  0.0603],
          [-0.0973, -0.0204,  0.0701]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2301]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0129]], device='cuda:0')

Epoch: 76 | Batch_idx: 0 |  Loss: (0.1440) | Acc: (94.00%) (121/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.1822) | Acc: (93.00%) (1320/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.2010) | Acc: (92.00%) (2499/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.1872) | Acc: (93.00%) (3711/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.1872) | Acc: (93.00%) (4926/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.1888) | Acc: (93.00%) (6134/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.1933) | Acc: (93.00%) (7320/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.1945) | Acc: (93.00%) (8515/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.1951) | Acc: (93.00%) (9713/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.1930) | Acc: (93.00%) (10921/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.1941) | Acc: (93.00%) (12118/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.1949) | Acc: (93.00%) (13308/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.1971) | Acc: (93.00%) (14495/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.1952) | Acc: (93.00%) (15700/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.1961) | Acc: (93.00%) (16883/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.1965) | Acc: (93.00%) (18071/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.1967) | Acc: (93.00%) (19265/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.1971) | Acc: (93.00%) (20461/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.1951) | Acc: (93.00%) (21672/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.1960) | Acc: (93.00%) (22861/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.1957) | Acc: (93.00%) (24054/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.1968) | Acc: (93.00%) (25243/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.1965) | Acc: (93.00%) (26442/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.1959) | Acc: (93.00%) (27645/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.1956) | Acc: (93.00%) (28848/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.1950) | Acc: (93.00%) (30049/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.1944) | Acc: (93.00%) (31258/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.1942) | Acc: (93.00%) (32457/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.1949) | Acc: (93.00%) (33642/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.1946) | Acc: (93.00%) (34847/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.1948) | Acc: (93.00%) (36041/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.1947) | Acc: (93.00%) (37238/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.1949) | Acc: (93.00%) (38435/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.1950) | Acc: (93.00%) (39630/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.1948) | Acc: (93.00%) (40828/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.1950) | Acc: (93.00%) (42025/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.1947) | Acc: (93.00%) (43227/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.1950) | Acc: (93.00%) (44420/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.1954) | Acc: (93.00%) (45617/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.1954) | Acc: (93.00%) (46767/50000)
# TEST : Loss: (0.3020) | Acc: (90.00%) (9021/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1129, -0.1216, -0.0835],
          [-0.0493, -0.0839,  0.0047],
          [-0.0241, -0.1351, -0.1734]],

         [[-0.0441, -0.0846, -0.0562],
          [-0.1478, -0.0214,  0.0134],
          [ 0.0080,  0.0639, -0.0230]],

         [[-0.0638,  0.0768, -0.1730],
          [ 0.1897,  0.3457,  0.1723],
          [ 0.0227,  0.2604,  0.1918]]],


        [[[ 0.3299, -0.0660,  0.1892],
          [ 0.1599, -0.0065, -0.1590],
          [-0.2117, -0.2598, -0.2542]],

         [[ 0.0251, -0.2374,  0.0075],
          [-0.0740,  0.3753, -0.1953],
          [ 0.2030,  0.0815,  0.1918]],

         [[-0.1750, -0.1973, -0.0587],
          [-0.1975,  0.1594, -0.0331],
          [ 0.0223,  0.1342,  0.2167]]],


        [[[-0.0001, -0.0003, -0.0006],
          [-0.0004, -0.0006, -0.0011],
          [-0.0011, -0.0010, -0.0012]],

         [[ 0.0002,  0.0002, -0.0001],
          [ 0.0000, -0.0000, -0.0002],
          [-0.0005, -0.0004, -0.0005]],

         [[ 0.0005,  0.0004,  0.0001],
          [ 0.0002,  0.0001, -0.0001],
          [-0.0003, -0.0003, -0.0005]]],


        ...,


        [[[ 0.0135, -0.0058, -0.0734],
          [ 0.0211,  0.0338, -0.0320],
          [-0.1967, -0.0217,  0.0113]],

         [[-0.1189, -0.1835,  0.0113],
          [ 0.1101,  0.0052, -0.1231],
          [ 0.1077, -0.0746, -0.0041]],

         [[ 0.0297,  0.1042,  0.1279],
          [ 0.2972,  0.3738,  0.1750],
          [ 0.2667,  0.2147,  0.0896]]],


        [[[ 0.2453,  0.0679,  0.0753],
          [ 0.1031, -0.0675, -0.0771],
          [ 0.0009,  0.1061, -0.0117]],

         [[-0.1224, -0.3053, -0.0608],
          [-0.0576, -0.3344, -0.2742],
          [ 0.0355, -0.0406, -0.0728]],

         [[ 0.0761, -0.1546, -0.0365],
          [ 0.0017, -0.0838, -0.0198],
          [-0.0228,  0.0471,  0.1261]]],


        [[[ 0.0119, -0.2193, -0.0439],
          [-0.1734, -0.4883, -0.2493],
          [ 0.1356, -0.0871, -0.0757]],

         [[ 0.1648, -0.2063,  0.0253],
          [ 0.0608, -0.1867,  0.0671],
          [ 0.1954,  0.2032,  0.0088]],

         [[ 0.0638, -0.2024,  0.1024],
          [ 0.1200, -0.0496,  0.0599],
          [-0.0969, -0.0203,  0.0697]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2487]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0376]], device='cuda:0')

Epoch: 77 | Batch_idx: 0 |  Loss: (0.2254) | Acc: (91.00%) (117/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2208) | Acc: (93.00%) (1311/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.1980) | Acc: (93.00%) (2521/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.1937) | Acc: (93.00%) (3716/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.1937) | Acc: (93.00%) (4908/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.1917) | Acc: (93.00%) (6111/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.1908) | Acc: (93.00%) (7318/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.1905) | Acc: (93.00%) (8529/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.1935) | Acc: (93.00%) (9717/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.1944) | Acc: (93.00%) (10911/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.1958) | Acc: (93.00%) (12107/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.1963) | Acc: (93.00%) (13303/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.1947) | Acc: (93.00%) (14505/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.1978) | Acc: (93.00%) (15669/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.1994) | Acc: (93.00%) (16858/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.1990) | Acc: (93.00%) (18056/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.1976) | Acc: (93.00%) (19268/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.1975) | Acc: (93.00%) (20464/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.1961) | Acc: (93.00%) (21672/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.1963) | Acc: (93.00%) (22866/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.1968) | Acc: (93.00%) (24047/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.1964) | Acc: (93.00%) (25251/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.1969) | Acc: (93.00%) (26448/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.1969) | Acc: (93.00%) (27645/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.1977) | Acc: (93.00%) (28832/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.1986) | Acc: (93.00%) (30008/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.1989) | Acc: (93.00%) (31196/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.1986) | Acc: (93.00%) (32392/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.1986) | Acc: (93.00%) (33595/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.1983) | Acc: (93.00%) (34800/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.1986) | Acc: (93.00%) (35994/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.1983) | Acc: (93.00%) (37197/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.1982) | Acc: (93.00%) (38397/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.1985) | Acc: (93.00%) (39587/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.1981) | Acc: (93.00%) (40797/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.1988) | Acc: (93.00%) (41969/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.1992) | Acc: (93.00%) (43158/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.1985) | Acc: (93.00%) (44368/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.1980) | Acc: (93.00%) (45574/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.1981) | Acc: (93.00%) (46730/50000)
# TEST : Loss: (0.2952) | Acc: (90.00%) (9040/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1135e-01, -1.1985e-01, -8.2328e-02],
          [-4.8696e-02, -8.2833e-02,  4.5913e-03],
          [-2.3764e-02, -1.3343e-01, -1.7125e-01]],

         [[-4.3469e-02, -8.3444e-02, -5.5406e-02],
          [-1.4595e-01, -2.1173e-02,  1.3180e-02],
          [ 7.8804e-03,  6.3106e-02, -2.2756e-02]],

         [[-6.2925e-02,  7.5786e-02, -1.7057e-01],
          [ 1.8710e-01,  3.4098e-01,  1.6993e-01],
          [ 2.2415e-02,  2.5688e-01,  1.8922e-01]]],


        [[[ 3.2938e-01, -6.5854e-02,  1.8893e-01],
          [ 1.5969e-01, -6.5122e-03, -1.5873e-01],
          [-2.1134e-01, -2.5945e-01, -2.5379e-01]],

         [[ 2.5065e-02, -2.3708e-01,  7.5308e-03],
          [-7.3900e-02,  3.7475e-01, -1.9499e-01],
          [ 2.0267e-01,  8.1424e-02,  1.9150e-01]],

         [[-1.7469e-01, -1.9702e-01, -5.8607e-02],
          [-1.9721e-01,  1.5912e-01, -3.3078e-02],
          [ 2.2312e-02,  1.3404e-01,  2.1632e-01]]],


        [[[-2.8454e-05, -9.2961e-05, -2.0358e-04],
          [-1.1904e-04, -1.9576e-04, -3.6715e-04],
          [-3.4985e-04, -2.9504e-04, -3.8582e-04]],

         [[ 5.4728e-05,  6.0877e-05, -1.8940e-05],
          [ 5.8734e-06, -8.4003e-06, -6.1961e-05],
          [-1.4227e-04, -9.4046e-05, -1.3223e-04]],

         [[ 1.3469e-04,  1.1176e-04,  3.3337e-05],
          [ 4.3224e-05,  1.8295e-05, -3.2086e-05],
          [-1.1014e-04, -7.9010e-05, -1.3959e-04]]],


        ...,


        [[[ 1.3426e-02, -5.7898e-03, -7.2870e-02],
          [ 2.0930e-02,  3.3524e-02, -3.1783e-02],
          [-1.9519e-01, -2.1553e-02,  1.1190e-02]],

         [[-1.1775e-01, -1.8179e-01,  1.1196e-02],
          [ 1.0889e-01,  5.1516e-03, -1.2182e-01],
          [ 1.0655e-01, -7.3786e-02, -4.0265e-03]],

         [[ 2.9308e-02,  1.0272e-01,  1.2627e-01],
          [ 2.9017e-01,  3.6408e-01,  1.7175e-01],
          [ 2.6075e-01,  2.0988e-01,  8.8055e-02]]],


        [[[ 2.4316e-01,  6.7147e-02,  7.4492e-02],
          [ 1.0215e-01, -6.6775e-02, -7.6249e-02],
          [ 9.1609e-04,  1.0510e-01, -1.1623e-02]],

         [[-1.2093e-01, -2.9897e-01, -5.9678e-02],
          [-5.6837e-02, -3.2639e-01, -2.6798e-01],
          [ 3.5185e-02, -4.0035e-02, -7.1874e-02]],

         [[ 7.5099e-02, -1.5125e-01, -3.5787e-02],
          [ 1.6266e-03, -8.1846e-02, -1.9380e-02],
          [-2.2577e-02,  4.6475e-02,  1.2440e-01]]],


        [[[ 1.1837e-02, -2.1623e-01, -4.3447e-02],
          [-1.7204e-01, -4.8082e-01, -2.4657e-01],
          [ 1.3484e-01, -8.6522e-02, -7.5157e-02]],

         [[ 1.6378e-01, -2.0454e-01,  2.5141e-02],
          [ 6.0371e-02, -1.8513e-01,  6.6559e-02],
          [ 1.9438e-01,  2.0196e-01,  8.7277e-03]],

         [[ 6.3425e-02, -2.0096e-01,  1.0170e-01],
          [ 1.1922e-01, -4.9254e-02,  5.9530e-02],
          [-9.6402e-02, -2.0161e-02,  6.9350e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2337]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0191]], device='cuda:0')

Epoch: 78 | Batch_idx: 0 |  Loss: (0.2282) | Acc: (93.00%) (120/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2062) | Acc: (94.00%) (1324/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2008) | Acc: (94.00%) (2527/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.1997) | Acc: (93.00%) (3724/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2027) | Acc: (93.00%) (4917/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2106) | Acc: (93.00%) (6097/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2097) | Acc: (93.00%) (7291/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2076) | Acc: (93.00%) (8483/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2057) | Acc: (93.00%) (9682/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.2046) | Acc: (93.00%) (10882/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.2052) | Acc: (93.00%) (12084/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.2040) | Acc: (93.00%) (13283/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.2032) | Acc: (93.00%) (14471/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.2049) | Acc: (93.00%) (15652/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.2048) | Acc: (93.00%) (16855/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.2053) | Acc: (93.00%) (18038/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.2046) | Acc: (93.00%) (19234/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.2039) | Acc: (93.00%) (20434/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.2036) | Acc: (93.00%) (21630/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.2033) | Acc: (93.00%) (22828/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.2038) | Acc: (93.00%) (24020/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.2025) | Acc: (93.00%) (25229/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.2028) | Acc: (93.00%) (26423/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.2028) | Acc: (93.00%) (27622/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.2029) | Acc: (93.00%) (28814/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.2023) | Acc: (93.00%) (30013/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.2028) | Acc: (93.00%) (31204/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.2029) | Acc: (93.00%) (32402/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2033) | Acc: (93.00%) (33592/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2022) | Acc: (93.00%) (34806/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2023) | Acc: (93.00%) (36004/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2019) | Acc: (93.00%) (37207/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2018) | Acc: (93.00%) (38417/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2017) | Acc: (93.00%) (39614/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2015) | Acc: (93.00%) (40812/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2013) | Acc: (93.00%) (42014/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2009) | Acc: (93.00%) (43219/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2003) | Acc: (93.00%) (44430/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2000) | Acc: (93.00%) (45641/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2002) | Acc: (93.00%) (46793/50000)
# TEST : Loss: (0.2968) | Acc: (90.00%) (9022/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0944e-01, -1.1779e-01, -8.0898e-02],
          [-4.7930e-02, -8.1548e-02,  4.5196e-03],
          [-2.3405e-02, -1.3147e-01, -1.6871e-01]],

         [[-4.2756e-02, -8.2070e-02, -5.4481e-02],
          [-1.4368e-01, -2.0845e-02,  1.2975e-02],
          [ 7.7604e-03,  6.2162e-02, -2.2415e-02]],

         [[-6.1876e-02,  7.4517e-02, -1.6768e-01],
          [ 1.8402e-01,  3.3535e-01,  1.6712e-01],
          [ 2.2049e-02,  2.5272e-01,  1.8616e-01]]],


        [[[ 3.2880e-01, -6.5736e-02,  1.8859e-01],
          [ 1.5939e-01, -6.5002e-03, -1.5844e-01],
          [-2.1096e-01, -2.5899e-01, -2.5334e-01]],

         [[ 2.5020e-02, -2.3664e-01,  7.5172e-03],
          [-7.3761e-02,  3.7404e-01, -1.9463e-01],
          [ 2.0229e-01,  8.1274e-02,  1.9116e-01]],

         [[-1.7436e-01, -1.9663e-01, -5.8495e-02],
          [-1.9682e-01,  1.5880e-01, -3.3014e-02],
          [ 2.2269e-02,  1.3378e-01,  2.1592e-01]]],


        [[[-6.6863e-06, -2.4117e-05, -5.1078e-05],
          [-2.7001e-05, -4.7276e-05, -9.8478e-05],
          [-8.7909e-05, -6.7661e-05, -9.6384e-05]],

         [[ 1.1942e-05,  1.3311e-05, -3.7236e-06],
          [ 1.2096e-06, -1.4999e-06, -1.1640e-05],
          [-3.3823e-05, -1.8333e-05, -2.6776e-05]],

         [[ 2.8545e-05,  2.1048e-05,  5.7423e-06],
          [ 9.3019e-06,  3.2495e-06, -6.1778e-06],
          [-2.7383e-05, -1.6316e-05, -3.1907e-05]]],


        ...,


        [[[ 1.3302e-02, -5.7365e-03, -7.2211e-02],
          [ 2.0728e-02,  3.3202e-02, -3.1481e-02],
          [-1.9335e-01, -2.1351e-02,  1.1086e-02]],

         [[-1.1638e-01, -1.7967e-01,  1.1072e-02],
          [ 1.0746e-01,  5.0830e-03, -1.2028e-01],
          [ 1.0518e-01, -7.2839e-02, -3.9772e-03]],

         [[ 2.8807e-02,  1.0093e-01,  1.2434e-01],
          [ 2.8179e-01,  3.5257e-01,  1.6793e-01],
          [ 2.5368e-01,  2.0411e-01,  8.6245e-02]]],


        [[[ 2.4052e-01,  6.6256e-02,  7.3497e-02],
          [ 1.0100e-01, -6.5866e-02, -7.5188e-02],
          [ 9.0659e-04,  1.0387e-01, -1.1488e-02]],

         [[-1.1915e-01, -2.9145e-01, -5.8295e-02],
          [-5.5937e-02, -3.1687e-01, -2.6056e-01],
          [ 3.4750e-02, -3.9409e-02, -7.0797e-02]],

         [[ 7.3880e-02, -1.4727e-01, -3.4915e-02],
          [ 1.5984e-03, -7.9512e-02, -1.8853e-02],
          [-2.2266e-02,  4.5683e-02,  1.2240e-01]]],


        [[[ 1.1727e-02, -2.1259e-01, -4.2903e-02],
          [-1.7041e-01, -4.7188e-01, -2.4327e-01],
          [ 1.3390e-01, -8.5774e-02, -7.4545e-02]],

         [[ 1.6249e-01, -2.0244e-01,  2.4910e-02],
          [ 5.9893e-02, -1.8319e-01,  6.5935e-02],
          [ 1.9314e-01,  2.0048e-01,  8.6665e-03]],

         [[ 6.2948e-02, -1.9919e-01,  1.0087e-01],
          [ 1.1833e-01, -4.8821e-02,  5.9039e-02],
          [-9.5782e-02, -2.0018e-02,  6.8873e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2341]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0057]], device='cuda:0')

Epoch: 79 | Batch_idx: 0 |  Loss: (0.1432) | Acc: (97.00%) (125/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2182) | Acc: (93.00%) (1320/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2095) | Acc: (93.00%) (2509/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2065) | Acc: (93.00%) (3706/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.1989) | Acc: (93.00%) (4924/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2040) | Acc: (93.00%) (6113/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2046) | Acc: (93.00%) (7313/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2055) | Acc: (93.00%) (8506/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2057) | Acc: (93.00%) (9702/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2030) | Acc: (93.00%) (10909/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2029) | Acc: (93.00%) (12106/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2017) | Acc: (93.00%) (13305/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.1998) | Acc: (93.00%) (14510/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2008) | Acc: (93.00%) (15704/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2028) | Acc: (93.00%) (16882/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2024) | Acc: (93.00%) (18083/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2043) | Acc: (93.00%) (19265/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2052) | Acc: (93.00%) (20452/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2050) | Acc: (93.00%) (21653/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2048) | Acc: (93.00%) (22857/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2057) | Acc: (93.00%) (24048/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2060) | Acc: (93.00%) (25244/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2058) | Acc: (93.00%) (26443/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2052) | Acc: (93.00%) (27637/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2057) | Acc: (93.00%) (28828/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2056) | Acc: (93.00%) (30029/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2058) | Acc: (93.00%) (31230/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2055) | Acc: (93.00%) (32435/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2053) | Acc: (93.00%) (33632/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2054) | Acc: (93.00%) (34826/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2059) | Acc: (93.00%) (36013/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2057) | Acc: (93.00%) (37214/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2068) | Acc: (93.00%) (38389/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2067) | Acc: (93.00%) (39597/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2072) | Acc: (93.00%) (40779/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2067) | Acc: (93.00%) (41992/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2065) | Acc: (93.00%) (43201/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2064) | Acc: (93.00%) (44406/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2066) | Acc: (93.00%) (45603/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2063) | Acc: (93.00%) (46769/50000)
# TEST : Loss: (0.2959) | Acc: (90.00%) (9010/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0717e-01, -1.1534e-01, -7.9192e-02],
          [-4.7015e-02, -8.0012e-02,  4.4339e-03],
          [-2.2976e-02, -1.2911e-01, -1.6567e-01]],

         [[-4.1905e-02, -8.0429e-02, -5.3377e-02],
          [-1.4096e-01, -2.0454e-02,  1.2731e-02],
          [ 7.6170e-03,  6.1034e-02, -2.2007e-02]],

         [[-6.0624e-02,  7.3002e-02, -1.6423e-01],
          [ 1.8034e-01,  3.2864e-01,  1.6377e-01],
          [ 2.1611e-02,  2.4774e-01,  1.8250e-01]]],


        [[[ 3.2808e-01, -6.5593e-02,  1.8819e-01],
          [ 1.5903e-01, -6.4857e-03, -1.5808e-01],
          [-2.1050e-01, -2.5842e-01, -2.5281e-01]],

         [[ 2.4965e-02, -2.3610e-01,  7.5007e-03],
          [-7.3592e-02,  3.7318e-01, -1.9419e-01],
          [ 2.0184e-01,  8.1092e-02,  1.9074e-01]],

         [[-1.7395e-01, -1.9616e-01, -5.8359e-02],
          [-1.9635e-01,  1.5842e-01, -3.2936e-02],
          [ 2.2217e-02,  1.3347e-01,  2.1544e-01]]],


        [[[-1.1326e-06, -4.6168e-06, -9.3820e-06],
          [-4.3776e-06, -8.2834e-06, -1.9644e-05],
          [-1.6178e-05, -1.1120e-05, -1.7610e-05]],

         [[ 1.8456e-06,  2.0623e-06, -5.0571e-07],
          [ 1.7400e-07, -1.8078e-07, -1.4942e-06],
          [-5.8123e-06, -2.4638e-06, -3.7725e-06]],

         [[ 4.2549e-06,  2.7102e-06,  6.6187e-07],
          [ 1.4131e-06,  3.8909e-07, -8.1760e-07],
          [-4.9734e-06, -2.3553e-06, -5.2231e-06]]],


        ...,


        [[[ 1.3152e-02, -5.6723e-03, -7.1417e-02],
          [ 2.0485e-02,  3.2814e-02, -3.1117e-02],
          [-1.9113e-01, -2.1109e-02,  1.0961e-02]],

         [[-1.1473e-01, -1.7712e-01,  1.0923e-02],
          [ 1.0574e-01,  5.0007e-03, -1.1843e-01],
          [ 1.0354e-01, -7.1703e-02, -3.9180e-03]],

         [[ 2.8210e-02,  9.8805e-02,  1.2202e-01],
          [ 2.7193e-01,  3.3907e-01,  1.6338e-01],
          [ 2.4533e-01,  1.9731e-01,  8.4095e-02]]],


        [[[ 2.3736e-01,  6.5189e-02,  7.2304e-02],
          [ 9.9624e-02, -6.4776e-02, -7.3919e-02],
          [ 8.9516e-04,  1.0239e-01, -1.1325e-02]],

         [[-1.1702e-01, -2.8256e-01, -5.6655e-02],
          [-5.4862e-02, -3.0567e-01, -2.5181e-01],
          [ 3.4227e-02, -3.8660e-02, -6.9509e-02]],

         [[ 7.2424e-02, -1.4258e-01, -3.3883e-02],
          [ 1.5649e-03, -7.6763e-02, -1.8233e-02],
          [-2.1895e-02,  4.4739e-02,  1.2001e-01]]],


        [[[ 1.1594e-02, -2.0824e-01, -4.2252e-02],
          [-1.6845e-01, -4.6123e-01, -2.3930e-01],
          [ 1.3277e-01, -8.4873e-02, -7.3807e-02]],

         [[ 1.6094e-01, -1.9991e-01,  2.4633e-02],
          [ 5.9316e-02, -1.8086e-01,  6.5184e-02],
          [ 1.9165e-01,  1.9870e-01,  8.5926e-03]],

         [[ 6.2374e-02, -1.9706e-01,  9.9876e-02],
          [ 1.1725e-01, -4.8299e-02,  5.8449e-02],
          [-9.5033e-02, -1.9845e-02,  6.8297e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2434]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0451]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 80 | Batch_idx: 0 |  Loss: (0.2384) | Acc: (91.00%) (117/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2971) | Acc: (89.00%) (1257/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.3324) | Acc: (88.00%) (2372/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.3819) | Acc: (86.00%) (3436/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.4178) | Acc: (85.00%) (4497/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.4209) | Acc: (85.00%) (5580/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.4219) | Acc: (85.00%) (6665/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.4261) | Acc: (85.00%) (7743/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.4275) | Acc: (85.00%) (8833/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.4308) | Acc: (85.00%) (9919/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.4318) | Acc: (85.00%) (11013/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.4300) | Acc: (85.00%) (12123/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.4297) | Acc: (85.00%) (13220/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.4242) | Acc: (85.00%) (14341/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.4192) | Acc: (85.00%) (15464/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.4139) | Acc: (85.00%) (16588/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.4120) | Acc: (85.00%) (17708/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.4067) | Acc: (86.00%) (18836/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.4019) | Acc: (86.00%) (19989/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.3995) | Acc: (86.00%) (21117/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.3965) | Acc: (86.00%) (22235/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.3945) | Acc: (86.00%) (23367/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.3927) | Acc: (86.00%) (24498/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.3897) | Acc: (86.00%) (25627/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.3877) | Acc: (86.00%) (26758/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.3850) | Acc: (86.00%) (27906/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.3851) | Acc: (86.00%) (29021/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.3829) | Acc: (86.00%) (30154/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.3799) | Acc: (86.00%) (31292/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.3786) | Acc: (87.00%) (32420/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.3762) | Acc: (87.00%) (33570/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.3745) | Acc: (87.00%) (34712/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.3739) | Acc: (87.00%) (35839/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.3732) | Acc: (87.00%) (36971/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.3713) | Acc: (87.00%) (38105/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.3709) | Acc: (87.00%) (39237/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.3709) | Acc: (87.00%) (40353/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.3708) | Acc: (87.00%) (41483/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.3698) | Acc: (87.00%) (42611/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.3687) | Acc: (87.00%) (43707/50000)
# TEST : Loss: (0.3937) | Acc: (86.00%) (8674/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-9.6700e-02, -9.9061e-02, -6.9216e-02],
          [-2.2894e-02, -5.0106e-02,  2.5274e-02],
          [ 4.9926e-03, -9.7487e-02, -1.4482e-01]],

         [[-3.5711e-02, -6.3651e-02, -4.0796e-02],
          [-1.2413e-01,  4.5711e-03,  3.0790e-02],
          [ 1.9801e-02,  8.1162e-02, -1.1088e-02]],

         [[-6.2186e-02,  7.9247e-02, -1.5867e-01],
          [ 1.9341e-01,  3.5185e-01,  1.8004e-01],
          [ 3.5510e-02,  2.7081e-01,  1.9212e-01]]],


        [[[ 3.3125e-01, -6.5124e-02,  2.1093e-01],
          [ 1.6011e-01, -6.3996e-03, -1.6692e-01],
          [-2.0895e-01, -2.6086e-01, -2.4019e-01]],

         [[ 9.8068e-03, -2.5464e-01,  1.5270e-02],
          [-8.2013e-02,  3.7001e-01, -1.9975e-01],
          [ 1.9789e-01,  8.1849e-02,  2.0918e-01]],

         [[-1.8321e-01, -2.1232e-01, -4.2510e-02],
          [-2.0823e-01,  1.5007e-01, -3.9062e-02],
          [ 1.5875e-02,  1.2689e-01,  2.2279e-01]]],


        [[[-1.2785e-07, -6.0667e-07, -1.1712e-06],
          [-4.6798e-07, -9.7520e-07, -2.7163e-06],
          [-2.0242e-06, -1.2092e-06, -2.1837e-06]],

         [[ 1.8590e-07,  2.0837e-07, -4.3364e-08],
          [ 1.6030e-08, -1.3356e-08, -1.1943e-07],
          [-6.6797e-07, -2.0852e-07, -3.3863e-07]],

         [[ 4.0970e-07,  2.1746e-07,  4.6246e-08],
          [ 1.3933e-07,  2.8511e-08, -6.7885e-08],
          [-6.1222e-07, -2.1791e-07, -5.6509e-07]]],


        ...,


        [[[ 2.2200e-02, -6.0145e-03, -6.4533e-02],
          [ 4.3078e-02,  4.9703e-02, -1.0625e-02],
          [-1.6678e-01,  1.2735e-03,  2.9640e-02]],

         [[-1.2416e-01, -1.9771e-01, -1.0755e-03],
          [ 1.1129e-01,  2.3254e-03, -1.1835e-01],
          [ 1.0989e-01, -6.7526e-02, -1.0095e-02]],

         [[ 2.6653e-02,  8.7132e-02,  1.2433e-01],
          [ 3.1122e-01,  3.6719e-01,  1.8230e-01],
          [ 2.7705e-01,  2.2061e-01,  7.8516e-02]]],


        [[[ 2.2102e-01,  4.3041e-02,  6.6314e-02],
          [ 7.0411e-02, -9.4281e-02, -7.8843e-02],
          [-1.5643e-02,  1.0331e-01,  1.4035e-02]],

         [[-1.1754e-01, -3.1241e-01, -6.7853e-02],
          [-7.1745e-02, -3.3752e-01, -2.5444e-01],
          [ 3.1121e-02, -2.9073e-02, -3.6872e-02]],

         [[ 6.1460e-02, -1.9061e-01, -6.4518e-02],
          [-2.6303e-02, -1.2309e-01, -3.7996e-02],
          [-3.2205e-02,  4.7321e-02,  1.4283e-01]]],


        [[[ 2.5200e-02, -2.1302e-01, -5.2914e-02],
          [-1.5348e-01, -4.6319e-01, -2.6293e-01],
          [ 1.4835e-01, -6.6620e-02, -7.0308e-02]],

         [[ 1.6412e-01, -2.2048e-01, -2.9469e-03],
          [ 7.2065e-02, -1.8389e-01,  4.6101e-02],
          [ 2.0716e-01,  2.1758e-01,  2.0125e-02]],

         [[ 5.9004e-02, -2.1460e-01,  7.8397e-02],
          [ 1.2199e-01, -4.9539e-02,  4.7428e-02],
          [-8.3941e-02, -1.8039e-03,  7.7972e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0040, -0.0034, -0.0035],
          [-0.0042, -0.0034, -0.0045],
          [-0.0047, -0.0036, -0.0048]],

         [[-0.0032, -0.0028, -0.0030],
          [-0.0031, -0.0025, -0.0038],
          [-0.0038, -0.0029, -0.0043]],

         [[-0.0028, -0.0024, -0.0026],
          [-0.0024, -0.0019, -0.0033],
          [-0.0026, -0.0018, -0.0034]]],


        [[[-0.0766, -0.0634, -0.0470],
          [-0.0069, -0.0333, -0.0287],
          [ 0.0195,  0.0103, -0.0304]],

         [[-0.0488, -0.0413, -0.0226],
          [ 0.0237, -0.0085, -0.0083],
          [ 0.0518,  0.0342, -0.0131]],

         [[-0.0162, -0.0184, -0.0057],
          [ 0.0346,  0.0068,  0.0033],
          [ 0.0563,  0.0472,  0.0103]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0142, -0.0154, -0.0156],
          [-0.0184, -0.0189, -0.0211],
          [-0.0173, -0.0187, -0.0224]],

         [[-0.0100, -0.0120, -0.0125],
          [-0.0132, -0.0133, -0.0151],
          [-0.0122, -0.0123, -0.0151]],

         [[-0.0004, -0.0024, -0.0043],
          [-0.0017, -0.0029, -0.0065],
          [-0.0016, -0.0032, -0.0070]]],


        [[[ 0.0002,  0.0010,  0.0022],
          [-0.0037, -0.0031, -0.0017],
          [-0.0062, -0.0062, -0.0037]],

         [[-0.0053,  0.0004,  0.0043],
          [-0.0068, -0.0010,  0.0026],
          [-0.0068, -0.0030,  0.0008]],

         [[-0.0041, -0.0005,  0.0036],
          [-0.0042, -0.0004,  0.0028],
          [-0.0036, -0.0014,  0.0020]]],


        [[[ 0.0225,  0.0108,  0.0192],
          [ 0.0157,  0.0047,  0.0128],
          [ 0.0155,  0.0092,  0.0108]],

         [[ 0.0196,  0.0110,  0.0207],
          [ 0.0161,  0.0065,  0.0154],
          [ 0.0162,  0.0099,  0.0130]],

         [[ 0.0120,  0.0033,  0.0133],
          [ 0.0137,  0.0036,  0.0115],
          [ 0.0163,  0.0084,  0.0102]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2392]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 81 | Batch_idx: 0 |  Loss: (0.2348) | Acc: (91.00%) (117/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2933) | Acc: (89.00%) (1264/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2889) | Acc: (89.00%) (2410/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2816) | Acc: (90.00%) (3576/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2871) | Acc: (90.00%) (4729/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2837) | Acc: (90.00%) (5886/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2851) | Acc: (90.00%) (7036/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2843) | Acc: (90.00%) (8193/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2898) | Acc: (90.00%) (9337/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2911) | Acc: (90.00%) (10485/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2876) | Acc: (90.00%) (11653/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2883) | Acc: (90.00%) (12795/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2880) | Acc: (90.00%) (13949/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2862) | Acc: (90.00%) (15115/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2870) | Acc: (90.00%) (16260/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2857) | Acc: (90.00%) (17417/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2849) | Acc: (90.00%) (18567/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2877) | Acc: (90.00%) (19706/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2882) | Acc: (90.00%) (20859/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2879) | Acc: (90.00%) (22026/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2883) | Acc: (90.00%) (23175/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2875) | Acc: (90.00%) (24335/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2871) | Acc: (90.00%) (25491/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2868) | Acc: (90.00%) (26651/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2861) | Acc: (90.00%) (27812/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2856) | Acc: (90.00%) (28975/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2839) | Acc: (90.00%) (30151/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2835) | Acc: (90.00%) (31307/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2828) | Acc: (90.00%) (32467/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2834) | Acc: (90.00%) (33611/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2836) | Acc: (90.00%) (34764/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2825) | Acc: (90.00%) (35930/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2816) | Acc: (90.00%) (37096/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2809) | Acc: (90.00%) (38263/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2799) | Acc: (90.00%) (39436/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2795) | Acc: (90.00%) (40602/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2789) | Acc: (90.00%) (41775/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2789) | Acc: (90.00%) (42942/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2794) | Acc: (90.00%) (44102/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2791) | Acc: (90.00%) (45230/50000)
# TEST : Loss: (0.3693) | Acc: (88.00%) (8805/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0893e-01, -1.1108e-01, -7.8209e-02],
          [-2.8076e-02, -5.3011e-02,  2.5525e-02],
          [ 7.0638e-03, -9.3321e-02, -1.3686e-01]],

         [[-5.6583e-02, -8.3016e-02, -5.6861e-02],
          [-1.3879e-01, -8.4987e-03,  2.1539e-02],
          [ 1.1839e-02,  7.5275e-02, -1.3789e-02]],

         [[-8.3623e-02,  5.8493e-02, -1.7062e-01],
          [ 1.7334e-01,  3.3500e-01,  1.7203e-01],
          [ 2.5688e-02,  2.6233e-01,  1.8899e-01]]],


        [[[ 3.3338e-01, -6.1263e-02,  2.1204e-01],
          [ 1.6145e-01, -2.7824e-03, -1.6799e-01],
          [-2.0981e-01, -2.5789e-01, -2.4520e-01]],

         [[ 8.7058e-03, -2.5802e-01,  6.9703e-03],
          [-8.2105e-02,  3.7431e-01, -2.0376e-01],
          [ 2.0112e-01,  9.1091e-02,  2.0704e-01]],

         [[-1.7972e-01, -2.1675e-01, -4.8752e-02],
          [-2.0536e-01,  1.5153e-01, -4.1185e-02],
          [ 2.4131e-02,  1.3605e-01,  2.2321e-01]]],


        [[[-8.7040e-09, -4.9925e-08, -9.0405e-08],
          [-2.9762e-08, -6.9966e-08, -2.3821e-07],
          [-1.5671e-07, -7.8548e-08, -1.6718e-07]],

         [[ 1.0973e-08,  1.2348e-08, -2.0920e-09],
          [ 8.4613e-10, -5.3428e-10, -5.2743e-09],
          [-4.6503e-08, -9.8952e-09, -1.7301e-08]],

         [[ 2.2858e-08,  9.6506e-09,  1.7245e-09],
          [ 8.0075e-09,  1.1288e-09, -3.1449e-09],
          [-4.6441e-08, -1.1564e-08, -3.6480e-08]]],


        ...,


        [[[ 4.0137e-02,  6.9045e-03, -5.1076e-02],
          [ 4.5813e-02,  4.9255e-02, -5.7272e-03],
          [-1.6126e-01,  7.0727e-03,  4.1709e-02]],

         [[-1.0157e-01, -1.8102e-01,  1.2952e-02],
          [ 1.1883e-01,  5.2908e-03, -1.1133e-01],
          [ 1.2111e-01, -5.6627e-02,  3.8639e-03]],

         [[ 4.9386e-02,  1.0614e-01,  1.4470e-01],
          [ 3.1898e-01,  3.6807e-01,  1.9483e-01],
          [ 2.8639e-01,  2.3009e-01,  9.4629e-02]]],


        [[[ 2.4621e-01,  5.6624e-02,  7.0701e-02],
          [ 9.4010e-02, -7.8254e-02, -7.5332e-02],
          [ 3.5997e-03,  1.2584e-01,  2.5874e-02]],

         [[-9.0149e-02, -2.9197e-01, -7.0914e-02],
          [-4.5940e-02, -3.1687e-01, -2.6626e-01],
          [ 4.7266e-02, -1.0574e-02, -3.8457e-02]],

         [[ 8.0253e-02, -1.7361e-01, -6.5841e-02],
          [-9.3168e-03, -1.0538e-01, -4.7557e-02],
          [-2.1244e-02,  6.4221e-02,  1.4235e-01]]],


        [[[ 2.2772e-02, -2.0766e-01, -4.2437e-02],
          [-1.6916e-01, -4.7840e-01, -2.6936e-01],
          [ 1.4474e-01, -7.1827e-02, -7.3029e-02]],

         [[ 1.6170e-01, -2.2120e-01,  3.3308e-04],
          [ 6.0367e-02, -1.9423e-01,  4.1150e-02],
          [ 2.0473e-01,  2.1006e-01,  1.5916e-02]],

         [[ 6.7827e-02, -1.9979e-01,  1.0219e-01],
          [ 1.2495e-01, -3.9037e-02,  7.1015e-02],
          [-7.5089e-02,  5.4157e-03,  9.3774e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0020,  0.0019,  0.0016],
          [ 0.0006,  0.0011,  0.0013],
          [ 0.0000,  0.0003,  0.0012]],

         [[ 0.0021,  0.0017,  0.0010],
          [ 0.0011,  0.0010,  0.0008],
          [ 0.0006,  0.0004,  0.0009]],

         [[ 0.0026,  0.0022,  0.0013],
          [ 0.0019,  0.0016,  0.0010],
          [ 0.0018,  0.0011,  0.0010]]],


        [[[ 0.0373,  0.0179, -0.0008],
          [ 0.0094, -0.0037, -0.0149],
          [ 0.0524,  0.0189,  0.0218]],

         [[ 0.0550,  0.0332,  0.0078],
          [ 0.0244,  0.0111, -0.0047],
          [ 0.0564,  0.0310,  0.0344]],

         [[ 0.0557,  0.0372,  0.0191],
          [ 0.0278,  0.0171, -0.0008],
          [ 0.0595,  0.0305,  0.0277]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0069,  0.0066,  0.0065],
          [ 0.0073,  0.0052,  0.0052],
          [ 0.0061,  0.0020,  0.0012]],

         [[ 0.0065,  0.0070,  0.0074],
          [ 0.0068,  0.0053,  0.0057],
          [ 0.0056,  0.0018,  0.0012]],

         [[ 0.0022,  0.0020,  0.0027],
          [ 0.0025,  0.0001,  0.0005],
          [ 0.0023, -0.0024, -0.0034]]],


        [[[ 0.0005, -0.0022,  0.0010],
          [ 0.0044,  0.0011,  0.0024],
          [ 0.0060,  0.0013,  0.0041]],

         [[ 0.0006, -0.0019,  0.0005],
          [ 0.0042,  0.0015,  0.0026],
          [ 0.0051,  0.0005,  0.0028]],

         [[-0.0012, -0.0025, -0.0007],
          [ 0.0022,  0.0006,  0.0018],
          [ 0.0024, -0.0011,  0.0012]]],


        [[[ 0.0061, -0.0010, -0.0012],
          [-0.0010, -0.0033,  0.0013],
          [-0.0073, -0.0077, -0.0035]],

         [[ 0.0065, -0.0005, -0.0013],
          [-0.0010, -0.0021,  0.0013],
          [-0.0077, -0.0072, -0.0037]],

         [[ 0.0050, -0.0006, -0.0012],
          [-0.0055, -0.0046, -0.0000],
          [-0.0148, -0.0132, -0.0086]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2386]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 82 | Batch_idx: 0 |  Loss: (0.3324) | Acc: (86.00%) (111/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2344) | Acc: (92.00%) (1302/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2360) | Acc: (92.00%) (2479/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2381) | Acc: (92.00%) (3666/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2326) | Acc: (92.00%) (4842/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2351) | Acc: (92.00%) (6014/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2379) | Acc: (91.00%) (7182/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2367) | Acc: (91.00%) (8360/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2350) | Acc: (92.00%) (9542/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2371) | Acc: (91.00%) (10708/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2375) | Acc: (91.00%) (11893/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2346) | Acc: (92.00%) (13080/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2362) | Acc: (91.00%) (14242/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2381) | Acc: (91.00%) (15415/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2404) | Acc: (91.00%) (16582/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2418) | Acc: (91.00%) (17746/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2425) | Acc: (91.00%) (18913/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2421) | Acc: (91.00%) (20093/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2433) | Acc: (91.00%) (21273/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2427) | Acc: (91.00%) (22455/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2438) | Acc: (91.00%) (23623/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2444) | Acc: (91.00%) (24792/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2460) | Acc: (91.00%) (25950/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2474) | Acc: (91.00%) (27099/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2489) | Acc: (91.00%) (28256/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2493) | Acc: (91.00%) (29427/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2491) | Acc: (91.00%) (30602/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2488) | Acc: (91.00%) (31776/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2476) | Acc: (91.00%) (32958/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2481) | Acc: (91.00%) (34130/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2494) | Acc: (91.00%) (35286/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2513) | Acc: (91.00%) (36435/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2512) | Acc: (91.00%) (37599/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2523) | Acc: (91.00%) (38751/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2511) | Acc: (91.00%) (39937/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2503) | Acc: (91.00%) (41117/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2500) | Acc: (91.00%) (42289/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2494) | Acc: (91.00%) (43471/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2500) | Acc: (91.00%) (44625/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2498) | Acc: (91.00%) (45751/50000)
# TEST : Loss: (0.4194) | Acc: (87.00%) (8709/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0402e-01, -1.0866e-01, -7.7087e-02],
          [-2.0224e-02, -5.0551e-02,  2.8724e-02],
          [ 7.8994e-03, -9.6086e-02, -1.3589e-01]],

         [[-4.8182e-02, -7.3953e-02, -4.8726e-02],
          [-1.2455e-01,  6.6377e-04,  3.1559e-02],
          [ 1.8966e-02,  7.6775e-02, -9.2128e-03]],

         [[-7.7717e-02,  6.4038e-02, -1.6466e-01],
          [ 1.8309e-01,  3.4064e-01,  1.7738e-01],
          [ 3.4508e-02,  2.6247e-01,  1.8890e-01]]],


        [[[ 3.3448e-01, -5.4552e-02,  2.2103e-01],
          [ 1.4977e-01, -4.4750e-03, -1.6963e-01],
          [-2.2092e-01, -2.6686e-01, -2.4860e-01]],

         [[ 1.5460e-02, -2.4695e-01,  1.7241e-02],
          [-8.7423e-02,  3.8243e-01, -1.9986e-01],
          [ 1.9465e-01,  9.0395e-02,  2.0842e-01]],

         [[-1.7750e-01, -2.1194e-01, -4.8030e-02],
          [-2.1422e-01,  1.5749e-01, -3.6920e-02],
          [ 1.7163e-02,  1.3854e-01,  2.2838e-01]]],


        [[[-3.1410e-10, -2.2871e-09, -3.8215e-09],
          [-9.8565e-10, -2.6974e-09, -1.1820e-08],
          [-6.6486e-09, -2.6719e-09, -6.9937e-09]],

         [[ 3.3076e-10,  3.7404e-10, -4.8845e-11],
          [ 2.2142e-11, -9.8341e-12, -1.1009e-10],
          [-1.7261e-09, -2.2627e-10, -4.3445e-10]],

         [[ 6.4159e-10,  2.0269e-10,  2.9025e-11],
          [ 2.3335e-10,  2.0505e-11, -6.9754e-11],
          [-1.9205e-09, -3.0466e-10, -1.2312e-09]]],


        ...,


        [[[ 1.8577e-02, -8.5754e-03, -6.9139e-02],
          [ 2.1772e-02,  3.3069e-02, -2.0819e-02],
          [-1.8032e-01, -5.2458e-03,  3.0678e-02]],

         [[-1.1718e-01, -1.9290e-01, -7.9797e-03],
          [ 9.8793e-02, -8.7471e-03, -1.2820e-01],
          [ 1.0766e-01, -6.2776e-02, -5.0568e-03]],

         [[ 4.9906e-02,  1.0727e-01,  1.3072e-01],
          [ 3.1154e-01,  3.6754e-01,  1.8618e-01],
          [ 2.7547e-01,  2.3378e-01,  9.4846e-02]]],


        [[[ 2.5017e-01,  5.3930e-02,  7.5499e-02],
          [ 9.3858e-02, -8.9553e-02, -7.7433e-02],
          [ 1.1456e-02,  1.1766e-01,  2.1861e-02]],

         [[-8.9592e-02, -2.9773e-01, -5.6632e-02],
          [-4.9765e-02, -3.2784e-01, -2.6072e-01],
          [ 4.7463e-02, -2.1761e-02, -4.7859e-02]],

         [[ 7.5040e-02, -1.8183e-01, -5.6039e-02],
          [-1.2509e-02, -1.0632e-01, -3.2539e-02],
          [-1.8459e-02,  6.3729e-02,  1.4159e-01]]],


        [[[ 2.0046e-02, -2.0290e-01, -4.8784e-02],
          [-1.6986e-01, -4.7968e-01, -2.8085e-01],
          [ 1.5142e-01, -6.7314e-02, -7.4206e-02]],

         [[ 1.5129e-01, -2.2574e-01, -5.9695e-03],
          [ 5.4753e-02, -1.9828e-01,  3.4186e-02],
          [ 2.0746e-01,  2.1231e-01,  1.6756e-02]],

         [[ 5.8001e-02, -2.0467e-01,  9.3971e-02],
          [ 1.2095e-01, -3.9219e-02,  6.8351e-02],
          [-7.0959e-02,  1.2354e-02,  9.8473e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0081, -0.0073, -0.0081],
          [-0.0068, -0.0046, -0.0047],
          [-0.0067, -0.0038, -0.0028]],

         [[-0.0084, -0.0079, -0.0087],
          [-0.0074, -0.0055, -0.0055],
          [-0.0072, -0.0045, -0.0033]],

         [[-0.0082, -0.0076, -0.0083],
          [-0.0074, -0.0056, -0.0055],
          [-0.0074, -0.0049, -0.0036]]],


        [[[ 0.0412,  0.0224,  0.0364],
          [ 0.0508,  0.0026,  0.0139],
          [ 0.0129,  0.0023, -0.0018]],

         [[ 0.0597,  0.0392,  0.0599],
          [ 0.0767,  0.0317,  0.0337],
          [ 0.0361,  0.0247,  0.0120]],

         [[ 0.0602,  0.0503,  0.0782],
          [ 0.0734,  0.0416,  0.0495],
          [ 0.0319,  0.0317,  0.0246]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0166,  0.0055,  0.0011],
          [ 0.0145,  0.0033, -0.0018],
          [ 0.0135,  0.0052,  0.0002]],

         [[ 0.0152,  0.0036, -0.0010],
          [ 0.0116,  0.0001, -0.0047],
          [ 0.0100,  0.0016, -0.0032]],

         [[ 0.0125,  0.0016, -0.0034],
          [ 0.0082, -0.0024, -0.0074],
          [ 0.0065, -0.0015, -0.0062]]],


        [[[-0.0095, -0.0101, -0.0108],
          [-0.0039, -0.0045, -0.0107],
          [-0.0092, -0.0111, -0.0171]],

         [[-0.0058, -0.0055, -0.0057],
          [-0.0022, -0.0018, -0.0075],
          [-0.0084, -0.0096, -0.0147]],

         [[-0.0018, -0.0021, -0.0025],
          [ 0.0003,  0.0002, -0.0047],
          [-0.0045, -0.0050, -0.0093]]],


        [[[-0.0179, -0.0123, -0.0030],
          [-0.0107, -0.0059,  0.0012],
          [-0.0161, -0.0129, -0.0090]],

         [[-0.0114, -0.0068,  0.0015],
          [-0.0073, -0.0035,  0.0030],
          [-0.0150, -0.0118, -0.0077]],

         [[-0.0126, -0.0089, -0.0028],
          [-0.0083, -0.0061, -0.0018],
          [-0.0133, -0.0118, -0.0097]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2380]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 83 | Batch_idx: 0 |  Loss: (0.2079) | Acc: (92.00%) (119/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2140) | Acc: (92.00%) (1305/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2107) | Acc: (92.00%) (2498/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2043) | Acc: (92.00%) (3689/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.1997) | Acc: (93.00%) (4889/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2110) | Acc: (92.00%) (6055/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2106) | Acc: (92.00%) (7241/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2108) | Acc: (92.00%) (8433/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2115) | Acc: (92.00%) (9613/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2141) | Acc: (92.00%) (10802/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2149) | Acc: (92.00%) (11977/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2166) | Acc: (92.00%) (13156/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2183) | Acc: (92.00%) (14337/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2187) | Acc: (92.00%) (15516/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2198) | Acc: (92.00%) (16690/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2208) | Acc: (92.00%) (17877/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2209) | Acc: (92.00%) (19063/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2216) | Acc: (92.00%) (20224/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2207) | Acc: (92.00%) (21415/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2217) | Acc: (92.00%) (22603/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2224) | Acc: (92.00%) (23778/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2241) | Acc: (92.00%) (24934/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2256) | Acc: (92.00%) (26089/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2258) | Acc: (92.00%) (27263/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2254) | Acc: (92.00%) (28450/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2256) | Acc: (92.00%) (29615/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2261) | Acc: (92.00%) (30793/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2258) | Acc: (92.00%) (31980/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2260) | Acc: (92.00%) (33160/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2264) | Acc: (92.00%) (34329/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2256) | Acc: (92.00%) (35515/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2257) | Acc: (92.00%) (36701/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2262) | Acc: (92.00%) (37870/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2258) | Acc: (92.00%) (39056/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2262) | Acc: (92.00%) (40235/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2263) | Acc: (92.00%) (41412/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2270) | Acc: (92.00%) (42587/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2280) | Acc: (92.00%) (43749/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2280) | Acc: (92.00%) (44930/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2286) | Acc: (92.00%) (46052/50000)
# TEST : Loss: (0.3289) | Acc: (89.00%) (8911/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0296e-01, -1.0864e-01, -6.8823e-02],
          [-1.2004e-02, -4.3155e-02,  3.9878e-02],
          [ 2.0313e-02, -9.0342e-02, -1.2803e-01]],

         [[-4.4757e-02, -7.1160e-02, -3.9270e-02],
          [-1.1051e-01,  1.1914e-02,  4.5550e-02],
          [ 3.3583e-02,  8.2640e-02, -2.8277e-03]],

         [[-7.8546e-02,  5.8479e-02, -1.6457e-01],
          [ 1.8948e-01,  3.4283e-01,  1.8282e-01],
          [ 4.6618e-02,  2.6181e-01,  1.8563e-01]]],


        [[[ 3.4084e-01, -5.1458e-02,  2.2133e-01],
          [ 1.5441e-01, -1.3053e-04, -1.6824e-01],
          [-2.1481e-01, -2.6814e-01, -2.5348e-01]],

         [[ 1.6259e-02, -2.4873e-01,  1.3836e-02],
          [-8.5555e-02,  3.8660e-01, -1.9878e-01],
          [ 2.0309e-01,  9.3019e-02,  2.0792e-01]],

         [[-1.7402e-01, -2.0821e-01, -4.2155e-02],
          [-2.0914e-01,  1.6310e-01, -3.0631e-02],
          [ 2.8260e-02,  1.4449e-01,  2.2819e-01]]],


        [[[-5.0706e-12, -5.0014e-11, -7.5450e-11],
          [-1.4260e-11, -4.7371e-11, -2.8602e-10],
          [-1.3188e-10, -4.0000e-11, -1.3627e-10]],

         [[ 4.2431e-12,  4.8285e-12, -4.5155e-13],
          [ 2.3697e-13, -6.6897e-14, -8.8098e-13],
          [-2.8883e-11, -2.0363e-12, -4.4098e-12]],

         [[ 7.5125e-12,  1.6349e-12,  1.7587e-13],
          [ 2.8667e-12,  1.3714e-13, -6.0359e-13],
          [-3.6874e-11, -3.2891e-12, -1.8247e-11]]],


        ...,


        [[[ 3.0536e-02,  3.3232e-03, -6.2079e-02],
          [ 2.1503e-02,  3.4013e-02, -2.0062e-02],
          [-1.7876e-01, -7.3158e-03,  3.0761e-02]],

         [[-1.0335e-01, -1.7798e-01, -3.6747e-04],
          [ 9.8761e-02, -5.7309e-03, -1.2487e-01],
          [ 1.0987e-01, -6.2155e-02, -1.7408e-03]],

         [[ 6.9219e-02,  1.2909e-01,  1.4014e-01],
          [ 3.1325e-01,  3.7483e-01,  1.8937e-01],
          [ 2.8447e-01,  2.3768e-01,  9.9809e-02]]],


        [[[ 2.5492e-01,  5.3060e-02,  8.6400e-02],
          [ 9.3235e-02, -9.2345e-02, -7.5806e-02],
          [ 1.6656e-02,  1.2187e-01,  2.7425e-02]],

         [[-8.0334e-02, -2.9734e-01, -4.0691e-02],
          [-4.8124e-02, -3.2944e-01, -2.5557e-01],
          [ 5.4850e-02, -1.4997e-02, -3.9554e-02]],

         [[ 8.1538e-02, -1.9284e-01, -5.5045e-02],
          [-6.3963e-03, -1.0781e-01, -3.3118e-02],
          [-5.1359e-03,  7.2032e-02,  1.4586e-01]]],


        [[[ 2.4559e-02, -1.9554e-01, -3.1975e-02],
          [-1.7317e-01, -4.8894e-01, -2.7401e-01],
          [ 1.5025e-01, -6.8619e-02, -7.1576e-02]],

         [[ 1.5822e-01, -2.1657e-01,  1.4458e-02],
          [ 5.6189e-02, -1.9625e-01,  5.0939e-02],
          [ 2.0922e-01,  2.1579e-01,  2.8537e-02]],

         [[ 6.6431e-02, -2.0155e-01,  1.0094e-01],
          [ 1.2429e-01, -4.2027e-02,  7.3276e-02],
          [-6.8641e-02,  1.1930e-02,  1.0135e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0012, -0.0007,  0.0002],
          [-0.0025, -0.0020, -0.0010],
          [-0.0030, -0.0024, -0.0015]],

         [[-0.0013, -0.0009, -0.0002],
          [-0.0024, -0.0019, -0.0010],
          [-0.0028, -0.0022, -0.0012]],

         [[-0.0005, -0.0002,  0.0003],
          [-0.0010, -0.0006, -0.0000],
          [-0.0014, -0.0008, -0.0001]]],


        [[[ 0.0019, -0.0189, -0.0378],
          [-0.0041, -0.0399, -0.0458],
          [-0.0112, -0.0413, -0.0515]],

         [[-0.0057, -0.0280, -0.0501],
          [-0.0103, -0.0470, -0.0543],
          [-0.0172, -0.0443, -0.0574]],

         [[-0.0054, -0.0270, -0.0425],
          [-0.0023, -0.0334, -0.0415],
          [-0.0000, -0.0258, -0.0362]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0066, -0.0019, -0.0004],
          [-0.0026,  0.0018,  0.0008],
          [-0.0034,  0.0001, -0.0026]],

         [[-0.0059, -0.0016, -0.0004],
          [-0.0015,  0.0026,  0.0016],
          [-0.0023,  0.0010, -0.0015]],

         [[-0.0052, -0.0017, -0.0008],
          [-0.0010,  0.0025,  0.0013],
          [-0.0024,  0.0004, -0.0017]]],


        [[[ 0.0011,  0.0051,  0.0036],
          [-0.0002,  0.0025,  0.0021],
          [-0.0012,  0.0016,  0.0015]],

         [[-0.0012,  0.0021,  0.0000],
          [-0.0031, -0.0005, -0.0018],
          [-0.0046, -0.0019, -0.0031]],

         [[-0.0011,  0.0021, -0.0006],
          [-0.0020,  0.0008, -0.0017],
          [-0.0023, -0.0000, -0.0023]]],


        [[[ 0.0065,  0.0044,  0.0032],
          [ 0.0031, -0.0001, -0.0015],
          [ 0.0013, -0.0006, -0.0017]],

         [[ 0.0081,  0.0062,  0.0056],
          [ 0.0037,  0.0016,  0.0008],
          [ 0.0015,  0.0009,  0.0000]],

         [[ 0.0097,  0.0082,  0.0056],
          [ 0.0053,  0.0039,  0.0023],
          [ 0.0023,  0.0015, -0.0003]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2373]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 84 | Batch_idx: 0 |  Loss: (0.2954) | Acc: (88.00%) (113/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2256) | Acc: (92.00%) (1296/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2185) | Acc: (92.00%) (2481/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2160) | Acc: (92.00%) (3677/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2100) | Acc: (92.00%) (4875/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2053) | Acc: (93.00%) (6079/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2003) | Acc: (93.00%) (7285/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2054) | Acc: (93.00%) (8458/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2037) | Acc: (93.00%) (9646/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2038) | Acc: (93.00%) (10834/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2050) | Acc: (92.00%) (12015/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2026) | Acc: (93.00%) (13217/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2038) | Acc: (92.00%) (14397/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2054) | Acc: (92.00%) (15583/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2053) | Acc: (92.00%) (16773/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2073) | Acc: (92.00%) (17944/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2078) | Acc: (92.00%) (19137/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2091) | Acc: (92.00%) (20316/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2104) | Acc: (92.00%) (21499/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2106) | Acc: (92.00%) (22688/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2115) | Acc: (92.00%) (23878/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2101) | Acc: (92.00%) (25084/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2099) | Acc: (92.00%) (26260/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2091) | Acc: (92.00%) (27462/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2088) | Acc: (92.00%) (28648/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2089) | Acc: (92.00%) (29844/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2091) | Acc: (92.00%) (31037/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2094) | Acc: (92.00%) (32231/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2095) | Acc: (92.00%) (33412/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2107) | Acc: (92.00%) (34576/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2104) | Acc: (92.00%) (35769/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2106) | Acc: (92.00%) (36955/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2107) | Acc: (92.00%) (38134/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2112) | Acc: (92.00%) (39310/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2106) | Acc: (92.00%) (40512/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2123) | Acc: (92.00%) (41684/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2123) | Acc: (92.00%) (42871/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2133) | Acc: (92.00%) (44040/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2144) | Acc: (92.00%) (45202/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2146) | Acc: (92.00%) (46346/50000)
# TEST : Loss: (0.3950) | Acc: (88.00%) (8818/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1369e-01, -1.1975e-01, -8.3598e-02],
          [-2.7019e-02, -5.2317e-02,  3.1928e-02],
          [-1.5542e-03, -1.0391e-01, -1.3463e-01]],

         [[-6.0035e-02, -8.3689e-02, -5.4116e-02],
          [-1.2755e-01,  2.0981e-03,  3.9433e-02],
          [ 4.9590e-03,  6.4207e-02, -1.2663e-02]],

         [[-8.9450e-02,  4.8489e-02, -1.7363e-01],
          [ 1.6789e-01,  3.3080e-01,  1.7840e-01],
          [ 1.3048e-02,  2.3863e-01,  1.7270e-01]]],


        [[[ 3.4815e-01, -5.4037e-02,  2.1161e-01],
          [ 1.5457e-01, -1.9715e-03, -1.7011e-01],
          [-2.1725e-01, -2.7317e-01, -2.4791e-01]],

         [[ 1.3807e-02, -2.5599e-01,  8.8177e-04],
          [-8.9940e-02,  3.8372e-01, -2.0154e-01],
          [ 1.9748e-01,  9.0949e-02,  2.1512e-01]],

         [[-1.7702e-01, -2.1417e-01, -5.0849e-02],
          [-2.1411e-01,  1.5873e-01, -3.4123e-02],
          [ 2.0351e-02,  1.4095e-01,  2.3204e-01]]],


        [[[-2.9105e-14, -4.2494e-13, -5.6194e-13],
          [-7.0998e-14, -3.0324e-13, -2.7683e-12],
          [-9.8815e-13, -2.0820e-13, -9.9772e-13]],

         [[ 1.8063e-14,  2.0724e-14, -1.2518e-15],
          [ 7.9613e-16, -1.2371e-16, -2.0196e-15],
          [-1.7368e-13, -5.4495e-15, -1.3822e-14]],

         [[ 2.8389e-14,  3.7872e-15,  2.7889e-16],
          [ 1.1535e-14,  2.4795e-16, -1.5340e-15],
          [-2.6491e-13, -1.1177e-14, -9.3739e-14]]],


        ...,


        [[[ 4.0666e-02,  1.5187e-02, -6.3017e-02],
          [ 2.9039e-02,  4.3859e-02, -2.4999e-02],
          [-1.8240e-01, -1.1327e-02,  2.0143e-02]],

         [[-1.0208e-01, -1.7368e-01, -1.2292e-02],
          [ 9.8520e-02, -1.4696e-03, -1.3981e-01],
          [ 9.3597e-02, -7.6050e-02, -2.4120e-02]],

         [[ 7.1584e-02,  1.3791e-01,  1.2925e-01],
          [ 3.1580e-01,  3.9727e-01,  1.7825e-01],
          [ 2.5810e-01,  2.2509e-01,  7.9755e-02]]],


        [[[ 2.5353e-01,  4.7632e-02,  8.0540e-02],
          [ 9.8454e-02, -9.1441e-02, -7.4429e-02],
          [ 1.6260e-02,  1.1437e-01,  2.4846e-02]],

         [[-8.7109e-02, -3.0688e-01, -5.1060e-02],
          [-5.4581e-02, -3.4023e-01, -2.6665e-01],
          [ 3.8282e-02, -3.9972e-02, -5.9987e-02]],

         [[ 7.6953e-02, -1.9173e-01, -4.8913e-02],
          [-7.2726e-03, -1.0108e-01, -2.1612e-02],
          [-1.5304e-02,  6.0549e-02,  1.4036e-01]]],


        [[[ 2.9966e-02, -2.0326e-01, -2.7664e-02],
          [-1.7083e-01, -4.9988e-01, -2.7211e-01],
          [ 1.4991e-01, -7.3418e-02, -6.5277e-02]],

         [[ 1.5299e-01, -2.3320e-01,  6.7911e-03],
          [ 4.9524e-02, -2.1361e-01,  4.3163e-02],
          [ 2.0470e-01,  2.0529e-01,  2.6503e-02]],

         [[ 6.1360e-02, -2.1632e-01,  9.3527e-02],
          [ 1.1964e-01, -5.5993e-02,  6.6412e-02],
          [-7.1047e-02,  2.4595e-03,  9.7245e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0010,  0.0020,  0.0007],
          [ 0.0017,  0.0034,  0.0016],
          [ 0.0012,  0.0031,  0.0013]],

         [[ 0.0007,  0.0011, -0.0005],
          [ 0.0015,  0.0030,  0.0012],
          [-0.0000,  0.0020,  0.0005]],

         [[-0.0001, -0.0006, -0.0022],
          [ 0.0013,  0.0019,  0.0004],
          [-0.0010,  0.0003, -0.0007]]],


        [[[-0.0311, -0.0926, -0.1065],
          [-0.0469, -0.0688, -0.0521],
          [-0.0203, -0.0135, -0.0226]],

         [[-0.0110, -0.0859, -0.1034],
          [-0.0459, -0.0726, -0.0478],
          [-0.0280, -0.0105, -0.0124]],

         [[ 0.0022, -0.0614, -0.0863],
          [-0.0261, -0.0541, -0.0326],
          [-0.0064, -0.0047, -0.0014]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0070,  0.0129,  0.0133],
          [ 0.0006,  0.0083,  0.0103],
          [ 0.0020,  0.0077,  0.0102]],

         [[ 0.0038,  0.0108,  0.0126],
          [-0.0013,  0.0076,  0.0107],
          [ 0.0006,  0.0076,  0.0111]],

         [[-0.0007,  0.0064,  0.0089],
          [-0.0048,  0.0042,  0.0084],
          [-0.0015,  0.0059,  0.0100]]],


        [[[ 0.0039,  0.0080,  0.0069],
          [ 0.0056,  0.0073,  0.0094],
          [ 0.0076,  0.0071,  0.0096]],

         [[ 0.0013,  0.0024, -0.0013],
          [ 0.0008,  0.0014,  0.0025],
          [ 0.0036,  0.0025,  0.0042]],

         [[-0.0010, -0.0002, -0.0049],
          [-0.0003, -0.0011, -0.0034],
          [ 0.0023, -0.0012, -0.0025]]],


        [[[-0.0053,  0.0010,  0.0042],
          [-0.0053,  0.0013,  0.0011],
          [-0.0109, -0.0055, -0.0049]],

         [[ 0.0141,  0.0212,  0.0254],
          [ 0.0150,  0.0213,  0.0211],
          [ 0.0075,  0.0123,  0.0140]],

         [[ 0.0220,  0.0247,  0.0267],
          [ 0.0212,  0.0248,  0.0250],
          [ 0.0089,  0.0127,  0.0180]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2363]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 85 | Batch_idx: 0 |  Loss: (0.1648) | Acc: (95.00%) (122/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2630) | Acc: (90.00%) (1275/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2879) | Acc: (89.00%) (2409/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2887) | Acc: (89.00%) (3556/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2757) | Acc: (90.00%) (4728/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2727) | Acc: (90.00%) (5894/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2688) | Acc: (90.00%) (7054/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2668) | Acc: (90.00%) (8225/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2605) | Acc: (90.00%) (9409/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2550) | Acc: (90.00%) (10592/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2558) | Acc: (90.00%) (11749/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2521) | Acc: (91.00%) (12932/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2511) | Acc: (91.00%) (14115/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2477) | Acc: (91.00%) (15305/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2467) | Acc: (91.00%) (16486/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2447) | Acc: (91.00%) (17664/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2421) | Acc: (91.00%) (18855/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2393) | Acc: (91.00%) (20053/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2370) | Acc: (91.00%) (21249/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2348) | Acc: (91.00%) (22435/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2337) | Acc: (91.00%) (23619/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2333) | Acc: (91.00%) (24798/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2329) | Acc: (91.00%) (25979/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2307) | Acc: (91.00%) (27183/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2301) | Acc: (91.00%) (28369/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2283) | Acc: (92.00%) (29569/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2272) | Acc: (92.00%) (30758/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2258) | Acc: (92.00%) (31959/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2248) | Acc: (92.00%) (33153/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2236) | Acc: (92.00%) (34346/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2223) | Acc: (92.00%) (35549/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2208) | Acc: (92.00%) (36754/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2202) | Acc: (92.00%) (37945/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2191) | Acc: (92.00%) (39151/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2186) | Acc: (92.00%) (40350/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2171) | Acc: (92.00%) (41552/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2165) | Acc: (92.00%) (42743/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2166) | Acc: (92.00%) (43931/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2162) | Acc: (92.00%) (45122/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2152) | Acc: (92.00%) (46272/50000)
# TEST : Loss: (0.3120) | Acc: (90.00%) (9020/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1165e-01, -1.1868e-01, -8.3205e-02],
          [-2.7174e-02, -5.2934e-02,  3.0402e-02],
          [-2.7566e-03, -1.0399e-01, -1.3308e-01]],

         [[-5.8825e-02, -8.2928e-02, -5.3634e-02],
          [-1.2581e-01,  5.7289e-04,  3.7961e-02],
          [ 4.0086e-03,  6.1451e-02, -1.2722e-02]],

         [[-8.7180e-02,  4.8098e-02, -1.6954e-01],
          [ 1.6392e-01,  3.2269e-01,  1.7459e-01],
          [ 1.2324e-02,  2.3239e-01,  1.6946e-01]]],


        [[[ 3.4804e-01, -5.2323e-02,  2.1357e-01],
          [ 1.5508e-01, -4.6075e-04, -1.6841e-01],
          [-2.1614e-01, -2.7137e-01, -2.4583e-01]],

         [[ 1.5024e-02, -2.5304e-01,  4.0269e-03],
          [-8.7692e-02,  3.8660e-01, -1.9850e-01],
          [ 1.9992e-01,  9.4180e-02,  2.1816e-01]],

         [[-1.7478e-01, -2.1047e-01, -4.7473e-02],
          [-2.1179e-01,  1.6157e-01, -3.1651e-02],
          [ 2.2496e-02,  1.4392e-01,  2.3475e-01]]],


        [[[-4.2945e-17, -1.0543e-15, -1.1716e-15],
          [-8.6640e-17, -5.1733e-16, -8.1519e-15],
          [-2.0767e-15, -2.6961e-16, -2.0338e-15]],

         [[ 1.7866e-17,  2.0727e-17, -6.9272e-19],
          [ 5.7208e-19, -3.9237e-20, -8.6148e-19],
          [-2.7266e-16, -2.8737e-18, -9.0397e-18]],

         [[ 2.3917e-17,  1.6390e-18,  7.1443e-20],
          [ 1.0575e-17,  7.6226e-20, -7.5374e-19],
          [-5.2662e-16, -8.1560e-18, -1.1929e-16]]],


        ...,


        [[[ 4.3909e-02,  1.8086e-02, -5.9391e-02],
          [ 3.2943e-02,  4.6611e-02, -2.2305e-02],
          [-1.7778e-01, -8.7455e-03,  2.2225e-02]],

         [[-9.8550e-02, -1.7039e-01, -1.0130e-02],
          [ 1.0158e-01,  8.3025e-04, -1.3724e-01],
          [ 9.6179e-02, -7.3599e-02, -2.2510e-02]],

         [[ 7.3182e-02,  1.3728e-01,  1.2879e-01],
          [ 3.1458e-01,  3.8983e-01,  1.7471e-01],
          [ 2.5665e-01,  2.2056e-01,  7.7656e-02]]],


        [[[ 2.5124e-01,  4.6055e-02,  7.9278e-02],
          [ 9.7485e-02, -9.0874e-02, -7.4168e-02],
          [ 1.6609e-02,  1.1447e-01,  2.4777e-02]],

         [[-8.7460e-02, -3.0497e-01, -5.0576e-02],
          [-5.4863e-02, -3.3629e-01, -2.6390e-01],
          [ 3.8339e-02, -3.9096e-02, -5.9942e-02]],

         [[ 7.4965e-02, -1.9138e-01, -4.8542e-02],
          [-8.8240e-03, -1.0066e-01, -2.1502e-02],
          [-1.5645e-02,  6.0210e-02,  1.3883e-01]]],


        [[[ 3.2727e-02, -2.0065e-01, -2.6223e-02],
          [-1.6721e-01, -4.9510e-01, -2.6883e-01],
          [ 1.5199e-01, -7.2824e-02, -6.4681e-02]],

         [[ 1.5421e-01, -2.3246e-01,  6.3021e-03],
          [ 5.1015e-02, -2.1296e-01,  4.2827e-02],
          [ 2.0619e-01,  2.0439e-01,  2.5980e-02]],

         [[ 6.1216e-02, -2.1675e-01,  9.2173e-02],
          [ 1.1937e-01, -5.7092e-02,  6.5157e-02],
          [-6.9705e-02,  1.5803e-03,  9.5663e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2278]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0262]], device='cuda:0')

Epoch: 86 | Batch_idx: 0 |  Loss: (0.1666) | Acc: (94.00%) (121/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2106) | Acc: (92.00%) (1307/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.1957) | Acc: (93.00%) (2514/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.1967) | Acc: (93.00%) (3699/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.1932) | Acc: (93.00%) (4901/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.1928) | Acc: (93.00%) (6091/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.1899) | Acc: (93.00%) (7297/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.1887) | Acc: (93.00%) (8506/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.1907) | Acc: (93.00%) (9698/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.1885) | Acc: (93.00%) (10907/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.1904) | Acc: (93.00%) (12090/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.1889) | Acc: (93.00%) (13296/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.1913) | Acc: (93.00%) (14475/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.1904) | Acc: (93.00%) (15672/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.1889) | Acc: (93.00%) (16889/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.1879) | Acc: (93.00%) (18094/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.1869) | Acc: (93.00%) (19297/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.1868) | Acc: (93.00%) (20501/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.1868) | Acc: (93.00%) (21698/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.1873) | Acc: (93.00%) (22899/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.1867) | Acc: (93.00%) (24103/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.1878) | Acc: (93.00%) (25286/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.1870) | Acc: (93.00%) (26495/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.1872) | Acc: (93.00%) (27690/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.1868) | Acc: (93.00%) (28893/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.1859) | Acc: (93.00%) (30108/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.1857) | Acc: (93.00%) (31314/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.1854) | Acc: (93.00%) (32515/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.1855) | Acc: (93.00%) (33707/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.1857) | Acc: (93.00%) (34905/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.1863) | Acc: (93.00%) (36091/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.1861) | Acc: (93.00%) (37302/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.1866) | Acc: (93.00%) (38489/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.1869) | Acc: (93.00%) (39690/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.1866) | Acc: (93.00%) (40892/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.1863) | Acc: (93.00%) (42091/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.1866) | Acc: (93.00%) (43284/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.1861) | Acc: (93.00%) (44487/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.1866) | Acc: (93.00%) (45675/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.1863) | Acc: (93.00%) (46836/50000)
# TEST : Loss: (0.2976) | Acc: (90.00%) (9051/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0929e-01, -1.1621e-01, -8.1466e-02],
          [-2.6626e-02, -5.1898e-02,  2.9797e-02],
          [-2.7017e-03, -1.0199e-01, -1.3048e-01]],

         [[-5.7577e-02, -8.1161e-02, -5.2495e-02],
          [-1.2305e-01,  5.6018e-04,  3.7110e-02],
          [ 3.9190e-03,  6.0083e-02, -1.2436e-02]],

         [[-8.5280e-02,  4.7031e-02, -1.6581e-01],
          [ 1.5980e-01,  3.1411e-01,  1.6999e-01],
          [ 1.1998e-02,  2.2594e-01,  1.6482e-01]]],


        [[[ 3.4762e-01, -5.2261e-02,  2.1332e-01],
          [ 1.5489e-01, -4.6019e-04, -1.6821e-01],
          [-2.1588e-01, -2.7105e-01, -2.4555e-01]],

         [[ 1.5006e-02, -2.5274e-01,  4.0222e-03],
          [-8.7583e-02,  3.8611e-01, -1.9825e-01],
          [ 1.9967e-01,  9.4063e-02,  2.1790e-01]],

         [[-1.7455e-01, -2.1019e-01, -4.7412e-02],
          [-2.1151e-01,  1.6135e-01, -3.1610e-02],
          [ 2.2467e-02,  1.4373e-01,  2.3445e-01]]],


        [[[-9.9483e-21, -5.0123e-19, -4.3863e-19],
          [-1.5372e-20, -1.4671e-19, -4.8975e-18],
          [-7.8604e-19, -5.2007e-20, -7.3805e-19]],

         [[ 2.3537e-21,  2.7738e-21, -3.9404e-23],
          [ 4.7634e-23, -9.7091e-25, -3.3330e-23],
          [-6.8870e-20, -1.5227e-22, -6.5653e-22]],

         [[ 2.5046e-21,  6.4788e-23,  1.2733e-24],
          [ 1.2501e-21,  1.7984e-24, -3.5983e-23],
          [-1.8460e-19, -6.9443e-22, -2.2451e-20]]],


        ...,


        [[[ 4.3589e-02,  1.7954e-02, -5.8967e-02],
          [ 3.2698e-02,  4.6265e-02, -2.2141e-02],
          [-1.7650e-01, -8.6828e-03,  2.2066e-02]],

         [[-9.7643e-02, -1.6882e-01, -1.0041e-02],
          [ 1.0053e-01,  8.2162e-04, -1.3589e-01],
          [ 9.5223e-02, -7.2868e-02, -2.2298e-02]],

         [[ 7.2200e-02,  1.3540e-01,  1.2723e-01],
          [ 3.0722e-01,  3.7994e-01,  1.7165e-01],
          [ 2.5144e-01,  2.1585e-01,  7.6422e-02]]],


        [[[ 2.4968e-01,  4.5712e-02,  7.8696e-02],
          [ 9.6866e-02, -9.0194e-02, -7.3596e-02],
          [ 1.6515e-02,  1.1377e-01,  2.4622e-02]],

         [[-8.6764e-02, -3.0114e-01, -4.9995e-02],
          [-5.4400e-02, -3.3171e-01, -2.6038e-01],
          [ 3.8086e-02, -3.8788e-02, -5.9480e-02]],

         [[ 7.4289e-02, -1.8869e-01, -4.7915e-02],
          [-8.7382e-03, -9.9102e-02, -2.1179e-02],
          [-1.5528e-02,  5.9672e-02,  1.3763e-01]]],


        [[[ 3.2565e-02, -1.9899e-01, -2.6053e-02],
          [-1.6639e-01, -4.9098e-01, -2.6698e-01],
          [ 1.5141e-01, -7.2485e-02, -6.4387e-02]],

         [[ 1.5355e-01, -2.3113e-01,  6.2706e-03],
          [ 5.0797e-02, -2.1175e-01,  4.2607e-02],
          [ 2.0546e-01,  2.0355e-01,  2.5876e-02]],

         [[ 6.0957e-02, -2.1563e-01,  9.1739e-02],
          [ 1.1887e-01, -5.6800e-02,  6.4848e-02],
          [-6.9449e-02,  1.5738e-03,  9.5277e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2385]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0153]], device='cuda:0')

Epoch: 87 | Batch_idx: 0 |  Loss: (0.1762) | Acc: (93.00%) (120/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.1720) | Acc: (94.00%) (1329/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.1669) | Acc: (94.00%) (2535/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.1731) | Acc: (94.00%) (3733/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.1699) | Acc: (94.00%) (4950/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.1715) | Acc: (94.00%) (6147/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.1733) | Acc: (94.00%) (7353/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.1790) | Acc: (93.00%) (8537/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.1789) | Acc: (94.00%) (9747/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.1802) | Acc: (93.00%) (10943/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.1821) | Acc: (93.00%) (12133/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.1828) | Acc: (93.00%) (13336/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.1816) | Acc: (93.00%) (14546/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.1816) | Acc: (93.00%) (15748/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.1825) | Acc: (93.00%) (16950/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.1819) | Acc: (93.00%) (18155/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.1819) | Acc: (93.00%) (19360/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.1818) | Acc: (93.00%) (20560/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.1829) | Acc: (93.00%) (21753/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.1823) | Acc: (93.00%) (22960/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.1827) | Acc: (93.00%) (24158/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.1810) | Acc: (93.00%) (25386/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.1810) | Acc: (93.00%) (26583/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.1821) | Acc: (93.00%) (27782/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.1819) | Acc: (93.00%) (28988/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.1824) | Acc: (93.00%) (30187/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.1827) | Acc: (93.00%) (31386/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.1826) | Acc: (93.00%) (32582/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.1823) | Acc: (93.00%) (33789/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.1829) | Acc: (93.00%) (34984/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.1836) | Acc: (93.00%) (36168/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.1842) | Acc: (93.00%) (37367/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.1835) | Acc: (93.00%) (38566/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.1834) | Acc: (93.00%) (39767/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.1831) | Acc: (93.00%) (40977/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.1834) | Acc: (93.00%) (42174/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.1838) | Acc: (93.00%) (43373/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.1836) | Acc: (93.00%) (44571/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.1836) | Acc: (93.00%) (45772/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.1834) | Acc: (93.00%) (46936/50000)
# TEST : Loss: (0.2957) | Acc: (90.00%) (9046/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0650e-01, -1.1326e-01, -7.9401e-02],
          [-2.5975e-02, -5.0665e-02,  2.9077e-02],
          [-2.6364e-03, -9.9611e-02, -1.2739e-01]],

         [[-5.6096e-02, -7.9063e-02, -5.1142e-02],
          [-1.1976e-01,  5.4511e-04,  3.6101e-02],
          [ 3.8128e-03,  5.8460e-02, -1.2098e-02]],

         [[-8.3025e-02,  4.5766e-02, -1.6138e-01],
          [ 1.5493e-01,  3.0398e-01,  1.6455e-01],
          [ 1.1613e-02,  2.1834e-01,  1.5936e-01]]],


        [[[ 3.4712e-01, -5.2185e-02,  2.1302e-01],
          [ 1.5466e-01, -4.5951e-04, -1.6796e-01],
          [-2.1557e-01, -2.7065e-01, -2.4520e-01]],

         [[ 1.4985e-02, -2.5237e-01,  4.0164e-03],
          [-8.7451e-02,  3.8553e-01, -1.9796e-01],
          [ 1.9937e-01,  9.3920e-02,  2.1758e-01]],

         [[-1.7428e-01, -2.0985e-01, -4.7338e-02],
          [-2.1117e-01,  1.6109e-01, -3.1559e-02],
          [ 2.2430e-02,  1.4350e-01,  2.3409e-01]]],


        [[[-1.5163e-25, -2.2788e-23, -1.3953e-23],
          [-1.5374e-25, -3.0591e-24, -3.1426e-22],
          [-2.5421e-23, -5.9425e-25, -2.2401e-23]],

         [[ 1.4527e-26,  1.7568e-26, -5.6644e-29],
          [ 1.3536e-28, -2.6072e-31, -2.2939e-29],
          [-1.2010e-24, -1.9192e-28, -1.4676e-27]],

         [[ 1.0544e-26,  4.6533e-29,  1.5576e-31],
          [ 6.4488e-27,  4.3348e-31, -3.7262e-29],
          [-5.3171e-24, -2.0514e-27, -2.4671e-25]]],


        ...,


        [[[ 4.3203e-02,  1.7795e-02, -5.8454e-02],
          [ 3.2402e-02,  4.5847e-02, -2.1942e-02],
          [-1.7496e-01, -8.6071e-03,  2.1875e-02]],

         [[-9.6551e-02, -1.6693e-01, -9.9343e-03],
          [ 9.9265e-02,  8.1124e-04, -1.3427e-01],
          [ 9.4074e-02, -7.1988e-02, -2.2043e-02]],

         [[ 7.1023e-02,  1.3315e-01,  1.2536e-01],
          [ 2.9850e-01,  3.6825e-01,  1.6800e-01],
          [ 2.4525e-01,  2.1026e-01,  7.4949e-02]]],


        [[[ 2.4780e-01,  4.5299e-02,  7.7994e-02],
          [ 9.6119e-02, -8.9375e-02, -7.2907e-02],
          [ 1.6400e-02,  1.1291e-01,  2.4434e-02]],

         [[-8.5926e-02, -2.9654e-01, -4.9297e-02],
          [-5.3842e-02, -3.2622e-01, -2.5616e-01],
          [ 3.7779e-02, -3.8416e-02, -5.8922e-02]],

         [[ 7.3474e-02, -1.8548e-01, -4.7164e-02],
          [-8.6351e-03, -9.7239e-02, -2.0792e-02],
          [-1.5387e-02,  5.9025e-02,  1.3617e-01]]],


        [[[ 3.2370e-02, -1.9699e-01, -2.5848e-02],
          [-1.6540e-01, -4.8603e-01, -2.6474e-01],
          [ 1.5072e-01, -7.2075e-02, -6.4032e-02]],

         [[ 1.5274e-01, -2.2952e-01,  6.2325e-03],
          [ 5.0533e-02, -2.1029e-01,  4.2342e-02],
          [ 2.0458e-01,  2.0253e-01,  2.5750e-02]],

         [[ 6.0644e-02, -2.1428e-01,  9.1215e-02],
          [ 1.1826e-01, -5.6448e-02,  6.4474e-02],
          [-6.9139e-02,  1.5659e-03,  9.4810e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2620]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0195]], device='cuda:0')

Epoch: 88 | Batch_idx: 0 |  Loss: (0.1563) | Acc: (94.00%) (121/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.1898) | Acc: (93.00%) (1319/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.1977) | Acc: (93.00%) (2510/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.1958) | Acc: (93.00%) (3714/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.1958) | Acc: (93.00%) (4912/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.1940) | Acc: (93.00%) (6109/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.1958) | Acc: (93.00%) (7300/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.1980) | Acc: (93.00%) (8490/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.1978) | Acc: (93.00%) (9689/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.1967) | Acc: (93.00%) (10890/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.1982) | Acc: (93.00%) (12080/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.1968) | Acc: (93.00%) (13290/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.1949) | Acc: (93.00%) (14498/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.1940) | Acc: (93.00%) (15697/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.1931) | Acc: (93.00%) (16900/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.1931) | Acc: (93.00%) (18100/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.1923) | Acc: (93.00%) (19302/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.1913) | Acc: (93.00%) (20508/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.1909) | Acc: (93.00%) (21708/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.1899) | Acc: (93.00%) (22921/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.1897) | Acc: (93.00%) (24133/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.1894) | Acc: (93.00%) (25330/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.1902) | Acc: (93.00%) (26529/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.1908) | Acc: (93.00%) (27731/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.1922) | Acc: (93.00%) (28917/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.1932) | Acc: (93.00%) (30103/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.1927) | Acc: (93.00%) (31311/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.1918) | Acc: (93.00%) (32527/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.1923) | Acc: (93.00%) (33713/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.1927) | Acc: (93.00%) (34903/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.1924) | Acc: (93.00%) (36105/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.1929) | Acc: (93.00%) (37301/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.1928) | Acc: (93.00%) (38502/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.1921) | Acc: (93.00%) (39713/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.1920) | Acc: (93.00%) (40914/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.1919) | Acc: (93.00%) (42121/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.1920) | Acc: (93.00%) (43323/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.1931) | Acc: (93.00%) (44497/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.1923) | Acc: (93.00%) (45711/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.1914) | Acc: (93.00%) (46884/50000)
# TEST : Loss: (0.2918) | Acc: (90.00%) (9043/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0319e-01, -1.0978e-01, -7.6959e-02],
          [-2.5204e-02, -4.9204e-02,  2.8225e-02],
          [-2.5591e-03, -9.6792e-02, -1.2373e-01]],

         [[-5.4345e-02, -7.6585e-02, -4.9544e-02],
          [-1.1588e-01,  5.2733e-04,  3.4910e-02],
          [ 3.6876e-03,  5.6546e-02, -1.1698e-02]],

         [[-8.0363e-02,  4.4272e-02, -1.5615e-01],
          [ 1.4920e-01,  2.9210e-01,  1.5818e-01],
          [ 1.1161e-02,  2.0945e-01,  1.5296e-01]]],


        [[[ 3.4651e-01, -5.2093e-02,  2.1265e-01],
          [ 1.5438e-01, -4.5868e-04, -1.6767e-01],
          [-2.1518e-01, -2.7018e-01, -2.4479e-01]],

         [[ 1.4958e-02, -2.5192e-01,  4.0094e-03],
          [-8.7290e-02,  3.8481e-01, -1.9760e-01],
          [ 1.9901e-01,  9.3747e-02,  2.1719e-01]],

         [[-1.7395e-01, -2.0944e-01, -4.7248e-02],
          [-2.1075e-01,  1.6077e-01, -3.1499e-02],
          [ 2.2386e-02,  1.4321e-01,  2.3365e-01]]],


        [[[-1.2180e-32, -2.1495e-29, -6.4492e-30],
          [-2.9278e-33, -5.5230e-31, -5.6284e-28],
          [-1.2160e-29, -1.9205e-32, -9.3825e-30]],

         [[-4.0651e-35, -4.0518e-35,  3.6630e-38],
          [-5.7331e-37, -1.5009e-40, -2.2938e-38],
          [-1.3885e-31,  3.0895e-38,  4.1958e-36]],

         [[-5.9315e-35,  4.5088e-38, -4.2731e-41],
          [-3.2153e-35,  2.0673e-40, -1.4918e-38],
          [-1.9923e-30,  9.1180e-36, -6.8975e-33]]],


        ...,


        [[[ 4.2739e-02,  1.7604e-02, -5.7837e-02],
          [ 3.2047e-02,  4.5344e-02, -2.1703e-02],
          [-1.7310e-01, -8.5160e-03,  2.1645e-02]],

         [[-9.5240e-02, -1.6466e-01, -9.8057e-03],
          [ 9.7750e-02,  7.9880e-04, -1.3232e-01],
          [ 9.2695e-02, -7.0932e-02, -2.1736e-02]],

         [[ 6.9619e-02,  1.3046e-01,  1.2312e-01],
          [ 2.8823e-01,  3.5452e-01,  1.6366e-01],
          [ 2.3792e-01,  2.0366e-01,  7.3195e-02]]],


        [[[ 2.4553e-01,  4.4800e-02,  7.7148e-02],
          [ 9.5219e-02, -8.8389e-02, -7.2078e-02],
          [ 1.6262e-02,  1.1189e-01,  2.4208e-02]],

         [[-8.4917e-02, -2.9105e-01, -4.8462e-02],
          [-5.3171e-02, -3.1966e-01, -2.5112e-01],
          [ 3.7410e-02, -3.7969e-02, -5.8252e-02]],

         [[ 7.2495e-02, -1.8164e-01, -4.6266e-02],
          [-8.5112e-03, -9.5020e-02, -2.0332e-02],
          [-1.5218e-02,  5.8247e-02,  1.3443e-01]]],


        [[[ 3.2134e-02, -1.9459e-01, -2.5601e-02],
          [-1.6421e-01, -4.8007e-01, -2.6205e-01],
          [ 1.4988e-01, -7.1580e-02, -6.3603e-02]],

         [[ 1.5177e-01, -2.2757e-01,  6.1864e-03],
          [ 5.0214e-02, -2.0853e-01,  4.2021e-02],
          [ 2.0351e-01,  2.0130e-01,  2.5597e-02]],

         [[ 6.0266e-02, -2.1264e-01,  9.0581e-02],
          [ 1.1752e-01, -5.6022e-02,  6.4022e-02],
          [-6.8764e-02,  1.5564e-03,  9.4245e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2537]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0139]], device='cuda:0')

Epoch: 89 | Batch_idx: 0 |  Loss: (0.2062) | Acc: (94.00%) (121/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.1966) | Acc: (93.00%) (1311/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.1873) | Acc: (93.00%) (2508/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.1889) | Acc: (93.00%) (3708/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.1866) | Acc: (93.00%) (4907/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.1840) | Acc: (93.00%) (6112/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.1868) | Acc: (93.00%) (7307/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.1860) | Acc: (93.00%) (8510/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.1859) | Acc: (93.00%) (9720/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.1865) | Acc: (93.00%) (10924/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.1884) | Acc: (93.00%) (12130/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.1877) | Acc: (93.00%) (13341/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.1885) | Acc: (93.00%) (14541/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.1893) | Acc: (93.00%) (15743/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.1895) | Acc: (93.00%) (16945/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.1904) | Acc: (93.00%) (18138/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.1901) | Acc: (93.00%) (19336/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.1916) | Acc: (93.00%) (20527/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.1922) | Acc: (93.00%) (21733/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.1928) | Acc: (93.00%) (22923/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.1916) | Acc: (93.00%) (24132/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.1923) | Acc: (93.00%) (25326/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.1917) | Acc: (93.00%) (26539/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.1916) | Acc: (93.00%) (27741/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.1915) | Acc: (93.00%) (28941/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.1919) | Acc: (93.00%) (30139/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.1921) | Acc: (93.00%) (31342/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.1921) | Acc: (93.00%) (32553/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.1926) | Acc: (93.00%) (33747/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.1924) | Acc: (93.00%) (34941/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.1926) | Acc: (93.00%) (36134/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.1929) | Acc: (93.00%) (37336/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.1939) | Acc: (93.00%) (38525/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.1938) | Acc: (93.00%) (39726/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.1941) | Acc: (93.00%) (40923/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.1947) | Acc: (93.00%) (42120/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.1954) | Acc: (93.00%) (43302/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.1960) | Acc: (93.00%) (44490/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.1965) | Acc: (93.00%) (45681/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.1969) | Acc: (93.00%) (46822/50000)
# TEST : Loss: (0.2923) | Acc: (90.00%) (9036/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-9.9313e-02, -1.0569e-01, -7.4091e-02],
          [-2.4297e-02, -4.7484e-02,  2.7222e-02],
          [-2.4681e-03, -9.3470e-02, -1.1942e-01]],

         [[-5.2289e-02, -7.3675e-02, -4.7668e-02],
          [-1.1133e-01,  5.0648e-04,  3.3515e-02],
          [ 3.5407e-03,  5.4301e-02, -1.1231e-02]],

         [[-7.7240e-02,  4.2521e-02, -1.5002e-01],
          [ 1.4253e-01,  2.7828e-01,  1.5076e-01],
          [ 1.0636e-02,  1.9911e-01,  1.4553e-01]]],


        [[[ 3.4577e-01, -5.1981e-02,  2.1221e-01],
          [ 1.5404e-01, -4.5768e-04, -1.6730e-01],
          [-2.1472e-01, -2.6960e-01, -2.4428e-01]],

         [[ 1.4926e-02, -2.5137e-01,  4.0009e-03],
          [-8.7095e-02,  3.8394e-01, -1.9716e-01],
          [ 1.9856e-01,  9.3537e-02,  2.1672e-01]],

         [[-1.7355e-01, -2.0894e-01, -4.7139e-02],
          [-2.1025e-01,  1.6038e-01, -3.1425e-02],
          [ 2.2333e-02,  1.4287e-01,  2.3311e-01]]],


        [[[ 5.2161e-41, -1.2920e-38, -6.6426e-39],
          [-2.0755e-41, -7.3228e-41,  9.2900e-37],
          [-1.2694e-38,  1.3238e-41, -9.2071e-39]],

         [[ 3.4899e-41,  3.1149e-41, -6.6068e-41],
          [-1.8870e-41, -2.5589e-41,  6.2286e-41],
          [ 4.7542e-41, -9.8273e-42, -3.6980e-41]],

         [[-6.6643e-41, -5.8209e-41,  4.1338e-43],
          [ 4.3020e-43,  4.5563e-41, -9.7993e-42],
          [-1.8085e-39,  1.8672e-41, -1.5849e-41]]],


        ...,


        [[[ 4.2181e-02,  1.7374e-02, -5.7096e-02],
          [ 3.1620e-02,  4.4740e-02, -2.1416e-02],
          [-1.7086e-01, -8.4065e-03,  2.1368e-02]],

         [[-9.3669e-02, -1.6195e-01, -9.6515e-03],
          [ 9.5938e-02,  7.8392e-04, -1.2999e-01],
          [ 9.1046e-02, -6.9669e-02, -2.1370e-02]],

         [[ 6.7948e-02,  1.2726e-01,  1.2044e-01],
          [ 2.7622e-01,  3.3851e-01,  1.5854e-01],
          [ 2.2930e-01,  1.9590e-01,  7.1117e-02]]],


        [[[ 2.4281e-01,  4.4202e-02,  7.6133e-02],
          [ 9.4135e-02, -8.7205e-02, -7.1082e-02],
          [ 1.6096e-02,  1.1065e-01,  2.3936e-02]],

         [[-8.3706e-02, -2.8451e-01, -4.7466e-02],
          [-5.2366e-02, -3.1186e-01, -2.4512e-01],
          [ 3.6965e-02, -3.7432e-02, -5.7446e-02]],

         [[ 7.1322e-02, -1.7708e-01, -4.5197e-02],
          [-8.3630e-03, -9.2389e-02, -1.9785e-02],
          [-1.5014e-02,  5.7314e-02,  1.3233e-01]]],


        [[[ 3.1849e-02, -1.9171e-01, -2.5303e-02],
          [-1.6277e-01, -4.7292e-01, -2.5882e-01],
          [ 1.4887e-01, -7.0982e-02, -6.3084e-02]],

         [[ 1.5060e-01, -2.2523e-01,  6.1308e-03],
          [ 4.9829e-02, -2.0640e-01,  4.1634e-02],
          [ 2.0222e-01,  1.9982e-01,  2.5414e-02]],

         [[ 5.9809e-02, -2.1067e-01,  8.9817e-02],
          [ 1.1663e-01, -5.5508e-02,  6.3476e-02],
          [-6.8310e-02,  1.5448e-03,  9.3562e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2652]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0150]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.2649) | Acc: (93.00%) (120/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2260) | Acc: (93.00%) (1311/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.3180) | Acc: (89.00%) (2416/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.3483) | Acc: (88.00%) (3516/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.3749) | Acc: (87.00%) (4589/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.3827) | Acc: (87.00%) (5706/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.3848) | Acc: (87.00%) (6817/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.3927) | Acc: (87.00%) (7914/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.3984) | Acc: (86.00%) (9001/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.4002) | Acc: (86.00%) (10111/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.4048) | Acc: (86.00%) (11203/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.4024) | Acc: (86.00%) (12315/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.4010) | Acc: (86.00%) (13426/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.3952) | Acc: (86.00%) (14565/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.3942) | Acc: (86.00%) (15673/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.3910) | Acc: (86.00%) (16815/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.3897) | Acc: (87.00%) (17931/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.3861) | Acc: (87.00%) (19068/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.3838) | Acc: (87.00%) (20196/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.3810) | Acc: (87.00%) (21339/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.3803) | Acc: (87.00%) (22459/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.3810) | Acc: (87.00%) (23569/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.3795) | Acc: (87.00%) (24699/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.3789) | Acc: (87.00%) (25814/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.3774) | Acc: (87.00%) (26937/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.3758) | Acc: (87.00%) (28065/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.3734) | Acc: (87.00%) (29213/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.3726) | Acc: (87.00%) (30339/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.3715) | Acc: (87.00%) (31469/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.3707) | Acc: (87.00%) (32595/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.3694) | Acc: (87.00%) (33750/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.3679) | Acc: (87.00%) (34888/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.3664) | Acc: (87.00%) (36031/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.3655) | Acc: (87.00%) (37171/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.3643) | Acc: (87.00%) (38320/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.3639) | Acc: (87.00%) (39453/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.3626) | Acc: (87.00%) (40598/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.3608) | Acc: (87.00%) (41743/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.3586) | Acc: (87.00%) (42910/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.3572) | Acc: (88.00%) (44022/50000)
# TEST : Loss: (0.3848) | Acc: (87.00%) (8748/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1261e-01, -1.0822e-01, -8.0278e-02],
          [-4.6184e-02, -6.2336e-02,  5.9897e-03],
          [-2.5079e-02, -1.1317e-01, -1.4598e-01]],

         [[-7.6370e-02, -8.3627e-02, -6.7601e-02],
          [-1.3846e-01, -1.9899e-02, -2.1506e-05],
          [-2.8854e-02,  2.1545e-02, -5.5907e-02]],

         [[-9.8175e-02,  3.6045e-02, -1.6225e-01],
          [ 1.1815e-01,  2.6696e-01,  1.2758e-01],
          [-1.2738e-02,  1.7474e-01,  1.0528e-01]]],


        [[[ 3.5239e-01, -3.7116e-02,  2.2901e-01],
          [ 1.4972e-01, -1.5672e-03, -1.6831e-01],
          [-2.2223e-01, -2.8419e-01, -2.4346e-01]],

         [[ 5.8232e-03, -2.5634e-01, -5.2597e-03],
          [-9.9190e-02,  3.8111e-01, -2.0520e-01],
          [ 1.9043e-01,  8.9994e-02,  2.2007e-01]],

         [[-1.8291e-01, -2.1885e-01, -5.5202e-02],
          [-2.1972e-01,  1.5223e-01, -3.7033e-02],
          [ 1.3578e-02,  1.3559e-01,  2.3275e-01]]],


        [[[ 1.0768e-41,  3.5719e-42,  1.3038e-41],
          [ 7.8333e-43, -2.2830e-41, -6.2090e-41],
          [ 2.3591e-41,  4.2288e-41, -5.6052e-44]],

         [[ 4.0067e-41,  4.5453e-41, -2.6653e-41],
          [ 4.4239e-42, -3.5486e-41, -6.3843e-42],
          [ 9.8371e-43,  3.1639e-41, -6.8375e-41]],

         [[-6.4931e-41, -2.2621e-41, -4.8366e-41],
          [-1.6788e-42,  1.0915e-41,  1.9872e-41],
          [ 1.0084e-41, -4.5696e-42,  1.6088e-41]]],


        ...,


        [[[ 6.5053e-02,  3.5517e-02, -4.4569e-02],
          [ 4.9184e-02,  6.7344e-02, -3.5485e-03],
          [-1.4590e-01,  1.9224e-02,  4.9064e-02]],

         [[-9.6364e-02, -1.7467e-01, -3.7073e-02],
          [ 9.9334e-02,  2.2900e-03, -1.4370e-01],
          [ 1.0895e-01, -5.3986e-02, -1.7661e-02]],

         [[ 7.0774e-02,  1.1759e-01,  9.0647e-02],
          [ 3.0881e-01,  3.6674e-01,  1.4671e-01],
          [ 2.6061e-01,  2.2361e-01,  7.1129e-02]]],


        [[[ 2.5666e-01,  5.7470e-02,  1.0158e-01],
          [ 9.6967e-02, -8.2526e-02, -5.6459e-02],
          [ 1.4016e-02,  1.1870e-01,  4.7837e-02]],

         [[-7.3837e-02, -2.7830e-01, -3.4947e-02],
          [-5.6255e-02, -3.1152e-01, -2.4837e-01],
          [ 3.1486e-02, -3.0483e-02, -4.4466e-02]],

         [[ 6.6926e-02, -1.9490e-01, -5.4544e-02],
          [-1.9840e-02, -1.0542e-01, -3.6114e-02],
          [-3.3658e-02,  4.8957e-02,  1.2915e-01]]],


        [[[ 3.1154e-02, -1.9570e-01,  1.3993e-02],
          [-1.9396e-01, -5.1407e-01, -2.3966e-01],
          [ 1.2341e-01, -8.6398e-02, -5.2782e-02]],

         [[ 1.5602e-01, -2.2270e-01,  3.8482e-02],
          [ 3.5522e-02, -2.2093e-01,  6.3233e-02],
          [ 1.8397e-01,  1.9343e-01,  3.8089e-02]],

         [[ 6.7101e-02, -2.0099e-01,  1.2199e-01],
          [ 1.0815e-01, -5.5533e-02,  9.5257e-02],
          [-8.5847e-02,  1.6622e-04,  1.1252e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0001,  0.0002,  0.0001],
          [-0.0009, -0.0008, -0.0009],
          [-0.0011, -0.0009, -0.0011]],

         [[ 0.0002,  0.0004,  0.0003],
          [-0.0006, -0.0005, -0.0006],
          [-0.0009, -0.0008, -0.0009]],

         [[ 0.0002,  0.0005,  0.0004],
          [-0.0005, -0.0003, -0.0003],
          [-0.0007, -0.0006, -0.0007]]],


        [[[-0.0599, -0.0437, -0.0490],
          [-0.0549, -0.0478, -0.0300],
          [-0.0887, -0.0945, -0.0358]],

         [[-0.0390, -0.0169, -0.0213],
          [-0.0370, -0.0225,  0.0001],
          [-0.0761, -0.0761, -0.0098]],

         [[-0.0321, -0.0105, -0.0178],
          [-0.0257, -0.0134,  0.0066],
          [-0.0612, -0.0626, -0.0037]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0088,  0.0074,  0.0065],
          [ 0.0052,  0.0038,  0.0024],
          [ 0.0046,  0.0047,  0.0022]],

         [[ 0.0076,  0.0062,  0.0049],
          [ 0.0044,  0.0033,  0.0018],
          [ 0.0032,  0.0039,  0.0020]],

         [[ 0.0032,  0.0019,  0.0011],
          [ 0.0008, -0.0001, -0.0011],
          [ 0.0005,  0.0015,  0.0003]]],


        [[[-0.0169, -0.0159, -0.0147],
          [-0.0131, -0.0088, -0.0067],
          [-0.0137, -0.0077, -0.0022]],

         [[-0.0121, -0.0107, -0.0098],
          [-0.0081, -0.0033, -0.0022],
          [-0.0092, -0.0029,  0.0013]],

         [[-0.0092, -0.0076, -0.0078],
          [-0.0060, -0.0014, -0.0014],
          [-0.0080, -0.0020,  0.0013]]],


        [[[-0.0079, -0.0088, -0.0059],
          [-0.0127, -0.0091, -0.0091],
          [-0.0194, -0.0117, -0.0102]],

         [[-0.0231, -0.0230, -0.0201],
          [-0.0240, -0.0197, -0.0201],
          [-0.0270, -0.0189, -0.0175]],

         [[-0.0326, -0.0314, -0.0292],
          [-0.0308, -0.0264, -0.0277],
          [-0.0307, -0.0230, -0.0223]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2666]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 91 | Batch_idx: 0 |  Loss: (0.3969) | Acc: (87.00%) (112/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2936) | Acc: (90.00%) (1273/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2772) | Acc: (91.00%) (2449/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2710) | Acc: (91.00%) (3622/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2711) | Acc: (91.00%) (4789/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2683) | Acc: (91.00%) (5952/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2697) | Acc: (90.00%) (7105/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2742) | Acc: (90.00%) (8260/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2721) | Acc: (90.00%) (9431/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2708) | Acc: (91.00%) (10613/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2676) | Acc: (91.00%) (11792/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2704) | Acc: (91.00%) (12943/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2702) | Acc: (91.00%) (14106/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2706) | Acc: (91.00%) (15263/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2680) | Acc: (91.00%) (16439/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2683) | Acc: (91.00%) (17595/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2679) | Acc: (91.00%) (18767/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2665) | Acc: (91.00%) (19943/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2663) | Acc: (91.00%) (21108/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2661) | Acc: (91.00%) (22268/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2678) | Acc: (91.00%) (23413/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2675) | Acc: (91.00%) (24581/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2668) | Acc: (91.00%) (25751/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2667) | Acc: (91.00%) (26921/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2677) | Acc: (91.00%) (28077/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2678) | Acc: (91.00%) (29251/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2688) | Acc: (91.00%) (30405/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2684) | Acc: (91.00%) (31571/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2669) | Acc: (91.00%) (32755/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2669) | Acc: (91.00%) (33922/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2664) | Acc: (91.00%) (35095/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2656) | Acc: (91.00%) (36274/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2659) | Acc: (91.00%) (37427/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2662) | Acc: (91.00%) (38584/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2656) | Acc: (91.00%) (39761/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2656) | Acc: (91.00%) (40922/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2649) | Acc: (91.00%) (42100/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2662) | Acc: (91.00%) (43258/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2669) | Acc: (91.00%) (44408/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2680) | Acc: (91.00%) (45507/50000)
# TEST : Loss: (0.4350) | Acc: (85.00%) (8578/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0804e-01, -1.0070e-01, -7.5120e-02],
          [-4.6889e-02, -5.8684e-02,  7.9348e-03],
          [-2.5773e-02, -1.0754e-01, -1.4060e-01]],

         [[-7.3195e-02, -7.5431e-02, -6.0150e-02],
          [-1.3538e-01, -1.3784e-02,  6.4732e-03],
          [-2.7559e-02,  2.7511e-02, -4.8781e-02]],

         [[-9.6404e-02,  3.8634e-02, -1.5312e-01],
          [ 1.1363e-01,  2.6437e-01,  1.3207e-01],
          [-1.2525e-02,  1.7548e-01,  1.0856e-01]]],


        [[[ 3.5778e-01, -2.8934e-02,  2.3617e-01],
          [ 1.5880e-01,  8.4921e-03, -1.6360e-01],
          [-2.1747e-01, -2.8338e-01, -2.4250e-01]],

         [[ 7.3978e-03, -2.5166e-01,  1.9447e-04],
          [-9.5684e-02,  3.9385e-01, -1.9880e-01],
          [ 1.9296e-01,  1.0109e-01,  2.2621e-01]],

         [[-1.7846e-01, -2.1917e-01, -5.4285e-02],
          [-2.1525e-01,  1.5978e-01, -3.1311e-02],
          [ 1.5831e-02,  1.4794e-01,  2.3935e-01]]],


        [[[ 2.3093e-41,  5.8584e-41, -5.5822e-41],
          [-1.5119e-41,  6.8980e-41, -2.6811e-41],
          [-4.8364e-41, -6.1471e-41, -6.6930e-41]],

         [[-3.2530e-41, -3.7619e-41, -3.9603e-41],
          [-5.0099e-41, -5.3340e-41,  2.1860e-42],
          [ 3.8965e-41, -4.6418e-41,  2.5383e-41]],

         [[ 3.9941e-41, -6.8032e-41, -6.2127e-41],
          [ 1.6879e-41,  3.6630e-41,  2.6239e-41],
          [-6.8400e-41,  4.9846e-41, -3.6285e-41]]],


        ...,


        [[[ 4.1115e-02,  2.0823e-02, -4.8766e-02],
          [ 2.5336e-02,  4.8409e-02, -1.3538e-02],
          [-1.6104e-01,  1.2513e-03,  3.2219e-02]],

         [[-1.2139e-01, -1.8570e-01, -3.3539e-02],
          [ 7.7582e-02, -1.2519e-02, -1.4324e-01],
          [ 1.0095e-01, -6.5937e-02, -2.8486e-02]],

         [[ 4.9922e-02,  1.1651e-01,  1.0724e-01],
          [ 3.0117e-01,  3.7126e-01,  1.7051e-01],
          [ 2.7366e-01,  2.1899e-01,  6.7333e-02]]],


        [[[ 2.5140e-01,  4.0148e-02,  8.8977e-02],
          [ 9.9868e-02, -9.1722e-02, -7.1795e-02],
          [-4.7055e-03,  9.3076e-02,  2.0710e-02]],

         [[-7.0671e-02, -2.9826e-01, -5.5335e-02],
          [-4.8153e-02, -3.2307e-01, -2.7836e-01],
          [ 1.2486e-02, -5.8272e-02, -7.6213e-02]],

         [[ 8.0483e-02, -2.0426e-01, -6.1635e-02],
          [ 3.8155e-03, -9.5338e-02, -4.5616e-02],
          [-3.5693e-02,  3.9487e-02,  1.1442e-01]]],


        [[[ 2.8772e-02, -2.0640e-01,  1.7345e-02],
          [-1.8857e-01, -5.1397e-01, -2.3268e-01],
          [ 1.2937e-01, -7.7654e-02, -4.0839e-02]],

         [[ 1.5192e-01, -2.3233e-01,  3.6284e-02],
          [ 3.7243e-02, -2.2346e-01,  6.4862e-02],
          [ 1.8955e-01,  1.9987e-01,  4.5771e-02]],

         [[ 5.0840e-02, -2.1939e-01,  1.1326e-01],
          [ 9.7845e-02, -6.8457e-02,  9.0250e-02],
          [-8.7656e-02, -4.7424e-04,  1.1485e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0001, -0.0001, -0.0001],
          [ 0.0001,  0.0001,  0.0001],
          [ 0.0001,  0.0003,  0.0003]],

         [[-0.0003, -0.0003, -0.0003],
          [-0.0000, -0.0000, -0.0000],
          [ 0.0002,  0.0002,  0.0002]],

         [[-0.0003, -0.0003, -0.0003],
          [-0.0001, -0.0002, -0.0002],
          [-0.0000,  0.0000,  0.0000]]],


        [[[ 0.0534,  0.0332,  0.0247],
          [-0.0075, -0.0300, -0.0081],
          [-0.0465, -0.0440, -0.0114]],

         [[ 0.0637,  0.0257,  0.0129],
          [-0.0115, -0.0368, -0.0167],
          [-0.0483, -0.0487,  0.0007]],

         [[ 0.0405,  0.0086, -0.0002],
          [-0.0191, -0.0413, -0.0167],
          [-0.0475, -0.0468, -0.0015]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0009, -0.0026, -0.0030],
          [ 0.0026,  0.0029,  0.0031],
          [ 0.0018,  0.0024,  0.0059]],

         [[-0.0034, -0.0049, -0.0048],
          [ 0.0003,  0.0005,  0.0007],
          [-0.0010, -0.0008,  0.0022]],

         [[-0.0045, -0.0054, -0.0049],
          [-0.0005,  0.0004,  0.0010],
          [-0.0011, -0.0003,  0.0026]]],


        [[[ 0.0083,  0.0092,  0.0069],
          [-0.0018,  0.0023, -0.0006],
          [-0.0054, -0.0001, -0.0009]],

         [[ 0.0068,  0.0071,  0.0053],
          [-0.0031, -0.0007, -0.0031],
          [-0.0063, -0.0022, -0.0038]],

         [[ 0.0082,  0.0078,  0.0065],
          [-0.0009,  0.0007, -0.0014],
          [-0.0043, -0.0007, -0.0021]]],


        [[[ 0.0152,  0.0097,  0.0196],
          [ 0.0082,  0.0068,  0.0155],
          [ 0.0128,  0.0115,  0.0171]],

         [[ 0.0144,  0.0081,  0.0151],
          [ 0.0097,  0.0087,  0.0137],
          [ 0.0196,  0.0170,  0.0176]],

         [[ 0.0148,  0.0066,  0.0106],
          [ 0.0099,  0.0069,  0.0094],
          [ 0.0152,  0.0117,  0.0109]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2661]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 92 | Batch_idx: 0 |  Loss: (0.3686) | Acc: (88.00%) (113/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2475) | Acc: (90.00%) (1280/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2430) | Acc: (91.00%) (2463/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2351) | Acc: (92.00%) (3653/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2263) | Acc: (92.00%) (4851/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2219) | Acc: (92.00%) (6046/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2242) | Acc: (92.00%) (7217/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2283) | Acc: (92.00%) (8385/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2292) | Acc: (92.00%) (9564/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2271) | Acc: (92.00%) (10745/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2255) | Acc: (92.00%) (11935/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2254) | Acc: (92.00%) (13107/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2247) | Acc: (92.00%) (14288/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2255) | Acc: (92.00%) (15460/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2261) | Acc: (92.00%) (16632/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2274) | Acc: (92.00%) (17816/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2286) | Acc: (92.00%) (18984/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2301) | Acc: (92.00%) (20149/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2312) | Acc: (92.00%) (21322/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2320) | Acc: (91.00%) (22491/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2333) | Acc: (91.00%) (23662/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2337) | Acc: (91.00%) (24843/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2335) | Acc: (92.00%) (26028/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2331) | Acc: (92.00%) (27207/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2356) | Acc: (91.00%) (28361/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2360) | Acc: (91.00%) (29541/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2358) | Acc: (91.00%) (30722/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2378) | Acc: (91.00%) (31879/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2376) | Acc: (91.00%) (33058/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2385) | Acc: (91.00%) (34233/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2381) | Acc: (91.00%) (35409/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2383) | Acc: (91.00%) (36573/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2378) | Acc: (91.00%) (37750/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2382) | Acc: (91.00%) (38921/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2391) | Acc: (91.00%) (40079/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2395) | Acc: (91.00%) (41248/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2397) | Acc: (91.00%) (42428/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2391) | Acc: (91.00%) (43617/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2399) | Acc: (91.00%) (44788/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2400) | Acc: (91.00%) (45918/50000)
# TEST : Loss: (0.3870) | Acc: (87.00%) (8792/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1011e-01, -9.6061e-02, -7.0660e-02],
          [-5.5209e-02, -6.0143e-02,  2.7730e-03],
          [-3.5286e-02, -1.0917e-01, -1.4320e-01]],

         [[-7.6882e-02, -7.4754e-02, -5.7398e-02],
          [-1.4387e-01, -2.1224e-02, -1.0320e-03],
          [-4.0806e-02,  1.6743e-02, -5.7642e-02]],

         [[-9.9549e-02,  3.4036e-02, -1.4778e-01],
          [ 9.7144e-02,  2.4826e-01,  1.2305e-01],
          [-2.4480e-02,  1.6161e-01,  9.7639e-02]]],


        [[[ 3.4964e-01, -3.2332e-02,  2.4276e-01],
          [ 1.5739e-01,  2.9485e-03, -1.7040e-01],
          [-2.1587e-01, -2.8842e-01, -2.4721e-01]],

         [[ 7.0504e-04, -2.5481e-01,  9.4657e-03],
          [-9.4071e-02,  3.9565e-01, -2.0284e-01],
          [ 1.9962e-01,  1.0397e-01,  2.2572e-01]],

         [[-1.8066e-01, -2.1927e-01, -4.4108e-02],
          [-2.1629e-01,  1.6165e-01, -3.2156e-02],
          [ 1.5539e-02,  1.4701e-01,  2.3899e-01]]],


        [[[ 3.1526e-41, -7.9033e-42, -1.2802e-41],
          [ 5.5898e-42,  5.2214e-41, -3.9627e-41],
          [-3.6083e-42, -5.0507e-41, -3.8572e-41]],

         [[ 1.3751e-41,  7.3933e-42,  5.6851e-42],
          [-1.5906e-41,  3.8645e-41, -4.4927e-41],
          [ 5.0912e-41,  7.0918e-41, -7.1064e-41]],

         [[-2.7408e-41,  5.9286e-41,  1.3733e-41],
          [ 6.8536e-41, -1.0889e-41, -5.5173e-41],
          [-3.6850e-41,  1.5706e-41, -1.9883e-41]]],


        ...,


        [[[ 4.7237e-02,  2.8883e-02, -3.8120e-02],
          [ 3.6291e-02,  6.2743e-02, -3.0664e-03],
          [-1.4984e-01,  1.5536e-02,  4.0299e-02]],

         [[-1.2868e-01, -1.9167e-01, -3.4286e-02],
          [ 7.9591e-02, -7.6294e-03, -1.4097e-01],
          [ 1.0797e-01, -5.7512e-02, -2.8247e-02]],

         [[ 3.8558e-02,  1.1030e-01,  1.1083e-01],
          [ 3.0023e-01,  3.7769e-01,  1.7450e-01],
          [ 2.8380e-01,  2.2739e-01,  6.4542e-02]]],


        [[[ 2.5490e-01,  3.5660e-02,  8.4351e-02],
          [ 1.0367e-01, -9.2795e-02, -7.4046e-02],
          [ 1.4389e-03,  1.0102e-01,  3.2025e-02]],

         [[-6.4777e-02, -3.0270e-01, -6.4514e-02],
          [-4.2400e-02, -3.1946e-01, -2.8277e-01],
          [ 1.8726e-02, -4.7469e-02, -6.3126e-02]],

         [[ 7.7491e-02, -2.1280e-01, -7.4445e-02],
          [ 5.2994e-03, -8.8454e-02, -5.1423e-02],
          [-2.8855e-02,  5.6855e-02,  1.2903e-01]]],


        [[[ 3.6537e-02, -2.0866e-01,  4.6889e-03],
          [-1.8297e-01, -5.1563e-01, -2.4591e-01],
          [ 1.3462e-01, -7.6225e-02, -5.0091e-02]],

         [[ 1.5609e-01, -2.3625e-01,  2.0900e-02],
          [ 4.2208e-02, -2.2218e-01,  5.3224e-02],
          [ 1.9386e-01,  2.0139e-01,  3.6410e-02]],

         [[ 5.1700e-02, -2.2323e-01,  1.0223e-01],
          [ 1.0138e-01, -6.5905e-02,  8.5623e-02],
          [-8.1744e-02,  4.7684e-03,  1.1097e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000, -0.0000, -0.0000],
          [-0.0002, -0.0002, -0.0001],
          [ 0.0000,  0.0000,  0.0003]],

         [[ 0.0002,  0.0001,  0.0001],
          [-0.0000, -0.0000, -0.0000],
          [ 0.0002,  0.0001,  0.0003]],

         [[ 0.0003,  0.0004,  0.0004],
          [ 0.0002,  0.0002,  0.0002],
          [ 0.0003,  0.0003,  0.0003]]],


        [[[-0.0358,  0.0047,  0.0341],
          [ 0.0321,  0.0557,  0.0445],
          [ 0.0416,  0.0526,  0.0425]],

         [[-0.0001,  0.0280,  0.0477],
          [ 0.0748,  0.0785,  0.0458],
          [ 0.0796,  0.0731,  0.0492]],

         [[ 0.0168,  0.0325,  0.0489],
          [ 0.0660,  0.0565,  0.0302],
          [ 0.0705,  0.0523,  0.0344]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0011,  0.0013, -0.0035],
          [ 0.0055,  0.0048,  0.0027],
          [ 0.0058,  0.0038,  0.0006]],

         [[ 0.0018,  0.0023, -0.0013],
          [ 0.0067,  0.0065,  0.0057],
          [ 0.0067,  0.0053,  0.0033]],

         [[-0.0025, -0.0018, -0.0041],
          [ 0.0011,  0.0013,  0.0015],
          [ 0.0011,  0.0004, -0.0007]]],


        [[[-0.0086, -0.0115, -0.0119],
          [-0.0047, -0.0071, -0.0099],
          [-0.0087, -0.0139, -0.0145]],

         [[-0.0034, -0.0057, -0.0053],
          [ 0.0006, -0.0023, -0.0039],
          [-0.0028, -0.0089, -0.0090]],

         [[ 0.0004, -0.0017,  0.0004],
          [ 0.0028, -0.0001,  0.0008],
          [-0.0000, -0.0053, -0.0043]]],


        [[[ 0.0145,  0.0022, -0.0083],
          [ 0.0156,  0.0033, -0.0006],
          [ 0.0013, -0.0072, -0.0011]],

         [[ 0.0161,  0.0070, -0.0003],
          [ 0.0206,  0.0103,  0.0080],
          [ 0.0090,  0.0022,  0.0092]],

         [[ 0.0137,  0.0069,  0.0018],
          [ 0.0168,  0.0083,  0.0071],
          [ 0.0056, -0.0012,  0.0052]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2654]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 93 | Batch_idx: 0 |  Loss: (0.1040) | Acc: (97.00%) (125/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.1928) | Acc: (93.00%) (1315/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.1944) | Acc: (93.00%) (2514/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.1886) | Acc: (93.00%) (3714/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.1968) | Acc: (93.00%) (4897/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.1969) | Acc: (93.00%) (6080/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.1982) | Acc: (93.00%) (7269/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.1987) | Acc: (93.00%) (8459/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.1966) | Acc: (93.00%) (9662/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.1981) | Acc: (93.00%) (10858/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2004) | Acc: (93.00%) (12045/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2036) | Acc: (93.00%) (13222/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2074) | Acc: (92.00%) (14396/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2072) | Acc: (92.00%) (15586/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2099) | Acc: (92.00%) (16765/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2100) | Acc: (92.00%) (17949/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2087) | Acc: (92.00%) (19135/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2072) | Acc: (92.00%) (20331/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2089) | Acc: (92.00%) (21493/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2106) | Acc: (92.00%) (22665/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2116) | Acc: (92.00%) (23843/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2127) | Acc: (92.00%) (25027/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2132) | Acc: (92.00%) (26207/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2148) | Acc: (92.00%) (27387/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2161) | Acc: (92.00%) (28560/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2170) | Acc: (92.00%) (29738/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2177) | Acc: (92.00%) (30897/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2184) | Acc: (92.00%) (32074/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2191) | Acc: (92.00%) (33249/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2194) | Acc: (92.00%) (34424/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2201) | Acc: (92.00%) (35593/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2214) | Acc: (92.00%) (36768/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2213) | Acc: (92.00%) (37949/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2224) | Acc: (92.00%) (39126/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2229) | Acc: (92.00%) (40304/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2233) | Acc: (92.00%) (41476/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2233) | Acc: (92.00%) (42649/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2231) | Acc: (92.00%) (43834/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2222) | Acc: (92.00%) (45034/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2223) | Acc: (92.00%) (46171/50000)
# TEST : Loss: (0.3387) | Acc: (89.00%) (8903/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-9.3111e-02, -7.4355e-02, -4.8519e-02],
          [-2.6017e-02, -2.6434e-02,  3.3593e-02],
          [-4.3905e-03, -7.2855e-02, -1.0270e-01]],

         [[-5.7387e-02, -4.8382e-02, -3.0936e-02],
          [-1.0780e-01,  1.5784e-02,  3.3936e-02],
          [-4.9049e-03,  5.4550e-02, -1.6650e-02]],

         [[-8.0588e-02,  5.7189e-02, -1.1680e-01],
          [ 1.2337e-01,  2.7587e-01,  1.5315e-01],
          [ 1.2604e-02,  1.9687e-01,  1.3278e-01]]],


        [[[ 3.4377e-01, -3.7409e-02,  2.3657e-01],
          [ 1.4971e-01, -2.3196e-03, -1.6902e-01],
          [-2.3338e-01, -2.9528e-01, -2.4579e-01]],

         [[ 2.8167e-04, -2.5776e-01,  1.6520e-03],
          [-9.7812e-02,  3.9586e-01, -1.9895e-01],
          [ 1.8601e-01,  1.0577e-01,  2.3195e-01]],

         [[-1.8571e-01, -2.2657e-01, -5.3817e-02],
          [-2.2414e-01,  1.5762e-01, -2.5755e-02],
          [ 8.3779e-03,  1.5237e-01,  2.4969e-01]]],


        [[[ 3.0714e-41,  2.7950e-41,  1.6863e-41],
          [-7.0518e-41, -6.9161e-41, -2.3107e-42],
          [ 1.2312e-41, -3.6752e-41,  4.8579e-41]],

         [[-3.0988e-41, -2.9942e-41,  4.8007e-41],
          [-5.9471e-42, -7.0497e-41, -1.1311e-41],
          [-2.9119e-42,  4.6581e-41, -6.5769e-41]],

         [[-1.1195e-41,  2.4306e-41, -3.2020e-41],
          [ 5.0782e-41,  5.4335e-41, -3.5677e-42],
          [ 5.1047e-41,  5.7719e-42, -5.8333e-41]]],


        ...,


        [[[ 4.3015e-02,  2.0491e-02, -5.4759e-02],
          [ 2.3857e-02,  5.2765e-02, -1.7766e-02],
          [-1.6662e-01,  6.9099e-03,  3.1567e-02]],

         [[-1.2090e-01, -1.8434e-01, -3.7796e-02],
          [ 7.9855e-02, -1.8729e-03, -1.4179e-01],
          [ 1.0199e-01, -5.1366e-02, -2.6099e-02]],

         [[ 4.5008e-02,  1.1815e-01,  1.0521e-01],
          [ 3.0119e-01,  3.9294e-01,  1.7334e-01],
          [ 2.6954e-01,  2.3596e-01,  6.5613e-02]]],


        [[[ 2.6626e-01,  3.2263e-02,  9.0087e-02],
          [ 1.1179e-01, -9.3714e-02, -6.4203e-02],
          [ 1.4249e-02,  1.0821e-01,  4.3743e-02]],

         [[-4.5575e-02, -2.9492e-01, -5.0725e-02],
          [-3.4633e-02, -3.1968e-01, -2.6557e-01],
          [ 2.5110e-02, -4.7920e-02, -5.8010e-02]],

         [[ 9.4729e-02, -2.0350e-01, -5.9713e-02],
          [ 1.5973e-02, -8.0155e-02, -2.7123e-02],
          [-1.5625e-02,  6.4260e-02,  1.4082e-01]]],


        [[[ 4.1117e-02, -2.1104e-01,  7.2848e-03],
          [-1.9075e-01, -5.1907e-01, -2.4177e-01],
          [ 1.3678e-01, -6.9505e-02, -4.1714e-02]],

         [[ 1.6480e-01, -2.3386e-01,  2.1005e-02],
          [ 4.0339e-02, -2.2072e-01,  5.5207e-02],
          [ 1.9791e-01,  2.0708e-01,  4.2323e-02]],

         [[ 5.2386e-02, -2.2722e-01,  9.8083e-02],
          [ 9.6173e-02, -6.7398e-02,  8.4193e-02],
          [-7.8060e-02,  9.7055e-03,  1.1365e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0013,  0.0010,  0.0009],
          [ 0.0010,  0.0005,  0.0006],
          [ 0.0007,  0.0005,  0.0005]],

         [[ 0.0013,  0.0008,  0.0007],
          [ 0.0011,  0.0005,  0.0006],
          [ 0.0009,  0.0006,  0.0006]],

         [[ 0.0012,  0.0007,  0.0006],
          [ 0.0012,  0.0006,  0.0006],
          [ 0.0012,  0.0008,  0.0008]]],


        [[[-0.0063, -0.0162, -0.0140],
          [ 0.0189,  0.0118, -0.0198],
          [-0.0038, -0.0076, -0.0461]],

         [[-0.0231, -0.0357, -0.0354],
          [ 0.0030, -0.0056, -0.0424],
          [-0.0286, -0.0298, -0.0682]],

         [[-0.0229, -0.0305, -0.0379],
          [-0.0056, -0.0112, -0.0483],
          [-0.0240, -0.0243, -0.0663]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0070,  0.0032,  0.0034],
          [ 0.0096,  0.0065,  0.0068],
          [ 0.0061,  0.0039,  0.0034]],

         [[ 0.0061,  0.0030,  0.0039],
          [ 0.0077,  0.0053,  0.0059],
          [ 0.0032,  0.0012,  0.0008]],

         [[ 0.0031,  0.0008,  0.0020],
          [ 0.0037,  0.0021,  0.0029],
          [-0.0015, -0.0029, -0.0028]]],


        [[[ 0.0113,  0.0072,  0.0063],
          [ 0.0121,  0.0073,  0.0054],
          [ 0.0003, -0.0014, -0.0029]],

         [[ 0.0090,  0.0022,  0.0021],
          [ 0.0099,  0.0036,  0.0024],
          [-0.0021, -0.0042, -0.0055]],

         [[ 0.0088,  0.0023,  0.0018],
          [ 0.0094,  0.0042,  0.0031],
          [-0.0025, -0.0045, -0.0055]]],


        [[[-0.0042, -0.0030, -0.0078],
          [ 0.0042, -0.0005, -0.0086],
          [-0.0027, -0.0091, -0.0165]],

         [[-0.0010, -0.0009, -0.0057],
          [ 0.0052,  0.0009, -0.0065],
          [ 0.0006, -0.0044, -0.0112]],

         [[ 0.0010,  0.0012, -0.0032],
          [ 0.0081,  0.0042, -0.0027],
          [ 0.0038, -0.0003, -0.0058]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2645]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 94 | Batch_idx: 0 |  Loss: (0.1226) | Acc: (96.00%) (123/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.1743) | Acc: (94.00%) (1331/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.1728) | Acc: (94.00%) (2540/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.1743) | Acc: (94.00%) (3734/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.1812) | Acc: (93.00%) (4927/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.1858) | Acc: (93.00%) (6116/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.1907) | Acc: (93.00%) (7293/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.1964) | Acc: (93.00%) (8481/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.1995) | Acc: (93.00%) (9664/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2014) | Acc: (93.00%) (10855/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2065) | Acc: (92.00%) (12020/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2083) | Acc: (92.00%) (13204/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2072) | Acc: (92.00%) (14399/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2075) | Acc: (92.00%) (15592/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2056) | Acc: (93.00%) (16788/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2050) | Acc: (93.00%) (17980/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2068) | Acc: (92.00%) (19158/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2079) | Acc: (92.00%) (20336/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2087) | Acc: (92.00%) (21524/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2106) | Acc: (92.00%) (22704/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2110) | Acc: (92.00%) (23893/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2124) | Acc: (92.00%) (25074/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2124) | Acc: (92.00%) (26260/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2121) | Acc: (92.00%) (27458/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2113) | Acc: (92.00%) (28662/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2116) | Acc: (92.00%) (29844/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2114) | Acc: (92.00%) (31030/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2123) | Acc: (92.00%) (32207/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2123) | Acc: (92.00%) (33395/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2118) | Acc: (92.00%) (34588/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2109) | Acc: (92.00%) (35787/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2109) | Acc: (92.00%) (36969/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2100) | Acc: (92.00%) (38160/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2090) | Acc: (92.00%) (39366/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2088) | Acc: (92.00%) (40553/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2097) | Acc: (92.00%) (41729/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2103) | Acc: (92.00%) (42905/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2105) | Acc: (92.00%) (44090/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2100) | Acc: (92.00%) (45282/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2105) | Acc: (92.00%) (46424/50000)
# TEST : Loss: (0.3326) | Acc: (89.00%) (8930/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-8.9312e-02, -7.1183e-02, -5.3643e-02],
          [-2.1144e-02, -2.3109e-02,  2.8899e-02],
          [-8.8835e-04, -6.7370e-02, -1.0053e-01]],

         [[-6.0769e-02, -4.9566e-02, -3.8632e-02],
          [-1.0506e-01,  1.5105e-02,  2.7040e-02],
          [-7.5665e-03,  5.1674e-02, -2.2153e-02]],

         [[-8.3218e-02,  5.1644e-02, -1.2293e-01],
          [ 1.2037e-01,  2.6726e-01,  1.4288e-01],
          [ 1.2954e-02,  1.9069e-01,  1.2302e-01]]],


        [[[ 3.4611e-01, -4.0984e-02,  2.3134e-01],
          [ 1.5032e-01, -4.6076e-03, -1.7871e-01],
          [-2.2778e-01, -2.9403e-01, -2.4342e-01]],

         [[ 3.1091e-03, -2.6118e-01, -3.0273e-03],
          [-9.6175e-02,  3.9608e-01, -2.0657e-01],
          [ 1.9108e-01,  1.0796e-01,  2.3575e-01]],

         [[-1.8246e-01, -2.2676e-01, -5.3669e-02],
          [-2.2340e-01,  1.5881e-01, -3.2926e-02],
          [ 1.5940e-02,  1.5443e-01,  2.5028e-01]]],


        [[[-2.3371e-41, -3.6006e-41,  5.8120e-41],
          [ 5.3499e-41,  4.7472e-41,  2.8920e-41],
          [ 6.2089e-41,  5.7542e-41,  2.3591e-41]],

         [[-2.7840e-41, -2.6471e-41,  4.1449e-41],
          [ 2.7391e-41, -3.0780e-41,  2.4852e-41],
          [ 3.5450e-41,  6.2229e-41, -5.8150e-41]],

         [[ 6.6745e-41,  1.0594e-42,  6.3197e-41],
          [-2.8228e-41, -2.2754e-41,  1.6782e-41],
          [ 1.3245e-41,  6.6925e-41,  6.1916e-41]]],


        ...,


        [[[ 4.8043e-02,  3.1438e-02, -4.3620e-02],
          [ 2.4787e-02,  5.3251e-02, -1.7319e-02],
          [-1.6728e-01,  4.2325e-03,  2.8989e-02]],

         [[-1.1411e-01, -1.6939e-01, -2.6132e-02],
          [ 7.8616e-02, -1.8817e-03, -1.4351e-01],
          [ 9.4293e-02, -5.7725e-02, -3.4244e-02]],

         [[ 6.2359e-02,  1.4743e-01,  1.2522e-01],
          [ 3.1104e-01,  4.0918e-01,  1.7773e-01],
          [ 2.6189e-01,  2.3105e-01,  5.7526e-02]]],


        [[[ 2.6954e-01,  3.8291e-02,  9.4596e-02],
          [ 1.1039e-01, -9.1229e-02, -7.1588e-02],
          [ 1.5263e-02,  1.1087e-01,  3.9044e-02]],

         [[-4.9721e-02, -2.9467e-01, -4.8689e-02],
          [-4.5741e-02, -3.2209e-01, -2.7543e-01],
          [ 1.4786e-02, -5.3774e-02, -6.9195e-02]],

         [[ 8.4899e-02, -2.0867e-01, -5.5538e-02],
          [-2.1497e-04, -9.0500e-02, -3.7974e-02],
          [-2.8439e-02,  5.3985e-02,  1.2375e-01]]],


        [[[ 4.1949e-02, -2.0659e-01, -4.3564e-03],
          [-1.9656e-01, -5.2158e-01, -2.4824e-01],
          [ 1.3822e-01, -5.4632e-02, -3.1472e-02]],

         [[ 1.6349e-01, -2.3245e-01,  8.9962e-03],
          [ 3.4149e-02, -2.2100e-01,  5.1061e-02],
          [ 1.9769e-01,  2.1877e-01,  5.0870e-02]],

         [[ 5.5065e-02, -2.2045e-01,  9.4938e-02],
          [ 9.4615e-02, -6.3185e-02,  8.7373e-02],
          [-7.3820e-02,  2.3968e-02,  1.2448e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0010,  0.0002,  0.0003],
          [-0.0000, -0.0009, -0.0010],
          [-0.0005, -0.0011, -0.0012]],

         [[ 0.0016,  0.0008,  0.0008],
          [ 0.0003, -0.0006, -0.0007],
          [-0.0001, -0.0008, -0.0009]],

         [[ 0.0029,  0.0022,  0.0020],
          [ 0.0014,  0.0007,  0.0005],
          [ 0.0009,  0.0004,  0.0003]]],


        [[[-0.0417, -0.0053,  0.0171],
          [-0.0091, -0.0102, -0.0094],
          [-0.0223, -0.0432, -0.0473]],

         [[-0.0134,  0.0308,  0.0452],
          [ 0.0177,  0.0247,  0.0357],
          [-0.0088, -0.0220, -0.0255]],

         [[-0.0252,  0.0175,  0.0298],
          [ 0.0146,  0.0297,  0.0407],
          [ 0.0038,  0.0003, -0.0043]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0086,  0.0109,  0.0096],
          [ 0.0103,  0.0116,  0.0112],
          [ 0.0030,  0.0057,  0.0039]],

         [[ 0.0014,  0.0058,  0.0048],
          [ 0.0021,  0.0058,  0.0064],
          [-0.0043,  0.0002, -0.0011]],

         [[-0.0001,  0.0045,  0.0037],
          [-0.0006,  0.0040,  0.0061],
          [-0.0065, -0.0009, -0.0003]]],


        [[[-0.0097, -0.0030, -0.0041],
          [-0.0128, -0.0078, -0.0056],
          [-0.0136, -0.0133, -0.0162]],

         [[-0.0085, -0.0034, -0.0031],
          [-0.0083, -0.0057, -0.0032],
          [-0.0104, -0.0116, -0.0149]],

         [[-0.0092, -0.0052, -0.0048],
          [-0.0074, -0.0049, -0.0028],
          [-0.0080, -0.0080, -0.0112]]],


        [[[-0.0194, -0.0043, -0.0011],
          [-0.0054,  0.0045,  0.0074],
          [ 0.0059,  0.0041, -0.0006]],

         [[-0.0077,  0.0094,  0.0112],
          [ 0.0107,  0.0204,  0.0212],
          [ 0.0203,  0.0172,  0.0119]],

         [[-0.0146,  0.0034,  0.0037],
          [ 0.0075,  0.0186,  0.0173],
          [ 0.0207,  0.0194,  0.0130]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2635]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 95 | Batch_idx: 0 |  Loss: (0.2191) | Acc: (92.00%) (118/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2219) | Acc: (92.00%) (1303/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2514) | Acc: (91.00%) (2455/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2706) | Acc: (90.00%) (3596/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2697) | Acc: (90.00%) (4754/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2677) | Acc: (90.00%) (5917/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2634) | Acc: (90.00%) (7093/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2597) | Acc: (90.00%) (8269/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2560) | Acc: (91.00%) (9446/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2521) | Acc: (91.00%) (10632/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2468) | Acc: (91.00%) (11824/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2473) | Acc: (91.00%) (12988/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2470) | Acc: (91.00%) (14170/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2441) | Acc: (91.00%) (15364/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2445) | Acc: (91.00%) (16535/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2412) | Acc: (91.00%) (17729/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2389) | Acc: (91.00%) (18917/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2375) | Acc: (91.00%) (20096/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2367) | Acc: (91.00%) (21277/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2375) | Acc: (91.00%) (22447/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2362) | Acc: (91.00%) (23632/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2346) | Acc: (91.00%) (24820/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2336) | Acc: (91.00%) (26011/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2318) | Acc: (92.00%) (27203/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2312) | Acc: (92.00%) (28391/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2292) | Acc: (92.00%) (29588/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2278) | Acc: (92.00%) (30778/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2269) | Acc: (92.00%) (31969/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2251) | Acc: (92.00%) (33182/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2237) | Acc: (92.00%) (34387/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2240) | Acc: (92.00%) (35565/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2224) | Acc: (92.00%) (36760/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2226) | Acc: (92.00%) (37934/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2224) | Acc: (92.00%) (39120/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2221) | Acc: (92.00%) (40302/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2209) | Acc: (92.00%) (41501/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2197) | Acc: (92.00%) (42708/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2193) | Acc: (92.00%) (43898/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2187) | Acc: (92.00%) (45102/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2180) | Acc: (92.00%) (46255/50000)
# TEST : Loss: (0.3161) | Acc: (89.00%) (8965/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-8.5930e-02, -6.7611e-02, -5.1249e-02],
          [-2.1113e-02, -2.2046e-02,  2.7838e-02],
          [-1.6419e-03, -6.4656e-02, -9.6160e-02]],

         [[-5.9249e-02, -4.7370e-02, -3.7084e-02],
          [-1.0104e-01,  1.4876e-02,  2.6474e-02],
          [-7.7317e-03,  4.9731e-02, -2.0440e-02]],

         [[-8.2213e-02,  4.7753e-02, -1.1929e-01],
          [ 1.1314e-01,  2.5405e-01,  1.3575e-01],
          [ 1.0960e-02,  1.8094e-01,  1.1683e-01]]],


        [[[ 3.4534e-01, -4.2316e-02,  2.2821e-01],
          [ 1.4871e-01, -6.2780e-03, -1.8139e-01],
          [-2.2819e-01, -2.9363e-01, -2.4432e-01]],

         [[ 1.2190e-03, -2.6333e-01, -6.5811e-03],
          [-9.8899e-02,  3.9286e-01, -2.1058e-01],
          [ 1.8913e-01,  1.0709e-01,  2.3341e-01]],

         [[-1.8405e-01, -2.2840e-01, -5.6328e-02],
          [-2.2572e-01,  1.5607e-01, -3.6689e-02],
          [ 1.4096e-02,  1.5370e-01,  2.4794e-01]]],


        [[[-2.7726e-41, -4.9286e-41,  1.8185e-41],
          [-6.9881e-41, -2.4289e-41, -3.7947e-42],
          [ 2.3194e-41, -1.6957e-41, -2.8018e-41]],

         [[ 4.3038e-41,  4.4672e-41, -1.0644e-41],
          [ 3.3900e-41,  1.2655e-41,  2.4901e-41],
          [-6.9765e-41,  7.4117e-41,  1.5924e-41]],

         [[-9.1981e-42,  8.3868e-42,  1.7847e-41],
          [-9.2640e-42, -7.3883e-41, -5.3936e-42],
          [-4.8088e-41,  1.5926e-41, -3.6567e-41]]],


        ...,


        [[[ 4.7993e-02,  3.2671e-02, -4.1498e-02],
          [ 2.3842e-02,  5.3315e-02, -1.6727e-02],
          [-1.6736e-01,  3.8776e-03,  2.8699e-02]],

         [[-1.1265e-01, -1.6650e-01, -2.3941e-02],
          [ 7.7580e-02, -9.7720e-04, -1.4180e-01],
          [ 9.2780e-02, -5.7286e-02, -3.3898e-02]],

         [[ 6.2654e-02,  1.4793e-01,  1.2585e-01],
          [ 3.0541e-01,  4.0362e-01,  1.7569e-01],
          [ 2.5722e-01,  2.2761e-01,  5.6349e-02]]],


        [[[ 2.6983e-01,  3.9660e-02,  9.5247e-02],
          [ 1.1070e-01, -8.9341e-02, -7.0526e-02],
          [ 1.5621e-02,  1.1115e-01,  3.9536e-02]],

         [[-4.7786e-02, -2.8952e-01, -4.7519e-02],
          [-4.4970e-02, -3.1581e-01, -2.7177e-01],
          [ 1.4824e-02, -5.2397e-02, -6.8284e-02]],

         [[ 8.6512e-02, -2.0169e-01, -5.1789e-02],
          [ 1.0383e-03, -8.5213e-02, -3.5367e-02],
          [-2.7432e-02,  5.5387e-02,  1.2389e-01]]],


        [[[ 4.1790e-02, -2.0708e-01, -6.3047e-03],
          [-1.9648e-01, -5.2018e-01, -2.4946e-01],
          [ 1.3605e-01, -5.5894e-02, -3.3077e-02]],

         [[ 1.6169e-01, -2.3425e-01,  5.8617e-03],
          [ 3.1883e-02, -2.2343e-01,  4.7096e-02],
          [ 1.9442e-01,  2.1542e-01,  4.7887e-02]],

         [[ 5.3991e-02, -2.2181e-01,  9.1896e-02],
          [ 9.2235e-02, -6.6114e-02,  8.3317e-02],
          [-7.6235e-02,  2.1142e-02,  1.2083e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1763]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0348]], device='cuda:0')

Epoch: 96 | Batch_idx: 0 |  Loss: (0.1576) | Acc: (92.00%) (119/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.1988) | Acc: (93.00%) (1310/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.1927) | Acc: (93.00%) (2508/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.1939) | Acc: (93.00%) (3693/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.1892) | Acc: (93.00%) (4903/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.1917) | Acc: (93.00%) (6088/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.1902) | Acc: (93.00%) (7289/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.1863) | Acc: (93.00%) (8494/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.1866) | Acc: (93.00%) (9699/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.1868) | Acc: (93.00%) (10896/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.1878) | Acc: (93.00%) (12087/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.1890) | Acc: (93.00%) (13281/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.1915) | Acc: (93.00%) (14469/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.1912) | Acc: (93.00%) (15661/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.1897) | Acc: (93.00%) (16868/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.1903) | Acc: (93.00%) (18058/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.1906) | Acc: (93.00%) (19256/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.1898) | Acc: (93.00%) (20466/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.1901) | Acc: (93.00%) (21667/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.1892) | Acc: (93.00%) (22878/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.1896) | Acc: (93.00%) (24062/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.1896) | Acc: (93.00%) (25262/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.1908) | Acc: (93.00%) (26454/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.1895) | Acc: (93.00%) (27663/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.1902) | Acc: (93.00%) (28856/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.1901) | Acc: (93.00%) (30053/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.1894) | Acc: (93.00%) (31258/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.1905) | Acc: (93.00%) (32439/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.1898) | Acc: (93.00%) (33641/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.1894) | Acc: (93.00%) (34844/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.1892) | Acc: (93.00%) (36045/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.1901) | Acc: (93.00%) (37238/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.1898) | Acc: (93.00%) (38445/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.1902) | Acc: (93.00%) (39642/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.1902) | Acc: (93.00%) (40837/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.1904) | Acc: (93.00%) (42034/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.1907) | Acc: (93.00%) (43225/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.1907) | Acc: (93.00%) (44438/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.1905) | Acc: (93.00%) (45638/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.1915) | Acc: (93.00%) (46781/50000)
# TEST : Loss: (0.3076) | Acc: (89.00%) (8978/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-8.0791e-02, -6.3613e-02, -4.8214e-02],
          [-1.9992e-02, -2.0912e-02,  2.6386e-02],
          [-1.5557e-03, -6.1422e-02, -9.1263e-02]],

         [[-5.5927e-02, -4.4706e-02, -3.4986e-02],
          [-9.5537e-02,  1.4060e-02,  2.5006e-02],
          [-7.3085e-03,  4.7026e-02, -1.9312e-02]],

         [[-7.7921e-02,  4.5275e-02, -1.1309e-01],
          [ 1.0692e-01,  2.3975e-01,  1.2807e-01],
          [ 1.0336e-02,  1.7048e-01,  1.1002e-01]]],


        [[[ 3.4494e-01, -4.2267e-02,  2.2795e-01],
          [ 1.4853e-01, -6.2703e-03, -1.8118e-01],
          [-2.2792e-01, -2.9329e-01, -2.4403e-01]],

         [[ 1.2176e-03, -2.6302e-01, -6.5732e-03],
          [-9.8778e-02,  3.9237e-01, -2.1032e-01],
          [ 1.8890e-01,  1.0696e-01,  2.3313e-01]],

         [[-1.8382e-01, -2.2810e-01, -5.6254e-02],
          [-2.2542e-01,  1.5587e-01, -3.6641e-02],
          [ 1.4078e-02,  1.5350e-01,  2.4762e-01]]],


        [[[ 6.2014e-41, -3.9128e-41,  9.6690e-43],
          [ 5.6429e-41,  4.0887e-41, -7.3837e-41],
          [-6.9420e-42, -1.9980e-41, -4.9645e-41]],

         [[-5.6240e-41, -5.4120e-41, -7.0513e-41],
          [-4.8987e-41,  5.8590e-41,  2.3776e-41],
          [-2.7636e-41,  3.4266e-41,  8.0238e-41]],

         [[-4.3132e-41,  3.5579e-41, -7.9741e-41],
          [ 3.6012e-41, -2.4263e-41, -2.5347e-41],
          [-7.5816e-41, -8.0869e-41, -1.3689e-41]]],


        ...,


        [[[ 4.7670e-02,  3.2454e-02, -4.1234e-02],
          [ 2.3675e-02,  5.2948e-02, -1.6616e-02],
          [-1.6622e-01,  3.8515e-03,  2.8512e-02]],

         [[-1.1169e-01, -1.6512e-01, -2.3759e-02],
          [ 7.6826e-02, -9.6796e-04, -1.4059e-01],
          [ 9.1930e-02, -5.6768e-02, -3.3617e-02]],

         [[ 6.1884e-02,  1.4614e-01,  1.2457e-01],
          [ 2.9875e-01,  3.9495e-01,  1.7323e-01],
          [ 2.5269e-01,  2.2349e-01,  5.5617e-02]]],


        [[[ 2.6792e-01,  3.9307e-02,  9.4411e-02],
          [ 1.0988e-01, -8.8495e-02, -6.9864e-02],
          [ 1.5515e-02,  1.1029e-01,  3.9236e-02]],

         [[-4.7354e-02, -2.8514e-01, -4.6840e-02],
          [-4.4526e-02, -3.0986e-01, -2.6687e-01],
          [ 1.4704e-02, -5.1860e-02, -6.7614e-02]],

         [[ 8.5592e-02, -1.9810e-01, -5.0924e-02],
          [ 1.0262e-03, -8.3445e-02, -3.4659e-02],
          [-2.7178e-02,  5.4743e-02,  1.2253e-01]]],


        [[[ 4.1560e-02, -2.0526e-01, -6.2639e-03],
          [-1.9534e-01, -5.1500e-01, -2.4773e-01],
          [ 1.3547e-01, -5.5612e-02, -3.2921e-02]],

         [[ 1.6093e-01, -2.3285e-01,  5.8315e-03],
          [ 3.1731e-02, -2.2206e-01,  4.6847e-02],
          [ 1.9367e-01,  2.1449e-01,  4.7690e-02]],

         [[ 5.3750e-02, -2.2067e-01,  9.1464e-02],
          [ 9.1821e-02, -6.5777e-02,  8.2924e-02],
          [-7.5941e-02,  2.1054e-02,  1.2034e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2139]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0044]], device='cuda:0')

Epoch: 97 | Batch_idx: 0 |  Loss: (0.1730) | Acc: (95.00%) (122/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.1791) | Acc: (94.00%) (1324/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.1843) | Acc: (94.00%) (2529/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.1876) | Acc: (93.00%) (3716/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.1929) | Acc: (93.00%) (4909/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.1928) | Acc: (93.00%) (6108/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.1896) | Acc: (93.00%) (7315/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.1872) | Acc: (93.00%) (8525/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.1904) | Acc: (93.00%) (9713/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.1919) | Acc: (93.00%) (10893/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.1926) | Acc: (93.00%) (12091/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.1921) | Acc: (93.00%) (13299/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.1901) | Acc: (93.00%) (14511/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.1900) | Acc: (93.00%) (15720/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.1905) | Acc: (93.00%) (16913/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.1906) | Acc: (93.00%) (18113/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.1919) | Acc: (93.00%) (19300/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.1911) | Acc: (93.00%) (20508/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.1914) | Acc: (93.00%) (21698/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.1912) | Acc: (93.00%) (22897/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.1910) | Acc: (93.00%) (24099/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.1903) | Acc: (93.00%) (25315/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.1910) | Acc: (93.00%) (26501/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.1917) | Acc: (93.00%) (27683/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.1922) | Acc: (93.00%) (28879/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.1937) | Acc: (93.00%) (30067/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.1929) | Acc: (93.00%) (31279/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.1926) | Acc: (93.00%) (32479/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.1937) | Acc: (93.00%) (33657/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.1937) | Acc: (93.00%) (34847/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.1935) | Acc: (93.00%) (36043/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.1924) | Acc: (93.00%) (37251/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.1919) | Acc: (93.00%) (38451/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.1923) | Acc: (93.00%) (39638/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.1939) | Acc: (93.00%) (40809/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.1947) | Acc: (93.00%) (41994/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.1945) | Acc: (93.00%) (43197/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.1942) | Acc: (93.00%) (44401/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.1943) | Acc: (93.00%) (45595/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.1943) | Acc: (93.00%) (46755/50000)
# TEST : Loss: (0.3002) | Acc: (89.00%) (8985/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-7.4953e-02, -5.9067e-02, -4.4764e-02],
          [-1.8709e-02, -1.9611e-02,  2.4720e-02],
          [-1.4569e-03, -5.7706e-02, -8.5641e-02]],

         [[-5.2136e-02, -4.1668e-02, -3.2595e-02],
          [-8.9250e-02,  1.3127e-02,  2.3329e-02],
          [-6.8247e-03,  4.3934e-02, -1.8024e-02]],

         [[-7.3001e-02,  4.2434e-02, -1.0597e-01],
          [ 9.9807e-02,  2.2344e-01,  1.1932e-01],
          [ 9.6258e-03,  1.5858e-01,  1.0227e-01]]],


        [[[ 3.4447e-01, -4.2207e-02,  2.2762e-01],
          [ 1.4832e-01, -6.2610e-03, -1.8091e-01],
          [-2.2760e-01, -2.9287e-01, -2.4368e-01]],

         [[ 1.2159e-03, -2.6263e-01, -6.5636e-03],
          [-9.8632e-02,  3.9177e-01, -2.1000e-01],
          [ 1.8862e-01,  1.0680e-01,  2.3278e-01]],

         [[-1.8354e-01, -2.2773e-01, -5.6164e-02],
          [-2.2507e-01,  1.5561e-01, -3.6582e-02],
          [ 1.4057e-02,  1.5326e-01,  2.4723e-01]]],


        [[[ 3.3085e-42,  1.1042e-41, -2.4313e-41],
          [-5.9799e-41,  6.2340e-41, -3.0761e-41],
          [-5.0979e-41,  4.7812e-41, -7.2956e-41]],

         [[-5.3841e-41,  7.7118e-41, -7.8442e-41],
          [-4.5216e-41,  4.9512e-41,  5.1795e-41],
          [ 6.3745e-41,  1.1506e-41,  1.4215e-41]],

         [[-2.8441e-41,  1.2514e-41,  3.7681e-41],
          [-7.0023e-41,  4.4348e-41, -8.0547e-42],
          [-4.4306e-41,  1.3004e-41, -6.9272e-41]]],


        ...,


        [[[ 4.7280e-02,  3.2193e-02, -4.0916e-02],
          [ 2.3474e-02,  5.2504e-02, -1.6482e-02],
          [-1.6485e-01,  3.8202e-03,  2.8286e-02]],

         [[-1.1054e-01, -1.6345e-01, -2.3539e-02],
          [ 7.5918e-02, -9.5683e-04, -1.3913e-01],
          [ 9.0908e-02, -5.6145e-02, -3.3277e-02]],

         [[ 6.0961e-02,  1.4399e-01,  1.2302e-01],
          [ 2.9084e-01,  3.8467e-01,  1.7028e-01],
          [ 2.4729e-01,  2.1858e-01,  5.4739e-02]]],


        [[[ 2.6561e-01,  3.8882e-02,  9.3403e-02],
          [ 1.0889e-01, -8.7476e-02, -6.9067e-02],
          [ 1.5387e-02,  1.0926e-01,  3.8875e-02]],

         [[-4.6834e-02, -2.7991e-01, -4.6026e-02],
          [-4.3991e-02, -3.0278e-01, -2.6103e-01],
          [ 1.4560e-02, -5.1214e-02, -6.6807e-02]],

         [[ 8.4488e-02, -1.9383e-01, -4.9891e-02],
          [ 1.0118e-03, -8.1345e-02, -3.3818e-02],
          [-2.6873e-02,  5.3969e-02,  1.2089e-01]]],


        [[[ 4.1281e-02, -2.0307e-01, -6.2146e-03],
          [-1.9396e-01, -5.0878e-01, -2.4563e-01],
          [ 1.3477e-01, -5.5271e-02, -3.2733e-02]],

         [[ 1.6002e-01, -2.3116e-01,  5.7949e-03],
          [ 3.1548e-02, -2.2040e-01,  4.6547e-02],
          [ 1.9277e-01,  2.1336e-01,  4.7450e-02]],

         [[ 5.3458e-02, -2.1931e-01,  9.0940e-02],
          [ 9.1319e-02, -6.5368e-02,  8.2449e-02],
          [-7.5585e-02,  2.0947e-02,  1.1975e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1988]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0482]], device='cuda:0')

Epoch: 98 | Batch_idx: 0 |  Loss: (0.1079) | Acc: (97.00%) (125/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.1762) | Acc: (95.00%) (1339/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.1744) | Acc: (94.00%) (2548/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.1769) | Acc: (94.00%) (3756/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.1819) | Acc: (94.00%) (4952/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.1886) | Acc: (94.00%) (6138/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.1895) | Acc: (93.00%) (7328/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.1914) | Acc: (93.00%) (8518/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.1937) | Acc: (93.00%) (9706/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.1953) | Acc: (93.00%) (10898/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.1933) | Acc: (93.00%) (12107/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.1944) | Acc: (93.00%) (13302/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.1967) | Acc: (93.00%) (14476/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.1949) | Acc: (93.00%) (15692/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.1969) | Acc: (93.00%) (16874/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.1962) | Acc: (93.00%) (18081/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.1949) | Acc: (93.00%) (19284/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.1959) | Acc: (93.00%) (20467/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.1968) | Acc: (93.00%) (21664/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.1957) | Acc: (93.00%) (22870/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.1970) | Acc: (93.00%) (24051/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.1969) | Acc: (93.00%) (25251/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.1971) | Acc: (93.00%) (26446/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.1979) | Acc: (93.00%) (27637/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.1972) | Acc: (93.00%) (28848/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.1963) | Acc: (93.00%) (30063/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.1956) | Acc: (93.00%) (31267/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.1956) | Acc: (93.00%) (32458/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.1963) | Acc: (93.00%) (33643/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.1957) | Acc: (93.00%) (34844/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.1958) | Acc: (93.00%) (36032/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.1950) | Acc: (93.00%) (37245/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.1956) | Acc: (93.00%) (38432/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.1954) | Acc: (93.00%) (39635/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.1948) | Acc: (93.00%) (40838/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.1942) | Acc: (93.00%) (42049/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.1943) | Acc: (93.00%) (43240/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.1945) | Acc: (93.00%) (44435/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.1945) | Acc: (93.00%) (45630/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.1950) | Acc: (93.00%) (46773/50000)
# TEST : Loss: (0.2976) | Acc: (89.00%) (8998/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-6.8417e-02, -5.3973e-02, -4.0898e-02],
          [-1.7258e-02, -1.8137e-02,  2.2836e-02],
          [-1.3452e-03, -5.3488e-02, -7.9268e-02]],

         [[-4.7870e-02, -3.8248e-02, -2.9904e-02],
          [-8.2157e-02,  1.2075e-02,  2.1440e-02],
          [-6.2792e-03,  4.0445e-02, -1.6572e-02]],

         [[-6.7433e-02,  3.9217e-02, -9.7915e-02],
          [ 9.1794e-02,  2.0510e-01,  1.0947e-01],
          [ 8.8269e-03,  1.4521e-01,  9.3572e-02]]],


        [[[ 3.4388e-01, -4.2134e-02,  2.2723e-01],
          [ 1.4806e-01, -6.2498e-03, -1.8058e-01],
          [-2.2720e-01, -2.9235e-01, -2.4326e-01]],

         [[ 1.2138e-03, -2.6216e-01, -6.5519e-03],
          [-9.8454e-02,  3.9104e-01, -2.0962e-01],
          [ 1.8828e-01,  1.0661e-01,  2.3236e-01]],

         [[-1.8319e-01, -2.2729e-01, -5.6055e-02],
          [-2.2464e-01,  1.5531e-01, -3.6511e-02],
          [ 1.4031e-02,  1.5297e-01,  2.4676e-01]]],


        [[[-3.8691e-41,  3.2538e-42, -7.8436e-41],
          [ 6.0714e-41, -7.3170e-41,  7.1682e-41],
          [-8.4937e-41, -7.3410e-41, -2.5406e-42]],

         [[-1.4638e-41, -4.5099e-41, -8.5787e-41],
          [-2.8284e-41, -8.6306e-41,  6.5497e-42],
          [-8.8800e-42,  2.5888e-41,  5.2871e-42]],

         [[ 8.8240e-42, -7.1203e-41, -3.2804e-41],
          [-1.9052e-41,  2.1538e-42,  6.9290e-41],
          [ 1.9303e-41,  8.9197e-41,  7.8469e-41]]],


        ...,


        [[[ 4.6810e-02,  3.1877e-02, -4.0532e-02],
          [ 2.3231e-02,  5.1970e-02, -1.6321e-02],
          [-1.6320e-01,  3.7823e-03,  2.8013e-02]],

         [[-1.0916e-01, -1.6145e-01, -2.3274e-02],
          [ 7.4829e-02, -9.4348e-04, -1.3738e-01],
          [ 8.9680e-02, -5.5396e-02, -3.2870e-02]],

         [[ 5.9856e-02,  1.4143e-01,  1.2118e-01],
          [ 2.8150e-01,  3.7252e-01,  1.6676e-01],
          [ 2.4088e-01,  2.1275e-01,  5.3690e-02]]],


        [[[ 2.6283e-01,  3.8372e-02,  9.2193e-02],
          [ 1.0769e-01, -8.6252e-02, -6.8110e-02],
          [ 1.5233e-02,  1.0802e-01,  3.8440e-02]],

         [[-4.6209e-02, -2.7367e-01, -4.5056e-02],
          [-4.3350e-02, -2.9438e-01, -2.5410e-01],
          [ 1.4386e-02, -5.0439e-02, -6.5839e-02]],

         [[ 8.3163e-02, -1.8876e-01, -4.8663e-02],
          [ 9.9449e-04, -7.8861e-02, -3.2822e-02],
          [-2.6506e-02,  5.3043e-02,  1.1892e-01]]],


        [[[ 4.0945e-02, -2.0045e-01, -6.1552e-03],
          [-1.9229e-01, -5.0131e-01, -2.4311e-01],
          [ 1.3393e-01, -5.4858e-02, -3.2506e-02]],

         [[ 1.5892e-01, -2.2912e-01,  5.7507e-03],
          [ 3.1326e-02, -2.1841e-01,  4.6185e-02],
          [ 1.9168e-01,  2.1200e-01,  4.7161e-02]],

         [[ 5.3106e-02, -2.1765e-01,  9.0307e-02],
          [ 9.0713e-02, -6.4875e-02,  8.1875e-02],
          [-7.5154e-02,  2.0819e-02,  1.1903e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2018]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0317]], device='cuda:0')

Epoch: 99 | Batch_idx: 0 |  Loss: (0.1522) | Acc: (96.00%) (123/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.1827) | Acc: (94.00%) (1325/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.1856) | Acc: (93.00%) (2525/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.1900) | Acc: (93.00%) (3717/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.1887) | Acc: (93.00%) (4929/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.1879) | Acc: (93.00%) (6132/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.1887) | Acc: (93.00%) (7323/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.1927) | Acc: (93.00%) (8514/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.1928) | Acc: (93.00%) (9712/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.1925) | Acc: (93.00%) (10912/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.1924) | Acc: (93.00%) (12116/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.1953) | Acc: (93.00%) (13299/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.1979) | Acc: (93.00%) (14496/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.1961) | Acc: (93.00%) (15711/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.1948) | Acc: (93.00%) (16911/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.1956) | Acc: (93.00%) (18106/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.1957) | Acc: (93.00%) (19304/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.1966) | Acc: (93.00%) (20486/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.1978) | Acc: (93.00%) (21673/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.1982) | Acc: (93.00%) (22860/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.1969) | Acc: (93.00%) (24069/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.1969) | Acc: (93.00%) (25266/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.1969) | Acc: (93.00%) (26465/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.1971) | Acc: (93.00%) (27669/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.1975) | Acc: (93.00%) (28863/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.1984) | Acc: (93.00%) (30046/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.1978) | Acc: (93.00%) (31242/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.1975) | Acc: (93.00%) (32445/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.1983) | Acc: (93.00%) (33644/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.1991) | Acc: (93.00%) (34837/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.1996) | Acc: (93.00%) (36036/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2003) | Acc: (93.00%) (37216/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2001) | Acc: (93.00%) (38417/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2003) | Acc: (93.00%) (39615/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2007) | Acc: (93.00%) (40805/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2005) | Acc: (93.00%) (42006/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2010) | Acc: (93.00%) (43203/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2012) | Acc: (93.00%) (44403/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2009) | Acc: (93.00%) (45609/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2012) | Acc: (93.00%) (46758/50000)
# TEST : Loss: (0.2982) | Acc: (89.00%) (8990/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-6.1229e-02, -4.8364e-02, -3.6643e-02],
          [-1.5644e-02, -1.6493e-02,  2.0736e-02],
          [-1.2207e-03, -4.8769e-02, -7.2151e-02]],

         [[-4.3147e-02, -3.4464e-02, -2.6929e-02],
          [-7.4284e-02,  1.0908e-02,  1.9347e-02],
          [-5.6740e-03,  3.6572e-02, -1.4963e-02]],

         [[-6.1230e-02,  3.5630e-02, -8.8938e-02],
          [ 8.2908e-02,  1.8481e-01,  9.8585e-02],
          [ 7.9439e-03,  1.3045e-01,  8.3986e-02]]],


        [[[ 3.4318e-01, -4.2045e-02,  2.2676e-01],
          [ 1.4774e-01, -6.2361e-03, -1.8019e-01],
          [-2.2672e-01, -2.9173e-01, -2.4275e-01]],

         [[ 1.2112e-03, -2.6158e-01, -6.5377e-03],
          [-9.8237e-02,  3.9016e-01, -2.0915e-01],
          [ 1.8787e-01,  1.0637e-01,  2.3186e-01]],

         [[-1.8278e-01, -2.2675e-01, -5.5923e-02],
          [-2.2412e-01,  1.5494e-01, -3.6424e-02],
          [ 1.3999e-02,  1.5262e-01,  2.4619e-01]]],


        [[[ 3.1313e-41, -5.7251e-41, -5.7167e-41],
          [-9.0877e-41, -4.9693e-41,  8.0806e-41],
          [-3.6731e-41,  1.7235e-41,  3.4074e-41]],

         [[-5.5236e-41, -8.9190e-41, -5.2580e-41],
          [ 2.2602e-41,  9.5997e-41,  5.3370e-41],
          [-1.0113e-41, -4.9293e-41,  2.0584e-41]],

         [[-4.1488e-41, -5.6032e-41,  9.4233e-41],
          [-5.4160e-41, -2.7970e-41,  1.3818e-41],
          [ 7.3400e-41,  9.7507e-41,  4.5174e-41]]],


        ...,


        [[[ 4.6245e-02,  3.1497e-02, -4.0070e-02],
          [ 2.2940e-02,  5.1328e-02, -1.6126e-02],
          [-1.6122e-01,  3.7368e-03,  2.7685e-02]],

         [[-1.0750e-01, -1.5905e-01, -2.2957e-02],
          [ 7.3526e-02, -9.2749e-04, -1.3527e-01],
          [ 8.8209e-02, -5.4499e-02, -3.2381e-02]],

         [[ 5.8540e-02,  1.3837e-01,  1.1897e-01],
          [ 2.7055e-01,  3.5827e-01,  1.6259e-01],
          [ 2.3331e-01,  2.0588e-01,  5.2442e-02]]],


        [[[ 2.5949e-01,  3.7760e-02,  9.0742e-02],
          [ 1.0626e-01, -8.4788e-02, -6.6965e-02],
          [ 1.5047e-02,  1.0652e-01,  3.7918e-02]],

         [[-4.5460e-02, -2.6627e-01, -4.3903e-02],
          [-4.2582e-02, -2.8449e-01, -2.4593e-01],
          [ 1.4177e-02, -4.9513e-02, -6.4681e-02]],

         [[ 8.1581e-02, -1.8277e-01, -4.7211e-02],
          [ 9.7385e-04, -7.5943e-02, -3.1650e-02],
          [-2.6066e-02,  5.1938e-02,  1.1658e-01]]],


        [[[ 4.0539e-02, -1.9730e-01, -6.0838e-03],
          [-1.9028e-01, -4.9237e-01, -2.4007e-01],
          [ 1.3291e-01, -5.4361e-02, -3.2231e-02]],

         [[ 1.5759e-01, -2.2666e-01,  5.6975e-03],
          [ 3.1058e-02, -2.1600e-01,  4.5748e-02],
          [ 1.9036e-01,  2.1035e-01,  4.6812e-02]],

         [[ 5.2681e-02, -2.1566e-01,  8.9544e-02],
          [ 8.9981e-02, -6.4280e-02,  8.1182e-02],
          [-7.4634e-02,  2.0663e-02,  1.1817e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1932]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0283]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 100 | Batch_idx: 0 |  Loss: (0.1830) | Acc: (96.00%) (123/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2290) | Acc: (92.00%) (1296/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2831) | Acc: (90.00%) (2426/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.3353) | Acc: (88.00%) (3518/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.3760) | Acc: (87.00%) (4581/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.3887) | Acc: (86.00%) (5662/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.3908) | Acc: (86.00%) (6769/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.3980) | Acc: (86.00%) (7851/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.3998) | Acc: (86.00%) (8958/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.4019) | Acc: (86.00%) (10056/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.4034) | Acc: (86.00%) (11153/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.4007) | Acc: (86.00%) (12274/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.3957) | Acc: (86.00%) (13412/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.3921) | Acc: (86.00%) (14534/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.3884) | Acc: (86.00%) (15675/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.3876) | Acc: (86.00%) (16794/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.3866) | Acc: (86.00%) (17915/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.3851) | Acc: (86.00%) (19036/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.3845) | Acc: (86.00%) (20149/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.3820) | Acc: (87.00%) (21281/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.3819) | Acc: (87.00%) (22395/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.3792) | Acc: (87.00%) (23535/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.3758) | Acc: (87.00%) (24672/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.3745) | Acc: (87.00%) (25799/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.3721) | Acc: (87.00%) (26935/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.3702) | Acc: (87.00%) (28077/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.3684) | Acc: (87.00%) (29213/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.3682) | Acc: (87.00%) (30338/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.3663) | Acc: (87.00%) (31487/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.3639) | Acc: (87.00%) (32636/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.3638) | Acc: (87.00%) (33755/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.3625) | Acc: (87.00%) (34892/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.3610) | Acc: (87.00%) (36046/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.3573) | Acc: (87.00%) (37228/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.3550) | Acc: (87.00%) (38378/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.3530) | Acc: (87.00%) (39525/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.3497) | Acc: (88.00%) (40701/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.3482) | Acc: (88.00%) (41852/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.3464) | Acc: (88.00%) (43011/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.3452) | Acc: (88.00%) (44122/50000)
# TEST : Loss: (0.3833) | Acc: (87.00%) (8754/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-4.2632e-02, -2.9520e-02, -1.9335e-02],
          [-8.4012e-04,  5.3004e-04,  3.4303e-02],
          [ 1.6612e-02, -2.6102e-02, -4.7567e-02]],

         [[-3.8432e-02, -2.7221e-02, -2.1082e-02],
          [-6.2153e-02,  1.8338e-02,  2.5719e-02],
          [ 4.9555e-03,  4.5534e-02, -1.7892e-03]],

         [[-5.9407e-02,  3.1777e-02, -8.0371e-02],
          [ 7.3635e-02,  1.6956e-01,  9.3125e-02],
          [ 1.3212e-02,  1.2612e-01,  8.3384e-02]]],


        [[[ 3.4460e-01, -3.6285e-02,  2.4309e-01],
          [ 1.4725e-01, -7.2276e-03, -1.8005e-01],
          [-2.2853e-01, -3.1312e-01, -2.5405e-01]],

         [[-7.7902e-03, -2.6794e-01,  2.0869e-03],
          [-9.3582e-02,  3.9174e-01, -2.0678e-01],
          [ 1.9818e-01,  9.7869e-02,  2.2528e-01]],

         [[-1.8802e-01, -2.3468e-01, -5.2001e-02],
          [-2.2144e-01,  1.5681e-01, -3.0295e-02],
          [ 2.1621e-02,  1.5099e-01,  2.4745e-01]]],


        [[[ 8.2024e-30,  9.4257e-30,  1.0845e-29],
          [ 7.8283e-30,  1.0527e-29,  1.0256e-29],
          [ 9.7523e-30,  1.2079e-29,  1.3756e-29]],

         [[ 8.2445e-30,  9.6637e-30,  5.7661e-30],
          [ 6.9641e-30,  7.0679e-31,  3.7586e-30],
          [ 1.2123e-29,  6.4448e-30,  8.8611e-30]],

         [[ 5.0427e-30,  2.1716e-30, -7.6569e-31],
          [ 6.2553e-30,  2.6949e-31,  3.2227e-30],
          [ 9.8247e-30,  7.0209e-30,  9.2736e-30]]],


        ...,


        [[[ 5.1480e-02,  4.5839e-02, -3.1342e-02],
          [ 3.0756e-02,  6.9016e-02, -4.2459e-03],
          [-1.5312e-01,  2.6078e-02,  4.7210e-02]],

         [[-1.2096e-01, -1.6215e-01, -3.5293e-02],
          [ 6.9933e-02,  7.8044e-03, -1.3856e-01],
          [ 8.4492e-02, -3.8250e-02, -2.6205e-02]],

         [[ 3.1405e-02,  1.3062e-01,  1.0344e-01],
          [ 2.7783e-01,  3.9519e-01,  1.6749e-01],
          [ 2.3503e-01,  2.4988e-01,  6.8264e-02]]],


        [[[ 2.4346e-01,  3.8857e-03,  6.3494e-02],
          [ 7.0261e-02, -1.2084e-01, -8.5051e-02],
          [ 2.4401e-03,  9.6223e-02,  3.2701e-02]],

         [[-4.9628e-02, -2.9719e-01, -6.8878e-02],
          [-6.3772e-02, -3.1213e-01, -2.4434e-01],
          [ 1.3738e-02, -5.1067e-02, -6.4449e-02]],

         [[ 8.7615e-02, -2.0328e-01, -7.1351e-02],
          [-7.3282e-03, -8.0391e-02, -2.1453e-02],
          [-1.6600e-02,  6.7431e-02,  1.2798e-01]]],


        [[[ 4.9777e-02, -1.9335e-01,  5.4914e-03],
          [-2.0858e-01, -5.1483e-01, -2.3451e-01],
          [ 1.2597e-01, -5.4310e-02, -2.0363e-02]],

         [[ 1.6179e-01, -2.2866e-01,  1.0796e-02],
          [ 1.3481e-02, -2.2722e-01,  5.8529e-02],
          [ 1.7980e-01,  2.1193e-01,  6.2715e-02]],

         [[ 4.8917e-02, -2.2772e-01,  8.5335e-02],
          [ 6.7479e-02, -7.9635e-02,  9.0569e-02],
          [-9.1803e-02,  1.5741e-02,  1.3030e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0217,  0.0369,  0.0602],
          [ 0.0366,  0.0641,  0.0792],
          [ 0.0366,  0.0374,  0.0220]],

         [[ 0.0304,  0.0415,  0.0630],
          [ 0.0413,  0.0648,  0.0799],
          [ 0.0350,  0.0332,  0.0171]],

         [[ 0.0162,  0.0276,  0.0555],
          [ 0.0422,  0.0704,  0.0823],
          [ 0.0429,  0.0546,  0.0418]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0094,  0.0119,  0.0137],
          [ 0.0059,  0.0100,  0.0106],
          [ 0.0033,  0.0059,  0.0064]],

         [[ 0.0081,  0.0114,  0.0132],
          [ 0.0027,  0.0069,  0.0076],
          [-0.0012,  0.0014,  0.0016]],

         [[ 0.0059,  0.0089,  0.0112],
          [-0.0001,  0.0036,  0.0051],
          [-0.0049, -0.0025, -0.0014]]],


        [[[-0.0021, -0.0004,  0.0020],
          [ 0.0033,  0.0029,  0.0022],
          [ 0.0091,  0.0068,  0.0071]],

         [[-0.0036, -0.0009,  0.0010],
          [ 0.0010,  0.0009, -0.0002],
          [ 0.0065,  0.0032,  0.0029]],

         [[-0.0020,  0.0009,  0.0025],
          [ 0.0014,  0.0023,  0.0015],
          [ 0.0066,  0.0047,  0.0042]]],


        [[[ 0.0052,  0.0033,  0.0017],
          [ 0.0038, -0.0023, -0.0063],
          [ 0.0016,  0.0004, -0.0019]],

         [[ 0.0054,  0.0048,  0.0032],
          [ 0.0032, -0.0017, -0.0056],
          [ 0.0004, -0.0024, -0.0038]],

         [[ 0.0109,  0.0091,  0.0073],
          [ 0.0086,  0.0044,  0.0012],
          [ 0.0058,  0.0032,  0.0009]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1957]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 101 | Batch_idx: 0 |  Loss: (0.1888) | Acc: (95.00%) (122/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2772) | Acc: (90.00%) (1279/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2716) | Acc: (91.00%) (2449/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2800) | Acc: (90.00%) (3605/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2802) | Acc: (90.00%) (4761/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2852) | Acc: (90.00%) (5904/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2814) | Acc: (90.00%) (7071/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2779) | Acc: (90.00%) (8236/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2766) | Acc: (90.00%) (9396/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2764) | Acc: (90.00%) (10548/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2767) | Acc: (90.00%) (11697/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2757) | Acc: (90.00%) (12860/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2750) | Acc: (90.00%) (14019/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2744) | Acc: (90.00%) (15180/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2773) | Acc: (90.00%) (16332/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2775) | Acc: (90.00%) (17485/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2759) | Acc: (90.00%) (18659/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2735) | Acc: (90.00%) (19824/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2756) | Acc: (90.00%) (20967/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2747) | Acc: (90.00%) (22133/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2748) | Acc: (90.00%) (23288/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2741) | Acc: (90.00%) (24452/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2726) | Acc: (90.00%) (25631/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2723) | Acc: (90.00%) (26796/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2708) | Acc: (90.00%) (27978/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2688) | Acc: (90.00%) (29166/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2684) | Acc: (90.00%) (30337/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2669) | Acc: (90.00%) (31512/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2669) | Acc: (90.00%) (32677/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2665) | Acc: (90.00%) (33843/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2655) | Acc: (90.00%) (35027/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2656) | Acc: (90.00%) (36184/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2657) | Acc: (90.00%) (37344/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2659) | Acc: (90.00%) (38499/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2664) | Acc: (90.00%) (39651/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2666) | Acc: (90.00%) (40821/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2664) | Acc: (90.00%) (41993/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2662) | Acc: (90.00%) (43153/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2652) | Acc: (90.00%) (44330/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2649) | Acc: (90.00%) (45453/50000)
# TEST : Loss: (0.3721) | Acc: (88.00%) (8800/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-3.6462e-02, -2.5360e-02, -1.6586e-02],
          [-7.3689e-04,  4.6884e-04,  3.0253e-02],
          [ 1.4643e-02, -2.3260e-02, -4.2247e-02]],

         [[-3.3263e-02, -2.3517e-02, -1.8196e-02],
          [-5.3789e-02,  1.5879e-02,  2.2212e-02],
          [ 4.2885e-03,  3.9609e-02, -1.5507e-03]],

         [[-5.2186e-02,  2.7887e-02, -7.0527e-02],
          [ 6.3589e-02,  1.4586e-01,  7.9970e-02],
          [ 1.1346e-02,  1.0823e-01,  7.1344e-02]]],


        [[[ 3.6081e-01, -2.0427e-02,  2.4905e-01],
          [ 1.5300e-01,  2.2736e-04, -1.7433e-01],
          [-2.2302e-01, -3.0763e-01, -2.4633e-01]],

         [[-2.8948e-03, -2.5929e-01,  3.8150e-03],
          [-9.0239e-02,  4.0163e-01, -2.0076e-01],
          [ 2.0255e-01,  1.0835e-01,  2.3131e-01]],

         [[-1.8390e-01, -2.2701e-01, -4.5855e-02],
          [-2.2488e-01,  1.6187e-01, -2.0448e-02],
          [ 1.8300e-02,  1.5765e-01,  2.5790e-01]]],


        [[[ 2.4488e-39, -7.3005e-39, -1.3594e-38],
          [ 7.8284e-39, -3.9008e-39,  4.4660e-39],
          [-1.1689e-38,  1.4838e-38, -1.5201e-38]],

         [[ 5.6717e-39,  8.0479e-39, -1.1940e-38],
          [-1.0131e-38,  1.4653e-38,  5.7515e-39],
          [ 2.2197e-39, -1.1084e-38, -1.7708e-38]],

         [[-1.9070e-39,  1.9301e-39,  6.9009e-39],
          [ 1.8565e-39,  1.0186e-38, -4.1826e-39],
          [-1.2024e-38, -1.1452e-38,  1.2196e-38]]],


        ...,


        [[[ 4.0615e-02,  3.9688e-02, -2.2955e-02],
          [ 1.7706e-02,  5.2291e-02, -7.7696e-03],
          [-1.5824e-01,  1.0881e-02,  3.4121e-02]],

         [[-1.4278e-01, -1.8384e-01, -4.2327e-02],
          [ 4.9720e-02, -2.2829e-02, -1.5318e-01],
          [ 8.1129e-02, -5.8824e-02, -4.7922e-02]],

         [[ 1.0155e-02,  1.1338e-01,  1.0529e-01],
          [ 2.6372e-01,  3.6549e-01,  1.6666e-01],
          [ 2.6513e-01,  2.5359e-01,  6.1148e-02]]],


        [[[ 2.6747e-01,  2.4258e-02,  9.5087e-02],
          [ 8.6176e-02, -1.0850e-01, -6.0159e-02],
          [ 1.5135e-02,  1.0536e-01,  5.3430e-02]],

         [[-3.3784e-02, -2.8501e-01, -3.6222e-02],
          [-5.4399e-02, -3.1052e-01, -2.1821e-01],
          [ 1.7195e-02, -5.2891e-02, -5.1750e-02]],

         [[ 9.5201e-02, -2.0497e-01, -4.7521e-02],
          [-8.6887e-03, -9.3619e-02, -1.8415e-03],
          [-2.3473e-02,  6.1573e-02,  1.4211e-01]]],


        [[[ 5.2305e-02, -2.0306e-01,  3.1365e-03],
          [-2.0564e-01, -5.1931e-01, -2.3916e-01],
          [ 1.3485e-01, -4.6874e-02, -2.4918e-02]],

         [[ 1.5051e-01, -2.4791e-01,  1.4678e-03],
          [ 4.6633e-03, -2.4289e-01,  4.5022e-02],
          [ 1.7709e-01,  2.0680e-01,  4.9052e-02]],

         [[ 5.2413e-02, -2.2986e-01,  8.7493e-02],
          [ 7.5849e-02, -7.6426e-02,  9.2358e-02],
          [-8.2398e-02,  2.3529e-02,  1.2856e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0391,  0.0144, -0.0158],
          [ 0.0218, -0.0012, -0.0090],
          [-0.0169, -0.0296, -0.0457]],

         [[ 0.0170, -0.0153, -0.0286],
          [ 0.0130,  0.0046,  0.0066],
          [-0.0026, -0.0032, -0.0126]],

         [[ 0.0947,  0.0634,  0.0259],
          [ 0.0522,  0.0360,  0.0310],
          [ 0.0039,  0.0026,  0.0030]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0043, -0.0090, -0.0152],
          [ 0.0141,  0.0111,  0.0032],
          [ 0.0138,  0.0113,  0.0019]],

         [[-0.0109, -0.0143, -0.0211],
          [ 0.0070,  0.0050, -0.0037],
          [ 0.0055,  0.0040, -0.0064]],

         [[-0.0129, -0.0157, -0.0226],
          [ 0.0029,  0.0008, -0.0078],
          [ 0.0007, -0.0005, -0.0106]]],


        [[[ 0.0010, -0.0008,  0.0023],
          [-0.0101, -0.0099, -0.0067],
          [-0.0233, -0.0259, -0.0277]],

         [[ 0.0020, -0.0007, -0.0007],
          [-0.0059, -0.0068, -0.0067],
          [-0.0193, -0.0221, -0.0237]],

         [[ 0.0060, -0.0000, -0.0018],
          [-0.0034, -0.0067, -0.0084],
          [-0.0157, -0.0196, -0.0229]]],


        [[[ 0.0227,  0.0011, -0.0001],
          [ 0.0032, -0.0186, -0.0126],
          [-0.0237, -0.0465, -0.0406]],

         [[-0.0024, -0.0229, -0.0190],
          [-0.0158, -0.0378, -0.0288],
          [-0.0400, -0.0642, -0.0569]],

         [[-0.0005, -0.0208, -0.0194],
          [-0.0122, -0.0339, -0.0294],
          [-0.0283, -0.0537, -0.0496]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1953]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 102 | Batch_idx: 0 |  Loss: (0.3037) | Acc: (90.00%) (116/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2284) | Acc: (92.00%) (1305/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.2413) | Acc: (91.00%) (2458/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2429) | Acc: (91.00%) (3632/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2446) | Acc: (91.00%) (4794/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2470) | Acc: (91.00%) (5969/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2468) | Acc: (91.00%) (7137/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2465) | Acc: (91.00%) (8310/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2462) | Acc: (91.00%) (9480/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2424) | Acc: (91.00%) (10667/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2420) | Acc: (91.00%) (11846/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2428) | Acc: (91.00%) (13027/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2418) | Acc: (91.00%) (14197/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2410) | Acc: (91.00%) (15382/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2410) | Acc: (91.00%) (16555/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2419) | Acc: (91.00%) (17722/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2434) | Acc: (91.00%) (18891/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2442) | Acc: (91.00%) (20051/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2444) | Acc: (91.00%) (21224/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2454) | Acc: (91.00%) (22386/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2449) | Acc: (91.00%) (23566/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2452) | Acc: (91.00%) (24737/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2442) | Acc: (91.00%) (25926/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2433) | Acc: (91.00%) (27111/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2436) | Acc: (91.00%) (28273/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2417) | Acc: (91.00%) (29462/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2414) | Acc: (91.00%) (30639/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2414) | Acc: (91.00%) (31817/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2407) | Acc: (91.00%) (33008/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2407) | Acc: (91.00%) (34180/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2407) | Acc: (91.00%) (35358/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2407) | Acc: (91.00%) (36528/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2404) | Acc: (91.00%) (37707/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2416) | Acc: (91.00%) (38871/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2420) | Acc: (91.00%) (40040/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2426) | Acc: (91.00%) (41204/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2423) | Acc: (91.00%) (42391/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2413) | Acc: (91.00%) (43581/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2405) | Acc: (91.00%) (44767/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2395) | Acc: (91.00%) (45911/50000)
# TEST : Loss: (0.3613) | Acc: (88.00%) (8856/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-3.0145e-02, -2.1080e-02, -1.3763e-02],
          [-6.2822e-04,  4.0383e-04,  2.5964e-02],
          [ 1.2558e-02, -2.0216e-02, -3.6569e-02]],

         [[-2.7901e-02, -1.9683e-02, -1.5212e-02],
          [-4.5113e-02,  1.3327e-02,  1.8582e-02],
          [ 3.5968e-03,  3.3428e-02, -1.3029e-03]],

         [[-4.4572e-02,  2.3790e-02, -6.0160e-02],
          [ 5.3194e-02,  1.2145e-01,  6.6444e-02],
          [ 9.4274e-03,  8.9844e-02,  5.9014e-02]]],


        [[[ 3.5914e-01, -1.5726e-02,  2.4725e-01],
          [ 1.5584e-01,  5.9950e-03, -1.7656e-01],
          [-2.1686e-01, -3.0993e-01, -2.5217e-01]],

         [[-1.0166e-02, -2.6122e-01, -6.6565e-03],
          [-9.0572e-02,  4.0528e-01, -2.0481e-01],
          [ 2.0733e-01,  1.0719e-01,  2.2754e-01]],

         [[-1.9343e-01, -2.3192e-01, -5.7116e-02],
          [-2.2922e-01,  1.6153e-01, -2.2779e-02],
          [ 2.0807e-02,  1.5517e-01,  2.5411e-01]]],


        [[[ 1.0743e-39, -7.8568e-40, -1.2141e-40],
          [ 5.8971e-40,  5.7895e-40, -7.0012e-40],
          [-1.0411e-40,  5.7283e-40, -4.4582e-41]],

         [[-2.4583e-40, -7.8697e-41, -2.3036e-40],
          [-7.8022e-40,  7.7918e-40,  3.4831e-40],
          [ 2.6014e-40, -9.8032e-41, -3.8431e-40]],

         [[-7.2170e-40,  4.7411e-40,  3.4243e-40],
          [-2.8799e-40,  5.4476e-40,  1.1995e-41],
          [ 6.9673e-41, -3.5091e-40,  2.1178e-40]]],


        ...,


        [[[ 4.0221e-02,  4.2375e-02, -2.1059e-02],
          [ 1.4773e-02,  5.0561e-02, -6.7000e-03],
          [-1.6963e-01,  3.3873e-03,  3.3212e-02]],

         [[-1.2456e-01, -1.6578e-01, -3.4830e-02],
          [ 7.3124e-02, -1.8164e-03, -1.3845e-01],
          [ 8.3875e-02, -5.4023e-02, -4.2117e-02]],

         [[ 2.6215e-02,  1.3209e-01,  1.0968e-01],
          [ 2.9425e-01,  3.9913e-01,  1.8405e-01],
          [ 2.5219e-01,  2.5163e-01,  6.4806e-02]]],


        [[[ 2.6789e-01,  1.8639e-02,  9.3292e-02],
          [ 8.2252e-02, -1.2574e-01, -7.5765e-02],
          [ 1.3832e-02,  9.5505e-02,  4.3679e-02]],

         [[-3.5606e-02, -2.9185e-01, -3.2700e-02],
          [-5.5599e-02, -3.2291e-01, -2.2392e-01],
          [ 1.6900e-02, -5.8292e-02, -5.5807e-02]],

         [[ 9.7266e-02, -2.0245e-01, -3.2361e-02],
          [-2.9738e-03, -8.8198e-02,  1.5259e-02],
          [-2.1847e-02,  6.2898e-02,  1.5129e-01]]],


        [[[ 6.9368e-02, -1.9883e-01,  7.8030e-03],
          [-1.8984e-01, -5.2008e-01, -2.4294e-01],
          [ 1.4370e-01, -4.5823e-02, -2.2132e-02]],

         [[ 1.5851e-01, -2.5165e-01, -9.2518e-04],
          [ 1.0373e-02, -2.5182e-01,  3.5849e-02],
          [ 1.7809e-01,  2.0059e-01,  4.8095e-02]],

         [[ 5.9181e-02, -2.3428e-01,  8.2301e-02],
          [ 7.9748e-02, -8.2219e-02,  8.6587e-02],
          [-8.4878e-02,  1.9044e-02,  1.2850e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0079, -0.0141, -0.0108],
          [ 0.0189,  0.0104, -0.0046],
          [ 0.0118,  0.0009, -0.0097]],

         [[ 0.0476,  0.0288,  0.0178],
          [ 0.0714,  0.0533,  0.0217],
          [ 0.0452,  0.0252,  0.0142]],

         [[ 0.0449,  0.0211,  0.0055],
          [ 0.0613,  0.0407,  0.0118],
          [ 0.0432,  0.0194,  0.0069]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0021,  0.0021,  0.0027],
          [-0.0046, -0.0016, -0.0032],
          [-0.0061, -0.0027, -0.0058]],

         [[ 0.0024,  0.0056,  0.0051],
          [-0.0012,  0.0012, -0.0018],
          [-0.0036, -0.0012, -0.0050]],

         [[ 0.0038,  0.0066,  0.0061],
          [-0.0002,  0.0018, -0.0011],
          [-0.0034, -0.0012, -0.0052]]],


        [[[-0.0376, -0.0483, -0.0455],
          [-0.0444, -0.0580, -0.0550],
          [-0.0418, -0.0524, -0.0486]],

         [[-0.0038, -0.0123, -0.0067],
          [-0.0040, -0.0159, -0.0115],
          [ 0.0031, -0.0072, -0.0029]],

         [[-0.0048, -0.0105, -0.0046],
          [-0.0040, -0.0131, -0.0078],
          [ 0.0037, -0.0044,  0.0003]]],


        [[[-0.0065, -0.0072, -0.0099],
          [-0.0127, -0.0118, -0.0136],
          [-0.0297, -0.0262, -0.0173]],

         [[-0.0115, -0.0128, -0.0152],
          [-0.0226, -0.0199, -0.0204],
          [-0.0364, -0.0327, -0.0228]],

         [[-0.0141, -0.0118, -0.0147],
          [-0.0251, -0.0196, -0.0189],
          [-0.0347, -0.0305, -0.0203]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1948]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 103 | Batch_idx: 0 |  Loss: (0.1636) | Acc: (96.00%) (123/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.2127) | Acc: (92.00%) (1305/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.2271) | Acc: (92.00%) (2479/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2236) | Acc: (92.00%) (3664/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2169) | Acc: (92.00%) (4860/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2132) | Acc: (92.00%) (6053/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.2143) | Acc: (92.00%) (7236/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.2115) | Acc: (92.00%) (8427/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2114) | Acc: (92.00%) (9617/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.2089) | Acc: (92.00%) (10808/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.2101) | Acc: (92.00%) (12004/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.2055) | Acc: (92.00%) (13212/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.2058) | Acc: (92.00%) (14395/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2072) | Acc: (92.00%) (15580/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.2094) | Acc: (92.00%) (16743/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2088) | Acc: (92.00%) (17928/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.2098) | Acc: (92.00%) (19111/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.2119) | Acc: (92.00%) (20275/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.2124) | Acc: (92.00%) (21454/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.2133) | Acc: (92.00%) (22628/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2138) | Acc: (92.00%) (23810/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2153) | Acc: (92.00%) (24989/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2145) | Acc: (92.00%) (26182/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2149) | Acc: (92.00%) (27366/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2153) | Acc: (92.00%) (28546/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2168) | Acc: (92.00%) (29715/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2184) | Acc: (92.00%) (30869/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2186) | Acc: (92.00%) (32050/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2174) | Acc: (92.00%) (33250/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2165) | Acc: (92.00%) (34443/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2155) | Acc: (92.00%) (35644/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2157) | Acc: (92.00%) (36829/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2162) | Acc: (92.00%) (38012/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2156) | Acc: (92.00%) (39207/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2163) | Acc: (92.00%) (40378/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2161) | Acc: (92.00%) (41560/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2159) | Acc: (92.00%) (42749/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2159) | Acc: (92.00%) (43937/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2155) | Acc: (92.00%) (45126/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2160) | Acc: (92.00%) (46254/50000)
# TEST : Loss: (0.3394) | Acc: (89.00%) (8948/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.2984e-02, -1.5683e-02, -9.8623e-03],
          [-5.2218e-04,  5.8168e-04,  2.1732e-02],
          [ 1.0526e-02, -1.6722e-02, -3.0439e-02]],

         [[-2.1527e-02, -1.4592e-02, -1.1028e-02],
          [-3.6285e-02,  1.1206e-02,  1.5312e-02],
          [ 3.1536e-03,  2.7715e-02, -6.2337e-04]],

         [[-3.5790e-02,  2.0823e-02, -4.8430e-02],
          [ 4.3117e-02,  9.7805e-02,  5.3545e-02],
          [ 7.9399e-03,  7.2332e-02,  4.7442e-02]]],


        [[[ 3.5565e-01, -1.8354e-02,  2.5253e-01],
          [ 1.4214e-01, -1.1839e-02, -1.8613e-01],
          [-2.1713e-01, -3.2025e-01, -2.5521e-01]],

         [[-1.2986e-02, -2.6492e-01, -1.4194e-04],
          [-1.0087e-01,  3.9386e-01, -2.0751e-01],
          [ 2.0875e-01,  1.0618e-01,  2.3622e-01]],

         [[-1.8769e-01, -2.2735e-01, -4.5350e-02],
          [-2.3327e-01,  1.5433e-01, -2.4239e-02],
          [ 2.7149e-02,  1.5688e-01,  2.6371e-01]]],


        [[[-1.8777e-42,  1.0383e-40, -1.1539e-40],
          [ 1.2140e-40, -2.3399e-41, -8.4347e-41],
          [-7.9742e-41,  7.6532e-41, -1.5987e-41]],

         [[-1.1033e-40,  8.9022e-41,  8.6108e-41],
          [-4.1069e-41,  1.2307e-40, -9.0747e-41],
          [ 1.1922e-40,  6.0159e-41,  1.0833e-40]],

         [[-1.1032e-40, -9.7638e-41, -4.4102e-41],
          [ 7.3676e-41, -1.1256e-40,  6.7934e-41],
          [ 1.0356e-40, -1.3574e-40,  1.1204e-40]]],


        ...,


        [[[ 2.5857e-02,  3.6837e-02, -2.5386e-02],
          [ 2.8646e-03,  4.2522e-02, -1.5879e-02],
          [-1.7642e-01, -4.6845e-03,  2.7887e-02]],

         [[-1.4051e-01, -1.7016e-01, -4.1345e-02],
          [ 6.0116e-02, -9.0356e-03, -1.4970e-01],
          [ 7.6929e-02, -5.9742e-02, -4.6889e-02]],

         [[ 1.3342e-02,  1.3340e-01,  1.0372e-01],
          [ 2.8370e-01,  4.0053e-01,  1.7449e-01],
          [ 2.5584e-01,  2.5603e-01,  6.7354e-02]]],


        [[[ 2.8889e-01,  3.2311e-02,  9.2565e-02],
          [ 1.1049e-01, -1.1136e-01, -6.4228e-02],
          [ 2.7058e-02,  9.3435e-02,  3.7311e-02]],

         [[-2.6068e-02, -2.8741e-01, -4.2547e-02],
          [-4.0173e-02, -3.1644e-01, -2.1567e-01],
          [ 1.4869e-02, -7.0163e-02, -6.6528e-02]],

         [[ 9.4856e-02, -2.1413e-01, -5.4098e-02],
          [ 3.0243e-03, -9.3336e-02,  1.7663e-02],
          [-3.2215e-02,  4.5533e-02,  1.4207e-01]]],


        [[[ 5.0668e-02, -2.1783e-01,  4.2479e-03],
          [-1.9296e-01, -5.1780e-01, -2.3293e-01],
          [ 1.4316e-01, -4.3273e-02, -1.2528e-02]],

         [[ 1.4436e-01, -2.5855e-01, -1.7989e-04],
          [ 9.7643e-03, -2.4424e-01,  4.6108e-02],
          [ 1.8015e-01,  2.0583e-01,  5.7325e-02]],

         [[ 5.2831e-02, -2.2944e-01,  9.3530e-02],
          [ 8.3703e-02, -6.6406e-02,  1.0533e-01],
          [-8.0641e-02,  3.0426e-02,  1.4435e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0812,  0.0562,  0.0554],
          [ 0.0807,  0.0718,  0.0527],
          [ 0.0964,  0.0507,  0.0319]],

         [[ 0.0834,  0.0699,  0.0735],
          [ 0.0679,  0.0686,  0.0638],
          [ 0.0819,  0.0556,  0.0388]],

         [[ 0.0397,  0.0355,  0.0391],
          [ 0.0297,  0.0302,  0.0342],
          [ 0.0334,  0.0086,  0.0038]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0004, -0.0031, -0.0005],
          [-0.0003, -0.0039, -0.0019],
          [ 0.0007, -0.0018,  0.0002]],

         [[-0.0004, -0.0041, -0.0024],
          [-0.0017, -0.0059, -0.0044],
          [-0.0019, -0.0047, -0.0027]],

         [[ 0.0033,  0.0004,  0.0024],
          [ 0.0014, -0.0024, -0.0008],
          [-0.0005, -0.0031, -0.0010]]],


        [[[-0.0205, -0.0108, -0.0054],
          [-0.0109, -0.0145, -0.0168],
          [ 0.0011, -0.0081, -0.0147]],

         [[-0.0045, -0.0014,  0.0008],
          [ 0.0004, -0.0076, -0.0115],
          [ 0.0082, -0.0046, -0.0114]],

         [[-0.0064, -0.0084, -0.0064],
          [-0.0057, -0.0136, -0.0158],
          [ 0.0017, -0.0094, -0.0146]]],


        [[[-0.0069,  0.0008, -0.0027],
          [ 0.0046,  0.0027, -0.0057],
          [ 0.0121,  0.0083, -0.0020]],

         [[ 0.0016,  0.0084,  0.0063],
          [ 0.0080,  0.0042, -0.0020],
          [ 0.0132,  0.0087, -0.0009]],

         [[-0.0006,  0.0043,  0.0047],
          [ 0.0036, -0.0004, -0.0022],
          [ 0.0090,  0.0049,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1942]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 104 | Batch_idx: 0 |  Loss: (0.1295) | Acc: (94.00%) (121/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.1961) | Acc: (93.00%) (1312/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.1904) | Acc: (93.00%) (2518/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.1900) | Acc: (93.00%) (3727/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.1921) | Acc: (93.00%) (4914/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.1961) | Acc: (93.00%) (6090/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.2004) | Acc: (93.00%) (7271/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.1985) | Acc: (93.00%) (8467/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.2006) | Acc: (93.00%) (9655/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.2024) | Acc: (93.00%) (10845/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.2068) | Acc: (92.00%) (12012/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.2080) | Acc: (92.00%) (13196/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.2081) | Acc: (92.00%) (14386/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.2090) | Acc: (92.00%) (15576/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.2105) | Acc: (92.00%) (16750/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.2095) | Acc: (92.00%) (17937/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.2105) | Acc: (92.00%) (19125/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.2118) | Acc: (92.00%) (20308/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.2121) | Acc: (92.00%) (21496/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.2117) | Acc: (92.00%) (22683/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.2124) | Acc: (92.00%) (23870/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.2126) | Acc: (92.00%) (25063/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.2124) | Acc: (92.00%) (26249/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.2122) | Acc: (92.00%) (27431/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.2113) | Acc: (92.00%) (28634/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.2108) | Acc: (92.00%) (29823/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.2111) | Acc: (92.00%) (31009/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.2118) | Acc: (92.00%) (32188/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.2101) | Acc: (92.00%) (33394/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.2098) | Acc: (92.00%) (34583/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.2090) | Acc: (92.00%) (35784/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.2078) | Acc: (92.00%) (36996/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.2078) | Acc: (92.00%) (38185/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.2078) | Acc: (92.00%) (39366/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.2078) | Acc: (92.00%) (40551/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.2070) | Acc: (92.00%) (41755/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.2076) | Acc: (92.00%) (42939/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.2077) | Acc: (92.00%) (44115/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.2079) | Acc: (92.00%) (45297/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.2079) | Acc: (92.00%) (46442/50000)
# TEST : Loss: (0.3455) | Acc: (89.00%) (8918/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.7341e-02, -1.1928e-02, -7.4816e-03],
          [-4.1226e-04,  4.6628e-04,  1.7328e-02],
          [ 8.3843e-03, -1.3585e-02, -2.4581e-02]],

         [[-1.6594e-02, -1.1213e-02, -8.4589e-03],
          [-2.7962e-02,  8.6439e-03,  1.1755e-02],
          [ 2.4301e-03,  2.1557e-02, -4.8163e-04]],

         [[-2.8339e-02,  1.6459e-02, -3.8278e-02],
          [ 3.3100e-02,  7.4594e-02,  4.0695e-02],
          [ 6.0338e-03,  5.4910e-02,  3.5819e-02]]],


        [[[ 3.6438e-01, -1.6138e-02,  2.5703e-01],
          [ 1.5599e-01,  1.8650e-03, -1.7843e-01],
          [-2.1026e-01, -3.1567e-01, -2.5961e-01]],

         [[-1.1704e-02, -2.6788e-01,  8.4620e-06],
          [-9.2601e-02,  4.0401e-01, -2.0578e-01],
          [ 2.1362e-01,  1.1017e-01,  2.2526e-01]],

         [[-1.8864e-01, -2.3295e-01, -4.8028e-02],
          [-2.3280e-01,  1.5792e-01, -2.6876e-02],
          [ 2.6446e-02,  1.5433e-01,  2.4942e-01]]],


        [[[-1.2081e-40,  5.4042e-41,  6.0634e-42],
          [-9.9927e-42, -1.3482e-40, -1.0119e-40],
          [ 1.0457e-40, -1.2181e-40, -1.2322e-40]],

         [[ 2.4188e-41, -1.1961e-40, -2.6911e-41],
          [-9.5755e-41,  1.1180e-41,  2.5125e-41],
          [-6.3878e-41,  1.1814e-40, -8.2231e-41]],

         [[ 6.2141e-41, -2.6232e-42, -1.0311e-40],
          [-1.3240e-40,  1.7684e-42,  1.3905e-40],
          [-1.1775e-40, -9.9729e-41, -9.3881e-41]]],


        ...,


        [[[ 4.5387e-02,  5.3469e-02, -1.2506e-02],
          [ 1.7175e-02,  5.3008e-02, -4.9907e-03],
          [-1.6383e-01,  6.4124e-03,  3.9322e-02]],

         [[-1.1505e-01, -1.4892e-01, -2.7955e-02],
          [ 8.2361e-02,  8.6472e-03, -1.3483e-01],
          [ 9.6800e-02, -4.1097e-02, -3.1977e-02]],

         [[ 3.6517e-02,  1.5118e-01,  1.1425e-01],
          [ 3.0015e-01,  4.1248e-01,  1.8506e-01],
          [ 2.6056e-01,  2.6401e-01,  7.4329e-02]]],


        [[[ 2.8768e-01,  3.8317e-02,  1.0039e-01],
          [ 1.0884e-01, -9.4402e-02, -5.2210e-02],
          [ 2.6645e-02,  1.0654e-01,  4.7915e-02]],

         [[-4.1879e-02, -2.9439e-01, -4.1034e-02],
          [-5.6747e-02, -3.1183e-01, -2.1617e-01],
          [ 2.1940e-04, -7.4940e-02, -7.3538e-02]],

         [[ 7.4448e-02, -2.2655e-01, -5.6299e-02],
          [-1.3355e-02, -9.0277e-02,  1.7107e-02],
          [-4.6870e-02,  3.9885e-02,  1.3648e-01]]],


        [[[ 4.8955e-02, -2.2702e-01,  7.7920e-03],
          [-2.0050e-01, -5.2852e-01, -2.3940e-01],
          [ 1.3388e-01, -4.7066e-02, -1.8344e-02]],

         [[ 1.4334e-01, -2.6847e-01, -6.9143e-03],
          [ 2.0301e-03, -2.5743e-01,  3.2359e-02],
          [ 1.6842e-01,  1.9625e-01,  4.7057e-02]],

         [[ 5.1111e-02, -2.3868e-01,  8.6356e-02],
          [ 7.5843e-02, -7.8651e-02,  9.3657e-02],
          [-9.1910e-02,  1.9719e-02,  1.3449e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0549,  0.0475,  0.0485],
          [ 0.0748,  0.0663,  0.0395],
          [ 0.1003,  0.0842,  0.0537]],

         [[ 0.0626,  0.0541,  0.0503],
          [ 0.0801,  0.0730,  0.0438],
          [ 0.0957,  0.0887,  0.0561]],

         [[ 0.0814,  0.0719,  0.0660],
          [ 0.0873,  0.0782,  0.0533],
          [ 0.0911,  0.0830,  0.0556]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0098,  0.0079,  0.0048],
          [ 0.0096,  0.0082,  0.0038],
          [ 0.0093,  0.0080,  0.0048]],

         [[ 0.0089,  0.0074,  0.0046],
          [ 0.0080,  0.0073,  0.0030],
          [ 0.0071,  0.0065,  0.0034]],

         [[ 0.0022,  0.0012, -0.0005],
          [ 0.0015,  0.0011, -0.0018],
          [ 0.0014,  0.0014, -0.0004]]],


        [[[-0.0069, -0.0058, -0.0071],
          [ 0.0013,  0.0033,  0.0006],
          [ 0.0153,  0.0180,  0.0108]],

         [[-0.0052, -0.0028, -0.0044],
          [-0.0015,  0.0023, -0.0003],
          [ 0.0086,  0.0132,  0.0076]],

         [[-0.0061, -0.0039, -0.0044],
          [-0.0035, -0.0002, -0.0019],
          [ 0.0045,  0.0073,  0.0027]]],


        [[[ 0.0034,  0.0013, -0.0012],
          [ 0.0062,  0.0054,  0.0016],
          [ 0.0152,  0.0153,  0.0110]],

         [[ 0.0042,  0.0046,  0.0005],
          [ 0.0052,  0.0086,  0.0051],
          [ 0.0113,  0.0154,  0.0139]],

         [[ 0.0035,  0.0046,  0.0025],
          [ 0.0046,  0.0086,  0.0066],
          [ 0.0094,  0.0127,  0.0120]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1935]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 105 | Batch_idx: 0 |  Loss: (0.1540) | Acc: (92.00%) (118/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.2101) | Acc: (91.00%) (1293/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2265) | Acc: (91.00%) (2469/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2298) | Acc: (91.00%) (3650/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2408) | Acc: (91.00%) (4816/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2414) | Acc: (91.00%) (5998/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2401) | Acc: (92.00%) (7187/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2369) | Acc: (92.00%) (8375/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2368) | Acc: (92.00%) (9551/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2352) | Acc: (92.00%) (10737/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2346) | Acc: (92.00%) (11917/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2337) | Acc: (92.00%) (13102/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2324) | Acc: (92.00%) (14283/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2282) | Acc: (92.00%) (15486/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2267) | Acc: (92.00%) (16682/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2260) | Acc: (92.00%) (17866/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2232) | Acc: (92.00%) (19070/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2210) | Acc: (92.00%) (20265/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2188) | Acc: (92.00%) (21465/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2179) | Acc: (92.00%) (22658/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2171) | Acc: (92.00%) (23852/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2147) | Acc: (92.00%) (25062/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2127) | Acc: (92.00%) (26266/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2120) | Acc: (92.00%) (27466/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2102) | Acc: (92.00%) (28676/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2094) | Acc: (92.00%) (29877/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2076) | Acc: (93.00%) (31086/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2071) | Acc: (93.00%) (32281/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2053) | Acc: (93.00%) (33497/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2045) | Acc: (93.00%) (34704/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2031) | Acc: (93.00%) (35914/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2018) | Acc: (93.00%) (37119/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2009) | Acc: (93.00%) (38324/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2004) | Acc: (93.00%) (39521/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2001) | Acc: (93.00%) (40723/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.1997) | Acc: (93.00%) (41924/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.1993) | Acc: (93.00%) (43120/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.1993) | Acc: (93.00%) (44309/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.1992) | Acc: (93.00%) (45507/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.1988) | Acc: (93.00%) (46655/50000)
# TEST : Loss: (0.3109) | Acc: (90.00%) (9002/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2304e-02, -8.5474e-03, -5.3442e-03],
          [-3.0916e-04,  3.5623e-04,  1.3152e-02],
          [ 6.3563e-03, -1.0549e-02, -1.8949e-02]],

         [[-1.2087e-02, -8.1354e-03, -6.1244e-03],
          [-2.0360e-02,  6.3015e-03,  8.5201e-03],
          [ 1.7692e-03,  1.5875e-02, -3.5180e-04]],

         [[-2.1329e-02,  1.2361e-02, -2.8746e-02],
          [ 2.3989e-02,  5.3644e-02,  2.9136e-02],
          [ 4.3191e-03,  3.9261e-02,  2.5439e-02]]],


        [[[ 3.6221e-01, -1.7744e-02,  2.5499e-01],
          [ 1.5478e-01,  1.2406e-03, -1.7957e-01],
          [-2.1188e-01, -3.1571e-01, -2.5998e-01]],

         [[-1.2778e-02, -2.6855e-01, -1.2746e-03],
          [-9.2615e-02,  4.0379e-01, -2.0649e-01],
          [ 2.1292e-01,  1.1089e-01,  2.2517e-01]],

         [[-1.8855e-01, -2.3254e-01, -4.8485e-02],
          [-2.3203e-01,  1.5817e-01, -2.7658e-02],
          [ 2.5973e-02,  1.5466e-01,  2.4880e-01]]],


        [[[-4.3946e-41,  6.3267e-41,  4.6363e-41],
          [-1.2446e-40,  4.6014e-41,  1.1874e-40],
          [-2.0135e-41, -5.4202e-41,  9.4628e-41]],

         [[ 1.2437e-40, -3.9283e-41, -6.5505e-41],
          [ 3.8099e-41, -1.5334e-40, -7.4302e-41],
          [-1.2745e-40,  8.6547e-41,  1.1181e-40]],

         [[-1.4902e-40, -1.0674e-40,  8.1130e-41],
          [ 6.4456e-41,  1.6672e-40,  5.2669e-41],
          [ 8.2231e-41, -1.1989e-40, -1.0267e-40]]],


        ...,


        [[[ 4.3827e-02,  5.1474e-02, -1.3631e-02],
          [ 1.6159e-02,  5.1250e-02, -5.7433e-03],
          [-1.6284e-01,  5.7717e-03,  3.8829e-02]],

         [[-1.1681e-01, -1.5070e-01, -2.9553e-02],
          [ 7.9559e-02,  5.8582e-03, -1.3529e-01],
          [ 9.5357e-02, -4.2208e-02, -3.2403e-02]],

         [[ 3.5011e-02,  1.4795e-01,  1.1288e-01],
          [ 2.9440e-01,  4.0247e-01,  1.8296e-01],
          [ 2.5830e-01,  2.5994e-01,  7.4303e-02]]],


        [[[ 2.8675e-01,  3.9958e-02,  1.0034e-01],
          [ 1.0814e-01, -9.2895e-02, -5.1926e-02],
          [ 2.4645e-02,  1.0472e-01,  4.6500e-02]],

         [[-4.2642e-02, -2.9181e-01, -4.2541e-02],
          [-5.7450e-02, -3.0862e-01, -2.1549e-01],
          [-1.6999e-03, -7.6042e-02, -7.4932e-02]],

         [[ 7.3759e-02, -2.2236e-01, -5.5711e-02],
          [-1.2674e-02, -8.6304e-02,  1.7873e-02],
          [-4.6846e-02,  3.9858e-02,  1.3495e-01]]],


        [[[ 4.8867e-02, -2.2505e-01,  7.6872e-03],
          [-1.9900e-01, -5.2388e-01, -2.3775e-01],
          [ 1.3394e-01, -4.6535e-02, -1.8238e-02]],

         [[ 1.4190e-01, -2.6857e-01, -8.1557e-03],
          [ 1.6331e-03, -2.5724e-01,  3.1543e-02],
          [ 1.6792e-01,  1.9519e-01,  4.6325e-02]],

         [[ 5.1030e-02, -2.3722e-01,  8.6346e-02],
          [ 7.6262e-02, -7.7665e-02,  9.4037e-02],
          [-9.0698e-02,  2.0465e-02,  1.3456e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2398]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0624]], device='cuda:0')

Epoch: 106 | Batch_idx: 0 |  Loss: (0.2569) | Acc: (90.00%) (116/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.2044) | Acc: (92.00%) (1300/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.1996) | Acc: (93.00%) (2501/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.1931) | Acc: (93.00%) (3709/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.1915) | Acc: (93.00%) (4896/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.1901) | Acc: (93.00%) (6091/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.1843) | Acc: (93.00%) (7303/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.1834) | Acc: (93.00%) (8509/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.1800) | Acc: (93.00%) (9719/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.1820) | Acc: (93.00%) (10915/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.1792) | Acc: (93.00%) (12126/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.1804) | Acc: (93.00%) (13316/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.1801) | Acc: (93.00%) (14517/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.1781) | Acc: (93.00%) (15726/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.1761) | Acc: (93.00%) (16945/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.1755) | Acc: (93.00%) (18153/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.1757) | Acc: (93.00%) (19354/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.1756) | Acc: (93.00%) (20566/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.1757) | Acc: (93.00%) (21772/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.1766) | Acc: (93.00%) (22965/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.1764) | Acc: (93.00%) (24170/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.1764) | Acc: (93.00%) (25370/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.1774) | Acc: (93.00%) (26558/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.1772) | Acc: (93.00%) (27762/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.1752) | Acc: (93.00%) (28991/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.1763) | Acc: (93.00%) (30187/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.1766) | Acc: (93.00%) (31391/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.1776) | Acc: (93.00%) (32587/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.1771) | Acc: (93.00%) (33794/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.1763) | Acc: (93.00%) (35011/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.1767) | Acc: (93.00%) (36209/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.1770) | Acc: (93.00%) (37406/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.1771) | Acc: (93.00%) (38615/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.1768) | Acc: (93.00%) (39818/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.1775) | Acc: (93.00%) (41016/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.1773) | Acc: (93.00%) (42223/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.1770) | Acc: (94.00%) (43438/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.1772) | Acc: (93.00%) (44637/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.1766) | Acc: (94.00%) (45854/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.1765) | Acc: (94.00%) (47017/50000)
# TEST : Loss: (0.3019) | Acc: (90.00%) (9014/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-8.1007e-03, -5.6952e-03, -3.5472e-03],
          [-2.1775e-04,  2.5666e-04,  9.4013e-03],
          [ 4.5367e-03, -7.7532e-03, -1.3804e-02]],

         [[-8.2161e-03, -5.5040e-03, -4.1327e-03],
          [-1.3834e-02,  4.2880e-03,  5.7567e-03],
          [ 1.2019e-03,  1.0936e-02, -2.3995e-04]],

         [[-1.5089e-02,  8.7219e-03, -2.0283e-02],
          [ 1.6208e-02,  3.5907e-02,  1.9395e-02],
          [ 2.8742e-03,  2.6093e-02,  1.6768e-02]]],


        [[[ 3.6181e-01, -1.7725e-02,  2.5471e-01],
          [ 1.5460e-01,  1.2392e-03, -1.7936e-01],
          [-2.1163e-01, -3.1534e-01, -2.5968e-01]],

         [[-1.2764e-02, -2.6824e-01, -1.2731e-03],
          [-9.2504e-02,  4.0331e-01, -2.0624e-01],
          [ 2.1267e-01,  1.1076e-01,  2.2490e-01]],

         [[-1.8832e-01, -2.3225e-01, -4.8424e-02],
          [-2.3173e-01,  1.5796e-01, -2.7623e-02],
          [ 2.5941e-02,  1.5447e-01,  2.4849e-01]]],


        [[[ 1.5309e-40,  1.3515e-40,  1.6994e-40],
          [ 8.7050e-41, -1.4771e-40,  9.6705e-41],
          [ 4.6638e-41,  1.4574e-40, -1.4386e-40]],

         [[-6.2602e-41,  1.6636e-40, -7.8815e-41],
          [ 8.4608e-41,  1.3910e-40,  1.0362e-40],
          [ 5.0134e-41, -1.5055e-40,  1.3582e-40]],

         [[ 4.1131e-41, -4.1563e-42, -7.5631e-41],
          [-1.1375e-40,  5.8527e-41, -1.6793e-40],
          [-1.2348e-40,  1.0339e-40, -1.2519e-40]]],


        ...,


        [[[ 4.3543e-02,  5.1149e-02, -1.3547e-02],
          [ 1.6053e-02,  5.0918e-02, -5.7069e-03],
          [-1.6179e-01,  5.7352e-03,  3.8591e-02]],

         [[-1.1585e-01, -1.4950e-01, -2.9327e-02],
          [ 7.8836e-02,  5.8052e-03, -1.3411e-01],
          [ 9.4529e-02, -4.1841e-02, -3.2135e-02]],

         [[ 3.4586e-02,  1.4616e-01,  1.1169e-01],
          [ 2.8834e-01,  3.9324e-01,  1.8007e-01],
          [ 2.5374e-01,  2.5500e-01,  7.3279e-02]]],


        [[[ 2.8507e-01,  3.9682e-02,  9.9646e-02],
          [ 1.0749e-01, -9.2215e-02, -5.1553e-02],
          [ 2.4506e-02,  1.0407e-01,  4.6219e-02]],

         [[-4.2336e-02, -2.8869e-01, -4.2116e-02],
          [-5.7014e-02, -3.0468e-01, -2.1308e-01],
          [-1.6890e-03, -7.5445e-02, -7.4382e-02]],

         [[ 7.3154e-02, -2.1960e-01, -5.5068e-02],
          [-1.2561e-02, -8.5004e-02,  1.7643e-02],
          [-4.6502e-02,  3.9498e-02,  1.3383e-01]]],


        [[[ 4.8592e-02, -2.2304e-01,  7.6387e-03],
          [-1.9784e-01, -5.1873e-01, -2.3618e-01],
          [ 1.3340e-01, -4.6316e-02, -1.8160e-02]],

         [[ 1.4123e-01, -2.6695e-01, -8.1142e-03],
          [ 1.6252e-03, -2.5561e-01,  3.1377e-02],
          [ 1.6729e-01,  1.9437e-01,  4.6144e-02]],

         [[ 5.0794e-02, -2.3598e-01,  8.5934e-02],
          [ 7.5906e-02, -7.7250e-02,  9.3584e-02],
          [-9.0346e-02,  2.0380e-02,  1.3403e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2781]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0215]], device='cuda:0')

Epoch: 107 | Batch_idx: 0 |  Loss: (0.1809) | Acc: (93.00%) (120/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.1720) | Acc: (94.00%) (1325/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.1786) | Acc: (93.00%) (2525/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.1801) | Acc: (93.00%) (3718/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.1747) | Acc: (94.00%) (4934/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.1753) | Acc: (93.00%) (6126/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.1765) | Acc: (93.00%) (7328/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.1778) | Acc: (93.00%) (8531/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.1772) | Acc: (93.00%) (9735/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.1768) | Acc: (93.00%) (10944/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.1793) | Acc: (93.00%) (12138/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.1778) | Acc: (93.00%) (13351/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.1784) | Acc: (93.00%) (14548/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.1783) | Acc: (93.00%) (15747/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.1802) | Acc: (93.00%) (16945/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.1786) | Acc: (93.00%) (18155/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.1795) | Acc: (93.00%) (19351/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.1781) | Acc: (93.00%) (20564/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.1784) | Acc: (93.00%) (21766/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.1777) | Acc: (93.00%) (22981/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.1781) | Acc: (94.00%) (24186/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.1779) | Acc: (94.00%) (25399/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.1778) | Acc: (94.00%) (26591/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.1777) | Acc: (94.00%) (27795/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.1767) | Acc: (94.00%) (29000/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.1770) | Acc: (94.00%) (30205/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.1770) | Acc: (94.00%) (31406/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.1774) | Acc: (93.00%) (32603/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.1775) | Acc: (93.00%) (33802/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.1766) | Acc: (94.00%) (35026/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.1766) | Acc: (94.00%) (36231/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.1762) | Acc: (94.00%) (37440/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.1773) | Acc: (94.00%) (38624/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.1772) | Acc: (94.00%) (39832/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.1778) | Acc: (93.00%) (41022/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.1781) | Acc: (93.00%) (42218/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.1782) | Acc: (93.00%) (43434/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.1783) | Acc: (93.00%) (44636/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.1781) | Acc: (93.00%) (45841/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.1782) | Acc: (93.00%) (46996/50000)
# TEST : Loss: (0.3002) | Acc: (90.00%) (9012/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-4.8673e-03, -3.4725e-03, -2.1526e-03],
          [-1.4208e-04,  1.7216e-04,  6.2454e-03],
          [ 3.0083e-03, -5.3283e-03, -9.3840e-03]],

         [[-5.1332e-03, -3.4189e-03, -2.5589e-03],
          [-8.6390e-03,  2.6824e-03,  3.5701e-03],
          [ 7.5042e-04,  6.9452e-03, -1.5054e-04]],

         [[-9.8985e-03,  5.7031e-03, -1.3263e-02],
          [ 1.0052e-02,  2.2019e-02,  1.1812e-02],
          [ 1.7497e-03,  1.5861e-02,  1.0090e-02]]],


        [[[ 3.6132e-01, -1.7700e-02,  2.5437e-01],
          [ 1.5438e-01,  1.2374e-03, -1.7911e-01],
          [-2.1133e-01, -3.1490e-01, -2.5933e-01]],

         [[-1.2746e-02, -2.6787e-01, -1.2713e-03],
          [-9.2370e-02,  4.0272e-01, -2.0595e-01],
          [ 2.1236e-01,  1.1060e-01,  2.2458e-01]],

         [[-1.8803e-01, -2.3189e-01, -4.8351e-02],
          [-2.3137e-01,  1.5772e-01, -2.7581e-02],
          [ 2.5901e-02,  1.5423e-01,  2.4811e-01]]],


        [[[ 1.5491e-40,  1.2144e-40,  8.2536e-42],
          [ 4.3777e-41, -1.4955e-40, -1.4878e-40],
          [-2.7904e-41, -1.4888e-40,  1.4764e-40]],

         [[ 4.2507e-41,  3.1978e-42,  1.2841e-40],
          [ 9.9862e-41,  1.8469e-40,  4.3394e-41],
          [ 2.0260e-40,  5.8881e-41,  4.9490e-41]],

         [[-1.2078e-40,  1.4228e-40, -9.2154e-41],
          [ 1.6726e-40,  1.5415e-40,  1.2342e-40],
          [-1.4875e-40, -1.7046e-40,  1.1463e-40]]],


        ...,


        [[[ 4.3200e-02,  5.0757e-02, -1.3446e-02],
          [ 1.5924e-02,  5.0517e-02, -5.6629e-03],
          [-1.6053e-01,  5.6912e-03,  3.8303e-02]],

         [[-1.1470e-01, -1.4804e-01, -2.9054e-02],
          [ 7.7966e-02,  5.7413e-03, -1.3270e-01],
          [ 9.3532e-02, -4.1399e-02, -3.1813e-02]],

         [[ 3.4075e-02,  1.4401e-01,  1.1025e-01],
          [ 2.8113e-01,  3.8231e-01,  1.7661e-01],
          [ 2.4830e-01,  2.4912e-01,  7.2053e-02]]],


        [[[ 2.8304e-01,  3.9349e-02,  9.8812e-02],
          [ 1.0670e-01, -9.1395e-02, -5.1103e-02],
          [ 2.4338e-02,  1.0329e-01,  4.5879e-02]],

         [[-4.1968e-02, -2.8493e-01, -4.1606e-02],
          [-5.6487e-02, -2.9996e-01, -2.1019e-01],
          [-1.6759e-03, -7.4725e-02, -7.3719e-02]],

         [[ 7.2426e-02, -2.1629e-01, -5.4296e-02],
          [-1.2425e-02, -8.3450e-02,  1.7366e-02],
          [-4.6088e-02,  3.9065e-02,  1.3249e-01]]],


        [[[ 4.8260e-02, -2.2062e-01,  7.5801e-03],
          [-1.9644e-01, -5.1254e-01, -2.3428e-01],
          [ 1.3274e-01, -4.6051e-02, -1.8064e-02]],

         [[ 1.4041e-01, -2.6499e-01, -8.0641e-03],
          [ 1.6156e-03, -2.5364e-01,  3.1176e-02],
          [ 1.6653e-01,  1.9338e-01,  4.5925e-02]],

         [[ 5.0509e-02, -2.3446e-01,  8.5437e-02],
          [ 7.5475e-02, -7.6749e-02,  9.3036e-02],
          [-8.9920e-02,  2.0277e-02,  1.3339e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2727]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0258]], device='cuda:0')

Epoch: 108 | Batch_idx: 0 |  Loss: (0.1965) | Acc: (92.00%) (119/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.1723) | Acc: (94.00%) (1325/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.1730) | Acc: (94.00%) (2533/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.1721) | Acc: (94.00%) (3740/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.1791) | Acc: (94.00%) (4940/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.1779) | Acc: (94.00%) (6155/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.1784) | Acc: (94.00%) (7359/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.1788) | Acc: (94.00%) (8558/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.1788) | Acc: (94.00%) (9762/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.1780) | Acc: (94.00%) (10959/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.1780) | Acc: (94.00%) (12164/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.1772) | Acc: (94.00%) (13368/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.1777) | Acc: (94.00%) (14574/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.1783) | Acc: (94.00%) (15775/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.1778) | Acc: (94.00%) (16991/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.1797) | Acc: (94.00%) (18189/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.1796) | Acc: (94.00%) (19390/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.1802) | Acc: (94.00%) (20590/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.1800) | Acc: (94.00%) (21800/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.1797) | Acc: (94.00%) (23006/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.1811) | Acc: (94.00%) (24195/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.1797) | Acc: (94.00%) (25408/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.1800) | Acc: (94.00%) (26620/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.1792) | Acc: (94.00%) (27829/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.1795) | Acc: (94.00%) (29026/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.1786) | Acc: (94.00%) (30247/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.1781) | Acc: (94.00%) (31450/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.1775) | Acc: (94.00%) (32672/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.1767) | Acc: (94.00%) (33893/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.1764) | Acc: (94.00%) (35099/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.1770) | Acc: (94.00%) (36297/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.1774) | Acc: (94.00%) (37495/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.1772) | Acc: (94.00%) (38698/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.1773) | Acc: (94.00%) (39892/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.1772) | Acc: (94.00%) (41101/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.1772) | Acc: (94.00%) (42301/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.1765) | Acc: (94.00%) (43521/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.1764) | Acc: (94.00%) (44725/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.1766) | Acc: (94.00%) (45923/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.1763) | Acc: (94.00%) (47083/50000)
# TEST : Loss: (0.2931) | Acc: (90.00%) (9026/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.6153e-03, -1.8996e-03, -1.1708e-03],
          [-8.4431e-05,  1.0582e-04,  3.7939e-03],
          [ 1.8234e-03, -3.3737e-03, -5.8636e-03]],

         [[-2.8930e-03, -1.9132e-03, -1.4265e-03],
          [-4.8661e-03,  1.5141e-03,  1.9940e-03],
          [ 4.2257e-04,  3.9932e-03, -8.5273e-05]],

         [[-5.9214e-03,  3.3982e-03, -7.9030e-03],
          [ 5.6143e-03,  1.2131e-02,  6.4524e-03],
          [ 9.5534e-04,  8.6445e-03,  5.4314e-03]]],


        [[[ 3.6073e-01, -1.7671e-02,  2.5395e-01],
          [ 1.5411e-01,  1.2353e-03, -1.7880e-01],
          [-2.1097e-01, -3.1436e-01, -2.5889e-01]],

         [[-1.2725e-02, -2.6741e-01, -1.2692e-03],
          [-9.2207e-02,  4.0200e-01, -2.0559e-01],
          [ 2.1199e-01,  1.1040e-01,  2.2419e-01]],

         [[-1.8769e-01, -2.3146e-01, -4.8263e-02],
          [-2.3094e-01,  1.5742e-01, -2.7530e-02],
          [ 2.5853e-02,  1.5394e-01,  2.4765e-01]]],


        [[[-1.6013e-40,  6.1813e-41,  1.2809e-41],
          [-1.7597e-40,  1.0496e-41,  1.8626e-40],
          [ 9.5901e-41, -1.9567e-40, -1.5300e-40]],

         [[-9.2496e-41,  1.3003e-40,  5.8130e-41],
          [-1.4056e-40,  1.5919e-40, -5.7762e-42],
          [-1.6533e-40,  7.0470e-41, -2.0144e-40]],

         [[-8.9770e-41, -6.1632e-41,  7.3764e-41],
          [ 3.6388e-41, -1.3518e-40, -1.3882e-40],
          [-1.2538e-40, -7.1046e-43, -2.0957e-40]]],


        ...,


        [[[ 4.2787e-02,  5.0284e-02, -1.3324e-02],
          [ 1.5770e-02,  5.0034e-02, -5.6098e-03],
          [-1.5901e-01,  5.6382e-03,  3.7956e-02]],

         [[-1.1331e-01, -1.4629e-01, -2.8726e-02],
          [ 7.6921e-02,  5.6646e-03, -1.3099e-01],
          [ 9.2333e-02, -4.0868e-02, -3.1425e-02]],

         [[ 3.3465e-02,  1.4145e-01,  1.0854e-01],
          [ 2.7262e-01,  3.6942e-01,  1.7249e-01],
          [ 2.4185e-01,  2.4215e-01,  7.0590e-02]]],


        [[[ 2.8059e-01,  3.8948e-02,  9.7808e-02],
          [ 1.0575e-01, -9.0407e-02, -5.0561e-02],
          [ 2.4136e-02,  1.0235e-01,  4.5469e-02]],

         [[-4.1524e-02, -2.8044e-01, -4.0993e-02],
          [-5.5854e-02, -2.9432e-01, -2.0672e-01],
          [-1.6601e-03, -7.3858e-02, -7.2921e-02]],

         [[ 7.1549e-02, -2.1233e-01, -5.3371e-02],
          [-1.2262e-02, -8.1597e-02,  1.7036e-02],
          [-4.5588e-02,  3.8544e-02,  1.3087e-01]]],


        [[[ 4.7859e-02, -2.1772e-01,  7.5095e-03],
          [-1.9475e-01, -5.0511e-01, -2.3199e-01],
          [ 1.3194e-01, -4.5731e-02, -1.7949e-02]],

         [[ 1.3943e-01, -2.6263e-01, -8.0035e-03],
          [ 1.6040e-03, -2.5127e-01,  3.0934e-02],
          [ 1.6561e-01,  1.9218e-01,  4.5660e-02]],

         [[ 5.0164e-02, -2.3264e-01,  8.4835e-02],
          [ 7.4955e-02, -7.6143e-02,  9.2375e-02],
          [-8.9405e-02,  2.0152e-02,  1.3261e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2883]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0118]], device='cuda:0')

Epoch: 109 | Batch_idx: 0 |  Loss: (0.2653) | Acc: (93.00%) (120/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.1787) | Acc: (94.00%) (1329/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.1854) | Acc: (94.00%) (2530/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.1878) | Acc: (94.00%) (3738/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.1874) | Acc: (94.00%) (4937/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.1855) | Acc: (94.00%) (6144/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.1874) | Acc: (94.00%) (7342/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.1876) | Acc: (94.00%) (8545/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.1834) | Acc: (94.00%) (9759/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.1825) | Acc: (94.00%) (10964/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.1824) | Acc: (94.00%) (12170/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.1818) | Acc: (94.00%) (13385/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.1813) | Acc: (94.00%) (14593/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.1812) | Acc: (94.00%) (15797/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.1814) | Acc: (94.00%) (16998/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.1809) | Acc: (94.00%) (18207/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.1801) | Acc: (94.00%) (19424/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.1816) | Acc: (94.00%) (20616/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.1822) | Acc: (94.00%) (21813/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.1823) | Acc: (94.00%) (23017/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.1839) | Acc: (94.00%) (24206/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.1837) | Acc: (94.00%) (25410/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.1835) | Acc: (94.00%) (26615/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.1843) | Acc: (94.00%) (27809/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.1848) | Acc: (93.00%) (28994/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.1845) | Acc: (94.00%) (30202/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.1843) | Acc: (94.00%) (31407/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.1840) | Acc: (94.00%) (32615/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.1840) | Acc: (94.00%) (33821/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.1836) | Acc: (94.00%) (35030/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.1830) | Acc: (94.00%) (36244/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.1838) | Acc: (94.00%) (37438/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.1836) | Acc: (94.00%) (38655/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.1838) | Acc: (94.00%) (39858/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.1841) | Acc: (94.00%) (41063/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.1847) | Acc: (94.00%) (42245/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.1850) | Acc: (94.00%) (43456/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.1848) | Acc: (94.00%) (44662/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.1847) | Acc: (94.00%) (45871/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.1844) | Acc: (94.00%) (47031/50000)
# TEST : Loss: (0.2910) | Acc: (90.00%) (9017/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2257e-03, -9.1000e-04, -5.5691e-04],
          [-4.4760e-05,  5.8468e-05,  2.0661e-03],
          [ 9.9028e-04, -1.9327e-03, -3.3052e-03]],

         [[-1.4374e-03, -9.4241e-04, -6.9930e-04],
          [-2.4161e-03,  7.5371e-04,  9.7985e-04],
          [ 2.0974e-04,  2.0332e-03, -4.2633e-05]],

         [[-3.1647e-03,  1.8074e-03, -4.2036e-03],
          [ 2.7590e-03,  5.8625e-03,  3.0859e-03],
          [ 4.5659e-04,  4.1227e-03,  2.5512e-03]]],


        [[[ 3.6001e-01, -1.7636e-02,  2.5344e-01],
          [ 1.5378e-01,  1.2327e-03, -1.7843e-01],
          [-2.1053e-01, -3.1371e-01, -2.5836e-01]],

         [[-1.2699e-02, -2.6686e-01, -1.2666e-03],
          [-9.2008e-02,  4.0113e-01, -2.0515e-01],
          [ 2.1154e-01,  1.1017e-01,  2.2372e-01]],

         [[-1.8727e-01, -2.3094e-01, -4.8155e-02],
          [-2.3041e-01,  1.5705e-01, -2.7468e-02],
          [ 2.5795e-02,  1.5359e-01,  2.4710e-01]]],


        [[[-1.8918e-40,  1.7247e-41, -1.2142e-40],
          [-2.0892e-40, -1.2888e-40,  2.2088e-40],
          [ 9.4794e-41, -2.1131e-40,  1.7033e-40]],

         [[ 5.8423e-41, -1.4403e-40,  1.1560e-40],
          [ 3.1588e-41, -1.3822e-40,  1.2542e-40],
          [-1.3641e-40, -4.8685e-41,  1.1516e-40]],

         [[-6.2564e-41,  1.2804e-40, -1.7080e-40],
          [ 4.3042e-41, -8.9219e-41,  1.9230e-40],
          [ 1.4523e-40,  1.9511e-40,  1.9545e-41]]],


        ...,


        [[[ 4.2290e-02,  4.9714e-02, -1.3178e-02],
          [ 1.5584e-02,  4.9453e-02, -5.5459e-03],
          [-1.5718e-01,  5.5743e-03,  3.7538e-02]],

         [[-1.1164e-01, -1.4419e-01, -2.8332e-02],
          [ 7.5669e-02,  5.5727e-03, -1.2895e-01],
          [ 9.0896e-02, -4.0232e-02, -3.0960e-02]],

         [[ 3.2737e-02,  1.3839e-01,  1.0648e-01],
          [ 2.6261e-01,  3.5433e-01,  1.6762e-01],
          [ 2.3423e-01,  2.3393e-01,  6.8850e-02]]],


        [[[ 2.7763e-01,  3.8466e-02,  9.6600e-02],
          [ 1.0461e-01, -8.9221e-02, -4.9910e-02],
          [ 2.3892e-02,  1.0122e-01,  4.4976e-02]],

         [[-4.0991e-02, -2.7507e-01, -4.0260e-02],
          [-5.5094e-02, -2.8760e-01, -2.0258e-01],
          [-1.6411e-03, -7.2818e-02, -7.1961e-02]],

         [[ 7.0498e-02, -2.0761e-01, -5.2268e-02],
          [-1.2066e-02, -7.9400e-02,  1.6642e-02],
          [-4.4988e-02,  3.7920e-02,  1.2892e-01]]],


        [[[ 4.7376e-02, -2.1424e-01,  7.4245e-03],
          [-1.9272e-01, -4.9622e-01, -2.2924e-01],
          [ 1.3098e-01, -4.5345e-02, -1.7811e-02]],

         [[ 1.3825e-01, -2.5978e-01, -7.9305e-03],
          [ 1.5900e-03, -2.4841e-01,  3.0642e-02],
          [ 1.6449e-01,  1.9073e-01,  4.5339e-02]],

         [[ 4.9749e-02, -2.3044e-01,  8.4109e-02],
          [ 7.4327e-02, -7.5414e-02,  9.1576e-02],
          [-8.8782e-02,  2.0002e-02,  1.3167e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2938]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0057]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 110 | Batch_idx: 0 |  Loss: (0.1119) | Acc: (96.00%) (124/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.2596) | Acc: (91.00%) (1287/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.2810) | Acc: (90.00%) (2433/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.3182) | Acc: (89.00%) (3537/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.3504) | Acc: (88.00%) (4632/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.3617) | Acc: (87.00%) (5731/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.3621) | Acc: (87.00%) (6850/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.3646) | Acc: (87.00%) (7951/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.3679) | Acc: (87.00%) (9072/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.3680) | Acc: (87.00%) (10193/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.3697) | Acc: (87.00%) (11319/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.3743) | Acc: (87.00%) (12416/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.3725) | Acc: (87.00%) (13542/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.3724) | Acc: (87.00%) (14662/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.3736) | Acc: (87.00%) (15772/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.3737) | Acc: (87.00%) (16891/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.3702) | Acc: (87.00%) (18027/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.3701) | Acc: (87.00%) (19147/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.3699) | Acc: (87.00%) (20270/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.3687) | Acc: (87.00%) (21405/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.3662) | Acc: (87.00%) (22544/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.3638) | Acc: (87.00%) (23680/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.3621) | Acc: (87.00%) (24809/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.3605) | Acc: (87.00%) (25945/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.3582) | Acc: (87.00%) (27099/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.3556) | Acc: (87.00%) (28234/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.3532) | Acc: (87.00%) (29391/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.3502) | Acc: (88.00%) (30564/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.3480) | Acc: (88.00%) (31718/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.3461) | Acc: (88.00%) (32873/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.3446) | Acc: (88.00%) (34022/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.3427) | Acc: (88.00%) (35176/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.3424) | Acc: (88.00%) (36306/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.3424) | Acc: (88.00%) (37425/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.3408) | Acc: (88.00%) (38580/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.3387) | Acc: (88.00%) (39743/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.3390) | Acc: (88.00%) (40877/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.3383) | Acc: (88.00%) (42016/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.3364) | Acc: (88.00%) (43179/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.3350) | Acc: (88.00%) (44301/50000)
# TEST : Loss: (0.3397) | Acc: (88.00%) (8883/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-4.8587e-04, -3.7053e-04, -2.2481e-04],
          [-2.0634e-05,  2.8352e-05,  9.8436e-04],
          [ 4.7022e-04, -9.7965e-04, -1.6426e-03]],

         [[-6.1208e-04, -3.9705e-04, -2.9291e-04],
          [-1.0279e-03,  3.2168e-04,  4.1161e-04],
          [ 8.9192e-05,  8.9205e-04, -1.8292e-05]],

         [[-1.4735e-03,  8.3654e-04, -1.9457e-03],
          [ 1.1590e-03,  2.4129e-03,  1.2540e-03],
          [ 1.8539e-04,  1.6695e-03,  1.0140e-03]]],


        [[[ 3.5978e-01, -1.1206e-02,  2.5819e-01],
          [ 1.4163e-01, -2.6280e-03, -1.8416e-01],
          [-2.1711e-01, -3.2383e-01, -2.5624e-01]],

         [[-2.8693e-02, -2.7826e-01, -1.6294e-02],
          [-1.1036e-01,  3.9630e-01, -2.1249e-01],
          [ 2.0149e-01,  1.0637e-01,  2.3154e-01]],

         [[-1.9039e-01, -2.3165e-01, -4.8678e-02],
          [-2.3744e-01,  1.5747e-01, -2.8674e-02],
          [ 2.6316e-02,  1.5804e-01,  2.6347e-01]]],


        [[[ 8.7527e-41,  2.2100e-41,  1.9762e-40],
          [ 1.9293e-40,  1.9745e-40, -2.0322e-40],
          [ 8.9441e-41, -3.0760e-41,  1.3198e-40]],

         [[ 1.9436e-40,  2.0064e-40, -2.2160e-41],
          [ 9.0380e-41, -1.3522e-40,  1.1785e-41],
          [-2.0787e-40,  2.3710e-41, -1.4711e-40]],

         [[-1.4967e-40, -1.7158e-40,  1.0702e-40],
          [ 1.5141e-40,  4.3412e-42, -9.3797e-41],
          [-1.9835e-40,  1.0150e-40,  1.1929e-40]]],


        ...,


        [[[ 3.3807e-02,  4.1467e-02, -1.9217e-02],
          [ 1.3486e-02,  5.2735e-02, -3.9975e-04],
          [-1.5867e-01,  6.4783e-03,  3.6139e-02]],

         [[-1.2333e-01, -1.5617e-01, -4.0406e-02],
          [ 7.7321e-02,  1.4662e-02, -1.2238e-01],
          [ 9.4728e-02, -3.2141e-02, -3.3390e-02]],

         [[ 2.2637e-02,  1.2647e-01,  9.2322e-02],
          [ 2.7664e-01,  3.8214e-01,  1.7654e-01],
          [ 2.3162e-01,  2.3496e-01,  5.7110e-02]]],


        [[[ 2.8517e-01,  4.2561e-02,  8.4246e-02],
          [ 9.8682e-02, -1.0683e-01, -7.4511e-02],
          [ 2.6785e-02,  9.4293e-02,  2.8735e-02]],

         [[-3.5327e-02, -2.5725e-01, -3.5275e-02],
          [-6.9116e-02, -3.1486e-01, -2.3095e-01],
          [ 2.3375e-04, -8.3850e-02, -9.1643e-02]],

         [[ 5.8592e-02, -2.1383e-01, -7.4388e-02],
          [-4.0542e-02, -1.2016e-01, -3.2341e-02],
          [-5.4056e-02,  1.7978e-02,  9.4504e-02]]],


        [[[ 7.4228e-02, -2.0359e-01,  8.0664e-03],
          [-1.6506e-01, -5.0649e-01, -2.6084e-01],
          [ 1.5166e-01, -4.3621e-02, -2.9328e-02]],

         [[ 1.4175e-01, -2.7179e-01, -1.8975e-02],
          [ 1.1200e-02, -2.7199e-01, -1.2397e-03],
          [ 1.7580e-01,  1.8243e-01,  3.1780e-02]],

         [[ 5.7722e-02, -2.2585e-01,  8.6889e-02],
          [ 8.6787e-02, -7.5281e-02,  8.1605e-02],
          [-7.9397e-02,  2.1355e-02,  1.2750e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0096, -0.0230, -0.0370],
          [ 0.0194, -0.0127, -0.0607],
          [ 0.0281, -0.0121, -0.0496]],

         [[ 0.0441,  0.0157, -0.0047],
          [ 0.0514,  0.0213, -0.0203],
          [ 0.0510,  0.0076, -0.0225]],

         [[ 0.0719,  0.0471,  0.0255],
          [ 0.0831,  0.0517,  0.0192],
          [ 0.0735,  0.0413,  0.0124]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0025, -0.0014, -0.0035],
          [-0.0070, -0.0051, -0.0049],
          [-0.0048, -0.0022, -0.0023]],

         [[-0.0005,  0.0018, -0.0000],
          [-0.0036, -0.0001, -0.0002],
          [-0.0011,  0.0021,  0.0022]],

         [[-0.0000,  0.0021,  0.0003],
          [-0.0027,  0.0004,  0.0011],
          [-0.0008,  0.0026,  0.0028]]],


        [[[ 0.0012, -0.0014, -0.0038],
          [-0.0039, -0.0072, -0.0057],
          [-0.0152, -0.0147, -0.0132]],

         [[ 0.0063,  0.0039, -0.0002],
          [ 0.0005, -0.0015, -0.0016],
          [-0.0101, -0.0074, -0.0062]],

         [[ 0.0032,  0.0013, -0.0037],
          [-0.0038, -0.0047, -0.0046],
          [-0.0139, -0.0113, -0.0106]]],


        [[[-0.0077, -0.0069, -0.0091],
          [-0.0083, -0.0034, -0.0009],
          [-0.0195, -0.0055, -0.0018]],

         [[-0.0057, -0.0079, -0.0109],
          [-0.0051, -0.0029, -0.0015],
          [-0.0153, -0.0038,  0.0001]],

         [[-0.0166, -0.0173, -0.0198],
          [-0.0170, -0.0138, -0.0131],
          [-0.0273, -0.0163, -0.0146]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2929]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 111 | Batch_idx: 0 |  Loss: (0.1437) | Acc: (94.00%) (121/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.2500) | Acc: (91.00%) (1289/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.2565) | Acc: (91.00%) (2453/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.2443) | Acc: (91.00%) (3642/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.2496) | Acc: (91.00%) (4813/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.2559) | Acc: (91.00%) (5974/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.2595) | Acc: (91.00%) (7135/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.2565) | Acc: (91.00%) (8309/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.2557) | Acc: (91.00%) (9483/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.2557) | Acc: (91.00%) (10644/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.2523) | Acc: (91.00%) (11828/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.2539) | Acc: (91.00%) (12987/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.2532) | Acc: (91.00%) (14148/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.2541) | Acc: (91.00%) (15313/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.2566) | Acc: (91.00%) (16465/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.2569) | Acc: (91.00%) (17637/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.2579) | Acc: (91.00%) (18792/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.2593) | Acc: (91.00%) (19954/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.2587) | Acc: (91.00%) (21116/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.2586) | Acc: (91.00%) (22287/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.2594) | Acc: (91.00%) (23449/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.2585) | Acc: (91.00%) (24630/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.2572) | Acc: (91.00%) (25806/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.2575) | Acc: (91.00%) (26969/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.2576) | Acc: (91.00%) (28127/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.2569) | Acc: (91.00%) (29309/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.2566) | Acc: (91.00%) (30474/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.2571) | Acc: (91.00%) (31637/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.2566) | Acc: (91.00%) (32813/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.2579) | Acc: (91.00%) (33980/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.2586) | Acc: (91.00%) (35136/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.2588) | Acc: (91.00%) (36306/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.2586) | Acc: (91.00%) (37476/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.2584) | Acc: (91.00%) (38648/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.2577) | Acc: (91.00%) (39828/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.2567) | Acc: (91.00%) (41006/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.2568) | Acc: (91.00%) (42183/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.2559) | Acc: (91.00%) (43366/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.2565) | Acc: (91.00%) (44528/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.2561) | Acc: (91.00%) (45657/50000)
# TEST : Loss: (0.3968) | Acc: (87.00%) (8753/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5680e-04, -1.2359e-04, -7.4189e-05],
          [-8.0151e-06,  1.1718e-05,  3.9812e-04],
          [ 1.8940e-04, -4.2748e-04, -6.9958e-04]],

         [[-2.1568e-04, -1.3810e-04, -1.0115e-04],
          [-3.6184e-04,  1.1367e-04,  1.4265e-04],
          [ 3.1380e-05,  3.2611e-04, -6.5060e-06]],

         [[-5.7936e-04,  3.2654e-04, -7.5959e-04],
          [ 4.0170e-04,  8.1553e-04,  4.1720e-04],
          [ 6.1617e-05,  5.5313e-04,  3.2833e-04]]],


        [[[ 3.6532e-01, -1.7693e-02,  2.4810e-01],
          [ 1.4347e-01, -1.2450e-02, -1.9328e-01],
          [-2.0843e-01, -3.2112e-01, -2.5548e-01]],

         [[-2.5459e-02, -2.8677e-01, -2.5706e-02],
          [-1.0676e-01,  3.9255e-01, -2.1930e-01],
          [ 2.1752e-01,  1.1960e-01,  2.3579e-01]],

         [[-1.8788e-01, -2.4361e-01, -5.7998e-02],
          [-2.4035e-01,  1.4647e-01, -3.9469e-02],
          [ 3.5290e-02,  1.6156e-01,  2.5954e-01]]],


        [[[ 1.8791e-40,  1.8696e-40,  9.6212e-41],
          [ 1.7001e-40, -1.0147e-40,  1.5160e-40],
          [ 5.1470e-41,  2.2081e-40, -1.6955e-40]],

         [[-2.3732e-40,  2.0550e-40,  9.6094e-41],
          [-1.0645e-40, -9.4180e-41, -1.0896e-40],
          [-1.8923e-40, -6.4631e-41, -1.7345e-40]],

         [[-1.4602e-40, -1.6736e-40,  1.5454e-40],
          [ 5.9798e-41,  2.6202e-40, -1.6906e-40],
          [ 1.0134e-41,  2.3864e-40,  1.6870e-40]]],


        ...,


        [[[ 4.5124e-02,  4.5565e-02, -1.5157e-02],
          [ 2.4378e-02,  6.0125e-02,  1.1043e-03],
          [-1.4598e-01,  1.7645e-02,  4.1025e-02]],

         [[-1.1711e-01, -1.5855e-01, -4.3799e-02],
          [ 8.8894e-02,  1.9242e-02, -1.2683e-01],
          [ 1.1472e-01, -1.3123e-02, -2.8056e-02]],

         [[ 2.1393e-02,  1.2416e-01,  8.9827e-02],
          [ 2.7060e-01,  3.7878e-01,  1.6177e-01],
          [ 2.4815e-01,  2.6547e-01,  6.3818e-02]]],


        [[[ 2.8363e-01,  3.1028e-02,  7.0733e-02],
          [ 8.7959e-02, -1.2503e-01, -8.1621e-02],
          [ 2.5866e-02,  9.9028e-02,  4.8044e-02]],

         [[-3.9225e-02, -2.7052e-01, -4.4059e-02],
          [-8.4658e-02, -3.3525e-01, -2.2213e-01],
          [-3.2833e-04, -6.9478e-02, -6.1086e-02]],

         [[ 6.1800e-02, -2.1749e-01, -7.4998e-02],
          [-4.8317e-02, -1.2106e-01, -7.8280e-03],
          [-4.3334e-02,  4.6477e-02,  1.3112e-01]]],


        [[[ 8.2943e-02, -1.9667e-01,  3.1695e-02],
          [-1.5832e-01, -5.0379e-01, -2.4795e-01],
          [ 1.6470e-01, -2.9575e-02, -1.7452e-02]],

         [[ 1.4912e-01, -2.7349e-01, -8.0033e-03],
          [ 1.8589e-02, -2.7333e-01,  7.3678e-03],
          [ 1.8685e-01,  1.8822e-01,  3.6187e-02]],

         [[ 6.1337e-02, -2.3311e-01,  9.1005e-02],
          [ 9.3298e-02, -7.7113e-02,  8.9500e-02],
          [-6.2905e-02,  2.8751e-02,  1.3119e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0212,  0.0053,  0.0269],
          [-0.0261, -0.0244,  0.0180],
          [-0.0216, -0.0142, -0.0081]],

         [[-0.0331, -0.0145,  0.0103],
          [-0.0531, -0.0383,  0.0151],
          [-0.0307, -0.0212, -0.0206]],

         [[-0.0372, -0.0248, -0.0124],
          [-0.0296, -0.0121,  0.0273],
          [-0.0039,  0.0063,  0.0004]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0236,  0.0232,  0.0170],
          [ 0.0158,  0.0210,  0.0163],
          [ 0.0036,  0.0090,  0.0075]],

         [[ 0.0221,  0.0197,  0.0117],
          [ 0.0165,  0.0188,  0.0110],
          [ 0.0050,  0.0073,  0.0042]],

         [[ 0.0142,  0.0083, -0.0003],
          [ 0.0064,  0.0054, -0.0038],
          [-0.0032, -0.0042, -0.0083]]],


        [[[ 0.0002, -0.0059,  0.0007],
          [ 0.0066,  0.0038,  0.0095],
          [ 0.0036,  0.0062,  0.0117]],

         [[-0.0026, -0.0076,  0.0017],
          [ 0.0039,  0.0033,  0.0086],
          [ 0.0009,  0.0033,  0.0074]],

         [[ 0.0030, -0.0040,  0.0028],
          [ 0.0053,  0.0032,  0.0076],
          [ 0.0012,  0.0039,  0.0082]]],


        [[[-0.0107, -0.0033,  0.0042],
          [ 0.0018,  0.0056,  0.0100],
          [ 0.0078,  0.0170,  0.0270]],

         [[-0.0218, -0.0149, -0.0027],
          [-0.0079, -0.0002,  0.0073],
          [-0.0001,  0.0063,  0.0162]],

         [[-0.0199, -0.0159, -0.0109],
          [-0.0113, -0.0075, -0.0006],
          [-0.0059, -0.0018,  0.0112]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2923]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 112 | Batch_idx: 0 |  Loss: (0.2235) | Acc: (92.00%) (118/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.2292) | Acc: (92.00%) (1300/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.2357) | Acc: (91.00%) (2458/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.2144) | Acc: (92.00%) (3667/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.2187) | Acc: (92.00%) (4849/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.2178) | Acc: (92.00%) (6038/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.2224) | Acc: (92.00%) (7206/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.2214) | Acc: (92.00%) (8395/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.2212) | Acc: (92.00%) (9572/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.2200) | Acc: (92.00%) (10766/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.2225) | Acc: (92.00%) (11943/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.2215) | Acc: (92.00%) (13129/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.2209) | Acc: (92.00%) (14314/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.2230) | Acc: (92.00%) (15489/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.2239) | Acc: (92.00%) (16666/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.2257) | Acc: (92.00%) (17834/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.2254) | Acc: (92.00%) (19024/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.2264) | Acc: (92.00%) (20194/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.2267) | Acc: (92.00%) (21379/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.2290) | Acc: (92.00%) (22545/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.2291) | Acc: (92.00%) (23722/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.2297) | Acc: (92.00%) (24909/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.2318) | Acc: (92.00%) (26067/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.2329) | Acc: (92.00%) (27231/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.2336) | Acc: (92.00%) (28397/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.2331) | Acc: (92.00%) (29587/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.2326) | Acc: (92.00%) (30774/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.2335) | Acc: (92.00%) (31946/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.2342) | Acc: (92.00%) (33111/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.2350) | Acc: (92.00%) (34280/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.2345) | Acc: (92.00%) (35462/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.2333) | Acc: (92.00%) (36660/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.2325) | Acc: (92.00%) (37845/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.2322) | Acc: (92.00%) (39026/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.2324) | Acc: (92.00%) (40209/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.2317) | Acc: (92.00%) (41394/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.2318) | Acc: (92.00%) (42571/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.2314) | Acc: (92.00%) (43755/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.2308) | Acc: (92.00%) (44945/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.2307) | Acc: (92.00%) (46079/50000)
# TEST : Loss: (0.3763) | Acc: (88.00%) (8807/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-3.9290e-05, -3.2254e-05, -1.9110e-05],
          [-2.5230e-06,  3.9805e-06,  1.3170e-04],
          [ 6.2338e-05, -1.5523e-04, -2.4659e-04]],

         [[-6.0227e-05, -3.7948e-05, -2.7551e-05],
          [-1.0091e-04,  3.1852e-05,  3.9025e-05],
          [ 8.7452e-06,  9.5273e-05, -1.8377e-06]],

         [[-1.8512e-04,  1.0341e-04, -2.4058e-04],
          [ 1.0990e-04,  2.1633e-04,  1.0855e-04],
          [ 1.6011e-05,  1.4317e-04,  8.2614e-05]]],


        [[[ 3.6779e-01, -1.2622e-02,  2.6425e-01],
          [ 1.5143e-01,  3.0791e-03, -1.8085e-01],
          [-2.1223e-01, -3.1994e-01, -2.5492e-01]],

         [[-2.6426e-02, -2.8593e-01, -1.4117e-02],
          [-1.0339e-01,  4.0402e-01, -2.0919e-01],
          [ 2.0864e-01,  1.2061e-01,  2.3928e-01]],

         [[-1.8973e-01, -2.4708e-01, -5.2501e-02],
          [-2.4146e-01,  1.5094e-01, -3.5682e-02],
          [ 2.4547e-02,  1.5673e-01,  2.5661e-01]]],


        [[[ 2.1828e-40,  1.2543e-40, -1.3834e-40],
          [ 9.9431e-41,  1.1044e-40, -1.5860e-40],
          [ 5.8841e-41,  1.9311e-40,  1.1636e-40]],

         [[-1.7258e-40,  1.7310e-40, -1.3818e-40],
          [ 1.5279e-40,  1.8735e-40,  1.3006e-40],
          [-2.1993e-40,  3.0124e-41, -2.0165e-40]],

         [[ 2.3738e-42, -1.3036e-41, -1.2568e-40],
          [ 1.3903e-40, -2.5417e-40, -1.9612e-40],
          [-2.0912e-40, -2.4431e-40,  1.9693e-40]]],


        ...,


        [[[ 1.8381e-02,  2.3672e-02, -3.0409e-02],
          [ 3.2233e-03,  3.9220e-02, -1.5221e-02],
          [-1.6638e-01, -3.6513e-03,  2.5424e-02]],

         [[-1.4262e-01, -1.7355e-01, -5.1864e-02],
          [ 7.4834e-02,  1.0090e-02, -1.3183e-01],
          [ 1.0064e-01, -2.4565e-02, -3.4829e-02]],

         [[-8.9875e-03,  1.0398e-01,  7.8283e-02],
          [ 2.6413e-01,  3.7881e-01,  1.7006e-01],
          [ 2.4397e-01,  2.6671e-01,  7.5898e-02]]],


        [[[ 2.7930e-01,  2.5303e-02,  7.0161e-02],
          [ 7.7082e-02, -1.3159e-01, -8.6897e-02],
          [ 9.6355e-03,  8.7130e-02,  3.9751e-02]],

         [[-4.1816e-02, -2.7455e-01, -4.3906e-02],
          [-9.4625e-02, -3.4179e-01, -2.2962e-01],
          [-1.4797e-02, -8.1848e-02, -7.3545e-02]],

         [[ 6.3195e-02, -2.2219e-01, -7.9081e-02],
          [-5.2723e-02, -1.2767e-01, -2.1449e-02],
          [-5.3025e-02,  3.6318e-02,  1.1516e-01]]],


        [[[ 7.0138e-02, -2.0464e-01,  3.2849e-02],
          [-1.7936e-01, -5.2528e-01, -2.6343e-01],
          [ 1.4792e-01, -4.1637e-02, -2.7310e-02]],

         [[ 1.4693e-01, -2.6601e-01, -3.3511e-03],
          [ 9.3009e-03, -2.7694e-01, -1.8182e-03],
          [ 1.7725e-01,  1.8309e-01,  2.8644e-02]],

         [[ 6.6891e-02, -2.1612e-01,  1.0490e-01],
          [ 9.3898e-02, -6.4637e-02,  9.3655e-02],
          [-6.4148e-02,  3.5141e-02,  1.3398e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0245,  0.0440,  0.0796],
          [ 0.0052,  0.0027,  0.0443],
          [-0.0075, -0.0019,  0.0408]],

         [[ 0.0098,  0.0201,  0.0529],
          [-0.0107, -0.0155,  0.0280],
          [-0.0208, -0.0085,  0.0417]],

         [[ 0.0144,  0.0147,  0.0434],
          [-0.0131, -0.0157,  0.0189],
          [-0.0303, -0.0118,  0.0396]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0195, -0.0173, -0.0164],
          [-0.0147, -0.0137, -0.0145],
          [-0.0121, -0.0128, -0.0141]],

         [[-0.0147, -0.0123, -0.0102],
          [-0.0096, -0.0077, -0.0075],
          [-0.0065, -0.0065, -0.0068]],

         [[-0.0127, -0.0092, -0.0064],
          [-0.0071, -0.0042, -0.0030],
          [-0.0017, -0.0003,  0.0000]]],


        [[[ 0.0070,  0.0111,  0.0109],
          [ 0.0015,  0.0031,  0.0054],
          [ 0.0035,  0.0068,  0.0105]],

         [[ 0.0047,  0.0089,  0.0088],
          [-0.0030, -0.0010,  0.0015],
          [-0.0006,  0.0037,  0.0076]],

         [[-0.0002,  0.0042,  0.0055],
          [-0.0068, -0.0039, -0.0012],
          [-0.0033,  0.0013,  0.0050]]],


        [[[-0.0259, -0.0083,  0.0003],
          [-0.0332, -0.0150, -0.0102],
          [-0.0344, -0.0199, -0.0169]],

         [[-0.0291, -0.0119, -0.0043],
          [-0.0381, -0.0203, -0.0173],
          [-0.0396, -0.0262, -0.0255]],

         [[-0.0249, -0.0078, -0.0018],
          [-0.0332, -0.0154, -0.0130],
          [-0.0334, -0.0193, -0.0181]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2916]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 113 | Batch_idx: 0 |  Loss: (0.1152) | Acc: (98.00%) (126/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.2100) | Acc: (93.00%) (1313/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1757) | Acc: (94.00%) (2535/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1795) | Acc: (93.00%) (3725/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1760) | Acc: (93.00%) (4928/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1793) | Acc: (93.00%) (6119/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1813) | Acc: (93.00%) (7316/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1868) | Acc: (93.00%) (8503/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1927) | Acc: (93.00%) (9677/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1968) | Acc: (93.00%) (10861/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1972) | Acc: (93.00%) (12051/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1955) | Acc: (93.00%) (13252/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1973) | Acc: (93.00%) (14436/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1988) | Acc: (93.00%) (15624/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.2013) | Acc: (93.00%) (16805/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.2021) | Acc: (93.00%) (17983/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.2030) | Acc: (93.00%) (19170/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.2030) | Acc: (93.00%) (20361/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.2047) | Acc: (92.00%) (21546/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.2047) | Acc: (93.00%) (22746/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.2059) | Acc: (93.00%) (23933/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.2064) | Acc: (93.00%) (25124/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.2070) | Acc: (92.00%) (26298/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.2060) | Acc: (93.00%) (27501/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.2071) | Acc: (92.00%) (28681/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.2073) | Acc: (92.00%) (29858/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.2082) | Acc: (92.00%) (31043/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.2087) | Acc: (92.00%) (32223/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.2090) | Acc: (92.00%) (33410/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.2109) | Acc: (92.00%) (34577/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.2104) | Acc: (92.00%) (35777/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.2101) | Acc: (92.00%) (36964/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.2102) | Acc: (92.00%) (38152/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.2092) | Acc: (92.00%) (39357/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.2095) | Acc: (92.00%) (40538/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.2085) | Acc: (92.00%) (41740/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.2100) | Acc: (92.00%) (42910/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.2099) | Acc: (92.00%) (44102/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.2101) | Acc: (92.00%) (45285/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.2099) | Acc: (92.00%) (46427/50000)
# TEST : Loss: (0.3384) | Acc: (89.00%) (8919/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-7.2055e-06, -6.2199e-06, -3.6260e-06],
          [-6.1313e-07,  1.0625e-06,  3.4021e-05],
          [ 1.6004e-05, -4.4976e-05, -6.8881e-05]],

         [[-1.2626e-05, -7.7990e-06, -5.6012e-06],
          [-2.1120e-05,  6.7061e-06,  7.9768e-06],
          [ 1.8289e-06,  2.1118e-05, -3.9073e-07]],

         [[-4.5824e-05,  2.5317e-05, -5.8908e-05],
          [ 2.2466e-05,  4.2565e-05,  2.0852e-05],
          [ 3.0712e-06,  2.7328e-05,  1.5228e-05]]],


        [[[ 3.6968e-01, -1.2999e-02,  2.5868e-01],
          [ 1.5232e-01,  3.3028e-04, -1.8917e-01],
          [-2.1763e-01, -3.3173e-01, -2.7014e-01]],

         [[-2.1982e-02, -2.8675e-01, -2.0572e-02],
          [-9.6130e-02,  4.0579e-01, -2.1695e-01],
          [ 2.0881e-01,  1.1459e-01,  2.3011e-01]],

         [[-1.8236e-01, -2.4540e-01, -5.5617e-02],
          [-2.3584e-01,  1.5494e-01, -3.9871e-02],
          [ 2.3777e-02,  1.5276e-01,  2.4903e-01]]],


        [[[-1.6164e-40,  2.1620e-40,  9.7762e-41],
          [-3.4180e-40, -1.6783e-40, -2.5984e-40],
          [ 1.0155e-40,  2.6653e-40, -1.5914e-40]],

         [[ 2.7502e-40,  8.2203e-41,  1.6813e-40],
          [-1.0706e-40,  1.3068e-40, -1.8215e-40],
          [ 1.5777e-40, -1.7067e-40,  1.0169e-41]],

         [[-1.1702e-40,  1.1040e-40, -1.3570e-41],
          [-1.5493e-40, -2.5071e-40,  1.8771e-40],
          [ 1.5995e-40,  1.5960e-40,  1.1283e-40]]],


        ...,


        [[[ 3.1680e-02,  3.5031e-02, -2.0033e-02],
          [ 1.9090e-02,  5.4236e-02, -6.5450e-04],
          [-1.5806e-01,  4.0821e-03,  3.3476e-02]],

         [[-1.2960e-01, -1.6239e-01, -4.3656e-02],
          [ 8.5636e-02,  2.0368e-02, -1.2205e-01],
          [ 9.7631e-02, -2.8863e-02, -3.7463e-02]],

         [[ 1.0498e-02,  1.1890e-01,  8.6394e-02],
          [ 2.9239e-01,  4.0064e-01,  1.8323e-01],
          [ 2.3977e-01,  2.4543e-01,  6.7328e-02]]],


        [[[ 3.0301e-01,  4.2753e-02,  7.6094e-02],
          [ 9.7598e-02, -1.1068e-01, -7.8489e-02],
          [ 2.8302e-02,  1.0330e-01,  4.5636e-02]],

         [[-2.6141e-02, -2.6403e-01, -4.7172e-02],
          [-7.9833e-02, -3.1372e-01, -2.1948e-01],
          [ 1.0491e-03, -6.0643e-02, -6.2546e-02]],

         [[ 6.4774e-02, -2.2325e-01, -9.1668e-02],
          [-5.7603e-02, -1.2320e-01, -2.7420e-02],
          [-5.1293e-02,  4.5754e-02,  1.1760e-01]]],


        [[[ 6.1709e-02, -2.1500e-01,  3.3623e-02],
          [-1.7867e-01, -5.1424e-01, -2.5112e-01],
          [ 1.5450e-01, -2.7307e-02, -1.6356e-02]],

         [[ 1.4174e-01, -2.7599e-01, -6.6040e-03],
          [ 9.8732e-03, -2.7200e-01,  5.4333e-03],
          [ 1.7790e-01,  1.9052e-01,  3.7196e-02]],

         [[ 6.3666e-02, -2.1782e-01,  1.0976e-01],
          [ 9.4410e-02, -5.4043e-02,  1.0821e-01],
          [-6.7376e-02,  4.4668e-02,  1.4724e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0646, -0.0573, -0.0527],
          [-0.0528, -0.0423, -0.0446],
          [-0.0682, -0.0653, -0.0578]],

         [[-0.0615, -0.0522, -0.0412],
          [-0.0517, -0.0383, -0.0334],
          [-0.0617, -0.0592, -0.0529]],

         [[-0.0361, -0.0181, -0.0080],
          [-0.0356, -0.0131, -0.0103],
          [-0.0486, -0.0412, -0.0342]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0020,  0.0110,  0.0136],
          [-0.0005,  0.0066,  0.0085],
          [ 0.0039,  0.0072,  0.0064]],

         [[-0.0017,  0.0079,  0.0109],
          [-0.0040,  0.0026,  0.0041],
          [-0.0002,  0.0017,  0.0006]],

         [[-0.0009,  0.0059,  0.0081],
          [-0.0029,  0.0016,  0.0027],
          [ 0.0011,  0.0014, -0.0000]]],


        [[[-0.0058, -0.0023,  0.0013],
          [-0.0047, -0.0010,  0.0030],
          [ 0.0026,  0.0064,  0.0109]],

         [[-0.0060, -0.0020,  0.0020],
          [-0.0051, -0.0013,  0.0028],
          [ 0.0025,  0.0059,  0.0108]],

         [[-0.0038, -0.0014,  0.0028],
          [-0.0028, -0.0001,  0.0040],
          [ 0.0038,  0.0071,  0.0114]]],


        [[[-0.0229, -0.0086, -0.0006],
          [-0.0149, -0.0018,  0.0080],
          [-0.0099,  0.0019,  0.0105]],

         [[-0.0187, -0.0053,  0.0016],
          [-0.0130, -0.0014,  0.0076],
          [-0.0079,  0.0015,  0.0095]],

         [[-0.0143, -0.0062, -0.0012],
          [-0.0101, -0.0026,  0.0051],
          [-0.0069, -0.0008,  0.0065]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2907]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 114 | Batch_idx: 0 |  Loss: (0.1574) | Acc: (94.00%) (121/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1720) | Acc: (94.00%) (1326/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1768) | Acc: (93.00%) (2523/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1821) | Acc: (93.00%) (3716/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1773) | Acc: (93.00%) (4921/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1766) | Acc: (93.00%) (6125/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1816) | Acc: (93.00%) (7307/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1865) | Acc: (93.00%) (8497/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1867) | Acc: (93.00%) (9698/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1877) | Acc: (93.00%) (10886/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1879) | Acc: (93.00%) (12081/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1880) | Acc: (93.00%) (13270/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1905) | Acc: (93.00%) (14460/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1912) | Acc: (93.00%) (15652/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1913) | Acc: (93.00%) (16854/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1922) | Acc: (93.00%) (18048/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1925) | Acc: (93.00%) (19243/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1923) | Acc: (93.00%) (20441/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1936) | Acc: (93.00%) (21613/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1950) | Acc: (93.00%) (22788/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1947) | Acc: (93.00%) (23979/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1937) | Acc: (93.00%) (25186/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1949) | Acc: (93.00%) (26359/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1955) | Acc: (93.00%) (27549/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.1960) | Acc: (93.00%) (28742/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.1972) | Acc: (93.00%) (29920/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.1973) | Acc: (93.00%) (31113/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1969) | Acc: (93.00%) (32315/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1972) | Acc: (93.00%) (33509/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1986) | Acc: (93.00%) (34687/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1986) | Acc: (93.00%) (35883/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1976) | Acc: (93.00%) (37086/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1983) | Acc: (93.00%) (38266/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1991) | Acc: (93.00%) (39448/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1990) | Acc: (93.00%) (40637/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1993) | Acc: (93.00%) (41822/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1985) | Acc: (93.00%) (43025/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1987) | Acc: (93.00%) (44218/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1991) | Acc: (93.00%) (45402/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1980) | Acc: (93.00%) (46570/50000)
# TEST : Loss: (0.3433) | Acc: (89.00%) (8937/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-8.9775e-07, -8.2477e-07, -4.7126e-07],
          [-1.0826e-07,  2.1067e-07,  6.4785e-06],
          [ 3.0243e-06, -9.8683e-06, -1.4446e-05]],

         [[-1.8568e-06, -1.1191e-06, -7.9299e-07],
          [-3.0999e-06,  9.9148e-07,  1.1369e-06],
          [ 2.6816e-07,  3.3278e-06, -5.8479e-08]],

         [[-8.2779e-06,  4.5114e-06, -1.0499e-05],
          [ 3.2025e-06,  5.7868e-06,  2.7520e-06],
          [ 4.0456e-07,  3.5782e-06,  1.9094e-06]]],


        [[[ 3.7209e-01, -4.6905e-03,  2.6917e-01],
          [ 1.4839e-01, -4.3741e-03, -1.8838e-01],
          [-2.1840e-01, -3.3226e-01, -2.5976e-01]],

         [[-2.2292e-02, -2.8324e-01, -1.4978e-02],
          [-1.0082e-01,  4.0222e-01, -2.1575e-01],
          [ 2.0545e-01,  1.1462e-01,  2.4209e-01]],

         [[-1.8930e-01, -2.4849e-01, -5.3129e-02],
          [-2.4513e-01,  1.4796e-01, -4.1227e-02],
          [ 1.9842e-02,  1.5174e-01,  2.5440e-01]]],


        [[[ 1.1998e-40,  2.4869e-40, -5.4076e-41],
          [ 9.5124e-41,  1.1020e-40,  6.9604e-41],
          [ 7.5970e-41,  8.5737e-41, -1.8335e-40]],

         [[-2.2371e-40, -1.7338e-40, -1.3648e-40],
          [ 5.9402e-41,  2.4592e-40, -1.1084e-40],
          [-2.5225e-40,  1.7930e-40, -1.2778e-40]],

         [[ 2.5770e-42, -1.5901e-40,  3.5692e-41],
          [ 9.5541e-41,  2.9755e-40,  1.2084e-40],
          [-1.1432e-40, -2.3065e-40,  2.1720e-40]]],


        ...,


        [[[ 1.2001e-02,  2.1494e-02, -3.1504e-02],
          [ 2.8010e-04,  3.9691e-02, -1.1217e-02],
          [-1.6974e-01, -5.0955e-03,  2.8639e-02]],

         [[-1.3984e-01, -1.6343e-01, -4.6766e-02],
          [ 7.6734e-02,  1.9082e-02, -1.2196e-01],
          [ 9.6673e-02, -2.5892e-02, -3.3469e-02]],

         [[ 5.7446e-03,  1.2459e-01,  8.5907e-02],
          [ 2.8623e-01,  4.0971e-01,  1.8429e-01],
          [ 2.4149e-01,  2.4960e-01,  6.8405e-02]]],


        [[[ 2.9856e-01,  4.3544e-02,  7.6781e-02],
          [ 9.2721e-02, -1.1542e-01, -8.8065e-02],
          [ 2.8267e-02,  1.0261e-01,  4.7359e-02]],

         [[-2.9444e-02, -2.5840e-01, -3.9700e-02],
          [-8.7043e-02, -3.2214e-01, -2.2840e-01],
          [-3.7921e-03, -6.2589e-02, -5.7798e-02]],

         [[ 6.1432e-02, -2.1799e-01, -8.2612e-02],
          [-6.4905e-02, -1.2859e-01, -2.9356e-02],
          [-5.6389e-02,  4.5376e-02,  1.2247e-01]]],


        [[[ 5.8385e-02, -2.2247e-01,  2.4735e-02],
          [-1.7498e-01, -5.2057e-01, -2.5712e-01],
          [ 1.5695e-01, -2.9091e-02, -2.3312e-02]],

         [[ 1.3812e-01, -2.7934e-01, -6.9151e-03],
          [ 1.4972e-02, -2.7008e-01,  8.5629e-03],
          [ 1.8318e-01,  1.9437e-01,  3.6576e-02]],

         [[ 5.4836e-02, -2.2973e-01,  1.0036e-01],
          [ 9.5157e-02, -5.8982e-02,  1.0374e-01],
          [-6.4044e-02,  4.5288e-02,  1.3961e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0324, -0.0345, -0.0136],
          [-0.0697, -0.0643, -0.0313],
          [-0.0819, -0.0698, -0.0419]],

         [[ 0.0048,  0.0104,  0.0365],
          [-0.0311, -0.0177,  0.0254],
          [-0.0479, -0.0247,  0.0055]],

         [[ 0.0214,  0.0390,  0.0627],
          [-0.0036,  0.0215,  0.0576],
          [-0.0220,  0.0031,  0.0291]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0046,  0.0028,  0.0023],
          [ 0.0010, -0.0006, -0.0034],
          [-0.0035, -0.0037, -0.0068]],

         [[ 0.0069,  0.0048,  0.0043],
          [ 0.0023,  0.0005, -0.0027],
          [-0.0016, -0.0022, -0.0061]],

         [[ 0.0079,  0.0053,  0.0043],
          [ 0.0031,  0.0006, -0.0027],
          [-0.0005, -0.0016, -0.0051]]],


        [[[-0.0043, -0.0052, -0.0068],
          [-0.0077, -0.0086, -0.0118],
          [-0.0068, -0.0067, -0.0116]],

         [[ 0.0011, -0.0000, -0.0021],
          [-0.0004, -0.0021, -0.0063],
          [ 0.0012,  0.0003, -0.0046]],

         [[ 0.0020,  0.0009, -0.0005],
          [ 0.0028,  0.0008, -0.0027],
          [ 0.0044,  0.0038,  0.0000]]],


        [[[ 0.0163,  0.0125,  0.0075],
          [ 0.0121,  0.0060, -0.0004],
          [ 0.0189,  0.0209,  0.0139]],

         [[ 0.0120,  0.0084,  0.0025],
          [ 0.0065,  0.0002, -0.0068],
          [ 0.0134,  0.0139,  0.0075]],

         [[ 0.0103,  0.0066,  0.0018],
          [ 0.0059, -0.0009, -0.0061],
          [ 0.0123,  0.0112,  0.0078]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2897]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 115 | Batch_idx: 0 |  Loss: (0.1891) | Acc: (92.00%) (118/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.2181) | Acc: (92.00%) (1304/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.2123) | Acc: (93.00%) (2504/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.2108) | Acc: (93.00%) (3693/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.2053) | Acc: (93.00%) (4890/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.2044) | Acc: (93.00%) (6078/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.2054) | Acc: (93.00%) (7268/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.2042) | Acc: (93.00%) (8458/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.2013) | Acc: (93.00%) (9661/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.2005) | Acc: (93.00%) (10861/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.1989) | Acc: (93.00%) (12062/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.1992) | Acc: (93.00%) (13256/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.2019) | Acc: (93.00%) (14445/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.2007) | Acc: (93.00%) (15644/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.1987) | Acc: (93.00%) (16851/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.1964) | Acc: (93.00%) (18067/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.1966) | Acc: (93.00%) (19261/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.1950) | Acc: (93.00%) (20475/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.1938) | Acc: (93.00%) (21677/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.1937) | Acc: (93.00%) (22877/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.1935) | Acc: (93.00%) (24078/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.1927) | Acc: (93.00%) (25277/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.1926) | Acc: (93.00%) (26485/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.1910) | Acc: (93.00%) (27699/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.1921) | Acc: (93.00%) (28890/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.1918) | Acc: (93.00%) (30087/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.1917) | Acc: (93.00%) (31283/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.1919) | Acc: (93.00%) (32481/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.1921) | Acc: (93.00%) (33676/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.1903) | Acc: (93.00%) (34901/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.1900) | Acc: (93.00%) (36107/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.1898) | Acc: (93.00%) (37305/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.1889) | Acc: (93.00%) (38514/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.1883) | Acc: (93.00%) (39728/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.1879) | Acc: (93.00%) (40940/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.1876) | Acc: (93.00%) (42139/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.1873) | Acc: (93.00%) (43347/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.1867) | Acc: (93.00%) (44554/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.1863) | Acc: (93.00%) (45762/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.1860) | Acc: (93.00%) (46920/50000)
# TEST : Loss: (0.2977) | Acc: (90.00%) (9053/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-6.9132e-08, -6.8647e-08, -3.8254e-08],
          [-1.2869e-08,  2.8917e-08,  8.4576e-07],
          [ 3.9108e-07, -1.5356e-06, -2.1257e-06]],

         [[-1.7582e-07, -1.0278e-07, -7.1613e-08],
          [-2.9280e-07,  9.4505e-08,  1.0353e-07],
          [ 2.5297e-08,  3.4339e-07, -5.6595e-09]],

         [[-1.0122e-06,  5.4239e-07, -1.2626e-06],
          [ 2.9167e-07,  4.9686e-07,  2.2771e-07],
          [ 3.3395e-08,  2.9315e-07,  1.4820e-07]]],


        [[[ 3.7033e-01, -5.2176e-03,  2.6722e-01],
          [ 1.4855e-01, -3.7120e-03, -1.8889e-01],
          [-2.1706e-01, -3.3115e-01, -2.5991e-01]],

         [[-2.5780e-02, -2.8563e-01, -1.8470e-02],
          [-1.0243e-01,  4.0063e-01, -2.1811e-01],
          [ 2.0491e-01,  1.1363e-01,  2.3993e-01]],

         [[-1.9274e-01, -2.5161e-01, -5.7404e-02],
          [-2.4670e-01,  1.4582e-01, -4.4387e-02],
          [ 1.9069e-02,  1.5016e-01,  2.5201e-01]]],


        [[[ 3.8809e-41, -2.3974e-40, -2.0471e-40],
          [ 2.5821e-40, -1.2090e-40,  8.2734e-41],
          [-8.3055e-42, -1.0234e-40,  1.7515e-40]],

         [[-3.0556e-40, -4.0782e-41, -2.0780e-40],
          [ 1.2194e-40,  2.7776e-40, -7.5744e-41],
          [-1.4073e-40, -2.2782e-40, -2.5171e-40]],

         [[-1.5250e-40, -1.5929e-41, -7.2413e-41],
          [-1.9639e-40,  1.7116e-40,  2.4689e-40],
          [ 1.5763e-40, -1.5680e-40,  1.4740e-40]]],


        ...,


        [[[ 8.1019e-03,  1.8195e-02, -3.5006e-02],
          [-2.7252e-03,  3.7475e-02, -1.3442e-02],
          [-1.7096e-01, -6.4972e-03,  2.6817e-02]],

         [[-1.4236e-01, -1.6476e-01, -4.9731e-02],
          [ 7.3781e-02,  1.8175e-02, -1.2227e-01],
          [ 9.4248e-02, -2.6061e-02, -3.3999e-02]],

         [[ 8.1736e-04,  1.1993e-01,  8.1261e-02],
          [ 2.7625e-01,  3.9943e-01,  1.8073e-01],
          [ 2.3558e-01,  2.4599e-01,  6.7884e-02]]],


        [[[ 2.9590e-01,  4.1442e-02,  7.4990e-02],
          [ 9.1525e-02, -1.1581e-01, -8.7938e-02],
          [ 2.9921e-02,  1.0321e-01,  4.9040e-02]],

         [[-2.9486e-02, -2.5605e-01, -3.8769e-02],
          [-8.7143e-02, -3.1785e-01, -2.2420e-01],
          [-2.0892e-03, -5.9860e-02, -5.4071e-02]],

         [[ 6.0822e-02, -2.1524e-01, -8.0855e-02],
          [-6.5612e-02, -1.2750e-01, -2.8127e-02],
          [-5.4425e-02,  4.6708e-02,  1.2424e-01]]],


        [[[ 5.6969e-02, -2.2339e-01,  2.1488e-02],
          [-1.7389e-01, -5.1592e-01, -2.5664e-01],
          [ 1.5810e-01, -2.7594e-02, -2.3491e-02]],

         [[ 1.3638e-01, -2.8005e-01, -9.7499e-03],
          [ 1.4855e-02, -2.6858e-01,  7.2291e-03],
          [ 1.8356e-01,  1.9431e-01,  3.5201e-02]],

         [[ 5.3483e-02, -2.3069e-01,  9.7314e-02],
          [ 9.4468e-02, -5.9056e-02,  1.0180e-01],
          [-6.3467e-02,  4.5164e-02,  1.3760e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2878]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0584]], device='cuda:0')

Epoch: 116 | Batch_idx: 0 |  Loss: (0.1607) | Acc: (94.00%) (121/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1866) | Acc: (93.00%) (1315/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1852) | Acc: (93.00%) (2516/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1715) | Acc: (94.00%) (3737/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1704) | Acc: (94.00%) (4944/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1724) | Acc: (94.00%) (6150/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1778) | Acc: (94.00%) (7349/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1739) | Acc: (94.00%) (8567/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1724) | Acc: (94.00%) (9778/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1739) | Acc: (94.00%) (10980/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1701) | Acc: (94.00%) (12197/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.1691) | Acc: (94.00%) (13407/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.1708) | Acc: (94.00%) (14613/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.1698) | Acc: (94.00%) (15824/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.1696) | Acc: (94.00%) (17033/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.1701) | Acc: (94.00%) (18233/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.1691) | Acc: (94.00%) (19451/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.1687) | Acc: (94.00%) (20658/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1681) | Acc: (94.00%) (21862/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1679) | Acc: (94.00%) (23070/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1666) | Acc: (94.00%) (24287/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1678) | Acc: (94.00%) (25490/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1673) | Acc: (94.00%) (26701/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1668) | Acc: (94.00%) (27908/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1669) | Acc: (94.00%) (29108/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1664) | Acc: (94.00%) (30323/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1668) | Acc: (94.00%) (31528/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1670) | Acc: (94.00%) (32727/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1671) | Acc: (94.00%) (33937/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1670) | Acc: (94.00%) (35147/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1671) | Acc: (94.00%) (36353/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1664) | Acc: (94.00%) (37570/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1660) | Acc: (94.00%) (38773/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1665) | Acc: (94.00%) (39981/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1673) | Acc: (94.00%) (41181/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1675) | Acc: (94.00%) (42395/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1676) | Acc: (94.00%) (43594/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1679) | Acc: (94.00%) (44794/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1686) | Acc: (94.00%) (45987/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1686) | Acc: (94.00%) (47149/50000)
# TEST : Loss: (0.2914) | Acc: (90.00%) (9059/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.9134e-09, -3.1900e-09, -1.7226e-09],
          [-9.3444e-10,  2.5126e-09,  6.9036e-08],
          [ 3.1546e-08, -1.5599e-07, -2.0141e-07]],

         [[-9.6052e-09, -5.4037e-09, -3.6867e-09],
          [-1.5947e-08,  5.2060e-09,  5.3862e-09],
          [ 1.3756e-09,  2.0893e-08, -3.1776e-10]],

         [[-7.6141e-08,  3.9948e-08, -9.3020e-08],
          [ 1.5177e-08,  2.4008e-08,  1.0503e-08],
          [ 1.5358e-09,  1.3355e-08,  6.3078e-09]]],


        [[[ 3.6994e-01, -5.2120e-03,  2.6693e-01],
          [ 1.4839e-01, -3.7080e-03, -1.8868e-01],
          [-2.1683e-01, -3.3081e-01, -2.5964e-01]],

         [[-2.5752e-02, -2.8531e-01, -1.8450e-02],
          [-1.0232e-01,  4.0018e-01, -2.1786e-01],
          [ 2.0469e-01,  1.1351e-01,  2.3967e-01]],

         [[-1.9251e-01, -2.5130e-01, -5.7334e-02],
          [-2.4641e-01,  1.4565e-01, -4.4334e-02],
          [ 1.9047e-02,  1.4999e-01,  2.5172e-01]]],


        [[[-1.1498e-41,  2.0776e-40, -1.2625e-40],
          [ 1.2019e-40, -1.4004e-40,  4.2096e-41],
          [-1.1720e-40, -2.8477e-40,  3.0335e-40]],

         [[ 1.1652e-40, -2.1555e-40, -5.3591e-41],
          [ 8.1895e-41,  1.8762e-40,  3.3499e-41],
          [-2.1526e-40,  2.8228e-40, -2.8445e-40]],

         [[-2.8846e-40,  1.6594e-40, -2.0071e-41],
          [-2.1885e-40,  6.7621e-41,  2.7982e-40],
          [ 2.3415e-40,  5.8092e-41, -3.0464e-42]]],


        ...,


        [[[ 8.0427e-03,  1.8061e-02, -3.4752e-02],
          [-2.7041e-03,  3.7183e-02, -1.3339e-02],
          [-1.6967e-01, -6.4488e-03,  2.6622e-02]],

         [[-1.4103e-01, -1.6322e-01, -4.9282e-02],
          [ 7.2972e-02,  1.7972e-02, -1.2098e-01],
          [ 9.3240e-02, -2.5782e-02, -3.3660e-02]],

         [[ 8.0679e-04,  1.1833e-01,  8.0304e-02],
          [ 2.6953e-01,  3.8727e-01,  1.7736e-01],
          [ 2.3043e-01,  2.3991e-01,  6.6764e-02]]],


        [[[ 2.9377e-01,  4.1081e-02,  7.4350e-02],
          [ 9.0824e-02, -1.1470e-01, -8.7122e-02],
          [ 2.9713e-02,  1.0239e-01,  4.8670e-02]],

         [[-2.9224e-02, -2.5262e-01, -3.8279e-02],
          [-8.6252e-02, -3.1175e-01, -2.2061e-01],
          [-2.0715e-03, -5.9216e-02, -5.3544e-02]],

         [[ 6.0188e-02, -2.1188e-01, -7.9607e-02],
          [-6.4795e-02, -1.2452e-01, -2.7558e-02],
          [-5.3876e-02,  4.6109e-02,  1.2280e-01]]],


        [[[ 5.6709e-02, -2.2184e-01,  2.1375e-02],
          [-1.7309e-01, -5.1208e-01, -2.5523e-01],
          [ 1.5753e-01, -2.7481e-02, -2.3399e-02]],

         [[ 1.3583e-01, -2.7858e-01, -9.7069e-03],
          [ 1.4795e-02, -2.6714e-01,  7.1966e-03],
          [ 1.8295e-01,  1.9359e-01,  3.5076e-02]],

         [[ 5.3266e-02, -2.2961e-01,  9.6904e-02],
          [ 9.4092e-02, -5.8780e-02,  1.0137e-01],
          [-6.3250e-02,  4.4997e-02,  1.3710e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2815]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0180]], device='cuda:0')

Epoch: 117 | Batch_idx: 0 |  Loss: (0.1580) | Acc: (94.00%) (121/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1881) | Acc: (93.00%) (1322/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1782) | Acc: (94.00%) (2533/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.1795) | Acc: (94.00%) (3740/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.1747) | Acc: (94.00%) (4948/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.1715) | Acc: (94.00%) (6169/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.1703) | Acc: (94.00%) (7371/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.1675) | Acc: (94.00%) (8588/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.1703) | Acc: (94.00%) (9786/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.1687) | Acc: (94.00%) (10993/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.1658) | Acc: (94.00%) (12208/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.1637) | Acc: (94.00%) (13430/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1635) | Acc: (94.00%) (14641/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1628) | Acc: (94.00%) (15854/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1628) | Acc: (94.00%) (17071/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1647) | Acc: (94.00%) (18262/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1660) | Acc: (94.00%) (19459/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1660) | Acc: (94.00%) (20667/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1657) | Acc: (94.00%) (21880/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1669) | Acc: (94.00%) (23075/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1659) | Acc: (94.00%) (24299/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1668) | Acc: (94.00%) (25502/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1667) | Acc: (94.00%) (26712/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1669) | Acc: (94.00%) (27927/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1668) | Acc: (94.00%) (29135/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1668) | Acc: (94.00%) (30341/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1677) | Acc: (94.00%) (31545/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1679) | Acc: (94.00%) (32743/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1674) | Acc: (94.00%) (33958/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1673) | Acc: (94.00%) (35172/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1671) | Acc: (94.00%) (36380/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1670) | Acc: (94.00%) (37587/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1666) | Acc: (94.00%) (38793/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1671) | Acc: (94.00%) (39999/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1674) | Acc: (94.00%) (41198/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1669) | Acc: (94.00%) (42413/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1672) | Acc: (94.00%) (43618/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1678) | Acc: (94.00%) (44819/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1674) | Acc: (94.00%) (46031/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1670) | Acc: (94.00%) (47204/50000)
# TEST : Loss: (0.2841) | Acc: (90.00%) (9082/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-5.7300e-11, -7.1028e-11, -3.6854e-11],
          [-3.6574e-11,  1.2324e-10,  3.1304e-09],
          [ 1.4093e-09, -9.3060e-09, -1.1013e-08]],

         [[-2.6254e-10, -1.4070e-10, -9.3471e-11],
          [-4.3418e-10,  1.4379e-10,  1.3838e-10],
          [ 3.7378e-11,  6.5432e-10, -8.9911e-12]],

         [[-3.1157e-09,  1.5918e-09, -3.7079e-09],
          [ 3.9000e-10,  5.6172e-10,  2.3168e-10],
          [ 3.3750e-11,  2.8996e-10,  1.2564e-10]]],


        [[[ 3.6947e-01, -5.2052e-03,  2.6659e-01],
          [ 1.4819e-01, -3.7032e-03, -1.8844e-01],
          [-2.1656e-01, -3.3039e-01, -2.5932e-01]],

         [[-2.5717e-02, -2.8492e-01, -1.8425e-02],
          [-1.0218e-01,  3.9964e-01, -2.1757e-01],
          [ 2.0442e-01,  1.1336e-01,  2.3936e-01]],

         [[-1.9223e-01, -2.5092e-01, -5.7250e-02],
          [-2.4605e-01,  1.4544e-01, -4.4270e-02],
          [ 1.9021e-02,  1.4978e-01,  2.5137e-01]]],


        [[[-3.2565e-40, -2.5040e-40, -8.3138e-41],
          [ 3.8817e-40, -1.5904e-40,  4.4067e-41],
          [-1.9152e-40, -2.5534e-40, -2.7337e-40]],

         [[ 1.0300e-42,  2.7400e-40,  7.7119e-41],
          [-3.8148e-41, -2.0168e-40, -9.9059e-41],
          [ 1.9491e-40, -2.8670e-40,  2.1056e-40]],

         [[-3.2211e-40,  1.8276e-40,  4.5695e-41],
          [ 2.7345e-40,  2.1316e-40,  1.7555e-40],
          [-3.5117e-40,  1.2782e-40, -1.9293e-40]]],


        ...,


        [[[ 7.9713e-03,  1.7900e-02, -3.4445e-02],
          [-2.6786e-03,  3.6832e-02, -1.3215e-02],
          [-1.6810e-01, -6.3904e-03,  2.6387e-02]],

         [[-1.3944e-01, -1.6136e-01, -4.8742e-02],
          [ 7.1999e-02,  1.7727e-02, -1.1943e-01],
          [ 9.2029e-02, -2.5447e-02, -3.3253e-02]],

         [[ 7.9411e-04,  1.1642e-01,  7.9154e-02],
          [ 2.6158e-01,  3.7297e-01,  1.7336e-01],
          [ 2.2432e-01,  2.3273e-01,  6.5426e-02]]],


        [[[ 2.9120e-01,  4.0646e-02,  7.3579e-02],
          [ 8.9979e-02, -1.1335e-01, -8.6140e-02],
          [ 2.9461e-02,  1.0142e-01,  4.8224e-02]],

         [[-2.8909e-02, -2.4851e-01, -3.7692e-02],
          [-8.5180e-02, -3.0449e-01, -2.1632e-01],
          [-2.0501e-03, -5.8443e-02, -5.2910e-02]],

         [[ 5.9426e-02, -2.0786e-01, -7.8117e-02],
          [-6.3815e-02, -1.2099e-01, -2.6881e-02],
          [-5.3216e-02,  4.5391e-02,  1.2108e-01]]],


        [[[ 5.6394e-02, -2.1997e-01,  2.1239e-02],
          [-1.7213e-01, -5.0745e-01, -2.5352e-01],
          [ 1.5685e-01, -2.7344e-02, -2.3288e-02]],

         [[ 1.3516e-01, -2.7680e-01, -9.6549e-03],
          [ 1.4722e-02, -2.6540e-01,  7.1573e-03],
          [ 1.8222e-01,  1.9272e-01,  3.4925e-02]],

         [[ 5.3004e-02, -2.2831e-01,  9.6407e-02],
          [ 9.3637e-02, -5.8447e-02,  1.0085e-01],
          [-6.2987e-02,  4.4794e-02,  1.3650e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2566]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0316]], device='cuda:0')

Epoch: 118 | Batch_idx: 0 |  Loss: (0.1295) | Acc: (94.00%) (121/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1478) | Acc: (95.00%) (1347/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1580) | Acc: (94.00%) (2550/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1576) | Acc: (94.00%) (3756/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1538) | Acc: (94.00%) (4976/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1546) | Acc: (94.00%) (6185/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1537) | Acc: (94.00%) (7399/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1550) | Acc: (94.00%) (8615/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1600) | Acc: (94.00%) (9815/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1593) | Acc: (94.00%) (11033/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1581) | Acc: (94.00%) (12254/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1611) | Acc: (94.00%) (13446/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1645) | Acc: (94.00%) (14645/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1652) | Acc: (94.00%) (15856/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1647) | Acc: (94.00%) (17068/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1646) | Acc: (94.00%) (18278/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1645) | Acc: (94.00%) (19496/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1646) | Acc: (94.00%) (20707/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1650) | Acc: (94.00%) (21913/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1646) | Acc: (94.00%) (23129/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1641) | Acc: (94.00%) (24346/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1639) | Acc: (94.00%) (25562/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1636) | Acc: (94.00%) (26773/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1627) | Acc: (94.00%) (27992/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1626) | Acc: (94.00%) (29206/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1638) | Acc: (94.00%) (30404/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1634) | Acc: (94.00%) (31621/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1632) | Acc: (94.00%) (32825/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1641) | Acc: (94.00%) (34023/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1644) | Acc: (94.00%) (35235/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1650) | Acc: (94.00%) (36436/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1651) | Acc: (94.00%) (37643/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1653) | Acc: (94.00%) (38852/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1648) | Acc: (94.00%) (40066/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1649) | Acc: (94.00%) (41282/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1660) | Acc: (94.00%) (42477/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1672) | Acc: (94.00%) (43666/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1669) | Acc: (94.00%) (44880/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1672) | Acc: (94.00%) (46082/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1672) | Acc: (94.00%) (47244/50000)
# TEST : Loss: (0.2856) | Acc: (90.00%) (9069/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-4.2464e-13, -6.1770e-13, -3.0443e-13],
          [-6.5478e-13,  2.9387e-12,  6.7571e-11],
          [ 2.9849e-11, -2.8430e-10, -3.0133e-10]],

         [[-2.9712e-12, -1.4963e-12, -9.6055e-13],
          [-4.8892e-12,  1.6494e-12,  1.4465e-12],
          [ 4.1981e-13,  8.8143e-12, -1.0637e-13]],

         [[-5.9025e-11,  2.9153e-11, -6.7942e-11],
          [ 4.0778e-12,  5.2066e-12,  1.9906e-12],
          [ 2.8857e-13,  2.4412e-12,  9.4636e-13]]],


        [[[ 3.6889e-01, -5.1970e-03,  2.6616e-01],
          [ 1.4796e-01, -3.6973e-03, -1.8814e-01],
          [-2.1623e-01, -3.2988e-01, -2.5893e-01]],

         [[-2.5676e-02, -2.8444e-01, -1.8394e-02],
          [-1.0202e-01,  3.9898e-01, -2.1721e-01],
          [ 2.0410e-01,  1.1317e-01,  2.3898e-01]],

         [[-1.9189e-01, -2.5046e-01, -5.7147e-02],
          [-2.4562e-01,  1.4519e-01, -4.4192e-02],
          [ 1.8989e-02,  1.4952e-01,  2.5095e-01]]],


        [[[-1.3297e-41,  3.2403e-40,  4.1513e-41],
          [-1.3245e-40,  2.3585e-40, -8.6054e-41],
          [-1.4504e-40,  2.7779e-40,  2.4152e-40]],

         [[-3.5449e-40, -3.3650e-40,  8.8231e-41],
          [-4.0279e-41, -2.2156e-40,  1.8673e-40],
          [-2.6717e-40,  2.7228e-40, -2.0143e-40]],

         [[ 2.1974e-40,  3.4781e-40,  1.2514e-40],
          [-3.4020e-40,  8.6292e-41, -2.5129e-40],
          [ 4.2653e-40, -2.9108e-40, -4.7350e-42]]],


        ...,


        [[[ 7.8854e-03,  1.7706e-02, -3.4076e-02],
          [-2.6479e-03,  3.6409e-02, -1.3066e-02],
          [-1.6622e-01, -6.3200e-03,  2.6104e-02]],

         [[-1.3752e-01, -1.5912e-01, -4.8094e-02],
          [ 7.0834e-02,  1.7434e-02, -1.1757e-01],
          [ 9.0578e-02, -2.5045e-02, -3.2765e-02]],

         [[ 7.7896e-04,  1.1414e-01,  7.7778e-02],
          [ 2.5222e-01,  3.5630e-01,  1.6860e-01],
          [ 2.1710e-01,  2.2428e-01,  6.3836e-02]]],


        [[[ 2.8811e-01,  4.0123e-02,  7.2652e-02],
          [ 8.8962e-02, -1.1174e-01, -8.4961e-02],
          [ 2.9157e-02,  1.0024e-01,  4.7687e-02]],

         [[-2.8531e-02, -2.4361e-01, -3.6990e-02],
          [-8.3895e-02, -2.9589e-01, -2.1121e-01],
          [-2.0245e-03, -5.7516e-02, -5.2149e-02]],

         [[ 5.8512e-02, -2.0308e-01, -7.6341e-02],
          [-6.2643e-02, -1.1683e-01, -2.6080e-02],
          [-5.2424e-02,  4.4532e-02,  1.1901e-01]]],


        [[[ 5.6013e-02, -2.1772e-01,  2.1075e-02],
          [-1.7096e-01, -5.0188e-01, -2.5146e-01],
          [ 1.5603e-01, -2.7178e-02, -2.3154e-02]],

         [[ 1.3435e-01, -2.7466e-01, -9.5920e-03],
          [ 1.4635e-02, -2.6330e-01,  7.1098e-03],
          [ 1.8133e-01,  1.9166e-01,  3.4742e-02]],

         [[ 5.2687e-02, -2.2673e-01,  9.5806e-02],
          [ 9.3087e-02, -5.8044e-02,  1.0022e-01],
          [-6.2669e-02,  4.4549e-02,  1.3577e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2713]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0294]], device='cuda:0')

Epoch: 119 | Batch_idx: 0 |  Loss: (0.1796) | Acc: (94.00%) (121/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1717) | Acc: (94.00%) (1329/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1686) | Acc: (94.00%) (2537/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1683) | Acc: (94.00%) (3750/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1739) | Acc: (94.00%) (4947/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1716) | Acc: (94.00%) (6161/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1688) | Acc: (94.00%) (7379/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1699) | Acc: (94.00%) (8588/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1686) | Acc: (94.00%) (9804/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1691) | Acc: (94.00%) (11013/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1692) | Acc: (94.00%) (12218/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1707) | Acc: (94.00%) (13415/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1726) | Acc: (94.00%) (14613/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1727) | Acc: (94.00%) (15818/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1739) | Acc: (94.00%) (17014/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1752) | Acc: (94.00%) (18221/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1768) | Acc: (94.00%) (19407/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1763) | Acc: (94.00%) (20616/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1767) | Acc: (94.00%) (21811/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1768) | Acc: (94.00%) (23014/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1772) | Acc: (94.00%) (24215/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1770) | Acc: (94.00%) (25420/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1767) | Acc: (94.00%) (26637/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1769) | Acc: (94.00%) (27840/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1768) | Acc: (94.00%) (29049/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1772) | Acc: (94.00%) (30252/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1770) | Acc: (94.00%) (31462/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1764) | Acc: (94.00%) (32675/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1759) | Acc: (94.00%) (33890/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1758) | Acc: (94.00%) (35096/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1757) | Acc: (94.00%) (36314/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1764) | Acc: (94.00%) (37509/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1754) | Acc: (94.00%) (38729/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1748) | Acc: (94.00%) (39952/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1751) | Acc: (94.00%) (41152/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1750) | Acc: (94.00%) (42372/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1755) | Acc: (94.00%) (43563/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1753) | Acc: (94.00%) (44776/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1753) | Acc: (94.00%) (45986/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1749) | Acc: (94.00%) (47158/50000)
# TEST : Loss: (0.2856) | Acc: (90.00%) (9081/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-8.7955e-16, -1.5802e-15, -7.2777e-16],
          [-4.2973e-15,  2.7911e-14,  5.6459e-13],
          [ 2.4340e-13, -3.7101e-12, -3.4149e-12]],

         [[-1.0739e-14, -4.9850e-15, -3.0599e-15],
          [-1.7556e-14,  6.0672e-15,  4.7119e-15],
          [ 1.5024e-15,  3.9992e-14, -4.0738e-16]],

         [[-4.1677e-13,  1.9705e-13, -4.5950e-13],
          [ 1.3288e-14,  1.4485e-14,  5.0118e-15],
          [ 7.2192e-16,  5.9837e-15,  2.0029e-15]]],


        [[[ 3.6819e-01, -5.1870e-03,  2.6565e-01],
          [ 1.4767e-01, -3.6902e-03, -1.8778e-01],
          [-2.1583e-01, -3.2926e-01, -2.5845e-01]],

         [[-2.5625e-02, -2.8386e-01, -1.8357e-02],
          [-1.0181e-01,  3.9818e-01, -2.1677e-01],
          [ 2.0370e-01,  1.1295e-01,  2.3851e-01]],

         [[-1.9148e-01, -2.4991e-01, -5.7023e-02],
          [-2.4510e-01,  1.4488e-01, -4.4097e-02],
          [ 1.8951e-02,  1.4921e-01,  2.5043e-01]]],


        [[[ 6.1848e-41, -1.3137e-41,  4.3653e-41],
          [-3.7756e-40, -1.9550e-40,  1.9483e-40],
          [-1.5975e-40, -7.9287e-41, -1.8283e-40]],

         [[-4.6665e-40, -2.1324e-40,  1.6412e-41],
          [ 1.1580e-40, -3.2392e-40, -2.0287e-40],
          [-2.9115e-40,  5.6960e-41,  1.6933e-41]],

         [[ 4.3230e-42, -2.6739e-40,  1.3525e-40],
          [ 1.7489e-40, -1.5010e-40,  2.0960e-40],
          [-2.8078e-40, -1.5659e-40,  2.2618e-40]]],


        ...,


        [[[ 7.7821e-03,  1.7473e-02, -3.3632e-02],
          [-2.6110e-03,  3.5902e-02, -1.2887e-02],
          [-1.6396e-01, -6.2356e-03,  2.5764e-02]],

         [[-1.3523e-01, -1.5645e-01, -4.7316e-02],
          [ 6.9443e-02,  1.7084e-02, -1.1535e-01],
          [ 8.8844e-02, -2.4565e-02, -3.2180e-02]],

         [[ 7.6093e-04,  1.1142e-01,  7.6138e-02],
          [ 2.4129e-01,  3.3703e-01,  1.6299e-01],
          [ 2.0864e-01,  2.1442e-01,  6.1953e-02]]],


        [[[ 2.8439e-01,  3.9496e-02,  7.1541e-02],
          [ 8.7741e-02, -1.0980e-01, -8.3549e-02],
          [ 2.8793e-02,  9.8832e-02,  4.7042e-02]],

         [[-2.8077e-02, -2.3777e-01, -3.6154e-02],
          [-8.2358e-02, -2.8576e-01, -2.0516e-01],
          [-1.9937e-03, -5.6409e-02, -5.1238e-02]],

         [[ 5.7420e-02, -1.9741e-01, -7.4236e-02],
          [-6.1246e-02, -1.1197e-01, -2.5139e-02],
          [-5.1476e-02,  4.3510e-02,  1.1655e-01]]],


        [[[ 5.5554e-02, -2.1501e-01,  2.0877e-02],
          [-1.6955e-01, -4.9518e-01, -2.4897e-01],
          [ 1.5504e-01, -2.6977e-02, -2.2992e-02]],

         [[ 1.3337e-01, -2.7207e-01, -9.5161e-03],
          [ 1.4529e-02, -2.6077e-01,  7.0525e-03],
          [ 1.8025e-01,  1.9039e-01,  3.4521e-02]],

         [[ 5.2305e-02, -2.2483e-01,  9.5081e-02],
          [ 9.2422e-02, -5.7557e-02,  9.9459e-02],
          [-6.2285e-02,  4.4254e-02,  1.3489e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2716]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0466]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1931) | Acc: (92.00%) (118/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.2164) | Acc: (92.00%) (1307/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.2634) | Acc: (90.00%) (2444/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.2960) | Acc: (90.00%) (3575/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.3310) | Acc: (88.00%) (4664/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.3416) | Acc: (88.00%) (5774/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.3599) | Acc: (87.00%) (6860/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.3681) | Acc: (87.00%) (7950/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.3715) | Acc: (87.00%) (9048/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.3729) | Acc: (87.00%) (10159/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.3675) | Acc: (87.00%) (11287/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.3700) | Acc: (87.00%) (12416/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.3668) | Acc: (87.00%) (13543/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.3647) | Acc: (87.00%) (14668/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.3638) | Acc: (87.00%) (15799/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.3584) | Acc: (87.00%) (16957/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.3587) | Acc: (87.00%) (18078/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.3598) | Acc: (87.00%) (19198/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.3585) | Acc: (87.00%) (20350/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.3559) | Acc: (87.00%) (21497/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.3539) | Acc: (88.00%) (22641/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.3518) | Acc: (88.00%) (23784/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.3504) | Acc: (88.00%) (24932/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.3487) | Acc: (88.00%) (26083/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.3461) | Acc: (88.00%) (27249/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.3449) | Acc: (88.00%) (28384/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.3438) | Acc: (88.00%) (29529/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.3413) | Acc: (88.00%) (30689/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.3389) | Acc: (88.00%) (31854/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.3370) | Acc: (88.00%) (33016/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.3356) | Acc: (88.00%) (34168/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.3356) | Acc: (88.00%) (35313/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.3343) | Acc: (88.00%) (36456/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.3342) | Acc: (88.00%) (37596/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.3337) | Acc: (88.00%) (38746/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.3321) | Acc: (88.00%) (39907/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.3316) | Acc: (88.00%) (41054/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.3316) | Acc: (88.00%) (42186/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.3306) | Acc: (88.00%) (43332/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.3297) | Acc: (88.00%) (44440/50000)
# TEST : Loss: (0.3921) | Acc: (87.00%) (8727/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-3.2631e-19, -7.8348e-19, -3.2884e-19],
          [-7.5776e-18,  8.0178e-17,  1.3702e-15],
          [ 5.7199e-16, -1.6152e-14, -1.2365e-14]],

         [[-8.5193e-18, -3.5417e-18, -2.0457e-18],
          [-1.3804e-17,  4.9288e-18,  3.2470e-18],
          [ 1.1760e-18,  4.3091e-17, -3.4948e-19]],

         [[-8.0974e-16,  3.6130e-16, -8.4321e-16],
          [ 9.1617e-18,  8.0532e-18,  2.4312e-18],
          [ 3.4716e-19,  2.7981e-18,  7.6544e-19]]],


        [[[ 3.6830e-01,  5.4340e-03,  2.7843e-01],
          [ 1.5798e-01,  1.1002e-03, -1.8450e-01],
          [-2.0493e-01, -3.3090e-01, -2.5878e-01]],

         [[-4.1959e-02, -2.9038e-01, -2.3637e-02],
          [-1.0846e-01,  3.9862e-01, -2.1864e-01],
          [ 2.0322e-01,  1.1623e-01,  2.4487e-01]],

         [[-1.9858e-01, -2.5198e-01, -5.9633e-02],
          [-2.4923e-01,  1.5177e-01, -4.1821e-02],
          [ 1.6447e-02,  1.5611e-01,  2.5726e-01]]],


        [[[ 2.3720e-40,  2.2905e-40, -1.1598e-40],
          [-4.1111e-40,  2.7982e-40,  5.2250e-41],
          [-2.5480e-40, -3.3702e-40,  4.6377e-41]],

         [[-3.3728e-40,  2.2348e-41,  1.0318e-40],
          [-4.6129e-41, -2.6137e-40,  2.1838e-40],
          [-1.4916e-40,  1.4819e-40, -2.4161e-40]],

         [[ 2.6012e-40, -2.8936e-40,  5.5770e-41],
          [ 1.8921e-40, -3.3729e-40, -3.8380e-40],
          [ 4.2933e-40,  9.0864e-41,  3.2999e-40]]],


        ...,


        [[[ 1.1939e-02,  1.5661e-02, -2.9848e-02],
          [ 1.0448e-02,  5.2842e-02,  2.3600e-03],
          [-1.5058e-01,  7.1418e-03,  3.9972e-02]],

         [[-1.3729e-01, -1.6638e-01, -5.4649e-02],
          [ 8.0381e-02,  3.6480e-02, -1.0665e-01],
          [ 1.0477e-01, -1.5622e-03, -1.6686e-02]],

         [[ 2.8593e-03,  1.0811e-01,  7.5446e-02],
          [ 2.6755e-01,  4.0731e-01,  1.8947e-01],
          [ 2.1845e-01,  2.5422e-01,  7.8022e-02]]],


        [[[ 2.9332e-01,  4.4508e-02,  7.1391e-02],
          [ 8.4326e-02, -1.1871e-01, -9.7699e-02],
          [ 2.3490e-02,  9.6858e-02,  5.4240e-02]],

         [[-2.2461e-02, -2.2890e-01, -2.5165e-02],
          [-8.9381e-02, -2.9799e-01, -2.2626e-01],
          [-1.0824e-03, -4.9967e-02, -4.3500e-02]],

         [[ 6.0879e-02, -1.9949e-01, -7.6789e-02],
          [-6.3096e-02, -1.3043e-01, -5.9259e-02],
          [-4.4041e-02,  5.3877e-02,  1.1937e-01]]],


        [[[ 6.8334e-02, -2.2107e-01,  4.2159e-02],
          [-1.7360e-01, -5.1009e-01, -2.0694e-01],
          [ 1.6186e-01, -4.4802e-03,  1.6743e-02]],

         [[ 1.2954e-01, -2.8851e-01,  3.4701e-03],
          [ 2.4927e-03, -2.7766e-01,  3.3836e-02],
          [ 1.7617e-01,  1.9844e-01,  5.8217e-02]],

         [[ 4.7635e-02, -2.3669e-01,  1.0272e-01],
          [ 8.0400e-02, -6.8811e-02,  1.1611e-01],
          [-6.9759e-02,  4.6733e-02,  1.4340e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0107,  0.0179,  0.0030],
          [ 0.0478,  0.0453,  0.0099],
          [ 0.1102,  0.0630,  0.0376]],

         [[-0.0410,  0.0108,  0.0129],
          [ 0.0165,  0.0276,  0.0208],
          [ 0.0938,  0.0601,  0.0553]],

         [[-0.0144,  0.0307,  0.0278],
          [ 0.0207,  0.0267,  0.0168],
          [ 0.0838,  0.0386,  0.0340]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0027, -0.0024, -0.0087],
          [-0.0019, -0.0014, -0.0079],
          [ 0.0118,  0.0105,  0.0039]],

         [[-0.0039, -0.0039, -0.0084],
          [-0.0037, -0.0036, -0.0080],
          [ 0.0102,  0.0084,  0.0030]],

         [[-0.0033, -0.0038, -0.0085],
          [-0.0029, -0.0037, -0.0084],
          [ 0.0085,  0.0056,  0.0000]]],


        [[[-0.0116, -0.0112, -0.0070],
          [ 0.0007,  0.0032,  0.0077],
          [ 0.0054,  0.0052,  0.0075]],

         [[-0.0152, -0.0120, -0.0089],
          [-0.0020,  0.0007,  0.0042],
          [ 0.0049,  0.0041,  0.0058]],

         [[-0.0150, -0.0112, -0.0070],
          [-0.0037, -0.0006,  0.0031],
          [ 0.0037,  0.0029,  0.0047]]],


        [[[ 0.0152,  0.0117,  0.0220],
          [ 0.0225,  0.0228,  0.0307],
          [ 0.0362,  0.0335,  0.0412]],

         [[ 0.0432,  0.0420,  0.0497],
          [ 0.0444,  0.0441,  0.0522],
          [ 0.0532,  0.0508,  0.0588]],

         [[ 0.0448,  0.0421,  0.0498],
          [ 0.0425,  0.0414,  0.0494],
          [ 0.0472,  0.0446,  0.0528]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2685]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 121 | Batch_idx: 0 |  Loss: (0.1834) | Acc: (94.00%) (121/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.2423) | Acc: (91.00%) (1292/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.2473) | Acc: (91.00%) (2461/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.2389) | Acc: (91.00%) (3642/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.2363) | Acc: (91.00%) (4818/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.2373) | Acc: (91.00%) (5990/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.2384) | Acc: (91.00%) (7168/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.2395) | Acc: (91.00%) (8340/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.2400) | Acc: (91.00%) (9518/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.2428) | Acc: (91.00%) (10686/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.2401) | Acc: (91.00%) (11874/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.2374) | Acc: (91.00%) (13058/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.2380) | Acc: (91.00%) (14225/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.2425) | Acc: (91.00%) (15374/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.2429) | Acc: (91.00%) (16544/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.2450) | Acc: (91.00%) (17700/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.2448) | Acc: (91.00%) (18865/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.2426) | Acc: (91.00%) (20059/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.2439) | Acc: (91.00%) (21215/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.2439) | Acc: (91.00%) (22385/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.2425) | Acc: (91.00%) (23577/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.2443) | Acc: (91.00%) (24742/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.2459) | Acc: (91.00%) (25895/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.2467) | Acc: (91.00%) (27043/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.2480) | Acc: (91.00%) (28192/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.2490) | Acc: (91.00%) (29359/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.2490) | Acc: (91.00%) (30532/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.2478) | Acc: (91.00%) (31722/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.2472) | Acc: (91.00%) (32904/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.2468) | Acc: (91.00%) (34086/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.2477) | Acc: (91.00%) (35242/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.2473) | Acc: (91.00%) (36412/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.2473) | Acc: (91.00%) (37581/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.2475) | Acc: (91.00%) (38749/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.2482) | Acc: (91.00%) (39903/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.2501) | Acc: (91.00%) (41043/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.2500) | Acc: (91.00%) (42216/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.2502) | Acc: (91.00%) (43381/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.2506) | Acc: (91.00%) (44547/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.2503) | Acc: (91.00%) (45686/50000)
# TEST : Loss: (0.3495) | Acc: (89.00%) (8905/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0239e-23, -3.7905e-23, -1.3863e-23],
          [-2.2500e-21,  4.6570e-20,  6.3203e-19],
          [ 2.5246e-19, -1.6463e-17, -9.8328e-18]],

         [[-8.1828e-22, -2.9009e-22, -1.5340e-22],
          [-1.3091e-21,  4.8989e-22,  2.5443e-22],
          [ 1.1079e-22,  6.4111e-21, -3.7564e-23]],

         [[-2.7499e-19,  1.1325e-19, -2.6460e-19],
          [ 7.1845e-22,  4.6129e-22,  1.1388e-22],
          [ 1.6052e-23,  1.2413e-22,  2.5117e-23]]],


        [[[ 3.7032e-01,  3.1217e-03,  2.6861e-01],
          [ 1.5937e-01,  4.0731e-03, -1.8919e-01],
          [-2.0393e-01, -3.2718e-01, -2.5495e-01]],

         [[-3.6438e-02, -2.9317e-01, -4.2281e-02],
          [-1.0217e-01,  4.0370e-01, -2.2476e-01],
          [ 2.1032e-01,  1.2728e-01,  2.5021e-01]],

         [[-1.9705e-01, -2.5526e-01, -7.3889e-02],
          [-2.5045e-01,  1.5409e-01, -4.4420e-02],
          [ 1.9197e-02,  1.6779e-01,  2.6430e-01]]],


        [[[ 7.7493e-41, -1.8769e-40,  2.2681e-40],
          [-1.7255e-40,  3.4137e-41,  2.3023e-40],
          [-1.8643e-40, -3.6340e-40, -3.9141e-40]],

         [[ 3.6600e-40,  2.0513e-40,  1.0946e-40],
          [-2.3329e-40,  2.8871e-40,  2.3358e-40],
          [ 1.0894e-40, -4.0021e-40,  3.8712e-40]],

         [[ 2.7920e-40, -1.2350e-40, -3.6529e-41],
          [-2.5470e-40, -1.7075e-40, -1.3224e-40],
          [ 4.6329e-40, -3.6275e-40, -4.7238e-42]]],


        ...,


        [[[ 1.2112e-02,  1.3244e-02, -3.3486e-02],
          [ 1.0357e-02,  5.1414e-02, -6.0479e-03],
          [-1.5284e-01,  5.4797e-03,  3.0669e-02]],

         [[-1.3064e-01, -1.6234e-01, -5.2598e-02],
          [ 8.4024e-02,  3.7234e-02, -1.1489e-01],
          [ 1.0458e-01, -2.3641e-03, -2.8906e-02]],

         [[ 1.3852e-02,  1.2319e-01,  9.1066e-02],
          [ 2.7446e-01,  4.2480e-01,  1.9000e-01],
          [ 2.1009e-01,  2.5073e-01,  5.9467e-02]]],


        [[[ 2.9306e-01,  4.4221e-02,  8.2440e-02],
          [ 9.8559e-02, -1.0064e-01, -7.1216e-02],
          [ 3.6250e-02,  1.1085e-01,  7.9195e-02]],

         [[-2.6385e-02, -2.3747e-01, -2.4284e-02],
          [-8.5525e-02, -2.8398e-01, -2.0870e-01],
          [-2.9367e-03, -4.6152e-02, -3.3144e-02]],

         [[ 2.5204e-02, -2.3400e-01, -9.9265e-02],
          [-8.3466e-02, -1.3424e-01, -6.0374e-02],
          [-6.4057e-02,  4.7413e-02,  1.1355e-01]]],


        [[[ 7.8973e-02, -2.1222e-01,  4.5115e-02],
          [-1.9133e-01, -5.3469e-01, -2.2507e-01],
          [ 1.4520e-01, -1.5706e-02,  4.7603e-03]],

         [[ 1.4048e-01, -2.8198e-01, -5.5087e-04],
          [-3.5192e-03, -2.8344e-01,  2.0665e-02],
          [ 1.6774e-01,  1.9629e-01,  5.0427e-02]],

         [[ 5.8472e-02, -2.2685e-01,  1.0122e-01],
          [ 8.2950e-02, -6.0134e-02,  1.1322e-01],
          [-6.6133e-02,  5.9914e-02,  1.4493e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0081,  0.0434,  0.0520],
          [ 0.0054,  0.0140,  0.0341],
          [ 0.0474,  0.0602,  0.0672]],

         [[-0.0236,  0.0191,  0.0406],
          [-0.0102, -0.0004,  0.0259],
          [ 0.0384,  0.0401,  0.0507]],

         [[-0.0304,  0.0051,  0.0276],
          [-0.0122, -0.0060,  0.0168],
          [ 0.0319,  0.0328,  0.0395]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0054,  0.0028,  0.0030],
          [ 0.0100,  0.0072,  0.0061],
          [ 0.0065,  0.0048,  0.0045]],

         [[ 0.0027,  0.0005,  0.0016],
          [ 0.0064,  0.0044,  0.0039],
          [ 0.0025,  0.0016,  0.0025]],

         [[ 0.0006, -0.0012, -0.0001],
          [ 0.0031,  0.0013,  0.0008],
          [-0.0016, -0.0022, -0.0009]]],


        [[[ 0.0116,  0.0056,  0.0040],
          [ 0.0068,  0.0041,  0.0057],
          [-0.0009,  0.0027,  0.0048]],

         [[ 0.0058,  0.0018,  0.0035],
          [ 0.0036,  0.0034,  0.0066],
          [-0.0019,  0.0027,  0.0050]],

         [[ 0.0037,  0.0012,  0.0029],
          [ 0.0038,  0.0038,  0.0057],
          [-0.0002,  0.0038,  0.0048]]],


        [[[ 0.0134, -0.0014, -0.0006],
          [ 0.0076, -0.0037,  0.0008],
          [ 0.0048, -0.0049, -0.0035]],

         [[-0.0035, -0.0110, -0.0040],
          [-0.0124, -0.0175, -0.0085],
          [-0.0147, -0.0209, -0.0145]],

         [[-0.0069, -0.0121, -0.0074],
          [-0.0168, -0.0204, -0.0132],
          [-0.0173, -0.0221, -0.0155]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2680]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 122 | Batch_idx: 0 |  Loss: (0.1615) | Acc: (94.00%) (121/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1936) | Acc: (93.00%) (1312/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.2107) | Acc: (92.00%) (2499/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.2182) | Acc: (92.00%) (3676/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.2176) | Acc: (92.00%) (4860/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.2145) | Acc: (92.00%) (6055/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.2197) | Acc: (92.00%) (7224/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.2213) | Acc: (92.00%) (8402/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.2208) | Acc: (92.00%) (9591/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.2194) | Acc: (92.00%) (10775/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.2198) | Acc: (92.00%) (11958/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.2197) | Acc: (92.00%) (13147/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.2173) | Acc: (92.00%) (14350/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.2185) | Acc: (92.00%) (15529/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.2176) | Acc: (92.00%) (16714/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.2169) | Acc: (92.00%) (17896/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.2174) | Acc: (92.00%) (19072/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.2202) | Acc: (92.00%) (20239/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.2194) | Acc: (92.00%) (21418/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.2200) | Acc: (92.00%) (22597/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.2193) | Acc: (92.00%) (23797/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.2199) | Acc: (92.00%) (24980/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.2209) | Acc: (92.00%) (26158/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.2203) | Acc: (92.00%) (27352/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.2203) | Acc: (92.00%) (28532/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.2205) | Acc: (92.00%) (29717/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.2209) | Acc: (92.00%) (30900/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.2199) | Acc: (92.00%) (32096/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.2201) | Acc: (92.00%) (33264/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.2204) | Acc: (92.00%) (34447/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.2199) | Acc: (92.00%) (35633/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.2213) | Acc: (92.00%) (36794/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.2224) | Acc: (92.00%) (37962/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.2229) | Acc: (92.00%) (39139/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.2230) | Acc: (92.00%) (40318/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.2242) | Acc: (92.00%) (41473/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.2249) | Acc: (92.00%) (42636/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.2251) | Acc: (92.00%) (43813/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.2245) | Acc: (92.00%) (45010/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.2254) | Acc: (92.00%) (46143/50000)
# TEST : Loss: (0.3616) | Acc: (89.00%) (8902/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-4.5990e-30, -4.0258e-29, -1.1297e-29],
          [-5.0337e-26,  2.8442e-24,  2.7474e-23],
          [ 1.0277e-23, -2.2637e-21, -9.4774e-22]],

         [[-2.9743e-27, -8.0112e-28, -3.6288e-28],
          [-4.6559e-27,  1.8875e-27,  6.5029e-28],
          [ 3.8965e-28,  4.8282e-26, -1.6523e-28]],

         [[-7.5496e-24,  2.7522e-24, -6.4417e-24],
          [ 1.8387e-27,  6.7166e-28,  1.1374e-28],
          [ 1.5640e-29,  1.1168e-28,  1.2382e-29]]],


        [[[ 3.7548e-01,  4.9628e-03,  2.6875e-01],
          [ 1.5620e-01, -3.4892e-03, -2.0342e-01],
          [-2.1021e-01, -3.4063e-01, -2.6991e-01]],

         [[-3.1108e-02, -2.9064e-01, -3.6751e-02],
          [-1.0732e-01,  3.9882e-01, -2.3267e-01],
          [ 2.0754e-01,  1.2162e-01,  2.4181e-01]],

         [[-1.8977e-01, -2.5410e-01, -6.6345e-02],
          [-2.5430e-01,  1.5076e-01, -5.0938e-02],
          [ 1.9593e-02,  1.6124e-01,  2.5627e-01]]],


        [[[ 1.0152e-02, -2.0370e-03, -8.0010e-03],
          [-1.4384e-02, -1.5074e-02, -1.6680e-02],
          [-1.7883e-02, -2.1035e-02, -1.6196e-02]],

         [[ 1.3614e-02,  4.1113e-03, -3.8864e-03],
          [ 6.5422e-03, -4.7215e-03, -1.0964e-02],
          [-1.7800e-03, -7.6022e-03, -2.0387e-02]],

         [[-4.7574e-03, -1.4576e-02, -1.8289e-02],
          [-1.2576e-02, -2.2619e-02, -2.4851e-02],
          [-1.4307e-02, -1.9835e-02, -3.0312e-02]]],


        ...,


        [[[ 1.5164e-02,  1.6687e-02, -3.3742e-02],
          [ 2.5510e-02,  7.0417e-02,  3.4037e-03],
          [-1.3340e-01,  2.9955e-02,  4.7075e-02]],

         [[-1.3635e-01, -1.6907e-01, -6.3041e-02],
          [ 9.0320e-02,  4.9757e-02, -1.1412e-01],
          [ 1.0967e-01,  1.3344e-02, -2.3579e-02]],

         [[-6.4981e-04,  1.0299e-01,  6.6269e-02],
          [ 2.8355e-01,  4.4059e-01,  1.7838e-01],
          [ 2.0963e-01,  2.7010e-01,  5.7301e-02]]],


        [[[ 3.0071e-01,  4.8070e-02,  8.6178e-02],
          [ 1.0223e-01, -9.8400e-02, -7.0100e-02],
          [ 4.5293e-02,  1.1497e-01,  7.7106e-02]],

         [[-1.9084e-02, -2.2642e-01, -1.9407e-02],
          [-8.5402e-02, -2.8287e-01, -2.1656e-01],
          [-2.4323e-03, -4.8234e-02, -4.5822e-02]],

         [[ 2.5654e-02, -2.3252e-01, -1.0578e-01],
          [-8.4046e-02, -1.4129e-01, -7.9517e-02],
          [-5.9249e-02,  4.5285e-02,  9.4957e-02]]],


        [[[ 6.3026e-02, -2.2525e-01,  4.0749e-02],
          [-2.0685e-01, -5.3796e-01, -2.1602e-01],
          [ 1.4216e-01, -1.0193e-02,  1.1043e-02]],

         [[ 1.3468e-01, -2.8676e-01, -2.4250e-04],
          [-1.1642e-02, -2.8655e-01,  2.9324e-02],
          [ 1.6445e-01,  1.9734e-01,  5.4171e-02]],

         [[ 4.4470e-02, -2.4153e-01,  9.1404e-02],
          [ 6.6104e-02, -7.3509e-02,  1.1021e-01],
          [-7.8338e-02,  5.1762e-02,  1.3823e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.2344,  0.1443,  0.0982],
          [ 0.1436,  0.0945,  0.1246],
          [ 0.0411,  0.0752,  0.1292]],

         [[ 0.2349,  0.1333,  0.0729],
          [ 0.1513,  0.0899,  0.1027],
          [ 0.0674,  0.0901,  0.1447]],

         [[ 0.1890,  0.1126,  0.0662],
          [ 0.1138,  0.0690,  0.0881],
          [ 0.0512,  0.0705,  0.1110]]],


        [[[ 0.0003,  0.0002,  0.0007],
          [ 0.0008,  0.0002,  0.0007],
          [ 0.0010,  0.0003,  0.0005]],

         [[ 0.0001, -0.0005,  0.0000],
          [ 0.0006, -0.0003,  0.0001],
          [ 0.0008, -0.0002, -0.0001]],

         [[-0.0002, -0.0006, -0.0002],
          [ 0.0002, -0.0006, -0.0003],
          [ 0.0004, -0.0005, -0.0003]]],


        ...,


        [[[-0.0025, -0.0034, -0.0055],
          [-0.0076, -0.0069, -0.0109],
          [-0.0084, -0.0088, -0.0151]],

         [[ 0.0030,  0.0014, -0.0000],
          [ 0.0005,  0.0003, -0.0036],
          [ 0.0002, -0.0016, -0.0078]],

         [[ 0.0038,  0.0017, -0.0004],
          [ 0.0024,  0.0007, -0.0036],
          [ 0.0026, -0.0007, -0.0068]]],


        [[[-0.0135, -0.0021, -0.0108],
          [-0.0146, -0.0053, -0.0126],
          [-0.0081,  0.0016, -0.0017]],

         [[-0.0082, -0.0005, -0.0069],
          [-0.0096, -0.0031, -0.0074],
          [-0.0061,  0.0009, -0.0005]],

         [[-0.0069, -0.0005, -0.0037],
          [-0.0066, -0.0017, -0.0033],
          [-0.0057,  0.0001,  0.0007]]],


        [[[-0.0395, -0.0163, -0.0029],
          [-0.0336, -0.0106, -0.0015],
          [-0.0310, -0.0060, -0.0111]],

         [[-0.0412, -0.0203, -0.0095],
          [-0.0420, -0.0215, -0.0141],
          [-0.0504, -0.0263, -0.0301]],

         [[-0.0470, -0.0237, -0.0109],
          [-0.0470, -0.0234, -0.0116],
          [-0.0583, -0.0320, -0.0290]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2674]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 123 | Batch_idx: 0 |  Loss: (0.2925) | Acc: (91.00%) (117/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.2225) | Acc: (92.00%) (1305/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.2132) | Acc: (92.00%) (2497/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.2146) | Acc: (92.00%) (3680/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.2113) | Acc: (92.00%) (4878/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.2066) | Acc: (92.00%) (6066/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.2096) | Acc: (92.00%) (7248/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.2100) | Acc: (92.00%) (8432/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.2093) | Acc: (92.00%) (9635/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.2096) | Acc: (92.00%) (10822/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.2080) | Acc: (92.00%) (12012/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.2065) | Acc: (92.00%) (13202/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.2058) | Acc: (92.00%) (14400/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.2047) | Acc: (93.00%) (15598/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.2043) | Acc: (92.00%) (16781/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.2049) | Acc: (92.00%) (17966/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.2075) | Acc: (92.00%) (19135/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.2064) | Acc: (92.00%) (20333/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.2046) | Acc: (92.00%) (21534/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.2073) | Acc: (92.00%) (22698/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.2081) | Acc: (92.00%) (23879/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.2098) | Acc: (92.00%) (25053/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.2087) | Acc: (92.00%) (26256/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.2094) | Acc: (92.00%) (27443/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.2105) | Acc: (92.00%) (28611/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.2103) | Acc: (92.00%) (29801/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.2097) | Acc: (92.00%) (31003/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.2092) | Acc: (92.00%) (32196/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.2078) | Acc: (92.00%) (33392/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.2076) | Acc: (92.00%) (34572/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.2067) | Acc: (92.00%) (35769/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.2065) | Acc: (92.00%) (36966/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.2055) | Acc: (92.00%) (38175/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.2050) | Acc: (92.00%) (39378/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.2063) | Acc: (92.00%) (40552/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.2069) | Acc: (92.00%) (41743/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.2073) | Acc: (92.00%) (42920/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.2080) | Acc: (92.00%) (44103/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.2081) | Acc: (92.00%) (45287/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.2091) | Acc: (92.00%) (46414/50000)
# TEST : Loss: (0.3222) | Acc: (89.00%) (8981/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-4.6865e-39, -1.3640e-38, -9.4465e-39],
          [-1.0734e-32,  4.6573e-30,  2.3767e-29],
          [ 7.8217e-30, -1.4989e-26, -3.4654e-27]],

         [[ 1.5945e-35,  3.2658e-36,  1.1561e-36],
          [ 2.4620e-35, -1.0416e-35, -2.3637e-36],
          [-2.0447e-36,  1.2288e-34,  9.2632e-37]],

         [[-2.5505e-30,  7.0965e-31, -1.6674e-30],
          [-6.6971e-36, -4.6937e-37,  5.4950e-38],
          [ 8.3681e-39,  7.6752e-38,  1.3039e-38]]],


        [[[ 3.8628e-01,  1.3255e-02,  2.8096e-01],
          [ 1.6947e-01,  2.4686e-03, -1.9582e-01],
          [-2.0462e-01, -3.4155e-01, -2.6945e-01]],

         [[-2.9173e-02, -2.9096e-01, -3.4344e-02],
          [-9.5935e-02,  4.0402e-01, -2.2811e-01],
          [ 2.1616e-01,  1.2786e-01,  2.4679e-01]],

         [[-1.8586e-01, -2.5210e-01, -6.7464e-02],
          [-2.4425e-01,  1.5139e-01, -5.5688e-02],
          [ 2.3818e-02,  1.5912e-01,  2.4970e-01]]],


        [[[-6.7959e-03, -1.5224e-02, -2.5242e-02],
          [-2.7660e-02, -3.2191e-02, -4.0068e-02],
          [-4.4696e-02, -5.4548e-02, -5.5016e-02]],

         [[ 2.8124e-02,  2.2084e-02,  3.0311e-03],
          [ 1.9122e-02,  9.4225e-03, -9.1399e-03],
          [-1.3157e-03, -1.2506e-02, -3.4264e-02]],

         [[ 2.1465e-02,  2.0071e-02,  1.0315e-02],
          [ 1.2086e-02,  6.6076e-03, -2.6866e-03],
          [ 3.5806e-04, -6.9209e-03, -2.2117e-02]]],


        ...,


        [[[ 2.3351e-02,  2.3761e-02, -3.0066e-02],
          [ 2.2224e-02,  6.2325e-02, -4.9286e-03],
          [-1.3755e-01,  2.2314e-02,  3.9670e-02]],

         [[-1.2673e-01, -1.5708e-01, -5.8148e-02],
          [ 8.2845e-02,  3.8101e-02, -1.2579e-01],
          [ 1.0635e-01,  6.7146e-03, -3.0837e-02]],

         [[ 1.2729e-02,  1.2257e-01,  7.8906e-02],
          [ 2.8220e-01,  4.3087e-01,  1.7241e-01],
          [ 2.2602e-01,  2.8007e-01,  5.9168e-02]]],


        [[[ 3.2654e-01,  6.1548e-02,  9.5346e-02],
          [ 1.2336e-01, -9.0855e-02, -6.6749e-02],
          [ 4.4478e-02,  1.0548e-01,  6.1753e-02]],

         [[ 1.6367e-03, -2.2129e-01, -2.0940e-02],
          [-6.6321e-02, -2.7830e-01, -2.1708e-01],
          [-6.3989e-03, -6.0989e-02, -6.4882e-02]],

         [[ 4.3255e-02, -2.2334e-01, -1.0734e-01],
          [-5.9590e-02, -1.2064e-01, -7.6901e-02],
          [-5.9669e-02,  3.6959e-02,  7.4682e-02]]],


        [[[ 6.5823e-02, -2.2574e-01,  4.9773e-02],
          [-2.0694e-01, -5.5458e-01, -2.2770e-01],
          [ 1.3747e-01, -1.7788e-02, -2.9613e-03]],

         [[ 1.4072e-01, -2.7996e-01,  1.1761e-02],
          [-4.2155e-03, -2.8826e-01,  2.5749e-02],
          [ 1.6694e-01,  1.9787e-01,  4.6385e-02]],

         [[ 4.8446e-02, -2.3629e-01,  9.6166e-02],
          [ 7.1439e-02, -7.6707e-02,  1.0269e-01],
          [-7.4116e-02,  5.1251e-02,  1.2794e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0345, -0.0260, -0.0265],
          [ 0.0273,  0.0365,  0.0442],
          [ 0.0949,  0.0915,  0.0736]],

         [[-0.0471, -0.0171, -0.0089],
          [ 0.0040,  0.0428,  0.0548],
          [ 0.0642,  0.0885,  0.0754]],

         [[-0.0105,  0.0153,  0.0358],
          [ 0.0298,  0.0713,  0.0915],
          [ 0.0602,  0.1068,  0.1110]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0162,  0.0116,  0.0047],
          [ 0.0107,  0.0077,  0.0037],
          [ 0.0101,  0.0080,  0.0051]],

         [[ 0.0159,  0.0115,  0.0059],
          [ 0.0091,  0.0065,  0.0035],
          [ 0.0113,  0.0100,  0.0077]],

         [[ 0.0071,  0.0040, -0.0011],
          [ 0.0017, -0.0006, -0.0034],
          [ 0.0049,  0.0036,  0.0007]]],


        [[[ 0.0103,  0.0033, -0.0090],
          [ 0.0131, -0.0002, -0.0108],
          [ 0.0072, -0.0072, -0.0134]],

         [[ 0.0040, -0.0004, -0.0013],
          [ 0.0100,  0.0023,  0.0003],
          [ 0.0084,  0.0008, -0.0004]],

         [[ 0.0067,  0.0027,  0.0041],
          [ 0.0099,  0.0052,  0.0068],
          [ 0.0063,  0.0025,  0.0036]]],


        [[[ 0.0045,  0.0001, -0.0093],
          [-0.0018,  0.0001,  0.0074],
          [-0.0104,  0.0004,  0.0171]],

         [[ 0.0007, -0.0055, -0.0100],
          [-0.0031, -0.0035,  0.0016],
          [-0.0110, -0.0031,  0.0118]],

         [[-0.0032, -0.0130, -0.0143],
          [-0.0061, -0.0087, -0.0039],
          [-0.0100, -0.0044,  0.0039]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2667]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 124 | Batch_idx: 0 |  Loss: (0.1560) | Acc: (94.00%) (121/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1926) | Acc: (93.00%) (1316/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1875) | Acc: (93.00%) (2516/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.2023) | Acc: (93.00%) (3693/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.2012) | Acc: (93.00%) (4882/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.2028) | Acc: (92.00%) (6070/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1978) | Acc: (93.00%) (7279/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1960) | Acc: (93.00%) (8479/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1944) | Acc: (93.00%) (9680/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1928) | Acc: (93.00%) (10883/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1925) | Acc: (93.00%) (12090/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1923) | Acc: (93.00%) (13284/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1931) | Acc: (93.00%) (14472/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1926) | Acc: (93.00%) (15666/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1926) | Acc: (93.00%) (16866/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1926) | Acc: (93.00%) (18066/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1936) | Acc: (93.00%) (19248/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1961) | Acc: (93.00%) (20423/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1959) | Acc: (93.00%) (21617/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1981) | Acc: (93.00%) (22795/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1974) | Acc: (93.00%) (23999/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1986) | Acc: (93.00%) (25176/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1975) | Acc: (93.00%) (26381/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1975) | Acc: (93.00%) (27579/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1971) | Acc: (93.00%) (28768/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1969) | Acc: (93.00%) (29965/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1974) | Acc: (93.00%) (31167/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1975) | Acc: (93.00%) (32361/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1971) | Acc: (93.00%) (33562/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1962) | Acc: (93.00%) (34766/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1975) | Acc: (93.00%) (35943/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1977) | Acc: (93.00%) (37129/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1975) | Acc: (93.00%) (38323/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1976) | Acc: (93.00%) (39521/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1977) | Acc: (93.00%) (40723/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1981) | Acc: (93.00%) (41901/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1981) | Acc: (93.00%) (43099/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1984) | Acc: (93.00%) (44288/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1992) | Acc: (93.00%) (45475/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1995) | Acc: (93.00%) (46623/50000)
# TEST : Loss: (0.3217) | Acc: (90.00%) (9004/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 1.7719e-41, -1.6793e-41,  1.0243e-42],
          [ 3.9780e-41, -5.6474e-39,  1.7856e-38],
          [ 7.1499e-39,  1.9987e-35,  1.8642e-35]],

         [[ 6.3133e-41,  2.9294e-41,  1.2997e-41],
          [ 5.0395e-41, -4.6571e-41, -2.4426e-41],
          [-6.7327e-41,  4.7730e-41,  6.6395e-41]],

         [[-2.0911e-39,  3.9013e-40, -9.1924e-40],
          [ 1.8126e-41,  2.7208e-41, -1.9027e-41],
          [ 4.5248e-42, -1.3579e-42, -1.5575e-41]]],


        [[[ 3.7740e-01,  9.2344e-03,  2.7960e-01],
          [ 1.6344e-01, -1.1613e-03, -1.9818e-01],
          [-2.1750e-01, -3.5246e-01, -2.7865e-01]],

         [[-3.1323e-02, -2.9142e-01, -2.9632e-02],
          [-9.3923e-02,  4.0964e-01, -2.2071e-01],
          [ 2.1224e-01,  1.2924e-01,  2.4902e-01]],

         [[-1.7697e-01, -2.4528e-01, -5.3203e-02],
          [-2.3289e-01,  1.6577e-01, -3.9313e-02],
          [ 2.6928e-02,  1.6798e-01,  2.5779e-01]]],


        [[[-3.0361e-03, -7.2030e-03, -1.4178e-02],
          [-9.5158e-03, -1.3066e-02, -2.1809e-02],
          [-2.1321e-02, -2.6982e-02, -3.1941e-02]],

         [[ 1.4735e-02,  1.1364e-02,  1.6269e-03],
          [ 8.9099e-03,  4.3896e-03, -4.5698e-03],
          [-5.9942e-04, -5.0473e-03, -1.4101e-02]],

         [[ 1.2587e-02,  1.1211e-02,  5.4393e-03],
          [ 7.0857e-03,  3.8061e-03, -1.4997e-03],
          [ 2.1601e-04, -4.0463e-03, -1.2463e-02]]],


        ...,


        [[[ 2.3684e-02,  2.8259e-02, -2.6250e-02],
          [ 2.2399e-02,  6.3747e-02, -6.5623e-03],
          [-1.3240e-01,  2.7410e-02,  4.0322e-02]],

         [[-1.3928e-01, -1.6354e-01, -6.4967e-02],
          [ 6.8628e-02,  2.9124e-02, -1.3644e-01],
          [ 1.0236e-01,  5.5142e-03, -3.4818e-02]],

         [[ 3.9500e-03,  1.2420e-01,  7.6953e-02],
          [ 2.6931e-01,  4.3436e-01,  1.6624e-01],
          [ 2.2621e-01,  2.9096e-01,  5.8980e-02]]],


        [[[ 3.3122e-01,  5.0018e-02,  8.9897e-02],
          [ 1.2102e-01, -1.0900e-01, -7.4114e-02],
          [ 3.9178e-02,  9.0202e-02,  6.3299e-02]],

         [[ 1.0925e-02, -2.2391e-01, -2.1364e-02],
          [-6.3507e-02, -2.8813e-01, -2.1599e-01],
          [-9.1933e-03, -6.8823e-02, -5.4342e-02]],

         [[ 4.9108e-02, -2.2368e-01, -1.0291e-01],
          [-5.2775e-02, -1.1619e-01, -6.0059e-02],
          [-5.5102e-02,  4.2962e-02,  9.8510e-02]]],


        [[[ 6.6306e-02, -2.3078e-01,  5.3376e-02],
          [-2.1140e-01, -5.5305e-01, -2.1351e-01],
          [ 1.3758e-01, -1.3196e-02,  4.2687e-03]],

         [[ 1.3747e-01, -2.9030e-01,  5.1864e-03],
          [-6.8857e-03, -2.8827e-01,  3.2755e-02],
          [ 1.6736e-01,  2.0246e-01,  5.3235e-02]],

         [[ 5.0918e-02, -2.3653e-01,  9.1876e-02],
          [ 7.3731e-02, -7.2905e-02,  1.0768e-01],
          [-7.0574e-02,  5.5484e-02,  1.3237e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0038,  0.0217,  0.0465],
          [ 0.0773,  0.1255,  0.1028],
          [ 0.1343,  0.1262,  0.0985]],

         [[-0.0411, -0.0241,  0.0017],
          [ 0.0280,  0.0697,  0.0456],
          [ 0.0821,  0.0625,  0.0355]],

         [[-0.0608, -0.0549, -0.0447],
          [ 0.0132,  0.0419,  0.0028],
          [ 0.0580,  0.0309, -0.0058]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0251,  0.0237,  0.0243],
          [ 0.0181,  0.0171,  0.0156],
          [ 0.0148,  0.0132,  0.0116]],

         [[ 0.0174,  0.0157,  0.0163],
          [ 0.0107,  0.0099,  0.0081],
          [ 0.0080,  0.0067,  0.0046]],

         [[ 0.0097,  0.0081,  0.0084],
          [ 0.0038,  0.0028,  0.0008],
          [ 0.0014,  0.0006, -0.0019]]],


        [[[-0.0251, -0.0193, -0.0164],
          [-0.0152, -0.0056, -0.0053],
          [-0.0060, -0.0019, -0.0050]],

         [[-0.0266, -0.0177, -0.0151],
          [-0.0174, -0.0053, -0.0059],
          [-0.0090, -0.0026, -0.0062]],

         [[-0.0227, -0.0127, -0.0104],
          [-0.0121, -0.0009, -0.0018],
          [-0.0059, -0.0002, -0.0030]]],


        [[[ 0.0022,  0.0057,  0.0158],
          [ 0.0033,  0.0061,  0.0192],
          [ 0.0179,  0.0212,  0.0301]],

         [[-0.0099, -0.0026,  0.0116],
          [-0.0074, -0.0034,  0.0111],
          [ 0.0105,  0.0126,  0.0214]],

         [[-0.0185, -0.0126, -0.0045],
          [-0.0208, -0.0195, -0.0107],
          [-0.0103, -0.0111, -0.0046]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2657]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 125 | Batch_idx: 0 |  Loss: (0.1500) | Acc: (96.00%) (124/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1681) | Acc: (94.00%) (1335/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.2059) | Acc: (93.00%) (2507/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.2148) | Acc: (92.00%) (3687/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.2152) | Acc: (92.00%) (4872/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.2160) | Acc: (92.00%) (6056/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.2184) | Acc: (92.00%) (7235/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.2180) | Acc: (92.00%) (8429/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.2180) | Acc: (92.00%) (9616/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.2154) | Acc: (92.00%) (10811/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.2128) | Acc: (92.00%) (12006/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.2110) | Acc: (92.00%) (13201/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.2117) | Acc: (92.00%) (14389/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.2109) | Acc: (92.00%) (15587/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.2087) | Acc: (93.00%) (16792/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.2069) | Acc: (93.00%) (17997/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.2059) | Acc: (93.00%) (19193/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.2044) | Acc: (93.00%) (20394/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.2023) | Acc: (93.00%) (21607/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.2007) | Acc: (93.00%) (22813/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1999) | Acc: (93.00%) (24008/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1993) | Acc: (93.00%) (25207/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1993) | Acc: (93.00%) (26392/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1984) | Acc: (93.00%) (27594/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1989) | Acc: (93.00%) (28780/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1984) | Acc: (93.00%) (29983/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1979) | Acc: (93.00%) (31186/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1961) | Acc: (93.00%) (32398/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1955) | Acc: (93.00%) (33602/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1945) | Acc: (93.00%) (34814/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1946) | Acc: (93.00%) (36018/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1939) | Acc: (93.00%) (37215/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1927) | Acc: (93.00%) (38428/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1920) | Acc: (93.00%) (39634/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1914) | Acc: (93.00%) (40843/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1910) | Acc: (93.00%) (42044/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1904) | Acc: (93.00%) (43252/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1899) | Acc: (93.00%) (44461/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1891) | Acc: (93.00%) (45681/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1894) | Acc: (93.00%) (46830/50000)
# TEST : Loss: (0.2971) | Acc: (90.00%) (9048/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-6.0753e-41,  3.3802e-41, -1.5905e-41],
          [-1.6928e-41,  2.6381e-41, -2.0326e-41],
          [-3.1029e-41, -5.9038e-41,  6.5771e-41]],

         [[ 6.6029e-41,  8.1415e-42, -1.6719e-41],
          [ 3.8956e-41, -5.3866e-41,  2.7564e-42],
          [-5.6227e-41,  6.0585e-41,  6.4041e-41]],

         [[-3.3281e-41,  4.5806e-41, -6.3882e-41],
          [ 4.4221e-41,  6.7096e-41, -6.7998e-41],
          [-5.3918e-41, -5.6038e-41,  6.3103e-41]]],


        [[[ 3.7929e-01,  1.0059e-02,  2.7857e-01],
          [ 1.6294e-01, -3.7382e-03, -2.0087e-01],
          [-2.1999e-01, -3.5533e-01, -2.8116e-01]],

         [[-2.9080e-02, -2.8997e-01, -2.9806e-02],
          [-9.4218e-02,  4.0713e-01, -2.2271e-01],
          [ 2.0943e-01,  1.2647e-01,  2.4678e-01]],

         [[-1.7466e-01, -2.4366e-01, -5.2852e-02],
          [-2.3286e-01,  1.6381e-01, -4.0846e-02],
          [ 2.4897e-02,  1.6580e-01,  2.5598e-01]]],


        [[[-1.1348e-03, -2.8886e-03, -7.0162e-03],
          [-2.5805e-03, -4.3421e-03, -1.0386e-02],
          [-8.6396e-03, -1.1432e-02, -1.6463e-02]],

         [[ 6.6967e-03,  5.0519e-03,  7.6146e-04],
          [ 3.5069e-03,  1.7273e-03, -1.9609e-03],
          [-2.2950e-04, -1.6653e-03, -4.7667e-03]],

         [[ 6.5654e-03,  5.5103e-03,  2.4912e-03],
          [ 3.6949e-03,  1.9423e-03, -7.3651e-04],
          [ 1.1664e-04, -2.1027e-03, -6.1916e-03]]],


        ...,


        [[[ 1.6863e-02,  2.2387e-02, -3.1671e-02],
          [ 1.7680e-02,  5.9396e-02, -1.0457e-02],
          [-1.3467e-01,  2.4485e-02,  3.7464e-02]],

         [[-1.4389e-01, -1.6712e-01, -6.9296e-02],
          [ 6.4464e-02,  2.5548e-02, -1.3852e-01],
          [ 9.9242e-02,  3.2459e-03, -3.6389e-02]],

         [[-8.4197e-04,  1.1890e-01,  7.2621e-02],
          [ 2.6108e-01,  4.2081e-01,  1.6204e-01],
          [ 2.2140e-01,  2.8264e-01,  5.8030e-02]]],


        [[[ 3.3596e-01,  5.4756e-02,  9.4238e-02],
          [ 1.2692e-01, -1.0369e-01, -6.9180e-02],
          [ 4.3705e-02,  9.2726e-02,  6.6313e-02]],

         [[ 1.6538e-02, -2.1718e-01, -1.6031e-02],
          [-5.6586e-02, -2.8035e-01, -2.0908e-01],
          [-5.1999e-03, -6.6482e-02, -5.1590e-02]],

         [[ 5.3205e-02, -2.1698e-01, -9.6817e-02],
          [-4.6957e-02, -1.1013e-01, -5.4961e-02],
          [-5.1618e-02,  4.4049e-02,  9.9515e-02]]],


        [[[ 6.7413e-02, -2.3062e-01,  5.2801e-02],
          [-2.0905e-01, -5.5138e-01, -2.1471e-01],
          [ 1.3632e-01, -1.5776e-02,  7.5974e-04]],

         [[ 1.3827e-01, -2.8936e-01,  4.7314e-03],
          [-5.6725e-03, -2.8790e-01,  3.0733e-02],
          [ 1.6584e-01,  1.9967e-01,  4.9998e-02]],

         [[ 5.3253e-02, -2.3387e-01,  9.3478e-02],
          [ 7.6457e-02, -7.0475e-02,  1.0847e-01],
          [-6.9136e-02,  5.6186e-02,  1.3188e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2157]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0553]], device='cuda:0')

Epoch: 126 | Batch_idx: 0 |  Loss: (0.1133) | Acc: (95.00%) (122/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1700) | Acc: (94.00%) (1325/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1732) | Acc: (94.00%) (2528/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1821) | Acc: (93.00%) (3720/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1848) | Acc: (93.00%) (4915/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1757) | Acc: (93.00%) (6133/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1777) | Acc: (93.00%) (7336/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1761) | Acc: (93.00%) (8541/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1745) | Acc: (94.00%) (9750/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1750) | Acc: (94.00%) (10953/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1746) | Acc: (94.00%) (12160/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1729) | Acc: (94.00%) (13375/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1722) | Acc: (94.00%) (14594/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1712) | Acc: (94.00%) (15802/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1723) | Acc: (94.00%) (16992/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1719) | Acc: (94.00%) (18194/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1708) | Acc: (94.00%) (19404/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1691) | Acc: (94.00%) (20621/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1690) | Acc: (94.00%) (21837/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1687) | Acc: (94.00%) (23049/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1685) | Acc: (94.00%) (24267/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1693) | Acc: (94.00%) (25468/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1695) | Acc: (94.00%) (26673/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1691) | Acc: (94.00%) (27889/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1687) | Acc: (94.00%) (29099/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1683) | Acc: (94.00%) (30314/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1688) | Acc: (94.00%) (31511/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1698) | Acc: (94.00%) (32701/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1702) | Acc: (94.00%) (33902/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1706) | Acc: (94.00%) (35103/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1711) | Acc: (94.00%) (36307/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1711) | Acc: (94.00%) (37515/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1712) | Acc: (94.00%) (38718/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1712) | Acc: (94.00%) (39924/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1709) | Acc: (94.00%) (41134/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1711) | Acc: (94.00%) (42336/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1710) | Acc: (94.00%) (43541/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1707) | Acc: (94.00%) (44754/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1702) | Acc: (94.00%) (45966/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1703) | Acc: (94.00%) (47129/50000)
# TEST : Loss: (0.2920) | Acc: (90.00%) (9065/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.8897e-41, -4.4125e-41, -3.5784e-41],
          [ 6.5282e-41, -1.1212e-41, -6.5268e-41],
          [-4.7410e-41, -6.7677e-41,  6.6258e-41]],

         [[-3.8618e-41,  3.5132e-41,  6.5903e-41],
          [-1.1847e-41,  6.3500e-41, -4.6333e-41],
          [ 2.7233e-41, -6.5212e-41, -4.0767e-41]],

         [[-3.4165e-41,  1.1223e-41,  2.3155e-41],
          [-5.9255e-41, -1.6198e-41, -2.2687e-42],
          [ 1.9911e-41,  1.1128e-41,  2.1956e-41]]],


        [[[ 3.7886e-01,  1.0048e-02,  2.7825e-01],
          [ 1.6275e-01, -3.7339e-03, -2.0064e-01],
          [-2.1973e-01, -3.5492e-01, -2.8084e-01]],

         [[-2.9046e-02, -2.8963e-01, -2.9771e-02],
          [-9.4104e-02,  4.0665e-01, -2.2245e-01],
          [ 2.0918e-01,  1.2632e-01,  2.4649e-01]],

         [[-1.7444e-01, -2.4334e-01, -5.2785e-02],
          [-2.3256e-01,  1.6360e-01, -4.0795e-02],
          [ 2.4866e-02,  1.6560e-01,  2.5566e-01]]],


        [[[-3.4072e-04, -9.4564e-04, -2.9728e-03],
          [-5.2180e-04, -1.1282e-03, -4.1986e-03],
          [-2.8649e-03, -4.0047e-03, -7.3329e-03]],

         [[ 2.5562e-03,  1.8768e-03,  3.0133e-04],
          [ 1.1219e-03,  5.5240e-04, -6.9754e-04],
          [-7.0971e-05, -4.2882e-04, -1.2648e-03]],

         [[ 2.9671e-03,  2.3154e-03,  9.5998e-04],
          [ 1.6693e-03,  8.5453e-04, -3.0915e-04],
          [ 5.4996e-05, -9.4597e-04, -2.6361e-03]]],


        ...,


        [[[ 1.6733e-02,  2.2214e-02, -3.1435e-02],
          [ 1.7534e-02,  5.8912e-02, -1.0374e-02],
          [-1.3360e-01,  2.4291e-02,  3.7170e-02]],

         [[-1.4249e-01, -1.6547e-01, -6.8652e-02],
          [ 6.3701e-02,  2.5242e-02, -1.3698e-01],
          [ 9.8124e-02,  3.2084e-03, -3.5995e-02]],

         [[-8.3089e-04,  1.1727e-01,  7.1745e-02],
          [ 2.5412e-01,  4.0748e-01,  1.5890e-01],
          [ 2.1617e-01,  2.7421e-01,  5.6945e-02]]],


        [[[ 3.3407e-01,  5.4406e-02,  9.3623e-02],
          [ 1.2618e-01, -1.0297e-01, -6.8695e-02],
          [ 4.3463e-02,  9.2171e-02,  6.5919e-02]],

         [[ 1.6419e-02, -2.1512e-01, -1.5879e-02],
          [-5.6136e-02, -2.7703e-01, -2.0667e-01],
          [-5.1633e-03, -6.5932e-02, -5.1191e-02]],

         [[ 5.2725e-02, -2.1415e-01, -9.5544e-02],
          [-4.6464e-02, -1.0827e-01, -5.4070e-02],
          [-5.1160e-02,  4.3577e-02,  9.8546e-02]]],


        [[[ 6.7100e-02, -2.2906e-01,  5.2551e-02],
          [-2.0806e-01, -5.4756e-01, -2.1367e-01],
          [ 1.3585e-01, -1.5716e-02,  7.5711e-04]],

         [[ 1.3772e-01, -2.8789e-01,  4.7122e-03],
          [-5.6495e-03, -2.8644e-01,  3.0608e-02],
          [ 1.6532e-01,  1.9898e-01,  4.9840e-02]],

         [[ 5.3046e-02, -2.3282e-01,  9.3111e-02],
          [ 7.6159e-02, -7.0162e-02,  1.0805e-01],
          [-6.8912e-02,  5.5993e-02,  1.3146e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2264]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0568]], device='cuda:0')

Epoch: 127 | Batch_idx: 0 |  Loss: (0.1921) | Acc: (93.00%) (120/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1770) | Acc: (94.00%) (1329/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1744) | Acc: (94.00%) (2527/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1732) | Acc: (93.00%) (3728/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1700) | Acc: (94.00%) (4936/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1651) | Acc: (94.00%) (6164/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1685) | Acc: (94.00%) (7364/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1688) | Acc: (94.00%) (8578/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1716) | Acc: (94.00%) (9778/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1736) | Acc: (94.00%) (10982/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1727) | Acc: (94.00%) (12181/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1712) | Acc: (94.00%) (13389/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1714) | Acc: (94.00%) (14591/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1707) | Acc: (94.00%) (15801/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1711) | Acc: (94.00%) (17007/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1714) | Acc: (94.00%) (18221/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1705) | Acc: (94.00%) (19431/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1703) | Acc: (94.00%) (20644/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1705) | Acc: (94.00%) (21854/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1702) | Acc: (94.00%) (23058/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1693) | Acc: (94.00%) (24276/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1698) | Acc: (94.00%) (25484/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1711) | Acc: (94.00%) (26675/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1702) | Acc: (94.00%) (27895/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1703) | Acc: (94.00%) (29097/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1700) | Acc: (94.00%) (30311/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1703) | Acc: (94.00%) (31522/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1711) | Acc: (94.00%) (32730/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1713) | Acc: (94.00%) (33923/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1713) | Acc: (94.00%) (35126/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1709) | Acc: (94.00%) (36340/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1711) | Acc: (94.00%) (37550/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1708) | Acc: (94.00%) (38766/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1701) | Acc: (94.00%) (39986/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1708) | Acc: (94.00%) (41178/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1708) | Acc: (94.00%) (42381/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1708) | Acc: (94.00%) (43586/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1710) | Acc: (94.00%) (44801/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1712) | Acc: (94.00%) (46008/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1720) | Acc: (94.00%) (47153/50000)
# TEST : Loss: (0.2872) | Acc: (90.00%) (9066/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 3.3057e-41,  6.7712e-41,  6.4247e-41],
          [ 6.6248e-41,  6.8439e-41, -1.7061e-41],
          [-3.9151e-41,  6.6459e-41, -3.8386e-41]],

         [[ 3.6969e-41,  2.6999e-41, -2.2939e-42],
          [ 6.1957e-41, -6.7360e-42, -1.8556e-41],
          [-5.0741e-41, -2.6000e-41,  3.3571e-41]],

         [[-6.8892e-41,  3.7165e-41, -1.7278e-42],
          [ 3.5540e-41,  6.2972e-41, -1.7150e-41],
          [-4.4191e-41, -3.1830e-41, -2.9247e-41]]],


        [[[ 3.7834e-01,  1.0034e-02,  2.7787e-01],
          [ 1.6252e-01, -3.7287e-03, -2.0036e-01],
          [-2.1942e-01, -3.5443e-01, -2.8046e-01]],

         [[-2.9005e-02, -2.8921e-01, -2.9729e-02],
          [-9.3966e-02,  4.0605e-01, -2.2213e-01],
          [ 2.0887e-01,  1.2613e-01,  2.4614e-01]],

         [[-1.7417e-01, -2.4296e-01, -5.2704e-02],
          [-2.3220e-01,  1.6335e-01, -4.0732e-02],
          [ 2.4828e-02,  1.6534e-01,  2.5528e-01]]],


        [[[-7.8111e-05, -2.4118e-04, -1.0412e-03],
          [-7.3382e-05, -2.1637e-04, -1.3881e-03],
          [-7.4235e-04, -1.1102e-03, -2.7310e-03]],

         [[ 7.8757e-04,  5.5928e-04,  9.7046e-05],
          [ 2.7815e-04,  1.3689e-04, -1.9705e-04],
          [-1.6874e-05, -8.1338e-05, -2.4893e-04]],

         [[ 1.1248e-03,  8.0269e-04,  2.9923e-04],
          [ 6.3255e-04,  3.1345e-04, -1.0704e-04],
          [ 2.1961e-05, -3.5661e-04, -9.2877e-04]]],


        ...,


        [[[ 1.6575e-02,  2.2006e-02, -3.1150e-02],
          [ 1.7358e-02,  5.8329e-02, -1.0274e-02],
          [-1.3230e-01,  2.4057e-02,  3.6816e-02]],

         [[-1.4081e-01, -1.6348e-01, -6.7876e-02],
          [ 6.2785e-02,  2.4874e-02, -1.3512e-01],
          [ 9.6783e-02,  3.1633e-03, -3.5521e-02]],

         [[-8.1762e-04,  1.1532e-01,  7.0693e-02],
          [ 2.4590e-01,  3.9185e-01,  1.5515e-01],
          [ 2.0997e-01,  2.6430e-01,  5.5652e-02]]],


        [[[ 3.3178e-01,  5.3982e-02,  9.2881e-02],
          [ 1.2528e-01, -1.0211e-01, -6.8110e-02],
          [ 4.3170e-02,  9.1500e-02,  6.5442e-02]],

         [[ 1.6276e-02, -2.1265e-01, -1.5697e-02],
          [-5.5593e-02, -2.7304e-01, -2.0377e-01],
          [-5.1191e-03, -6.5269e-02, -5.0709e-02]],

         [[ 5.2146e-02, -2.1077e-01, -9.4018e-02],
          [-4.5872e-02, -1.0604e-01, -5.3006e-02],
          [-5.0609e-02,  4.3009e-02,  9.7381e-02]]],


        [[[ 6.6722e-02, -2.2717e-01,  5.2249e-02],
          [-2.0687e-01, -5.4296e-01, -2.1242e-01],
          [ 1.3528e-01, -1.5643e-02,  7.5393e-04]],

         [[ 1.3705e-01, -2.8612e-01,  4.6889e-03],
          [-5.6216e-03, -2.8467e-01,  3.0457e-02],
          [ 1.6468e-01,  1.9815e-01,  4.9649e-02]],

         [[ 5.2797e-02, -2.3155e-01,  9.2667e-02],
          [ 7.5799e-02, -6.9784e-02,  1.0754e-01],
          [-6.8642e-02,  5.5760e-02,  1.3095e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2386]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0319]], device='cuda:0')

Epoch: 128 | Batch_idx: 0 |  Loss: (0.1776) | Acc: (94.00%) (121/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1519) | Acc: (95.00%) (1341/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1628) | Acc: (94.00%) (2544/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1607) | Acc: (94.00%) (3762/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1649) | Acc: (94.00%) (4966/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1673) | Acc: (94.00%) (6163/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1669) | Acc: (94.00%) (7386/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1689) | Acc: (94.00%) (8597/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1669) | Acc: (94.00%) (9810/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1688) | Acc: (94.00%) (11015/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1692) | Acc: (94.00%) (12224/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1695) | Acc: (94.00%) (13427/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1698) | Acc: (94.00%) (14629/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1687) | Acc: (94.00%) (15840/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1693) | Acc: (94.00%) (17038/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1698) | Acc: (94.00%) (18239/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1700) | Acc: (94.00%) (19445/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1712) | Acc: (94.00%) (20644/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1710) | Acc: (94.00%) (21851/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1709) | Acc: (94.00%) (23059/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1708) | Acc: (94.00%) (24259/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1710) | Acc: (94.00%) (25462/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1713) | Acc: (94.00%) (26664/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1712) | Acc: (94.00%) (27867/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1723) | Acc: (94.00%) (29063/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1725) | Acc: (94.00%) (30271/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1734) | Acc: (94.00%) (31473/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1734) | Acc: (94.00%) (32684/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1735) | Acc: (94.00%) (33894/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1732) | Acc: (94.00%) (35098/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1733) | Acc: (94.00%) (36305/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1734) | Acc: (94.00%) (37509/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1726) | Acc: (94.00%) (38724/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1722) | Acc: (94.00%) (39934/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1729) | Acc: (94.00%) (41125/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1732) | Acc: (94.00%) (42329/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1731) | Acc: (94.00%) (43541/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1729) | Acc: (94.00%) (44751/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1726) | Acc: (94.00%) (45960/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1722) | Acc: (94.00%) (47131/50000)
# TEST : Loss: (0.2865) | Acc: (90.00%) (9069/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 2.9864e-41,  1.3377e-41, -3.1319e-41],
          [ 5.5079e-41, -4.6192e-41,  3.3085e-42],
          [ 3.0773e-41,  2.8330e-41,  3.7181e-41]],

         [[-4.6038e-41,  1.9383e-41, -1.6123e-41],
          [ 6.1918e-41,  5.1834e-42, -1.8110e-41],
          [-3.9451e-41, -7.1679e-41,  9.9604e-42]],

         [[ 5.6254e-41, -1.0112e-41, -2.6936e-41],
          [ 4.7519e-41,  3.4958e-41,  3.0302e-41],
          [ 7.1256e-42,  3.1430e-41, -2.5271e-41]]],


        [[[ 3.7770e-01,  1.0017e-02,  2.7741e-01],
          [ 1.6224e-01, -3.7224e-03, -2.0002e-01],
          [-2.1904e-01, -3.5383e-01, -2.7999e-01]],

         [[-2.8955e-02, -2.8870e-01, -2.9678e-02],
          [-9.3798e-02,  4.0534e-01, -2.2174e-01],
          [ 2.0850e-01,  1.2591e-01,  2.4571e-01]],

         [[-1.7384e-01, -2.4250e-01, -5.2606e-02],
          [-2.3176e-01,  1.6304e-01, -4.0656e-02],
          [ 2.4781e-02,  1.6504e-01,  2.5481e-01]]],


        [[[-1.2833e-05, -4.5205e-05, -2.8859e-04],
          [-6.5720e-06, -2.8497e-05, -3.5837e-04],
          [-1.4189e-04, -2.3066e-04, -8.1632e-04]],

         [[ 1.8640e-04,  1.2704e-04,  2.4257e-05],
          [ 5.0343e-05,  2.4762e-05, -4.1906e-05],
          [-2.8999e-06, -1.0567e-05, -3.3857e-05]],

         [[ 3.4364e-04,  2.1969e-04,  7.1842e-05],
          [ 1.9314e-04,  9.1958e-05, -2.9249e-05],
          [ 7.1516e-06, -1.0819e-04, -2.5930e-04]]],


        ...,


        [[[ 1.6385e-02,  2.1756e-02, -3.0807e-02],
          [ 1.7146e-02,  5.7628e-02, -1.0153e-02],
          [-1.3074e-01,  2.3775e-02,  3.6389e-02]],

         [[-1.3879e-01, -1.6110e-01, -6.6945e-02],
          [ 6.1689e-02,  2.4433e-02, -1.3291e-01],
          [ 9.5175e-02,  3.1094e-03, -3.4954e-02]],

         [[-8.0177e-04,  1.1300e-01,  6.9435e-02],
          [ 2.3627e-01,  3.7365e-01,  1.5072e-01],
          [ 2.0268e-01,  2.5272e-01,  5.4120e-02]]],


        [[[ 3.2901e-01,  5.3472e-02,  9.1986e-02],
          [ 1.2420e-01, -1.0108e-01, -6.7405e-02],
          [ 4.2816e-02,  9.0690e-02,  6.4867e-02]],

         [[ 1.6104e-02, -2.0967e-01, -1.5477e-02],
          [-5.4940e-02, -2.6827e-01, -2.0029e-01],
          [-5.0659e-03, -6.4472e-02, -5.0129e-02]],

         [[ 5.1451e-02, -2.0672e-01, -9.2195e-02],
          [-4.5163e-02, -1.0339e-01, -5.1741e-02],
          [-4.9946e-02,  4.2329e-02,  9.5983e-02]]],


        [[[ 6.6265e-02, -2.2490e-01,  5.1883e-02],
          [-2.0544e-01, -5.3741e-01, -2.1090e-01],
          [ 1.3459e-01, -1.5555e-02,  7.5007e-04]],

         [[ 1.3624e-01, -2.8397e-01,  4.6606e-03],
          [-5.5879e-03, -2.8253e-01,  3.0273e-02],
          [ 1.6391e-01,  1.9715e-01,  4.9417e-02]],

         [[ 5.2495e-02, -2.3001e-01,  9.2130e-02],
          [ 7.5363e-02, -6.9326e-02,  1.0693e-01],
          [-6.8315e-02,  5.5477e-02,  1.3033e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2464]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0367]], device='cuda:0')

Epoch: 129 | Batch_idx: 0 |  Loss: (0.1624) | Acc: (96.00%) (123/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1751) | Acc: (94.00%) (1331/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1648) | Acc: (94.00%) (2547/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1664) | Acc: (94.00%) (3756/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1674) | Acc: (94.00%) (4966/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1655) | Acc: (94.00%) (6179/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1651) | Acc: (94.00%) (7398/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1700) | Acc: (94.00%) (8590/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1682) | Acc: (94.00%) (9802/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1709) | Acc: (94.00%) (10996/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1741) | Acc: (94.00%) (12190/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1752) | Acc: (94.00%) (13391/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1744) | Acc: (94.00%) (14600/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1737) | Acc: (94.00%) (15808/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1750) | Acc: (94.00%) (17004/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1744) | Acc: (94.00%) (18220/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1748) | Acc: (94.00%) (19428/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1747) | Acc: (94.00%) (20641/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1753) | Acc: (94.00%) (21852/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1750) | Acc: (94.00%) (23071/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1757) | Acc: (94.00%) (24272/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1756) | Acc: (94.00%) (25486/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1749) | Acc: (94.00%) (26704/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1746) | Acc: (94.00%) (27906/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1746) | Acc: (94.00%) (29117/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1747) | Acc: (94.00%) (30324/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1745) | Acc: (94.00%) (31534/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1739) | Acc: (94.00%) (32746/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1728) | Acc: (94.00%) (33969/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1734) | Acc: (94.00%) (35168/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1737) | Acc: (94.00%) (36372/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1740) | Acc: (94.00%) (37578/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1743) | Acc: (94.00%) (38778/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1744) | Acc: (94.00%) (39986/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1751) | Acc: (94.00%) (41181/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1756) | Acc: (94.00%) (42382/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1760) | Acc: (94.00%) (43583/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1756) | Acc: (94.00%) (44802/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1758) | Acc: (94.00%) (46007/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1760) | Acc: (94.00%) (47161/50000)
# TEST : Loss: (0.2838) | Acc: (90.00%) (9068/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5971e-41,  2.9674e-41, -5.9103e-41],
          [-6.8554e-41, -7.1789e-41,  6.4582e-41],
          [ 6.4992e-41,  7.1399e-41,  2.2927e-41]],

         [[-5.6310e-41,  7.1447e-41,  4.0804e-41],
          [-5.4609e-42,  7.3805e-41, -7.0019e-41],
          [ 6.8219e-41,  3.8726e-41, -7.6294e-41]],

         [[-3.3236e-41,  7.1088e-41,  8.2312e-42],
          [-2.3009e-42,  5.9352e-41,  3.1039e-41],
          [ 1.4247e-41,  5.4974e-41,  2.1427e-41]]],


        [[[ 3.7693e-01,  9.9961e-03,  2.7685e-01],
          [ 1.6190e-01, -3.7147e-03, -1.9961e-01],
          [-2.1857e-01, -3.5310e-01, -2.7942e-01]],

         [[-2.8895e-02, -2.8808e-01, -2.9615e-02],
          [-9.3594e-02,  4.0446e-01, -2.2126e-01],
          [ 2.0804e-01,  1.2564e-01,  2.4519e-01]],

         [[-1.7344e-01, -2.4193e-01, -5.2486e-02],
          [-2.3122e-01,  1.6267e-01, -4.0563e-02],
          [ 2.4724e-02,  1.6467e-01,  2.5424e-01]]],


        [[[-1.3947e-06, -5.7866e-06, -5.9944e-05],
          [-3.3482e-07, -2.3519e-06, -6.8189e-05],
          [-1.8611e-05, -3.3549e-05, -1.8612e-04]],

         [[ 3.1854e-05,  2.0633e-05,  4.4348e-06],
          [ 6.1704e-06,  3.0330e-06, -6.2733e-06],
          [-3.3331e-07, -8.5728e-07, -2.9084e-06]],

         [[ 8.0486e-05,  4.4927e-05,  1.2497e-05],
          [ 4.5208e-05,  2.0488e-05, -5.9699e-06],
          [ 1.8122e-06, -2.5126e-05, -5.4346e-05]]],


        ...,


        [[[ 1.6158e-02,  2.1456e-02, -3.0394e-02],
          [ 1.6892e-02,  5.6786e-02, -1.0007e-02],
          [-1.2887e-01,  2.3437e-02,  3.5878e-02]],

         [[-1.3637e-01, -1.5824e-01, -6.5830e-02],
          [ 6.0382e-02,  2.3909e-02, -1.3026e-01],
          [ 9.3257e-02,  3.0450e-03, -3.4276e-02]],

         [[-7.8291e-04,  1.1023e-01,  6.7935e-02],
          [ 2.2507e-01,  3.5265e-01,  1.4550e-01],
          [ 1.9415e-01,  2.3933e-01,  5.2314e-02]]],


        [[[ 3.2568e-01,  5.2858e-02,  9.0909e-02],
          [ 1.2290e-01, -9.9828e-02, -6.6558e-02],
          [ 4.2389e-02,  8.9716e-02,  6.4174e-02]],

         [[ 1.5896e-02, -2.0611e-01, -1.5215e-02],
          [-5.4157e-02, -2.6258e-01, -1.9615e-01],
          [-5.0020e-03, -6.3515e-02, -4.9432e-02]],

         [[ 5.0619e-02, -2.0190e-01, -9.0026e-02],
          [-4.4315e-02, -1.0026e-01, -5.0242e-02],
          [-4.9152e-02,  4.1516e-02,  9.4309e-02]]],


        [[[ 6.5714e-02, -2.2217e-01,  5.1443e-02],
          [-2.0370e-01, -5.3074e-01, -2.0908e-01],
          [ 1.3376e-01, -1.5448e-02,  7.4540e-04]],

         [[ 1.3526e-01, -2.8139e-01,  4.6266e-03],
          [-5.5472e-03, -2.7994e-01,  3.0052e-02],
          [ 1.6297e-01,  1.9593e-01,  4.9137e-02]],

         [[ 5.2129e-02, -2.2816e-01,  9.1480e-02],
          [ 7.4836e-02, -6.8774e-02,  1.0619e-01],
          [-6.7919e-02,  5.5136e-02,  1.2958e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2427]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0369]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 130 | Batch_idx: 0 |  Loss: (0.1588) | Acc: (93.00%) (120/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.2150) | Acc: (92.00%) (1300/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.2587) | Acc: (90.00%) (2441/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.2900) | Acc: (90.00%) (3572/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.3303) | Acc: (88.00%) (4651/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.3498) | Acc: (88.00%) (5762/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.3576) | Acc: (88.00%) (6879/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.3659) | Acc: (87.00%) (7986/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.3656) | Acc: (87.00%) (9101/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.3664) | Acc: (87.00%) (10218/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.3694) | Acc: (87.00%) (11327/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.3683) | Acc: (87.00%) (12448/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.3683) | Acc: (87.00%) (13560/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.3650) | Acc: (87.00%) (14699/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.3621) | Acc: (87.00%) (15840/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.3621) | Acc: (87.00%) (16973/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.3572) | Acc: (87.00%) (18135/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.3539) | Acc: (88.00%) (19288/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.3517) | Acc: (88.00%) (20419/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.3491) | Acc: (88.00%) (21569/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.3457) | Acc: (88.00%) (22732/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.3446) | Acc: (88.00%) (23874/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.3424) | Acc: (88.00%) (25013/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.3419) | Acc: (88.00%) (26162/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.3392) | Acc: (88.00%) (27321/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.3388) | Acc: (88.00%) (28461/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.3373) | Acc: (88.00%) (29611/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.3363) | Acc: (88.00%) (30761/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.3347) | Acc: (88.00%) (31918/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.3342) | Acc: (88.00%) (33053/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.3341) | Acc: (88.00%) (34184/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.3326) | Acc: (88.00%) (35339/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.3316) | Acc: (88.00%) (36474/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.3325) | Acc: (88.00%) (37585/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.3306) | Acc: (88.00%) (38753/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.3295) | Acc: (88.00%) (39903/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.3282) | Acc: (88.00%) (41065/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.3277) | Acc: (88.00%) (42203/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.3268) | Acc: (88.00%) (43360/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.3258) | Acc: (88.00%) (44464/50000)
# TEST : Loss: (0.4888) | Acc: (84.00%) (8497/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-4.0398e-41,  1.0417e-41, -5.6192e-41],
          [ 6.1307e-42, -5.6739e-41,  7.5337e-41],
          [ 6.1834e-41, -4.6414e-41, -5.3049e-41]],

         [[ 4.4205e-41,  9.6101e-42,  4.9949e-41],
          [-4.6387e-41, -2.4102e-41, -2.0745e-41],
          [-2.7912e-41, -2.7973e-41,  4.6247e-41]],

         [[-7.0753e-41,  1.3661e-41,  6.9978e-41],
          [-7.9270e-41,  5.8807e-41,  3.2734e-42],
          [-3.3827e-42,  4.6010e-41,  3.2908e-41]]],


        [[[ 3.7567e-01,  1.3150e-02,  2.8956e-01],
          [ 1.7027e-01,  2.5845e-03, -1.9480e-01],
          [-2.0002e-01, -3.4732e-01, -2.7847e-01]],

         [[-3.9160e-02, -2.9655e-01, -2.8942e-02],
          [-9.2461e-02,  4.1203e-01, -2.1839e-01],
          [ 2.2097e-01,  1.3760e-01,  2.4752e-01]],

         [[-1.9139e-01, -2.5824e-01, -5.0167e-02],
          [-2.4575e-01,  1.6116e-01, -3.7055e-02],
          [ 2.5744e-02,  1.6504e-01,  2.5693e-01]]],


        [[[-9.0540e-08, -4.6090e-07, -8.7157e-06],
          [-8.3772e-09, -1.0813e-07, -8.8932e-06],
          [-1.5280e-06, -3.1332e-06, -3.0372e-05]],

         [[ 3.6356e-06,  2.2107e-06,  5.5042e-07],
          [ 4.6554e-07,  2.2864e-07, -6.0729e-07],
          [-2.3207e-08, -3.8577e-08, -1.4062e-07]],

         [[ 1.3578e-05,  6.4074e-06,  1.4581e-06],
          [ 7.6204e-06,  3.2492e-06, -8.4936e-07],
          [ 3.3696e-07, -4.1943e-06, -7.9901e-06]]],


        ...,


        [[[ 2.4711e-03,  2.5789e-02, -2.1989e-02],
          [ 7.7288e-03,  5.5814e-02, -1.1156e-02],
          [-1.3761e-01,  1.7871e-02,  3.2164e-02]],

         [[-1.4688e-01, -1.4431e-01, -4.9848e-02],
          [ 5.1828e-02,  3.3468e-02, -1.2323e-01],
          [ 8.6551e-02,  5.8146e-03, -3.3126e-02]],

         [[ 2.0135e-04,  1.3633e-01,  9.2295e-02],
          [ 2.3072e-01,  4.0380e-01,  1.7437e-01],
          [ 1.8511e-01,  2.5861e-01,  7.1567e-02]]],


        [[[ 3.1300e-01,  3.5406e-02,  8.1092e-02],
          [ 1.0938e-01, -1.2752e-01, -8.4894e-02],
          [ 4.5441e-02,  8.6218e-02,  7.5929e-02]],

         [[ 8.2369e-03, -2.1979e-01, -2.5617e-02],
          [-6.7039e-02, -2.9840e-01, -2.2188e-01],
          [ 2.2164e-03, -6.3119e-02, -3.2326e-02]],

         [[ 4.2536e-02, -2.1147e-01, -9.0037e-02],
          [-5.6977e-02, -1.3556e-01, -7.5935e-02],
          [-3.6794e-02,  4.7022e-02,  1.1115e-01]]],


        [[[ 9.6775e-02, -2.0068e-01,  8.1868e-02],
          [-1.7898e-01, -5.4163e-01, -2.1840e-01],
          [ 1.5246e-01, -1.3530e-02, -8.8991e-03]],

         [[ 1.6302e-01, -2.7709e-01,  1.8354e-02],
          [ 1.3717e-02, -2.9627e-01,  1.3808e-02],
          [ 1.7506e-01,  1.9077e-01,  3.3372e-02]],

         [[ 7.2879e-02, -2.2994e-01,  1.0105e-01],
          [ 8.7834e-02, -8.2063e-02,  9.0849e-02],
          [-6.2932e-02,  5.1765e-02,  1.1550e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.1686,  0.1951,  0.1687],
          [ 0.1941,  0.1862,  0.1300],
          [ 0.1812,  0.1587,  0.1075]],

         [[ 0.1900,  0.2203,  0.1941],
          [ 0.1964,  0.1991,  0.1514],
          [ 0.1820,  0.1656,  0.1208]],

         [[ 0.1534,  0.1912,  0.1619],
          [ 0.1555,  0.1700,  0.1273],
          [ 0.1375,  0.1300,  0.1102]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0060, -0.0042, -0.0040],
          [ 0.0043,  0.0051,  0.0036],
          [ 0.0083,  0.0063,  0.0014]],

         [[-0.0035, -0.0021, -0.0018],
          [ 0.0074,  0.0076,  0.0060],
          [ 0.0122,  0.0093,  0.0045]],

         [[-0.0073, -0.0075, -0.0089],
          [ 0.0010, -0.0003, -0.0037],
          [ 0.0064,  0.0016, -0.0044]]],


        [[[ 0.0048,  0.0064,  0.0130],
          [-0.0004, -0.0030,  0.0008],
          [-0.0040, -0.0068, -0.0024]],

         [[ 0.0031,  0.0064,  0.0141],
          [-0.0017, -0.0033,  0.0015],
          [-0.0055, -0.0073, -0.0018]],

         [[ 0.0007,  0.0037,  0.0100],
          [-0.0024, -0.0033,  0.0006],
          [-0.0062, -0.0076, -0.0032]]],


        [[[ 0.0192,  0.0172,  0.0149],
          [-0.0076, -0.0063, -0.0073],
          [-0.0072, -0.0061, -0.0047]],

         [[ 0.0181,  0.0209,  0.0212],
          [-0.0089, -0.0021,  0.0004],
          [-0.0080, -0.0024,  0.0009]],

         [[ 0.0174,  0.0242,  0.0243],
          [-0.0085,  0.0018,  0.0061],
          [-0.0081, -0.0014,  0.0037]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2396]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 131 | Batch_idx: 0 |  Loss: (0.3312) | Acc: (87.00%) (112/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.2593) | Acc: (90.00%) (1281/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.2577) | Acc: (90.00%) (2445/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.2585) | Acc: (91.00%) (3611/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.2572) | Acc: (90.00%) (4770/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.2533) | Acc: (90.00%) (5939/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.2507) | Acc: (91.00%) (7117/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.2505) | Acc: (91.00%) (8287/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.2539) | Acc: (91.00%) (9446/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.2526) | Acc: (91.00%) (10619/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.2550) | Acc: (91.00%) (11785/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.2571) | Acc: (91.00%) (12936/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.2542) | Acc: (91.00%) (14126/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.2542) | Acc: (91.00%) (15299/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.2537) | Acc: (91.00%) (16466/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.2535) | Acc: (91.00%) (17641/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.2535) | Acc: (91.00%) (18809/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.2533) | Acc: (91.00%) (19977/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.2514) | Acc: (91.00%) (21165/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.2518) | Acc: (91.00%) (22326/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.2521) | Acc: (91.00%) (23493/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.2522) | Acc: (91.00%) (24661/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.2520) | Acc: (91.00%) (25831/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.2518) | Acc: (91.00%) (26997/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.2523) | Acc: (91.00%) (28162/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.2519) | Acc: (91.00%) (29332/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.2521) | Acc: (91.00%) (30503/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.2507) | Acc: (91.00%) (31682/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.2511) | Acc: (91.00%) (32844/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.2513) | Acc: (91.00%) (34017/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.2506) | Acc: (91.00%) (35190/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.2514) | Acc: (91.00%) (36359/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.2518) | Acc: (91.00%) (37516/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.2514) | Acc: (91.00%) (38692/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.2511) | Acc: (91.00%) (39867/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.2505) | Acc: (91.00%) (41041/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.2510) | Acc: (91.00%) (42198/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.2505) | Acc: (91.00%) (43377/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.2503) | Acc: (91.00%) (44548/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.2501) | Acc: (91.00%) (45692/50000)
# TEST : Loss: (0.3788) | Acc: (88.00%) (8822/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-5.7494e-41, -6.1951e-42, -4.9253e-41],
          [ 5.5831e-41,  5.1932e-42,  6.7335e-41],
          [ 7.6905e-41,  3.1965e-41, -1.2742e-41]],

         [[-5.2100e-42, -8.0720e-41, -2.8047e-41],
          [ 8.2492e-41, -2.9751e-41,  7.3539e-41],
          [-1.0669e-41,  4.2032e-41, -2.1925e-41]],

         [[-5.5482e-41,  6.6906e-41,  2.7481e-41],
          [-1.2065e-41,  1.3828e-41, -3.7804e-41],
          [-4.5797e-41,  1.3876e-41,  3.1354e-41]]],


        [[[ 3.7506e-01,  1.3967e-02,  2.8672e-01],
          [ 1.6330e-01, -6.9407e-03, -2.0061e-01],
          [-2.0968e-01, -3.6516e-01, -2.8817e-01]],

         [[-3.7733e-02, -2.9770e-01, -3.7692e-02],
          [-8.9842e-02,  4.1103e-01, -2.2246e-01],
          [ 2.2386e-01,  1.3226e-01,  2.4647e-01]],

         [[-1.8932e-01, -2.6242e-01, -6.1535e-02],
          [-2.4212e-01,  1.5525e-01, -4.4382e-02],
          [ 2.9266e-02,  1.5860e-01,  2.5411e-01]]],


        [[[-3.0773e-09, -2.0266e-08, -8.1365e-07],
          [-8.4639e-11, -2.3754e-09, -7.2503e-07],
          [-6.9793e-08, -1.6824e-07, -3.2731e-06]],

         [[ 2.5092e-07,  1.4098e-07,  4.2182e-08],
          [ 1.9121e-08,  9.3809e-09, -3.4110e-08],
          [-8.6153e-10, -8.2462e-10, -3.2928e-09]],

         [[ 1.5251e-06,  5.8396e-07,  1.0345e-07],
          [ 8.5504e-07,  3.3794e-07, -7.7176e-08],
          [ 4.2707e-08, -4.6497e-07, -7.5632e-07]]],


        ...,


        [[[ 9.6822e-03,  3.3343e-02, -2.6701e-02],
          [ 1.1142e-02,  6.8719e-02, -8.7144e-03],
          [-1.3128e-01,  3.2902e-02,  3.8086e-02]],

         [[-1.3376e-01, -1.3427e-01, -5.8215e-02],
          [ 5.9870e-02,  4.8935e-02, -1.2317e-01],
          [ 1.0100e-01,  2.7417e-02, -2.7432e-02]],

         [[ 7.6742e-03,  1.4471e-01,  7.9687e-02],
          [ 2.3145e-01,  4.2942e-01,  1.6495e-01],
          [ 1.9532e-01,  2.8808e-01,  7.0453e-02]]],


        [[[ 3.1166e-01,  2.6981e-02,  7.4855e-02],
          [ 1.1392e-01, -1.3318e-01, -8.5640e-02],
          [ 4.3701e-02,  7.7709e-02,  7.3339e-02]],

         [[ 7.9246e-03, -2.2416e-01, -2.2224e-02],
          [-5.9826e-02, -2.9966e-01, -2.0979e-01],
          [ 5.1522e-04, -7.0312e-02, -3.0968e-02]],

         [[ 2.1928e-02, -2.4173e-01, -1.0035e-01],
          [-7.7359e-02, -1.7194e-01, -7.6660e-02],
          [-6.1294e-02,  1.9603e-02,  1.0316e-01]]],


        [[[ 8.0708e-02, -2.2478e-01,  6.9909e-02],
          [-1.8978e-01, -5.4806e-01, -2.2265e-01],
          [ 1.4316e-01, -1.3780e-02, -2.1610e-02]],

         [[ 1.5283e-01, -2.8953e-01,  1.4486e-02],
          [ 9.8886e-03, -2.9226e-01,  1.6803e-02],
          [ 1.7033e-01,  1.9170e-01,  2.2664e-02]],

         [[ 7.5350e-02, -2.2328e-01,  1.1226e-01],
          [ 9.6913e-02, -5.8377e-02,  1.0760e-01],
          [-6.0582e-02,  6.5613e-02,  1.1259e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0329,  0.0097, -0.0014],
          [ 0.0556,  0.0333,  0.0347],
          [ 0.0605,  0.0611,  0.0456]],

         [[-0.0057, -0.0257, -0.0248],
          [ 0.0131, -0.0076,  0.0064],
          [ 0.0199,  0.0189,  0.0150]],

         [[-0.0356, -0.0422, -0.0380],
          [-0.0252, -0.0262, -0.0064],
          [-0.0212, -0.0113,  0.0011]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0079,  0.0012, -0.0038],
          [ 0.0007, -0.0047, -0.0062],
          [-0.0071, -0.0103, -0.0082]],

         [[ 0.0065,  0.0014, -0.0014],
          [-0.0013, -0.0041, -0.0039],
          [-0.0059, -0.0065, -0.0042]],

         [[ 0.0125,  0.0078,  0.0045],
          [ 0.0037,  0.0006, -0.0001],
          [-0.0023, -0.0032, -0.0017]]],


        [[[ 0.0081,  0.0114,  0.0100],
          [ 0.0062,  0.0087,  0.0112],
          [ 0.0107,  0.0127,  0.0108]],

         [[-0.0045,  0.0000, -0.0025],
          [-0.0047,  0.0031,  0.0044],
          [-0.0000,  0.0097,  0.0077]],

         [[ 0.0003,  0.0035,  0.0007],
          [ 0.0012,  0.0077,  0.0083],
          [ 0.0032,  0.0117,  0.0095]]],


        [[[ 0.0105,  0.0100,  0.0394],
          [ 0.0025,  0.0072,  0.0353],
          [ 0.0156,  0.0132,  0.0443]],

         [[ 0.0277,  0.0256,  0.0441],
          [ 0.0182,  0.0246,  0.0436],
          [ 0.0243,  0.0282,  0.0562]],

         [[ 0.0122,  0.0082,  0.0212],
          [ 0.0053,  0.0079,  0.0214],
          [ 0.0132,  0.0141,  0.0337]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2391]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 132 | Batch_idx: 0 |  Loss: (0.1988) | Acc: (91.00%) (117/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1739) | Acc: (94.00%) (1334/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1806) | Acc: (94.00%) (2535/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1878) | Acc: (94.00%) (3733/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1932) | Acc: (93.00%) (4921/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1979) | Acc: (93.00%) (6100/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.2025) | Acc: (93.00%) (7281/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.2022) | Acc: (93.00%) (8475/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.2003) | Acc: (93.00%) (9678/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.2016) | Acc: (93.00%) (10860/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.2066) | Acc: (93.00%) (12030/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.2080) | Acc: (93.00%) (13219/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.2104) | Acc: (92.00%) (14387/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.2094) | Acc: (92.00%) (15584/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.2089) | Acc: (92.00%) (16778/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.2081) | Acc: (92.00%) (17971/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.2091) | Acc: (92.00%) (19154/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.2096) | Acc: (92.00%) (20342/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.2097) | Acc: (92.00%) (21524/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.2115) | Acc: (92.00%) (22697/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.2124) | Acc: (92.00%) (23888/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.2145) | Acc: (92.00%) (25060/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.2157) | Acc: (92.00%) (26233/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.2164) | Acc: (92.00%) (27410/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.2164) | Acc: (92.00%) (28591/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.2167) | Acc: (92.00%) (29767/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.2171) | Acc: (92.00%) (30949/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.2175) | Acc: (92.00%) (32128/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.2182) | Acc: (92.00%) (33301/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.2187) | Acc: (92.00%) (34478/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.2188) | Acc: (92.00%) (35666/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.2198) | Acc: (92.00%) (36835/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.2191) | Acc: (92.00%) (38029/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.2192) | Acc: (92.00%) (39206/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.2187) | Acc: (92.00%) (40403/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.2191) | Acc: (92.00%) (41582/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.2202) | Acc: (92.00%) (42764/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.2204) | Acc: (92.00%) (43941/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.2202) | Acc: (92.00%) (45130/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.2203) | Acc: (92.00%) (46263/50000)
# TEST : Loss: (0.3396) | Acc: (89.00%) (8915/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-6.9249e-41,  1.5032e-41, -7.4762e-41],
          [ 5.4264e-41,  7.4053e-41,  5.6570e-41],
          [ 7.8456e-41, -2.2268e-41,  6.4062e-41]],

         [[-7.1327e-41,  2.3170e-41, -7.1096e-41],
          [-5.7593e-43,  8.3871e-41,  3.8415e-41],
          [ 7.3886e-41, -4.1337e-41, -4.6028e-41]],

         [[-6.9000e-42,  2.2398e-41, -2.5177e-41],
          [ 7.8124e-41, -3.2926e-41, -3.5900e-41],
          [-2.5306e-41,  2.6981e-41,  8.4189e-41]]],


        [[[ 3.7023e-01,  1.4310e-02,  2.9227e-01],
          [ 1.6160e-01, -4.2105e-03, -2.0239e-01],
          [-2.0527e-01, -3.6115e-01, -2.8480e-01]],

         [[-4.6844e-02, -2.9820e-01, -3.0596e-02],
          [-9.4526e-02,  4.1600e-01, -2.2064e-01],
          [ 2.2746e-01,  1.4049e-01,  2.5417e-01]],

         [[-1.8645e-01, -2.5484e-01, -4.8419e-02],
          [-2.3518e-01,  1.6897e-01, -3.8761e-02],
          [ 4.2099e-02,  1.7380e-01,  2.6766e-01]]],


        [[[-4.6023e-11, -4.2066e-10, -4.3667e-08],
          [-2.6368e-13, -2.0302e-11, -3.2826e-08],
          [-1.5205e-09, -4.4990e-09, -2.1027e-07]],

         [[ 9.2129e-09,  4.6855e-09,  1.7670e-09],
          [ 3.6396e-10,  1.7832e-10, -9.6557e-10],
          [-1.4419e-11, -6.8043e-12, -3.0552e-11]],

         [[ 1.0317e-07,  3.0409e-08,  3.9322e-09],
          [ 5.7769e-08,  2.0766e-08, -4.0037e-09],
          [ 3.3597e-09, -3.0944e-08, -4.1301e-08]]],


        ...,


        [[[ 1.5637e-02,  3.9096e-02, -1.7275e-02],
          [ 2.2091e-02,  7.8316e-02,  6.4279e-04],
          [-1.2079e-01,  3.8788e-02,  4.0517e-02]],

         [[-1.2950e-01, -1.3143e-01, -5.1697e-02],
          [ 7.2222e-02,  6.0813e-02, -1.1184e-01],
          [ 1.1438e-01,  3.5881e-02, -2.4157e-02]],

         [[ 1.2465e-02,  1.4543e-01,  8.4719e-02],
          [ 2.4503e-01,  4.3830e-01,  1.7274e-01],
          [ 1.9386e-01,  2.7327e-01,  5.7198e-02]]],


        [[[ 3.1815e-01,  2.9311e-02,  7.9479e-02],
          [ 1.1290e-01, -1.3837e-01, -9.2111e-02],
          [ 5.2893e-02,  8.2397e-02,  7.5988e-02]],

         [[ 8.8367e-03, -2.2413e-01, -1.7890e-02],
          [-6.8507e-02, -3.0513e-01, -2.1569e-01],
          [ 4.6152e-03, -6.4571e-02, -2.7692e-02]],

         [[ 2.7157e-02, -2.2483e-01, -7.2851e-02],
          [-7.9565e-02, -1.5149e-01, -5.9536e-02],
          [-4.7961e-02,  3.8384e-02,  1.1561e-01]]],


        [[[ 7.4957e-02, -2.3478e-01,  6.8629e-02],
          [-1.9067e-01, -5.4630e-01, -2.1442e-01],
          [ 1.4727e-01, -2.8985e-03, -1.1337e-02]],

         [[ 1.4034e-01, -3.0640e-01,  6.1255e-03],
          [ 4.4590e-04, -3.0006e-01,  1.3867e-02],
          [ 1.6703e-01,  1.9336e-01,  2.2391e-02]],

         [[ 7.0554e-02, -2.2936e-01,  1.1167e-01],
          [ 9.3902e-02, -5.6210e-02,  1.1102e-01],
          [-6.0289e-02,  6.9980e-02,  1.1430e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.1045, -0.1221, -0.0967],
          [-0.1340, -0.1256, -0.0896],
          [-0.1275, -0.1257, -0.1062]],

         [[-0.1252, -0.1424, -0.1201],
          [-0.1515, -0.1487, -0.1083],
          [-0.1430, -0.1353, -0.1117]],

         [[-0.0778, -0.0870, -0.0631],
          [-0.0909, -0.0848, -0.0443],
          [-0.0799, -0.0689, -0.0460]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0162, -0.0144, -0.0119],
          [-0.0021, -0.0047, -0.0035],
          [-0.0000, -0.0034, -0.0016]],

         [[-0.0164, -0.0151, -0.0121],
          [-0.0011, -0.0038, -0.0024],
          [ 0.0020, -0.0018, -0.0003]],

         [[-0.0146, -0.0135, -0.0108],
          [-0.0005, -0.0026, -0.0014],
          [ 0.0034,  0.0005,  0.0015]]],


        [[[ 0.0074,  0.0185,  0.0212],
          [-0.0004,  0.0112,  0.0163],
          [-0.0026,  0.0072,  0.0122]],

         [[-0.0005,  0.0068,  0.0077],
          [-0.0102, -0.0025,  0.0016],
          [-0.0124, -0.0059, -0.0017]],

         [[ 0.0045,  0.0115,  0.0100],
          [-0.0045,  0.0020,  0.0039],
          [-0.0051,  0.0005,  0.0033]]],


        [[[-0.0001,  0.0063,  0.0191],
          [ 0.0076,  0.0124,  0.0216],
          [ 0.0305,  0.0289,  0.0283]],

         [[ 0.0013,  0.0044,  0.0144],
          [ 0.0077,  0.0087,  0.0158],
          [ 0.0279,  0.0217,  0.0201]],

         [[ 0.0054,  0.0070,  0.0136],
          [ 0.0051,  0.0055,  0.0099],
          [ 0.0201,  0.0152,  0.0136]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2385]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 133 | Batch_idx: 0 |  Loss: (0.2281) | Acc: (92.00%) (118/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1750) | Acc: (94.00%) (1324/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1890) | Acc: (93.00%) (2510/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1882) | Acc: (93.00%) (3707/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1932) | Acc: (93.00%) (4888/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1895) | Acc: (93.00%) (6090/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1893) | Acc: (93.00%) (7287/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1885) | Acc: (93.00%) (8492/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1859) | Acc: (93.00%) (9696/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1847) | Acc: (93.00%) (10901/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1870) | Acc: (93.00%) (12083/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1885) | Acc: (93.00%) (13264/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1902) | Acc: (93.00%) (14461/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1916) | Acc: (93.00%) (15647/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1925) | Acc: (93.00%) (16844/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1935) | Acc: (93.00%) (18018/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1940) | Acc: (93.00%) (19206/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1947) | Acc: (93.00%) (20387/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1947) | Acc: (93.00%) (21576/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1939) | Acc: (93.00%) (22776/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1953) | Acc: (93.00%) (23966/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1978) | Acc: (93.00%) (25144/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1972) | Acc: (93.00%) (26351/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1988) | Acc: (93.00%) (27530/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.2002) | Acc: (93.00%) (28709/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.2005) | Acc: (93.00%) (29900/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.2006) | Acc: (93.00%) (31100/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.2013) | Acc: (93.00%) (32281/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.2014) | Acc: (93.00%) (33474/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.2016) | Acc: (93.00%) (34659/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.2022) | Acc: (93.00%) (35850/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.2020) | Acc: (93.00%) (37048/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.2021) | Acc: (93.00%) (38240/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.2017) | Acc: (93.00%) (39439/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.2025) | Acc: (93.00%) (40609/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.2025) | Acc: (93.00%) (41799/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.2035) | Acc: (93.00%) (42975/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.2028) | Acc: (93.00%) (44176/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.2029) | Acc: (93.00%) (45360/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.2034) | Acc: (93.00%) (46504/50000)
# TEST : Loss: (0.3360) | Acc: (89.00%) (8914/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 5.4253e-41,  6.9715e-41,  1.1372e-41],
          [-6.9088e-41,  7.5157e-41,  5.8628e-41],
          [ 8.4957e-41,  9.7362e-42, -2.7835e-41]],

         [[-5.1777e-41,  6.3500e-41, -7.4290e-41],
          [ 3.3666e-41,  1.4831e-41, -1.2451e-41],
          [ 6.3385e-41,  1.6782e-41,  4.7944e-41]],

         [[ 6.4678e-41,  1.4083e-42, -4.5884e-41],
          [ 6.5313e-41, -2.7862e-41, -6.8247e-41],
          [ 3.0487e-41,  8.4708e-41,  7.8361e-42]]],


        [[[ 3.8292e-01,  2.8056e-02,  3.0300e-01],
          [ 1.6556e-01,  1.3969e-03, -1.9476e-01],
          [-2.0992e-01, -3.6219e-01, -2.8050e-01]],

         [[-3.9290e-02, -2.9123e-01, -2.7952e-02],
          [-9.7005e-02,  4.1756e-01, -2.1923e-01],
          [ 2.1818e-01,  1.3918e-01,  2.5597e-01]],

         [[-1.8205e-01, -2.5551e-01, -4.9678e-02],
          [-2.4741e-01,  1.6264e-01, -4.1946e-02],
          [ 2.4439e-02,  1.6843e-01,  2.6826e-01]]],


        [[[-2.3923e-13, -3.3421e-12, -1.1670e-09],
          [-1.7103e-16, -5.0761e-14, -7.0718e-10],
          [-1.2857e-11, -4.9507e-11, -7.0526e-09]],

         [[ 1.5204e-10,  6.8093e-11,  3.4486e-11],
          [ 2.5857e-12,  1.2647e-12, -1.1429e-11],
          [-8.6729e-14, -1.6242e-14, -8.5111e-14]],

         [[ 3.6935e-09,  7.8225e-10,  6.7823e-11],
          [ 2.0649e-09,  6.5853e-10, -1.0250e-10],
          [ 1.4544e-10, -1.0852e-09, -1.1282e-09]]],


        ...,


        [[[-2.7272e-03,  2.7495e-02, -2.6575e-02],
          [ 3.2897e-03,  6.4596e-02, -1.2370e-02],
          [-1.3902e-01,  2.2640e-02,  2.7600e-02]],

         [[-1.3901e-01, -1.3668e-01, -5.9997e-02],
          [ 6.0877e-02,  4.8879e-02, -1.2726e-01],
          [ 1.0242e-01,  2.0413e-02, -3.9679e-02]],

         [[ 9.7271e-03,  1.5560e-01,  8.9902e-02],
          [ 2.4046e-01,  4.4089e-01,  1.6730e-01],
          [ 1.7835e-01,  2.5756e-01,  4.9914e-02]]],


        [[[ 3.2459e-01,  3.7326e-02,  7.5818e-02],
          [ 1.1981e-01, -1.3331e-01, -9.5608e-02],
          [ 5.0980e-02,  8.0412e-02,  7.3135e-02]],

         [[ 1.5801e-02, -2.1602e-01, -3.3816e-02],
          [-6.1292e-02, -3.0208e-01, -2.3735e-01],
          [-4.4992e-03, -7.9301e-02, -5.1938e-02]],

         [[ 3.8175e-02, -2.0538e-01, -8.4189e-02],
          [-7.0553e-02, -1.3722e-01, -8.0937e-02],
          [-6.0101e-02,  2.2271e-02,  8.5775e-02]]],


        [[[ 6.9347e-02, -2.4544e-01,  6.5645e-02],
          [-2.0080e-01, -5.6096e-01, -2.1347e-01],
          [ 1.3373e-01, -9.3454e-03, -1.0528e-02]],

         [[ 1.4462e-01, -3.0175e-01,  1.3428e-02],
          [ 7.2212e-03, -2.9504e-01,  2.2433e-02],
          [ 1.6258e-01,  1.9177e-01,  2.1870e-02]],

         [[ 6.6932e-02, -2.3329e-01,  1.1277e-01],
          [ 9.6200e-02, -5.7078e-02,  1.1306e-01],
          [-6.8302e-02,  6.3397e-02,  1.0553e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0471, -0.0213, -0.0003],
          [-0.0422, -0.0081,  0.0194],
          [-0.0177,  0.0001,  0.0047]],

         [[-0.0593, -0.0326, -0.0089],
          [-0.0521, -0.0100,  0.0214],
          [-0.0127,  0.0074,  0.0163]],

         [[-0.0332, -0.0012,  0.0123],
          [-0.0374,  0.0022,  0.0213],
          [-0.0099,  0.0028,  0.0066]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0107, -0.0082, -0.0060],
          [-0.0088, -0.0073, -0.0066],
          [-0.0062, -0.0063, -0.0073]],

         [[-0.0046, -0.0018,  0.0015],
          [-0.0013,  0.0009,  0.0023],
          [ 0.0035,  0.0044,  0.0041]],

         [[-0.0072, -0.0039,  0.0005],
          [-0.0042, -0.0015,  0.0009],
          [ 0.0019,  0.0031,  0.0033]]],


        [[[-0.0071, -0.0043,  0.0024],
          [-0.0018, -0.0001,  0.0022],
          [ 0.0028,  0.0047,  0.0018]],

         [[-0.0060, -0.0052, -0.0013],
          [-0.0010, -0.0014, -0.0011],
          [ 0.0023,  0.0030, -0.0001]],

         [[-0.0020, -0.0028,  0.0002],
          [ 0.0008, -0.0006, -0.0008],
          [ 0.0026,  0.0024, -0.0004]]],


        [[[-0.0257, -0.0115, -0.0255],
          [-0.0236, -0.0039, -0.0135],
          [-0.0244, -0.0049, -0.0073]],

         [[-0.0194, -0.0066, -0.0202],
          [-0.0193,  0.0004, -0.0088],
          [-0.0206,  0.0003, -0.0007]],

         [[-0.0062,  0.0036, -0.0069],
          [-0.0094,  0.0085,  0.0018],
          [-0.0118,  0.0074,  0.0071]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2378]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 134 | Batch_idx: 0 |  Loss: (0.1624) | Acc: (94.00%) (121/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1871) | Acc: (93.00%) (1320/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1991) | Acc: (93.00%) (2509/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1989) | Acc: (93.00%) (3695/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.2002) | Acc: (93.00%) (4883/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1971) | Acc: (93.00%) (6078/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1944) | Acc: (93.00%) (7281/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1921) | Acc: (93.00%) (8477/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1947) | Acc: (93.00%) (9658/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1914) | Acc: (93.00%) (10859/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1909) | Acc: (93.00%) (12056/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1911) | Acc: (93.00%) (13257/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1931) | Acc: (93.00%) (14440/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1926) | Acc: (93.00%) (15639/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1917) | Acc: (93.00%) (16845/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1903) | Acc: (93.00%) (18048/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1899) | Acc: (93.00%) (19247/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1886) | Acc: (93.00%) (20446/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1886) | Acc: (93.00%) (21637/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1908) | Acc: (93.00%) (22825/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1900) | Acc: (93.00%) (24023/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1908) | Acc: (93.00%) (25215/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1914) | Acc: (93.00%) (26404/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1915) | Acc: (93.00%) (27606/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1912) | Acc: (93.00%) (28810/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1915) | Acc: (93.00%) (30000/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1907) | Acc: (93.00%) (31194/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1913) | Acc: (93.00%) (32387/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1903) | Acc: (93.00%) (33593/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1914) | Acc: (93.00%) (34773/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1919) | Acc: (93.00%) (35957/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1923) | Acc: (93.00%) (37147/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1939) | Acc: (93.00%) (38314/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1939) | Acc: (93.00%) (39503/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1940) | Acc: (93.00%) (40697/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1946) | Acc: (93.00%) (41879/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1946) | Acc: (93.00%) (43071/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1940) | Acc: (93.00%) (44280/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1945) | Acc: (93.00%) (45467/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1939) | Acc: (93.00%) (46620/50000)
# TEST : Loss: (0.3435) | Acc: (89.00%) (8947/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 4.3272e-42, -2.2404e-41, -5.3731e-41],
          [ 7.9839e-41,  7.9030e-41,  8.6155e-41],
          [ 5.9536e-41,  5.7464e-41, -8.6282e-41]],

         [[-7.9938e-41,  8.7570e-41, -7.5590e-41],
          [-3.3141e-41, -2.4122e-41, -8.3658e-43],
          [ 3.4337e-41,  9.1964e-41,  8.9553e-41]],

         [[ 2.7346e-41, -3.6998e-41,  2.0575e-41],
          [ 6.4762e-41,  1.0119e-41,  8.4046e-41],
          [ 6.6150e-41,  2.4401e-41, -5.0499e-41]]],


        [[[ 3.7423e-01,  2.1009e-02,  2.9568e-01],
          [ 1.6501e-01,  1.7754e-03, -1.9798e-01],
          [-2.0906e-01, -3.6318e-01, -2.8999e-01]],

         [[-5.1817e-02, -3.0129e-01, -3.8670e-02],
          [-9.9040e-02,  4.1608e-01, -2.2242e-01],
          [ 2.1740e-01,  1.3878e-01,  2.4351e-01]],

         [[-1.9054e-01, -2.6114e-01, -5.1996e-02],
          [-2.3981e-01,  1.7009e-01, -3.4571e-02],
          [ 3.6216e-02,  1.8092e-01,  2.6845e-01]]],


        [[[-3.0924e-16, -7.5889e-15, -1.2831e-11],
          [-1.2273e-20, -2.4391e-17, -5.8940e-12],
          [-3.1697e-14, -1.7249e-13, -1.0370e-10]],

         [[ 8.9797e-13,  3.4101e-13,  2.5305e-13],
          [ 5.0646e-15,  2.4715e-15, -4.3808e-14],
          [-1.3620e-16, -7.3243e-18, -4.7408e-17]],

         [[ 5.9021e-11,  8.1900e-12,  4.2418e-13],
          [ 3.2930e-11,  9.0139e-12, -1.0666e-12],
          [ 2.9599e-12, -1.6891e-11, -1.2759e-11]]],


        ...,


        [[[-9.7267e-03,  2.4310e-02, -3.1257e-02],
          [-3.8766e-03,  6.1303e-02, -1.9336e-02],
          [-1.4781e-01,  2.1699e-02,  2.8356e-02]],

         [[-1.3620e-01, -1.2828e-01, -5.4594e-02],
          [ 6.4461e-02,  5.8486e-02, -1.2243e-01],
          [ 1.0176e-01,  3.2928e-02, -2.3602e-02]],

         [[ 7.7252e-03,  1.6235e-01,  9.3652e-02],
          [ 2.3139e-01,  4.5447e-01,  1.7419e-01],
          [ 1.5694e-01,  2.7288e-01,  7.2250e-02]]],


        [[[ 3.2730e-01,  3.7890e-02,  6.3324e-02],
          [ 1.2666e-01, -1.3362e-01, -1.0643e-01],
          [ 5.5156e-02,  7.9738e-02,  6.8111e-02]],

         [[ 1.4837e-02, -2.1769e-01, -4.8402e-02],
          [-5.5648e-02, -3.0014e-01, -2.4403e-01],
          [-4.7876e-03, -8.3528e-02, -5.6070e-02]],

         [[ 4.0025e-02, -2.0461e-01, -9.7140e-02],
          [-5.7671e-02, -1.1961e-01, -7.6700e-02],
          [-5.2306e-02,  3.1726e-02,  9.0906e-02]]],


        [[[ 7.5412e-02, -2.4974e-01,  6.9653e-02],
          [-1.9264e-01, -5.5936e-01, -2.0110e-01],
          [ 1.4091e-01, -1.9653e-03, -1.9044e-03]],

         [[ 1.4899e-01, -3.0351e-01,  1.8372e-02],
          [ 1.2506e-02, -2.9411e-01,  3.2523e-02],
          [ 1.6515e-01,  1.9531e-01,  2.9014e-02]],

         [[ 7.4883e-02, -2.3493e-01,  1.1040e-01],
          [ 1.0532e-01, -5.6560e-02,  1.1521e-01],
          [-6.5119e-02,  6.5750e-02,  1.0642e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0551,  0.0396,  0.0533],
          [ 0.0019, -0.0106, -0.0147],
          [ 0.0010, -0.0230, -0.0382]],

         [[ 0.0318,  0.0087,  0.0280],
          [-0.0180, -0.0385, -0.0409],
          [-0.0143, -0.0482, -0.0611]],

         [[ 0.0441,  0.0265,  0.0535],
          [-0.0006, -0.0124, -0.0102],
          [ 0.0182, -0.0081, -0.0152]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0035, -0.0057, -0.0083],
          [-0.0079, -0.0110, -0.0140],
          [-0.0076, -0.0104, -0.0138]],

         [[-0.0009, -0.0027, -0.0046],
          [-0.0026, -0.0052, -0.0078],
          [-0.0010, -0.0037, -0.0067]],

         [[-0.0016, -0.0019, -0.0029],
          [-0.0001, -0.0014, -0.0033],
          [ 0.0024,  0.0006, -0.0021]]],


        [[[-0.0046, -0.0038,  0.0005],
          [-0.0015, -0.0009, -0.0030],
          [-0.0008,  0.0002, -0.0028]],

         [[-0.0037, -0.0017,  0.0034],
          [-0.0016,  0.0001, -0.0013],
          [-0.0015,  0.0008, -0.0018]],

         [[-0.0048, -0.0036,  0.0020],
          [-0.0042, -0.0029, -0.0033],
          [-0.0060, -0.0033, -0.0046]]],


        [[[-0.0366, -0.0177, -0.0343],
          [-0.0358, -0.0185, -0.0405],
          [-0.0321, -0.0216, -0.0396]],

         [[-0.0418, -0.0251, -0.0430],
          [-0.0434, -0.0278, -0.0499],
          [-0.0395, -0.0295, -0.0462]],

         [[-0.0401, -0.0262, -0.0404],
          [-0.0435, -0.0288, -0.0465],
          [-0.0377, -0.0294, -0.0432]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2370]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1584) | Acc: (92.00%) (119/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.2341) | Acc: (91.00%) (1291/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.2347) | Acc: (91.00%) (2469/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.2304) | Acc: (92.00%) (3654/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.2320) | Acc: (91.00%) (4819/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.2242) | Acc: (92.00%) (6009/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.2219) | Acc: (92.00%) (7201/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.2172) | Acc: (92.00%) (8392/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.2173) | Acc: (92.00%) (9578/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.2135) | Acc: (92.00%) (10775/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.2134) | Acc: (92.00%) (11965/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.2114) | Acc: (92.00%) (13167/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.2077) | Acc: (92.00%) (14376/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.2065) | Acc: (92.00%) (15570/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.2041) | Acc: (92.00%) (16777/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.2021) | Acc: (92.00%) (17974/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1994) | Acc: (93.00%) (19182/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1988) | Acc: (93.00%) (20380/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1965) | Acc: (93.00%) (21591/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1953) | Acc: (93.00%) (22792/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1963) | Acc: (93.00%) (23977/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1960) | Acc: (93.00%) (25173/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1942) | Acc: (93.00%) (26380/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1925) | Acc: (93.00%) (27590/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1910) | Acc: (93.00%) (28795/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1895) | Acc: (93.00%) (30016/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1890) | Acc: (93.00%) (31223/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1892) | Acc: (93.00%) (32426/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1880) | Acc: (93.00%) (33638/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1873) | Acc: (93.00%) (34851/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1858) | Acc: (93.00%) (36067/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1855) | Acc: (93.00%) (37271/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1850) | Acc: (93.00%) (38473/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1849) | Acc: (93.00%) (39673/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1840) | Acc: (93.00%) (40886/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1835) | Acc: (93.00%) (42085/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1822) | Acc: (93.00%) (43302/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1822) | Acc: (93.00%) (44503/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1821) | Acc: (93.00%) (45707/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1820) | Acc: (93.00%) (46870/50000)
# TEST : Loss: (0.3040) | Acc: (89.00%) (8992/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 5.7369e-42, -4.0603e-41, -5.1341e-41],
          [ 5.0122e-41,  7.0003e-41, -1.8478e-41],
          [-8.8400e-41, -5.3595e-41, -7.9938e-41]],

         [[ 5.2008e-41, -1.0187e-41, -6.0728e-41],
          [ 6.2401e-41, -7.6278e-41,  8.0762e-41],
          [-9.1000e-42,  9.4824e-41,  5.7733e-41]],

         [[-5.8496e-41, -6.1937e-42,  5.9700e-41],
          [ 7.7942e-41,  7.7736e-41,  7.4848e-41],
          [-4.5370e-41, -1.0062e-40,  8.0517e-41]]],


        [[[ 3.7292e-01,  2.0341e-02,  2.9499e-01],
          [ 1.6643e-01,  3.4896e-03, -1.9548e-01],
          [-2.0716e-01, -3.6016e-01, -2.8605e-01]],

         [[-5.2564e-02, -3.0152e-01, -3.9248e-02],
          [-9.7137e-02,  4.1761e-01, -2.1988e-01],
          [ 2.1877e-01,  1.4143e-01,  2.4694e-01]],

         [[-1.9230e-01, -2.6297e-01, -5.4762e-02],
          [-2.3920e-01,  1.6964e-01, -3.4683e-02],
          [ 3.6385e-02,  1.8129e-01,  2.6944e-01]]],


        [[[-5.9503e-20, -3.1953e-18, -4.4657e-14],
          [-2.6856e-26, -1.1266e-21, -1.4256e-14],
          [-1.4940e-17, -1.3021e-16, -5.2732e-13]],

         [[ 1.3764e-15,  4.1940e-16,  5.1730e-16],
          [ 1.7393e-18,  8.4610e-19, -3.7621e-17],
          [-3.4420e-20, -3.0784e-22, -2.7229e-21]],

         [[ 3.3434e-13,  2.6735e-14,  7.0159e-16],
          [ 1.8605e-13,  4.1757e-14, -3.4538e-15],
          [ 2.2923e-14, -9.2468e-14, -4.6075e-14]]],


        ...,


        [[[-1.0475e-02,  2.3788e-02, -3.1539e-02],
          [-3.5074e-03,  6.2153e-02, -1.8102e-02],
          [-1.4724e-01,  2.2239e-02,  2.9009e-02]],

         [[-1.3624e-01, -1.2758e-01, -5.4590e-02],
          [ 6.4056e-02,  5.9605e-02, -1.1976e-01],
          [ 9.9800e-02,  3.3299e-02, -2.2364e-02]],

         [[ 5.8766e-03,  1.6021e-01,  9.2451e-02],
          [ 2.2502e-01,  4.4421e-01,  1.7356e-01],
          [ 1.4876e-01,  2.6501e-01,  7.1274e-02]]],


        [[[ 3.2847e-01,  4.0593e-02,  6.5733e-02],
          [ 1.2862e-01, -1.2988e-01, -1.0221e-01],
          [ 5.5647e-02,  7.9611e-02,  6.8306e-02]],

         [[ 1.6804e-02, -2.1420e-01, -4.7441e-02],
          [-5.3084e-02, -2.9516e-01, -2.3971e-01],
          [-4.5765e-03, -8.4494e-02, -5.6961e-02]],

         [[ 4.1403e-02, -2.0065e-01, -9.5757e-02],
          [-5.5224e-02, -1.1599e-01, -7.3679e-02],
          [-5.2046e-02,  2.9303e-02,  8.8256e-02]]],


        [[[ 8.1687e-02, -2.4347e-01,  7.5665e-02],
          [-1.8566e-01, -5.5094e-01, -1.9340e-01],
          [ 1.4506e-01,  8.2784e-04,  2.4624e-03]],

         [[ 1.5426e-01, -2.9868e-01,  2.3611e-02],
          [ 1.8060e-02, -2.8906e-01,  3.8447e-02],
          [ 1.6910e-01,  1.9750e-01,  3.3388e-02]],

         [[ 7.9755e-02, -2.3103e-01,  1.1470e-01],
          [ 1.1032e-01, -5.2963e-02,  1.2015e-01],
          [-6.0684e-02,  6.8246e-02,  1.1028e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2397]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0499]], device='cuda:0')

Epoch: 136 | Batch_idx: 0 |  Loss: (0.2128) | Acc: (94.00%) (121/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1665) | Acc: (94.00%) (1330/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1685) | Acc: (94.00%) (2534/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1635) | Acc: (94.00%) (3744/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1615) | Acc: (94.00%) (4954/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1611) | Acc: (94.00%) (6167/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1605) | Acc: (94.00%) (7381/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1633) | Acc: (94.00%) (8584/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1592) | Acc: (94.00%) (9805/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1633) | Acc: (94.00%) (11005/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1652) | Acc: (94.00%) (12206/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1641) | Acc: (94.00%) (13412/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1655) | Acc: (94.00%) (14614/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1634) | Acc: (94.00%) (15832/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1631) | Acc: (94.00%) (17036/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1623) | Acc: (94.00%) (18264/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1642) | Acc: (94.00%) (19460/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1637) | Acc: (94.00%) (20673/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1633) | Acc: (94.00%) (21879/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1639) | Acc: (94.00%) (23080/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1631) | Acc: (94.00%) (24299/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1628) | Acc: (94.00%) (25508/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1640) | Acc: (94.00%) (26696/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1638) | Acc: (94.00%) (27917/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1636) | Acc: (94.00%) (29130/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1629) | Acc: (94.00%) (30345/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1626) | Acc: (94.00%) (31556/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1622) | Acc: (94.00%) (32774/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1624) | Acc: (94.00%) (33972/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1617) | Acc: (94.00%) (35191/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1618) | Acc: (94.00%) (36395/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1615) | Acc: (94.00%) (37604/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1608) | Acc: (94.00%) (38825/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1613) | Acc: (94.00%) (40033/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1612) | Acc: (94.00%) (41247/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1609) | Acc: (94.00%) (42468/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1603) | Acc: (94.00%) (43691/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1607) | Acc: (94.00%) (44898/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1614) | Acc: (94.00%) (46090/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1614) | Acc: (94.00%) (47254/50000)
# TEST : Loss: (0.2962) | Acc: (90.00%) (9037/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1488e-40,  8.0188e-41,  3.6313e-41],
          [ 3.2139e-41,  5.8438e-41,  1.3800e-41],
          [ 9.6258e-41, -8.9853e-41, -9.2240e-41]],

         [[ 4.7171e-41, -1.1971e-41,  9.9030e-42],
          [ 3.9580e-41, -7.6662e-41,  1.1320e-40],
          [ 4.3286e-42,  8.4595e-41,  7.9870e-41]],

         [[-3.3980e-41, -4.4242e-41, -5.3663e-41],
          [-3.0616e-41, -2.8316e-41, -8.8003e-41],
          [ 1.0026e-41, -8.0252e-42,  9.7170e-41]]],


        [[[ 3.7250e-01,  2.0318e-02,  2.9465e-01],
          [ 1.6623e-01,  3.4855e-03, -1.9525e-01],
          [-2.0692e-01, -3.5975e-01, -2.8572e-01]],

         [[-5.2503e-02, -3.0117e-01, -3.9201e-02],
          [-9.7021e-02,  4.1710e-01, -2.1961e-01],
          [ 2.1851e-01,  1.4126e-01,  2.4664e-01]],

         [[-1.9206e-01, -2.6264e-01, -5.4693e-02],
          [-2.3890e-01,  1.6942e-01, -3.4639e-02],
          [ 3.6339e-02,  1.8106e-01,  2.6911e-01]]],


        [[[-6.7720e-25, -1.2124e-22, -3.3662e-17],
          [ 7.3500e-35, -1.0952e-27, -6.5462e-18],
          [-6.7055e-22, -1.1643e-20, -6.6191e-16]],

         [[ 3.3625e-19,  7.5234e-20,  1.8847e-19],
          [ 4.8570e-23,  2.3514e-23, -4.0496e-21],
          [-6.0069e-25, -2.4940e-28, -3.9846e-27]],

         [[ 4.8475e-16,  1.8476e-17,  1.9059e-19],
          [ 2.6880e-16,  4.6267e-17, -2.3609e-18],
          [ 5.0327e-17, -1.2810e-16, -3.6505e-17]]],


        ...,


        [[[-1.0396e-02,  2.3605e-02, -3.1304e-02],
          [-3.4789e-03,  6.1650e-02, -1.7959e-02],
          [-1.4608e-01,  2.2066e-02,  2.8789e-02]],

         [[-1.3493e-01, -1.2631e-01, -5.4080e-02],
          [ 6.3303e-02,  5.8885e-02, -1.1843e-01],
          [ 9.8698e-02,  3.2927e-02, -2.2135e-02]],

         [[ 5.8031e-03,  1.5798e-01,  9.1315e-02],
          [ 2.1965e-01,  4.2838e-01,  1.7009e-01],
          [ 1.4554e-01,  2.5761e-01,  7.0048e-02]]],


        [[[ 3.2649e-01,  4.0300e-02,  6.5256e-02],
          [ 1.2778e-01, -1.2881e-01, -1.0139e-01],
          [ 5.5307e-02,  7.9064e-02,  6.7851e-02]],

         [[ 1.6683e-02, -2.1199e-01, -4.6953e-02],
          [-5.2645e-02, -2.9099e-01, -2.3658e-01],
          [-4.5431e-03, -8.3712e-02, -5.6472e-02]],

         [[ 4.1034e-02, -1.9793e-01, -9.4443e-02],
          [-5.4639e-02, -1.1366e-01, -7.2344e-02],
          [-5.1586e-02,  2.8967e-02,  8.7329e-02]]],


        [[[ 8.1332e-02, -2.4181e-01,  7.5318e-02],
          [-1.8485e-01, -5.4696e-01, -1.9247e-01],
          [ 1.4460e-01,  8.2478e-04,  2.4541e-03]],

         [[ 1.5366e-01, -2.9710e-01,  2.3516e-02],
          [ 1.7990e-02, -2.8751e-01,  3.8289e-02],
          [ 1.6859e-01,  1.9683e-01,  3.3284e-02]],

         [[ 7.9442e-02, -2.2993e-01,  1.1425e-01],
          [ 1.0989e-01, -5.2713e-02,  1.1968e-01],
          [-6.0492e-02,  6.8008e-02,  1.0992e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2574]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0870]], device='cuda:0')

Epoch: 137 | Batch_idx: 0 |  Loss: (0.1613) | Acc: (96.00%) (123/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1710) | Acc: (93.00%) (1321/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1650) | Acc: (94.00%) (2531/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1597) | Acc: (94.00%) (3744/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1644) | Acc: (94.00%) (4951/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1641) | Acc: (94.00%) (6159/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1623) | Acc: (94.00%) (7367/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1622) | Acc: (94.00%) (8572/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1642) | Acc: (94.00%) (9777/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1628) | Acc: (94.00%) (10990/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1644) | Acc: (94.00%) (12188/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1634) | Acc: (94.00%) (13399/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1617) | Acc: (94.00%) (14621/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1643) | Acc: (94.00%) (15811/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1645) | Acc: (94.00%) (17015/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1644) | Acc: (94.00%) (18233/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1641) | Acc: (94.00%) (19439/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1640) | Acc: (94.00%) (20652/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1629) | Acc: (94.00%) (21868/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1636) | Acc: (94.00%) (23071/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1623) | Acc: (94.00%) (24291/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1632) | Acc: (94.00%) (25494/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1617) | Acc: (94.00%) (26722/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1616) | Acc: (94.00%) (27934/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1623) | Acc: (94.00%) (29130/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1617) | Acc: (94.00%) (30352/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1613) | Acc: (94.00%) (31568/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1627) | Acc: (94.00%) (32759/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1619) | Acc: (94.00%) (33982/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1627) | Acc: (94.00%) (35179/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1624) | Acc: (94.00%) (36392/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1612) | Acc: (94.00%) (37623/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1623) | Acc: (94.00%) (38824/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1625) | Acc: (94.00%) (40024/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1619) | Acc: (94.00%) (41239/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1626) | Acc: (94.00%) (42436/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1625) | Acc: (94.00%) (43654/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1619) | Acc: (94.00%) (44875/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1626) | Acc: (94.00%) (46079/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1628) | Acc: (94.00%) (47245/50000)
# TEST : Loss: (0.2903) | Acc: (90.00%) (9036/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 3.4224e-41,  9.6802e-41,  2.3501e-41],
          [ 7.3291e-41, -8.8596e-41, -3.7975e-41],
          [-1.0213e-40, -1.0376e-40, -1.1166e-40]],

         [[ 8.8219e-41,  6.0837e-41,  3.7268e-41],
          [-1.4316e-41,  5.0047e-41,  7.3799e-41],
          [ 4.7868e-42,  1.1409e-40,  7.1669e-41]],

         [[ 8.8426e-41, -4.2199e-41,  5.3633e-41],
          [-6.2218e-41,  6.8598e-41, -1.6830e-42],
          [-8.5472e-41, -8.6824e-42,  2.9937e-41]]],


        [[[ 3.7199e-01,  2.0290e-02,  2.9424e-01],
          [ 1.6600e-01,  3.4805e-03, -1.9498e-01],
          [-2.0662e-01, -3.5924e-01, -2.8532e-01]],

         [[-5.2429e-02, -3.0074e-01, -3.9144e-02],
          [-9.6881e-02,  4.1649e-01, -2.1929e-01],
          [ 2.1819e-01,  1.4105e-01,  2.4629e-01]],

         [[-1.9176e-01, -2.6223e-01, -5.4609e-02],
          [-2.3853e-01,  1.6916e-01, -3.4586e-02],
          [ 3.6283e-02,  1.8078e-01,  2.6870e-01]]],


        [[[-2.1571e-32, -8.0270e-29, -3.0035e-21],
          [ 5.2707e-41, -5.9201e-37, -2.8265e-22],
          [-6.1705e-28, -3.7430e-26, -1.2220e-19]],

         [[ 5.5675e-24,  7.6583e-25,  5.7548e-24],
          [ 1.7025e-29,  8.1568e-30, -1.7857e-26],
          [-6.9587e-32, -2.1045e-37,  2.8658e-36]],

         [[ 1.0957e-19,  1.4538e-21,  3.7191e-24],
          [ 6.0459e-20,  7.1616e-21, -1.8285e-22],
          [ 2.0230e-20, -2.7165e-20, -3.5000e-21]]],


        ...,


        [[[-1.0300e-02,  2.3384e-02, -3.1021e-02],
          [-3.4445e-03,  6.1044e-02, -1.7788e-02],
          [-1.4469e-01,  2.1857e-02,  2.8525e-02]],

         [[-1.3335e-01, -1.2478e-01, -5.3467e-02],
          [ 6.2399e-02,  5.8022e-02, -1.1683e-01],
          [ 9.7373e-02,  3.2480e-02, -2.1859e-02]],

         [[ 5.7149e-03,  1.5531e-01,  8.9953e-02],
          [ 2.1329e-01,  4.0988e-01,  1.6596e-01],
          [ 1.4171e-01,  2.4888e-01,  6.8585e-02]]],


        [[[ 3.2410e-01,  3.9946e-02,  6.4680e-02],
          [ 1.2677e-01, -1.2752e-01, -1.0039e-01],
          [ 5.4897e-02,  7.8403e-02,  6.7303e-02]],

         [[ 1.6537e-02, -2.0933e-01, -4.6367e-02],
          [-5.2116e-02, -2.8600e-01, -2.3282e-01],
          [-4.5028e-03, -8.2770e-02, -5.5883e-02]],

         [[ 4.0591e-02, -1.9467e-01, -9.2870e-02],
          [-5.3936e-02, -1.1089e-01, -7.0753e-02],
          [-5.1033e-02,  2.8564e-02,  8.6216e-02]]],


        [[[ 8.0904e-02, -2.3980e-01,  7.4898e-02],
          [-1.8386e-01, -5.4215e-01, -1.9135e-01],
          [ 1.4404e-01,  8.2108e-04,  2.4440e-03]],

         [[ 1.5293e-01, -2.9518e-01,  2.3402e-02],
          [ 1.7904e-02, -2.8563e-01,  3.8099e-02],
          [ 1.6797e-01,  1.9601e-01,  3.3157e-02]],

         [[ 7.9062e-02, -2.2860e-01,  1.1370e-01],
          [ 1.0937e-01, -5.2411e-02,  1.1911e-01],
          [-6.0260e-02,  6.7721e-02,  1.0949e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2457]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0137]], device='cuda:0')

Epoch: 138 | Batch_idx: 0 |  Loss: (0.0838) | Acc: (96.00%) (124/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1679) | Acc: (93.00%) (1322/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1653) | Acc: (94.00%) (2531/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1597) | Acc: (94.00%) (3754/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1639) | Acc: (94.00%) (4955/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1621) | Acc: (94.00%) (6163/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1598) | Acc: (94.00%) (7384/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1598) | Acc: (94.00%) (8592/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1585) | Acc: (94.00%) (9803/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1567) | Acc: (94.00%) (11024/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1550) | Acc: (94.00%) (12248/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1557) | Acc: (94.00%) (13458/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1541) | Acc: (94.00%) (14683/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1532) | Acc: (94.00%) (15901/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1537) | Acc: (94.00%) (17104/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1540) | Acc: (94.00%) (18313/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1538) | Acc: (94.00%) (19531/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1552) | Acc: (94.00%) (20739/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1568) | Acc: (94.00%) (21944/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1577) | Acc: (94.00%) (23147/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1578) | Acc: (94.00%) (24357/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1584) | Acc: (94.00%) (25570/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1599) | Acc: (94.00%) (26760/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1610) | Acc: (94.00%) (27946/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1616) | Acc: (94.00%) (29156/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1623) | Acc: (94.00%) (30365/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1633) | Acc: (94.00%) (31568/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1638) | Acc: (94.00%) (32771/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1642) | Acc: (94.00%) (33981/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1645) | Acc: (94.00%) (35180/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1651) | Acc: (94.00%) (36384/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1649) | Acc: (94.00%) (37600/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1648) | Acc: (94.00%) (38813/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1645) | Acc: (94.00%) (40026/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1650) | Acc: (94.00%) (41225/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1655) | Acc: (94.00%) (42419/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1653) | Acc: (94.00%) (43634/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1652) | Acc: (94.00%) (44852/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1651) | Acc: (94.00%) (46062/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1656) | Acc: (94.00%) (47219/50000)
# TEST : Loss: (0.2846) | Acc: (90.00%) (9052/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-5.4519e-41, -4.7852e-41, -6.6155e-41],
          [ 6.7160e-41,  8.0659e-42,  1.3537e-41],
          [-8.3332e-41,  1.1022e-40, -2.3200e-41]],

         [[ 9.0636e-42,  4.2856e-41, -1.2208e-40],
          [-7.7164e-41,  1.0435e-40,  1.1195e-40],
          [-1.6130e-41, -1.3912e-41, -2.2869e-42]],

         [[ 5.2043e-41, -2.3909e-41, -3.7566e-41],
          [ 7.6651e-41,  1.2910e-40,  7.6529e-41],
          [ 1.0139e-40, -7.3980e-41, -1.0825e-40]]],


        [[[ 3.7136e-01,  2.0255e-02,  2.9374e-01],
          [ 1.6571e-01,  3.4745e-03, -1.9464e-01],
          [-2.0627e-01, -3.5863e-01, -2.8483e-01]],

         [[-5.2338e-02, -3.0022e-01, -3.9076e-02],
          [-9.6710e-02,  4.1575e-01, -2.1890e-01],
          [ 2.1780e-01,  1.4080e-01,  2.4585e-01]],

         [[-1.9141e-01, -2.6174e-01, -5.4507e-02],
          [-2.3809e-01,  1.6884e-01, -3.4521e-02],
          [ 3.6215e-02,  1.8045e-01,  2.6821e-01]]],


        [[[ 2.8833e-41, -8.2164e-38, -9.6210e-27],
          [ 2.5995e-41, -4.8624e-41, -2.4133e-28],
          [-3.9946e-37,  1.8227e-34, -1.3022e-24]],

         [[ 5.6139e-31,  1.5739e-32,  2.4409e-30],
          [ 1.4497e-38,  6.8697e-39,  1.0006e-34],
          [ 2.7882e-41,  1.9534e-42, -2.9544e-41]],

         [[ 1.6071e-24,  3.7426e-27,  5.7161e-31],
          [ 8.7998e-25,  5.7511e-26, -4.5783e-28],
          [ 7.1614e-25, -3.6050e-25, -1.2683e-26]]],


        ...,


        [[[-1.0184e-02,  2.3119e-02, -3.0679e-02],
          [-3.4031e-03,  6.0315e-02, -1.7581e-02],
          [-1.4301e-01,  2.1605e-02,  2.8206e-02]],

         [[-1.3145e-01, -1.2294e-01, -5.2730e-02],
          [ 6.1317e-02,  5.6990e-02, -1.1492e-01],
          [ 9.5786e-02,  3.1945e-02, -2.1529e-02]],

         [[ 5.6094e-03,  1.5212e-01,  8.8324e-02],
          [ 2.0580e-01,  3.8847e-01,  1.6107e-01],
          [ 1.3719e-01,  2.3867e-01,  6.6847e-02]]],


        [[[ 3.2122e-01,  3.9520e-02,  6.3987e-02],
          [ 1.2555e-01, -1.2598e-01, -9.9195e-02],
          [ 5.4402e-02,  7.7607e-02,  6.6643e-02]],

         [[ 1.6361e-02, -2.0614e-01, -4.5664e-02],
          [-5.1480e-02, -2.8005e-01, -2.2833e-01],
          [-4.4543e-03, -8.1639e-02, -5.5175e-02]],

         [[ 4.0058e-02, -1.9078e-01, -9.0991e-02],
          [-5.3094e-02, -1.0761e-01, -6.8866e-02],
          [-5.0368e-02,  2.8080e-02,  8.4880e-02]]],


        [[[ 8.0385e-02, -2.3738e-01,  7.4390e-02],
          [-1.8267e-01, -5.3636e-01, -1.8999e-01],
          [ 1.4337e-01,  8.1659e-04,  2.4319e-03]],

         [[ 1.5204e-01, -2.9287e-01,  2.3263e-02],
          [ 1.7801e-02, -2.8336e-01,  3.7868e-02],
          [ 1.6722e-01,  1.9502e-01,  3.3004e-02]],

         [[ 7.8603e-02, -2.2700e-01,  1.1304e-01],
          [ 1.0874e-01, -5.2046e-02,  1.1841e-01],
          [-5.9978e-02,  6.7373e-02,  1.0897e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2482]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0289]], device='cuda:0')

Epoch: 139 | Batch_idx: 0 |  Loss: (0.2000) | Acc: (93.00%) (120/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1747) | Acc: (94.00%) (1329/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1708) | Acc: (94.00%) (2540/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1756) | Acc: (94.00%) (3742/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1736) | Acc: (94.00%) (4960/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1677) | Acc: (94.00%) (6189/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1703) | Acc: (94.00%) (7389/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1688) | Acc: (94.00%) (8598/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1679) | Acc: (94.00%) (9803/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1666) | Acc: (94.00%) (11024/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1666) | Acc: (94.00%) (12231/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1657) | Acc: (94.00%) (13447/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1648) | Acc: (94.00%) (14665/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1635) | Acc: (94.00%) (15888/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1643) | Acc: (94.00%) (17101/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1654) | Acc: (94.00%) (18309/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1652) | Acc: (94.00%) (19518/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1661) | Acc: (94.00%) (20727/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1661) | Acc: (94.00%) (21938/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1662) | Acc: (94.00%) (23155/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1659) | Acc: (94.00%) (24365/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1647) | Acc: (94.00%) (25592/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1648) | Acc: (94.00%) (26802/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1651) | Acc: (94.00%) (28011/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1660) | Acc: (94.00%) (29212/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1662) | Acc: (94.00%) (30421/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1665) | Acc: (94.00%) (31624/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1664) | Acc: (94.00%) (32832/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1676) | Acc: (94.00%) (34028/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1679) | Acc: (94.00%) (35235/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1678) | Acc: (94.00%) (36450/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1681) | Acc: (94.00%) (37649/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1676) | Acc: (94.00%) (38863/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1685) | Acc: (94.00%) (40061/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1677) | Acc: (94.00%) (41277/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1677) | Acc: (94.00%) (42486/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1675) | Acc: (94.00%) (43709/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1682) | Acc: (94.00%) (44905/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1684) | Acc: (94.00%) (46122/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1687) | Acc: (94.00%) (47279/50000)
# TEST : Loss: (0.2864) | Acc: (90.00%) (9057/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 1.3162e-41, -1.0456e-40,  6.1831e-41],
          [-6.6996e-41, -1.0542e-40, -1.0254e-40],
          [ 1.2922e-40,  1.2514e-40, -5.8143e-41]],

         [[-2.4900e-41,  1.1520e-40,  1.8096e-41],
          [-3.1543e-42, -8.3027e-42,  9.7284e-41],
          [-1.9849e-41,  1.3930e-40, -7.4388e-41]],

         [[-3.4950e-41, -2.0927e-41, -2.0301e-41],
          [ 9.1580e-41, -5.0798e-41, -5.8948e-41],
          [ 5.5525e-41,  5.3588e-41,  4.3379e-41]]],


        [[[ 3.7061e-01,  2.0214e-02,  2.9313e-01],
          [ 1.6537e-01,  3.4672e-03, -1.9423e-01],
          [-2.0583e-01, -3.5789e-01, -2.8425e-01]],

         [[-5.2229e-02, -2.9958e-01, -3.8992e-02],
          [-9.6502e-02,  4.1484e-01, -2.1842e-01],
          [ 2.1733e-01,  1.4050e-01,  2.4533e-01]],

         [[-1.9098e-01, -2.6115e-01, -5.4384e-02],
          [-2.3754e-01,  1.6845e-01, -3.4442e-02],
          [ 3.6133e-02,  1.8004e-01,  2.6761e-01]]],


        [[[ 6.1307e-41,  4.5636e-41,  4.6686e-35],
          [ 2.6374e-41,  6.1335e-42, -1.8613e-37],
          [-2.4104e-41,  5.3183e-41, -3.2314e-32]],

         [[-2.6440e-40,  1.3060e-42,  2.4073e-39],
          [-1.8122e-41, -3.0834e-41,  3.2884e-41],
          [-1.8726e-41,  6.2080e-41, -6.7436e-41]],

         [[ 1.1572e-31, -1.3760e-35, -2.0439e-41],
          [ 6.1967e-32,  2.9836e-34,  1.6096e-36],
          [ 4.1237e-31, -1.9229e-32,  6.7865e-35]]],


        ...,


        [[[-1.0046e-02,  2.2800e-02, -3.0269e-02],
          [-3.3535e-03,  5.9439e-02, -1.7333e-02],
          [-1.4100e-01,  2.1303e-02,  2.7824e-02]],

         [[-1.2919e-01, -1.2074e-01, -5.1848e-02],
          [ 6.0027e-02,  5.5759e-02, -1.1264e-01],
          [ 9.3891e-02,  3.1306e-02, -2.1133e-02]],

         [[ 5.4838e-03,  1.4833e-01,  8.6383e-02],
          [ 1.9705e-01,  3.6395e-01,  1.5532e-01],
          [ 1.3188e-01,  2.2681e-01,  6.4792e-02]]],


        [[[ 3.1775e-01,  3.9008e-02,  6.3154e-02],
          [ 1.2408e-01, -1.2412e-01, -9.7759e-02],
          [ 5.3806e-02,  7.6649e-02,  6.5848e-02]],

         [[ 1.6150e-02, -2.0232e-01, -4.4823e-02],
          [-5.0717e-02, -2.7297e-01, -2.2299e-01],
          [-4.3961e-03, -8.0285e-02, -5.4326e-02]],

         [[ 3.9420e-02, -1.8615e-01, -8.8758e-02],
          [-5.2087e-02, -1.0376e-01, -6.6637e-02],
          [-4.9571e-02,  2.7503e-02,  8.3284e-02]]],


        [[[ 7.9759e-02, -2.3448e-01,  7.3778e-02],
          [-1.8124e-01, -5.2940e-01, -1.8836e-01],
          [ 1.4255e-01,  8.1117e-04,  2.4172e-03]],

         [[ 1.5098e-01, -2.9008e-01,  2.3096e-02],
          [ 1.7676e-02, -2.8062e-01,  3.7589e-02],
          [ 1.6631e-01,  1.9382e-01,  3.2818e-02]],

         [[ 7.8048e-02, -2.2507e-01,  1.1225e-01],
          [ 1.0799e-01, -5.1605e-02,  1.1758e-01],
          [-5.9637e-02,  6.6952e-02,  1.0834e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2385]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0535]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 140 | Batch_idx: 0 |  Loss: (0.1851) | Acc: (93.00%) (120/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.2187) | Acc: (92.00%) (1305/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.2959) | Acc: (90.00%) (2434/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.3191) | Acc: (89.00%) (3562/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.3375) | Acc: (88.00%) (4664/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.3505) | Acc: (88.00%) (5766/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.3572) | Acc: (88.00%) (6878/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.3656) | Acc: (87.00%) (7980/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.3729) | Acc: (87.00%) (9081/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.3797) | Acc: (87.00%) (10183/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.3821) | Acc: (87.00%) (11282/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.3821) | Acc: (87.00%) (12401/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.3789) | Acc: (87.00%) (13529/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.3744) | Acc: (87.00%) (14669/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.3726) | Acc: (87.00%) (15804/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.3686) | Acc: (87.00%) (16946/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.3661) | Acc: (87.00%) (18085/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.3629) | Acc: (87.00%) (19227/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.3608) | Acc: (87.00%) (20359/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.3594) | Acc: (87.00%) (21493/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.3563) | Acc: (88.00%) (22652/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.3522) | Acc: (88.00%) (23818/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.3500) | Acc: (88.00%) (24961/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.3479) | Acc: (88.00%) (26115/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.3460) | Acc: (88.00%) (27258/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.3441) | Acc: (88.00%) (28414/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.3420) | Acc: (88.00%) (29576/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.3382) | Acc: (88.00%) (30750/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.3366) | Acc: (88.00%) (31905/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.3352) | Acc: (88.00%) (33049/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.3357) | Acc: (88.00%) (34179/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.3339) | Acc: (88.00%) (35331/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.3327) | Acc: (88.00%) (36486/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.3322) | Acc: (88.00%) (37627/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.3313) | Acc: (88.00%) (38779/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.3302) | Acc: (88.00%) (39921/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.3295) | Acc: (88.00%) (41069/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.3294) | Acc: (88.00%) (42210/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.3289) | Acc: (88.00%) (43362/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.3270) | Acc: (88.00%) (44483/50000)
# TEST : Loss: (0.5028) | Acc: (84.00%) (8497/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4910e-40, -6.9165e-41, -1.1734e-40],
          [-4.0933e-41, -9.0169e-41, -6.5162e-41],
          [-4.5403e-41, -8.5031e-41,  1.0157e-40]],

         [[ 7.7661e-41,  1.5884e-40, -6.6597e-41],
          [-3.6602e-42, -7.4901e-41, -9.0202e-41],
          [ 7.3931e-41, -6.2504e-41,  3.9072e-41]],

         [[ 8.5116e-41, -3.4926e-41,  6.3169e-41],
          [ 3.4175e-41,  3.0843e-41, -7.0970e-41],
          [-3.5245e-41,  4.0360e-41, -1.6995e-41]]],


        [[[ 3.7529e-01,  3.0324e-02,  3.0027e-01],
          [ 1.6933e-01,  9.5613e-03, -1.9420e-01],
          [-2.0318e-01, -3.6881e-01, -2.6925e-01]],

         [[-5.4126e-02, -2.9579e-01, -3.6875e-02],
          [-9.8643e-02,  4.2487e-01, -2.1752e-01],
          [ 2.1613e-01,  1.3411e-01,  2.6516e-01]],

         [[-1.9162e-01, -2.5826e-01, -5.4119e-02],
          [-2.4366e-01,  1.7046e-01, -3.6612e-02],
          [ 2.7214e-02,  1.6611e-01,  2.8013e-01]]],


        [[[-6.4472e-41,  3.8756e-41,  3.3314e-41],
          [ 2.3727e-41, -6.9831e-41,  4.5612e-42],
          [ 3.0554e-41,  6.8062e-41,  2.5099e-41]],

         [[ 4.7644e-43, -2.4488e-41, -3.0764e-41],
          [ 6.0937e-41,  5.6432e-41,  3.7408e-41],
          [ 5.9582e-41,  8.7749e-42,  1.2722e-41]],

         [[-7.2269e-41, -3.0304e-41,  2.3814e-41],
          [-3.4814e-41,  6.3752e-41,  1.4372e-41],
          [ 4.3429e-40,  3.8590e-41,  3.6732e-41]]],


        ...,


        [[[-1.4369e-02,  2.2395e-02, -3.5017e-02],
          [ 1.4737e-03,  7.2898e-02, -8.7928e-03],
          [-1.4110e-01,  2.7851e-02,  3.0557e-02]],

         [[-1.1875e-01, -1.0791e-01, -4.7542e-02],
          [ 9.0491e-02,  9.9791e-02, -8.3654e-02],
          [ 1.0726e-01,  5.6585e-02, -7.2631e-03]],

         [[ 4.2234e-03,  1.5720e-01,  9.0559e-02],
          [ 2.2455e-01,  4.4526e-01,  1.8421e-01],
          [ 1.2998e-01,  2.4748e-01,  5.2532e-02]]],


        [[[ 3.0415e-01,  1.1802e-02,  5.6089e-02],
          [ 1.1110e-01, -1.3661e-01, -1.0445e-01],
          [ 4.5405e-02,  7.8141e-02,  7.4094e-02]],

         [[-1.4439e-02, -2.4917e-01, -5.6493e-02],
          [-7.6620e-02, -2.8803e-01, -2.1756e-01],
          [-2.0510e-02, -7.5600e-02, -3.6233e-02]],

         [[ 1.4953e-02, -2.3107e-01, -9.5934e-02],
          [-6.6453e-02, -9.7047e-02, -3.9840e-02],
          [-6.1649e-02,  3.6409e-02,  1.0349e-01]]],


        [[[ 8.9664e-02, -2.1938e-01,  1.2249e-01],
          [-1.9105e-01, -5.6862e-01, -1.7640e-01],
          [ 1.4072e-01, -1.0899e-02,  1.2286e-02]],

         [[ 1.5925e-01, -2.8237e-01,  5.2311e-02],
          [ 1.2625e-02, -3.0429e-01,  3.9899e-02],
          [ 1.5987e-01,  1.7862e-01,  3.0835e-02]],

         [[ 6.9489e-02, -2.3153e-01,  1.2287e-01],
          [ 9.1258e-02, -7.6712e-02,  1.1393e-01],
          [-7.8548e-02,  4.3292e-02,  9.6876e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0051,  0.0063,  0.0196],
          [ 0.0069,  0.0134,  0.0139],
          [ 0.0374,  0.0369,  0.0440]],

         [[ 0.0173,  0.0158,  0.0215],
          [ 0.0126,  0.0163,  0.0112],
          [ 0.0319,  0.0306,  0.0323]],

         [[ 0.0043,  0.0058,  0.0126],
          [-0.0000,  0.0057,  0.0054],
          [ 0.0173,  0.0203,  0.0296]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0038, -0.0064, -0.0063],
          [-0.0038, -0.0052, -0.0043],
          [-0.0028, -0.0028, -0.0017]],

         [[-0.0016, -0.0039, -0.0035],
          [-0.0019, -0.0027, -0.0014],
          [-0.0010, -0.0004,  0.0011]],

         [[ 0.0003, -0.0022, -0.0023],
          [-0.0003, -0.0009,  0.0002],
          [ 0.0004,  0.0016,  0.0032]]],


        [[[ 0.0071,  0.0035,  0.0025],
          [ 0.0034,  0.0002, -0.0007],
          [ 0.0025,  0.0004,  0.0014]],

         [[ 0.0046,  0.0024,  0.0030],
          [ 0.0021,  0.0005,  0.0004],
          [ 0.0018,  0.0005,  0.0012]],

         [[ 0.0054,  0.0038,  0.0053],
          [ 0.0027,  0.0018,  0.0026],
          [ 0.0013,  0.0007,  0.0013]]],


        [[[-0.0167, -0.0136, -0.0175],
          [-0.0127, -0.0142, -0.0236],
          [-0.0224, -0.0251, -0.0325]],

         [[-0.0249, -0.0192, -0.0195],
          [-0.0211, -0.0194, -0.0247],
          [-0.0287, -0.0290, -0.0338]],

         [[-0.0203, -0.0144, -0.0152],
          [-0.0200, -0.0178, -0.0223],
          [-0.0308, -0.0303, -0.0348]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2366]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 141 | Batch_idx: 0 |  Loss: (0.2126) | Acc: (90.00%) (116/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.2290) | Acc: (90.00%) (1279/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.2321) | Acc: (91.00%) (2469/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.2361) | Acc: (91.00%) (3641/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.2400) | Acc: (91.00%) (4805/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.2365) | Acc: (91.00%) (5996/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.2368) | Acc: (91.00%) (7173/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.2386) | Acc: (91.00%) (8335/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.2411) | Acc: (91.00%) (9510/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.2410) | Acc: (91.00%) (10686/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.2399) | Acc: (91.00%) (11859/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.2440) | Acc: (91.00%) (13017/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.2444) | Acc: (91.00%) (14192/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.2424) | Acc: (91.00%) (15377/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.2422) | Acc: (91.00%) (16556/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.2407) | Acc: (91.00%) (17737/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.2439) | Acc: (91.00%) (18886/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.2425) | Acc: (91.00%) (20074/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.2429) | Acc: (91.00%) (21242/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.2429) | Acc: (91.00%) (22423/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.2435) | Acc: (91.00%) (23588/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.2430) | Acc: (91.00%) (24775/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.2429) | Acc: (91.00%) (25955/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.2434) | Acc: (91.00%) (27123/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.2435) | Acc: (91.00%) (28301/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.2447) | Acc: (91.00%) (29455/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.2444) | Acc: (91.00%) (30633/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.2457) | Acc: (91.00%) (31775/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.2455) | Acc: (91.00%) (32955/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.2453) | Acc: (91.00%) (34126/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.2446) | Acc: (91.00%) (35297/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.2441) | Acc: (91.00%) (36478/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.2447) | Acc: (91.00%) (37646/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.2438) | Acc: (91.00%) (38825/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.2440) | Acc: (91.00%) (39999/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.2444) | Acc: (91.00%) (41159/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.2447) | Acc: (91.00%) (42332/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.2435) | Acc: (91.00%) (43516/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.2438) | Acc: (91.00%) (44681/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.2433) | Acc: (91.00%) (45817/50000)
# TEST : Loss: (0.3629) | Acc: (88.00%) (8866/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-4.0045e-41, -2.8631e-41, -3.2067e-41],
          [-8.4648e-41,  1.1456e-40,  5.6680e-41],
          [ 1.4197e-41,  7.6484e-41,  1.2156e-40]],

         [[ 4.1460e-41,  7.2528e-41,  1.0396e-40],
          [ 8.6068e-41, -1.3757e-41, -1.7296e-40],
          [ 1.1478e-40, -7.4024e-41,  7.2397e-41]],

         [[ 6.6525e-41, -4.1670e-41,  7.3764e-42],
          [ 1.0610e-40, -1.3633e-40, -3.0348e-41],
          [-1.0965e-40,  4.9386e-41, -2.0736e-41]]],


        [[[ 3.7836e-01,  2.8238e-02,  2.9091e-01],
          [ 1.6204e-01,  1.4021e-03, -2.0686e-01],
          [-2.0714e-01, -3.8164e-01, -2.9638e-01]],

         [[-5.2199e-02, -3.0084e-01, -4.9014e-02],
          [-1.0050e-01,  4.2407e-01, -2.2695e-01],
          [ 2.1502e-01,  1.3039e-01,  2.4605e-01]],

         [[-1.8324e-01, -2.5660e-01, -5.7209e-02],
          [-2.3953e-01,  1.7710e-01, -3.5968e-02],
          [ 3.4903e-02,  1.7190e-01,  2.6876e-01]]],


        [[[-6.9615e-41,  6.0578e-41,  5.2595e-41],
          [ 6.2554e-42,  6.2316e-41,  6.5152e-41],
          [-3.6050e-41, -3.7689e-41,  5.4967e-41]],

         [[-3.7164e-41,  3.7824e-41,  5.0618e-41],
          [ 1.8783e-41,  1.3033e-41, -6.2359e-41],
          [ 7.0684e-41,  2.0025e-42, -5.1934e-41]],

         [[-3.0836e-41, -4.2768e-42,  4.0991e-41],
          [-6.6403e-41,  5.1414e-41, -9.8932e-42],
          [-3.4095e-41,  6.7140e-41,  5.1806e-41]]],


        ...,


        [[[-2.8521e-02,  9.3305e-03, -5.9480e-02],
          [-8.0342e-03,  6.0685e-02, -3.2091e-02],
          [-1.4740e-01,  1.8902e-02,  8.4817e-03]],

         [[-1.2834e-01, -1.1806e-01, -7.1007e-02],
          [ 9.3928e-02,  9.7114e-02, -1.0266e-01],
          [ 1.1745e-01,  6.0991e-02, -2.5448e-02]],

         [[-5.8888e-03,  1.4401e-01,  6.3196e-02],
          [ 2.3336e-01,  4.3237e-01,  1.5095e-01],
          [ 1.4747e-01,  2.5444e-01,  2.3455e-02]]],


        [[[ 3.0362e-01,  1.8341e-02,  7.0415e-02],
          [ 1.1034e-01, -1.3681e-01, -9.6138e-02],
          [ 5.3072e-02,  8.3238e-02,  8.5149e-02]],

         [[-1.7072e-02, -2.3186e-01, -2.6923e-02],
          [-8.5334e-02, -2.8965e-01, -2.0627e-01],
          [-2.1958e-02, -7.6464e-02, -3.2423e-02]],

         [[-1.3373e-02, -2.4160e-01, -8.9959e-02],
          [-9.6184e-02, -1.2053e-01, -5.7178e-02],
          [-7.8204e-02,  2.2100e-02,  8.8280e-02]]],


        [[[ 9.7485e-02, -2.1567e-01,  1.2112e-01],
          [-1.8697e-01, -5.7413e-01, -1.8254e-01],
          [ 1.5157e-01, -5.8180e-03,  2.3753e-02]],

         [[ 1.6456e-01, -2.8081e-01,  4.5931e-02],
          [ 1.7239e-02, -3.0513e-01,  3.3875e-02],
          [ 1.6855e-01,  1.8335e-01,  3.9954e-02]],

         [[ 7.1274e-02, -2.3329e-01,  1.1156e-01],
          [ 9.3639e-02, -8.0018e-02,  1.0133e-01],
          [-7.0852e-02,  4.5557e-02,  9.8678e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.1875,  0.1447,  0.1298],
          [ 0.1518,  0.1224,  0.1358],
          [ 0.0899,  0.0733,  0.0822]],

         [[ 0.1402,  0.1012,  0.0930],
          [ 0.1031,  0.0763,  0.0959],
          [ 0.0582,  0.0500,  0.0521]],

         [[ 0.0637,  0.0306,  0.0228],
          [ 0.0306,  0.0150,  0.0320],
          [-0.0036, -0.0089, -0.0040]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0065, -0.0023,  0.0050],
          [ 0.0007,  0.0070,  0.0098],
          [ 0.0074,  0.0086,  0.0083]],

         [[-0.0106, -0.0059,  0.0017],
          [-0.0028,  0.0042,  0.0068],
          [ 0.0041,  0.0052,  0.0043]],

         [[-0.0132, -0.0092, -0.0029],
          [-0.0052,  0.0006,  0.0026],
          [ 0.0016,  0.0021,  0.0004]]],


        [[[-0.0194, -0.0083, -0.0140],
          [-0.0156, -0.0064, -0.0131],
          [-0.0078, -0.0029, -0.0092]],

         [[-0.0094, -0.0007, -0.0097],
          [-0.0083, -0.0022, -0.0131],
          [-0.0045, -0.0016, -0.0112]],

         [[-0.0055, -0.0006, -0.0114],
          [-0.0082, -0.0037, -0.0130],
          [-0.0080, -0.0043, -0.0111]]],


        [[[-0.0265, -0.0073, -0.0005],
          [-0.0096,  0.0005, -0.0090],
          [ 0.0164,  0.0197, -0.0011]],

         [[-0.0258, -0.0115, -0.0151],
          [-0.0156, -0.0126, -0.0317],
          [ 0.0053,  0.0015, -0.0255]],

         [[-0.0205, -0.0104, -0.0124],
          [-0.0168, -0.0128, -0.0273],
          [ 0.0014,  0.0039, -0.0185]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2362]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 142 | Batch_idx: 0 |  Loss: (0.1131) | Acc: (96.00%) (123/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.2019) | Acc: (92.00%) (1304/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.2070) | Acc: (92.00%) (2485/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.2046) | Acc: (92.00%) (3678/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.2059) | Acc: (93.00%) (4883/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.2095) | Acc: (92.00%) (6065/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.2092) | Acc: (92.00%) (7252/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.2084) | Acc: (92.00%) (8435/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.2086) | Acc: (92.00%) (9628/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.2117) | Acc: (92.00%) (10800/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.2092) | Acc: (92.00%) (11995/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.2098) | Acc: (92.00%) (13187/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.2097) | Acc: (92.00%) (14368/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.2087) | Acc: (92.00%) (15560/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.2087) | Acc: (92.00%) (16747/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.2093) | Acc: (92.00%) (17937/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.2086) | Acc: (92.00%) (19130/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.2087) | Acc: (92.00%) (20325/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.2092) | Acc: (92.00%) (21507/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.2091) | Acc: (92.00%) (22698/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.2089) | Acc: (92.00%) (23888/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.2076) | Acc: (92.00%) (25086/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.2088) | Acc: (92.00%) (26254/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.2102) | Acc: (92.00%) (27438/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.2108) | Acc: (92.00%) (28623/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.2110) | Acc: (92.00%) (29802/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.2126) | Acc: (92.00%) (30978/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.2141) | Acc: (92.00%) (32143/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.2135) | Acc: (92.00%) (33344/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.2145) | Acc: (92.00%) (34514/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.2148) | Acc: (92.00%) (35685/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.2151) | Acc: (92.00%) (36860/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.2151) | Acc: (92.00%) (38054/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.2145) | Acc: (92.00%) (39261/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.2142) | Acc: (92.00%) (40451/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.2143) | Acc: (92.00%) (41622/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.2148) | Acc: (92.00%) (42796/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.2156) | Acc: (92.00%) (43969/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.2162) | Acc: (92.00%) (45147/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.2163) | Acc: (92.00%) (46290/50000)
# TEST : Loss: (0.3363) | Acc: (89.00%) (8958/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 1.8509e-40, -3.4216e-41, -1.2105e-40],
          [-2.1678e-42, -1.4149e-40, -1.3537e-40],
          [ 1.3999e-40, -5.8377e-41, -9.9799e-41]],

         [[ 8.0045e-41, -3.6177e-41,  4.6251e-41],
          [-8.1724e-41,  1.2433e-40,  1.2017e-40],
          [-8.0629e-41,  3.0142e-41,  2.5488e-41]],

         [[-5.9182e-41,  7.6526e-41, -1.1909e-40],
          [-9.1747e-41,  2.0114e-40,  5.9897e-41],
          [ 9.4987e-41,  5.8019e-41,  2.4915e-41]]],


        [[[ 3.9140e-01,  3.3927e-02,  2.9200e-01],
          [ 1.7934e-01,  2.9818e-03, -2.1008e-01],
          [-1.9108e-01, -3.7278e-01, -2.8945e-01]],

         [[-4.9398e-02, -3.0497e-01, -5.4482e-02],
          [-9.3560e-02,  4.1995e-01, -2.3446e-01],
          [ 2.2154e-01,  1.3505e-01,  2.4902e-01]],

         [[-1.8466e-01, -2.6384e-01, -6.4532e-02],
          [-2.3854e-01,  1.7001e-01, -4.4507e-02],
          [ 3.1683e-02,  1.6886e-01,  2.6885e-01]]],


        [[[-3.2608e-42, -5.1394e-41, -6.0047e-41],
          [ 5.7216e-41,  4.7388e-41,  6.3451e-42],
          [ 5.5650e-41,  2.6587e-41, -6.7446e-41]],

         [[-4.8538e-41, -2.4181e-41,  6.2736e-42],
          [-3.3562e-41, -3.2726e-41, -2.4517e-41],
          [-3.0199e-41, -5.8450e-41, -2.1525e-41]],

         [[ 2.6765e-42, -3.6739e-41,  4.9124e-41],
          [ 4.3409e-41, -4.7923e-41,  5.5972e-41],
          [ 3.5275e-41, -4.3943e-41, -6.0364e-41]]],


        ...,


        [[[-1.3954e-02,  1.8494e-02, -5.7293e-02],
          [ 3.6203e-03,  6.0556e-02, -3.7523e-02],
          [-1.3710e-01,  2.3316e-02,  8.1319e-03]],

         [[-1.1547e-01, -1.0887e-01, -6.7218e-02],
          [ 1.0948e-01,  9.7814e-02, -1.0438e-01],
          [ 1.3484e-01,  7.3677e-02, -1.7382e-02]],

         [[ 1.9896e-03,  1.4945e-01,  6.2636e-02],
          [ 2.5159e-01,  4.1572e-01,  1.3992e-01],
          [ 1.7893e-01,  2.7722e-01,  3.1584e-02]]],


        [[[ 3.0173e-01,  1.9093e-02,  7.1503e-02],
          [ 1.1366e-01, -1.2937e-01, -8.8871e-02],
          [ 5.9525e-02,  9.7261e-02,  9.8366e-02]],

         [[-1.9234e-02, -2.2643e-01, -2.5728e-02],
          [-8.5501e-02, -2.7816e-01, -1.9289e-01],
          [-2.0842e-02, -6.3921e-02, -1.6205e-02]],

         [[-2.4062e-02, -2.5674e-01, -1.0790e-01],
          [-1.1071e-01, -1.4011e-01, -6.9209e-02],
          [-8.6446e-02,  1.7663e-02,  8.4892e-02]]],


        [[[ 8.2183e-02, -2.3205e-01,  1.1144e-01],
          [-2.0161e-01, -5.8053e-01, -1.8751e-01],
          [ 1.4527e-01, -6.3082e-03,  1.8121e-02]],

         [[ 1.6919e-01, -2.6946e-01,  5.5505e-02],
          [ 2.1431e-02, -2.8691e-01,  4.7549e-02],
          [ 1.7378e-01,  1.9490e-01,  4.6470e-02]],

         [[ 7.7671e-02, -2.2174e-01,  1.2147e-01],
          [ 9.7363e-02, -6.4477e-02,  1.1456e-01],
          [-6.5117e-02,  5.6694e-02,  1.0257e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.1374, -0.1874, -0.1965],
          [-0.1304, -0.1839, -0.1740],
          [-0.1635, -0.1885, -0.1583]],

         [[-0.0961, -0.1349, -0.1540],
          [-0.1007, -0.1388, -0.1420],
          [-0.1386, -0.1500, -0.1249]],

         [[-0.0765, -0.1064, -0.1298],
          [-0.0900, -0.1184, -0.1205],
          [-0.1269, -0.1331, -0.1159]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0025,  0.0069,  0.0067],
          [-0.0017,  0.0072,  0.0079],
          [-0.0057, -0.0007, -0.0019]],

         [[-0.0022,  0.0075,  0.0069],
          [-0.0014,  0.0068,  0.0068],
          [-0.0043, -0.0002, -0.0024]],

         [[-0.0047,  0.0042,  0.0036],
          [-0.0033,  0.0043,  0.0043],
          [-0.0052, -0.0009, -0.0026]]],


        [[[-0.0096, -0.0136, -0.0111],
          [-0.0029, -0.0051, -0.0050],
          [-0.0053, -0.0104, -0.0086]],

         [[-0.0038, -0.0093, -0.0076],
          [ 0.0016, -0.0016, -0.0008],
          [-0.0026, -0.0073, -0.0048]],

         [[-0.0016, -0.0065, -0.0049],
          [ 0.0014, -0.0011, -0.0008],
          [-0.0027, -0.0073, -0.0059]]],


        [[[-0.0031, -0.0135, -0.0282],
          [ 0.0112,  0.0016, -0.0116],
          [ 0.0066, -0.0078, -0.0120]],

         [[-0.0046, -0.0200, -0.0349],
          [ 0.0103, -0.0044, -0.0173],
          [ 0.0037, -0.0109, -0.0144]],

         [[ 0.0070, -0.0081, -0.0206],
          [ 0.0184,  0.0028, -0.0086],
          [ 0.0168,  0.0009, -0.0020]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2356]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 143 | Batch_idx: 0 |  Loss: (0.0816) | Acc: (98.00%) (126/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1809) | Acc: (93.00%) (1321/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1959) | Acc: (93.00%) (2509/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1959) | Acc: (93.00%) (3720/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1943) | Acc: (93.00%) (4920/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1902) | Acc: (93.00%) (6127/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1903) | Acc: (93.00%) (7333/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1932) | Acc: (93.00%) (8520/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1921) | Acc: (93.00%) (9718/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1922) | Acc: (93.00%) (10916/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1932) | Acc: (93.00%) (12104/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1944) | Acc: (93.00%) (13301/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1965) | Acc: (93.00%) (14490/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1967) | Acc: (93.00%) (15683/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1967) | Acc: (93.00%) (16871/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1969) | Acc: (93.00%) (18065/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1961) | Acc: (93.00%) (19255/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1962) | Acc: (93.00%) (20440/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1971) | Acc: (93.00%) (21630/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1981) | Acc: (93.00%) (22824/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1991) | Acc: (93.00%) (24011/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1980) | Acc: (93.00%) (25220/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1978) | Acc: (93.00%) (26410/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1973) | Acc: (93.00%) (27607/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1966) | Acc: (93.00%) (28811/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1984) | Acc: (93.00%) (29979/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1987) | Acc: (93.00%) (31174/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1997) | Acc: (93.00%) (32359/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1996) | Acc: (93.00%) (33557/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1996) | Acc: (93.00%) (34750/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.2000) | Acc: (93.00%) (35929/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.2002) | Acc: (93.00%) (37120/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.2016) | Acc: (93.00%) (38292/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.2015) | Acc: (93.00%) (39481/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.2020) | Acc: (93.00%) (40658/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.2022) | Acc: (93.00%) (41853/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.2031) | Acc: (93.00%) (43022/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.2025) | Acc: (93.00%) (44225/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.2029) | Acc: (93.00%) (45409/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.2027) | Acc: (93.00%) (46550/50000)
# TEST : Loss: (0.3269) | Acc: (89.00%) (8969/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 2.1930e-40,  3.5506e-41,  1.0616e-40],
          [-7.0522e-41,  9.8857e-41, -1.3485e-41],
          [-2.9605e-41, -1.0139e-40, -2.7170e-41]],

         [[-1.0612e-40, -2.0916e-40, -1.6761e-40],
          [ 2.9672e-41, -1.6360e-41,  6.9181e-41],
          [-9.6587e-41, -1.0573e-40, -7.3232e-42]],

         [[ 1.1093e-40, -4.2613e-41,  5.7163e-41],
          [-1.0957e-40, -1.5738e-40,  7.1070e-41],
          [ 1.1331e-40,  3.0183e-41, -8.7116e-41]]],


        [[[ 3.8599e-01,  2.7444e-02,  2.8678e-01],
          [ 1.7308e-01, -5.9575e-03, -2.1852e-01],
          [-1.9959e-01, -3.7817e-01, -2.9259e-01]],

         [[-4.2849e-02, -3.0067e-01, -4.7677e-02],
          [-8.9543e-02,  4.2382e-01, -2.2881e-01],
          [ 2.2250e-01,  1.4199e-01,  2.5941e-01]],

         [[-1.7852e-01, -2.6121e-01, -5.8436e-02],
          [-2.3842e-01,  1.6922e-01, -4.2829e-02],
          [ 3.3096e-02,  1.7663e-01,  2.8023e-01]]],


        [[[ 1.7160e-41, -2.3972e-41,  1.8926e-41],
          [ 4.3126e-41,  4.0603e-41,  1.4581e-41],
          [-2.7970e-42,  5.5169e-41, -6.0416e-41]],

         [[-2.2000e-42, -4.5408e-41, -1.7044e-41],
          [-2.0750e-41, -2.9509e-41, -5.1998e-41],
          [ 5.1938e-41, -7.3603e-41, -4.3105e-41]],

         [[-3.1950e-43, -2.9195e-41,  3.5838e-41],
          [ 4.2556e-41, -6.9076e-41,  6.3339e-43],
          [-1.8573e-41, -4.9980e-41,  1.8039e-41]]],


        ...,


        [[[-1.5216e-03,  3.1885e-02, -3.1189e-02],
          [ 1.7026e-02,  7.6169e-02, -1.4603e-02],
          [-1.2527e-01,  3.7851e-02,  2.6525e-02]],

         [[-1.1368e-01, -1.0623e-01, -4.9266e-02],
          [ 1.0752e-01,  9.9767e-02, -9.1060e-02],
          [ 1.2791e-01,  7.3170e-02, -1.0755e-02]],

         [[ 8.6040e-03,  1.5650e-01,  8.5106e-02],
          [ 2.5622e-01,  4.3028e-01,  1.6617e-01],
          [ 1.6538e-01,  2.7928e-01,  4.3456e-02]]],


        [[[ 3.0880e-01,  2.1083e-02,  7.4542e-02],
          [ 1.1975e-01, -1.3295e-01, -9.1842e-02],
          [ 7.0481e-02,  1.0652e-01,  1.0449e-01]],

         [[-2.3063e-03, -2.1333e-01, -2.1041e-02],
          [-7.4497e-02, -2.7816e-01, -2.0320e-01],
          [-7.4794e-03, -5.2108e-02, -1.7062e-02]],

         [[-8.6693e-03, -2.4613e-01, -1.0520e-01],
          [-9.9529e-02, -1.4525e-01, -8.5990e-02],
          [-7.6966e-02,  2.3095e-02,  7.6922e-02]]],


        [[[ 7.8323e-02, -2.4424e-01,  9.4746e-02],
          [-2.0148e-01, -5.9186e-01, -2.0568e-01],
          [ 1.4353e-01, -1.1609e-02,  8.2780e-03]],

         [[ 1.6072e-01, -2.8153e-01,  4.3409e-02],
          [ 1.6648e-02, -2.9900e-01,  3.1198e-02],
          [ 1.6860e-01,  1.8792e-01,  3.5700e-02]],

         [[ 7.4210e-02, -2.2559e-01,  1.1787e-01],
          [ 9.6289e-02, -6.7446e-02,  1.0595e-01],
          [-6.4240e-02,  5.8816e-02,  9.7431e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0202, -0.0231, -0.0139],
          [-0.0154, -0.0203, -0.0174],
          [-0.0125, -0.0083,  0.0067]],

         [[-0.0096, -0.0128, -0.0029],
          [-0.0116, -0.0123, -0.0070],
          [-0.0125, -0.0016,  0.0189]],

         [[-0.0078, -0.0160, -0.0086],
          [-0.0068, -0.0176, -0.0214],
          [-0.0015, -0.0088, -0.0010]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0034, -0.0027, -0.0024],
          [-0.0023, -0.0027, -0.0028],
          [-0.0031, -0.0038, -0.0037]],

         [[-0.0031, -0.0018, -0.0007],
          [-0.0019, -0.0019, -0.0014],
          [-0.0023, -0.0028, -0.0020]],

         [[-0.0002,  0.0006,  0.0003],
          [ 0.0005,  0.0002, -0.0007],
          [ 0.0005, -0.0001, -0.0011]]],


        [[[-0.0027, -0.0006, -0.0007],
          [-0.0045, -0.0009, -0.0010],
          [-0.0046, -0.0001, -0.0006]],

         [[-0.0025, -0.0003, -0.0003],
          [-0.0035,  0.0000, -0.0004],
          [-0.0034,  0.0009, -0.0001]],

         [[-0.0034, -0.0021, -0.0024],
          [-0.0023, -0.0003, -0.0012],
          [-0.0029, -0.0003, -0.0019]]],


        [[[-0.0069, -0.0047, -0.0013],
          [-0.0013,  0.0014,  0.0011],
          [-0.0001,  0.0076,  0.0062]],

         [[-0.0126, -0.0097, -0.0045],
          [-0.0083, -0.0048, -0.0038],
          [-0.0070,  0.0002, -0.0013]],

         [[-0.0188, -0.0163, -0.0095],
          [-0.0127, -0.0104, -0.0077],
          [-0.0106, -0.0039, -0.0042]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2349]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 144 | Batch_idx: 0 |  Loss: (0.1875) | Acc: (94.00%) (121/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.2044) | Acc: (92.00%) (1301/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1915) | Acc: (93.00%) (2507/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1836) | Acc: (93.00%) (3715/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1815) | Acc: (93.00%) (4904/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1824) | Acc: (93.00%) (6100/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1807) | Acc: (93.00%) (7316/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1829) | Acc: (93.00%) (8505/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1834) | Acc: (93.00%) (9709/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1835) | Acc: (93.00%) (10912/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1853) | Acc: (93.00%) (12097/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1844) | Acc: (93.00%) (13299/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1835) | Acc: (93.00%) (14501/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1855) | Acc: (93.00%) (15689/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1858) | Acc: (93.00%) (16888/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1850) | Acc: (93.00%) (18097/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1837) | Acc: (93.00%) (19301/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1843) | Acc: (93.00%) (20487/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1843) | Acc: (93.00%) (21687/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1832) | Acc: (93.00%) (22897/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1826) | Acc: (93.00%) (24103/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1834) | Acc: (93.00%) (25290/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1836) | Acc: (93.00%) (26488/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1843) | Acc: (93.00%) (27680/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1836) | Acc: (93.00%) (28885/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1835) | Acc: (93.00%) (30081/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1836) | Acc: (93.00%) (31270/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1849) | Acc: (93.00%) (32439/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1866) | Acc: (93.00%) (33626/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1862) | Acc: (93.00%) (34827/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1864) | Acc: (93.00%) (36021/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1866) | Acc: (93.00%) (37212/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1870) | Acc: (93.00%) (38403/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1869) | Acc: (93.00%) (39607/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1873) | Acc: (93.00%) (40799/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1884) | Acc: (93.00%) (41985/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1884) | Acc: (93.00%) (43180/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1887) | Acc: (93.00%) (44385/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1886) | Acc: (93.00%) (45593/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1882) | Acc: (93.00%) (46751/50000)
# TEST : Loss: (0.3308) | Acc: (89.00%) (8990/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 2.8874e-41,  8.7449e-41, -1.8868e-40],
          [-1.0288e-40, -8.8737e-41, -7.4940e-41],
          [ 8.1071e-41, -2.9904e-41,  7.7678e-41]],

         [[-1.0288e-40, -1.3748e-40, -8.9899e-41],
          [-6.8229e-42, -2.1028e-41, -4.7128e-41],
          [ 1.8328e-41,  1.8911e-40,  3.5515e-41]],

         [[ 3.3429e-41, -7.0356e-41,  1.2796e-40],
          [ 6.9034e-41,  2.3684e-40,  3.9847e-41],
          [-4.5514e-42,  8.2360e-41,  1.4982e-40]]],


        [[[ 3.8551e-01,  3.8549e-02,  3.0462e-01],
          [ 1.7142e-01, -2.0168e-03, -2.1544e-01],
          [-1.9928e-01, -3.7295e-01, -2.8714e-01]],

         [[-5.6222e-02, -3.0450e-01, -4.6011e-02],
          [-9.9287e-02,  4.1973e-01, -2.3663e-01],
          [ 2.1770e-01,  1.4371e-01,  2.5938e-01]],

         [[-1.8464e-01, -2.5741e-01, -5.2364e-02],
          [-2.4313e-01,  1.7018e-01, -4.7635e-02],
          [ 3.1411e-02,  1.7765e-01,  2.7995e-01]]],


        [[[ 2.0226e-41, -4.6523e-43,  9.4434e-42],
          [-3.6560e-41,  6.8351e-41, -5.2301e-41],
          [-2.0357e-41,  1.4412e-41, -3.1892e-41]],

         [[-1.1805e-41,  1.3132e-41, -4.8845e-41],
          [ 3.9032e-41,  1.6851e-41, -2.1109e-41],
          [-3.9347e-41, -1.9942e-41, -7.4682e-41]],

         [[-6.7082e-41, -2.2035e-41, -3.1138e-41],
          [-5.1795e-41,  4.6809e-41, -1.2535e-41],
          [ 2.3475e-41,  4.3145e-41,  1.7363e-41]]],


        ...,


        [[[-8.2736e-03,  3.3739e-02, -2.5871e-02],
          [ 8.8551e-03,  7.2765e-02, -1.7408e-02],
          [-1.3501e-01,  3.2301e-02,  2.0028e-02]],

         [[-1.2047e-01, -1.0419e-01, -4.4853e-02],
          [ 9.5741e-02,  9.3264e-02, -9.5158e-02],
          [ 1.1115e-01,  6.1923e-02, -2.0925e-02]],

         [[ 1.0185e-02,  1.6678e-01,  9.8481e-02],
          [ 2.5645e-01,  4.4084e-01,  1.7737e-01],
          [ 1.4582e-01,  2.6461e-01,  4.0211e-02]]],


        [[[ 3.0991e-01,  2.7898e-02,  8.6044e-02],
          [ 1.2004e-01, -1.3417e-01, -8.8470e-02],
          [ 7.4672e-02,  1.0800e-01,  1.0822e-01]],

         [[-4.4951e-03, -2.0771e-01, -4.0699e-03],
          [-7.4736e-02, -2.7914e-01, -1.9417e-01],
          [-1.2599e-03, -4.5142e-02, -6.9951e-03]],

         [[-2.4566e-02, -2.5356e-01, -9.7196e-02],
          [-1.0355e-01, -1.4495e-01, -7.1138e-02],
          [-7.0835e-02,  3.3187e-02,  8.9094e-02]]],


        [[[ 8.8966e-02, -2.3375e-01,  1.1419e-01],
          [-1.9472e-01, -5.9064e-01, -1.9454e-01],
          [ 1.4531e-01, -6.9894e-03,  2.0279e-02]],

         [[ 1.6031e-01, -2.8510e-01,  5.0040e-02],
          [ 1.4502e-02, -3.0663e-01,  3.4578e-02],
          [ 1.6536e-01,  1.8761e-01,  4.3738e-02]],

         [[ 6.5971e-02, -2.3976e-01,  1.1316e-01],
          [ 8.5292e-02, -8.3774e-02,  1.0114e-01],
          [-7.2815e-02,  5.0928e-02,  9.6115e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0648,  0.0525,  0.0344],
          [ 0.0606,  0.0536,  0.0383],
          [ 0.0534,  0.0586,  0.0706]],

         [[ 0.0501,  0.0410,  0.0282],
          [ 0.0487,  0.0436,  0.0285],
          [ 0.0405,  0.0483,  0.0551]],

         [[ 0.0398,  0.0340,  0.0213],
          [ 0.0277,  0.0240,  0.0167],
          [ 0.0178,  0.0263,  0.0308]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0001,  0.0014,  0.0037],
          [ 0.0048,  0.0054,  0.0053],
          [ 0.0079,  0.0079,  0.0071]],

         [[-0.0005,  0.0008,  0.0030],
          [ 0.0032,  0.0037,  0.0034],
          [ 0.0057,  0.0056,  0.0048]],

         [[-0.0028, -0.0024, -0.0005],
          [-0.0008, -0.0007, -0.0009],
          [ 0.0011,  0.0011,  0.0005]]],


        [[[-0.0066, -0.0002,  0.0066],
          [-0.0031, -0.0001,  0.0085],
          [ 0.0006,  0.0053,  0.0173]],

         [[-0.0052, -0.0020,  0.0059],
          [-0.0007, -0.0000,  0.0089],
          [ 0.0027,  0.0064,  0.0180]],

         [[-0.0037, -0.0028,  0.0028],
          [-0.0016, -0.0023,  0.0049],
          [ 0.0007,  0.0028,  0.0120]]],


        [[[ 0.0112,  0.0044,  0.0117],
          [ 0.0104,  0.0101,  0.0180],
          [ 0.0110,  0.0141,  0.0223]],

         [[ 0.0057,  0.0007,  0.0091],
          [ 0.0084,  0.0095,  0.0154],
          [ 0.0100,  0.0141,  0.0192]],

         [[ 0.0078,  0.0031,  0.0101],
          [ 0.0093,  0.0104,  0.0153],
          [ 0.0131,  0.0159,  0.0207]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2341]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1756) | Acc: (91.00%) (117/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.2170) | Acc: (92.00%) (1306/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.2018) | Acc: (93.00%) (2509/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.2076) | Acc: (93.00%) (3693/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.2144) | Acc: (92.00%) (4859/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.2068) | Acc: (92.00%) (6060/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.2051) | Acc: (92.00%) (7251/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.2008) | Acc: (92.00%) (8450/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.2009) | Acc: (92.00%) (9639/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.2027) | Acc: (92.00%) (10827/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.2006) | Acc: (92.00%) (12021/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1996) | Acc: (92.00%) (13213/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1985) | Acc: (93.00%) (14417/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1971) | Acc: (93.00%) (15617/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1950) | Acc: (93.00%) (16831/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1935) | Acc: (93.00%) (18035/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1939) | Acc: (93.00%) (19219/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1930) | Acc: (93.00%) (20425/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1919) | Acc: (93.00%) (21639/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1904) | Acc: (93.00%) (22848/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1899) | Acc: (93.00%) (24049/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1900) | Acc: (93.00%) (25243/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1887) | Acc: (93.00%) (26448/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1879) | Acc: (93.00%) (27655/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1867) | Acc: (93.00%) (28864/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1857) | Acc: (93.00%) (30076/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1842) | Acc: (93.00%) (31291/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1829) | Acc: (93.00%) (32510/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1826) | Acc: (93.00%) (33717/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1825) | Acc: (93.00%) (34915/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1824) | Acc: (93.00%) (36115/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1827) | Acc: (93.00%) (37321/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1826) | Acc: (93.00%) (38516/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1816) | Acc: (93.00%) (39735/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1814) | Acc: (93.00%) (40933/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1802) | Acc: (93.00%) (42152/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1805) | Acc: (93.00%) (43352/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1806) | Acc: (93.00%) (44559/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1799) | Acc: (93.00%) (45780/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1795) | Acc: (93.00%) (46946/50000)
# TEST : Loss: (0.2954) | Acc: (90.00%) (9081/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-7.5021e-41,  1.2972e-40,  2.0574e-41],
          [-1.2082e-40,  2.9406e-41,  4.5614e-41],
          [-1.5302e-40, -7.8576e-41, -1.4440e-40]],

         [[ 8.2703e-41, -5.9302e-41,  7.5075e-41],
          [-5.7658e-41,  1.2496e-40,  1.5288e-40],
          [-5.2666e-41, -2.2130e-40,  9.3546e-41]],

         [[ 8.6986e-41,  5.7431e-41, -1.7256e-40],
          [-2.1268e-41,  1.2225e-40, -5.2254e-42],
          [ 7.5017e-41,  1.2483e-40, -2.0214e-40]]],


        [[[ 3.8469e-01,  3.9488e-02,  3.0625e-01],
          [ 1.7132e-01, -1.2245e-03, -2.1405e-01],
          [-1.9896e-01, -3.7072e-01, -2.8557e-01]],

         [[-5.6038e-02, -3.0304e-01, -4.4194e-02],
          [-9.8734e-02,  4.2023e-01, -2.3528e-01],
          [ 2.1807e-01,  1.4583e-01,  2.6085e-01]],

         [[-1.8408e-01, -2.5610e-01, -5.0679e-02],
          [-2.4197e-01,  1.7108e-01, -4.6380e-02],
          [ 3.2352e-02,  1.7975e-01,  2.8174e-01]]],


        [[[-6.4806e-41, -7.6329e-42, -5.9161e-41],
          [-6.4342e-41,  7.9008e-41, -5.7707e-41],
          [-3.9222e-42, -6.6307e-41,  5.3510e-41]],

         [[ 6.8275e-41, -2.9838e-41, -6.7795e-42],
          [ 7.7304e-41,  4.1649e-41,  7.3345e-41],
          [-4.7206e-41, -3.0554e-41, -2.2865e-41]],

         [[ 5.9047e-41, -6.5214e-41, -1.9210e-41],
          [ 7.3403e-41, -4.6201e-42,  4.5083e-41],
          [-5.3926e-41, -4.7875e-41, -4.9076e-41]]],


        ...,


        [[[-8.4705e-03,  3.2931e-02, -2.5488e-02],
          [ 7.3643e-03,  7.0590e-02, -1.8245e-02],
          [-1.3463e-01,  3.1316e-02,  1.9525e-02]],

         [[-1.1927e-01, -1.0372e-01, -4.3960e-02],
          [ 9.2883e-02,  8.9921e-02, -9.5253e-02],
          [ 1.0926e-01,  6.0086e-02, -2.1262e-02]],

         [[ 1.2461e-02,  1.6615e-01,  9.9520e-02],
          [ 2.5171e-01,  4.2645e-01,  1.7492e-01],
          [ 1.4504e-01,  2.5866e-01,  4.0629e-02]]],


        [[[ 3.0988e-01,  2.9543e-02,  8.6981e-02],
          [ 1.2127e-01, -1.2985e-01, -8.4354e-02],
          [ 7.6357e-02,  1.1116e-01,  1.1083e-01]],

         [[-4.3980e-03, -2.0429e-01, -3.5801e-03],
          [-7.5161e-02, -2.7365e-01, -1.9063e-01],
          [-2.0786e-03, -4.3153e-02, -6.4218e-03]],

         [[-2.3564e-02, -2.4652e-01, -9.3684e-02],
          [-1.0348e-01, -1.3901e-01, -6.7581e-02],
          [-7.1500e-02,  3.4446e-02,  8.8860e-02]]],


        [[[ 8.8893e-02, -2.3260e-01,  1.1334e-01],
          [-1.9380e-01, -5.8767e-01, -1.9482e-01],
          [ 1.4604e-01, -5.2531e-03,  2.0751e-02]],

         [[ 1.6201e-01, -2.8135e-01,  5.1035e-02],
          [ 1.6316e-02, -3.0285e-01,  3.5341e-02],
          [ 1.6710e-01,  1.9025e-01,  4.5340e-02]],

         [[ 6.7216e-02, -2.3725e-01,  1.1336e-01],
          [ 8.5829e-02, -8.2177e-02,  1.0076e-01],
          [-7.2220e-02,  5.2127e-02,  9.5956e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2322]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0023]], device='cuda:0')

Epoch: 146 | Batch_idx: 0 |  Loss: (0.1708) | Acc: (94.00%) (121/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1634) | Acc: (94.00%) (1331/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1640) | Acc: (94.00%) (2543/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1694) | Acc: (94.00%) (3738/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1708) | Acc: (94.00%) (4940/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1728) | Acc: (94.00%) (6142/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1707) | Acc: (94.00%) (7356/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1693) | Acc: (94.00%) (8558/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1695) | Acc: (94.00%) (9766/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1683) | Acc: (94.00%) (10981/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1676) | Acc: (94.00%) (12197/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1671) | Acc: (94.00%) (13411/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1667) | Acc: (94.00%) (14619/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1656) | Acc: (94.00%) (15839/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1649) | Acc: (94.00%) (17050/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1642) | Acc: (94.00%) (18267/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1633) | Acc: (94.00%) (19473/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1632) | Acc: (94.00%) (20692/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1641) | Acc: (94.00%) (21889/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1636) | Acc: (94.00%) (23102/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1640) | Acc: (94.00%) (24304/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1631) | Acc: (94.00%) (25513/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1633) | Acc: (94.00%) (26722/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1627) | Acc: (94.00%) (27940/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1620) | Acc: (94.00%) (29164/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1626) | Acc: (94.00%) (30359/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1630) | Acc: (94.00%) (31559/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1631) | Acc: (94.00%) (32765/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1632) | Acc: (94.00%) (33975/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1636) | Acc: (94.00%) (35181/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1635) | Acc: (94.00%) (36394/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1632) | Acc: (94.00%) (37608/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1632) | Acc: (94.00%) (38816/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1629) | Acc: (94.00%) (40027/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1630) | Acc: (94.00%) (41234/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1627) | Acc: (94.00%) (42450/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1628) | Acc: (94.00%) (43659/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1621) | Acc: (94.00%) (44883/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1619) | Acc: (94.00%) (46091/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1624) | Acc: (94.00%) (47254/50000)
# TEST : Loss: (0.2916) | Acc: (90.00%) (9086/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 3.6811e-41, -6.4926e-41, -1.6442e-40],
          [-1.1369e-40,  3.4880e-41, -1.6089e-40],
          [ 1.1444e-40, -1.1840e-40,  1.8611e-40]],

         [[-2.3057e-41, -1.3067e-40, -3.2289e-41],
          [-6.8193e-41, -1.2043e-40,  1.1863e-40],
          [ 2.0636e-40, -1.7275e-40, -8.7539e-42]],

         [[ 1.3044e-40, -4.2681e-41,  1.0118e-40],
          [ 9.4831e-41,  1.7505e-40,  5.4571e-41],
          [ 1.5040e-40, -7.3620e-41, -4.6658e-41]]],


        [[[ 3.8427e-01,  3.9444e-02,  3.0590e-01],
          [ 1.7112e-01, -1.2231e-03, -2.1380e-01],
          [-1.9872e-01, -3.7029e-01, -2.8525e-01]],

         [[-5.5975e-02, -3.0269e-01, -4.4143e-02],
          [-9.8618e-02,  4.1973e-01, -2.3500e-01],
          [ 2.1780e-01,  1.4566e-01,  2.6054e-01]],

         [[-1.8386e-01, -2.5578e-01, -5.0616e-02],
          [-2.4166e-01,  1.7086e-01, -4.6322e-02],
          [ 3.2311e-02,  1.7952e-01,  2.8139e-01]]],


        [[[ 7.9959e-41, -8.9683e-43, -6.6267e-42],
          [-6.5987e-41,  7.2957e-41, -3.5565e-41],
          [ 3.7092e-41,  1.4552e-41, -3.4555e-41]],

         [[-1.0807e-41,  5.3622e-41,  1.2947e-41],
          [ 7.6397e-41,  7.3977e-41, -6.9834e-41],
          [ 5.7798e-41,  1.0678e-42,  2.0977e-42]],

         [[-1.8553e-42, -1.3415e-41,  4.7306e-41],
          [-2.2160e-41, -6.3871e-42,  5.5269e-41],
          [-1.7768e-41,  7.3110e-41, -2.1015e-41]]],


        ...,


        [[[-8.4008e-03,  3.2660e-02, -2.5286e-02],
          [ 7.2975e-03,  6.9948e-02, -1.8086e-02],
          [-1.3346e-01,  3.1044e-02,  1.9363e-02]],

         [[-1.1805e-01, -1.0265e-01, -4.3537e-02],
          [ 9.1665e-02,  8.8693e-02, -9.4102e-02],
          [ 1.0792e-01,  5.9319e-02, -2.1023e-02]],

         [[ 1.2300e-02,  1.6391e-01,  9.8328e-02],
          [ 2.4506e-01,  4.1106e-01,  1.7139e-01],
          [ 1.4172e-01,  2.5109e-01,  3.9906e-02]]],


        [[[ 3.0787e-01,  2.9326e-02,  8.6341e-02],
          [ 1.2045e-01, -1.2882e-01, -8.3680e-02],
          [ 7.5891e-02,  1.1043e-01,  1.1009e-01]],

         [[-4.3598e-03, -2.0188e-01, -3.5398e-03],
          [-7.4443e-02, -2.6953e-01, -1.8800e-01],
          [-2.0625e-03, -4.2758e-02, -6.3656e-03]],

         [[-2.3304e-02, -2.4251e-01, -9.2264e-02],
          [-1.0218e-01, -1.3588e-01, -6.6269e-02],
          [-7.0807e-02,  3.4036e-02,  8.7886e-02]]],


        [[[ 8.8570e-02, -2.3145e-01,  1.1292e-01],
          [-1.9307e-01, -5.8443e-01, -1.9405e-01],
          [ 1.4562e-01, -5.2363e-03,  2.0690e-02]],

         [[ 1.6148e-01, -2.8024e-01,  5.0867e-02],
          [ 1.6261e-02, -3.0157e-01,  3.5218e-02],
          [ 1.6664e-01,  1.8969e-01,  4.5215e-02]],

         [[ 6.6999e-02, -2.3640e-01,  1.1300e-01],
          [ 8.5548e-02, -8.1875e-02,  1.0043e-01],
          [-7.2018e-02,  5.1974e-02,  9.5688e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2321]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0282]], device='cuda:0')

Epoch: 147 | Batch_idx: 0 |  Loss: (0.1569) | Acc: (92.00%) (118/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1716) | Acc: (94.00%) (1328/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1701) | Acc: (94.00%) (2542/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1647) | Acc: (94.00%) (3758/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1647) | Acc: (94.00%) (4966/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1621) | Acc: (94.00%) (6180/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1585) | Acc: (94.00%) (7405/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1574) | Acc: (94.00%) (8620/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1586) | Acc: (94.00%) (9824/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1597) | Acc: (94.00%) (11025/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1592) | Acc: (94.00%) (12244/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1587) | Acc: (94.00%) (13454/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1588) | Acc: (94.00%) (14661/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1597) | Acc: (94.00%) (15867/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1601) | Acc: (94.00%) (17075/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1613) | Acc: (94.00%) (18279/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1613) | Acc: (94.00%) (19491/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1624) | Acc: (94.00%) (20695/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1621) | Acc: (94.00%) (21909/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1620) | Acc: (94.00%) (23120/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1623) | Acc: (94.00%) (24325/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1611) | Acc: (94.00%) (25547/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1615) | Acc: (94.00%) (26753/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1613) | Acc: (94.00%) (27965/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1612) | Acc: (94.00%) (29177/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1619) | Acc: (94.00%) (30382/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1617) | Acc: (94.00%) (31595/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1620) | Acc: (94.00%) (32805/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1625) | Acc: (94.00%) (34004/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1621) | Acc: (94.00%) (35212/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1606) | Acc: (94.00%) (36439/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1607) | Acc: (94.00%) (37651/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1605) | Acc: (94.00%) (38873/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1605) | Acc: (94.00%) (40082/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1605) | Acc: (94.00%) (41293/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1609) | Acc: (94.00%) (42503/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1616) | Acc: (94.00%) (43696/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1623) | Acc: (94.00%) (44900/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1625) | Acc: (94.00%) (46104/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1623) | Acc: (94.00%) (47268/50000)
# TEST : Loss: (0.2861) | Acc: (91.00%) (9108/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 1.8566e-40,  1.0008e-40, -8.3358e-41],
          [-5.7888e-42, -5.0573e-41, -1.8798e-40],
          [ 2.2720e-40,  6.0214e-42, -1.9809e-40]],

         [[-2.8086e-41, -1.5326e-40, -3.7361e-41],
          [ 1.5945e-40, -1.0524e-40,  1.3572e-40],
          [ 1.3416e-40, -2.3317e-40, -1.3751e-41]],

         [[ 2.4266e-41,  7.8498e-41, -1.2955e-41],
          [-1.3531e-40, -1.0231e-41, -8.4339e-41],
          [ 1.0293e-40,  5.5389e-41, -5.4508e-41]]],


        [[[ 3.8376e-01,  3.9390e-02,  3.0549e-01],
          [ 1.7088e-01, -1.2214e-03, -2.1350e-01],
          [-1.9844e-01, -3.6976e-01, -2.8485e-01]],

         [[-5.5898e-02, -3.0227e-01, -4.4081e-02],
          [-9.8476e-02,  4.1912e-01, -2.3466e-01],
          [ 2.1748e-01,  1.4544e-01,  2.6016e-01]],

         [[-1.8359e-01, -2.5539e-01, -5.0540e-02],
          [-2.4130e-01,  1.7060e-01, -4.6251e-02],
          [ 3.2261e-02,  1.7925e-01,  2.8097e-01]]],


        [[[-8.1735e-41,  9.2121e-42,  5.6142e-41],
          [-8.3446e-41,  8.2082e-41, -3.4786e-41],
          [ 1.4596e-41,  7.5746e-41, -2.6413e-41]],

         [[-3.2918e-41, -6.9450e-41,  4.1277e-41],
          [ 6.3283e-42,  7.1100e-41, -9.0440e-42],
          [ 5.1344e-42,  7.1933e-41,  1.4523e-41]],

         [[-7.3736e-41,  7.6278e-41,  3.0630e-41],
          [-4.1085e-41,  4.3286e-42, -3.7471e-41],
          [-1.6376e-41, -4.3426e-42,  7.9761e-41]]],


        ...,


        [[[-8.3168e-03,  3.2334e-02, -2.5043e-02],
          [ 7.2171e-03,  6.9175e-02, -1.7895e-02],
          [-1.3206e-01,  3.0716e-02,  1.9167e-02]],

         [[-1.1659e-01, -1.0136e-01, -4.3029e-02],
          [ 9.0206e-02,  8.7222e-02, -9.2720e-02],
          [ 1.0632e-01,  5.8398e-02, -2.0736e-02]],

         [[ 1.2108e-02,  1.6122e-01,  9.6898e-02],
          [ 2.3721e-01,  3.9309e-01,  1.6720e-01],
          [ 1.3779e-01,  2.4219e-01,  3.9045e-02]]],


        [[[ 3.0545e-01,  2.9065e-02,  8.5568e-02],
          [ 1.1946e-01, -1.2757e-01, -8.2868e-02],
          [ 7.5329e-02,  1.0955e-01,  1.0921e-01]],

         [[-4.3138e-03, -1.9898e-01, -3.4914e-03],
          [-7.3579e-02, -2.6460e-01, -1.8485e-01],
          [-2.0430e-03, -4.2282e-02, -6.2978e-03]],

         [[-2.2992e-02, -2.3772e-01, -9.0567e-02],
          [-1.0061e-01, -1.3218e-01, -6.4707e-02],
          [-6.9973e-02,  3.3542e-02,  8.6716e-02]]],


        [[[ 8.8178e-02, -2.3006e-01,  1.1241e-01],
          [-1.9218e-01, -5.8052e-01, -1.9312e-01],
          [ 1.4512e-01, -5.2160e-03,  2.0617e-02]],

         [[ 1.6084e-01, -2.7888e-01,  5.0662e-02],
          [ 1.6194e-02, -3.0002e-01,  3.5070e-02],
          [ 1.6609e-01,  1.8901e-01,  4.5063e-02]],

         [[ 6.6737e-02, -2.3537e-01,  1.1256e-01],
          [ 8.5207e-02, -8.1510e-02,  1.0003e-01],
          [-7.1773e-02,  5.1789e-02,  9.5363e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2420]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0001]], device='cuda:0')

Epoch: 148 | Batch_idx: 0 |  Loss: (0.0889) | Acc: (97.00%) (125/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1532) | Acc: (94.00%) (1335/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1557) | Acc: (94.00%) (2545/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1549) | Acc: (94.00%) (3761/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1570) | Acc: (94.00%) (4962/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1532) | Acc: (94.00%) (6182/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1518) | Acc: (94.00%) (7408/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1533) | Acc: (94.00%) (8623/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1524) | Acc: (94.00%) (9839/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1529) | Acc: (94.00%) (11056/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1524) | Acc: (94.00%) (12272/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1540) | Acc: (94.00%) (13480/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1549) | Acc: (94.00%) (14694/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1551) | Acc: (94.00%) (15906/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1548) | Acc: (94.00%) (17122/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1566) | Acc: (94.00%) (18323/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1553) | Acc: (94.00%) (19543/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1551) | Acc: (94.00%) (20759/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1547) | Acc: (94.00%) (21968/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1558) | Acc: (94.00%) (23168/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1555) | Acc: (94.00%) (24375/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1555) | Acc: (94.00%) (25589/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1551) | Acc: (94.00%) (26809/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1552) | Acc: (94.00%) (28023/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1558) | Acc: (94.00%) (29235/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1562) | Acc: (94.00%) (30442/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1570) | Acc: (94.00%) (31645/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1567) | Acc: (94.00%) (32856/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1574) | Acc: (94.00%) (34067/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1582) | Acc: (94.00%) (35273/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1584) | Acc: (94.00%) (36483/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1583) | Acc: (94.00%) (37693/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1582) | Acc: (94.00%) (38911/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1581) | Acc: (94.00%) (40122/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1592) | Acc: (94.00%) (41309/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1604) | Acc: (94.00%) (42505/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1599) | Acc: (94.00%) (43727/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1608) | Acc: (94.00%) (44923/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1609) | Acc: (94.00%) (46142/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1609) | Acc: (94.00%) (47302/50000)
# TEST : Loss: (0.2796) | Acc: (91.00%) (9101/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 8.5240e-41,  1.1642e-40,  2.3702e-40],
          [ 6.3972e-41,  2.2473e-40, -1.4465e-40],
          [ 2.2784e-40, -1.2463e-40, -1.6142e-40]],

         [[ 1.2633e-40, -1.7642e-40,  1.1917e-40],
          [-1.3855e-40, -1.2119e-40,  2.3784e-40],
          [ 3.5907e-41, -3.5945e-41,  1.3969e-40]],

         [[-9.8890e-42, -9.4213e-41, -1.8252e-41],
          [ 1.6585e-40,  1.9352e-40, -1.5976e-41],
          [-1.3042e-40,  6.1085e-41,  1.4815e-40]]],


        [[[ 3.8314e-01,  3.9325e-02,  3.0498e-01],
          [ 1.7059e-01, -1.2193e-03, -2.1313e-01],
          [-1.9809e-01, -3.6912e-01, -2.8436e-01]],

         [[-5.5806e-02, -3.0175e-01, -4.4007e-02],
          [-9.8304e-02,  4.1838e-01, -2.3425e-01],
          [ 2.1709e-01,  1.4518e-01,  2.5970e-01]],

         [[-1.8326e-01, -2.5492e-01, -5.0447e-02],
          [-2.4085e-01,  1.7028e-01, -4.6165e-02],
          [ 3.2201e-02,  1.7891e-01,  2.8045e-01]]],


        [[[ 8.7469e-41,  8.8310e-41, -3.8007e-41],
          [-4.3990e-41,  2.7129e-42, -3.1882e-41],
          [-6.8005e-41,  6.5561e-41,  4.0335e-41]],

         [[ 9.0580e-42,  4.5548e-41,  8.6149e-41],
          [-1.6591e-42, -5.3116e-41,  8.4312e-41],
          [-1.9195e-41,  1.5807e-42, -5.5232e-41]],

         [[ 4.2703e-41,  2.9408e-41, -7.1940e-41],
          [ 7.7537e-41, -2.3023e-41, -6.0179e-41],
          [-1.3621e-41, -2.2669e-41, -2.0540e-41]]],


        ...,


        [[[-8.2158e-03,  3.1941e-02, -2.4751e-02],
          [ 7.1205e-03,  6.8247e-02, -1.7665e-02],
          [-1.3037e-01,  3.0323e-02,  1.8932e-02]],

         [[-1.1484e-01, -9.9818e-02, -4.2419e-02],
          [ 8.8462e-02,  8.5467e-02, -9.1067e-02],
          [ 1.0441e-01,  5.7299e-02, -2.0393e-02]],

         [[ 1.1877e-02,  1.5802e-01,  9.5187e-02],
          [ 2.2800e-01,  3.7231e-01,  1.6223e-01],
          [ 1.3315e-01,  2.3178e-01,  3.8022e-02]]],


        [[[ 3.0252e-01,  2.8751e-02,  8.4638e-02],
          [ 1.1827e-01, -1.2608e-01, -8.1891e-02],
          [ 7.4651e-02,  1.0849e-01,  1.0815e-01]],

         [[-4.2585e-03, -1.9551e-01, -3.4335e-03],
          [-7.2541e-02, -2.5873e-01, -1.8110e-01],
          [-2.0197e-03, -4.1711e-02, -6.2164e-03]],

         [[-2.2617e-02, -2.3202e-01, -8.8545e-02],
          [-9.8744e-02, -1.2781e-01, -6.2857e-02],
          [-6.8972e-02,  3.2952e-02,  8.5315e-02]]],


        [[[ 8.7705e-02, -2.2838e-01,  1.1179e-01],
          [-1.9110e-01, -5.7581e-01, -1.9200e-01],
          [ 1.4451e-01, -5.1914e-03,  2.0527e-02]],

         [[ 1.6007e-01, -2.7724e-01,  5.0415e-02],
          [ 1.6113e-02, -2.9815e-01,  3.4891e-02],
          [ 1.6543e-01,  1.8819e-01,  4.4880e-02]],

         [[ 6.6419e-02, -2.3412e-01,  1.1203e-01],
          [ 8.4795e-02, -8.1068e-02,  9.9547e-02],
          [-7.1476e-02,  5.1565e-02,  9.4969e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2448]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0046]], device='cuda:0')

Epoch: 149 | Batch_idx: 0 |  Loss: (0.1849) | Acc: (92.00%) (119/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1798) | Acc: (93.00%) (1322/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1801) | Acc: (93.00%) (2523/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1795) | Acc: (93.00%) (3724/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1689) | Acc: (94.00%) (4952/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1630) | Acc: (94.00%) (6178/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1613) | Acc: (94.00%) (7396/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1601) | Acc: (94.00%) (8608/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1609) | Acc: (94.00%) (9812/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1604) | Acc: (94.00%) (11035/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1586) | Acc: (94.00%) (12255/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1599) | Acc: (94.00%) (13456/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1616) | Acc: (94.00%) (14658/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1616) | Acc: (94.00%) (15869/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1631) | Acc: (94.00%) (17067/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1621) | Acc: (94.00%) (18288/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1610) | Acc: (94.00%) (19515/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1621) | Acc: (94.00%) (20710/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1628) | Acc: (94.00%) (21913/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1634) | Acc: (94.00%) (23117/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1649) | Acc: (94.00%) (24317/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1655) | Acc: (94.00%) (25524/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1650) | Acc: (94.00%) (26739/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1661) | Acc: (94.00%) (27932/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1659) | Acc: (94.00%) (29143/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1663) | Acc: (94.00%) (30341/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1663) | Acc: (94.00%) (31548/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1660) | Acc: (94.00%) (32767/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1662) | Acc: (94.00%) (33975/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1655) | Acc: (94.00%) (35199/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1658) | Acc: (94.00%) (36414/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1667) | Acc: (94.00%) (37610/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1667) | Acc: (94.00%) (38815/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1666) | Acc: (94.00%) (40023/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1671) | Acc: (94.00%) (41232/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1673) | Acc: (94.00%) (42440/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1675) | Acc: (94.00%) (43644/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1677) | Acc: (94.00%) (44852/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1677) | Acc: (94.00%) (46059/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1682) | Acc: (94.00%) (47212/50000)
# TEST : Loss: (0.2816) | Acc: (90.00%) (9090/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-9.5448e-41,  8.6876e-41,  1.7459e-40],
          [ 1.1790e-40, -1.0895e-40, -1.6621e-40],
          [ 9.4596e-41,  1.3326e-40,  1.3295e-40]],

         [[-1.7628e-40,  1.6601e-40, -1.8735e-40],
          [-1.5794e-40, -9.2927e-41, -2.3776e-40],
          [-9.8430e-41, -1.7353e-40,  6.9238e-41]],

         [[-5.2317e-41,  1.0432e-40,  1.4696e-40],
          [-1.3392e-40,  1.2820e-40, -1.1061e-40],
          [ 1.3565e-40, -1.6641e-40,  1.1853e-40]]],


        [[[ 3.8238e-01,  3.9246e-02,  3.0437e-01],
          [ 1.7023e-01, -1.2167e-03, -2.1269e-01],
          [-1.9767e-01, -3.6835e-01, -2.8377e-01]],

         [[-5.5693e-02, -3.0113e-01, -4.3916e-02],
          [-9.8095e-02,  4.1747e-01, -2.3375e-01],
          [ 2.1661e-01,  1.4486e-01,  2.5915e-01]],

         [[-1.8285e-01, -2.5434e-01, -5.0335e-02],
          [-2.4031e-01,  1.6989e-01, -4.6062e-02],
          [ 3.2128e-02,  1.7851e-01,  2.7983e-01]]],


        [[[ 5.3709e-41, -3.2177e-41, -8.7194e-41],
          [-1.1798e-41, -3.1854e-41, -7.2297e-41],
          [-5.2253e-41,  1.5435e-41, -6.0949e-41]],

         [[-7.7359e-41,  6.5394e-41, -2.8502e-42],
          [ 7.4741e-41,  2.8114e-41,  8.1323e-41],
          [-8.2573e-41,  1.5430e-41,  4.4757e-42]],

         [[ 7.8543e-42,  4.3999e-41,  2.5718e-41],
          [-4.9986e-41,  7.3037e-41, -6.3976e-41],
          [ 2.2028e-41,  5.9304e-41, -8.8992e-41]]],


        ...,


        [[[-8.0946e-03,  3.1470e-02, -2.4400e-02],
          [ 7.0048e-03,  6.7135e-02, -1.7390e-02],
          [-1.2834e-01,  2.9850e-02,  1.8650e-02]],

         [[-1.1275e-01, -9.7971e-02, -4.1688e-02],
          [ 8.6387e-02,  8.3379e-02, -8.9096e-02],
          [ 1.0213e-01,  5.5989e-02, -1.9983e-02]],

         [[ 1.1603e-02,  1.5421e-01,  9.3147e-02],
          [ 2.1728e-01,  3.4851e-01,  1.5639e-01],
          [ 1.2771e-01,  2.1973e-01,  3.6813e-02]]],


        [[[ 2.9901e-01,  2.8373e-02,  8.3520e-02],
          [ 1.1684e-01, -1.2428e-01, -8.0718e-02],
          [ 7.3834e-02,  1.0722e-01,  1.0687e-01]],

         [[-4.1923e-03, -1.9138e-01, -3.3644e-03],
          [-7.1300e-02, -2.5177e-01, -1.7663e-01],
          [-1.9916e-03, -4.1027e-02, -6.1188e-03]],

         [[-2.2170e-02, -2.2528e-01, -8.6146e-02],
          [-9.6517e-02, -1.2269e-01, -6.0679e-02],
          [-6.7775e-02,  3.2248e-02,  8.3641e-02]]],


        [[[ 8.7132e-02, -2.2635e-01,  1.1105e-01],
          [-1.8979e-01, -5.7012e-01, -1.9064e-01],
          [ 1.4377e-01, -5.1617e-03,  2.0419e-02]],

         [[ 1.5913e-01, -2.7526e-01,  5.0116e-02],
          [ 1.6015e-02, -2.9589e-01,  3.4674e-02],
          [ 1.6462e-01,  1.8719e-01,  4.4657e-02]],

         [[ 6.6035e-02, -2.3261e-01,  1.1139e-01],
          [ 8.4296e-02, -8.0534e-02,  9.8962e-02],
          [-7.1117e-02,  5.1294e-02,  9.4492e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2629]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0138]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 150 | Batch_idx: 0 |  Loss: (0.1796) | Acc: (92.00%) (119/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.2313) | Acc: (92.00%) (1296/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.2662) | Acc: (90.00%) (2438/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.3166) | Acc: (89.00%) (3533/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.3488) | Acc: (88.00%) (4622/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.3675) | Acc: (87.00%) (5715/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.3832) | Acc: (86.00%) (6792/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.3797) | Acc: (87.00%) (7921/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.3830) | Acc: (87.00%) (9025/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.3816) | Acc: (87.00%) (10142/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.3825) | Acc: (87.00%) (11263/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.3791) | Acc: (87.00%) (12390/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.3771) | Acc: (87.00%) (13513/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.3738) | Acc: (87.00%) (14646/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.3713) | Acc: (87.00%) (15778/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.3696) | Acc: (87.00%) (16919/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.3671) | Acc: (87.00%) (18048/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.3641) | Acc: (87.00%) (19184/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.3603) | Acc: (87.00%) (20336/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.3573) | Acc: (87.00%) (21485/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.3539) | Acc: (87.00%) (22635/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.3506) | Acc: (88.00%) (23793/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.3467) | Acc: (88.00%) (24949/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.3462) | Acc: (88.00%) (26086/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.3435) | Acc: (88.00%) (27247/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.3418) | Acc: (88.00%) (28401/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.3400) | Acc: (88.00%) (29548/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.3371) | Acc: (88.00%) (30727/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.3366) | Acc: (88.00%) (31866/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.3347) | Acc: (88.00%) (33017/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.3322) | Acc: (88.00%) (34174/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.3297) | Acc: (88.00%) (35343/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.3275) | Acc: (88.00%) (36514/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.3249) | Acc: (88.00%) (37681/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.3250) | Acc: (88.00%) (38823/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.3250) | Acc: (88.00%) (39954/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.3251) | Acc: (88.00%) (41095/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.3245) | Acc: (88.00%) (42250/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.3233) | Acc: (89.00%) (43410/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.3224) | Acc: (89.00%) (44526/50000)
# TEST : Loss: (0.4245) | Acc: (86.00%) (8668/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.7167e-40, -7.6511e-42,  3.0125e-40],
          [ 1.3592e-40, -7.9818e-41,  9.7408e-41],
          [ 1.5408e-40,  1.5129e-40,  1.5032e-40]],

         [[-1.4825e-40,  1.8481e-40, -5.5140e-41],
          [-1.7656e-40, -1.6689e-42,  3.0285e-40],
          [-1.1518e-40,  1.1008e-40,  1.3322e-40]],

         [[-1.0671e-40, -7.6076e-41, -1.7112e-40],
          [-1.5180e-40,  2.5335e-40, -1.7682e-40],
          [-6.4460e-42, -1.3155e-40,  2.2366e-41]]],


        [[[ 3.8367e-01,  3.6974e-02,  3.1382e-01],
          [ 1.7129e-01, -4.8417e-03, -2.1456e-01],
          [-2.1257e-01, -3.9150e-01, -3.0249e-01]],

         [[-6.4137e-02, -3.1028e-01, -4.3120e-02],
          [-9.8776e-02,  4.2026e-01, -2.3080e-01],
          [ 2.0914e-01,  1.3757e-01,  2.4702e-01]],

         [[-1.8198e-01, -2.5801e-01, -4.6393e-02],
          [-2.3736e-01,  1.7913e-01, -3.8460e-02],
          [ 2.5430e-02,  1.7110e-01,  2.7023e-01]]],


        [[[-3.2803e-41,  9.2843e-41, -9.1449e-41],
          [-3.9475e-41,  4.7777e-41,  7.6187e-41],
          [ 6.2537e-41,  4.4630e-41,  5.7958e-42]],

         [[-7.7787e-41, -3.0274e-41,  2.6974e-41],
          [-2.9939e-41, -4.0761e-41,  8.1564e-41],
          [ 5.2802e-41,  5.1070e-41,  4.9746e-42]],

         [[ 1.0074e-41, -6.4461e-41,  4.3066e-41],
          [ 7.1119e-41,  7.8327e-41,  4.0436e-41],
          [ 7.4507e-42, -3.3403e-41, -9.0342e-41]]],


        ...,


        [[[-1.0382e-02,  2.7107e-02, -2.9643e-02],
          [ 2.4928e-02,  7.8941e-02, -1.2878e-03],
          [-9.0186e-02,  5.9987e-02,  5.0937e-02]],

         [[-1.2563e-01, -1.1482e-01, -6.1333e-02],
          [ 9.6707e-02,  8.4470e-02, -8.0773e-02],
          [ 1.3798e-01,  8.6777e-02,  9.5922e-03]],

         [[ 7.2557e-03,  1.4629e-01,  7.6663e-02],
          [ 2.3868e-01,  3.5334e-01,  1.6635e-01],
          [ 1.6969e-01,  2.5588e-01,  6.2923e-02]]],


        [[[ 3.1304e-01,  2.9333e-02,  6.5202e-02],
          [ 1.0654e-01, -1.5750e-01, -1.2532e-01],
          [ 5.7075e-02,  7.6406e-02,  6.9263e-02]],

         [[ 1.3266e-02, -1.7375e-01, -1.0294e-03],
          [-8.1576e-02, -2.7863e-01, -2.0299e-01],
          [-1.8471e-02, -6.2786e-02, -2.6638e-02]],

         [[-5.3318e-03, -1.9656e-01, -7.2560e-02],
          [-1.1660e-01, -1.5378e-01, -8.4745e-02],
          [-8.9630e-02,  9.2403e-03,  6.6821e-02]]],


        [[[ 7.7012e-02, -2.3310e-01,  1.0946e-01],
          [-2.0637e-01, -5.8703e-01, -2.0221e-01],
          [ 1.3780e-01,  1.7387e-03,  2.1704e-02]],

         [[ 1.5337e-01, -2.7496e-01,  5.6625e-02],
          [ 8.8903e-03, -2.9864e-01,  3.4309e-02],
          [ 1.6835e-01,  1.9796e-01,  4.9971e-02]],

         [[ 5.6751e-02, -2.3569e-01,  1.1594e-01],
          [ 7.3217e-02, -8.2130e-02,  1.0206e-01],
          [-7.3920e-02,  5.9379e-02,  1.0259e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0054, -0.0415, -0.0607],
          [ 0.0183, -0.0390, -0.0490],
          [ 0.0227, -0.0368, -0.0453]],

         [[ 0.0095, -0.0240, -0.0344],
          [ 0.0347, -0.0207, -0.0262],
          [ 0.0467, -0.0138, -0.0210]],

         [[ 0.0507,  0.0155,  0.0039],
          [ 0.0679,  0.0167,  0.0096],
          [ 0.0790,  0.0197,  0.0078]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0081,  0.0081,  0.0114],
          [ 0.0065,  0.0076,  0.0133],
          [ 0.0086,  0.0101,  0.0147]],

         [[ 0.0047,  0.0044,  0.0079],
          [ 0.0029,  0.0029,  0.0086],
          [ 0.0052,  0.0055,  0.0096]],

         [[ 0.0009,  0.0002,  0.0022],
          [-0.0017, -0.0022,  0.0022],
          [-0.0005, -0.0005,  0.0026]]],


        [[[ 0.0009, -0.0030, -0.0023],
          [-0.0054, -0.0085, -0.0059],
          [-0.0131, -0.0196, -0.0122]],

         [[ 0.0017, -0.0002,  0.0029],
          [-0.0044, -0.0063, -0.0021],
          [-0.0114, -0.0166, -0.0087]],

         [[ 0.0079,  0.0061,  0.0068],
          [ 0.0033,  0.0009,  0.0025],
          [-0.0022, -0.0081, -0.0027]]],


        [[[-0.0243, -0.0218, -0.0304],
          [-0.0392, -0.0256, -0.0267],
          [-0.0621, -0.0478, -0.0323]],

         [[-0.0172, -0.0126, -0.0214],
          [-0.0346, -0.0181, -0.0184],
          [-0.0601, -0.0433, -0.0255]],

         [[-0.0112, -0.0074, -0.0148],
          [-0.0273, -0.0136, -0.0144],
          [-0.0488, -0.0345, -0.0191]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2652]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 151 | Batch_idx: 0 |  Loss: (0.3031) | Acc: (91.00%) (117/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.2405) | Acc: (92.00%) (1298/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.2355) | Acc: (92.00%) (2476/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.2351) | Acc: (91.00%) (3638/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.2420) | Acc: (91.00%) (4800/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.2348) | Acc: (91.00%) (5990/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.2313) | Acc: (91.00%) (7171/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.2327) | Acc: (91.00%) (8351/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.2305) | Acc: (92.00%) (9542/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.2329) | Acc: (91.00%) (10709/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.2312) | Acc: (92.00%) (11900/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.2309) | Acc: (92.00%) (13075/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.2334) | Acc: (91.00%) (14237/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.2373) | Acc: (91.00%) (15400/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.2397) | Acc: (91.00%) (16558/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.2395) | Acc: (91.00%) (17727/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.2403) | Acc: (91.00%) (18901/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.2414) | Acc: (91.00%) (20065/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.2446) | Acc: (91.00%) (21225/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.2446) | Acc: (91.00%) (22397/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.2440) | Acc: (91.00%) (23567/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.2458) | Acc: (91.00%) (24730/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.2469) | Acc: (91.00%) (25892/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.2468) | Acc: (91.00%) (27059/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.2450) | Acc: (91.00%) (28240/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.2446) | Acc: (91.00%) (29416/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.2448) | Acc: (91.00%) (30597/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.2448) | Acc: (91.00%) (31778/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.2446) | Acc: (91.00%) (32945/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.2439) | Acc: (91.00%) (34129/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.2458) | Acc: (91.00%) (35281/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.2461) | Acc: (91.00%) (36458/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.2450) | Acc: (91.00%) (37643/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.2445) | Acc: (91.00%) (38822/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.2453) | Acc: (91.00%) (39985/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.2459) | Acc: (91.00%) (41149/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.2464) | Acc: (91.00%) (42314/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.2463) | Acc: (91.00%) (43487/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.2454) | Acc: (91.00%) (44677/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.2447) | Acc: (91.00%) (45819/50000)
# TEST : Loss: (0.3697) | Acc: (88.00%) (8838/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 3.6805e-40, -1.2797e-40,  3.3976e-41],
          [ 9.9836e-41,  1.3686e-41,  2.2188e-40],
          [ 1.7302e-40,  1.1874e-40,  1.1701e-40]],

         [[ 6.8479e-41, -2.6600e-40,  5.6498e-41],
          [-1.3765e-40,  1.1505e-40, -1.3304e-40],
          [-2.4903e-40, -2.1626e-40,  1.5276e-40]],

         [[ 9.8991e-41, -3.0621e-41, -1.9022e-40],
          [-1.7055e-40,  2.8621e-40, -1.9660e-40],
          [-1.8724e-40,  9.6357e-41,  1.4488e-40]]],


        [[[ 3.9407e-01,  4.0968e-02,  3.1673e-01],
          [ 1.7705e-01, -3.9777e-03, -2.0743e-01],
          [-2.0450e-01, -3.8878e-01, -2.9976e-01]],

         [[-5.7117e-02, -3.1608e-01, -5.2952e-02],
          [-9.3837e-02,  4.1657e-01, -2.3146e-01],
          [ 2.1861e-01,  1.4377e-01,  2.5106e-01]],

         [[-1.6778e-01, -2.5532e-01, -4.9506e-02],
          [-2.3079e-01,  1.8263e-01, -3.5048e-02],
          [ 3.5939e-02,  1.8205e-01,  2.8357e-01]]],


        [[[-6.2310e-41, -8.5666e-41, -5.0493e-41],
          [-1.2345e-40,  1.0323e-40,  7.8683e-41],
          [ 1.0515e-41,  8.4678e-41,  5.5552e-41]],

         [[ 8.7064e-41,  7.6219e-41, -3.6156e-41],
          [ 6.4484e-41,  7.9519e-41,  1.0842e-40],
          [-2.2652e-41,  4.1420e-41,  5.7691e-41]],

         [[-9.1286e-41,  3.8529e-41, -8.9533e-41],
          [-5.7120e-41, -5.2912e-41, -8.0961e-41],
          [ 7.3410e-41,  7.9180e-41, -9.6582e-41]]],


        ...,


        [[[-5.4742e-03,  1.5068e-02, -4.2275e-02],
          [ 2.8539e-02,  6.4744e-02, -1.4004e-02],
          [-9.1015e-02,  4.7521e-02,  4.0115e-02]],

         [[-1.1877e-01, -1.2564e-01, -6.9484e-02],
          [ 1.0093e-01,  6.8212e-02, -9.1270e-02],
          [ 1.4113e-01,  7.6509e-02,  3.0719e-04]],

         [[ 2.7548e-02,  1.4710e-01,  7.9343e-02],
          [ 2.7397e-01,  3.4791e-01,  1.6841e-01],
          [ 1.9635e-01,  2.5328e-01,  6.0476e-02]]],


        [[[ 3.2375e-01,  3.1855e-02,  7.3093e-02],
          [ 1.3072e-01, -1.5341e-01, -1.1215e-01],
          [ 9.2525e-02,  9.4288e-02,  9.1098e-02]],

         [[ 2.4086e-02, -1.7664e-01, -6.9492e-04],
          [-5.2970e-02, -2.7596e-01, -1.8827e-01],
          [ 2.1159e-02, -4.2691e-02, -6.9900e-03]],

         [[ 9.3633e-03, -2.0595e-01, -7.2182e-02],
          [-8.0752e-02, -1.5229e-01, -6.6759e-02],
          [-4.7090e-02,  2.8949e-02,  8.5161e-02]]],


        [[[ 6.9631e-02, -2.5175e-01,  9.7089e-02],
          [-1.9617e-01, -5.9522e-01, -2.0175e-01],
          [ 1.4720e-01, -4.0180e-03,  2.2899e-02]],

         [[ 1.4565e-01, -2.9062e-01,  3.9265e-02],
          [ 2.1673e-02, -2.9942e-01,  3.1932e-02],
          [ 1.7947e-01,  1.9463e-01,  4.6553e-02]],

         [[ 4.2388e-02, -2.5345e-01,  9.6881e-02],
          [ 7.6452e-02, -8.7614e-02,  9.5956e-02],
          [-6.9624e-02,  5.3727e-02,  9.4718e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0746,  0.0477,  0.0158],
          [ 0.0636,  0.0331,  0.0127],
          [ 0.0263,  0.0036, -0.0164]],

         [[ 0.0801,  0.0567,  0.0131],
          [ 0.0636,  0.0330,  0.0076],
          [ 0.0271,  0.0101, -0.0123]],

         [[ 0.0494,  0.0317, -0.0054],
          [ 0.0283,  0.0056, -0.0139],
          [ 0.0019, -0.0112, -0.0256]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0061,  0.0042,  0.0050],
          [ 0.0030,  0.0016,  0.0022],
          [ 0.0034,  0.0020,  0.0030]],

         [[ 0.0038,  0.0021,  0.0031],
          [ 0.0016,  0.0001,  0.0009],
          [ 0.0026,  0.0004,  0.0012]],

         [[ 0.0019,  0.0005,  0.0022],
          [ 0.0006, -0.0007,  0.0007],
          [ 0.0016, -0.0006,  0.0009]]],


        [[[ 0.0144,  0.0145,  0.0135],
          [ 0.0178,  0.0188,  0.0191],
          [ 0.0105,  0.0104,  0.0088]],

         [[ 0.0068,  0.0061,  0.0045],
          [ 0.0071,  0.0076,  0.0078],
          [-0.0022, -0.0027, -0.0039]],

         [[ 0.0019,  0.0021,  0.0005],
          [ 0.0002,  0.0030,  0.0037],
          [-0.0090, -0.0068, -0.0060]]],


        [[[ 0.0080,  0.0070,  0.0117],
          [-0.0020, -0.0038,  0.0029],
          [-0.0020, -0.0052,  0.0024]],

         [[ 0.0118,  0.0098,  0.0162],
          [ 0.0014, -0.0016,  0.0060],
          [-0.0018, -0.0070,  0.0008]],

         [[ 0.0068,  0.0053,  0.0105],
          [-0.0001, -0.0037,  0.0007],
          [-0.0053, -0.0099, -0.0055]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2646]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 152 | Batch_idx: 0 |  Loss: (0.1130) | Acc: (96.00%) (123/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.2102) | Acc: (92.00%) (1304/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.2241) | Acc: (92.00%) (2480/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.2189) | Acc: (92.00%) (3675/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.2203) | Acc: (92.00%) (4860/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.2208) | Acc: (92.00%) (6048/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.2195) | Acc: (92.00%) (7239/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.2205) | Acc: (92.00%) (8423/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.2183) | Acc: (92.00%) (9614/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.2171) | Acc: (92.00%) (10799/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.2182) | Acc: (92.00%) (11978/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.2170) | Acc: (92.00%) (13168/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.2172) | Acc: (92.00%) (14363/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.2176) | Acc: (92.00%) (15549/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.2176) | Acc: (92.00%) (16740/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.2180) | Acc: (92.00%) (17922/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.2190) | Acc: (92.00%) (19097/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.2201) | Acc: (92.00%) (20281/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.2180) | Acc: (92.00%) (21484/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.2160) | Acc: (92.00%) (22689/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.2145) | Acc: (92.00%) (23884/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.2127) | Acc: (92.00%) (25090/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.2120) | Acc: (92.00%) (26280/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.2114) | Acc: (92.00%) (27462/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.2112) | Acc: (92.00%) (28646/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.2106) | Acc: (92.00%) (29839/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.2098) | Acc: (92.00%) (31028/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.2098) | Acc: (92.00%) (32213/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.2102) | Acc: (92.00%) (33387/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.2109) | Acc: (92.00%) (34573/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.2104) | Acc: (92.00%) (35766/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.2098) | Acc: (92.00%) (36978/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.2094) | Acc: (92.00%) (38169/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.2093) | Acc: (92.00%) (39357/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.2095) | Acc: (92.00%) (40540/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.2086) | Acc: (92.00%) (41742/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.2087) | Acc: (92.00%) (42931/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.2088) | Acc: (92.00%) (44112/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.2097) | Acc: (92.00%) (45276/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.2100) | Acc: (92.00%) (46419/50000)
# TEST : Loss: (0.3442) | Acc: (89.00%) (8909/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-4.0664e-40, -1.4205e-40, -1.6313e-40],
          [-1.0626e-41,  1.3287e-40, -2.3289e-40],
          [ 1.3227e-40,  1.6729e-41,  1.3195e-41]],

         [[-1.8099e-40,  2.9534e-40, -1.3813e-40],
          [-1.5266e-40,  1.9362e-40,  4.8615e-41],
          [ 3.0900e-40,  2.7091e-40,  1.7159e-40]],

         [[ 4.7521e-41,  2.7763e-41,  9.7465e-41],
          [ 1.4231e-40,  3.1811e-40, -1.5146e-40],
          [-2.0856e-40, -1.6086e-40, -1.1080e-40]]],


        [[[ 3.9938e-01,  4.4477e-02,  3.0943e-01],
          [ 1.8772e-01, -2.0793e-03, -2.1263e-01],
          [-1.9471e-01, -3.9131e-01, -3.0006e-01]],

         [[-5.6853e-02, -3.1486e-01, -5.8543e-02],
          [-8.8221e-02,  4.1987e-01, -2.3294e-01],
          [ 2.2848e-01,  1.4640e-01,  2.5620e-01]],

         [[-1.6988e-01, -2.5691e-01, -5.5464e-02],
          [-2.3091e-01,  1.7667e-01, -4.1017e-02],
          [ 4.0248e-02,  1.7736e-01,  2.8143e-01]]],


        [[[ 6.5144e-41, -8.2985e-41, -4.0433e-41],
          [ 5.3738e-41, -1.3492e-40, -7.8789e-41],
          [ 6.4261e-41, -6.6380e-41,  8.1732e-41]],

         [[ 8.2270e-41,  8.0170e-41,  7.3023e-41],
          [ 9.1701e-41,  1.0230e-40, -7.1758e-41],
          [-2.7334e-41,  5.0639e-41,  6.8536e-41]],

         [[-4.6481e-42,  3.0928e-41, -5.9037e-42],
          [-6.9649e-41,  6.9866e-41, -3.4954e-41],
          [ 7.9529e-41, -8.2940e-41, -4.4166e-41]]],


        ...,


        [[[-3.8113e-03,  1.6660e-02, -3.8003e-02],
          [ 3.1157e-02,  6.9084e-02, -1.2749e-02],
          [-8.4887e-02,  5.8102e-02,  4.3577e-02]],

         [[-1.2076e-01, -1.3166e-01, -7.2848e-02],
          [ 9.4550e-02,  5.9436e-02, -1.0485e-01],
          [ 1.3875e-01,  7.8874e-02, -8.1776e-03]],

         [[ 3.3350e-02,  1.4701e-01,  8.3889e-02],
          [ 2.7734e-01,  3.5039e-01,  1.6610e-01],
          [ 1.8823e-01,  2.6022e-01,  5.6541e-02]]],


        [[[ 3.1149e-01,  1.4375e-02,  6.6005e-02],
          [ 1.1240e-01, -1.7384e-01, -1.2592e-01],
          [ 6.7855e-02,  6.6837e-02,  7.1449e-02]],

         [[ 9.0138e-03, -1.9681e-01, -9.2472e-03],
          [-7.3744e-02, -3.0149e-01, -2.0193e-01],
          [-2.9345e-03, -6.9328e-02, -2.3314e-02]],

         [[ 1.7989e-03, -2.2203e-01, -7.7098e-02],
          [-1.0231e-01, -1.8810e-01, -8.1711e-02],
          [-6.9884e-02,  1.3901e-03,  7.1699e-02]]],


        [[[ 5.4613e-02, -2.5874e-01,  9.2304e-02],
          [-1.9942e-01, -5.8594e-01, -2.0257e-01],
          [ 1.5251e-01,  1.2916e-02,  2.7882e-02]],

         [[ 1.3458e-01, -2.9368e-01,  3.6832e-02],
          [ 2.0522e-02, -2.9094e-01,  3.1425e-02],
          [ 1.8684e-01,  2.1134e-01,  5.0965e-02]],

         [[ 3.4994e-02, -2.5571e-01,  9.6201e-02],
          [ 8.1066e-02, -7.6470e-02,  9.9134e-02],
          [-5.5393e-02,  7.4905e-02,  1.0344e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0225, -0.0100, -0.0225],
          [-0.0455, -0.0289, -0.0450],
          [-0.0633, -0.0371, -0.0230]],

         [[-0.0142, -0.0007, -0.0049],
          [-0.0351, -0.0132, -0.0237],
          [-0.0470, -0.0225, -0.0064]],

         [[-0.0039,  0.0033, -0.0048],
          [-0.0325, -0.0160, -0.0317],
          [-0.0469, -0.0286, -0.0223]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0113,  0.0113,  0.0088],
          [ 0.0130,  0.0105,  0.0089],
          [ 0.0131,  0.0120,  0.0109]],

         [[ 0.0067,  0.0062,  0.0024],
          [ 0.0085,  0.0055,  0.0027],
          [ 0.0086,  0.0069,  0.0044]],

         [[-0.0013, -0.0012, -0.0050],
          [ 0.0009, -0.0013, -0.0045],
          [ 0.0011, -0.0005, -0.0036]]],


        [[[-0.0108, -0.0079, -0.0091],
          [-0.0130, -0.0078, -0.0104],
          [-0.0224, -0.0170, -0.0184]],

         [[-0.0057, -0.0027, -0.0045],
          [-0.0083, -0.0032, -0.0063],
          [-0.0179, -0.0125, -0.0150]],

         [[-0.0040, -0.0022, -0.0032],
          [-0.0055, -0.0021, -0.0042],
          [-0.0146, -0.0102, -0.0121]]],


        [[[-0.0072, -0.0038, -0.0041],
          [-0.0017,  0.0066,  0.0058],
          [ 0.0039,  0.0116,  0.0117]],

         [[-0.0065, -0.0019, -0.0004],
          [-0.0028,  0.0064,  0.0064],
          [ 0.0023,  0.0105,  0.0108]],

         [[-0.0042, -0.0000,  0.0033],
          [ 0.0027,  0.0081,  0.0073],
          [ 0.0110,  0.0154,  0.0123]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2640]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 153 | Batch_idx: 0 |  Loss: (0.2115) | Acc: (92.00%) (118/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1912) | Acc: (93.00%) (1315/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1919) | Acc: (93.00%) (2517/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1862) | Acc: (93.00%) (3721/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1790) | Acc: (94.00%) (4936/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1840) | Acc: (93.00%) (6130/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1826) | Acc: (93.00%) (7329/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1846) | Acc: (93.00%) (8526/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1888) | Acc: (93.00%) (9718/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1859) | Acc: (93.00%) (10912/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1852) | Acc: (93.00%) (12112/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1858) | Acc: (93.00%) (13303/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1845) | Acc: (93.00%) (14513/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1845) | Acc: (93.00%) (15712/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1842) | Acc: (93.00%) (16907/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1846) | Acc: (93.00%) (18107/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1850) | Acc: (93.00%) (19306/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1866) | Acc: (93.00%) (20505/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1883) | Acc: (93.00%) (21686/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1914) | Acc: (93.00%) (22850/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1904) | Acc: (93.00%) (24059/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1912) | Acc: (93.00%) (25258/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1923) | Acc: (93.00%) (26447/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1938) | Acc: (93.00%) (27628/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1943) | Acc: (93.00%) (28813/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1945) | Acc: (93.00%) (30005/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1947) | Acc: (93.00%) (31196/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1948) | Acc: (93.00%) (32387/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1963) | Acc: (93.00%) (33562/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1967) | Acc: (93.00%) (34748/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1971) | Acc: (93.00%) (35933/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1978) | Acc: (93.00%) (37123/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1987) | Acc: (93.00%) (38309/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.2004) | Acc: (93.00%) (39478/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1996) | Acc: (93.00%) (40677/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1991) | Acc: (93.00%) (41875/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1987) | Acc: (93.00%) (43076/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1991) | Acc: (93.00%) (44258/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1991) | Acc: (93.00%) (45440/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1993) | Acc: (93.00%) (46594/50000)
# TEST : Loss: (0.3343) | Acc: (89.00%) (8925/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-7.3397e-41, -1.5714e-40,  2.6548e-40],
          [ 1.2533e-40,  2.1382e-40,  1.4561e-40],
          [-1.8977e-40, -1.1087e-40, -1.8166e-40]],

         [[ 1.6323e-40, -3.2503e-40,  6.2386e-41],
          [ 1.9172e-40,  1.4181e-40,  5.2954e-41],
          [-3.0802e-40, -3.3686e-40, -1.6896e-40]],

         [[-1.7324e-41,  9.9700e-41, -1.6515e-40],
          [-2.7495e-40,  2.7497e-40,  2.0187e-40],
          [ 2.8574e-40,  1.9312e-40,  2.7346e-41]]],


        [[[ 3.9065e-01,  4.3437e-02,  3.1168e-01],
          [ 1.8053e-01, -1.1252e-03, -2.1382e-01],
          [-1.9983e-01, -3.9792e-01, -3.0427e-01]],

         [[-6.1891e-02, -3.1335e-01, -5.3063e-02],
          [-9.2266e-02,  4.2579e-01, -2.2916e-01],
          [ 2.2728e-01,  1.4683e-01,  2.6028e-01]],

         [[-1.7903e-01, -2.6031e-01, -5.4005e-02],
          [-2.4138e-01,  1.7660e-01, -4.2175e-02],
          [ 3.4958e-02,  1.7335e-01,  2.7848e-01]]],


        [[[ 7.9144e-41,  9.1027e-41, -1.1134e-40],
          [-6.8647e-41,  4.6173e-41, -7.5869e-41],
          [-1.1902e-40, -3.4452e-41,  1.1072e-40]],

         [[ 6.4178e-41,  9.6601e-41, -1.2655e-41],
          [ 8.5552e-41,  9.0894e-41, -5.7163e-41],
          [ 8.3634e-41, -8.2195e-41,  8.2799e-41]],

         [[ 2.8893e-41,  5.6350e-41,  3.4871e-41],
          [-6.0444e-41, -4.1460e-41, -4.6229e-42],
          [-8.5710e-41, -5.3645e-41,  1.4299e-41]]],


        ...,


        [[[ 1.6329e-02,  2.9723e-02, -3.1098e-02],
          [ 3.4954e-02,  6.9431e-02, -1.4122e-02],
          [-7.7747e-02,  6.6835e-02,  5.1775e-02]],

         [[-1.0240e-01, -1.2102e-01, -7.3696e-02],
          [ 9.8315e-02,  6.0318e-02, -1.0914e-01],
          [ 1.5145e-01,  9.5480e-02,  2.9637e-03]],

         [[ 4.1306e-02,  1.4933e-01,  7.7773e-02],
          [ 2.6906e-01,  3.3827e-01,  1.5459e-01],
          [ 1.9952e-01,  2.8350e-01,  6.7855e-02]]],


        [[[ 3.2117e-01,  2.5120e-02,  7.3428e-02],
          [ 1.2488e-01, -1.5957e-01, -1.1473e-01],
          [ 7.5882e-02,  7.7663e-02,  8.7564e-02]],

         [[ 1.5483e-02, -1.9279e-01, -1.5241e-02],
          [-6.6726e-02, -2.9209e-01, -2.0306e-01],
          [-3.7920e-03, -6.5518e-02, -1.8556e-02]],

         [[ 6.9941e-03, -2.1433e-01, -8.1957e-02],
          [-1.0171e-01, -1.8384e-01, -9.0434e-02],
          [-7.9119e-02, -2.5927e-03,  7.0314e-02]]],


        [[[ 5.5949e-02, -2.6047e-01,  8.4473e-02],
          [-2.0908e-01, -5.9823e-01, -2.1507e-01],
          [ 1.3997e-01,  1.8414e-03,  1.8250e-02]],

         [[ 1.4282e-01, -2.8773e-01,  3.6251e-02],
          [ 1.9969e-02, -2.9105e-01,  2.9211e-02],
          [ 1.7921e-01,  2.0557e-01,  4.8295e-02]],

         [[ 5.2814e-02, -2.3875e-01,  1.0802e-01],
          [ 9.4890e-02, -5.9517e-02,  1.1223e-01],
          [-4.8424e-02,  8.3455e-02,  1.1195e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0320,  0.1270,  0.1416],
          [ 0.0924,  0.1554,  0.1358],
          [ 0.1331,  0.1364,  0.1408]],

         [[ 0.0140,  0.1142,  0.1260],
          [ 0.0785,  0.1410,  0.1289],
          [ 0.1211,  0.1212,  0.1161]],

         [[ 0.0378,  0.1240,  0.1345],
          [ 0.0917,  0.1514,  0.1387],
          [ 0.1364,  0.1348,  0.1308]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0200,  0.0238,  0.0205],
          [ 0.0144,  0.0158,  0.0111],
          [ 0.0104,  0.0104,  0.0046]],

         [[ 0.0134,  0.0159,  0.0103],
          [ 0.0052,  0.0058, -0.0010],
          [-0.0014, -0.0022, -0.0094]],

         [[ 0.0111,  0.0127,  0.0066],
          [ 0.0032,  0.0031, -0.0036],
          [-0.0033, -0.0046, -0.0111]]],


        [[[-0.0031, -0.0053, -0.0012],
          [-0.0032, -0.0025, -0.0008],
          [-0.0033,  0.0001,  0.0023]],

         [[-0.0054, -0.0046, -0.0016],
          [-0.0054, -0.0021, -0.0006],
          [-0.0062, -0.0007,  0.0020]],

         [[-0.0007,  0.0008,  0.0028],
          [-0.0003,  0.0033,  0.0036],
          [-0.0013,  0.0035,  0.0055]]],


        [[[ 0.0301,  0.0164,  0.0110],
          [ 0.0305,  0.0113,  0.0072],
          [ 0.0307,  0.0241,  0.0143]],

         [[ 0.0199,  0.0071,  0.0030],
          [ 0.0213,  0.0040,  0.0016],
          [ 0.0271,  0.0200,  0.0115]],

         [[ 0.0150,  0.0019, -0.0019],
          [ 0.0145, -0.0015, -0.0024],
          [ 0.0182,  0.0113,  0.0060]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2632]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 154 | Batch_idx: 0 |  Loss: (0.1605) | Acc: (94.00%) (121/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1543) | Acc: (94.00%) (1329/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1684) | Acc: (94.00%) (2533/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1599) | Acc: (94.00%) (3752/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1663) | Acc: (94.00%) (4949/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1731) | Acc: (94.00%) (6142/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1769) | Acc: (94.00%) (7344/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1766) | Acc: (94.00%) (8553/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1803) | Acc: (93.00%) (9744/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1781) | Acc: (94.00%) (10958/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1765) | Acc: (94.00%) (12164/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1750) | Acc: (94.00%) (13373/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1747) | Acc: (94.00%) (14564/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1781) | Acc: (93.00%) (15750/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1769) | Acc: (93.00%) (16949/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1764) | Acc: (93.00%) (18158/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1751) | Acc: (94.00%) (19374/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1740) | Acc: (94.00%) (20587/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1733) | Acc: (94.00%) (21790/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1740) | Acc: (94.00%) (22992/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1769) | Acc: (93.00%) (24179/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1775) | Acc: (93.00%) (25379/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1778) | Acc: (93.00%) (26581/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1786) | Acc: (93.00%) (27767/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1795) | Acc: (93.00%) (28960/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1803) | Acc: (93.00%) (30148/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1816) | Acc: (93.00%) (31339/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1827) | Acc: (93.00%) (32528/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1824) | Acc: (93.00%) (33725/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1828) | Acc: (93.00%) (34922/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1823) | Acc: (93.00%) (36127/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1833) | Acc: (93.00%) (37313/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1835) | Acc: (93.00%) (38512/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1846) | Acc: (93.00%) (39698/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1839) | Acc: (93.00%) (40905/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1837) | Acc: (93.00%) (42108/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1832) | Acc: (93.00%) (43323/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1835) | Acc: (93.00%) (44509/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1837) | Acc: (93.00%) (45706/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1835) | Acc: (93.00%) (46858/50000)
# TEST : Loss: (0.3360) | Acc: (89.00%) (8949/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-3.2475e-40, -9.5793e-42,  2.0968e-40],
          [-1.6426e-40, -2.0273e-40,  1.2504e-41],
          [-1.3446e-40,  1.6184e-40,  2.3231e-40]],

         [[ 1.0087e-40,  4.1470e-41, -1.0494e-41],
          [-2.6264e-40, -2.0963e-42,  5.8571e-41],
          [ 2.1647e-40, -2.1478e-40, -2.7160e-41]],

         [[-9.5861e-41,  1.0999e-40,  1.9561e-40],
          [ 1.7603e-40, -3.3949e-40, -2.6188e-40],
          [ 7.0847e-41,  1.3145e-40,  2.8138e-41]]],


        [[[ 3.8991e-01,  4.9145e-02,  3.0917e-01],
          [ 1.7999e-01, -6.4779e-03, -2.2327e-01],
          [-2.0359e-01, -4.0100e-01, -3.1168e-01]],

         [[-6.2337e-02, -3.0592e-01, -5.1407e-02],
          [-9.1033e-02,  4.2609e-01, -2.3158e-01],
          [ 2.2617e-01,  1.5190e-01,  2.6335e-01]],

         [[-1.7288e-01, -2.4980e-01, -4.5109e-02],
          [-2.3862e-01,  1.7970e-01, -3.6858e-02],
          [ 3.0729e-02,  1.8172e-01,  2.9080e-01]]],


        [[[ 1.5624e-40,  9.8747e-41, -1.3422e-40],
          [ 2.3142e-41,  1.6700e-40,  9.8490e-41],
          [-1.9551e-41,  1.2102e-41, -9.4132e-41]],

         [[-9.7788e-41, -8.0451e-41, -1.0310e-40],
          [-3.2633e-41,  6.0382e-41, -6.8395e-41],
          [-6.8818e-41, -6.2892e-41,  6.5322e-41]],

         [[ 3.5435e-41, -4.5639e-41, -9.9170e-41],
          [-9.4057e-41,  5.8045e-41, -2.8972e-41],
          [-1.0266e-40,  4.0705e-41,  8.4046e-41]]],


        ...,


        [[[-2.1524e-02,  2.7609e-03, -4.6915e-02],
          [ 6.6401e-03,  5.2069e-02, -2.4236e-02],
          [-1.0512e-01,  4.5417e-02,  3.5475e-02]],

         [[-1.4080e-01, -1.4347e-01, -8.3730e-02],
          [ 6.8322e-02,  4.8307e-02, -1.1264e-01],
          [ 1.2217e-01,  7.6129e-02, -8.2216e-03]],

         [[ 1.3231e-02,  1.3883e-01,  7.9944e-02],
          [ 2.5439e-01,  3.6004e-01,  1.7328e-01],
          [ 1.8371e-01,  2.8599e-01,  7.6652e-02]]],


        [[[ 3.0935e-01,  1.5329e-02,  6.8240e-02],
          [ 1.1535e-01, -1.7189e-01, -1.2141e-01],
          [ 7.3358e-02,  7.3087e-02,  9.1082e-02]],

         [[ 9.3342e-03, -1.9650e-01, -1.0896e-02],
          [-7.5002e-02, -3.0577e-01, -2.0267e-01],
          [-8.4039e-03, -6.9780e-02, -9.8073e-03]],

         [[-1.4396e-03, -2.2024e-01, -7.5580e-02],
          [-1.1459e-01, -2.0403e-01, -8.7645e-02],
          [-8.3666e-02, -3.5882e-03,  8.2888e-02]]],


        [[[ 5.3668e-02, -2.7354e-01,  7.1163e-02],
          [-2.0268e-01, -5.9997e-01, -2.1329e-01],
          [ 1.4099e-01, -2.7066e-03,  2.1658e-02]],

         [[ 1.3666e-01, -3.0218e-01,  2.2198e-02],
          [ 1.8674e-02, -2.9766e-01,  2.7713e-02],
          [ 1.7660e-01,  1.9913e-01,  4.9079e-02]],

         [[ 3.4069e-02, -2.6094e-01,  8.9999e-02],
          [ 8.2033e-02, -7.4362e-02,  1.0553e-01],
          [-5.7220e-02,  7.4064e-02,  1.0954e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0093, -0.0009, -0.0037],
          [-0.0057, -0.0038,  0.0095],
          [-0.0126, -0.0091,  0.0103]],

         [[-0.0121, -0.0166, -0.0127],
          [-0.0188, -0.0135, -0.0012],
          [-0.0182, -0.0156, -0.0013]],

         [[-0.0003,  0.0015,  0.0003],
          [-0.0037,  0.0047,  0.0113],
          [-0.0086, -0.0047,  0.0067]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0006,  0.0025,  0.0019],
          [ 0.0016,  0.0032,  0.0029],
          [ 0.0005,  0.0009,  0.0016]],

         [[-0.0004,  0.0015,  0.0012],
          [ 0.0008,  0.0022,  0.0016],
          [-0.0000,  0.0002,  0.0009]],

         [[-0.0005,  0.0006,  0.0002],
          [-0.0001,  0.0009,  0.0008],
          [-0.0009, -0.0006,  0.0003]]],


        [[[-0.0108, -0.0112, -0.0125],
          [-0.0035, -0.0050, -0.0064],
          [-0.0018, -0.0039, -0.0055]],

         [[-0.0097, -0.0081, -0.0089],
          [-0.0030, -0.0029, -0.0035],
          [-0.0021, -0.0030, -0.0032]],

         [[-0.0055, -0.0027, -0.0033],
          [ 0.0003,  0.0021,  0.0016],
          [-0.0003,  0.0009,  0.0010]]],


        [[[ 0.0006, -0.0034, -0.0085],
          [ 0.0006,  0.0016, -0.0026],
          [ 0.0003,  0.0039, -0.0028]],

         [[ 0.0030,  0.0010, -0.0035],
          [ 0.0012,  0.0029,  0.0012],
          [ 0.0006,  0.0044,  0.0006]],

         [[-0.0072, -0.0121, -0.0155],
          [-0.0067, -0.0075, -0.0093],
          [-0.0057, -0.0027, -0.0064]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2622]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 155 | Batch_idx: 0 |  Loss: (0.1354) | Acc: (94.00%) (121/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.2003) | Acc: (92.00%) (1309/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1973) | Acc: (92.00%) (2497/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1983) | Acc: (92.00%) (3674/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.2067) | Acc: (92.00%) (4866/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.2034) | Acc: (92.00%) (6060/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1986) | Acc: (93.00%) (7267/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1941) | Acc: (93.00%) (8471/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1883) | Acc: (93.00%) (9687/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1881) | Acc: (93.00%) (10879/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1843) | Acc: (93.00%) (12104/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1818) | Acc: (93.00%) (13315/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1801) | Acc: (93.00%) (14526/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1795) | Acc: (93.00%) (15738/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1788) | Acc: (93.00%) (16941/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1764) | Acc: (93.00%) (18155/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1767) | Acc: (93.00%) (19360/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1757) | Acc: (93.00%) (20566/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1753) | Acc: (93.00%) (21765/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1762) | Acc: (93.00%) (22955/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1764) | Acc: (93.00%) (24160/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1761) | Acc: (93.00%) (25365/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1752) | Acc: (93.00%) (26577/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1750) | Acc: (93.00%) (27782/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1737) | Acc: (94.00%) (29002/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1737) | Acc: (94.00%) (30204/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1740) | Acc: (93.00%) (31400/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1731) | Acc: (94.00%) (32614/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1734) | Acc: (93.00%) (33806/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1734) | Acc: (93.00%) (35011/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1725) | Acc: (94.00%) (36229/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1719) | Acc: (94.00%) (37444/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1710) | Acc: (94.00%) (38658/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1702) | Acc: (94.00%) (39876/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1697) | Acc: (94.00%) (41088/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1696) | Acc: (94.00%) (42295/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1688) | Acc: (94.00%) (43520/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1685) | Acc: (94.00%) (44735/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1682) | Acc: (94.00%) (45944/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1680) | Acc: (94.00%) (47107/50000)
# TEST : Loss: (0.2929) | Acc: (90.00%) (9066/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 4.4211e-40,  1.6474e-40, -2.9793e-40],
          [-1.3189e-41,  1.7704e-40,  2.5499e-40],
          [ 1.3923e-41,  2.5465e-40,  1.7434e-40]],

         [[-6.1835e-41, -3.8402e-40, -9.6593e-41],
          [-1.9707e-40, -1.7295e-40, -2.8071e-40],
          [ 6.4080e-41,  3.5542e-40,  1.4327e-40]],

         [[-1.0601e-40,  3.8006e-41, -1.9557e-40],
          [ 1.8961e-40,  3.2784e-40, -1.9442e-40],
          [ 4.2530e-40, -3.0491e-41,  2.0424e-40]]],


        [[[ 3.8763e-01,  4.5884e-02,  3.0421e-01],
          [ 1.7815e-01, -9.7850e-03, -2.2764e-01],
          [-2.0483e-01, -4.0345e-01, -3.1450e-01]],

         [[-6.3557e-02, -3.0806e-01, -5.5362e-02],
          [-9.2041e-02,  4.2322e-01, -2.3530e-01],
          [ 2.2514e-01,  1.4958e-01,  2.6037e-01]],

         [[-1.7408e-01, -2.5232e-01, -4.8509e-02],
          [-2.3954e-01,  1.7659e-01, -4.0756e-02],
          [ 2.9882e-02,  1.7894e-01,  2.8712e-01]]],


        [[[ 6.2436e-41, -1.2174e-40, -8.9614e-41],
          [ 2.8692e-41,  8.9445e-42,  3.2469e-41],
          [ 3.2374e-41,  1.5093e-41, -5.2734e-41]],

         [[-2.7908e-41,  7.7779e-41,  3.0227e-41],
          [-4.1173e-41, -9.0136e-41,  1.2033e-40],
          [ 5.9676e-41, -7.6425e-41, -1.0826e-40]],

         [[-8.3466e-41,  8.1778e-41,  1.0980e-40],
          [-7.0925e-41, -7.7436e-42,  1.0320e-40],
          [-4.5991e-42, -5.2701e-41, -5.9499e-41]]],


        ...,


        [[[-2.1418e-02,  2.9112e-03, -4.6540e-02],
          [ 6.8101e-03,  5.2661e-02, -2.4075e-02],
          [-1.0306e-01,  4.5884e-02,  3.4685e-02]],

         [[-1.3907e-01, -1.4181e-01, -8.2791e-02],
          [ 6.8349e-02,  4.9461e-02, -1.1108e-01],
          [ 1.2314e-01,  7.6772e-02, -8.4409e-03]],

         [[ 1.2955e-02,  1.3630e-01,  7.7955e-02],
          [ 2.4910e-01,  3.5028e-01,  1.6860e-01],
          [ 1.8222e-01,  2.7760e-01,  7.3173e-02]]],


        [[[ 3.0949e-01,  1.6970e-02,  6.8293e-02],
          [ 1.1633e-01, -1.6945e-01, -1.2128e-01],
          [ 7.4093e-02,  7.3367e-02,  8.9396e-02]],

         [[ 1.0621e-02, -1.9317e-01, -1.0369e-02],
          [-7.3192e-02, -3.0110e-01, -2.0170e-01],
          [-7.9766e-03, -6.9402e-02, -1.1618e-02]],

         [[-7.8433e-04, -2.1669e-01, -7.5189e-02],
          [-1.1322e-01, -2.0040e-01, -8.9124e-02],
          [-8.3442e-02, -4.9033e-03,  7.9134e-02]]],


        [[[ 5.0648e-02, -2.7531e-01,  6.9514e-02],
          [-2.0423e-01, -6.0019e-01, -2.1431e-01],
          [ 1.3755e-01, -6.5357e-03,  1.9012e-02]],

         [[ 1.3340e-01, -3.0427e-01,  2.0169e-02],
          [ 1.6236e-02, -2.9981e-01,  2.5132e-02],
          [ 1.7314e-01,  1.9465e-01,  4.5796e-02]],

         [[ 3.2685e-02, -2.6121e-01,  8.9074e-02],
          [ 8.0907e-02, -7.5439e-02,  1.0407e-01],
          [-5.8787e-02,  7.1138e-02,  1.0721e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2305]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0075]], device='cuda:0')

Epoch: 156 | Batch_idx: 0 |  Loss: (0.1353) | Acc: (96.00%) (124/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1444) | Acc: (95.00%) (1343/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1471) | Acc: (95.00%) (2556/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1487) | Acc: (94.00%) (3763/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1518) | Acc: (94.00%) (4976/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1512) | Acc: (94.00%) (6191/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.1535) | Acc: (94.00%) (7401/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.1556) | Acc: (94.00%) (8612/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.1554) | Acc: (94.00%) (9826/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.1569) | Acc: (94.00%) (11031/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.1547) | Acc: (94.00%) (12248/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.1543) | Acc: (94.00%) (13467/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.1552) | Acc: (94.00%) (14671/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.1556) | Acc: (94.00%) (15878/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.1556) | Acc: (94.00%) (17090/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.1546) | Acc: (94.00%) (18309/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.1554) | Acc: (94.00%) (19506/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.1553) | Acc: (94.00%) (20724/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.1544) | Acc: (94.00%) (21951/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.1555) | Acc: (94.00%) (23154/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.1546) | Acc: (94.00%) (24380/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.1538) | Acc: (94.00%) (25601/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.1539) | Acc: (94.00%) (26816/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.1543) | Acc: (94.00%) (28020/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.1540) | Acc: (94.00%) (29235/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.1532) | Acc: (94.00%) (30461/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.1537) | Acc: (94.00%) (31664/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.1538) | Acc: (94.00%) (32877/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.1535) | Acc: (94.00%) (34101/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.1539) | Acc: (94.00%) (35295/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.1547) | Acc: (94.00%) (36498/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.1557) | Acc: (94.00%) (37689/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.1556) | Acc: (94.00%) (38900/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.1557) | Acc: (94.00%) (40110/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.1559) | Acc: (94.00%) (41328/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.1563) | Acc: (94.00%) (42535/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.1570) | Acc: (94.00%) (43736/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.1565) | Acc: (94.00%) (44951/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.1561) | Acc: (94.00%) (46174/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.1559) | Acc: (94.00%) (47347/50000)
# TEST : Loss: (0.2881) | Acc: (90.00%) (9072/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-2.8142e-40,  2.7076e-40, -4.1287e-40],
          [ 1.6439e-40,  2.7689e-40, -2.4967e-40],
          [ 1.8903e-40,  1.9016e-40,  1.6657e-41]],

         [[ 2.4036e-41, -3.1961e-40, -1.0290e-40],
          [ 1.5645e-40, -2.7752e-40,  2.5362e-40],
          [ 7.0155e-41,  1.9955e-40,  1.5462e-40]],

         [[-2.7437e-41, -4.7355e-41, -2.0984e-40],
          [ 1.0997e-40,  2.5978e-40, -2.0776e-40],
          [-1.1258e-41, -2.2043e-40,  2.1940e-40]]],


        [[[ 3.8717e-01,  4.5831e-02,  3.0385e-01],
          [ 1.7793e-01, -9.7733e-03, -2.2737e-01],
          [-2.0458e-01, -4.0296e-01, -3.1413e-01]],

         [[-6.3481e-02, -3.0769e-01, -5.5297e-02],
          [-9.1926e-02,  4.2270e-01, -2.3501e-01],
          [ 2.2485e-01,  1.4939e-01,  2.6005e-01]],

         [[-1.7386e-01, -2.5200e-01, -4.8448e-02],
          [-2.3923e-01,  1.7636e-01, -4.0704e-02],
          [ 2.9842e-02,  1.7870e-01,  2.8674e-01]]],


        [[[ 7.5707e-41,  1.2828e-40,  7.7136e-41],
          [-1.1484e-40, -2.1227e-40,  1.0838e-40],
          [-1.2358e-40, -5.9723e-41,  1.6233e-40]],

         [[-9.2041e-41, -5.4362e-41, -5.6970e-41],
          [ 1.1922e-40, -3.8861e-41,  1.4374e-40],
          [ 2.9672e-41,  1.3470e-40, -4.9520e-41]],

         [[-3.9746e-41, -3.2762e-41, -1.0735e-40],
          [ 5.3432e-42,  8.4197e-41,  8.9888e-41],
          [ 1.1065e-40,  8.9200e-41, -9.3614e-41]]],


        ...,


        [[[-2.1234e-02,  2.8863e-03, -4.6157e-02],
          [ 6.7452e-03,  5.2160e-02, -2.3853e-02],
          [-1.0210e-01,  4.5459e-02,  3.4377e-02]],

         [[-1.3754e-01, -1.4026e-01, -8.1953e-02],
          [ 6.7358e-02,  4.8729e-02, -1.0964e-01],
          [ 1.2141e-01,  7.5677e-02, -8.3372e-03]],

         [[ 1.2776e-02,  1.3437e-01,  7.6973e-02],
          [ 2.4200e-01,  3.3784e-01,  1.6503e-01],
          [ 1.7721e-01,  2.6795e-01,  7.1743e-02]]],


        [[[ 3.0769e-01,  1.6861e-02,  6.7849e-02],
          [ 1.1561e-01, -1.6826e-01, -1.2043e-01],
          [ 7.3658e-02,  7.2917e-02,  8.8846e-02]],

         [[ 1.0541e-02, -1.9129e-01, -1.0271e-02],
          [-7.2567e-02, -2.9726e-01, -1.9933e-01],
          [-7.9180e-03, -6.8816e-02, -1.1525e-02]],

         [[-7.7683e-04, -2.1369e-01, -7.4217e-02],
          [-1.1191e-01, -1.9603e-01, -8.7562e-02],
          [-8.2664e-02, -4.8478e-03,  7.8322e-02]]],


        [[[ 5.0463e-02, -2.7390e-01,  6.9252e-02],
          [-2.0349e-01, -5.9720e-01, -2.1351e-01],
          [ 1.3717e-01, -6.5161e-03,  1.8959e-02]],

         [[ 1.3297e-01, -3.0305e-01,  2.0103e-02],
          [ 1.6184e-02, -2.9865e-01,  2.5051e-02],
          [ 1.7269e-01,  1.9411e-01,  4.5677e-02]],

         [[ 3.2580e-02, -2.6027e-01,  8.8788e-02],
          [ 8.0652e-02, -7.5175e-02,  1.0375e-01],
          [-5.8630e-02,  7.0941e-02,  1.0693e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2106]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0342]], device='cuda:0')

Epoch: 157 | Batch_idx: 0 |  Loss: (0.1896) | Acc: (93.00%) (120/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.1472) | Acc: (95.00%) (1345/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.1470) | Acc: (95.00%) (2560/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1355) | Acc: (95.00%) (3795/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1427) | Acc: (95.00%) (5004/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1438) | Acc: (95.00%) (6215/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1452) | Acc: (95.00%) (7423/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1440) | Acc: (95.00%) (8639/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1475) | Acc: (94.00%) (9844/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1478) | Acc: (94.00%) (11059/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1482) | Acc: (94.00%) (12275/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1481) | Acc: (94.00%) (13487/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1474) | Acc: (94.00%) (14706/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1475) | Acc: (94.00%) (15923/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1456) | Acc: (95.00%) (17151/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1443) | Acc: (95.00%) (18380/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1445) | Acc: (95.00%) (19595/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1450) | Acc: (95.00%) (20803/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1453) | Acc: (95.00%) (22016/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1468) | Acc: (94.00%) (23219/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1470) | Acc: (94.00%) (24436/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1469) | Acc: (94.00%) (25651/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1472) | Acc: (94.00%) (26860/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1483) | Acc: (94.00%) (28065/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1482) | Acc: (94.00%) (29279/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1486) | Acc: (94.00%) (30493/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1488) | Acc: (94.00%) (31707/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1488) | Acc: (94.00%) (32922/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1490) | Acc: (94.00%) (34138/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1492) | Acc: (94.00%) (35363/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1498) | Acc: (94.00%) (36565/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1504) | Acc: (94.00%) (37768/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1505) | Acc: (94.00%) (38984/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1503) | Acc: (94.00%) (40197/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1507) | Acc: (94.00%) (41391/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1505) | Acc: (94.00%) (42604/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1504) | Acc: (94.00%) (43817/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1507) | Acc: (94.00%) (45035/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1509) | Acc: (94.00%) (46244/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1501) | Acc: (94.00%) (47437/50000)
# TEST : Loss: (0.2822) | Acc: (90.00%) (9077/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 5.0249e-40,  1.8807e-40, -4.3821e-40],
          [ 2.7176e-40,  2.0292e-40, -2.6847e-40],
          [ 2.9537e-40,  2.1083e-41, -1.6705e-40]],

         [[ 1.2188e-40,  3.4768e-40, -1.0454e-41],
          [-2.9891e-41, -1.9777e-40,  1.7143e-40],
          [ 1.7235e-40, -7.8141e-41, -3.1114e-41]],

         [[-2.9455e-41, -1.4529e-40, -3.5278e-41],
          [ 1.1743e-40,  2.7671e-40, -2.3299e-41],
          [ 8.8664e-41, -2.3471e-40,  3.3446e-41]]],


        [[[ 3.8662e-01,  4.5766e-02,  3.0343e-01],
          [ 1.7767e-01, -9.7591e-03, -2.2704e-01],
          [-2.0427e-01, -4.0238e-01, -3.1369e-01]],

         [[-6.3389e-02, -3.0724e-01, -5.5217e-02],
          [-9.1787e-02,  4.2207e-01, -2.3466e-01],
          [ 2.2450e-01,  1.4917e-01,  2.5966e-01]],

         [[-1.7359e-01, -2.5161e-01, -4.8374e-02],
          [-2.3885e-01,  1.7608e-01, -4.0641e-02],
          [ 2.9794e-02,  1.7841e-01,  2.8630e-01]]],


        [[[ 2.1883e-41, -1.2522e-40, -6.2007e-41],
          [ 2.3820e-40,  1.4936e-40, -1.1570e-40],
          [-1.9366e-42,  5.5884e-42,  2.1416e-41]],

         [[-3.9256e-41, -6.4558e-41, -3.9950e-41],
          [-5.8897e-42,  1.5230e-40, -7.2692e-41],
          [-1.3769e-41,  6.3106e-41,  1.6797e-40]],

         [[ 9.6479e-41, -1.0468e-40, -1.2732e-40],
          [-8.8785e-41, -4.9459e-41, -1.2801e-40],
          [-7.6093e-41, -2.9525e-42,  6.7840e-41]]],


        ...,


        [[[-2.1012e-02,  2.8564e-03, -4.5695e-02],
          [ 6.6671e-03,  5.1556e-02, -2.3586e-02],
          [-1.0094e-01,  4.4947e-02,  3.4005e-02]],

         [[-1.3570e-01, -1.3839e-01, -8.0947e-02],
          [ 6.6171e-02,  4.7855e-02, -1.0792e-01],
          [ 1.1934e-01,  7.4365e-02, -8.2127e-03]],

         [[ 1.2562e-02,  1.3206e-01,  7.5795e-02],
          [ 2.3364e-01,  3.2332e-01,  1.6080e-01],
          [ 1.7131e-01,  2.5665e-01,  7.0041e-02]]],


        [[[ 3.0552e-01,  1.6731e-02,  6.7313e-02],
          [ 1.1475e-01, -1.6683e-01, -1.1940e-01],
          [ 7.3133e-02,  7.2372e-02,  8.8183e-02]],

         [[ 1.0444e-02, -1.8903e-01, -1.0154e-02],
          [-7.1814e-02, -2.9266e-01, -1.9650e-01],
          [-7.8472e-03, -6.8109e-02, -1.1413e-02]],

         [[-7.6782e-04, -2.1008e-01, -7.3051e-02],
          [-1.1034e-01, -1.9085e-01, -8.5700e-02],
          [-8.1727e-02, -4.7811e-03,  7.7345e-02]]],


        [[[ 5.0239e-02, -2.7219e-01,  6.8935e-02],
          [-2.0260e-01, -5.9357e-01, -2.1256e-01],
          [ 1.3670e-01, -6.4923e-03,  1.8895e-02]],

         [[ 1.3245e-01, -3.0159e-01,  2.0022e-02],
          [ 1.6121e-02, -2.9724e-01,  2.4953e-02],
          [ 1.7214e-01,  1.9346e-01,  4.5534e-02]],

         [[ 3.2454e-02, -2.5913e-01,  8.8443e-02],
          [ 8.0344e-02, -7.4855e-02,  1.0336e-01],
          [-5.8440e-02,  7.0702e-02,  1.0659e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2269]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0536]], device='cuda:0')

Epoch: 158 | Batch_idx: 0 |  Loss: (0.1846) | Acc: (91.00%) (117/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.1602) | Acc: (94.00%) (1331/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.1806) | Acc: (93.00%) (2526/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.1742) | Acc: (94.00%) (3738/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.1719) | Acc: (94.00%) (4947/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.1654) | Acc: (94.00%) (6166/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.1632) | Acc: (94.00%) (7376/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.1626) | Acc: (94.00%) (8586/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.1602) | Acc: (94.00%) (9803/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1610) | Acc: (94.00%) (11013/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1617) | Acc: (94.00%) (12218/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1588) | Acc: (94.00%) (13447/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1576) | Acc: (94.00%) (14666/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1570) | Acc: (94.00%) (15878/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1568) | Acc: (94.00%) (17096/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1562) | Acc: (94.00%) (18312/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1554) | Acc: (94.00%) (19535/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1551) | Acc: (94.00%) (20751/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1554) | Acc: (94.00%) (21969/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1552) | Acc: (94.00%) (23175/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1557) | Acc: (94.00%) (24391/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1548) | Acc: (94.00%) (25618/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1538) | Acc: (94.00%) (26844/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1550) | Acc: (94.00%) (28044/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1554) | Acc: (94.00%) (29260/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1556) | Acc: (94.00%) (30480/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1558) | Acc: (94.00%) (31689/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1556) | Acc: (94.00%) (32895/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1552) | Acc: (94.00%) (34121/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1553) | Acc: (94.00%) (35343/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1550) | Acc: (94.00%) (36553/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1557) | Acc: (94.00%) (37763/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1561) | Acc: (94.00%) (38975/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1561) | Acc: (94.00%) (40185/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1562) | Acc: (94.00%) (41389/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1558) | Acc: (94.00%) (42613/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1557) | Acc: (94.00%) (43820/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1555) | Acc: (94.00%) (45030/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1556) | Acc: (94.00%) (46242/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1554) | Acc: (94.00%) (47419/50000)
# TEST : Loss: (0.2796) | Acc: (90.00%) (9063/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 4.2447e-40, -1.2849e-41,  6.2785e-41],
          [ 1.8588e-40, -2.7700e-40,  1.3737e-41],
          [ 2.1546e-40, -2.6743e-40,  2.1429e-40]],

         [[ 1.2740e-40, -2.5674e-40,  9.3439e-41],
          [-2.3912e-40,  2.0328e-40, -4.4159e-40],
          [ 1.8187e-40,  2.2436e-40, -2.3984e-40]],

         [[ 7.0913e-41, -1.5397e-40,  1.6345e-40],
          [ 2.2832e-40,  8.3473e-41,  1.8396e-40],
          [ 4.0932e-40, -3.8077e-41, -1.7509e-40]]],


        [[[ 3.8595e-01,  4.5687e-02,  3.0291e-01],
          [ 1.7735e-01, -9.7418e-03, -2.2664e-01],
          [-2.0390e-01, -4.0166e-01, -3.1314e-01]],

         [[-6.3277e-02, -3.0670e-01, -5.5120e-02],
          [-9.1618e-02,  4.2130e-01, -2.3424e-01],
          [ 2.2408e-01,  1.4889e-01,  2.5919e-01]],

         [[-1.7326e-01, -2.5113e-01, -4.8283e-02],
          [-2.3839e-01,  1.7575e-01, -4.0564e-02],
          [ 2.9735e-02,  1.7806e-01,  2.8575e-01]]],


        [[[-5.6118e-41,  1.2267e-40,  1.5552e-41],
          [-5.6329e-41,  1.7365e-40,  5.4794e-41],
          [ 1.7051e-40, -2.8735e-41, -9.1464e-41]],

         [[ 1.5724e-40,  2.7935e-41,  1.8295e-41],
          [ 1.6977e-40,  3.3113e-42,  1.1336e-40],
          [-1.8180e-41, -5.9210e-41,  6.2115e-41]],

         [[ 1.1649e-40,  9.3116e-41, -1.1563e-40],
          [-3.5634e-41,  1.5022e-41,  3.6236e-41],
          [ 7.5173e-41, -1.0451e-40, -1.3236e-40]]],


        ...,


        [[[-2.0746e-02,  2.8203e-03, -4.5140e-02],
          [ 6.5733e-03,  5.0832e-02, -2.3265e-02],
          [-9.9551e-02,  4.4332e-02,  3.3559e-02]],

         [[-1.3350e-01, -1.3615e-01, -7.9739e-02],
          [ 6.4757e-02,  4.6812e-02, -1.0585e-01],
          [ 1.1687e-01,  7.2801e-02, -8.0639e-03]],

         [[ 1.2306e-02,  1.2930e-01,  7.4387e-02],
          [ 2.2386e-01,  3.0649e-01,  1.5580e-01],
          [ 1.6440e-01,  2.4356e-01,  6.8026e-02]]],


        [[[ 3.0290e-01,  1.6574e-02,  6.6667e-02],
          [ 1.1370e-01, -1.6510e-01, -1.1816e-01],
          [ 7.2498e-02,  7.1715e-02,  8.7382e-02]],

         [[ 1.0328e-02, -1.8632e-01, -1.0012e-02],
          [-7.0908e-02, -2.8716e-01, -1.9311e-01],
          [-7.7620e-03, -6.7260e-02, -1.1278e-02]],

         [[-7.5700e-04, -2.0579e-01, -7.1657e-02],
          [-1.0846e-01, -1.8473e-01, -8.3487e-02],
          [-8.0603e-02, -4.7012e-03,  7.6173e-02]]],


        [[[ 4.9968e-02, -2.7013e-01,  6.8551e-02],
          [-2.0152e-01, -5.8920e-01, -2.1139e-01],
          [ 1.3614e-01, -6.4636e-03,  1.8818e-02]],

         [[ 1.3181e-01, -2.9981e-01,  1.9925e-02],
          [ 1.6045e-02, -2.9553e-01,  2.4834e-02],
          [ 1.7148e-01,  1.9268e-01,  4.5360e-02]],

         [[ 3.2301e-02, -2.5775e-01,  8.8024e-02],
          [ 7.9970e-02, -7.4467e-02,  1.0288e-01],
          [-5.8210e-02,  7.0413e-02,  1.0617e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2233]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0021]], device='cuda:0')

Epoch: 159 | Batch_idx: 0 |  Loss: (0.1000) | Acc: (97.00%) (125/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1423) | Acc: (95.00%) (1342/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.1420) | Acc: (95.00%) (2558/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.1538) | Acc: (94.00%) (3759/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.1530) | Acc: (94.00%) (4971/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.1557) | Acc: (94.00%) (6186/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.1540) | Acc: (94.00%) (7403/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.1552) | Acc: (94.00%) (8614/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.1557) | Acc: (94.00%) (9824/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1574) | Acc: (94.00%) (11037/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1572) | Acc: (94.00%) (12249/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1565) | Acc: (94.00%) (13471/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.1571) | Acc: (94.00%) (14676/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.1572) | Acc: (94.00%) (15888/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.1575) | Acc: (94.00%) (17097/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1579) | Acc: (94.00%) (18303/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1580) | Acc: (94.00%) (19518/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1588) | Acc: (94.00%) (20727/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1599) | Acc: (94.00%) (21934/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1590) | Acc: (94.00%) (23160/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1587) | Acc: (94.00%) (24379/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1587) | Acc: (94.00%) (25593/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1584) | Acc: (94.00%) (26813/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1575) | Acc: (94.00%) (28039/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1575) | Acc: (94.00%) (29249/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1564) | Acc: (94.00%) (30477/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1571) | Acc: (94.00%) (31686/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1576) | Acc: (94.00%) (32889/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1571) | Acc: (94.00%) (34107/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1571) | Acc: (94.00%) (35319/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1568) | Acc: (94.00%) (36538/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1570) | Acc: (94.00%) (37747/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1570) | Acc: (94.00%) (38960/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1570) | Acc: (94.00%) (40169/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1565) | Acc: (94.00%) (41390/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1564) | Acc: (94.00%) (42611/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1568) | Acc: (94.00%) (43811/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1567) | Acc: (94.00%) (45033/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1570) | Acc: (94.00%) (46246/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1573) | Acc: (94.00%) (47413/50000)
# TEST : Loss: (0.2803) | Acc: (90.00%) (9062/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 1.1358e-40,  2.0460e-40, -3.7392e-40],
          [-1.7871e-41, -1.8678e-40, -3.0030e-40],
          [ 1.8487e-41, -1.7927e-40,  2.0997e-41]],

         [[ 2.4008e-41,  2.7337e-40,  9.8430e-41],
          [-2.5142e-40,  2.1337e-40, -1.3593e-40],
          [ 8.2064e-41,  3.4299e-40, -2.5218e-40]],

         [[ 7.6222e-41, -5.6035e-41,  2.7771e-40],
          [ 1.3097e-40,  1.9656e-40,  3.0142e-40],
          [ 4.2972e-40,  1.7941e-40, -2.9301e-40]]],


        [[[ 3.8514e-01,  4.5592e-02,  3.0228e-01],
          [ 1.7696e-01, -9.7209e-03, -2.2616e-01],
          [-2.0345e-01, -4.0080e-01, -3.1248e-01]],

         [[-6.3141e-02, -3.0604e-01, -5.5002e-02],
          [-9.1413e-02,  4.2036e-01, -2.3372e-01],
          [ 2.2357e-01,  1.4855e-01,  2.5862e-01]],

         [[-1.7287e-01, -2.5056e-01, -4.8174e-02],
          [-2.3782e-01,  1.7534e-01, -4.0471e-02],
          [ 2.9663e-02,  1.7764e-01,  2.8509e-01]]],


        [[[-1.3862e-40, -1.0587e-40, -1.2710e-40],
          [-1.5641e-40,  1.5059e-40,  6.8566e-42],
          [-1.1824e-40,  7.9047e-42,  3.0908e-41]],

         [[ 6.5069e-41,  3.2444e-41,  2.1143e-41],
          [-1.5165e-40,  1.4725e-40, -1.6483e-40],
          [ 1.1861e-40,  1.1720e-40, -8.3751e-41]],

         [[-1.4373e-41,  1.1093e-40,  1.6136e-40],
          [ 1.6215e-40,  1.7621e-41,  4.3866e-41],
          [-1.3811e-40, -7.3927e-41, -1.0120e-41]]],


        ...,


        [[[-2.0426e-02,  2.7772e-03, -4.4473e-02],
          [ 6.4610e-03,  4.9965e-02, -2.2881e-02],
          [-9.7886e-02,  4.3595e-02,  3.3025e-02]],

         [[-1.3087e-01, -1.3348e-01, -7.8295e-02],
          [ 6.3077e-02,  4.5574e-02, -1.0340e-01],
          [ 1.1393e-01,  7.0943e-02, -7.8866e-03]],

         [[ 1.2002e-02,  1.2603e-01,  7.2710e-02],
          [ 2.1252e-01,  2.8721e-01,  1.4993e-01],
          [ 1.5636e-01,  2.2853e-01,  6.5653e-02]]],


        [[[ 2.9974e-01,  1.6384e-02,  6.5890e-02],
          [ 1.1245e-01, -1.6302e-01, -1.1666e-01],
          [ 7.1735e-02,  7.0924e-02,  8.6419e-02]],

         [[ 1.0188e-02, -1.8307e-01, -9.8432e-03],
          [-6.9823e-02, -2.8062e-01, -1.8906e-01],
          [-7.6597e-03, -6.6241e-02, -1.1116e-02]],

         [[-7.4404e-04, -2.0068e-01, -6.9999e-02],
          [-1.0621e-01, -1.7755e-01, -8.0874e-02],
          [-7.9256e-02, -4.6058e-03,  7.4772e-02]]],


        [[[ 4.9641e-02, -2.6765e-01,  6.8088e-02],
          [-2.0021e-01, -5.8392e-01, -2.0999e-01],
          [ 1.3547e-01, -6.4288e-03,  1.8725e-02]],

         [[ 1.3105e-01, -2.9767e-01,  1.9807e-02],
          [ 1.5953e-02, -2.9347e-01,  2.4690e-02],
          [ 1.7069e-01,  1.9173e-01,  4.5150e-02]],

         [[ 3.2116e-02, -2.5608e-01,  8.7517e-02],
          [ 7.9518e-02, -7.3999e-02,  1.0231e-01],
          [-5.7931e-02,  7.0062e-02,  1.0566e-01]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2023]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0009]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 160 | Batch_idx: 0 |  Loss: (0.1623) | Acc: (95.00%) (122/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.1621) | Acc: (95.00%) (1339/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.2097) | Acc: (93.00%) (2513/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.2604) | Acc: (91.00%) (3630/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.2892) | Acc: (90.00%) (4743/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.3068) | Acc: (89.00%) (5863/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.3107) | Acc: (89.00%) (7003/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.3228) | Acc: (89.00%) (8127/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.3322) | Acc: (89.00%) (9238/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.3364) | Acc: (88.00%) (10363/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.3423) | Acc: (88.00%) (11460/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.3422) | Acc: (88.00%) (12584/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.3413) | Acc: (88.00%) (13716/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.3425) | Acc: (88.00%) (14844/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.3414) | Acc: (88.00%) (15972/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.3380) | Acc: (88.00%) (17134/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.3353) | Acc: (88.00%) (18288/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.3331) | Acc: (88.00%) (19426/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.3311) | Acc: (88.00%) (20580/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.3332) | Acc: (88.00%) (21699/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.3326) | Acc: (88.00%) (22835/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.3311) | Acc: (88.00%) (23983/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.3286) | Acc: (88.00%) (25140/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.3275) | Acc: (88.00%) (26286/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.3240) | Acc: (88.00%) (27446/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.3230) | Acc: (89.00%) (28596/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.3209) | Acc: (89.00%) (29755/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.3194) | Acc: (89.00%) (30903/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.3172) | Acc: (89.00%) (32066/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.3166) | Acc: (89.00%) (33220/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.3158) | Acc: (89.00%) (34369/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.3158) | Acc: (89.00%) (35518/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.3145) | Acc: (89.00%) (36681/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.3139) | Acc: (89.00%) (37846/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.3135) | Acc: (89.00%) (38996/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.3128) | Acc: (89.00%) (40137/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.3126) | Acc: (89.00%) (41292/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.3119) | Acc: (89.00%) (42449/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.3111) | Acc: (89.00%) (43603/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.3103) | Acc: (89.00%) (44712/50000)
# TEST : Loss: (0.3589) | Acc: (88.00%) (8812/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-3.4014e-40,  2.1340e-40,  2.9673e-40],
          [-2.4158e-40,  2.3929e-41, -5.3401e-40],
          [-1.9930e-40,  2.8159e-41, -1.9372e-40]],

         [[-8.8964e-41, -1.6851e-40, -1.0466e-41],
          [-3.6453e-41, -3.4122e-42,  3.1221e-40],
          [-1.4071e-40, -3.1450e-40, -3.7689e-41]],

         [[-2.9493e-41,  5.2275e-41,  1.7937e-40],
          [-8.9864e-41, -4.7917e-40,  1.9866e-40],
          [-4.6598e-40,  3.0053e-40, -1.8959e-40]]],


        [[[ 3.9825e-01,  5.3084e-02,  3.1341e-01],
          [ 1.7698e-01, -4.6980e-03, -2.1360e-01],
          [-2.1846e-01, -4.0726e-01, -2.9739e-01]],

         [[-5.3349e-02, -3.0315e-01, -5.1934e-02],
          [-8.6129e-02,  4.2784e-01, -2.2547e-01],
          [ 2.2262e-01,  1.5492e-01,  2.7579e-01]],

         [[-1.7008e-01, -2.5992e-01, -5.5466e-02],
          [-2.4088e-01,  1.7185e-01, -3.9400e-02],
          [ 2.5907e-02,  1.7663e-01,  2.9430e-01]]],


        [[[-1.6373e-40,  1.1770e-40,  8.9869e-41],
          [-1.8345e-40,  1.4646e-40, -1.2353e-40],
          [ 7.4176e-41,  5.8920e-41, -4.5223e-41]],

         [[-1.3276e-40, -1.0783e-40, -8.8953e-41],
          [-1.7941e-40, -1.2741e-40,  1.8490e-40],
          [-1.9590e-40, -8.2766e-41, -1.5828e-40]],

         [[-1.8818e-41,  1.3070e-40, -1.4257e-40],
          [-9.1955e-41, -6.2478e-41,  4.8590e-41],
          [ 1.0816e-40, -1.0711e-40,  1.1406e-40]]],


        ...,


        [[[-1.3168e-02,  1.0405e-02, -3.4120e-02],
          [ 1.0683e-02,  6.1970e-02, -1.4895e-02],
          [-1.0450e-01,  4.8196e-02,  3.8489e-02]],

         [[-1.1203e-01, -1.1267e-01, -6.1235e-02],
          [ 8.6140e-02,  8.0304e-02, -8.3043e-02],
          [ 1.2004e-01,  9.4538e-02,  6.5543e-03]],

         [[ 1.8894e-02,  1.3656e-01,  8.2179e-02],
          [ 2.3580e-01,  3.3694e-01,  1.6889e-01],
          [ 1.6370e-01,  2.6596e-01,  8.3292e-02]]],


        [[[ 3.2006e-01,  2.1279e-02,  7.4620e-02],
          [ 1.0475e-01, -1.8805e-01, -1.3526e-01],
          [ 6.1774e-02,  6.1317e-02,  7.8872e-02]],

         [[ 4.9090e-02, -1.5949e-01,  1.8413e-02],
          [-5.8064e-02, -2.9164e-01, -1.9159e-01],
          [-9.9756e-04, -5.6297e-02,  1.0524e-03]],

         [[ 1.3579e-02, -1.9284e-01, -4.3728e-02],
          [-1.1670e-01, -2.0170e-01, -7.4032e-02],
          [-8.2592e-02,  6.1904e-03,  1.0018e-01]]],


        [[[ 6.0846e-02, -2.8210e-01,  7.1861e-02],
          [-2.0285e-01, -5.8904e-01, -1.8241e-01],
          [ 1.3632e-01,  8.9658e-03,  4.4607e-02]],

         [[ 1.3723e-01, -3.1150e-01,  1.6562e-02],
          [ 1.2045e-02, -3.0011e-01,  3.9055e-02],
          [ 1.6413e-01,  1.9616e-01,  5.6210e-02]],

         [[ 4.1692e-02, -2.5883e-01,  8.8405e-02],
          [ 7.3653e-02, -7.8794e-02,  1.1363e-01],
          [-6.8846e-02,  7.2523e-02,  1.1404e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0171,  0.0298,  0.0270],
          [ 0.0480,  0.0492,  0.0127],
          [ 0.1042,  0.0567,  0.0233]],

         [[ 0.0534,  0.0596,  0.0427],
          [ 0.0562,  0.0610,  0.0299],
          [ 0.0966,  0.0564,  0.0286]],

         [[ 0.0198,  0.0316,  0.0216],
          [ 0.0202,  0.0290,  0.0117],
          [ 0.0627,  0.0400,  0.0165]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0054, -0.0006,  0.0049],
          [-0.0014,  0.0005,  0.0035],
          [ 0.0008, -0.0000,  0.0001]],

         [[-0.0034,  0.0003,  0.0056],
          [-0.0001,  0.0002,  0.0029],
          [ 0.0012, -0.0011, -0.0020]],

         [[-0.0025,  0.0003,  0.0066],
          [ 0.0003, -0.0004,  0.0036],
          [ 0.0009, -0.0024, -0.0023]]],


        [[[-0.0176, -0.0162, -0.0159],
          [-0.0143, -0.0152, -0.0137],
          [-0.0082, -0.0088, -0.0087]],

         [[-0.0139, -0.0128, -0.0115],
          [-0.0084, -0.0099, -0.0082],
          [-0.0040, -0.0055, -0.0035]],

         [[ 0.0039,  0.0002, -0.0004],
          [ 0.0053, -0.0005, -0.0018],
          [ 0.0056,  0.0001, -0.0005]]],


        [[[-0.0071, -0.0129, -0.0283],
          [-0.0108, -0.0139, -0.0223],
          [-0.0254, -0.0278, -0.0325]],

         [[-0.0125, -0.0157, -0.0306],
          [-0.0118, -0.0126, -0.0225],
          [-0.0245, -0.0243, -0.0294]],

         [[-0.0166, -0.0182, -0.0295],
          [-0.0174, -0.0173, -0.0254],
          [-0.0302, -0.0307, -0.0344]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2042]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 161 | Batch_idx: 0 |  Loss: (0.2400) | Acc: (90.00%) (116/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.2031) | Acc: (92.00%) (1307/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.2326) | Acc: (91.00%) (2465/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.2331) | Acc: (91.00%) (3639/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.2270) | Acc: (91.00%) (4819/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.2304) | Acc: (91.00%) (5993/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.2334) | Acc: (91.00%) (7166/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.2326) | Acc: (91.00%) (8341/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.2370) | Acc: (91.00%) (9506/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.2382) | Acc: (91.00%) (10678/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.2350) | Acc: (91.00%) (11862/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.2339) | Acc: (91.00%) (13047/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.2309) | Acc: (91.00%) (14241/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.2318) | Acc: (91.00%) (15414/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.2319) | Acc: (91.00%) (16596/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.2304) | Acc: (91.00%) (17780/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.2321) | Acc: (91.00%) (18949/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.2334) | Acc: (91.00%) (20122/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.2354) | Acc: (91.00%) (21281/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.2364) | Acc: (91.00%) (22452/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.2359) | Acc: (91.00%) (23638/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.2362) | Acc: (91.00%) (24812/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.2357) | Acc: (91.00%) (25997/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.2352) | Acc: (91.00%) (27173/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.2355) | Acc: (91.00%) (28344/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.2351) | Acc: (91.00%) (29522/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.2355) | Acc: (91.00%) (30694/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.2348) | Acc: (91.00%) (31880/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.2355) | Acc: (91.00%) (33053/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.2359) | Acc: (91.00%) (34221/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.2355) | Acc: (91.00%) (35409/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.2355) | Acc: (91.00%) (36577/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.2351) | Acc: (91.00%) (37760/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.2360) | Acc: (91.00%) (38927/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.2359) | Acc: (91.00%) (40113/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.2359) | Acc: (91.00%) (41289/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.2363) | Acc: (91.00%) (42462/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.2363) | Acc: (91.00%) (43636/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.2363) | Acc: (91.00%) (44815/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.2359) | Acc: (91.00%) (45948/50000)
# TEST : Loss: (0.3528) | Acc: (88.00%) (8889/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-4.6998e-40, -1.4722e-41, -4.7553e-41],
          [-2.0337e-41,  2.5327e-40, -3.2694e-40],
          [ 2.1609e-41,  2.5486e-40, -3.1385e-40]],

         [[-9.2979e-41, -5.2635e-40, -1.2783e-40],
          [ 1.9587e-40, -2.3731e-40, -1.4635e-40],
          [-1.4559e-40, -2.0946e-40,  1.9426e-40]],

         [[-1.4432e-40,  1.6943e-40, -4.3876e-41],
          [ 1.4075e-40, -2.5066e-41, -3.0824e-41],
          [ 2.2577e-40,  1.9247e-40,  4.1251e-41]]],


        [[[ 4.0388e-01,  4.8441e-02,  3.0331e-01],
          [ 1.9545e-01, -2.0912e-03, -2.1453e-01],
          [-2.1309e-01, -4.1757e-01, -3.0513e-01]],

         [[-6.5956e-02, -3.1931e-01, -6.7067e-02],
          [-8.0692e-02,  4.2531e-01, -2.3221e-01],
          [ 2.2110e-01,  1.4415e-01,  2.6577e-01]],

         [[-1.6947e-01, -2.6597e-01, -6.2090e-02],
          [-2.2771e-01,  1.7644e-01, -4.2147e-02],
          [ 2.8240e-02,  1.7128e-01,  2.8888e-01]]],


        [[[-4.1781e-02, -4.3380e-02, -2.9736e-02],
          [-3.9602e-02, -3.3912e-02, -1.1356e-02],
          [-2.5736e-02, -1.1506e-02,  1.1836e-02]],

         [[-2.8295e-02, -2.9282e-02, -1.6046e-02],
          [-3.7313e-02, -3.0359e-02, -7.8045e-03],
          [-2.9303e-02, -1.5210e-02,  7.1722e-03]],

         [[-4.7502e-02, -5.0643e-02, -4.1049e-02],
          [-5.3235e-02, -5.2078e-02, -3.5689e-02],
          [-4.3540e-02, -3.8651e-02, -2.2403e-02]]],


        ...,


        [[[-1.2831e-02,  1.6141e-02, -2.8746e-02],
          [ 7.8226e-03,  5.8983e-02, -2.1074e-02],
          [-9.7044e-02,  4.9224e-02,  3.1064e-02]],

         [[-1.0935e-01, -1.0399e-01, -5.6374e-02],
          [ 8.5533e-02,  7.9210e-02, -9.1203e-02],
          [ 1.2784e-01,  9.2654e-02, -8.1276e-03]],

         [[ 2.3443e-02,  1.5166e-01,  9.1052e-02],
          [ 2.3468e-01,  3.3957e-01,  1.5991e-01],
          [ 1.8601e-01,  2.7620e-01,  7.1646e-02]]],


        [[[ 3.1186e-01,  1.0317e-02,  7.4838e-02],
          [ 1.1591e-01, -1.7866e-01, -1.2694e-01],
          [ 8.7033e-02,  7.9243e-02,  9.4875e-02]],

         [[ 3.8303e-02, -1.7982e-01,  7.3864e-03],
          [-5.5339e-02, -2.9246e-01, -1.9540e-01],
          [ 1.2080e-02, -5.2729e-02,  1.0030e-03]],

         [[-1.1978e-03, -2.1976e-01, -6.8275e-02],
          [-1.1828e-01, -2.0426e-01, -8.9001e-02],
          [-7.2443e-02,  8.5913e-03,  9.4315e-02]]],


        [[[ 6.1733e-02, -2.8562e-01,  8.3327e-02],
          [-2.0063e-01, -5.9502e-01, -1.7264e-01],
          [ 1.3734e-01,  6.4641e-03,  5.5300e-02]],

         [[ 1.4282e-01, -3.1312e-01,  2.2930e-02],
          [ 2.1337e-02, -3.0053e-01,  4.6046e-02],
          [ 1.6976e-01,  1.9502e-01,  6.3339e-02]],

         [[ 5.0999e-02, -2.5689e-01,  8.4447e-02],
          [ 8.7207e-02, -7.3344e-02,  1.1470e-01],
          [-6.3510e-02,  7.1174e-02,  1.1399e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0959, -0.0620, -0.0461],
          [-0.0673, -0.0469, -0.0569],
          [-0.0027, -0.0167, -0.0342]],

         [[-0.1178, -0.0719, -0.0432],
          [-0.0847, -0.0606, -0.0578],
          [-0.0185, -0.0213, -0.0457]],

         [[-0.1108, -0.0999, -0.0780],
          [-0.1123, -0.0992, -0.0817],
          [-0.0644, -0.0682, -0.0645]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0010, -0.0026, -0.0075],
          [ 0.0010, -0.0014, -0.0028],
          [ 0.0063,  0.0058,  0.0040]],

         [[ 0.0003, -0.0031, -0.0080],
          [ 0.0008, -0.0019, -0.0034],
          [ 0.0053,  0.0040,  0.0020]],

         [[-0.0022, -0.0051, -0.0091],
          [-0.0009, -0.0034, -0.0044],
          [ 0.0044,  0.0030,  0.0015]]],


        [[[-0.0004, -0.0022, -0.0052],
          [ 0.0077,  0.0083,  0.0033],
          [-0.0006,  0.0009, -0.0019]],

         [[-0.0054, -0.0065, -0.0074],
          [ 0.0013,  0.0022, -0.0012],
          [-0.0061, -0.0045, -0.0066]],

         [[-0.0063, -0.0058, -0.0059],
          [ 0.0003,  0.0024, -0.0001],
          [-0.0049, -0.0024, -0.0041]]],


        [[[-0.0135, -0.0087, -0.0013],
          [ 0.0004, -0.0019,  0.0069],
          [-0.0039, -0.0132,  0.0002]],

         [[-0.0184, -0.0120, -0.0043],
          [-0.0037, -0.0057,  0.0028],
          [-0.0072, -0.0159, -0.0025]],

         [[-0.0195, -0.0103, -0.0043],
          [-0.0094, -0.0061, -0.0003],
          [-0.0098, -0.0098,  0.0002]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2039]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 162 | Batch_idx: 0 |  Loss: (0.1887) | Acc: (96.00%) (123/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.2144) | Acc: (92.00%) (1306/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.2059) | Acc: (92.00%) (2498/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.2040) | Acc: (93.00%) (3692/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.2040) | Acc: (93.00%) (4884/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.2020) | Acc: (93.00%) (6075/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.2072) | Acc: (92.00%) (7246/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.2108) | Acc: (92.00%) (8426/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.2115) | Acc: (92.00%) (9614/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.2113) | Acc: (92.00%) (10805/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.2121) | Acc: (92.00%) (11984/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.2137) | Acc: (92.00%) (13159/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.2122) | Acc: (92.00%) (14356/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.2132) | Acc: (92.00%) (15535/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.2130) | Acc: (92.00%) (16721/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.2104) | Acc: (92.00%) (17916/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.2104) | Acc: (92.00%) (19107/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.2093) | Acc: (92.00%) (20301/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.2103) | Acc: (92.00%) (21480/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.2116) | Acc: (92.00%) (22663/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.2119) | Acc: (92.00%) (23860/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.2117) | Acc: (92.00%) (25054/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.2111) | Acc: (92.00%) (26242/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.2111) | Acc: (92.00%) (27434/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.2105) | Acc: (92.00%) (28628/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.2105) | Acc: (92.00%) (29816/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.2103) | Acc: (92.00%) (31004/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.2094) | Acc: (92.00%) (32205/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.2084) | Acc: (92.00%) (33401/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.2094) | Acc: (92.00%) (34576/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.2106) | Acc: (92.00%) (35757/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.2102) | Acc: (92.00%) (36947/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.2104) | Acc: (92.00%) (38125/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.2106) | Acc: (92.00%) (39306/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.2101) | Acc: (92.00%) (40489/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.2112) | Acc: (92.00%) (41664/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.2105) | Acc: (92.00%) (42854/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.2110) | Acc: (92.00%) (44042/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.2112) | Acc: (92.00%) (45228/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.2115) | Acc: (92.00%) (46370/50000)
# TEST : Loss: (0.3304) | Acc: (89.00%) (8952/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 4.9172e-40, -2.5745e-40, -2.9201e-40],
          [ 2.1740e-40,  2.6162e-40, -3.3766e-40],
          [ 2.5795e-40,  2.6484e-40, -2.0833e-40]],

         [[ 2.4035e-41, -4.2146e-40, -1.3129e-40],
          [ 3.2200e-40, -2.4438e-40,  3.3202e-40],
          [-2.6966e-40,  2.6420e-40,  3.2025e-40]],

         [[-1.4811e-40,  1.7513e-40, -2.8308e-40],
          [ 2.6504e-40, -3.8964e-40, -2.7363e-40],
          [-2.5370e-40, -4.5108e-41,  2.8627e-40]]],


        [[[ 4.1497e-01,  5.7370e-02,  3.1959e-01],
          [ 1.9477e-01,  4.0837e-03, -2.0246e-01],
          [-2.1970e-01, -4.1265e-01, -2.9204e-01]],

         [[-6.4942e-02, -3.2250e-01, -6.0782e-02],
          [-8.9523e-02,  4.2341e-01, -2.2813e-01],
          [ 2.1144e-01,  1.4699e-01,  2.7369e-01]],

         [[-1.6921e-01, -2.6832e-01, -5.2242e-02],
          [-2.3816e-01,  1.7573e-01, -3.6502e-02],
          [ 2.0235e-02,  1.7513e-01,  2.9645e-01]]],


        [[[-2.6794e-02, -2.7785e-02, -1.9863e-02],
          [-2.6128e-02, -2.1507e-02, -7.3061e-03],
          [-1.8477e-02, -8.0529e-03,  8.2492e-03]],

         [[-1.8364e-02, -1.9383e-02, -1.0972e-02],
          [-2.5191e-02, -2.0336e-02, -5.3677e-03],
          [-2.1594e-02, -1.1146e-02,  5.3236e-03]],

         [[-3.5044e-02, -3.7943e-02, -3.0877e-02],
          [-4.0629e-02, -4.0040e-02, -2.7547e-02],
          [-3.4291e-02, -3.0572e-02, -1.7794e-02]]],


        ...,


        [[[ 4.2729e-03,  2.4757e-02, -2.9545e-02],
          [ 1.4211e-02,  6.5366e-02, -2.5854e-02],
          [-1.0658e-01,  4.1225e-02,  1.8964e-02]],

         [[-9.3334e-02, -9.7814e-02, -6.4083e-02],
          [ 8.9002e-02,  8.5167e-02, -1.0376e-01],
          [ 1.1012e-01,  7.8018e-02, -3.0872e-02]],

         [[ 4.9568e-02,  1.6927e-01,  9.1087e-02],
          [ 2.5515e-01,  3.7454e-01,  1.5229e-01],
          [ 1.6442e-01,  2.5565e-01,  4.3399e-02]]],


        [[[ 3.0571e-01,  2.9973e-03,  7.1076e-02],
          [ 1.0802e-01, -1.9006e-01, -1.3114e-01],
          [ 7.8769e-02,  6.8851e-02,  8.0432e-02]],

         [[ 4.2819e-02, -1.8148e-01,  1.0992e-02],
          [-5.7853e-02, -3.0605e-01, -1.9343e-01],
          [ 2.1023e-03, -7.0186e-02, -1.7105e-02]],

         [[-3.2655e-03, -2.3480e-01, -6.8858e-02],
          [-1.2762e-01, -2.3287e-01, -8.4956e-02],
          [-8.9654e-02, -1.7109e-02,  7.1900e-02]]],


        [[[ 5.8209e-02, -2.8333e-01,  9.6152e-02],
          [-2.0140e-01, -6.0570e-01, -1.7517e-01],
          [ 1.3953e-01,  3.4179e-04,  5.0610e-02]],

         [[ 1.3523e-01, -3.1700e-01,  3.3435e-02],
          [ 1.5613e-02, -3.1334e-01,  4.0656e-02],
          [ 1.6948e-01,  1.8638e-01,  5.4826e-02]],

         [[ 4.3772e-02, -2.5940e-01,  9.2166e-02],
          [ 8.3769e-02, -8.0560e-02,  1.0952e-01],
          [-6.1156e-02,  6.5771e-02,  1.0503e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.1538, -0.1312, -0.1109],
          [-0.1226, -0.1149, -0.1071],
          [-0.0940, -0.1073, -0.1024]],

         [[-0.1361, -0.1296, -0.1173],
          [-0.1049, -0.1106, -0.1158],
          [-0.0798, -0.1011, -0.1057]],

         [[-0.1145, -0.1133, -0.1090],
          [-0.0781, -0.0864, -0.0945],
          [-0.0483, -0.0691, -0.0750]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0106, -0.0060, -0.0026],
          [-0.0121, -0.0076, -0.0059],
          [-0.0119, -0.0077, -0.0067]],

         [[-0.0120, -0.0062, -0.0020],
          [-0.0157, -0.0102, -0.0079],
          [-0.0158, -0.0109, -0.0094]],

         [[ 0.0005,  0.0072,  0.0106],
          [-0.0046,  0.0022,  0.0041],
          [-0.0059,  0.0003,  0.0014]]],


        [[[-0.0072,  0.0009, -0.0035],
          [-0.0066, -0.0013, -0.0018],
          [-0.0090, -0.0052, -0.0061]],

         [[-0.0090, -0.0015, -0.0035],
          [-0.0085, -0.0027, -0.0012],
          [-0.0115, -0.0066, -0.0054]],

         [[-0.0075, -0.0001, -0.0011],
          [-0.0076, -0.0019,  0.0006],
          [-0.0102, -0.0052, -0.0030]]],


        [[[-0.0014, -0.0015,  0.0038],
          [ 0.0008, -0.0048, -0.0021],
          [-0.0017, -0.0038, -0.0113]],

         [[-0.0081, -0.0034,  0.0033],
          [-0.0051, -0.0070, -0.0047],
          [-0.0051, -0.0060, -0.0163]],

         [[-0.0052,  0.0006,  0.0051],
          [-0.0037, -0.0039, -0.0030],
          [-0.0046, -0.0054, -0.0180]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2034]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 163 | Batch_idx: 0 |  Loss: (0.1676) | Acc: (95.00%) (122/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.1727) | Acc: (94.00%) (1328/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.1729) | Acc: (94.00%) (2535/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.1800) | Acc: (93.00%) (3723/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.1862) | Acc: (93.00%) (4917/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.1860) | Acc: (93.00%) (6112/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.1873) | Acc: (93.00%) (7306/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.1818) | Acc: (93.00%) (8524/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.1820) | Acc: (93.00%) (9730/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1786) | Acc: (93.00%) (10940/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.1837) | Acc: (93.00%) (12126/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1823) | Acc: (93.00%) (13330/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.1832) | Acc: (93.00%) (14524/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.1859) | Acc: (93.00%) (15713/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.1883) | Acc: (93.00%) (16895/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.1918) | Acc: (93.00%) (18064/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.1908) | Acc: (93.00%) (19262/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1919) | Acc: (93.00%) (20453/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1904) | Acc: (93.00%) (21655/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1913) | Acc: (93.00%) (22842/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1914) | Acc: (93.00%) (24029/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1919) | Acc: (93.00%) (25226/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1931) | Acc: (93.00%) (26408/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1924) | Acc: (93.00%) (27607/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1926) | Acc: (93.00%) (28804/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1940) | Acc: (93.00%) (29982/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1938) | Acc: (93.00%) (31181/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1937) | Acc: (93.00%) (32384/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1945) | Acc: (93.00%) (33571/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1948) | Acc: (93.00%) (34768/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1957) | Acc: (93.00%) (35952/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1956) | Acc: (93.00%) (37150/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1951) | Acc: (93.00%) (38355/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1957) | Acc: (93.00%) (39541/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1950) | Acc: (93.00%) (40747/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1946) | Acc: (93.00%) (41943/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1952) | Acc: (93.00%) (43134/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1958) | Acc: (93.00%) (44322/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1952) | Acc: (93.00%) (45525/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1954) | Acc: (93.00%) (46680/50000)
# TEST : Loss: (0.3521) | Acc: (88.00%) (8890/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 5.0331e-40, -2.6335e-40,  4.4770e-40],
          [ 2.2397e-40,  2.6851e-40, -4.6830e-40],
          [ 2.6470e-40, -2.0758e-40, -2.1539e-40]],

         [[ 1.4764e-40,  6.2924e-41, -1.0437e-41],
          [ 2.0711e-40, -3.3785e-42,  5.8757e-40],
          [-1.5217e-40, -3.4411e-40,  2.0514e-40]],

         [[-2.9467e-41, -6.5139e-41, -2.9113e-40],
          [ 1.4726e-40,  4.6970e-40, -2.7951e-40],
          [ 1.1298e-40, -2.9520e-40, -2.0601e-40]]],


        [[[ 4.0698e-01,  5.9109e-02,  3.2517e-01],
          [ 1.9437e-01,  5.5152e-03, -2.0245e-01],
          [-2.1963e-01, -4.1522e-01, -2.8963e-01]],

         [[-6.4251e-02, -3.1606e-01, -5.4279e-02],
          [-8.3476e-02,  4.2754e-01, -2.2619e-01],
          [ 2.1600e-01,  1.4878e-01,  2.8016e-01]],

         [[-1.7072e-01, -2.6312e-01, -4.1855e-02],
          [-2.3294e-01,  1.8396e-01, -2.5563e-02],
          [ 2.9193e-02,  1.8278e-01,  3.1195e-01]]],


        [[[-1.5611e-02, -1.6150e-02, -1.2151e-02],
          [-1.5750e-02, -1.2348e-02, -4.2696e-03],
          [-1.2349e-02, -5.2186e-03,  5.3076e-03]],

         [[-1.0858e-02, -1.1727e-02, -6.9080e-03],
          [-1.5611e-02, -1.2476e-02, -3.4008e-03],
          [-1.4894e-02, -7.6349e-03,  3.6992e-03]],

         [[-2.4196e-02, -2.6688e-02, -2.1822e-02],
          [-2.9231e-02, -2.9061e-02, -2.0086e-02],
          [-2.5637e-02, -2.2974e-02, -1.3436e-02]]],


        ...,


        [[[-1.6876e-02,  1.3376e-02, -4.0920e-02],
          [ 7.5310e-03,  6.8084e-02, -2.5375e-02],
          [-1.0178e-01,  5.0160e-02,  2.6668e-02]],

         [[-1.2135e-01, -1.1444e-01, -8.3163e-02],
          [ 7.9504e-02,  8.6579e-02, -1.0909e-01],
          [ 1.1706e-01,  8.7840e-02, -2.6684e-02]],

         [[ 2.2758e-02,  1.5154e-01,  6.9366e-02],
          [ 2.3834e-01,  3.6743e-01,  1.3617e-01],
          [ 1.7801e-01,  2.6546e-01,  4.1775e-02]]],


        [[[ 3.1289e-01,  1.3391e-02,  7.1898e-02],
          [ 1.1109e-01, -1.8531e-01, -1.3213e-01],
          [ 8.5619e-02,  7.6430e-02,  8.5582e-02]],

         [[ 3.9829e-02, -1.7968e-01,  1.7092e-03],
          [-6.3271e-02, -3.0844e-01, -2.0364e-01],
          [ 5.9661e-03, -6.2485e-02, -1.3352e-02]],

         [[ 6.4357e-03, -2.1696e-01, -6.4670e-02],
          [-1.2307e-01, -2.1672e-01, -8.0062e-02],
          [-7.5766e-02,  2.8659e-03,  8.6956e-02]]],


        [[[ 6.4887e-02, -2.8881e-01,  8.5112e-02],
          [-2.0497e-01, -6.1989e-01, -1.8638e-01],
          [ 1.3160e-01, -8.0731e-03,  4.3499e-02]],

         [[ 1.4271e-01, -3.2203e-01,  2.0939e-02],
          [ 1.2885e-02, -3.2770e-01,  2.6648e-02],
          [ 1.5838e-01,  1.7195e-01,  4.0851e-02]],

         [[ 6.7359e-02, -2.4284e-01,  9.8444e-02],
          [ 9.7977e-02, -7.1659e-02,  1.1305e-01],
          [-5.8974e-02,  6.7600e-02,  1.0362e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0461, -0.0415, -0.0386],
          [-0.0321, -0.0366, -0.0343],
          [-0.0155, -0.0126, -0.0149]],

         [[-0.0783, -0.0790, -0.0788],
          [-0.0533, -0.0654, -0.0669],
          [-0.0396, -0.0396, -0.0380]],

         [[-0.1160, -0.1155, -0.1145],
          [-0.0900, -0.1046, -0.1039],
          [-0.0786, -0.0805, -0.0748]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0067,  0.0056,  0.0050],
          [ 0.0047,  0.0012,  0.0005],
          [ 0.0016, -0.0011, -0.0002]],

         [[ 0.0088,  0.0071,  0.0061],
          [ 0.0057,  0.0018,  0.0010],
          [ 0.0017, -0.0017, -0.0012]],

         [[ 0.0077,  0.0061,  0.0048],
          [ 0.0044,  0.0011,  0.0001],
          [ 0.0001, -0.0027, -0.0021]]],


        [[[ 0.0220,  0.0194,  0.0159],
          [ 0.0145,  0.0105,  0.0122],
          [ 0.0264,  0.0218,  0.0239]],

         [[ 0.0185,  0.0147,  0.0128],
          [ 0.0109,  0.0061,  0.0085],
          [ 0.0235,  0.0183,  0.0203]],

         [[ 0.0142,  0.0115,  0.0083],
          [ 0.0068,  0.0031,  0.0043],
          [ 0.0181,  0.0130,  0.0136]]],


        [[[ 0.0014,  0.0044,  0.0030],
          [-0.0023, -0.0013,  0.0026],
          [ 0.0026,  0.0015,  0.0044]],

         [[ 0.0092,  0.0110,  0.0110],
          [ 0.0048,  0.0040,  0.0079],
          [ 0.0099,  0.0066,  0.0078]],

         [[ 0.0045,  0.0042,  0.0012],
          [ 0.0003, -0.0011,  0.0008],
          [ 0.0064,  0.0022,  0.0020]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2028]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 164 | Batch_idx: 0 |  Loss: (0.1074) | Acc: (94.00%) (121/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1817) | Acc: (93.00%) (1322/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.1890) | Acc: (93.00%) (2515/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.1781) | Acc: (93.00%) (3729/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.1770) | Acc: (94.00%) (4938/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.1789) | Acc: (93.00%) (6131/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.1764) | Acc: (93.00%) (7332/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.1744) | Acc: (93.00%) (8538/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.1758) | Acc: (93.00%) (9733/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.1773) | Acc: (93.00%) (10929/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.1802) | Acc: (93.00%) (12114/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.1825) | Acc: (93.00%) (13302/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.1829) | Acc: (93.00%) (14500/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.1830) | Acc: (93.00%) (15701/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.1822) | Acc: (93.00%) (16898/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.1826) | Acc: (93.00%) (18096/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.1832) | Acc: (93.00%) (19287/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.1826) | Acc: (93.00%) (20484/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.1824) | Acc: (93.00%) (21680/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.1823) | Acc: (93.00%) (22868/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.1821) | Acc: (93.00%) (24062/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.1827) | Acc: (93.00%) (25257/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.1820) | Acc: (93.00%) (26462/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.1825) | Acc: (93.00%) (27655/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.1822) | Acc: (93.00%) (28857/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.1826) | Acc: (93.00%) (30041/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.1828) | Acc: (93.00%) (31245/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.1830) | Acc: (93.00%) (32443/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.1824) | Acc: (93.00%) (33646/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.1823) | Acc: (93.00%) (34840/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.1836) | Acc: (93.00%) (36031/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.1842) | Acc: (93.00%) (37219/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.1852) | Acc: (93.00%) (38402/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.1854) | Acc: (93.00%) (39599/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.1849) | Acc: (93.00%) (40796/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.1849) | Acc: (93.00%) (41997/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.1849) | Acc: (93.00%) (43206/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1846) | Acc: (93.00%) (44411/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.1845) | Acc: (93.00%) (45610/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1836) | Acc: (93.00%) (46771/50000)
# TEST : Loss: (0.3179) | Acc: (90.00%) (9021/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 1.3159e-40, -1.4686e-41, -1.7808e-40],
          [-2.0361e-41,  2.6305e-41,  2.6712e-40],
          [ 2.1573e-41,  3.2547e-41,  2.5679e-41]],

         [[ 1.5027e-40, -3.1480e-40,  1.1605e-40],
          [ 2.1238e-40,  2.4905e-40,  4.7341e-40],
          [ 9.7732e-41, -3.5224e-40,  2.1044e-40]],

         [[ 9.5375e-41, -6.8001e-41, -4.8195e-41],
          [-1.0302e-40,  9.9285e-41, -3.0791e-41],
          [-3.9211e-40,  2.0727e-40,  4.3369e-41]]],


        [[[ 3.9960e-01,  5.4634e-02,  3.1706e-01],
          [ 1.9769e-01,  1.0594e-02, -2.0667e-01],
          [-2.1462e-01, -4.1764e-01, -2.9868e-01]],

         [[-7.2145e-02, -3.2110e-01, -6.2325e-02],
          [-8.1766e-02,  4.3202e-01, -2.2759e-01],
          [ 2.1769e-01,  1.4785e-01,  2.7348e-01]],

         [[-1.8007e-01, -2.7371e-01, -5.8597e-02],
          [-2.3336e-01,  1.8577e-01, -3.3029e-02],
          [ 3.0181e-02,  1.7944e-01,  3.0260e-01]]],


        [[[-8.0792e-03, -8.3334e-03, -6.6743e-03],
          [-8.4972e-03, -6.2759e-03, -2.2175e-03],
          [-7.5568e-03, -3.0755e-03,  3.1007e-03]],

         [[-5.7209e-03, -6.3545e-03, -3.9304e-03],
          [-8.7115e-03, -6.8765e-03, -1.9498e-03],
          [-9.4722e-03, -4.8148e-03,  2.3740e-03]],

         [[-1.5409e-02, -1.7384e-02, -1.4298e-02],
          [-1.9573e-02, -1.9669e-02, -1.3672e-02],
          [-1.7991e-02, -1.6222e-02, -9.5433e-03]]],


        ...,


        [[[-1.7441e-02,  1.2344e-02, -4.3283e-02],
          [ 1.4096e-02,  7.8503e-02, -1.4986e-02],
          [-1.0162e-01,  5.3899e-02,  3.1288e-02]],

         [[-1.3072e-01, -1.2015e-01, -8.9510e-02],
          [ 8.1103e-02,  1.0036e-01, -9.6730e-02],
          [ 1.1298e-01,  9.6278e-02, -1.7863e-02]],

         [[ 5.7113e-03,  1.3749e-01,  5.6934e-02],
          [ 2.3095e-01,  3.8550e-01,  1.4758e-01],
          [ 1.5981e-01,  2.7561e-01,  5.1474e-02]]],


        [[[ 3.1439e-01,  1.1506e-02,  7.6089e-02],
          [ 1.1135e-01, -1.8976e-01, -1.2760e-01],
          [ 9.6861e-02,  8.7729e-02,  1.0332e-01]],

         [[ 4.1131e-02, -1.7871e-01,  9.1360e-03],
          [-6.0744e-02, -3.0778e-01, -1.9452e-01],
          [ 2.1162e-02, -4.1873e-02,  9.1572e-03]],

         [[ 7.4621e-04, -2.1583e-01, -5.6421e-02],
          [-1.2574e-01, -2.0784e-01, -6.7051e-02],
          [-6.1655e-02,  2.6795e-02,  1.0942e-01]]],


        [[[ 5.3518e-02, -2.8459e-01,  1.0070e-01],
          [-2.1048e-01, -6.1137e-01, -1.7338e-01],
          [ 1.3233e-01,  3.0710e-03,  5.8246e-02]],

         [[ 1.2896e-01, -3.2466e-01,  2.7515e-02],
          [ 5.1908e-03, -3.2530e-01,  3.2395e-02],
          [ 1.5903e-01,  1.8189e-01,  5.2799e-02]],

         [[ 5.1890e-02, -2.4793e-01,  1.0266e-01],
          [ 9.2384e-02, -6.7272e-02,  1.1952e-01],
          [-5.5904e-02,  7.9041e-02,  1.1552e-01]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0162, -0.0253, -0.0390],
          [ 0.0252,  0.0088, -0.0245],
          [ 0.0082, -0.0082, -0.0235]],

         [[-0.0198, -0.0171, -0.0312],
          [ 0.0215,  0.0138, -0.0154],
          [-0.0025, -0.0142, -0.0245]],

         [[ 0.0121,  0.0272,  0.0122],
          [ 0.0410,  0.0449,  0.0250],
          [ 0.0271,  0.0189,  0.0075]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0064,  0.0033, -0.0030],
          [ 0.0084,  0.0082,  0.0035],
          [ 0.0095,  0.0099,  0.0051]],

         [[ 0.0004, -0.0016, -0.0078],
          [ 0.0026,  0.0030, -0.0009],
          [ 0.0038,  0.0044,  0.0009]],

         [[-0.0058, -0.0070, -0.0112],
          [-0.0018, -0.0012, -0.0036],
          [ 0.0006,  0.0008, -0.0014]]],


        [[[-0.0054, -0.0047,  0.0027],
          [ 0.0117,  0.0090,  0.0156],
          [ 0.0135,  0.0095,  0.0122]],

         [[-0.0060, -0.0069, -0.0014],
          [ 0.0081,  0.0039,  0.0103],
          [ 0.0073,  0.0020,  0.0061]],

         [[-0.0087, -0.0103, -0.0057],
          [-0.0004, -0.0037,  0.0037],
          [-0.0010, -0.0051,  0.0009]]],


        [[[-0.0005,  0.0009,  0.0143],
          [ 0.0119,  0.0128,  0.0225],
          [ 0.0178,  0.0147,  0.0170]],

         [[-0.0142, -0.0143,  0.0007],
          [ 0.0009,  0.0009,  0.0109],
          [ 0.0100,  0.0079,  0.0084]],

         [[-0.0160, -0.0166, -0.0059],
          [-0.0020, -0.0031,  0.0040],
          [ 0.0056,  0.0030,  0.0010]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2022]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
4 hours 4 mins 4 secs for training