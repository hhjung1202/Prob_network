Files already downloaded and verified
USE 1 GPUs!
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (fc): Linear(in_features=1, out_features=1, bias=False)
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)
Epoch: 0 | Batch_idx: 0 |  Loss: (2.2900) | Acc: (14.00%) (18/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.1716) | Acc: (19.00%) (278/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.0605) | Acc: (23.00%) (622/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.0023) | Acc: (24.00%) (991/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (1.9549) | Acc: (26.00%) (1375/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (1.9176) | Acc: (27.00%) (1786/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (1.8934) | Acc: (28.00%) (2188/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (1.8697) | Acc: (28.00%) (2613/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (1.8451) | Acc: (29.00%) (3063/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (1.8273) | Acc: (30.00%) (3525/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (1.8110) | Acc: (30.00%) (3993/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (1.7941) | Acc: (31.00%) (4501/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (1.7760) | Acc: (32.00%) (5024/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (1.7556) | Acc: (33.00%) (5581/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (1.7395) | Acc: (33.00%) (6118/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (1.7264) | Acc: (34.00%) (6654/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (1.7127) | Acc: (35.00%) (7222/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (1.7027) | Acc: (35.00%) (7750/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (1.6919) | Acc: (35.00%) (8306/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (1.6785) | Acc: (36.00%) (8916/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (1.6659) | Acc: (36.00%) (9512/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (1.6516) | Acc: (37.00%) (10143/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (1.6391) | Acc: (38.00%) (10771/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (1.6268) | Acc: (38.00%) (11408/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (1.6168) | Acc: (38.00%) (12005/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (1.6054) | Acc: (39.00%) (12677/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (1.5942) | Acc: (39.00%) (13333/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (1.5844) | Acc: (40.00%) (13974/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (1.5764) | Acc: (40.00%) (14633/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (1.5655) | Acc: (41.00%) (15343/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (1.5567) | Acc: (41.00%) (16016/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (1.5478) | Acc: (41.00%) (16663/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (1.5401) | Acc: (42.00%) (17343/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (1.5311) | Acc: (42.00%) (18044/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (1.5222) | Acc: (42.00%) (18744/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (1.5135) | Acc: (43.00%) (19453/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (1.5061) | Acc: (43.00%) (20126/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (1.4984) | Acc: (43.00%) (20836/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (1.4917) | Acc: (44.00%) (21522/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (1.4848) | Acc: (44.00%) (22193/50000)
# TEST : Loss: (1.2891) | Acc: (54.00%) (5428/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0059,  0.0661,  0.0140],
          [-0.0978,  0.0274,  0.0411],
          [ 0.0102, -0.0847,  0.1732]],

         [[-0.0957,  0.1179,  0.0462],
          [-0.1007,  0.0956, -0.1462],
          [ 0.0014, -0.0936, -0.0908]],

         [[ 0.0110,  0.2150, -0.1102],
          [ 0.0645, -0.1693,  0.0013],
          [ 0.0426, -0.1043,  0.1974]]],


        [[[-0.0572, -0.1475, -0.0758],
          [-0.1456,  0.1260,  0.1271],
          [ 0.0740, -0.0241,  0.1486]],

         [[-0.1622, -0.0968, -0.0440],
          [-0.1557,  0.0316,  0.1912],
          [ 0.1739, -0.0716,  0.0416]],

         [[-0.1242,  0.1792, -0.1474],
          [ 0.0787,  0.1606, -0.1605],
          [-0.0068,  0.0718,  0.0349]]],


        [[[-0.1162,  0.1612,  0.0433],
          [ 0.0735,  0.0040, -0.1248],
          [-0.1911,  0.0753, -0.1371]],

         [[ 0.1250,  0.0113,  0.0010],
          [ 0.0402,  0.1126,  0.0791],
          [ 0.0348,  0.0794, -0.1987]],

         [[-0.0830, -0.0214,  0.1291],
          [-0.0001,  0.1456,  0.0604],
          [-0.1422, -0.1074, -0.1402]]],


        ...,


        [[[-0.1300, -0.0688,  0.0071],
          [ 0.1983, -0.0454,  0.0100],
          [ 0.1462, -0.0085,  0.1119]],

         [[ 0.1748,  0.0790, -0.0603],
          [-0.1234, -0.1834, -0.1464],
          [ 0.0471,  0.0688, -0.1638]],

         [[ 0.1673, -0.0647, -0.0632],
          [-0.0994, -0.0943, -0.1784],
          [ 0.0122, -0.0440, -0.0840]]],


        [[[ 0.1325,  0.0966,  0.0427],
          [-0.0272, -0.0649,  0.1028],
          [-0.0445, -0.1540,  0.0637]],

         [[ 0.0637,  0.1712, -0.1538],
          [-0.0514, -0.0546, -0.1391],
          [-0.0947, -0.1501,  0.0451]],

         [[ 0.0359,  0.1671, -0.0894],
          [-0.1171,  0.1149,  0.1085],
          [ 0.0397,  0.0171, -0.0041]]],


        [[[ 0.1280, -0.0408,  0.1172],
          [-0.0431,  0.1389, -0.2240],
          [-0.1409, -0.0895, -0.2108]],

         [[-0.0846,  0.1091, -0.0226],
          [ 0.0665, -0.0259,  0.0584],
          [ 0.0369,  0.0425, -0.0254]],

         [[ 0.1952,  0.2236,  0.1209],
          [ 0.0767,  0.0960,  0.0290],
          [-0.1036, -0.0088,  0.0955]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0968, -0.0865, -0.0597],
          [-0.1340, -0.1191, -0.0965],
          [-0.1260, -0.1095, -0.0939]],

         [[-0.0370, -0.0284, -0.0040],
          [-0.0771, -0.0661, -0.0481],
          [-0.0805, -0.0685, -0.0564]],

         [[-0.0642, -0.0651, -0.0433],
          [-0.0929, -0.0912, -0.0775],
          [-0.0936, -0.0904, -0.0843]]],


        [[[ 0.0054,  0.0148,  0.0158],
          [ 0.0102,  0.0110,  0.0134],
          [ 0.0044,  0.0075,  0.0157]],

         [[ 0.0159,  0.0184,  0.0149],
          [ 0.0173,  0.0128,  0.0105],
          [ 0.0103,  0.0089,  0.0123]],

         [[ 0.0248,  0.0263,  0.0234],
          [ 0.0275,  0.0231,  0.0210],
          [ 0.0250,  0.0238,  0.0262]]],


        [[[-0.1861, -0.1999, -0.1722],
          [-0.1930, -0.2032, -0.1683],
          [-0.1886, -0.1958, -0.1701]],

         [[-0.2149, -0.2344, -0.2092],
          [-0.2236, -0.2381, -0.2052],
          [-0.2205, -0.2289, -0.2023]],

         [[-0.2214, -0.2390, -0.2250],
          [-0.2320, -0.2444, -0.2224],
          [-0.2283, -0.2340, -0.2156]]],


        ...,


        [[[ 0.0397,  0.0313,  0.0227],
          [ 0.0238,  0.0167,  0.0108],
          [ 0.0282,  0.0220,  0.0187]],

         [[ 0.0369,  0.0310,  0.0250],
          [ 0.0212,  0.0160,  0.0122],
          [ 0.0283,  0.0238,  0.0220]],

         [[ 0.0275,  0.0193,  0.0132],
          [ 0.0162,  0.0083,  0.0045],
          [ 0.0249,  0.0179,  0.0153]]],


        [[[-0.0350, -0.0336, -0.0297],
          [-0.0392, -0.0373, -0.0345],
          [-0.0411, -0.0390, -0.0370]],

         [[-0.0283, -0.0281, -0.0253],
          [-0.0303, -0.0299, -0.0290],
          [-0.0317, -0.0306, -0.0303]],

         [[-0.0274, -0.0255, -0.0232],
          [-0.0280, -0.0263, -0.0260],
          [-0.0282, -0.0258, -0.0256]]],


        [[[-0.0015, -0.0027, -0.0025],
          [-0.0030, -0.0034, -0.0032],
          [-0.0036, -0.0035, -0.0041]],

         [[-0.0014, -0.0025, -0.0021],
          [-0.0027, -0.0029, -0.0028],
          [-0.0031, -0.0029, -0.0036]],

         [[-0.0010, -0.0017, -0.0014],
          [-0.0021, -0.0022, -0.0022],
          [-0.0026, -0.0023, -0.0031]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.]], device='cuda:0')

percentage_weight_grad None

Epoch: 1 | Batch_idx: 0 |  Loss: (1.1787) | Acc: (55.00%) (71/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.1753) | Acc: (57.00%) (809/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.2317) | Acc: (55.00%) (1481/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.2100) | Acc: (55.00%) (2200/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.1899) | Acc: (56.00%) (2960/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.1804) | Acc: (57.00%) (3734/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.1725) | Acc: (57.00%) (4498/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.1711) | Acc: (57.00%) (5238/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.1743) | Acc: (57.00%) (5947/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.1707) | Acc: (57.00%) (6690/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.1680) | Acc: (57.00%) (7436/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.1646) | Acc: (57.00%) (8200/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.1643) | Acc: (57.00%) (8942/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.1599) | Acc: (57.00%) (9714/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.1527) | Acc: (58.00%) (10518/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.1515) | Acc: (58.00%) (11267/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.1482) | Acc: (58.00%) (12030/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.1434) | Acc: (58.00%) (12809/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.1377) | Acc: (58.00%) (13610/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.1313) | Acc: (59.00%) (14431/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.1262) | Acc: (59.00%) (15247/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.1201) | Acc: (59.00%) (16054/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.1165) | Acc: (59.00%) (16880/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.1112) | Acc: (59.00%) (17708/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.1089) | Acc: (59.00%) (18506/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.1075) | Acc: (60.00%) (19292/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.1076) | Acc: (60.00%) (20066/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.1043) | Acc: (60.00%) (20857/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.1015) | Acc: (60.00%) (21672/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.0979) | Acc: (60.00%) (22494/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.0953) | Acc: (60.00%) (23298/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.0915) | Acc: (60.00%) (24129/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.0896) | Acc: (60.00%) (24919/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.0867) | Acc: (60.00%) (25748/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.0837) | Acc: (60.00%) (26566/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.0795) | Acc: (61.00%) (27432/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.0747) | Acc: (61.00%) (28297/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.0716) | Acc: (61.00%) (29121/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.0675) | Acc: (61.00%) (29982/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.0642) | Acc: (61.00%) (30808/50000)
# TEST : Loss: (1.0834) | Acc: (61.00%) (6198/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0138,  0.0663, -0.0191],
          [-0.0871,  0.0289,  0.0297],
          [ 0.0224, -0.0974,  0.1677]],

         [[-0.0976,  0.1256,  0.0250],
          [-0.0835,  0.1007, -0.1485],
          [ 0.0205, -0.1038, -0.0867]],

         [[ 0.0049,  0.2163, -0.1343],
          [ 0.0760, -0.1693, -0.0051],
          [ 0.0556, -0.1180,  0.1977]]],


        [[[-0.0602, -0.1520, -0.0910],
          [-0.1445,  0.1336,  0.1227],
          [ 0.0820, -0.0161,  0.1497]],

         [[-0.1613, -0.0940, -0.0515],
          [-0.1557,  0.0415,  0.1894],
          [ 0.1733, -0.0702,  0.0374]],

         [[-0.1297,  0.1758, -0.1556],
          [ 0.0708,  0.1628, -0.1640],
          [-0.0156,  0.0648,  0.0267]]],


        [[[-0.1208,  0.1585,  0.0431],
          [ 0.0719,  0.0075, -0.1249],
          [-0.1910,  0.0747, -0.1401]],

         [[ 0.1210,  0.0097,  0.0001],
          [ 0.0387,  0.1163,  0.0774],
          [ 0.0309,  0.0753, -0.2058]],

         [[-0.0857, -0.0226,  0.1295],
          [-0.0011,  0.1491,  0.0600],
          [-0.1436, -0.1090, -0.1447]]],


        ...,


        [[[-0.1315, -0.0730,  0.0050],
          [ 0.1965, -0.0552,  0.0005],
          [ 0.1480, -0.0114,  0.1083]],

         [[ 0.1712,  0.0691, -0.0622],
          [-0.1283, -0.2058, -0.1641],
          [ 0.0499,  0.0629, -0.1662]],

         [[ 0.1868, -0.0359, -0.0251],
          [-0.0856, -0.0902, -0.1670],
          [ 0.0225, -0.0377, -0.0738]]],


        [[[ 0.1315,  0.0962,  0.0278],
          [-0.0280, -0.0672,  0.0973],
          [-0.0460, -0.1584,  0.0628]],

         [[ 0.0660,  0.1733, -0.1623],
          [-0.0523, -0.0574, -0.1410],
          [-0.0964, -0.1556,  0.0461]],

         [[ 0.0350,  0.1663, -0.1011],
          [-0.1188,  0.1108,  0.1035],
          [ 0.0363,  0.0095, -0.0067]]],


        [[[ 0.1118, -0.0506,  0.0880],
          [-0.0550,  0.1228, -0.2454],
          [-0.1567, -0.1094, -0.2324]],

         [[-0.0947,  0.0994, -0.0491],
          [ 0.0569, -0.0308,  0.0358],
          [ 0.0237,  0.0279, -0.0426]],

         [[ 0.1535,  0.1941,  0.0724],
          [ 0.0599,  0.0883,  0.0057],
          [-0.1146, -0.0172,  0.0799]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0606, -0.0836, -0.1117],
          [-0.0632, -0.0878, -0.1005],
          [-0.0491, -0.0543, -0.0574]],

         [[ 0.0296,  0.0128, -0.0119],
          [ 0.0180, -0.0025, -0.0162],
          [ 0.0161,  0.0174,  0.0147]],

         [[ 0.0605,  0.0516,  0.0309],
          [ 0.0426,  0.0285,  0.0143],
          [ 0.0464,  0.0478,  0.0463]]],


        [[[ 0.0064, -0.0055, -0.0202],
          [ 0.0130, -0.0010, -0.0182],
          [ 0.0032, -0.0015, -0.0125]],

         [[ 0.0030, -0.0077, -0.0176],
          [ 0.0112,  0.0001, -0.0117],
          [ 0.0083,  0.0065, -0.0006]],

         [[ 0.0317,  0.0205,  0.0102],
          [ 0.0452,  0.0334,  0.0221],
          [ 0.0405,  0.0363,  0.0308]]],


        [[[-0.0903, -0.0917, -0.0741],
          [-0.1011, -0.1045, -0.0820],
          [-0.0998, -0.1044, -0.0849]],

         [[-0.1096, -0.1155, -0.0974],
          [-0.1165, -0.1244, -0.1017],
          [-0.1110, -0.1179, -0.0977]],

         [[-0.0711, -0.0780, -0.0667],
          [-0.0834, -0.0926, -0.0778],
          [-0.0843, -0.0926, -0.0787]]],


        ...,


        [[[ 0.0087,  0.0064,  0.0044],
          [ 0.0140,  0.0115,  0.0094],
          [ 0.0234,  0.0238,  0.0231]],

         [[ 0.0121,  0.0081,  0.0039],
          [ 0.0129,  0.0072,  0.0017],
          [ 0.0184,  0.0149,  0.0107]],

         [[ 0.0288,  0.0246,  0.0213],
          [ 0.0282,  0.0218,  0.0174],
          [ 0.0341,  0.0290,  0.0254]]],


        [[[-0.0237, -0.0250, -0.0230],
          [-0.0205, -0.0205, -0.0193],
          [-0.0204, -0.0191, -0.0181]],

         [[-0.0176, -0.0189, -0.0174],
          [-0.0153, -0.0157, -0.0158],
          [-0.0180, -0.0171, -0.0172]],

         [[-0.0111, -0.0121, -0.0105],
          [-0.0094, -0.0095, -0.0095],
          [-0.0105, -0.0096, -0.0097]]],


        [[[-0.0025, -0.0035, -0.0032],
          [-0.0029, -0.0039, -0.0037],
          [-0.0029, -0.0036, -0.0036]],

         [[-0.0027, -0.0036, -0.0034],
          [-0.0033, -0.0042, -0.0040],
          [-0.0037, -0.0044, -0.0044]],

         [[-0.0029, -0.0034, -0.0031],
          [-0.0033, -0.0038, -0.0036],
          [-0.0033, -0.0038, -0.0038]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.]], device='cuda:0')

percentage_weight_grad None

Epoch: 2 | Batch_idx: 0 |  Loss: (0.9863) | Acc: (64.00%) (83/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (0.9146) | Acc: (66.00%) (932/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (0.8993) | Acc: (67.00%) (1824/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (0.8972) | Acc: (67.00%) (2693/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (0.9058) | Acc: (67.00%) (3541/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (0.9031) | Acc: (67.00%) (4439/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (0.9066) | Acc: (67.00%) (5303/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (0.9037) | Acc: (68.00%) (6190/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (0.9081) | Acc: (67.00%) (7044/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (0.9056) | Acc: (68.00%) (7921/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (0.9048) | Acc: (67.00%) (8785/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (0.8995) | Acc: (67.00%) (9661/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (0.8968) | Acc: (68.00%) (10561/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (0.8987) | Acc: (68.00%) (11426/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (0.8963) | Acc: (68.00%) (12326/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (0.8923) | Acc: (68.00%) (13219/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (0.8899) | Acc: (68.00%) (14134/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (0.8899) | Acc: (68.00%) (15002/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (0.8910) | Acc: (68.00%) (15871/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (0.8907) | Acc: (68.00%) (16725/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (0.8905) | Acc: (68.00%) (17604/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (0.8897) | Acc: (68.00%) (18491/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (0.8869) | Acc: (68.00%) (19405/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (0.8876) | Acc: (68.00%) (20264/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (0.8859) | Acc: (68.00%) (21157/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (0.8849) | Acc: (68.00%) (22047/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (0.8830) | Acc: (68.00%) (22947/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (0.8795) | Acc: (68.00%) (23861/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (0.8779) | Acc: (68.00%) (24775/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (0.8741) | Acc: (69.00%) (25709/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (0.8716) | Acc: (69.00%) (26632/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (0.8699) | Acc: (69.00%) (27540/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (0.8685) | Acc: (69.00%) (28443/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (0.8690) | Acc: (69.00%) (29326/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (0.8676) | Acc: (69.00%) (30233/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (0.8675) | Acc: (69.00%) (31137/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (0.8665) | Acc: (69.00%) (32047/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (0.8647) | Acc: (69.00%) (32947/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (0.8633) | Acc: (69.00%) (33870/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (0.8623) | Acc: (69.00%) (34749/50000)
# TEST : Loss: (0.8287) | Acc: (70.00%) (7097/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0196,  0.0688, -0.0318],
          [-0.0811,  0.0308,  0.0259],
          [ 0.0268, -0.1121,  0.1644]],

         [[-0.0977,  0.1333,  0.0234],
          [-0.0725,  0.1057, -0.1417],
          [ 0.0312, -0.1177, -0.0842]],

         [[ 0.0029,  0.2191, -0.1410],
          [ 0.0840, -0.1673, -0.0048],
          [ 0.0621, -0.1328,  0.1950]]],


        [[[-0.0593, -0.1535, -0.0988],
          [-0.1419,  0.1392,  0.1214],
          [ 0.0886, -0.0113,  0.1531]],

         [[-0.1567, -0.0891, -0.0535],
          [-0.1507,  0.0519,  0.1929],
          [ 0.1792, -0.0646,  0.0428]],

         [[-0.1331,  0.1755, -0.1571],
          [ 0.0680,  0.1682, -0.1602],
          [-0.0157,  0.0661,  0.0304]]],


        [[[-0.1206,  0.1609,  0.0478],
          [ 0.0749,  0.0169, -0.1191],
          [-0.1882,  0.0783, -0.1379]],

         [[ 0.1222,  0.0131,  0.0037],
          [ 0.0434,  0.1274,  0.0821],
          [ 0.0321,  0.0785, -0.2053]],

         [[-0.0824, -0.0191,  0.1346],
          [ 0.0045,  0.1597,  0.0664],
          [-0.1397, -0.1028, -0.1403]]],


        ...,


        [[[-0.1417, -0.0870, -0.0089],
          [ 0.1843, -0.0754, -0.0202],
          [ 0.1383, -0.0276,  0.0904]],

         [[ 0.1644,  0.0569, -0.0675],
          [-0.1326, -0.2242, -0.1785],
          [ 0.0523,  0.0575, -0.1699]],

         [[ 0.1944, -0.0286, -0.0135],
          [-0.0802, -0.0985, -0.1728],
          [ 0.0304, -0.0373, -0.0736]]],


        [[[ 0.1339,  0.0977,  0.0216],
          [-0.0238, -0.0678,  0.0953],
          [-0.0364, -0.1573,  0.0652]],

         [[ 0.0670,  0.1731, -0.1670],
          [-0.0529, -0.0616, -0.1417],
          [-0.0915, -0.1591,  0.0482]],

         [[ 0.0409,  0.1713, -0.1003],
          [-0.1129,  0.1128,  0.1063],
          [ 0.0441,  0.0095, -0.0043]]],


        [[[ 0.1177, -0.0425,  0.0929],
          [-0.0470,  0.1251, -0.2407],
          [-0.1544, -0.1119, -0.2320]],

         [[-0.0956,  0.0959, -0.0495],
          [ 0.0531, -0.0323,  0.0291],
          [ 0.0160,  0.0192, -0.0487]],

         [[ 0.1426,  0.1904,  0.0744],
          [ 0.0580,  0.0927,  0.0086],
          [-0.1173, -0.0178,  0.0780]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0198,  0.0415,  0.0301],
          [ 0.0025,  0.0325,  0.0267],
          [ 0.0160,  0.0363,  0.0231]],

         [[ 0.0096,  0.0196,  0.0040],
          [-0.0016,  0.0195,  0.0100],
          [ 0.0257,  0.0422,  0.0276]],

         [[ 0.0196,  0.0232,  0.0103],
          [ 0.0106,  0.0274,  0.0184],
          [ 0.0301,  0.0396,  0.0225]]],


        [[[ 0.0257,  0.0232,  0.0283],
          [ 0.0231,  0.0169,  0.0189],
          [ 0.0332,  0.0336,  0.0225]],

         [[ 0.0281,  0.0295,  0.0380],
          [ 0.0277,  0.0254,  0.0317],
          [ 0.0383,  0.0404,  0.0328]],

         [[ 0.0645,  0.0649,  0.0665],
          [ 0.0546,  0.0511,  0.0524],
          [ 0.0531,  0.0552,  0.0470]]],


        [[[ 0.0849,  0.0925,  0.1029],
          [ 0.0697,  0.0812,  0.0988],
          [ 0.0724,  0.0839,  0.0971]],

         [[ 0.0932,  0.0979,  0.1075],
          [ 0.0817,  0.0900,  0.1080],
          [ 0.0868,  0.0949,  0.1088]],

         [[ 0.0706,  0.0743,  0.0860],
          [ 0.0647,  0.0741,  0.0958],
          [ 0.0702,  0.0823,  0.0991]]],


        ...,


        [[[-0.0086, -0.0056, -0.0053],
          [-0.0096, -0.0038, -0.0011],
          [-0.0100, -0.0021, -0.0000]],

         [[-0.0037, -0.0029, -0.0049],
          [-0.0056, -0.0026, -0.0022],
          [-0.0054, -0.0002, -0.0004]],

         [[-0.0007, -0.0017, -0.0026],
          [-0.0025, -0.0011, -0.0000],
          [-0.0008,  0.0023,  0.0021]]],


        [[[-0.0153, -0.0168, -0.0211],
          [-0.0140, -0.0156, -0.0188],
          [-0.0128, -0.0182, -0.0219]],

         [[-0.0191, -0.0199, -0.0237],
          [-0.0160, -0.0168, -0.0201],
          [-0.0126, -0.0168, -0.0212]],

         [[-0.0194, -0.0191, -0.0217],
          [-0.0164, -0.0161, -0.0186],
          [-0.0125, -0.0165, -0.0207]]],


        [[[ 0.0019,  0.0026,  0.0011],
          [ 0.0009,  0.0009, -0.0002],
          [-0.0001, -0.0003, -0.0015]],

         [[-0.0005,  0.0002, -0.0012],
          [-0.0015, -0.0015, -0.0026],
          [-0.0024, -0.0027, -0.0040]],

         [[-0.0015, -0.0010, -0.0022],
          [-0.0025, -0.0026, -0.0034],
          [-0.0033, -0.0037, -0.0047]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.]], device='cuda:0')

percentage_weight_grad None

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 3 | Batch_idx: 0 |  Loss: (0.7266) | Acc: (75.00%) (97/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (0.8474) | Acc: (70.00%) (996/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (0.9724) | Acc: (66.00%) (1799/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.0546) | Acc: (64.00%) (2545/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.0523) | Acc: (64.00%) (3367/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.0654) | Acc: (64.00%) (4183/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.0653) | Acc: (63.00%) (4980/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.0617) | Acc: (63.00%) (5803/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.0552) | Acc: (64.00%) (6640/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.0464) | Acc: (64.00%) (7484/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.0392) | Acc: (64.00%) (8312/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.0317) | Acc: (64.00%) (9178/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.0225) | Acc: (64.00%) (10060/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.0151) | Acc: (65.00%) (10925/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.0117) | Acc: (65.00%) (11779/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.0050) | Acc: (65.00%) (12661/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.0017) | Acc: (65.00%) (13521/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (0.9976) | Acc: (65.00%) (14390/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (0.9912) | Acc: (65.00%) (15265/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (0.9861) | Acc: (66.00%) (16149/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (0.9811) | Acc: (66.00%) (17043/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (0.9757) | Acc: (66.00%) (17933/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (0.9699) | Acc: (66.00%) (18841/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (0.9655) | Acc: (66.00%) (19732/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (0.9627) | Acc: (66.00%) (20613/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (0.9594) | Acc: (66.00%) (21486/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (0.9543) | Acc: (67.00%) (22406/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (0.9506) | Acc: (67.00%) (23316/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (0.9472) | Acc: (67.00%) (24201/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (0.9453) | Acc: (67.00%) (25078/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (0.9427) | Acc: (67.00%) (25993/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (0.9404) | Acc: (67.00%) (26887/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (0.9361) | Acc: (67.00%) (27814/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (0.9347) | Acc: (67.00%) (28717/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (0.9334) | Acc: (67.00%) (29598/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (0.9313) | Acc: (67.00%) (30500/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (0.9285) | Acc: (68.00%) (31423/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (0.9262) | Acc: (68.00%) (32350/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (0.9249) | Acc: (68.00%) (33241/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (0.9217) | Acc: (68.00%) (34152/50000)
# TEST : Loss: (0.8377) | Acc: (71.00%) (7110/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0175,  0.0707, -0.0299],
          [-0.0793,  0.0321,  0.0270],
          [ 0.0285, -0.1112,  0.1654]],

         [[-0.0953,  0.1355,  0.0256],
          [-0.0707,  0.1069, -0.1404],
          [ 0.0328, -0.1171, -0.0832]],

         [[ 0.0048,  0.2209, -0.1392],
          [ 0.0854, -0.1660, -0.0039],
          [ 0.0636, -0.1320,  0.1958]]],


        [[[-0.0605, -0.1541, -0.0995],
          [-0.1427,  0.1387,  0.1207],
          [ 0.0877, -0.0117,  0.1527]],

         [[-0.1577, -0.0897, -0.0542],
          [-0.1515,  0.0514,  0.1920],
          [ 0.1779, -0.0653,  0.0421]],

         [[-0.1352,  0.1735, -0.1584],
          [ 0.0659,  0.1666, -0.1614],
          [-0.0177,  0.0642,  0.0288]]],


        [[[-0.1225,  0.1587,  0.0453],
          [ 0.0731,  0.0149, -0.1216],
          [-0.1898,  0.0761, -0.1404]],

         [[ 0.1199,  0.0108,  0.0011],
          [ 0.0415,  0.1253,  0.0794],
          [ 0.0302,  0.0761, -0.2080]],

         [[-0.0842, -0.0210,  0.1324],
          [ 0.0029,  0.1579,  0.0641],
          [-0.1414, -0.1047, -0.1427]]],


        ...,


        [[[-0.1398, -0.0852, -0.0071],
          [ 0.1848, -0.0745, -0.0197],
          [ 0.1382, -0.0278,  0.0898]],

         [[ 0.1648,  0.0578, -0.0657],
          [-0.1318, -0.2231, -0.1781],
          [ 0.0515,  0.0558, -0.1710]],

         [[ 0.1941, -0.0276, -0.0123],
          [-0.0795, -0.0975, -0.1718],
          [ 0.0300, -0.0380, -0.0745]]],


        [[[ 0.1385,  0.1032,  0.0280],
          [-0.0181, -0.0613,  0.1016],
          [-0.0307, -0.1504,  0.0721]],

         [[ 0.0721,  0.1783, -0.1601],
          [-0.0475, -0.0558, -0.1350],
          [-0.0865, -0.1534,  0.0540]],

         [[ 0.0466,  0.1770, -0.0931],
          [-0.1069,  0.1183,  0.1124],
          [ 0.0486,  0.0147,  0.0020]]],


        [[[ 0.1166, -0.0399,  0.0939],
          [-0.0439,  0.1252, -0.2315],
          [-0.1488, -0.1064, -0.2229]],

         [[-0.0907,  0.0966, -0.0439],
          [ 0.0550, -0.0276,  0.0331],
          [ 0.0184,  0.0222, -0.0430]],

         [[ 0.1427,  0.1897,  0.0784],
          [ 0.0604,  0.0954,  0.0143],
          [-0.1114, -0.0132,  0.0814]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.0855]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0683]], device='cuda:0')

Epoch: 4 | Batch_idx: 0 |  Loss: (0.8497) | Acc: (67.00%) (87/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (0.8096) | Acc: (71.00%) (1001/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (0.8313) | Acc: (70.00%) (1903/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (0.8495) | Acc: (70.00%) (2795/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (0.8392) | Acc: (70.00%) (3721/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (0.8453) | Acc: (70.00%) (4629/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (0.8501) | Acc: (70.00%) (5513/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (0.8415) | Acc: (70.00%) (6450/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (0.8404) | Acc: (70.00%) (7360/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (0.8374) | Acc: (71.00%) (8286/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (0.8343) | Acc: (71.00%) (9215/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (0.8385) | Acc: (71.00%) (10090/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (0.8389) | Acc: (70.00%) (10995/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (0.8405) | Acc: (70.00%) (11902/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (0.8391) | Acc: (71.00%) (12820/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (0.8409) | Acc: (70.00%) (13719/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (0.8372) | Acc: (71.00%) (14665/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (0.8354) | Acc: (71.00%) (15589/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (0.8335) | Acc: (71.00%) (16517/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (0.8333) | Acc: (71.00%) (17427/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (0.8339) | Acc: (71.00%) (18354/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (0.8351) | Acc: (71.00%) (19248/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (0.8361) | Acc: (71.00%) (20165/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (0.8331) | Acc: (71.00%) (21116/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (0.8312) | Acc: (71.00%) (22065/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (0.8296) | Acc: (71.00%) (22983/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (0.8295) | Acc: (71.00%) (23907/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (0.8282) | Acc: (71.00%) (24833/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (0.8258) | Acc: (71.00%) (25767/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (0.8278) | Acc: (71.00%) (26649/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (0.8280) | Acc: (71.00%) (27567/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (0.8276) | Acc: (71.00%) (28497/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (0.8285) | Acc: (71.00%) (29388/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (0.8274) | Acc: (71.00%) (30323/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (0.8289) | Acc: (71.00%) (31213/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (0.8269) | Acc: (71.00%) (32156/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (0.8262) | Acc: (71.00%) (33083/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (0.8251) | Acc: (71.00%) (34016/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (0.8253) | Acc: (71.00%) (34920/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (0.8251) | Acc: (71.00%) (35819/50000)
# TEST : Loss: (0.8098) | Acc: (72.00%) (7211/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0175,  0.0706, -0.0298],
          [-0.0792,  0.0320,  0.0270],
          [ 0.0285, -0.1111,  0.1653]],

         [[-0.0952,  0.1354,  0.0256],
          [-0.0706,  0.1068, -0.1403],
          [ 0.0327, -0.1170, -0.0832]],

         [[ 0.0048,  0.2207, -0.1391],
          [ 0.0854, -0.1659, -0.0039],
          [ 0.0635, -0.1319,  0.1957]]],


        [[[-0.0604, -0.1539, -0.0994],
          [-0.1425,  0.1385,  0.1205],
          [ 0.0876, -0.0117,  0.1525]],

         [[-0.1574, -0.0896, -0.0541],
          [-0.1513,  0.0514,  0.1918],
          [ 0.1776, -0.0652,  0.0421]],

         [[-0.1350,  0.1733, -0.1582],
          [ 0.0658,  0.1664, -0.1611],
          [-0.0177,  0.0642,  0.0287]]],


        [[[-0.1224,  0.1586,  0.0452],
          [ 0.0730,  0.0149, -0.1215],
          [-0.1896,  0.0760, -0.1402]],

         [[ 0.1198,  0.0107,  0.0010],
          [ 0.0415,  0.1252,  0.0793],
          [ 0.0302,  0.0761, -0.2077]],

         [[-0.0842, -0.0210,  0.1322],
          [ 0.0029,  0.1577,  0.0640],
          [-0.1412, -0.1046, -0.1425]]],


        ...,


        [[[-0.1394, -0.0849, -0.0071],
          [ 0.1842, -0.0742, -0.0197],
          [ 0.1378, -0.0277,  0.0895]],

         [[ 0.1642,  0.0575, -0.0653],
          [-0.1312, -0.2218, -0.1768],
          [ 0.0513,  0.0555, -0.1701]],

         [[ 0.1932, -0.0274, -0.0122],
          [-0.0791, -0.0967, -0.1701],
          [ 0.0299, -0.0377, -0.0740]]],


        [[[ 0.1379,  0.1027,  0.0278],
          [-0.0180, -0.0610,  0.1012],
          [-0.0305, -0.1497,  0.0717]],

         [[ 0.0718,  0.1775, -0.1594],
          [-0.0472, -0.0555, -0.1344],
          [-0.0861, -0.1527,  0.0538]],

         [[ 0.0464,  0.1762, -0.0926],
          [-0.1064,  0.1178,  0.1119],
          [ 0.0483,  0.0146,  0.0020]]],


        [[[ 0.1134, -0.0388,  0.0913],
          [-0.0427,  0.1217, -0.2248],
          [-0.1447, -0.1034, -0.2166]],

         [[-0.0879,  0.0936, -0.0425],
          [ 0.0533, -0.0267,  0.0321],
          [ 0.0178,  0.0215, -0.0418]],

         [[ 0.1375,  0.1827,  0.0756],
          [ 0.0584,  0.0921,  0.0139],
          [-0.1079, -0.0128,  0.0789]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.1782]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0056]], device='cuda:0')

Epoch: 5 | Batch_idx: 0 |  Loss: (0.8196) | Acc: (75.00%) (96/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (0.7890) | Acc: (73.00%) (1040/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (0.7935) | Acc: (73.00%) (1963/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (0.7810) | Acc: (73.00%) (2898/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (0.7811) | Acc: (73.00%) (3847/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (0.7834) | Acc: (73.00%) (4789/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (0.7827) | Acc: (73.00%) (5737/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (0.7866) | Acc: (73.00%) (6665/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (0.7911) | Acc: (73.00%) (7581/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (0.7921) | Acc: (73.00%) (8526/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (0.7961) | Acc: (73.00%) (9451/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (0.7967) | Acc: (72.00%) (10367/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (0.7984) | Acc: (72.00%) (11304/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (0.8025) | Acc: (72.00%) (12202/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (0.8003) | Acc: (72.00%) (13155/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (0.8045) | Acc: (72.00%) (14058/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (0.8057) | Acc: (72.00%) (14983/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (0.8058) | Acc: (72.00%) (15913/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (0.8069) | Acc: (72.00%) (16810/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (0.8109) | Acc: (72.00%) (17694/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (0.8114) | Acc: (72.00%) (18623/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (0.8098) | Acc: (72.00%) (19574/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (0.8097) | Acc: (72.00%) (20509/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (0.8105) | Acc: (72.00%) (21412/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (0.8115) | Acc: (72.00%) (22332/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (0.8102) | Acc: (72.00%) (23280/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (0.8111) | Acc: (72.00%) (24198/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (0.8106) | Acc: (72.00%) (25119/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (0.8110) | Acc: (72.00%) (26036/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (0.8104) | Acc: (72.00%) (26953/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (0.8110) | Acc: (72.00%) (27874/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (0.8121) | Acc: (72.00%) (28783/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (0.8118) | Acc: (72.00%) (29703/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (0.8114) | Acc: (72.00%) (30624/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (0.8112) | Acc: (72.00%) (31558/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (0.8114) | Acc: (72.00%) (32472/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (0.8108) | Acc: (72.00%) (33407/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (0.8105) | Acc: (72.00%) (34337/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (0.8102) | Acc: (72.00%) (35274/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (0.8100) | Acc: (72.00%) (36175/50000)
# TEST : Loss: (0.8098) | Acc: (72.00%) (7211/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0175,  0.0705, -0.0298],
          [-0.0792,  0.0320,  0.0270],
          [ 0.0285, -0.1110,  0.1651]],

         [[-0.0951,  0.1352,  0.0256],
          [-0.0706,  0.1067, -0.1401],
          [ 0.0327, -0.1169, -0.0831]],

         [[ 0.0048,  0.2205, -0.1390],
          [ 0.0853, -0.1657, -0.0039],
          [ 0.0635, -0.1317,  0.1955]]],


        [[[-0.0603, -0.1536, -0.0992],
          [-0.1423,  0.1383,  0.1203],
          [ 0.0874, -0.0117,  0.1522]],

         [[-0.1571, -0.0894, -0.0540],
          [-0.1510,  0.0513,  0.1914],
          [ 0.1773, -0.0651,  0.0420]],

         [[-0.1347,  0.1729, -0.1579],
          [ 0.0657,  0.1661, -0.1609],
          [-0.0176,  0.0640,  0.0287]]],


        [[[-0.1222,  0.1584,  0.0452],
          [ 0.0729,  0.0148, -0.1214],
          [-0.1894,  0.0760, -0.1401]],

         [[ 0.1197,  0.0107,  0.0010],
          [ 0.0414,  0.1250,  0.0792],
          [ 0.0301,  0.0760, -0.2075]],

         [[-0.0841, -0.0210,  0.1321],
          [ 0.0029,  0.1575,  0.0639],
          [-0.1410, -0.1045, -0.1423]]],


        ...,


        [[[-0.1388, -0.0846, -0.0071],
          [ 0.1835, -0.0739, -0.0196],
          [ 0.1373, -0.0276,  0.0892]],

         [[ 0.1634,  0.0572, -0.0648],
          [-0.1304, -0.2200, -0.1753],
          [ 0.0510,  0.0552, -0.1690]],

         [[ 0.1922, -0.0272, -0.0121],
          [-0.0785, -0.0957, -0.1680],
          [ 0.0297, -0.0375, -0.0734]]],


        [[[ 0.1372,  0.1022,  0.0277],
          [-0.0179, -0.0606,  0.1006],
          [-0.0303, -0.1488,  0.0713]],

         [[ 0.0714,  0.1766, -0.1585],
          [-0.0470, -0.0552, -0.1337],
          [-0.0856, -0.1518,  0.0535]],

         [[ 0.0461,  0.1752, -0.0921],
          [-0.1058,  0.1171,  0.1112],
          [ 0.0480,  0.0145,  0.0020]]],


        [[[ 0.1095, -0.0375,  0.0880],
          [-0.0412,  0.1174, -0.2167],
          [-0.1396, -0.0998, -0.2088]],

         [[-0.0845,  0.0900, -0.0408],
          [ 0.0513, -0.0257,  0.0309],
          [ 0.0172,  0.0207, -0.0402]],

         [[ 0.1313,  0.1744,  0.0721],
          [ 0.0559,  0.0881,  0.0133],
          [-0.1037, -0.0123,  0.0759]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2285]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0154]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 6 | Batch_idx: 0 |  Loss: (0.8988) | Acc: (69.00%) (89/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.3044) | Acc: (53.00%) (749/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.2292) | Acc: (55.00%) (1487/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.1990) | Acc: (56.00%) (2246/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.1651) | Acc: (57.00%) (3039/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.1508) | Acc: (58.00%) (3808/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.1386) | Acc: (58.00%) (4604/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.1185) | Acc: (59.00%) (5423/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.1089) | Acc: (59.00%) (6213/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.0875) | Acc: (60.00%) (7077/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.0765) | Acc: (61.00%) (7929/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.0676) | Acc: (61.00%) (8783/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.0508) | Acc: (62.00%) (9689/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.0456) | Acc: (62.00%) (10542/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.0346) | Acc: (63.00%) (11418/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.0261) | Acc: (63.00%) (12285/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.0164) | Acc: (63.00%) (13163/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.0060) | Acc: (64.00%) (14032/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (0.9977) | Acc: (64.00%) (14928/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (0.9886) | Acc: (64.00%) (15841/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (0.9818) | Acc: (65.00%) (16739/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (0.9737) | Acc: (65.00%) (17652/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (0.9675) | Acc: (65.00%) (18559/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (0.9611) | Acc: (65.00%) (19479/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (0.9548) | Acc: (66.00%) (20402/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (0.9508) | Acc: (66.00%) (21300/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (0.9459) | Acc: (66.00%) (22217/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (0.9409) | Acc: (66.00%) (23139/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (0.9349) | Acc: (66.00%) (24084/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (0.9294) | Acc: (67.00%) (25027/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (0.9248) | Acc: (67.00%) (25958/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (0.9209) | Acc: (67.00%) (26873/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (0.9170) | Acc: (67.00%) (27789/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (0.9120) | Acc: (67.00%) (28749/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (0.9083) | Acc: (67.00%) (29669/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (0.9033) | Acc: (68.00%) (30621/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (0.8983) | Acc: (68.00%) (31563/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (0.8945) | Acc: (68.00%) (32511/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (0.8905) | Acc: (68.00%) (33461/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (0.8859) | Acc: (68.00%) (34390/50000)
# TEST : Loss: (0.7498) | Acc: (74.00%) (7400/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0273,  0.0790, -0.0352],
          [-0.0694,  0.0414,  0.0382],
          [ 0.0392, -0.1226,  0.1800]],

         [[-0.1046,  0.1414,  0.0267],
          [-0.0588,  0.1124, -0.1238],
          [ 0.0554, -0.1282, -0.0639]],

         [[-0.0084,  0.2127, -0.1544],
          [ 0.0904, -0.1723, -0.0098],
          [ 0.0721, -0.1572,  0.1885]]],


        [[[-0.0607, -0.1608, -0.1075],
          [-0.1367,  0.1471,  0.1236],
          [ 0.0986, -0.0038,  0.1575]],

         [[-0.1561, -0.0898, -0.0568],
          [-0.1444,  0.0641,  0.1959],
          [ 0.1855, -0.0605,  0.0430]],

         [[-0.1348,  0.1697, -0.1577],
          [ 0.0687,  0.1763, -0.1518],
          [-0.0129,  0.0676,  0.0332]]],


        [[[-0.1235,  0.1603,  0.0506],
          [ 0.0750,  0.0242, -0.1175],
          [-0.1846,  0.0759, -0.1474]],

         [[ 0.1132,  0.0128,  0.0057],
          [ 0.0380,  0.1337,  0.0827],
          [ 0.0231,  0.0693, -0.2173]],

         [[-0.0880, -0.0168,  0.1428],
          [ 0.0008,  0.1673,  0.0727],
          [-0.1424, -0.1037, -0.1419]]],


        ...,


        [[[-0.1348, -0.0842, -0.0030],
          [ 0.1855, -0.0837, -0.0276],
          [ 0.1420, -0.0287,  0.0864]],

         [[ 0.1640,  0.0493, -0.0634],
          [-0.1305, -0.2433, -0.1937],
          [ 0.0577,  0.0558, -0.1667]],

         [[ 0.2010, -0.0132,  0.0139],
          [-0.0759, -0.1026, -0.1601],
          [ 0.0304, -0.0385, -0.0699]]],


        [[[ 0.1325,  0.0957,  0.0140],
          [-0.0206, -0.0678,  0.0926],
          [-0.0317, -0.1588,  0.0580]],

         [[ 0.0587,  0.1623, -0.1762],
          [-0.0605, -0.0714, -0.1465],
          [-0.0961, -0.1696,  0.0340]],

         [[ 0.0349,  0.1630, -0.1076],
          [-0.1137,  0.1058,  0.0998],
          [ 0.0408,  0.0024, -0.0132]]],


        [[[ 0.1194, -0.0199,  0.0991],
          [-0.0211,  0.1329, -0.1939],
          [-0.1226, -0.0861, -0.1955]],

         [[-0.0660,  0.1034, -0.0234],
          [ 0.0651, -0.0060,  0.0429],
          [ 0.0247,  0.0281, -0.0338]],

         [[ 0.1334,  0.1762,  0.0753],
          [ 0.0654,  0.0982,  0.0188],
          [-0.0933, -0.0059,  0.0735]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 3.2300e-02,  3.8112e-02,  1.2715e-01],
          [-9.4879e-03, -1.8522e-02,  3.8777e-02],
          [-3.0915e-02, -3.3110e-02,  1.1422e-02]],

         [[ 3.7366e-02,  3.7798e-02,  8.1912e-02],
          [-6.7532e-03, -9.3741e-03,  1.5410e-02],
          [-3.1215e-02, -2.1025e-02,  7.6316e-03]],

         [[-3.3134e-02, -2.1191e-02,  1.7293e-02],
          [-9.0209e-02, -8.2437e-02, -4.7927e-02],
          [-1.4042e-01, -1.2449e-01, -7.7514e-02]]],


        [[[ 3.4085e-02,  1.1495e-02,  4.3691e-03],
          [ 3.7925e-02,  2.0080e-02,  8.8104e-03],
          [ 3.2910e-02,  2.4779e-02,  2.6129e-02]],

         [[-5.1247e-03, -2.5417e-02, -2.9792e-02],
          [ 5.0583e-03, -1.2122e-02, -2.3398e-02],
          [ 4.1289e-03, -4.2590e-03, -4.8458e-03]],

         [[-3.2062e-02, -4.7596e-02, -4.7695e-02],
          [-2.6956e-02, -3.9574e-02, -4.6249e-02],
          [-3.2182e-02, -3.7540e-02, -3.5697e-02]]],


        [[[ 8.3636e-02,  8.5476e-02,  9.5274e-02],
          [ 8.8791e-02,  8.7611e-02,  9.2458e-02],
          [ 1.0212e-01,  9.0497e-02,  9.9541e-02]],

         [[ 1.1478e-01,  1.2116e-01,  1.2686e-01],
          [ 1.1654e-01,  1.1949e-01,  1.1829e-01],
          [ 1.2244e-01,  1.1536e-01,  1.1941e-01]],

         [[ 1.2097e-01,  1.2686e-01,  1.2796e-01],
          [ 1.2933e-01,  1.3427e-01,  1.2710e-01],
          [ 1.2508e-01,  1.2131e-01,  1.2079e-01]]],


        ...,


        [[[-5.2344e-03, -9.2594e-03,  1.6202e-03],
          [-4.9830e-03, -1.0742e-02, -1.6103e-03],
          [-6.0190e-03, -1.1774e-02, -6.8133e-03]],

         [[ 5.2975e-03,  1.8518e-03,  9.7859e-03],
          [ 4.1210e-03, -9.6861e-04,  5.3792e-03],
          [ 1.7087e-03, -3.1109e-03, -3.7216e-05]],

         [[ 2.0367e-02,  1.5228e-02,  2.0795e-02],
          [ 1.4571e-02,  7.1357e-03,  1.0472e-02],
          [ 1.0187e-02,  2.7649e-03,  2.6776e-03]]],


        [[[ 1.4087e-02,  1.6664e-02,  1.9751e-02],
          [ 7.1767e-03,  1.1269e-02,  1.6452e-02],
          [ 3.9289e-03,  6.2088e-03,  1.1696e-02]],

         [[ 2.0536e-02,  2.2327e-02,  2.3867e-02],
          [ 1.3993e-02,  1.7807e-02,  2.1320e-02],
          [ 9.5146e-03,  1.1972e-02,  1.6421e-02]],

         [[ 1.5208e-02,  1.6852e-02,  1.7701e-02],
          [ 7.3768e-03,  1.0631e-02,  1.3849e-02],
          [ 2.5396e-03,  4.6468e-03,  9.3047e-03]]],


        [[[ 2.5898e-04,  2.2960e-04,  3.1488e-04],
          [ 2.4165e-05,  8.7385e-05,  2.4414e-04],
          [ 2.9193e-05,  1.1665e-04,  2.2280e-04]],

         [[ 2.0456e-04,  1.3059e-04,  1.4363e-04],
          [-7.0372e-05,  1.2310e-05,  1.4798e-04],
          [-3.2545e-05,  1.4232e-04,  3.1612e-04]],

         [[ 1.8428e-04,  7.9605e-06,  3.1212e-06],
          [-1.4968e-04, -7.9014e-05,  6.1025e-05],
          [-1.3237e-04,  7.3541e-05,  3.1722e-04]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2312]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 7 | Batch_idx: 0 |  Loss: (0.6237) | Acc: (76.00%) (98/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (0.7017) | Acc: (75.00%) (1064/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (0.6987) | Acc: (76.00%) (2045/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (0.7088) | Acc: (75.00%) (3009/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (0.7091) | Acc: (75.00%) (3971/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (0.7125) | Acc: (75.00%) (4937/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (0.7169) | Acc: (75.00%) (5893/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (0.7100) | Acc: (75.00%) (6870/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (0.7108) | Acc: (75.00%) (7839/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (0.7109) | Acc: (75.00%) (8801/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (0.7100) | Acc: (75.00%) (9760/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (0.7093) | Acc: (75.00%) (10730/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (0.7076) | Acc: (75.00%) (11711/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (0.7043) | Acc: (75.00%) (12684/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (0.7037) | Acc: (75.00%) (13660/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (0.7004) | Acc: (75.00%) (14662/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (0.6973) | Acc: (75.00%) (15654/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (0.6970) | Acc: (75.00%) (16616/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (0.6926) | Acc: (76.00%) (17621/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (0.6908) | Acc: (76.00%) (18606/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (0.6879) | Acc: (76.00%) (19614/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (0.6874) | Acc: (76.00%) (20575/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (0.6862) | Acc: (76.00%) (21565/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (0.6838) | Acc: (76.00%) (22561/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (0.6832) | Acc: (76.00%) (23558/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (0.6820) | Acc: (76.00%) (24566/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (0.6797) | Acc: (76.00%) (25571/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (0.6788) | Acc: (76.00%) (26566/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (0.6784) | Acc: (76.00%) (27558/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (0.6772) | Acc: (76.00%) (28552/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (0.6761) | Acc: (76.00%) (29553/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (0.6739) | Acc: (76.00%) (30560/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (0.6727) | Acc: (76.00%) (31564/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (0.6729) | Acc: (76.00%) (32548/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (0.6726) | Acc: (76.00%) (33526/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (0.6709) | Acc: (76.00%) (34541/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (0.6687) | Acc: (76.00%) (35554/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (0.6672) | Acc: (77.00%) (36572/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (0.6659) | Acc: (77.00%) (37574/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (0.6660) | Acc: (77.00%) (38516/50000)
# TEST : Loss: (0.7255) | Acc: (75.00%) (7517/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0366,  0.0799, -0.0460],
          [-0.0702,  0.0412,  0.0388],
          [ 0.0341, -0.1346,  0.1861]],

         [[-0.1086,  0.1444,  0.0255],
          [-0.0568,  0.1104, -0.1221],
          [ 0.0547, -0.1386, -0.0566]],

         [[-0.0130,  0.2168, -0.1518],
          [ 0.0959, -0.1620, -0.0023],
          [ 0.0787, -0.1534,  0.2005]]],


        [[[-0.0708, -0.1728, -0.1187],
          [-0.1456,  0.1449,  0.1221],
          [ 0.0912, -0.0103,  0.1512]],

         [[-0.1666, -0.1018, -0.0708],
          [-0.1518,  0.0626,  0.1917],
          [ 0.1792, -0.0672,  0.0348]],

         [[-0.1380,  0.1642, -0.1652],
          [ 0.0647,  0.1772, -0.1527],
          [-0.0171,  0.0625,  0.0266]]],


        [[[-0.1244,  0.1629,  0.0512],
          [ 0.0731,  0.0267, -0.1221],
          [-0.1845,  0.0729, -0.1541]],

         [[ 0.1087,  0.0130,  0.0019],
          [ 0.0321,  0.1340,  0.0744],
          [ 0.0157,  0.0607, -0.2298]],

         [[-0.0931, -0.0209,  0.1362],
          [-0.0070,  0.1633,  0.0628],
          [-0.1499, -0.1131, -0.1551]]],


        ...,


        [[[-0.1350, -0.0816,  0.0001],
          [ 0.1835, -0.0874, -0.0278],
          [ 0.1417, -0.0283,  0.0875]],

         [[ 0.1651,  0.0488, -0.0636],
          [-0.1320, -0.2556, -0.2025],
          [ 0.0593,  0.0531, -0.1682]],

         [[ 0.2086, -0.0050,  0.0194],
          [-0.0721, -0.1037, -0.1565],
          [ 0.0317, -0.0407, -0.0708]]],


        [[[ 0.1258,  0.0910,  0.0089],
          [-0.0282, -0.0749,  0.0899],
          [-0.0380, -0.1678,  0.0507]],

         [[ 0.0535,  0.1556, -0.1803],
          [-0.0651, -0.0770, -0.1463],
          [-0.0968, -0.1738,  0.0302]],

         [[ 0.0327,  0.1594, -0.1091],
          [-0.1114,  0.1069,  0.1044],
          [ 0.0437,  0.0028, -0.0128]]],


        [[[ 0.1075, -0.0195,  0.0908],
          [-0.0259,  0.1252, -0.1875],
          [-0.1263, -0.0890, -0.1907]],

         [[-0.0692,  0.0993, -0.0257],
          [ 0.0585, -0.0054,  0.0394],
          [ 0.0183,  0.0227, -0.0348]],

         [[ 0.1196,  0.1694,  0.0709],
          [ 0.0617,  0.0969,  0.0199],
          [-0.0903, -0.0058,  0.0712]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0724,  0.0667,  0.0427],
          [ 0.0432,  0.0360,  0.0223],
          [-0.0220, -0.0173, -0.0347]],

         [[ 0.1155,  0.1025,  0.0880],
          [ 0.0873,  0.0659,  0.0597],
          [ 0.0175,  0.0137, -0.0038]],

         [[ 0.0720,  0.0747,  0.0576],
          [ 0.0303,  0.0132,  0.0293],
          [-0.0472, -0.0429, -0.0200]]],


        [[[-0.0249, -0.0226, -0.0253],
          [-0.0216, -0.0253, -0.0329],
          [-0.0193, -0.0278, -0.0394]],

         [[ 0.0048,  0.0121,  0.0113],
          [ 0.0127,  0.0119,  0.0057],
          [ 0.0186,  0.0112,  0.0009]],

         [[ 0.0189,  0.0316,  0.0321],
          [ 0.0313,  0.0368,  0.0321],
          [ 0.0400,  0.0391,  0.0295]]],


        [[[-0.0598, -0.0605, -0.0434],
          [-0.0608, -0.0668, -0.0471],
          [-0.0577, -0.0639, -0.0481]],

         [[-0.0309, -0.0387, -0.0334],
          [-0.0362, -0.0505, -0.0400],
          [-0.0363, -0.0488, -0.0386]],

         [[-0.0319, -0.0320, -0.0288],
          [-0.0230, -0.0296, -0.0259],
          [-0.0121, -0.0224, -0.0218]]],


        ...,


        [[[ 0.0273,  0.0277,  0.0215],
          [ 0.0239,  0.0226,  0.0154],
          [ 0.0263,  0.0246,  0.0185]],

         [[ 0.0146,  0.0154,  0.0099],
          [ 0.0106,  0.0102,  0.0044],
          [ 0.0162,  0.0165,  0.0123]],

         [[ 0.0192,  0.0183,  0.0122],
          [ 0.0119,  0.0082,  0.0009],
          [ 0.0137,  0.0106,  0.0048]]],


        [[[ 0.0016,  0.0031,  0.0045],
          [ 0.0015,  0.0025,  0.0036],
          [-0.0016,  0.0007,  0.0019]],

         [[ 0.0049,  0.0052,  0.0053],
          [ 0.0035,  0.0035,  0.0040],
          [-0.0006,  0.0010,  0.0020]],

         [[ 0.0031,  0.0035,  0.0034],
          [ 0.0017,  0.0014,  0.0020],
          [-0.0023, -0.0014, -0.0002]]],


        [[[-0.0005, -0.0005, -0.0008],
          [-0.0009, -0.0008, -0.0010],
          [-0.0010, -0.0009, -0.0009]],

         [[-0.0005, -0.0004, -0.0008],
          [-0.0007, -0.0007, -0.0008],
          [-0.0008, -0.0006, -0.0007]],

         [[-0.0006, -0.0005, -0.0008],
          [-0.0007, -0.0006, -0.0008],
          [-0.0008, -0.0006, -0.0007]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2308]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 8 | Batch_idx: 0 |  Loss: (0.5033) | Acc: (83.00%) (107/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (0.6146) | Acc: (80.00%) (1128/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (0.5937) | Acc: (80.00%) (2158/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (0.6006) | Acc: (79.00%) (3171/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (0.5922) | Acc: (79.00%) (4188/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (0.5879) | Acc: (79.00%) (5222/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (0.5923) | Acc: (79.00%) (6243/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (0.5907) | Acc: (80.00%) (7285/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (0.5883) | Acc: (80.00%) (8320/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (0.5893) | Acc: (80.00%) (9326/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (0.5895) | Acc: (80.00%) (10344/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (0.5854) | Acc: (80.00%) (11382/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (0.5879) | Acc: (79.00%) (12374/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (0.5854) | Acc: (79.00%) (13413/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (0.5825) | Acc: (79.00%) (14438/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (0.5814) | Acc: (79.00%) (15457/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (0.5835) | Acc: (79.00%) (16461/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (0.5838) | Acc: (79.00%) (17492/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (0.5849) | Acc: (79.00%) (18514/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (0.5842) | Acc: (79.00%) (19557/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (0.5843) | Acc: (80.00%) (20585/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (0.5827) | Acc: (80.00%) (21636/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (0.5814) | Acc: (80.00%) (22664/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (0.5826) | Acc: (80.00%) (23662/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (0.5826) | Acc: (80.00%) (24690/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (0.5807) | Acc: (80.00%) (25743/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (0.5799) | Acc: (80.00%) (26785/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (0.5789) | Acc: (80.00%) (27814/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (0.5783) | Acc: (80.00%) (28846/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (0.5772) | Acc: (80.00%) (29882/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (0.5764) | Acc: (80.00%) (30918/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (0.5763) | Acc: (80.00%) (31954/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (0.5766) | Acc: (80.00%) (32975/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (0.5781) | Acc: (80.00%) (33992/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (0.5784) | Acc: (80.00%) (35025/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (0.5760) | Acc: (80.00%) (36094/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (0.5757) | Acc: (80.00%) (37121/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (0.5758) | Acc: (80.00%) (38141/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (0.5736) | Acc: (80.00%) (39193/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (0.5722) | Acc: (80.00%) (40227/50000)
# TEST : Loss: (0.6558) | Acc: (78.00%) (7809/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0369,  0.0860, -0.0498],
          [-0.0733,  0.0375,  0.0285],
          [ 0.0295, -0.1457,  0.1834]],

         [[-0.1051,  0.1557,  0.0317],
          [-0.0606,  0.1058, -0.1281],
          [ 0.0471, -0.1514, -0.0581]],

         [[-0.0233,  0.2143, -0.1516],
          [ 0.0815, -0.1687, -0.0104],
          [ 0.0688, -0.1633,  0.1984]]],


        [[[-0.0671, -0.1702, -0.1112],
          [-0.1385,  0.1564,  0.1355],
          [ 0.1021, -0.0020,  0.1591]],

         [[-0.1631, -0.1020, -0.0701],
          [-0.1448,  0.0706,  0.1980],
          [ 0.1865, -0.0655,  0.0349]],

         [[-0.1346,  0.1646, -0.1632],
          [ 0.0690,  0.1842, -0.1460],
          [-0.0149,  0.0618,  0.0251]]],


        [[[-0.1204,  0.1676,  0.0538],
          [ 0.0794,  0.0342, -0.1192],
          [-0.1825,  0.0738, -0.1531]],

         [[ 0.1124,  0.0180,  0.0049],
          [ 0.0399,  0.1423,  0.0775],
          [ 0.0150,  0.0585, -0.2309]],

         [[-0.0824, -0.0123,  0.1420],
          [ 0.0030,  0.1714,  0.0660],
          [-0.1468, -0.1122, -0.1548]]],


        ...,


        [[[-0.1369, -0.0799,  0.0071],
          [ 0.1821, -0.0892, -0.0261],
          [ 0.1380, -0.0325,  0.0849]],

         [[ 0.1709,  0.0556, -0.0537],
          [-0.1282, -0.2576, -0.2059],
          [ 0.0565,  0.0449, -0.1757]],

         [[ 0.2198,  0.0074,  0.0320],
          [-0.0620, -0.0994, -0.1569],
          [ 0.0320, -0.0492, -0.0834]]],


        [[[ 0.1195,  0.0857,  0.0040],
          [-0.0332, -0.0808,  0.0822],
          [-0.0386, -0.1737,  0.0421]],

         [[ 0.0436,  0.1433, -0.1913],
          [-0.0705, -0.0857, -0.1573],
          [-0.0945, -0.1776,  0.0200]],

         [[ 0.0268,  0.1517, -0.1158],
          [-0.1123,  0.1021,  0.0962],
          [ 0.0486,  0.0018, -0.0196]]],


        [[[ 0.0999, -0.0214,  0.0829],
          [-0.0255,  0.1201, -0.1801],
          [-0.1216, -0.0870, -0.1873]],

         [[-0.0679,  0.0921, -0.0260],
          [ 0.0536, -0.0025,  0.0379],
          [ 0.0142,  0.0202, -0.0366]],

         [[ 0.1113,  0.1602,  0.0673],
          [ 0.0595,  0.0968,  0.0200],
          [-0.0869, -0.0047,  0.0651]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0826,  0.0573,  0.0117],
          [ 0.0456,  0.0357,  0.0052],
          [-0.0002, -0.0042, -0.0479]],

         [[ 0.0420,  0.0270, -0.0231],
          [ 0.0082,  0.0035, -0.0217],
          [-0.0368, -0.0427, -0.0675]],

         [[ 0.0397,  0.0128, -0.0223],
          [ 0.0096,  0.0028, -0.0071],
          [-0.0224, -0.0263, -0.0504]]],


        [[[ 0.0179,  0.0233,  0.0327],
          [ 0.0140,  0.0170,  0.0259],
          [ 0.0165,  0.0229,  0.0297]],

         [[ 0.0399,  0.0445,  0.0531],
          [ 0.0385,  0.0421,  0.0489],
          [ 0.0416,  0.0473,  0.0531]],

         [[ 0.0218,  0.0244,  0.0315],
          [ 0.0212,  0.0208,  0.0271],
          [ 0.0215,  0.0242,  0.0304]]],


        [[[-0.0503, -0.0467, -0.0459],
          [-0.0448, -0.0369, -0.0363],
          [-0.0433, -0.0410, -0.0420]],

         [[-0.0794, -0.0750, -0.0737],
          [-0.0722, -0.0594, -0.0583],
          [-0.0670, -0.0615, -0.0583]],

         [[-0.0861, -0.0819, -0.0849],
          [-0.0782, -0.0721, -0.0731],
          [-0.0779, -0.0767, -0.0771]]],


        ...,


        [[[-0.0100, -0.0030,  0.0020],
          [-0.0081, -0.0009,  0.0042],
          [ 0.0016,  0.0071,  0.0104]],

         [[-0.0168, -0.0101, -0.0050],
          [-0.0142, -0.0073, -0.0018],
          [-0.0033,  0.0022,  0.0059]],

         [[-0.0126, -0.0096, -0.0072],
          [-0.0125, -0.0086, -0.0052],
          [-0.0061, -0.0022,  0.0010]]],


        [[[-0.0021, -0.0019, -0.0019],
          [-0.0013, -0.0002, -0.0006],
          [-0.0017,  0.0002, -0.0002]],

         [[-0.0025, -0.0024, -0.0027],
          [-0.0014, -0.0004, -0.0009],
          [-0.0021, -0.0003, -0.0006]],

         [[-0.0013, -0.0015, -0.0020],
          [-0.0010, -0.0006, -0.0010],
          [-0.0023, -0.0011, -0.0010]]],


        [[[ 0.0003,  0.0003,  0.0001],
          [ 0.0000, -0.0000, -0.0002],
          [-0.0004, -0.0003, -0.0001]],

         [[-0.0001, -0.0000, -0.0002],
          [-0.0003, -0.0003, -0.0004],
          [-0.0007, -0.0006, -0.0004]],

         [[-0.0002, -0.0002, -0.0004],
          [-0.0004, -0.0004, -0.0006],
          [-0.0008, -0.0007, -0.0006]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.2303]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 9 | Batch_idx: 0 |  Loss: (0.5646) | Acc: (75.00%) (97/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (0.5573) | Acc: (79.00%) (1123/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (0.6324) | Acc: (77.00%) (2085/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (0.6560) | Acc: (77.00%) (3059/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (0.6692) | Acc: (76.00%) (4032/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (0.6895) | Acc: (76.00%) (4987/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (0.6845) | Acc: (76.00%) (5977/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (0.6785) | Acc: (76.00%) (6971/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (0.6680) | Acc: (77.00%) (7997/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (0.6590) | Acc: (77.00%) (9017/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (0.6546) | Acc: (77.00%) (10025/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (0.6497) | Acc: (77.00%) (11023/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (0.6444) | Acc: (77.00%) (12054/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (0.6336) | Acc: (78.00%) (13111/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (0.6272) | Acc: (78.00%) (14153/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (0.6241) | Acc: (78.00%) (15201/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (0.6191) | Acc: (78.00%) (16237/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (0.6165) | Acc: (78.00%) (17265/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (0.6140) | Acc: (79.00%) (18306/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (0.6107) | Acc: (79.00%) (19342/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (0.6115) | Acc: (79.00%) (20367/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (0.6079) | Acc: (79.00%) (21403/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (0.6038) | Acc: (79.00%) (22464/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (0.6000) | Acc: (79.00%) (23510/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (0.5987) | Acc: (79.00%) (24552/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (0.5973) | Acc: (79.00%) (25578/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (0.5953) | Acc: (79.00%) (26618/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (0.5926) | Acc: (79.00%) (27669/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (0.5902) | Acc: (79.00%) (28713/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (0.5878) | Acc: (79.00%) (29766/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (0.5850) | Acc: (79.00%) (30821/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (0.5843) | Acc: (80.00%) (31849/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (0.5833) | Acc: (80.00%) (32889/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (0.5821) | Acc: (80.00%) (33931/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (0.5798) | Acc: (80.00%) (35000/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (0.5790) | Acc: (80.00%) (36041/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (0.5778) | Acc: (80.00%) (37095/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (0.5763) | Acc: (80.00%) (38145/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (0.5752) | Acc: (80.00%) (39197/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (0.5735) | Acc: (80.00%) (40209/50000)
# TEST : Loss: (0.5368) | Acc: (81.00%) (8161/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0390,  0.0841, -0.0509],
          [-0.0751,  0.0351,  0.0261],
          [ 0.0286, -0.1469,  0.1822]],

         [[-0.1073,  0.1536,  0.0308],
          [-0.0626,  0.1031, -0.1304],
          [ 0.0460, -0.1528, -0.0591]],

         [[-0.0251,  0.2127, -0.1524],
          [ 0.0798, -0.1705, -0.0126],
          [ 0.0674, -0.1648,  0.1970]]],


        [[[-0.0677, -0.1707, -0.1122],
          [-0.1391,  0.1555,  0.1339],
          [ 0.1018, -0.0023,  0.1578]],

         [[-0.1651, -0.1040, -0.0724],
          [-0.1467,  0.0686,  0.1953],
          [ 0.1846, -0.0669,  0.0327]],

         [[-0.1369,  0.1619, -0.1657],
          [ 0.0663,  0.1817, -0.1485],
          [-0.0169,  0.0599,  0.0228]]],


        [[[-0.1171,  0.1704,  0.0566],
          [ 0.0821,  0.0368, -0.1161],
          [-0.1802,  0.0757, -0.1504]],

         [[ 0.1147,  0.0205,  0.0072],
          [ 0.0421,  0.1443,  0.0794],
          [ 0.0169,  0.0599, -0.2291]],

         [[-0.0790, -0.0092,  0.1445],
          [ 0.0061,  0.1740,  0.0684],
          [-0.1438, -0.1098, -0.1526]]],


        ...,


        [[[-0.1363, -0.0806,  0.0059],
          [ 0.1822, -0.0893, -0.0267],
          [ 0.1379, -0.0327,  0.0841]],

         [[ 0.1717,  0.0555, -0.0536],
          [-0.1260, -0.2550, -0.2038],
          [ 0.0572,  0.0450, -0.1745]],

         [[ 0.2198,  0.0075,  0.0321],
          [-0.0606, -0.0978, -0.1547],
          [ 0.0325, -0.0485, -0.0825]]],


        [[[ 0.1187,  0.0854,  0.0044],
          [-0.0329, -0.0802,  0.0817],
          [-0.0383, -0.1726,  0.0413]],

         [[ 0.0438,  0.1432, -0.1887],
          [-0.0691, -0.0843, -0.1551],
          [-0.0928, -0.1755,  0.0202]],

         [[ 0.0281,  0.1522, -0.1130],
          [-0.1095,  0.1029,  0.0971],
          [ 0.0499,  0.0030, -0.0182]]],


        [[[ 0.0936, -0.0208,  0.0774],
          [-0.0250,  0.1127, -0.1707],
          [-0.1163, -0.0834, -0.1789]],

         [[-0.0635,  0.0857, -0.0247],
          [ 0.0493, -0.0029,  0.0353],
          [ 0.0121,  0.0181, -0.0358]],

         [[ 0.1012,  0.1466,  0.0618],
          [ 0.0536,  0.0891,  0.0179],
          [-0.0838, -0.0060,  0.0599]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3336]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0029]], device='cuda:0')

Epoch: 10 | Batch_idx: 0 |  Loss: (0.4400) | Acc: (85.00%) (109/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (0.5877) | Acc: (79.00%) (1116/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (0.5614) | Acc: (80.00%) (2163/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (0.5486) | Acc: (81.00%) (3226/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (0.5365) | Acc: (81.00%) (4301/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (0.5337) | Acc: (81.00%) (5336/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (0.5326) | Acc: (81.00%) (6392/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (0.5286) | Acc: (81.00%) (7451/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (0.5260) | Acc: (82.00%) (8513/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (0.5206) | Acc: (82.00%) (9589/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (0.5217) | Acc: (82.00%) (10642/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (0.5203) | Acc: (82.00%) (11696/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (0.5174) | Acc: (82.00%) (12771/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (0.5187) | Acc: (82.00%) (13814/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (0.5179) | Acc: (82.00%) (14875/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (0.5160) | Acc: (82.00%) (15939/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (0.5174) | Acc: (82.00%) (16968/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (0.5207) | Acc: (82.00%) (17999/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (0.5245) | Acc: (82.00%) (19015/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (0.5244) | Acc: (82.00%) (20062/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (0.5246) | Acc: (82.00%) (21106/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (0.5239) | Acc: (82.00%) (22168/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (0.5233) | Acc: (82.00%) (23224/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (0.5224) | Acc: (82.00%) (24293/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (0.5217) | Acc: (82.00%) (25355/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (0.5209) | Acc: (82.00%) (26430/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (0.5205) | Acc: (82.00%) (27498/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (0.5184) | Acc: (82.00%) (28581/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (0.5173) | Acc: (82.00%) (29650/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (0.5176) | Acc: (82.00%) (30699/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (0.5185) | Acc: (82.00%) (31752/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (0.5178) | Acc: (82.00%) (32821/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (0.5184) | Acc: (82.00%) (33862/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (0.5185) | Acc: (82.00%) (34915/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (0.5187) | Acc: (82.00%) (35963/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (0.5193) | Acc: (82.00%) (37009/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (0.5196) | Acc: (82.00%) (38058/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (0.5186) | Acc: (82.00%) (39125/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (0.5187) | Acc: (82.00%) (40178/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (0.5188) | Acc: (82.00%) (41206/50000)
# TEST : Loss: (0.5202) | Acc: (82.00%) (8207/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0389,  0.0840, -0.0508],
          [-0.0750,  0.0350,  0.0261],
          [ 0.0286, -0.1468,  0.1821]],

         [[-0.1072,  0.1535,  0.0308],
          [-0.0626,  0.1030, -0.1303],
          [ 0.0460, -0.1527, -0.0590]],

         [[-0.0251,  0.2125, -0.1522],
          [ 0.0797, -0.1704, -0.0126],
          [ 0.0673, -0.1646,  0.1968]]],


        [[[-0.0676, -0.1704, -0.1120],
          [-0.1388,  0.1552,  0.1337],
          [ 0.1016, -0.0023,  0.1575]],

         [[-0.1648, -0.1038, -0.0723],
          [-0.1464,  0.0685,  0.1949],
          [ 0.1843, -0.0668,  0.0326]],

         [[-0.1366,  0.1616, -0.1653],
          [ 0.0662,  0.1814, -0.1482],
          [-0.0169,  0.0598,  0.0227]]],


        [[[-0.1169,  0.1701,  0.0566],
          [ 0.0820,  0.0368, -0.1160],
          [-0.1799,  0.0756, -0.1502]],

         [[ 0.1146,  0.0205,  0.0072],
          [ 0.0421,  0.1441,  0.0793],
          [ 0.0169,  0.0598, -0.2288]],

         [[-0.0789, -0.0092,  0.1443],
          [ 0.0061,  0.1738,  0.0683],
          [-0.1436, -0.1096, -0.1524]]],


        ...,


        [[[-0.1358, -0.0803,  0.0058],
          [ 0.1815, -0.0889, -0.0266],
          [ 0.1375, -0.0326,  0.0838]],

         [[ 0.1710,  0.0552, -0.0533],
          [-0.1254, -0.2531, -0.2018],
          [ 0.0570,  0.0448, -0.1735]],

         [[ 0.2189,  0.0075,  0.0320],
          [-0.0603, -0.0970, -0.1534],
          [ 0.0324, -0.0482, -0.0819]]],


        [[[ 0.1176,  0.0846,  0.0044],
          [-0.0326, -0.0794,  0.0809],
          [-0.0379, -0.1707,  0.0409]],

         [[ 0.0434,  0.1418, -0.1870],
          [-0.0684, -0.0834, -0.1534],
          [-0.0917, -0.1734,  0.0200]],

         [[ 0.0278,  0.1507, -0.1118],
          [-0.1083,  0.1017,  0.0961],
          [ 0.0493,  0.0030, -0.0180]]],


        [[[ 0.0871, -0.0194,  0.0719],
          [-0.0233,  0.1050, -0.1594],
          [-0.1089, -0.0781, -0.1678]],

         [[-0.0582,  0.0786, -0.0227],
          [ 0.0456, -0.0026,  0.0328],
          [ 0.0113,  0.0169, -0.0335]],

         [[ 0.0913,  0.1322,  0.0564],
          [ 0.0491,  0.0817,  0.0166],
          [-0.0780, -0.0056,  0.0560]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3532]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0754]], device='cuda:0')

Epoch: 11 | Batch_idx: 0 |  Loss: (0.5819) | Acc: (81.00%) (104/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (0.5205) | Acc: (82.00%) (1164/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (0.5140) | Acc: (83.00%) (2237/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (0.5020) | Acc: (83.00%) (3315/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (0.4982) | Acc: (83.00%) (4376/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (0.4934) | Acc: (83.00%) (5459/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (0.4975) | Acc: (83.00%) (6514/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (0.4988) | Acc: (83.00%) (7581/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (0.4996) | Acc: (83.00%) (8639/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (0.4990) | Acc: (83.00%) (9708/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (0.5014) | Acc: (83.00%) (10749/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (0.5022) | Acc: (83.00%) (11801/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (0.5023) | Acc: (83.00%) (12859/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (0.5046) | Acc: (82.00%) (13914/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (0.5075) | Acc: (82.00%) (14940/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (0.5062) | Acc: (82.00%) (16015/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (0.5063) | Acc: (82.00%) (17073/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (0.5056) | Acc: (82.00%) (18141/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (0.5071) | Acc: (82.00%) (19207/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (0.5071) | Acc: (82.00%) (20269/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (0.5082) | Acc: (82.00%) (21333/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (0.5084) | Acc: (82.00%) (22402/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (0.5070) | Acc: (83.00%) (23488/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (0.5059) | Acc: (83.00%) (24567/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (0.5061) | Acc: (83.00%) (25635/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (0.5071) | Acc: (83.00%) (26693/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (0.5070) | Acc: (83.00%) (27751/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (0.5073) | Acc: (83.00%) (28808/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (0.5077) | Acc: (83.00%) (29867/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (0.5072) | Acc: (83.00%) (30921/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (0.5086) | Acc: (82.00%) (31954/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (0.5100) | Acc: (82.00%) (32989/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (0.5112) | Acc: (82.00%) (34035/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (0.5121) | Acc: (82.00%) (35094/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (0.5131) | Acc: (82.00%) (36147/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (0.5135) | Acc: (82.00%) (37205/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (0.5145) | Acc: (82.00%) (38245/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (0.5143) | Acc: (82.00%) (39301/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (0.5146) | Acc: (82.00%) (40342/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (0.5147) | Acc: (82.00%) (41374/50000)
# TEST : Loss: (0.5242) | Acc: (82.00%) (8200/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0389,  0.0839, -0.0508],
          [-0.0749,  0.0350,  0.0261],
          [ 0.0286, -0.1466,  0.1819]],

         [[-0.1071,  0.1533,  0.0308],
          [-0.0625,  0.1029, -0.1301],
          [ 0.0459, -0.1525, -0.0590]],

         [[-0.0251,  0.2123, -0.1521],
          [ 0.0796, -0.1702, -0.0126],
          [ 0.0673, -0.1645,  0.1966]]],


        [[[-0.0675, -0.1701, -0.1117],
          [-0.1385,  0.1549,  0.1334],
          [ 0.1014, -0.0023,  0.1572]],

         [[-0.1644, -0.1036, -0.0721],
          [-0.1461,  0.0683,  0.1945],
          [ 0.1839, -0.0667,  0.0326]],

         [[-0.1363,  0.1612, -0.1650],
          [ 0.0660,  0.1810, -0.1479],
          [-0.0168,  0.0597,  0.0227]]],


        [[[-0.1167,  0.1698,  0.0565],
          [ 0.0818,  0.0367, -0.1158],
          [-0.1796,  0.0755, -0.1499]],

         [[ 0.1144,  0.0205,  0.0072],
          [ 0.0420,  0.1438,  0.0791],
          [ 0.0168,  0.0597, -0.2284]],

         [[-0.0787, -0.0091,  0.1441],
          [ 0.0060,  0.1734,  0.0682],
          [-0.1433, -0.1094, -0.1521]]],


        ...,


        [[[-0.1352, -0.0799,  0.0058],
          [ 0.1807, -0.0884, -0.0265],
          [ 0.1369, -0.0324,  0.0833]],

         [[ 0.1702,  0.0548, -0.0529],
          [-0.1247, -0.2507, -0.1994],
          [ 0.0567,  0.0445, -0.1722]],

         [[ 0.2178,  0.0075,  0.0317],
          [-0.0599, -0.0962, -0.1518],
          [ 0.0322, -0.0479, -0.0813]]],


        [[[ 0.1163,  0.0837,  0.0044],
          [-0.0322, -0.0784,  0.0799],
          [-0.0374, -0.1684,  0.0403]],

         [[ 0.0429,  0.1402, -0.1848],
          [-0.0675, -0.0823, -0.1515],
          [-0.0903, -0.1708,  0.0197]],

         [[ 0.0275,  0.1489, -0.1105],
          [-0.1069,  0.1004,  0.0948],
          [ 0.0486,  0.0030, -0.0177]]],


        [[[ 0.0797, -0.0177,  0.0658],
          [-0.0214,  0.0964, -0.1466],
          [-0.1005, -0.0721, -0.1551]],

         [[-0.0524,  0.0708, -0.0205],
          [ 0.0414, -0.0024,  0.0300],
          [ 0.0104,  0.0155, -0.0310]],

         [[ 0.0805,  0.1166,  0.0504],
          [ 0.0441,  0.0734,  0.0151],
          [-0.0714, -0.0051,  0.0516]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3475]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0135]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 12 | Batch_idx: 0 |  Loss: (0.4665) | Acc: (85.00%) (109/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.7353) | Acc: (76.00%) (1076/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.7851) | Acc: (73.00%) (1985/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.7940) | Acc: (73.00%) (2911/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.7898) | Acc: (73.00%) (3851/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.7909) | Acc: (73.00%) (4790/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.7737) | Acc: (74.00%) (5778/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.7630) | Acc: (74.00%) (6758/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.7542) | Acc: (74.00%) (7742/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.7490) | Acc: (74.00%) (8720/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.7459) | Acc: (74.00%) (9679/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.7394) | Acc: (75.00%) (10666/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.7363) | Acc: (75.00%) (11631/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.7372) | Acc: (75.00%) (12581/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.7323) | Acc: (75.00%) (13564/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.7238) | Acc: (75.00%) (14596/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.7204) | Acc: (75.00%) (15572/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.7138) | Acc: (75.00%) (16584/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.7102) | Acc: (75.00%) (17580/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.7079) | Acc: (75.00%) (18568/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.7033) | Acc: (76.00%) (19578/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.6983) | Acc: (76.00%) (20611/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.6949) | Acc: (76.00%) (21635/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.6919) | Acc: (76.00%) (22645/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.6892) | Acc: (76.00%) (23649/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.6872) | Acc: (76.00%) (24647/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.6839) | Acc: (76.00%) (25659/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.6782) | Acc: (76.00%) (26709/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.6742) | Acc: (77.00%) (27749/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.6712) | Acc: (77.00%) (28780/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.6673) | Acc: (77.00%) (29811/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.6653) | Acc: (77.00%) (30823/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.6618) | Acc: (77.00%) (31863/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.6582) | Acc: (77.00%) (32915/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.6558) | Acc: (77.00%) (33946/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.6538) | Acc: (77.00%) (34970/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.6514) | Acc: (77.00%) (36007/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.6474) | Acc: (78.00%) (37058/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.6454) | Acc: (78.00%) (38098/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.6422) | Acc: (78.00%) (39111/50000)
# TEST : Loss: (0.6442) | Acc: (78.00%) (7881/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0447,  0.0951, -0.0541],
          [-0.0729,  0.0329,  0.0220],
          [ 0.0367, -0.1566,  0.1904]],

         [[-0.1006,  0.1670,  0.0397],
          [-0.0497,  0.1029, -0.1255],
          [ 0.0651, -0.1600, -0.0478]],

         [[-0.0294,  0.2101, -0.1570],
          [ 0.0840, -0.1706, -0.0152],
          [ 0.0817, -0.1688,  0.2020]]],


        [[[-0.0748, -0.1834, -0.1244],
          [-0.1414,  0.1532,  0.1282],
          [ 0.1095, -0.0009,  0.1528]],

         [[-0.1643, -0.1096, -0.0832],
          [-0.1443,  0.0712,  0.1883],
          [ 0.1951, -0.0619,  0.0283]],

         [[-0.1336,  0.1606, -0.1688],
          [ 0.0664,  0.1850, -0.1496],
          [-0.0058,  0.0645,  0.0220]]],


        [[[-0.1204,  0.1750,  0.0660],
          [ 0.0891,  0.0484, -0.1101],
          [-0.1697,  0.0781, -0.1515]],

         [[ 0.1076,  0.0248,  0.0132],
          [ 0.0438,  0.1515,  0.0800],
          [ 0.0165,  0.0546, -0.2378]],

         [[-0.0855, -0.0064,  0.1491],
          [ 0.0040,  0.1765,  0.0660],
          [-0.1485, -0.1181, -0.1644]]],


        ...,


        [[[-0.1439, -0.0909, -0.0027],
          [ 0.1707, -0.1068, -0.0449],
          [ 0.1303, -0.0434,  0.0726]],

         [[ 0.1730,  0.0566, -0.0441],
          [-0.1220, -0.2595, -0.2083],
          [ 0.0598,  0.0424, -0.1737]],

         [[ 0.2176,  0.0112,  0.0448],
          [-0.0657, -0.1081, -0.1558],
          [ 0.0216, -0.0627, -0.0932]]],


        [[[ 0.1301,  0.0951,  0.0092],
          [-0.0219, -0.0751,  0.0870],
          [-0.0259, -0.1687,  0.0422]],

         [[ 0.0520,  0.1444, -0.1823],
          [-0.0609, -0.0845, -0.1450],
          [-0.0752, -0.1680,  0.0221]],

         [[ 0.0417,  0.1573, -0.1025],
          [-0.0925,  0.1051,  0.1050],
          [ 0.0645,  0.0113, -0.0096]]],


        [[[ 0.0776, -0.0117,  0.0623],
          [-0.0164,  0.0923, -0.1316],
          [-0.0777, -0.0549, -0.1317]],

         [[-0.0320,  0.0770, -0.0048],
          [ 0.0470,  0.0101,  0.0389],
          [ 0.0305,  0.0323, -0.0087]],

         [[ 0.0885,  0.1172,  0.0612],
          [ 0.0516,  0.0795,  0.0292],
          [-0.0446,  0.0146,  0.0700]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0477, -0.0216,  0.0359],
          [-0.0666, -0.0497, -0.0147],
          [-0.0970, -0.1062, -0.0771]],

         [[-0.0740, -0.0596,  0.0150],
          [-0.0868, -0.0679, -0.0370],
          [-0.1127, -0.1134, -0.0918]],

         [[-0.1132, -0.1195, -0.0300],
          [-0.1016, -0.0965, -0.0560],
          [-0.1044, -0.1084, -0.0837]]],


        [[[ 0.0177,  0.0191,  0.0101],
          [ 0.0080,  0.0134,  0.0070],
          [ 0.0104,  0.0129,  0.0131]],

         [[ 0.0271,  0.0256,  0.0151],
          [ 0.0188,  0.0204,  0.0114],
          [ 0.0192,  0.0187,  0.0178]],

         [[ 0.0530,  0.0507,  0.0369],
          [ 0.0474,  0.0473,  0.0368],
          [ 0.0506,  0.0494,  0.0467]]],


        [[[-0.0238, -0.0116, -0.0129],
          [-0.0040,  0.0015, -0.0036],
          [-0.0074, -0.0081, -0.0082]],

         [[-0.0256, -0.0087, -0.0060],
          [-0.0094, -0.0012, -0.0002],
          [-0.0130, -0.0117, -0.0087]],

         [[ 0.0111,  0.0271,  0.0235],
          [ 0.0281,  0.0372,  0.0374],
          [ 0.0230,  0.0252,  0.0280]]],


        ...,


        [[[-0.0003, -0.0053, -0.0092],
          [ 0.0076,  0.0058,  0.0031],
          [ 0.0090,  0.0093,  0.0075]],

         [[ 0.0007, -0.0041, -0.0080],
          [ 0.0052,  0.0037,  0.0009],
          [ 0.0058,  0.0060,  0.0035]],

         [[ 0.0028, -0.0004, -0.0035],
          [ 0.0048,  0.0041,  0.0017],
          [ 0.0032,  0.0039,  0.0012]]],


        [[[-0.0002, -0.0005, -0.0014],
          [ 0.0005,  0.0002, -0.0008],
          [ 0.0003,  0.0004, -0.0007]],

         [[-0.0009, -0.0009, -0.0012],
          [-0.0009, -0.0008, -0.0011],
          [-0.0014, -0.0008, -0.0014]],

         [[-0.0003, -0.0004, -0.0004],
          [-0.0010, -0.0011, -0.0011],
          [-0.0013, -0.0010, -0.0014]]],


        [[[ 0.0001,  0.0000,  0.0001],
          [ 0.0002,  0.0003,  0.0004],
          [ 0.0005,  0.0005,  0.0004]],

         [[ 0.0001,  0.0001,  0.0002],
          [ 0.0002,  0.0003,  0.0005],
          [ 0.0005,  0.0005,  0.0005]],

         [[ 0.0001,  0.0001,  0.0002],
          [ 0.0001,  0.0002,  0.0003],
          [ 0.0002,  0.0002,  0.0002]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3471]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 13 | Batch_idx: 0 |  Loss: (0.5176) | Acc: (81.00%) (104/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.5177) | Acc: (82.00%) (1162/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.5257) | Acc: (82.00%) (2210/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.5198) | Acc: (82.00%) (3275/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.5199) | Acc: (82.00%) (4332/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.5234) | Acc: (82.00%) (5383/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.5309) | Acc: (82.00%) (6419/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.5295) | Acc: (82.00%) (7468/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.5294) | Acc: (82.00%) (8519/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.5253) | Acc: (82.00%) (9600/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.5252) | Acc: (82.00%) (10667/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.5281) | Acc: (82.00%) (11717/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.5278) | Acc: (82.00%) (12754/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.5324) | Acc: (82.00%) (13781/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.5320) | Acc: (82.00%) (14841/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.5303) | Acc: (82.00%) (15906/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.5272) | Acc: (82.00%) (16963/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.5252) | Acc: (82.00%) (18032/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.5249) | Acc: (82.00%) (19079/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.5227) | Acc: (82.00%) (20158/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.5217) | Acc: (82.00%) (21212/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.5230) | Acc: (82.00%) (22254/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.5208) | Acc: (82.00%) (23335/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.5200) | Acc: (82.00%) (24387/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.5195) | Acc: (82.00%) (25448/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.5193) | Acc: (82.00%) (26510/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.5179) | Acc: (82.00%) (27589/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.5185) | Acc: (82.00%) (28650/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.5169) | Acc: (82.00%) (29725/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.5170) | Acc: (82.00%) (30768/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.5161) | Acc: (82.00%) (31832/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.5140) | Acc: (82.00%) (32914/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.5143) | Acc: (82.00%) (33964/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.5123) | Acc: (82.00%) (35047/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.5118) | Acc: (82.00%) (36122/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.5117) | Acc: (82.00%) (37186/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.5106) | Acc: (82.00%) (38269/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.5104) | Acc: (82.00%) (39324/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.5096) | Acc: (82.00%) (40392/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.5088) | Acc: (82.00%) (41413/50000)
# TEST : Loss: (0.5494) | Acc: (81.00%) (8109/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0523,  0.1049, -0.0521],
          [-0.0792,  0.0379,  0.0221],
          [ 0.0386, -0.1589,  0.1930]],

         [[-0.1087,  0.1754,  0.0448],
          [-0.0562,  0.0997, -0.1291],
          [ 0.0676, -0.1697, -0.0526]],

         [[-0.0366,  0.2127, -0.1519],
          [ 0.0834, -0.1695, -0.0193],
          [ 0.0912, -0.1667,  0.1975]]],


        [[[-0.0770, -0.1832, -0.1187],
          [-0.1374,  0.1637,  0.1396],
          [ 0.1160,  0.0106,  0.1647]],

         [[-0.1676, -0.1107, -0.0812],
          [-0.1414,  0.0801,  0.1963],
          [ 0.1998, -0.0539,  0.0364]],

         [[-0.1381,  0.1556, -0.1710],
          [ 0.0638,  0.1856, -0.1480],
          [-0.0097,  0.0617,  0.0199]]],


        [[[-0.1211,  0.1742,  0.0640],
          [ 0.0927,  0.0510, -0.1123],
          [-0.1715,  0.0737, -0.1572]],

         [[ 0.1054,  0.0265,  0.0133],
          [ 0.0421,  0.1526,  0.0767],
          [ 0.0052,  0.0449, -0.2469]],

         [[-0.0856, -0.0022,  0.1531],
          [ 0.0040,  0.1772,  0.0620],
          [-0.1552, -0.1261, -0.1748]]],


        ...,


        [[[-0.1548, -0.1065, -0.0127],
          [ 0.1621, -0.1226, -0.0563],
          [ 0.1241, -0.0551,  0.0639]],

         [[ 0.1685,  0.0474, -0.0426],
          [-0.1230, -0.2730, -0.2138],
          [ 0.0604,  0.0348, -0.1754]],

         [[ 0.2190,  0.0115,  0.0507],
          [-0.0593, -0.1060, -0.1492],
          [ 0.0280, -0.0607, -0.0876]]],


        [[[ 0.1311,  0.0929,  0.0045],
          [-0.0228, -0.0783,  0.0823],
          [-0.0269, -0.1726,  0.0357]],

         [[ 0.0524,  0.1388, -0.1865],
          [-0.0598, -0.0873, -0.1470],
          [-0.0694, -0.1666,  0.0176]],

         [[ 0.0444,  0.1536, -0.1055],
          [-0.0852,  0.1052,  0.1021],
          [ 0.0729,  0.0155, -0.0122]]],


        [[[ 0.0610, -0.0186,  0.0510],
          [-0.0272,  0.0708, -0.1361],
          [-0.0828, -0.0679, -0.1445]],

         [[-0.0348,  0.0631, -0.0054],
          [ 0.0314, -0.0024,  0.0211],
          [ 0.0199,  0.0136, -0.0299]],

         [[ 0.0774,  0.1036,  0.0594],
          [ 0.0406,  0.0649,  0.0174],
          [-0.0407,  0.0077,  0.0510]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.1205, -0.0659, -0.0424],
          [-0.1159, -0.0671, -0.0490],
          [-0.1254, -0.0913, -0.0947]],

         [[-0.1046, -0.0398, -0.0072],
          [-0.1061, -0.0386, -0.0124],
          [-0.1194, -0.0731, -0.0711]],

         [[-0.0858, -0.0481, -0.0398],
          [-0.0949, -0.0617, -0.0655],
          [-0.1294, -0.0972, -0.1139]]],


        [[[ 0.0223,  0.0167,  0.0082],
          [ 0.0241,  0.0141,  0.0092],
          [ 0.0248,  0.0194,  0.0143]],

         [[ 0.0202,  0.0139,  0.0047],
          [ 0.0237,  0.0131,  0.0063],
          [ 0.0226,  0.0191,  0.0136]],

         [[ 0.0188,  0.0185,  0.0182],
          [ 0.0278,  0.0250,  0.0257],
          [ 0.0371,  0.0372,  0.0349]]],


        [[[ 0.0078,  0.0072,  0.0167],
          [-0.0008,  0.0036,  0.0215],
          [-0.0030, -0.0001,  0.0133]],

         [[ 0.0027,  0.0029,  0.0153],
          [-0.0081,  0.0007,  0.0215],
          [-0.0100,  0.0002,  0.0154]],

         [[-0.0003,  0.0032,  0.0099],
          [-0.0031,  0.0028,  0.0152],
          [-0.0088, -0.0068,  0.0045]]],


        ...,


        [[[ 0.0183,  0.0152,  0.0159],
          [ 0.0084,  0.0020,  0.0009],
          [ 0.0133,  0.0062,  0.0032]],

         [[ 0.0184,  0.0152,  0.0163],
          [ 0.0117,  0.0051,  0.0034],
          [ 0.0178,  0.0099,  0.0054]],

         [[ 0.0117,  0.0095,  0.0112],
          [ 0.0044,  0.0009,  0.0017],
          [ 0.0099,  0.0065,  0.0067]]],


        [[[-0.0039, -0.0031, -0.0013],
          [-0.0031, -0.0024, -0.0014],
          [-0.0032, -0.0027, -0.0020]],

         [[-0.0044, -0.0037, -0.0019],
          [-0.0035, -0.0027, -0.0016],
          [-0.0035, -0.0030, -0.0023]],

         [[-0.0037, -0.0033, -0.0017],
          [-0.0029, -0.0023, -0.0011],
          [-0.0029, -0.0023, -0.0014]]],


        [[[ 0.0000,  0.0001,  0.0001],
          [ 0.0001,  0.0002,  0.0001],
          [-0.0000,  0.0000, -0.0001]],

         [[ 0.0001,  0.0001,  0.0001],
          [ 0.0001,  0.0002,  0.0001],
          [ 0.0000,  0.0001, -0.0001]],

         [[-0.0001, -0.0001, -0.0001],
          [-0.0001,  0.0000, -0.0001],
          [-0.0001, -0.0000, -0.0002]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3463]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 14 | Batch_idx: 0 |  Loss: (0.4135) | Acc: (84.00%) (108/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.4329) | Acc: (84.00%) (1187/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.4635) | Acc: (83.00%) (2240/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.4492) | Acc: (83.00%) (3328/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.4479) | Acc: (84.00%) (4411/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.4506) | Acc: (83.00%) (5481/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.4523) | Acc: (83.00%) (6550/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.4536) | Acc: (83.00%) (7619/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.4541) | Acc: (83.00%) (8697/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.4522) | Acc: (84.00%) (9799/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.4569) | Acc: (83.00%) (10857/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.4579) | Acc: (83.00%) (11923/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.4558) | Acc: (84.00%) (13019/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.4575) | Acc: (84.00%) (14088/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.4560) | Acc: (84.00%) (15173/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.4545) | Acc: (84.00%) (16265/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.4531) | Acc: (84.00%) (17361/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.4539) | Acc: (84.00%) (18453/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.4521) | Acc: (84.00%) (19560/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.4531) | Acc: (84.00%) (20620/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.4509) | Acc: (84.00%) (21716/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.4489) | Acc: (84.00%) (22804/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.4499) | Acc: (84.00%) (23886/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.4496) | Acc: (84.00%) (24980/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.4488) | Acc: (84.00%) (26053/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.4494) | Acc: (84.00%) (27127/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.4479) | Acc: (84.00%) (28231/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.4482) | Acc: (84.00%) (29306/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.4481) | Acc: (84.00%) (30393/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.4475) | Acc: (84.00%) (31496/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.4497) | Acc: (84.00%) (32551/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.4501) | Acc: (84.00%) (33624/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.4507) | Acc: (84.00%) (34702/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.4501) | Acc: (84.00%) (35795/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.4505) | Acc: (84.00%) (36879/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.4505) | Acc: (84.00%) (37957/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.4505) | Acc: (84.00%) (39059/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.4494) | Acc: (84.00%) (40172/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.4486) | Acc: (84.00%) (41278/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.4495) | Acc: (84.00%) (42307/50000)
# TEST : Loss: (0.4634) | Acc: (84.00%) (8437/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0535,  0.1128, -0.0594],
          [-0.0820,  0.0393,  0.0156],
          [ 0.0410, -0.1635,  0.1954]],

         [[-0.0984,  0.1873,  0.0470],
          [-0.0537,  0.1001, -0.1319],
          [ 0.0690, -0.1781, -0.0511]],

         [[-0.0287,  0.2216, -0.1462],
          [ 0.0908, -0.1626, -0.0178],
          [ 0.1010, -0.1643,  0.2033]]],


        [[[-0.0833, -0.1948, -0.1277],
          [-0.1375,  0.1625,  0.1363],
          [ 0.1136,  0.0104,  0.1641]],

         [[-0.1779, -0.1268, -0.0969],
          [-0.1452,  0.0738,  0.1855],
          [ 0.1944, -0.0594,  0.0297]],

         [[-0.1307,  0.1559, -0.1723],
          [ 0.0723,  0.1885, -0.1498],
          [-0.0074,  0.0629,  0.0196]]],


        [[[-0.1211,  0.1769,  0.0671],
          [ 0.0923,  0.0523, -0.1131],
          [-0.1717,  0.0733, -0.1595]],

         [[ 0.1052,  0.0298,  0.0129],
          [ 0.0404,  0.1524,  0.0722],
          [-0.0017,  0.0386, -0.2542]],

         [[-0.0847,  0.0028,  0.1574],
          [ 0.0002,  0.1770,  0.0610],
          [-0.1603, -0.1299, -0.1799]]],


        ...,


        [[[-0.1596, -0.1079, -0.0099],
          [ 0.1620, -0.1240, -0.0530],
          [ 0.1299, -0.0491,  0.0711]],

         [[ 0.1736,  0.0547, -0.0366],
          [-0.1183, -0.2724, -0.2156],
          [ 0.0661,  0.0373, -0.1744]],

         [[ 0.2244,  0.0215,  0.0592],
          [-0.0506, -0.0997, -0.1475],
          [ 0.0344, -0.0569, -0.0875]]],


        [[[ 0.1294,  0.0914,  0.0032],
          [-0.0250, -0.0799,  0.0823],
          [-0.0278, -0.1754,  0.0324]],

         [[ 0.0521,  0.1348, -0.1881],
          [-0.0615, -0.0890, -0.1441],
          [-0.0698, -0.1694,  0.0149]],

         [[ 0.0452,  0.1512, -0.1069],
          [-0.0810,  0.1056,  0.1030],
          [ 0.0769,  0.0155, -0.0124]]],


        [[[ 0.0636, -0.0098,  0.0578],
          [-0.0154,  0.0765, -0.1133],
          [-0.0630, -0.0454, -0.1154]],

         [[-0.0205,  0.0639,  0.0047],
          [ 0.0395,  0.0127,  0.0311],
          [ 0.0316,  0.0311, -0.0063]],

         [[ 0.0850,  0.1032,  0.0645],
          [ 0.0518,  0.0769,  0.0309],
          [-0.0194,  0.0295,  0.0707]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 1.5712e-02,  4.8837e-02,  4.1121e-02],
          [ 2.7486e-02,  4.5596e-02,  2.3888e-02],
          [ 7.6243e-03,  4.0811e-02,  2.5003e-02]],

         [[ 6.5289e-03,  5.0256e-02,  5.1791e-02],
          [ 2.0340e-02,  5.0028e-02,  3.6034e-02],
          [ 3.1493e-03,  4.5715e-02,  3.5395e-02]],

         [[ 9.0105e-03,  5.2102e-02,  5.6974e-02],
          [ 1.7934e-02,  4.5125e-02,  4.0736e-02],
          [ 5.8274e-03,  4.1530e-02,  4.0325e-02]]],


        [[[-5.2744e-02, -6.3358e-02, -6.3861e-02],
          [-4.9342e-02, -5.9419e-02, -6.4096e-02],
          [-4.5253e-02, -5.8896e-02, -5.7341e-02]],

         [[-4.7307e-02, -5.7249e-02, -5.3883e-02],
          [-4.2189e-02, -5.3492e-02, -5.4780e-02],
          [-3.8160e-02, -5.4339e-02, -5.0597e-02]],

         [[-4.8287e-02, -5.3464e-02, -4.5182e-02],
          [-5.1747e-02, -5.8590e-02, -5.4192e-02],
          [-5.1145e-02, -6.3629e-02, -5.5370e-02]]],


        [[[-4.9309e-02, -4.1677e-02, -3.9549e-02],
          [-3.9482e-02, -3.5775e-02, -3.4670e-02],
          [-3.9329e-02, -4.0377e-02, -3.6274e-02]],

         [[-6.1538e-02, -5.7244e-02, -5.6236e-02],
          [-5.2570e-02, -5.2406e-02, -5.2426e-02],
          [-5.0724e-02, -5.6326e-02, -5.4957e-02]],

         [[-6.6260e-02, -6.1821e-02, -6.1041e-02],
          [-5.6134e-02, -5.3513e-02, -5.2144e-02],
          [-4.9730e-02, -5.1331e-02, -4.8936e-02]]],


        ...,


        [[[-2.1657e-02, -1.5637e-02, -2.2191e-02],
          [-1.8931e-02, -1.2389e-02, -1.6168e-02],
          [-2.2318e-02, -1.7755e-02, -1.7730e-02]],

         [[-1.8124e-02, -9.9737e-03, -1.4407e-02],
          [-1.3650e-02, -4.6845e-03, -5.9203e-03],
          [-1.6467e-02, -9.5530e-03, -7.2837e-03]],

         [[-1.4812e-02, -8.2137e-03, -1.2343e-02],
          [-1.0720e-02, -3.3201e-03, -4.6677e-03],
          [-1.2108e-02, -6.5455e-03, -5.4214e-03]]],


        [[[-1.5347e-03, -9.0409e-04, -4.3954e-04],
          [-1.2087e-03, -8.2794e-04,  2.1970e-04],
          [-6.0779e-04, -2.3505e-04,  1.0004e-03]],

         [[-2.0191e-03, -1.4020e-03, -6.4345e-04],
          [-1.4200e-03, -1.1019e-03, -2.4162e-05],
          [-5.0717e-04, -2.5301e-04,  9.8969e-04]],

         [[-1.1192e-03, -5.2262e-04,  2.1445e-04],
          [-6.3989e-04, -3.1872e-04,  7.3968e-04],
          [ 4.5219e-04,  6.1311e-04,  1.7323e-03]]],


        [[[-2.5301e-04, -1.2746e-04,  1.1413e-04],
          [-1.1863e-04,  3.4678e-05,  2.5534e-04],
          [-1.8982e-04, -8.1016e-05,  1.3990e-04]],

         [[-2.2563e-04, -1.3897e-04,  1.0335e-04],
          [-1.3088e-04, -1.1879e-05,  2.3084e-04],
          [-2.2071e-04, -1.2957e-04,  1.2579e-04]],

         [[-1.1757e-04, -7.5084e-06,  2.3669e-04],
          [-4.1147e-06,  1.2281e-04,  3.9208e-04],
          [-5.7419e-05,  2.2013e-06,  2.7615e-04]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.3454]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 15 | Batch_idx: 0 |  Loss: (0.4210) | Acc: (84.00%) (108/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.4497) | Acc: (84.00%) (1195/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.5104) | Acc: (82.00%) (2228/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.5506) | Acc: (81.00%) (3224/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.5640) | Acc: (80.00%) (4239/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.5752) | Acc: (80.00%) (5256/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.5776) | Acc: (80.00%) (6285/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.5798) | Acc: (80.00%) (7313/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.5735) | Acc: (80.00%) (8370/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.5753) | Acc: (80.00%) (9405/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.5742) | Acc: (80.00%) (10430/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.5671) | Acc: (80.00%) (11481/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.5671) | Acc: (80.00%) (12510/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.5621) | Acc: (80.00%) (13574/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.5568) | Acc: (81.00%) (14640/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.5488) | Acc: (81.00%) (15734/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.5464) | Acc: (81.00%) (16784/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.5439) | Acc: (81.00%) (17843/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.5402) | Acc: (81.00%) (18923/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.5371) | Acc: (81.00%) (19976/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.5365) | Acc: (81.00%) (21027/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.5336) | Acc: (81.00%) (22096/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.5291) | Acc: (81.00%) (23183/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.5261) | Acc: (82.00%) (24257/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.5237) | Acc: (82.00%) (25330/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.5232) | Acc: (82.00%) (26401/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.5207) | Acc: (82.00%) (27494/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.5192) | Acc: (82.00%) (28561/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.5160) | Acc: (82.00%) (29655/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.5142) | Acc: (82.00%) (30746/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.5130) | Acc: (82.00%) (31810/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.5112) | Acc: (82.00%) (32887/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.5115) | Acc: (82.00%) (33950/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.5103) | Acc: (82.00%) (35022/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.5093) | Acc: (82.00%) (36093/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.5085) | Acc: (82.00%) (37163/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.5062) | Acc: (82.00%) (38253/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.5047) | Acc: (82.00%) (39340/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.5029) | Acc: (82.00%) (40433/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.5017) | Acc: (82.00%) (41463/50000)
# TEST : Loss: (0.4666) | Acc: (84.00%) (8442/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0558,  0.1105, -0.0624],
          [-0.0835,  0.0378,  0.0144],
          [ 0.0403, -0.1642,  0.1944]],

         [[-0.0996,  0.1857,  0.0443],
          [-0.0546,  0.0989, -0.1331],
          [ 0.0692, -0.1786, -0.0518]],

         [[-0.0324,  0.2179, -0.1506],
          [ 0.0879, -0.1656, -0.0214],
          [ 0.0995, -0.1668,  0.1999]]],


        [[[-0.0813, -0.1923, -0.1254],
          [-0.1354,  0.1647,  0.1385],
          [ 0.1144,  0.0124,  0.1659]],

         [[-0.1764, -0.1252, -0.0955],
          [-0.1441,  0.0750,  0.1865],
          [ 0.1941, -0.0583,  0.0308]],

         [[-0.1286,  0.1577, -0.1704],
          [ 0.0741,  0.1905, -0.1476],
          [-0.0063,  0.0648,  0.0213]]],


        [[[-0.1182,  0.1792,  0.0687],
          [ 0.0948,  0.0549, -0.1110],
          [-0.1689,  0.0760, -0.1570]],

         [[ 0.1084,  0.0328,  0.0149],
          [ 0.0437,  0.1555,  0.0744],
          [ 0.0014,  0.0417, -0.2513]],

         [[-0.0815,  0.0054,  0.1586],
          [ 0.0031,  0.1793,  0.0624],
          [-0.1574, -0.1273, -0.1781]]],


        ...,


        [[[-0.1599, -0.1080, -0.0089],
          [ 0.1600, -0.1249, -0.0531],
          [ 0.1285, -0.0496,  0.0708]],

         [[ 0.1733,  0.0550, -0.0343],
          [-0.1180, -0.2713, -0.2137],
          [ 0.0661,  0.0375, -0.1724]],

         [[ 0.2244,  0.0225,  0.0616],
          [-0.0491, -0.0979, -0.1442],
          [ 0.0361, -0.0542, -0.0839]]],


        [[[ 0.1308,  0.0928,  0.0063],
          [-0.0218, -0.0759,  0.0835],
          [-0.0256, -0.1705,  0.0329]],

         [[ 0.0545,  0.1356, -0.1824],
          [-0.0580, -0.0852, -0.1398],
          [-0.0673, -0.1650,  0.0148]],

         [[ 0.0477,  0.1518, -0.1023],
          [-0.0773,  0.1059,  0.1031],
          [ 0.0767,  0.0160, -0.0121]]],


        [[[ 0.0583, -0.0077,  0.0520],
          [-0.0130,  0.0690, -0.1024],
          [-0.0564, -0.0405, -0.1049]],

         [[-0.0162,  0.0561,  0.0040],
          [ 0.0359,  0.0117,  0.0274],
          [ 0.0296,  0.0288, -0.0057]],

         [[ 0.0713,  0.0850,  0.0540],
          [ 0.0451,  0.0658,  0.0262],
          [-0.0169,  0.0266,  0.0632]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4388]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0482]], device='cuda:0')

Epoch: 16 | Batch_idx: 0 |  Loss: (0.3181) | Acc: (89.00%) (114/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.4247) | Acc: (86.00%) (1216/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.4349) | Acc: (85.00%) (2295/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.4280) | Acc: (85.00%) (3399/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.4308) | Acc: (85.00%) (4493/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.4332) | Acc: (85.00%) (5582/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.4397) | Acc: (85.00%) (6668/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.4388) | Acc: (85.00%) (7757/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.4362) | Acc: (85.00%) (8868/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.4404) | Acc: (85.00%) (9946/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.4354) | Acc: (85.00%) (11063/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.4356) | Acc: (85.00%) (12158/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.4352) | Acc: (85.00%) (13265/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.4349) | Acc: (85.00%) (14357/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.4326) | Acc: (85.00%) (15472/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.4318) | Acc: (85.00%) (16574/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.4310) | Acc: (85.00%) (17669/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.4322) | Acc: (85.00%) (18752/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.4339) | Acc: (85.00%) (19852/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.4320) | Acc: (85.00%) (20964/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.4321) | Acc: (85.00%) (22057/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.4323) | Acc: (85.00%) (23152/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.4308) | Acc: (85.00%) (24247/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.4310) | Acc: (85.00%) (25346/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.4311) | Acc: (85.00%) (26444/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.4311) | Acc: (85.00%) (27541/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.4317) | Acc: (85.00%) (28645/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.4346) | Acc: (85.00%) (29714/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.4351) | Acc: (85.00%) (30805/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.4363) | Acc: (85.00%) (31884/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.4358) | Acc: (85.00%) (32991/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.4356) | Acc: (85.00%) (34089/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.4351) | Acc: (85.00%) (35179/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.4352) | Acc: (85.00%) (36276/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.4349) | Acc: (85.00%) (37375/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.4350) | Acc: (85.00%) (38463/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.4345) | Acc: (85.00%) (39579/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.4363) | Acc: (85.00%) (40654/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.4357) | Acc: (85.00%) (41758/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.4359) | Acc: (85.00%) (42798/50000)
# TEST : Loss: (0.4494) | Acc: (84.00%) (8461/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0557,  0.1104, -0.0623],
          [-0.0835,  0.0378,  0.0144],
          [ 0.0403, -0.1641,  0.1942]],

         [[-0.0995,  0.1855,  0.0443],
          [-0.0545,  0.0988, -0.1330],
          [ 0.0691, -0.1784, -0.0517]],

         [[-0.0324,  0.2176, -0.1504],
          [ 0.0878, -0.1654, -0.0213],
          [ 0.0994, -0.1666,  0.1997]]],


        [[[-0.0811, -0.1920, -0.1251],
          [-0.1352,  0.1644,  0.1382],
          [ 0.1142,  0.0124,  0.1656]],

         [[-0.1760, -0.1249, -0.0953],
          [-0.1439,  0.0749,  0.1861],
          [ 0.1938, -0.0582,  0.0307]],

         [[-0.1283,  0.1573, -0.1701],
          [ 0.0739,  0.1901, -0.1473],
          [-0.0062,  0.0647,  0.0213]]],


        [[[-0.1180,  0.1789,  0.0685],
          [ 0.0946,  0.0548, -0.1109],
          [-0.1687,  0.0759, -0.1568]],

         [[ 0.1083,  0.0328,  0.0149],
          [ 0.0436,  0.1552,  0.0743],
          [ 0.0014,  0.0416, -0.2509]],

         [[-0.0813,  0.0054,  0.1584],
          [ 0.0031,  0.1790,  0.0623],
          [-0.1571, -0.1271, -0.1778]]],


        ...,


        [[[-0.1592, -0.1074, -0.0089],
          [ 0.1592, -0.1241, -0.0527],
          [ 0.1279, -0.0493,  0.0703]],

         [[ 0.1724,  0.0546, -0.0341],
          [-0.1174, -0.2687, -0.2108],
          [ 0.0658,  0.0373, -0.1709]],

         [[ 0.2233,  0.0223,  0.0612],
          [-0.0488, -0.0971, -0.1428],
          [ 0.0359, -0.0538, -0.0832]]],


        [[[ 0.1287,  0.0913,  0.0061],
          [-0.0214, -0.0745,  0.0820],
          [-0.0250, -0.1668,  0.0323]],

         [[ 0.0536,  0.1333, -0.1793],
          [-0.0569, -0.0835, -0.1370],
          [-0.0658, -0.1611,  0.0145]],

         [[ 0.0469,  0.1491, -0.1005],
          [-0.0758,  0.1038,  0.1010],
          [ 0.0751,  0.0157, -0.0119]]],


        [[[ 0.0509, -0.0067,  0.0454],
          [-0.0114,  0.0605, -0.0903],
          [-0.0502, -0.0359, -0.0936]],

         [[-0.0136,  0.0470,  0.0034],
          [ 0.0307,  0.0100,  0.0238],
          [ 0.0261,  0.0254, -0.0051]],

         [[ 0.0567,  0.0669,  0.0445],
          [ 0.0376,  0.0547,  0.0225],
          [-0.0148,  0.0232,  0.0558]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4576]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0218]], device='cuda:0')

Epoch: 17 | Batch_idx: 0 |  Loss: (0.3459) | Acc: (89.00%) (115/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.4162) | Acc: (85.00%) (1208/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.4205) | Acc: (85.00%) (2300/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.4205) | Acc: (85.00%) (3400/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.4313) | Acc: (85.00%) (4485/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.4325) | Acc: (85.00%) (5589/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.4313) | Acc: (85.00%) (6687/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.4300) | Acc: (85.00%) (7785/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.4373) | Acc: (85.00%) (8854/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.4408) | Acc: (85.00%) (9941/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.4374) | Acc: (85.00%) (11046/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.4352) | Acc: (85.00%) (12156/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.4325) | Acc: (85.00%) (13254/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.4329) | Acc: (85.00%) (14345/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.4341) | Acc: (85.00%) (15425/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.4327) | Acc: (85.00%) (16529/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.4328) | Acc: (85.00%) (17619/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.4318) | Acc: (85.00%) (18729/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.4333) | Acc: (85.00%) (19818/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.4329) | Acc: (85.00%) (20922/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.4319) | Acc: (85.00%) (22033/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.4303) | Acc: (85.00%) (23140/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.4288) | Acc: (85.00%) (24248/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.4306) | Acc: (85.00%) (25344/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.4305) | Acc: (85.00%) (26442/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.4311) | Acc: (85.00%) (27535/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.4311) | Acc: (85.00%) (28638/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.4325) | Acc: (85.00%) (29723/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.4310) | Acc: (85.00%) (30833/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.4312) | Acc: (85.00%) (31926/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.4320) | Acc: (85.00%) (33012/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.4324) | Acc: (85.00%) (34109/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.4331) | Acc: (85.00%) (35204/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.4325) | Acc: (85.00%) (36312/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.4323) | Acc: (85.00%) (37421/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.4313) | Acc: (85.00%) (38527/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.4315) | Acc: (85.00%) (39610/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.4316) | Acc: (85.00%) (40714/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.4333) | Acc: (85.00%) (41788/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.4336) | Acc: (85.00%) (42858/50000)
# TEST : Loss: (0.4491) | Acc: (84.00%) (8478/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0557,  0.1103, -0.0622],
          [-0.0834,  0.0378,  0.0144],
          [ 0.0402, -0.1639,  0.1940]],

         [[-0.0994,  0.1853,  0.0442],
          [-0.0545,  0.0987, -0.1328],
          [ 0.0690, -0.1782, -0.0516]],

         [[-0.0323,  0.2174, -0.1502],
          [ 0.0877, -0.1652, -0.0213],
          [ 0.0992, -0.1664,  0.1995]]],


        [[[-0.0809, -0.1915, -0.1248],
          [-0.1349,  0.1640,  0.1379],
          [ 0.1140,  0.0123,  0.1652]],

         [[-0.1756, -0.1246, -0.0950],
          [-0.1435,  0.0747,  0.1857],
          [ 0.1933, -0.0581,  0.0307]],

         [[-0.1280,  0.1569, -0.1696],
          [ 0.0737,  0.1896, -0.1469],
          [-0.0062,  0.0645,  0.0212]]],


        [[[-0.1178,  0.1785,  0.0684],
          [ 0.0945,  0.0547, -0.1107],
          [-0.1684,  0.0758, -0.1565]],

         [[ 0.1080,  0.0327,  0.0149],
          [ 0.0435,  0.1549,  0.0741],
          [ 0.0014,  0.0415, -0.2504]],

         [[-0.0811,  0.0054,  0.1580],
          [ 0.0031,  0.1786,  0.0621],
          [-0.1568, -0.1268, -0.1774]]],


        ...,


        [[[-0.1583, -0.1067, -0.0088],
          [ 0.1582, -0.1231, -0.0523],
          [ 0.1272, -0.0490,  0.0698]],

         [[ 0.1714,  0.0542, -0.0338],
          [-0.1166, -0.2655, -0.2074],
          [ 0.0654,  0.0369, -0.1692]],

         [[ 0.2220,  0.0222,  0.0607],
          [-0.0484, -0.0962, -0.1411],
          [ 0.0357, -0.0534, -0.0824]]],


        [[[ 0.1262,  0.0895,  0.0060],
          [-0.0210, -0.0727,  0.0801],
          [-0.0244, -0.1623,  0.0314]],

         [[ 0.0526,  0.1307, -0.1755],
          [-0.0556, -0.0815, -0.1337],
          [-0.0641, -0.1565,  0.0141]],

         [[ 0.0459,  0.1460, -0.0983],
          [-0.0740,  0.1012,  0.0986],
          [ 0.0731,  0.0152, -0.0115]]],


        [[[ 0.0432, -0.0057,  0.0385],
          [-0.0097,  0.0516, -0.0776],
          [-0.0435, -0.0311, -0.0814]],

         [[-0.0110,  0.0378,  0.0028],
          [ 0.0254,  0.0082,  0.0200],
          [ 0.0224,  0.0217, -0.0044]],

         [[ 0.0429,  0.0501,  0.0352],
          [ 0.0300,  0.0436,  0.0187],
          [-0.0126,  0.0197,  0.0480]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4538]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0239]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 18 | Batch_idx: 0 |  Loss: (0.3552) | Acc: (89.00%) (114/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.4868) | Acc: (83.00%) (1173/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.5270) | Acc: (82.00%) (2210/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.5544) | Acc: (81.00%) (3236/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.5773) | Acc: (80.00%) (4217/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.5964) | Acc: (79.00%) (5211/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.5919) | Acc: (79.00%) (6237/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.5927) | Acc: (79.00%) (7255/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.5973) | Acc: (79.00%) (8259/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.5970) | Acc: (79.00%) (9284/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.5970) | Acc: (79.00%) (10305/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.5961) | Acc: (79.00%) (11333/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.5891) | Acc: (80.00%) (12396/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.5874) | Acc: (80.00%) (13436/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.5828) | Acc: (80.00%) (14489/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.5809) | Acc: (80.00%) (15529/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.5778) | Acc: (80.00%) (16573/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.5750) | Acc: (80.00%) (17617/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.5758) | Acc: (80.00%) (18646/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.5736) | Acc: (80.00%) (19705/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.5718) | Acc: (80.00%) (20747/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.5694) | Acc: (80.00%) (21805/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.5655) | Acc: (80.00%) (22860/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.5623) | Acc: (80.00%) (23923/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.5610) | Acc: (80.00%) (24971/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.5597) | Acc: (80.00%) (26005/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.5575) | Acc: (80.00%) (27055/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.5562) | Acc: (81.00%) (28101/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.5553) | Acc: (81.00%) (29152/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.5525) | Acc: (81.00%) (30233/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.5499) | Acc: (81.00%) (31314/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.5476) | Acc: (81.00%) (32392/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.5448) | Acc: (81.00%) (33467/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.5419) | Acc: (81.00%) (34556/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.5404) | Acc: (81.00%) (35619/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.5394) | Acc: (81.00%) (36669/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.5388) | Acc: (81.00%) (37727/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.5371) | Acc: (81.00%) (38811/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.5357) | Acc: (81.00%) (39887/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.5347) | Acc: (81.00%) (40910/50000)
# TEST : Loss: (0.4952) | Acc: (83.00%) (8318/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0631,  0.1262, -0.0625],
          [-0.0849,  0.0479,  0.0163],
          [ 0.0415, -0.1677,  0.1955]],

         [[-0.1078,  0.2020,  0.0538],
          [-0.0567,  0.1017, -0.1306],
          [ 0.0691, -0.1901, -0.0547]],

         [[-0.0510,  0.2163, -0.1504],
          [ 0.0780, -0.1620, -0.0279],
          [ 0.0972, -0.1725,  0.1928]]],


        [[[-0.0858, -0.1968, -0.1282],
          [-0.1403,  0.1679,  0.1404],
          [ 0.1179,  0.0184,  0.1701]],

         [[-0.1819, -0.1319, -0.1024],
          [-0.1486,  0.0778,  0.1844],
          [ 0.1980, -0.0512,  0.0372]],

         [[-0.1221,  0.1601, -0.1648],
          [ 0.0761,  0.1976, -0.1411],
          [ 0.0004,  0.0700,  0.0280]]],


        [[[-0.1280,  0.1710,  0.0585],
          [ 0.0885,  0.0484, -0.1239],
          [-0.1847,  0.0572, -0.1771]],

         [[ 0.0999,  0.0339,  0.0120],
          [ 0.0451,  0.1609,  0.0727],
          [-0.0076,  0.0344, -0.2587]],

         [[-0.0703,  0.0234,  0.1733],
          [ 0.0123,  0.1939,  0.0763],
          [-0.1574, -0.1199, -0.1677]]],


        ...,


        [[[-0.1579, -0.1128,  0.0035],
          [ 0.1518, -0.1392, -0.0470],
          [ 0.1246, -0.0513,  0.0808]],

         [[ 0.1791,  0.0552, -0.0180],
          [-0.1139, -0.2787, -0.2028],
          [ 0.0730,  0.0425, -0.1553]],

         [[ 0.2271,  0.0232,  0.0687],
          [-0.0453, -0.1051, -0.1428],
          [ 0.0403, -0.0570, -0.0881]]],


        [[[ 0.1158,  0.0800, -0.0063],
          [-0.0335, -0.0846,  0.0649],
          [-0.0241, -0.1634,  0.0224]],

         [[ 0.0443,  0.1200, -0.1849],
          [-0.0629, -0.0910, -0.1424],
          [-0.0570, -0.1538,  0.0086]],

         [[ 0.0382,  0.1378, -0.1037],
          [-0.0736,  0.0983,  0.0934],
          [ 0.0814,  0.0219, -0.0089]]],


        [[[ 0.0019, -0.0420, -0.0032],
          [-0.0518, -0.0038, -0.1069],
          [-0.0687, -0.0618, -0.1004]],

         [[-0.0300,  0.0036, -0.0176],
          [-0.0060, -0.0260, -0.0027],
          [ 0.0129,  0.0049, -0.0096]],

         [[ 0.0112,  0.0043,  0.0062],
          [-0.0041, -0.0036, -0.0044],
          [-0.0184, -0.0004,  0.0323]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0656, -0.0596, -0.0408],
          [-0.0703, -0.0469, -0.0238],
          [-0.0444, -0.0282, -0.0233]],

         [[-0.0597, -0.0560, -0.0355],
          [-0.0756, -0.0493, -0.0264],
          [-0.0655, -0.0486, -0.0381]],

         [[-0.0576, -0.0722, -0.0718],
          [-0.0598, -0.0502, -0.0461],
          [-0.0526, -0.0480, -0.0476]]],


        [[[ 0.0421,  0.0281,  0.0266],
          [ 0.0300,  0.0259,  0.0328],
          [ 0.0373,  0.0360,  0.0368]],

         [[ 0.0171,  0.0008, -0.0053],
          [ 0.0080,  0.0005,  0.0008],
          [ 0.0121,  0.0123,  0.0088]],

         [[ 0.0056, -0.0029, -0.0059],
          [-0.0074, -0.0111, -0.0075],
          [-0.0021, -0.0009,  0.0000]]],


        [[[-0.0556, -0.0306, -0.0229],
          [-0.0645, -0.0420, -0.0291],
          [-0.0606, -0.0406, -0.0260]],

         [[-0.0664, -0.0404, -0.0263],
          [-0.0784, -0.0539, -0.0333],
          [-0.0795, -0.0558, -0.0321]],

         [[-0.0722, -0.0491, -0.0341],
          [-0.0815, -0.0578, -0.0388],
          [-0.0730, -0.0502, -0.0342]]],


        ...,


        [[[ 0.0221,  0.0131,  0.0051],
          [ 0.0194,  0.0115,  0.0035],
          [ 0.0152,  0.0114,  0.0052]],

         [[ 0.0146,  0.0064, -0.0002],
          [ 0.0134,  0.0063, -0.0010],
          [ 0.0118,  0.0086,  0.0023]],

         [[ 0.0066,  0.0009, -0.0032],
          [ 0.0052,  0.0009, -0.0030],
          [ 0.0046,  0.0035,  0.0015]]],


        [[[-0.0015, -0.0010, -0.0006],
          [-0.0015, -0.0012, -0.0007],
          [-0.0012, -0.0007, -0.0002]],

         [[-0.0019, -0.0014, -0.0010],
          [-0.0019, -0.0016, -0.0012],
          [-0.0015, -0.0011, -0.0006]],

         [[-0.0027, -0.0021, -0.0015],
          [-0.0026, -0.0021, -0.0018],
          [-0.0021, -0.0016, -0.0013]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4538]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 19 | Batch_idx: 0 |  Loss: (0.4003) | Acc: (86.00%) (111/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.4316) | Acc: (85.00%) (1210/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.4500) | Acc: (84.00%) (2276/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.4456) | Acc: (84.00%) (3366/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.4410) | Acc: (85.00%) (4468/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.4454) | Acc: (84.00%) (5546/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.4483) | Acc: (84.00%) (6616/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.4472) | Acc: (84.00%) (7714/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.4481) | Acc: (84.00%) (8795/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.4497) | Acc: (84.00%) (9870/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.4526) | Acc: (84.00%) (10935/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.4533) | Acc: (84.00%) (12014/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.4536) | Acc: (84.00%) (13094/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.4525) | Acc: (84.00%) (14182/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.4479) | Acc: (84.00%) (15291/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.4475) | Acc: (84.00%) (16385/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.4444) | Acc: (84.00%) (17492/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.4444) | Acc: (84.00%) (18580/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.4419) | Acc: (84.00%) (19673/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.4409) | Acc: (84.00%) (20764/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.4402) | Acc: (84.00%) (21852/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.4388) | Acc: (85.00%) (22957/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.4389) | Acc: (85.00%) (24053/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.4376) | Acc: (85.00%) (25164/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.4380) | Acc: (85.00%) (26251/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.4374) | Acc: (85.00%) (27344/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.4367) | Acc: (85.00%) (28433/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.4345) | Acc: (85.00%) (29552/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.4372) | Acc: (85.00%) (30619/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.4359) | Acc: (85.00%) (31730/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.4347) | Acc: (85.00%) (32839/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.4345) | Acc: (85.00%) (33926/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.4338) | Acc: (85.00%) (35027/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.4334) | Acc: (85.00%) (36124/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.4324) | Acc: (85.00%) (37233/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.4314) | Acc: (85.00%) (38342/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.4318) | Acc: (85.00%) (39418/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.4318) | Acc: (85.00%) (40496/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.4308) | Acc: (85.00%) (41603/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.4291) | Acc: (85.00%) (42683/50000)
# TEST : Loss: (0.4381) | Acc: (85.00%) (8513/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0648,  0.1291, -0.0644],
          [-0.0853,  0.0419,  0.0063],
          [ 0.0374, -0.1774,  0.1929]],

         [[-0.1080,  0.2080,  0.0589],
          [-0.0551,  0.0953, -0.1352],
          [ 0.0696, -0.2014, -0.0544]],

         [[-0.0538,  0.2199, -0.1427],
          [ 0.0836, -0.1615, -0.0285],
          [ 0.1038, -0.1720,  0.1969]]],


        [[[-0.0852, -0.2001, -0.1310],
          [-0.1382,  0.1726,  0.1442],
          [ 0.1284,  0.0258,  0.1734]],

         [[-0.1819, -0.1363, -0.1067],
          [-0.1478,  0.0812,  0.1858],
          [ 0.2036, -0.0495,  0.0371]],

         [[-0.1244,  0.1519, -0.1717],
          [ 0.0713,  0.1950, -0.1438],
          [ 0.0002,  0.0663,  0.0225]]],


        [[[-0.1241,  0.1763,  0.0665],
          [ 0.0953,  0.0570, -0.1161],
          [-0.1831,  0.0565, -0.1738]],

         [[ 0.0998,  0.0372,  0.0166],
          [ 0.0495,  0.1691,  0.0779],
          [-0.0089,  0.0321, -0.2594]],

         [[-0.0739,  0.0248,  0.1764],
          [ 0.0088,  0.1953,  0.0759],
          [-0.1629, -0.1255, -0.1731]]],


        ...,


        [[[-0.1696, -0.1226, -0.0017],
          [ 0.1433, -0.1484, -0.0507],
          [ 0.1168, -0.0574,  0.0796]],

         [[ 0.1617,  0.0372, -0.0313],
          [-0.1281, -0.3045, -0.2240],
          [ 0.0604,  0.0250, -0.1663]],

         [[ 0.2177,  0.0125,  0.0565],
          [-0.0463, -0.1115, -0.1530],
          [ 0.0389, -0.0605, -0.0944]]],


        [[[ 0.1088,  0.0818,  0.0013],
          [-0.0364, -0.0837,  0.0678],
          [-0.0215, -0.1556,  0.0338]],

         [[ 0.0324,  0.1144, -0.1807],
          [-0.0722, -0.0977, -0.1437],
          [-0.0601, -0.1551,  0.0083]],

         [[ 0.0295,  0.1339, -0.1012],
          [-0.0768,  0.0926,  0.0889],
          [ 0.0787,  0.0191, -0.0078]]],


        [[[ 0.0024, -0.0356, -0.0021],
          [-0.0448, -0.0041, -0.0932],
          [-0.0602, -0.0547, -0.0891]],

         [[-0.0233,  0.0036, -0.0135],
          [-0.0049, -0.0224, -0.0025],
          [ 0.0119,  0.0044, -0.0081]],

         [[ 0.0096,  0.0035,  0.0056],
          [-0.0037, -0.0040, -0.0043],
          [-0.0154, -0.0004,  0.0286]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0603, -0.0978, -0.0844],
          [-0.0664, -0.0880, -0.0810],
          [-0.0277, -0.0431, -0.0480]],

         [[-0.0772, -0.1070, -0.0916],
          [-0.0870, -0.0993, -0.0880],
          [-0.0422, -0.0598, -0.0634]],

         [[-0.0618, -0.0809, -0.0768],
          [-0.0626, -0.0841, -0.0744],
          [-0.0159, -0.0543, -0.0552]]],


        [[[-0.0002, -0.0052, -0.0043],
          [ 0.0047, -0.0006, -0.0079],
          [ 0.0054,  0.0029, -0.0001]],

         [[ 0.0024, -0.0076, -0.0109],
          [ 0.0069, -0.0038, -0.0157],
          [ 0.0039, -0.0015, -0.0059]],

         [[ 0.0020, -0.0056, -0.0049],
          [ 0.0082, -0.0012, -0.0095],
          [ 0.0073, -0.0004, -0.0039]]],


        [[[ 0.0190,  0.0105,  0.0112],
          [ 0.0121,  0.0029,  0.0064],
          [ 0.0084, -0.0007,  0.0005]],

         [[ 0.0170,  0.0030,  0.0014],
          [ 0.0082, -0.0040, -0.0023],
          [ 0.0060, -0.0051, -0.0077]],

         [[-0.0066, -0.0214, -0.0234],
          [-0.0148, -0.0259, -0.0241],
          [-0.0121, -0.0209, -0.0246]]],


        ...,


        [[[ 0.0159,  0.0065,  0.0062],
          [ 0.0180,  0.0094,  0.0100],
          [ 0.0186,  0.0098,  0.0108]],

         [[ 0.0126,  0.0028,  0.0014],
          [ 0.0141,  0.0043,  0.0034],
          [ 0.0152,  0.0049,  0.0036]],

         [[ 0.0086,  0.0007,  0.0003],
          [ 0.0101,  0.0013,  0.0004],
          [ 0.0103,  0.0006, -0.0011]]],


        [[[-0.0014, -0.0014, -0.0012],
          [-0.0008, -0.0010, -0.0009],
          [-0.0007, -0.0009, -0.0008]],

         [[-0.0010, -0.0009, -0.0007],
          [-0.0005, -0.0006, -0.0006],
          [-0.0005, -0.0007, -0.0007]],

         [[-0.0012, -0.0010, -0.0009],
          [-0.0007, -0.0007, -0.0008],
          [-0.0007, -0.0009, -0.0009]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4528]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 20 | Batch_idx: 0 |  Loss: (0.3250) | Acc: (89.00%) (115/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.3737) | Acc: (87.00%) (1228/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.3624) | Acc: (87.00%) (2344/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.3516) | Acc: (87.00%) (3482/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.3657) | Acc: (87.00%) (4595/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.3713) | Acc: (87.00%) (5701/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.3756) | Acc: (87.00%) (6825/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.3698) | Acc: (87.00%) (7959/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.3752) | Acc: (87.00%) (9061/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.3801) | Acc: (87.00%) (10151/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.3857) | Acc: (86.00%) (11238/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.3859) | Acc: (86.00%) (12349/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.3867) | Acc: (86.00%) (13456/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.3835) | Acc: (86.00%) (14584/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.3826) | Acc: (87.00%) (15705/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.3804) | Acc: (87.00%) (16838/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.3816) | Acc: (87.00%) (17951/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.3812) | Acc: (87.00%) (19069/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.3813) | Acc: (87.00%) (20171/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.3803) | Acc: (87.00%) (21290/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.3798) | Acc: (87.00%) (22416/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.3813) | Acc: (87.00%) (23523/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.3820) | Acc: (87.00%) (24621/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.3830) | Acc: (87.00%) (25735/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.3850) | Acc: (87.00%) (26843/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.3855) | Acc: (87.00%) (27954/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.3876) | Acc: (86.00%) (29043/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.3882) | Acc: (86.00%) (30136/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.3877) | Acc: (86.00%) (31256/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.3881) | Acc: (86.00%) (32363/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.3875) | Acc: (86.00%) (33479/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.3878) | Acc: (86.00%) (34579/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.3881) | Acc: (86.00%) (35687/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.3875) | Acc: (86.00%) (36801/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.3871) | Acc: (86.00%) (37920/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.3861) | Acc: (86.00%) (39053/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.3855) | Acc: (86.00%) (40171/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.3867) | Acc: (86.00%) (41269/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.3862) | Acc: (86.00%) (42388/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.3862) | Acc: (86.00%) (43459/50000)
# TEST : Loss: (0.4143) | Acc: (86.00%) (8620/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0689,  0.1291, -0.0640],
          [-0.0763,  0.0460,  0.0135],
          [ 0.0523, -0.1763,  0.1992]],

         [[-0.1132,  0.2047,  0.0578],
          [-0.0467,  0.0922, -0.1326],
          [ 0.0807, -0.2090, -0.0539]],

         [[-0.0551,  0.2185, -0.1375],
          [ 0.0959, -0.1558, -0.0229],
          [ 0.1217, -0.1678,  0.2026]]],


        [[[-0.0938, -0.2144, -0.1444],
          [-0.1463,  0.1668,  0.1387],
          [ 0.1186,  0.0157,  0.1678]],

         [[-0.1891, -0.1483, -0.1184],
          [-0.1561,  0.0775,  0.1825],
          [ 0.1929, -0.0576,  0.0352]],

         [[-0.1199,  0.1500, -0.1755],
          [ 0.0718,  0.1975, -0.1420],
          [-0.0045,  0.0633,  0.0247]]],


        [[[-0.1237,  0.1784,  0.0678],
          [ 0.0978,  0.0593, -0.1171],
          [-0.1812,  0.0545, -0.1769]],

         [[ 0.1026,  0.0414,  0.0179],
          [ 0.0566,  0.1748,  0.0775],
          [-0.0041,  0.0322, -0.2629]],

         [[-0.0716,  0.0281,  0.1782],
          [ 0.0124,  0.1965,  0.0725],
          [-0.1612, -0.1293, -0.1813]]],


        ...,


        [[[-0.1612, -0.1162,  0.0116],
          [ 0.1518, -0.1484, -0.0459],
          [ 0.1221, -0.0628,  0.0716]],

         [[ 0.1752,  0.0439, -0.0194],
          [-0.1115, -0.2991, -0.2157],
          [ 0.0708,  0.0216, -0.1725]],

         [[ 0.2216,  0.0081,  0.0580],
          [-0.0388, -0.1195, -0.1564],
          [ 0.0460, -0.0673, -0.1015]]],


        [[[ 0.0998,  0.0753,  0.0030],
          [-0.0456, -0.0932,  0.0594],
          [-0.0205, -0.1598,  0.0199]],

         [[ 0.0276,  0.1082, -0.1726],
          [-0.0749, -0.1029, -0.1427],
          [-0.0488, -0.1526, -0.0013]],

         [[ 0.0285,  0.1319, -0.0900],
          [-0.0727,  0.0899,  0.0902],
          [ 0.0914,  0.0243, -0.0059]]],


        [[[ 0.0023, -0.0293, -0.0015],
          [-0.0374, -0.0036, -0.0787],
          [-0.0513, -0.0468, -0.0771]],

         [[-0.0178,  0.0030, -0.0104],
          [-0.0038, -0.0182, -0.0020],
          [ 0.0102,  0.0038, -0.0068]],

         [[ 0.0076,  0.0028,  0.0047],
          [-0.0028, -0.0033, -0.0035],
          [-0.0127, -0.0003,  0.0247]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0371, -0.0594, -0.0971],
          [ 0.0081, -0.0285, -0.0908],
          [ 0.0200, -0.0286, -0.0712]],

         [[-0.0465, -0.0845, -0.1202],
          [-0.0232, -0.0696, -0.1297],
          [-0.0276, -0.0858, -0.1274]],

         [[-0.0564, -0.0935, -0.1475],
          [-0.0540, -0.0977, -0.1604],
          [-0.0692, -0.1216, -0.1703]]],


        [[[ 0.0565,  0.0393,  0.0276],
          [ 0.0560,  0.0363,  0.0307],
          [ 0.0664,  0.0538,  0.0486]],

         [[ 0.0474,  0.0286,  0.0152],
          [ 0.0486,  0.0263,  0.0167],
          [ 0.0598,  0.0426,  0.0338]],

         [[ 0.0350,  0.0187,  0.0066],
          [ 0.0416,  0.0222,  0.0136],
          [ 0.0565,  0.0369,  0.0266]]],


        [[[ 0.0131,  0.0112, -0.0085],
          [ 0.0390,  0.0274, -0.0013],
          [ 0.0433,  0.0233,  0.0010]],

         [[ 0.0032, -0.0038, -0.0280],
          [ 0.0224,  0.0080, -0.0201],
          [ 0.0244,  0.0034, -0.0153]],

         [[-0.0017, -0.0115, -0.0394],
          [ 0.0087, -0.0049, -0.0344],
          [ 0.0025, -0.0136, -0.0313]]],


        ...,


        [[[ 0.0116,  0.0057,  0.0017],
          [ 0.0139,  0.0080,  0.0048],
          [ 0.0214,  0.0162,  0.0125]],

         [[ 0.0158,  0.0091,  0.0038],
          [ 0.0169,  0.0096,  0.0044],
          [ 0.0246,  0.0177,  0.0118]],

         [[ 0.0136,  0.0073,  0.0015],
          [ 0.0115,  0.0047, -0.0008],
          [ 0.0161,  0.0105,  0.0051]]],


        [[[-0.0010, -0.0014, -0.0015],
          [-0.0006, -0.0009, -0.0013],
          [-0.0003, -0.0001, -0.0005]],

         [[-0.0006, -0.0010, -0.0012],
          [-0.0003, -0.0006, -0.0010],
          [-0.0001,  0.0001, -0.0004]],

         [[-0.0005, -0.0008, -0.0009],
          [-0.0001, -0.0004, -0.0008],
          [-0.0000,  0.0003, -0.0001]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4515]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 21 | Batch_idx: 0 |  Loss: (0.3018) | Acc: (89.00%) (115/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.3846) | Acc: (86.00%) (1220/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.4566) | Acc: (83.00%) (2252/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.4854) | Acc: (83.00%) (3301/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.4912) | Acc: (83.00%) (4366/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.4899) | Acc: (83.00%) (5426/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.4805) | Acc: (83.00%) (6531/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.4711) | Acc: (83.00%) (7627/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.4646) | Acc: (84.00%) (8724/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.4626) | Acc: (84.00%) (9811/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.4584) | Acc: (84.00%) (10908/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.4560) | Acc: (84.00%) (11998/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.4549) | Acc: (84.00%) (13070/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.4488) | Acc: (84.00%) (14195/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.4463) | Acc: (84.00%) (15301/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.4444) | Acc: (84.00%) (16399/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.4437) | Acc: (84.00%) (17504/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.4420) | Acc: (84.00%) (18598/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.4405) | Acc: (85.00%) (19705/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.4384) | Acc: (85.00%) (20821/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.4358) | Acc: (85.00%) (21936/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.4321) | Acc: (85.00%) (23065/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.4303) | Acc: (85.00%) (24179/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.4288) | Acc: (85.00%) (25293/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.4271) | Acc: (85.00%) (26410/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.4252) | Acc: (85.00%) (27535/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.4214) | Acc: (85.00%) (28668/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.4198) | Acc: (85.00%) (29782/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.4197) | Acc: (85.00%) (30898/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.4173) | Acc: (85.00%) (32032/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.4151) | Acc: (86.00%) (33165/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.4140) | Acc: (86.00%) (34275/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.4119) | Acc: (86.00%) (35400/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.4111) | Acc: (86.00%) (36505/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.4101) | Acc: (86.00%) (37629/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.4089) | Acc: (86.00%) (38750/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.4082) | Acc: (86.00%) (39867/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.4066) | Acc: (86.00%) (41006/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.4052) | Acc: (86.00%) (42131/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.4038) | Acc: (86.00%) (43211/50000)
# TEST : Loss: (0.4103) | Acc: (86.00%) (8608/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0685,  0.1298, -0.0639],
          [-0.0743,  0.0472,  0.0149],
          [ 0.0527, -0.1749,  0.2008]],

         [[-0.1124,  0.2055,  0.0579],
          [-0.0442,  0.0940, -0.1303],
          [ 0.0822, -0.2062, -0.0510]],

         [[-0.0536,  0.2205, -0.1353],
          [ 0.0993, -0.1525, -0.0190],
          [ 0.1243, -0.1639,  0.2070]]],


        [[[-0.0965, -0.2166, -0.1466],
          [-0.1482,  0.1642,  0.1365],
          [ 0.1153,  0.0126,  0.1647]],

         [[-0.1917, -0.1504, -0.1205],
          [-0.1581,  0.0752,  0.1804],
          [ 0.1896, -0.0602,  0.0328]],

         [[-0.1227,  0.1470, -0.1778],
          [ 0.0687,  0.1940, -0.1446],
          [-0.0087,  0.0590,  0.0208]]],


        [[[-0.1255,  0.1760,  0.0660],
          [ 0.0946,  0.0566, -0.1189],
          [-0.1842,  0.0518, -0.1787]],

         [[ 0.1015,  0.0404,  0.0176],
          [ 0.0542,  0.1729,  0.0765],
          [-0.0067,  0.0305, -0.2634]],

         [[-0.0715,  0.0281,  0.1789],
          [ 0.0111,  0.1956,  0.0727],
          [-0.1620, -0.1293, -0.1806]]],


        ...,


        [[[-0.1620, -0.1165,  0.0115],
          [ 0.1487, -0.1494, -0.0470],
          [ 0.1189, -0.0645,  0.0694]],

         [[ 0.1724,  0.0419, -0.0195],
          [-0.1136, -0.2992, -0.2150],
          [ 0.0679,  0.0195, -0.1726]],

         [[ 0.2194,  0.0078,  0.0585],
          [-0.0397, -0.1187, -0.1540],
          [ 0.0445, -0.0670, -0.1004]]],


        [[[ 0.0977,  0.0739,  0.0038],
          [-0.0436, -0.0894,  0.0580],
          [-0.0191, -0.1531,  0.0195]],

         [[ 0.0276,  0.1058, -0.1663],
          [-0.0718, -0.0984, -0.1365],
          [-0.0461, -0.1455, -0.0007]],

         [[ 0.0282,  0.1283, -0.0866],
          [-0.0698,  0.0866,  0.0870],
          [ 0.0881,  0.0227, -0.0058]]],


        [[[ 0.0018, -0.0232, -0.0012],
          [-0.0300, -0.0028, -0.0639],
          [-0.0424, -0.0387, -0.0646]],

         [[-0.0133,  0.0022, -0.0079],
          [-0.0030, -0.0140, -0.0016],
          [ 0.0083,  0.0031, -0.0057]],

         [[ 0.0053,  0.0020,  0.0035],
          [-0.0020, -0.0024, -0.0028],
          [-0.0102, -0.0002,  0.0205]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4485]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0272]], device='cuda:0')

Epoch: 22 | Batch_idx: 0 |  Loss: (0.3624) | Acc: (85.00%) (110/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.3459) | Acc: (87.00%) (1239/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.3461) | Acc: (87.00%) (2365/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.3619) | Acc: (87.00%) (3477/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.3668) | Acc: (87.00%) (4602/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.3628) | Acc: (87.00%) (5744/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.3581) | Acc: (88.00%) (6890/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.3534) | Acc: (88.00%) (8036/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.3527) | Acc: (88.00%) (9166/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.3501) | Acc: (88.00%) (10307/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.3518) | Acc: (88.00%) (11429/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.3519) | Acc: (88.00%) (12555/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.3517) | Acc: (88.00%) (13678/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.3521) | Acc: (88.00%) (14807/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.3506) | Acc: (88.00%) (15947/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.3523) | Acc: (88.00%) (17075/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.3528) | Acc: (88.00%) (18203/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.3518) | Acc: (88.00%) (19341/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.3530) | Acc: (88.00%) (20460/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.3517) | Acc: (88.00%) (21620/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.3527) | Acc: (88.00%) (22751/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.3520) | Acc: (88.00%) (23893/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.3523) | Acc: (88.00%) (25022/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.3513) | Acc: (88.00%) (26159/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.3513) | Acc: (88.00%) (27283/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.3515) | Acc: (88.00%) (28411/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.3520) | Acc: (88.00%) (29540/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.3524) | Acc: (88.00%) (30666/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.3531) | Acc: (88.00%) (31785/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.3522) | Acc: (88.00%) (32927/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.3522) | Acc: (88.00%) (34062/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.3525) | Acc: (88.00%) (35199/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.3523) | Acc: (88.00%) (36328/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.3528) | Acc: (88.00%) (37456/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.3542) | Acc: (88.00%) (38562/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.3533) | Acc: (88.00%) (39710/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.3516) | Acc: (88.00%) (40869/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.3522) | Acc: (88.00%) (41992/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.3515) | Acc: (88.00%) (43147/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.3515) | Acc: (88.00%) (44221/50000)
# TEST : Loss: (0.3957) | Acc: (86.00%) (8665/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0684,  0.1296, -0.0638],
          [-0.0742,  0.0471,  0.0149],
          [ 0.0526, -0.1746,  0.2005]],

         [[-0.1123,  0.2052,  0.0579],
          [-0.0441,  0.0939, -0.1301],
          [ 0.0821, -0.2059, -0.0510]],

         [[-0.0536,  0.2202, -0.1351],
          [ 0.0992, -0.1523, -0.0190],
          [ 0.1241, -0.1637,  0.2068]]],


        [[[-0.0963, -0.2162, -0.1463],
          [-0.1479,  0.1638,  0.1362],
          [ 0.1150,  0.0126,  0.1643]],

         [[-0.1912, -0.1500, -0.1202],
          [-0.1578,  0.0750,  0.1800],
          [ 0.1892, -0.0600,  0.0327]],

         [[-0.1224,  0.1467, -0.1774],
          [ 0.0685,  0.1935, -0.1442],
          [-0.0086,  0.0589,  0.0208]]],


        [[[-0.1253,  0.1757,  0.0659],
          [ 0.0944,  0.0565, -0.1187],
          [-0.1839,  0.0517, -0.1784]],

         [[ 0.1013,  0.0403,  0.0176],
          [ 0.0541,  0.1726,  0.0764],
          [-0.0067,  0.0305, -0.2629]],

         [[-0.0713,  0.0281,  0.1786],
          [ 0.0111,  0.1953,  0.0725],
          [-0.1616, -0.1291, -0.1802]]],


        ...,


        [[[-0.1611, -0.1157,  0.0115],
          [ 0.1478, -0.1481, -0.0465],
          [ 0.1182, -0.0640,  0.0689]],

         [[ 0.1714,  0.0416, -0.0194],
          [-0.1128, -0.2952, -0.2113],
          [ 0.0675,  0.0194, -0.1709]],

         [[ 0.2181,  0.0077,  0.0581],
          [-0.0394, -0.1174, -0.1522],
          [ 0.0442, -0.0665, -0.0995]]],


        [[[ 0.0944,  0.0713,  0.0037],
          [-0.0418, -0.0855,  0.0555],
          [-0.0182, -0.1451,  0.0186]],

         [[ 0.0266,  0.1020, -0.1599],
          [-0.0687, -0.0937, -0.1301],
          [-0.0438, -0.1372, -0.0007]],

         [[ 0.0272,  0.1235, -0.0832],
          [-0.0668,  0.0827,  0.0830],
          [ 0.0839,  0.0215, -0.0055]]],


        [[[ 0.0014, -0.0174, -0.0009],
          [-0.0229, -0.0022, -0.0496],
          [-0.0336, -0.0307, -0.0521]],

         [[-0.0092,  0.0015, -0.0056],
          [-0.0021, -0.0102, -0.0012],
          [ 0.0065,  0.0024, -0.0046]],

         [[ 0.0034,  0.0013,  0.0024],
          [-0.0014, -0.0017, -0.0021],
          [-0.0078, -0.0002,  0.0163]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4427]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0447]], device='cuda:0')

Epoch: 23 | Batch_idx: 0 |  Loss: (0.3444) | Acc: (88.00%) (113/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.3468) | Acc: (88.00%) (1247/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.3606) | Acc: (88.00%) (2368/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.3508) | Acc: (88.00%) (3509/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.3515) | Acc: (88.00%) (4639/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.3483) | Acc: (88.00%) (5780/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.3480) | Acc: (88.00%) (6917/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.3444) | Acc: (88.00%) (8054/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.3412) | Acc: (88.00%) (9204/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.3464) | Acc: (88.00%) (10315/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.3470) | Acc: (88.00%) (11439/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.3495) | Acc: (88.00%) (12551/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.3473) | Acc: (88.00%) (13700/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.3472) | Acc: (88.00%) (14837/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.3459) | Acc: (88.00%) (15978/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.3447) | Acc: (88.00%) (17112/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.3427) | Acc: (88.00%) (18265/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.3425) | Acc: (88.00%) (19388/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.3432) | Acc: (88.00%) (20509/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.3436) | Acc: (88.00%) (21648/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.3457) | Acc: (88.00%) (22757/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.3453) | Acc: (88.00%) (23883/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.3461) | Acc: (88.00%) (25010/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.3464) | Acc: (88.00%) (26144/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.3474) | Acc: (88.00%) (27275/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.3469) | Acc: (88.00%) (28401/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.3470) | Acc: (88.00%) (29537/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.3480) | Acc: (88.00%) (30673/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.3487) | Acc: (88.00%) (31795/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.3491) | Acc: (88.00%) (32916/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.3498) | Acc: (88.00%) (34045/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.3502) | Acc: (88.00%) (35175/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.3504) | Acc: (88.00%) (36302/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.3511) | Acc: (88.00%) (37415/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.3516) | Acc: (88.00%) (38537/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.3515) | Acc: (88.00%) (39673/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.3525) | Acc: (88.00%) (40788/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.3518) | Acc: (88.00%) (41934/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.3511) | Acc: (88.00%) (43076/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.3506) | Acc: (88.00%) (44181/50000)
# TEST : Loss: (0.3923) | Acc: (86.00%) (8678/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0683,  0.1294, -0.0637],
          [-0.0741,  0.0471,  0.0149],
          [ 0.0526, -0.1744,  0.2002]],

         [[-0.1121,  0.2049,  0.0578],
          [-0.0441,  0.0937, -0.1299],
          [ 0.0820, -0.2056, -0.0509]],

         [[-0.0535,  0.2198, -0.1349],
          [ 0.0990, -0.1521, -0.0189],
          [ 0.1240, -0.1634,  0.2064]]],


        [[[-0.0961, -0.2156, -0.1459],
          [-0.1475,  0.1634,  0.1359],
          [ 0.1147,  0.0125,  0.1639]],

         [[-0.1907, -0.1496, -0.1199],
          [-0.1573,  0.0748,  0.1795],
          [ 0.1887, -0.0599,  0.0326]],

         [[-0.1221,  0.1462, -0.1769],
          [ 0.0683,  0.1930, -0.1438],
          [-0.0086,  0.0587,  0.0207]]],


        [[[-0.1250,  0.1753,  0.0657],
          [ 0.0942,  0.0564, -0.1185],
          [-0.1835,  0.0516, -0.1780]],

         [[ 0.1011,  0.0402,  0.0175],
          [ 0.0540,  0.1722,  0.0762],
          [-0.0066,  0.0304, -0.2623]],

         [[-0.0712,  0.0280,  0.1781],
          [ 0.0111,  0.1948,  0.0724],
          [-0.1613, -0.1288, -0.1798]]],


        ...,


        [[[-0.1600, -0.1148,  0.0114],
          [ 0.1467, -0.1465, -0.0460],
          [ 0.1174, -0.0635,  0.0683]],

         [[ 0.1702,  0.0412, -0.0192],
          [-0.1119, -0.2905, -0.2068],
          [ 0.0670,  0.0192, -0.1689]],

         [[ 0.2165,  0.0076,  0.0575],
          [-0.0391, -0.1159, -0.1500],
          [ 0.0439, -0.0658, -0.0983]]],


        [[[ 0.0906,  0.0683,  0.0035],
          [-0.0397, -0.0810,  0.0527],
          [-0.0172, -0.1360,  0.0175]],

         [[ 0.0255,  0.0975, -0.1524],
          [-0.0652, -0.0883, -0.1227],
          [-0.0412, -0.1277, -0.0006]],

         [[ 0.0260,  0.1179, -0.0793],
          [-0.0633,  0.0780,  0.0785],
          [ 0.0790,  0.0202, -0.0052]]],


        [[[ 0.0010, -0.0123, -0.0006],
          [-0.0165, -0.0015, -0.0364],
          [-0.0253, -0.0232, -0.0401]],

         [[-0.0060,  0.0010, -0.0037],
          [-0.0014, -0.0069, -0.0009],
          [ 0.0048,  0.0018, -0.0035]],

         [[ 0.0020,  0.0007,  0.0015],
          [-0.0009, -0.0011, -0.0015],
          [-0.0056, -0.0001,  0.0123]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4460]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0295]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 24 | Batch_idx: 0 |  Loss: (0.4154) | Acc: (85.00%) (110/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.4212) | Acc: (85.00%) (1210/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.4569) | Acc: (84.00%) (2269/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.4873) | Acc: (83.00%) (3306/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.4949) | Acc: (83.00%) (4358/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.5041) | Acc: (82.00%) (5394/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.5092) | Acc: (82.00%) (6447/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.5099) | Acc: (82.00%) (7491/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.5153) | Acc: (82.00%) (8530/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.5195) | Acc: (82.00%) (9580/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.5202) | Acc: (82.00%) (10635/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.5179) | Acc: (82.00%) (11691/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.5106) | Acc: (82.00%) (12788/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.5071) | Acc: (82.00%) (13870/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.5026) | Acc: (82.00%) (14964/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.5006) | Acc: (82.00%) (16031/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.4994) | Acc: (82.00%) (17101/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.5002) | Acc: (82.00%) (18157/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.4971) | Acc: (83.00%) (19239/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.4948) | Acc: (83.00%) (20332/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.4946) | Acc: (83.00%) (21404/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.4911) | Acc: (83.00%) (22501/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.4895) | Acc: (83.00%) (23586/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.4868) | Acc: (83.00%) (24684/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.4854) | Acc: (83.00%) (25767/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.4873) | Acc: (83.00%) (26818/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.4869) | Acc: (83.00%) (27879/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.4860) | Acc: (83.00%) (28956/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.4846) | Acc: (83.00%) (30053/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.4843) | Acc: (83.00%) (31133/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.4818) | Acc: (83.00%) (32241/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.4808) | Acc: (83.00%) (33327/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.4800) | Acc: (83.00%) (34409/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.4781) | Acc: (83.00%) (35493/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.4761) | Acc: (83.00%) (36600/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.4751) | Acc: (83.00%) (37692/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.4731) | Acc: (83.00%) (38796/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.4711) | Acc: (84.00%) (39904/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.4703) | Acc: (84.00%) (40986/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.4688) | Acc: (84.00%) (42058/50000)
# TEST : Loss: (0.4650) | Acc: (84.00%) (8467/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0610,  0.1456, -0.0641],
          [-0.0796,  0.0417,  0.0012],
          [ 0.0410, -0.1820,  0.1935]],

         [[-0.1059,  0.2237,  0.0559],
          [-0.0520,  0.0810, -0.1480],
          [ 0.0745, -0.2180, -0.0601]],

         [[-0.0549,  0.2318, -0.1384],
          [ 0.0860, -0.1595, -0.0331],
          [ 0.1144, -0.1672,  0.2061]]],


        [[[-0.0991, -0.2136, -0.1362],
          [-0.1437,  0.1766,  0.1498],
          [ 0.1206,  0.0243,  0.1769]],

         [[-0.1955, -0.1507, -0.1179],
          [-0.1522,  0.0871,  0.1881],
          [ 0.1957, -0.0496,  0.0430]],

         [[-0.1197,  0.1493, -0.1733],
          [ 0.0768,  0.2074, -0.1327],
          [-0.0056,  0.0643,  0.0297]]],


        [[[-0.1249,  0.1799,  0.0728],
          [ 0.1001,  0.0631, -0.1146],
          [-0.1811,  0.0516, -0.1787]],

         [[ 0.0969,  0.0417,  0.0182],
          [ 0.0545,  0.1750,  0.0748],
          [-0.0136,  0.0247, -0.2677]],

         [[-0.0809,  0.0285,  0.1766],
          [ 0.0045,  0.1943,  0.0675],
          [-0.1760, -0.1389, -0.1901]]],


        ...,


        [[[-0.1562, -0.1214,  0.0100],
          [ 0.1452, -0.1594, -0.0458],
          [ 0.1234, -0.0688,  0.0796]],

         [[ 0.1789,  0.0327, -0.0188],
          [-0.1066, -0.3116, -0.2063],
          [ 0.0780,  0.0114, -0.1512]],

         [[ 0.2216, -0.0031,  0.0534],
          [-0.0328, -0.1272, -0.1447],
          [ 0.0522, -0.0736, -0.0904]]],


        [[[ 0.1086,  0.0876,  0.0278],
          [-0.0289, -0.0654,  0.0640],
          [-0.0070, -0.1160,  0.0342]],

         [[ 0.0470,  0.1164, -0.1184],
          [-0.0561, -0.0740, -0.1011],
          [-0.0365, -0.1163,  0.0111]],

         [[ 0.0340,  0.1221, -0.0652],
          [-0.0665,  0.0683,  0.0711],
          [ 0.0646,  0.0069, -0.0110]]],


        [[[ 0.0022, -0.0075,  0.0007],
          [-0.0112, -0.0022, -0.0257],
          [-0.0178, -0.0172, -0.0294]],

         [[-0.0012,  0.0018, -0.0013],
          [-0.0006, -0.0051, -0.0013],
          [ 0.0039,  0.0010, -0.0028]],

         [[-0.0022, -0.0038, -0.0028],
          [-0.0049, -0.0058, -0.0051],
          [-0.0069, -0.0039,  0.0055]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0138,  0.0082,  0.0352],
          [-0.0213, -0.0311,  0.0123],
          [-0.0349, -0.0164, -0.0191]],

         [[-0.0194, -0.0031,  0.0189],
          [-0.0165, -0.0286, -0.0032],
          [-0.0350, -0.0209, -0.0247]],

         [[-0.0212, -0.0048,  0.0087],
          [-0.0311, -0.0400, -0.0184],
          [-0.0470, -0.0346, -0.0316]]],


        [[[ 0.0156,  0.0186,  0.0279],
          [ 0.0220,  0.0195,  0.0274],
          [ 0.0162,  0.0159,  0.0164]],

         [[-0.0016,  0.0048,  0.0156],
          [ 0.0046,  0.0079,  0.0197],
          [ 0.0080,  0.0135,  0.0150]],

         [[-0.0211, -0.0160, -0.0048],
          [-0.0162, -0.0120,  0.0014],
          [-0.0080, -0.0043, -0.0002]]],


        [[[-0.0081, -0.0016,  0.0044],
          [-0.0217, -0.0092,  0.0021],
          [-0.0170, -0.0067,  0.0058]],

         [[ 0.0047,  0.0168,  0.0230],
          [-0.0064,  0.0129,  0.0239],
          [-0.0019,  0.0165,  0.0278]],

         [[-0.0008,  0.0116,  0.0155],
          [-0.0112,  0.0047,  0.0112],
          [-0.0069,  0.0076,  0.0156]]],


        ...,


        [[[-0.0018,  0.0003,  0.0025],
          [ 0.0022,  0.0033,  0.0035],
          [-0.0003,  0.0008,  0.0003]],

         [[-0.0013,  0.0003, -0.0001],
          [ 0.0015,  0.0015, -0.0011],
          [-0.0033, -0.0034, -0.0055]],

         [[-0.0007,  0.0020,  0.0019],
          [ 0.0008,  0.0016, -0.0006],
          [-0.0042, -0.0028, -0.0052]]],


        [[[-0.0003, -0.0003, -0.0003],
          [-0.0003, -0.0003, -0.0002],
          [-0.0004, -0.0002, -0.0001]],

         [[-0.0002, -0.0002, -0.0002],
          [-0.0002, -0.0001, -0.0001],
          [-0.0003, -0.0000, -0.0001]],

         [[-0.0001, -0.0000, -0.0001],
          [-0.0001, -0.0000, -0.0000],
          [-0.0002,  0.0000,  0.0001]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4466]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 25 | Batch_idx: 0 |  Loss: (0.4847) | Acc: (81.00%) (104/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.3977) | Acc: (86.00%) (1213/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.3839) | Acc: (86.00%) (2333/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.3894) | Acc: (86.00%) (3432/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.3871) | Acc: (86.00%) (4540/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.3949) | Acc: (86.00%) (5624/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.3904) | Acc: (86.00%) (6746/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.3863) | Acc: (86.00%) (7869/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.3873) | Acc: (86.00%) (8986/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.3899) | Acc: (86.00%) (10086/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.3899) | Acc: (86.00%) (11198/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.3902) | Acc: (86.00%) (12317/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.3903) | Acc: (86.00%) (13432/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.3904) | Acc: (86.00%) (14539/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.3901) | Acc: (86.00%) (15652/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.3885) | Acc: (86.00%) (16777/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.3872) | Acc: (86.00%) (17895/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.3869) | Acc: (86.00%) (19015/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.3869) | Acc: (86.00%) (20134/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.3846) | Acc: (87.00%) (21276/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.3858) | Acc: (86.00%) (22383/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.3849) | Acc: (86.00%) (23492/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.3852) | Acc: (86.00%) (24590/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.3834) | Acc: (87.00%) (25725/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.3815) | Acc: (87.00%) (26864/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.3803) | Acc: (87.00%) (27992/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.3796) | Acc: (87.00%) (29102/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.3823) | Acc: (87.00%) (30183/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.3811) | Acc: (87.00%) (31325/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.3807) | Acc: (87.00%) (32434/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.3804) | Acc: (87.00%) (33554/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.3807) | Acc: (87.00%) (34654/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.3804) | Acc: (87.00%) (35773/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.3814) | Acc: (87.00%) (36872/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.3817) | Acc: (87.00%) (37997/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.3819) | Acc: (87.00%) (39114/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.3814) | Acc: (87.00%) (40236/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.3809) | Acc: (87.00%) (41364/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.3805) | Acc: (87.00%) (42494/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.3808) | Acc: (87.00%) (43569/50000)
# TEST : Loss: (0.4582) | Acc: (85.00%) (8513/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0629,  0.1547, -0.0513],
          [-0.0763,  0.0409,  0.0062],
          [ 0.0448, -0.1820,  0.2065]],

         [[-0.1023,  0.2350,  0.0677],
          [-0.0489,  0.0764, -0.1446],
          [ 0.0719, -0.2247, -0.0521]],

         [[-0.0621,  0.2276, -0.1347],
          [ 0.0796, -0.1662, -0.0362],
          [ 0.1062, -0.1691,  0.2085]]],


        [[[-0.0933, -0.2109, -0.1349],
          [-0.1357,  0.1853,  0.1544],
          [ 0.1310,  0.0336,  0.1827]],

         [[-0.1902, -0.1506, -0.1201],
          [-0.1459,  0.0951,  0.1921],
          [ 0.2048, -0.0406,  0.0495]],

         [[-0.1141,  0.1509, -0.1711],
          [ 0.0812,  0.2152, -0.1258],
          [ 0.0013,  0.0726,  0.0382]]],


        [[[-0.1116,  0.1923,  0.0835],
          [ 0.1155,  0.0771, -0.1006],
          [-0.1763,  0.0518, -0.1720]],

         [[ 0.0933,  0.0407,  0.0164],
          [ 0.0575,  0.1797,  0.0792],
          [-0.0225,  0.0148, -0.2701]],

         [[-0.0835,  0.0309,  0.1826],
          [ 0.0064,  0.1997,  0.0772],
          [-0.1830, -0.1449, -0.1878]]],


        ...,


        [[[-0.1558, -0.1178,  0.0104],
          [ 0.1421, -0.1702, -0.0640],
          [ 0.1147, -0.0796,  0.0637]],

         [[ 0.1849,  0.0474,  0.0006],
          [-0.1027, -0.3142, -0.2066],
          [ 0.0770,  0.0057, -0.1543]],

         [[ 0.2254,  0.0089,  0.0693],
          [-0.0305, -0.1284, -0.1432],
          [ 0.0533, -0.0744, -0.0879]]],


        [[[ 0.1068,  0.0857,  0.0282],
          [-0.0236, -0.0589,  0.0602],
          [-0.0003, -0.1025,  0.0337]],

         [[ 0.0442,  0.1084, -0.1139],
          [-0.0544, -0.0720, -0.0992],
          [-0.0341, -0.1090,  0.0051]],

         [[ 0.0288,  0.1110, -0.0661],
          [-0.0673,  0.0580,  0.0600],
          [ 0.0558,  0.0007, -0.0162]]],


        [[[ 0.0017, -0.0044,  0.0006],
          [-0.0071, -0.0019, -0.0166],
          [-0.0118, -0.0118, -0.0203]],

         [[-0.0000,  0.0012, -0.0004],
          [-0.0003, -0.0032, -0.0011],
          [ 0.0026,  0.0004, -0.0021]],

         [[-0.0044, -0.0054, -0.0051],
          [-0.0064, -0.0072, -0.0069],
          [-0.0077, -0.0060,  0.0003]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0066,  0.0182, -0.0010],
          [-0.0209,  0.0042, -0.0202],
          [-0.0187,  0.0028, -0.0222]],

         [[ 0.0091,  0.0249,  0.0139],
          [-0.0112,  0.0103, -0.0069],
          [-0.0133,  0.0086, -0.0119]],

         [[ 0.0051,  0.0162,  0.0133],
          [-0.0225, -0.0025, -0.0128],
          [-0.0150,  0.0020, -0.0175]]],


        [[[ 0.0085,  0.0126,  0.0316],
          [ 0.0086,  0.0174,  0.0325],
          [ 0.0077,  0.0081,  0.0116]],

         [[-0.0076, -0.0052,  0.0091],
          [-0.0137, -0.0051,  0.0068],
          [-0.0169, -0.0161, -0.0128]],

         [[-0.0164, -0.0172, -0.0061],
          [-0.0120, -0.0067,  0.0040],
          [-0.0086, -0.0076, -0.0040]]],


        [[[ 0.0435,  0.0639,  0.0719],
          [ 0.0530,  0.0724,  0.0732],
          [ 0.0531,  0.0734,  0.0760]],

         [[ 0.0354,  0.0537,  0.0610],
          [ 0.0512,  0.0678,  0.0681],
          [ 0.0565,  0.0731,  0.0741]],

         [[ 0.0122,  0.0279,  0.0348],
          [ 0.0236,  0.0365,  0.0389],
          [ 0.0374,  0.0487,  0.0503]]],


        ...,


        [[[ 0.0268,  0.0236,  0.0265],
          [ 0.0160,  0.0087,  0.0121],
          [ 0.0026, -0.0036,  0.0008]],

         [[ 0.0239,  0.0177,  0.0196],
          [ 0.0148,  0.0050,  0.0067],
          [ 0.0016, -0.0063, -0.0040]],

         [[ 0.0265,  0.0184,  0.0202],
          [ 0.0190,  0.0087,  0.0100],
          [ 0.0084,  0.0017,  0.0037]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4456]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 26 | Batch_idx: 0 |  Loss: (0.3203) | Acc: (89.00%) (115/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.3330) | Acc: (88.00%) (1246/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.3430) | Acc: (88.00%) (2382/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.3390) | Acc: (88.00%) (3525/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.3339) | Acc: (88.00%) (4664/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.3357) | Acc: (88.00%) (5795/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.3380) | Acc: (88.00%) (6932/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.3356) | Acc: (88.00%) (8075/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.3337) | Acc: (88.00%) (9227/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.3297) | Acc: (89.00%) (10380/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.3281) | Acc: (89.00%) (11510/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.3309) | Acc: (88.00%) (12637/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.3294) | Acc: (89.00%) (13789/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.3298) | Acc: (89.00%) (14931/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.3273) | Acc: (89.00%) (16083/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.3289) | Acc: (89.00%) (17216/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.3288) | Acc: (89.00%) (18360/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.3304) | Acc: (88.00%) (19477/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.3296) | Acc: (88.00%) (20618/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.3312) | Acc: (88.00%) (21727/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.3330) | Acc: (88.00%) (22843/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.3345) | Acc: (88.00%) (23947/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.3357) | Acc: (88.00%) (25078/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.3385) | Acc: (88.00%) (26196/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.3381) | Acc: (88.00%) (27327/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.3389) | Acc: (88.00%) (28453/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.3385) | Acc: (88.00%) (29576/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.3396) | Acc: (88.00%) (30696/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.3395) | Acc: (88.00%) (31835/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.3394) | Acc: (88.00%) (32967/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.3410) | Acc: (88.00%) (34078/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.3405) | Acc: (88.00%) (35218/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.3410) | Acc: (88.00%) (36336/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.3409) | Acc: (88.00%) (37479/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.3400) | Acc: (88.00%) (38615/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.3397) | Acc: (88.00%) (39749/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.3402) | Acc: (88.00%) (40875/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.3398) | Acc: (88.00%) (42019/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.3406) | Acc: (88.00%) (43144/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.3407) | Acc: (88.00%) (44238/50000)
# TEST : Loss: (0.3921) | Acc: (86.00%) (8635/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0697,  0.1549, -0.0655],
          [-0.0738,  0.0397, -0.0034],
          [ 0.0470, -0.1931,  0.1951]],

         [[-0.1045,  0.2392,  0.0644],
          [-0.0459,  0.0769, -0.1475],
          [ 0.0723, -0.2334, -0.0613]],

         [[-0.0567,  0.2312, -0.1392],
          [ 0.0884, -0.1575, -0.0405],
          [ 0.1137, -0.1676,  0.1987]]],


        [[[-0.1047, -0.2252, -0.1450],
          [-0.1399,  0.1792,  0.1465],
          [ 0.1281,  0.0283,  0.1727]],

         [[-0.1988, -0.1636, -0.1326],
          [-0.1465,  0.0913,  0.1834],
          [ 0.2051, -0.0446,  0.0404]],

         [[-0.1100,  0.1469, -0.1785],
          [ 0.0883,  0.2141, -0.1341],
          [ 0.0057,  0.0707,  0.0301]]],


        [[[-0.1158,  0.1862,  0.0767],
          [ 0.1139,  0.0739, -0.1065],
          [-0.1822,  0.0408, -0.1836]],

         [[ 0.0873,  0.0378,  0.0158],
          [ 0.0526,  0.1759,  0.0767],
          [-0.0305,  0.0031, -0.2799]],

         [[-0.0888,  0.0278,  0.1802],
          [ 0.0041,  0.1965,  0.0738],
          [-0.1849, -0.1527, -0.1989]]],


        ...,


        [[[-0.1504, -0.1076,  0.0217],
          [ 0.1572, -0.1566, -0.0464],
          [ 0.1384, -0.0567,  0.0873]],

         [[ 0.1796,  0.0410, -0.0038],
          [-0.0938, -0.3159, -0.2131],
          [ 0.0929,  0.0144, -0.1499]],

         [[ 0.2083, -0.0074,  0.0564],
          [-0.0414, -0.1510, -0.1648],
          [ 0.0501, -0.0888, -0.1058]]],


        [[[ 0.0993,  0.0784,  0.0235],
          [-0.0254, -0.0578,  0.0524],
          [-0.0047, -0.0992,  0.0265]],

         [[ 0.0417,  0.1008, -0.1061],
          [-0.0527, -0.0679, -0.0921],
          [-0.0333, -0.1022,  0.0019]],

         [[ 0.0292,  0.1055, -0.0594],
          [-0.0608,  0.0554,  0.0569],
          [ 0.0523,  0.0010, -0.0141]]],


        [[[ 0.0023, -0.0016,  0.0014],
          [-0.0036, -0.0014, -0.0095],
          [-0.0065, -0.0071, -0.0124]],

         [[ 0.0013,  0.0011,  0.0007],
          [-0.0001, -0.0023, -0.0009],
          [ 0.0018, -0.0000, -0.0012]],

         [[-0.0010, -0.0021, -0.0019],
          [-0.0033, -0.0045, -0.0043],
          [-0.0044, -0.0041, -0.0000]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0174, -0.0165,  0.0288],
          [ 0.0011, -0.0099,  0.0078],
          [-0.0128, -0.0187, -0.0128]],

         [[-0.0304, -0.0258,  0.0145],
          [-0.0205, -0.0279, -0.0074],
          [-0.0274, -0.0383, -0.0275]],

         [[ 0.0102,  0.0062,  0.0352],
          [ 0.0061, -0.0053,  0.0122],
          [-0.0066, -0.0110, -0.0058]]],


        [[[-0.0261, -0.0220, -0.0156],
          [-0.0236, -0.0325, -0.0289],
          [-0.0224, -0.0278, -0.0243]],

         [[-0.0376, -0.0349, -0.0312],
          [-0.0325, -0.0370, -0.0356],
          [-0.0339, -0.0365, -0.0313]],

         [[-0.0223, -0.0201, -0.0159],
          [-0.0119, -0.0127, -0.0140],
          [-0.0131, -0.0130, -0.0118]]],


        [[[ 0.0735,  0.0604,  0.0546],
          [ 0.0740,  0.0626,  0.0651],
          [ 0.0599,  0.0499,  0.0556]],

         [[ 0.0947,  0.0896,  0.0838],
          [ 0.0973,  0.0899,  0.0913],
          [ 0.0832,  0.0778,  0.0817]],

         [[ 0.0914,  0.0874,  0.0791],
          [ 0.0952,  0.0859,  0.0819],
          [ 0.0852,  0.0748,  0.0735]]],


        ...,


        [[[ 0.0056,  0.0079,  0.0035],
          [-0.0053, -0.0032, -0.0069],
          [-0.0051, -0.0061, -0.0102]],

         [[ 0.0088,  0.0105,  0.0062],
          [-0.0011,  0.0005, -0.0030],
          [-0.0022, -0.0018, -0.0051]],

         [[ 0.0247,  0.0249,  0.0213],
          [ 0.0151,  0.0145,  0.0117],
          [ 0.0130,  0.0130,  0.0111]]],


        [[[-0.0000,  0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0001, -0.0001]],

         [[ 0.0001,  0.0001,  0.0001],
          [ 0.0001,  0.0001,  0.0001],
          [ 0.0001,  0.0001,  0.0001]],

         [[ 0.0001,  0.0001,  0.0001],
          [ 0.0001,  0.0001,  0.0001],
          [ 0.0001,  0.0001,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4443]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 27 | Batch_idx: 0 |  Loss: (0.3457) | Acc: (89.00%) (115/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.3596) | Acc: (88.00%) (1245/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.3899) | Acc: (86.00%) (2335/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.3924) | Acc: (86.00%) (3449/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.3915) | Acc: (87.00%) (4570/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.3970) | Acc: (86.00%) (5663/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.3990) | Acc: (86.00%) (6765/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.3936) | Acc: (86.00%) (7887/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.3869) | Acc: (87.00%) (9032/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.3826) | Acc: (87.00%) (10157/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.3822) | Acc: (87.00%) (11276/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.3773) | Acc: (87.00%) (12409/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.3730) | Acc: (87.00%) (13553/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.3698) | Acc: (87.00%) (14703/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.3663) | Acc: (87.00%) (15832/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.3639) | Acc: (87.00%) (16978/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.3660) | Acc: (87.00%) (18079/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.3643) | Acc: (87.00%) (19206/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.3624) | Acc: (87.00%) (20336/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.3611) | Acc: (87.00%) (21477/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.3591) | Acc: (87.00%) (22618/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.3577) | Acc: (87.00%) (23757/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.3556) | Acc: (88.00%) (24903/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.3548) | Acc: (88.00%) (26039/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.3535) | Acc: (88.00%) (27170/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.3512) | Acc: (88.00%) (28322/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.3508) | Acc: (88.00%) (29449/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.3489) | Acc: (88.00%) (30604/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.3468) | Acc: (88.00%) (31765/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.3456) | Acc: (88.00%) (32909/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.3460) | Acc: (88.00%) (34025/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.3449) | Acc: (88.00%) (35181/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.3441) | Acc: (88.00%) (36328/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.3434) | Acc: (88.00%) (37477/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.3430) | Acc: (88.00%) (38600/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.3418) | Acc: (88.00%) (39748/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.3410) | Acc: (88.00%) (40901/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.3398) | Acc: (88.00%) (42056/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.3388) | Acc: (88.00%) (43206/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.3387) | Acc: (88.00%) (44302/50000)
# TEST : Loss: (0.3611) | Acc: (87.00%) (8771/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0698,  0.1550, -0.0668],
          [-0.0751,  0.0383, -0.0040],
          [ 0.0462, -0.1935,  0.1941]],

         [[-0.1040,  0.2402,  0.0647],
          [-0.0467,  0.0765, -0.1466],
          [ 0.0717, -0.2330, -0.0610]],

         [[-0.0582,  0.2297, -0.1409],
          [ 0.0857, -0.1592, -0.0417],
          [ 0.1114, -0.1688,  0.1970]]],


        [[[-0.1052, -0.2267, -0.1472],
          [-0.1414,  0.1770,  0.1448],
          [ 0.1271,  0.0272,  0.1715]],

         [[-0.1967, -0.1629, -0.1326],
          [-0.1459,  0.0910,  0.1831],
          [ 0.2058, -0.0437,  0.0411]],

         [[-0.1080,  0.1470, -0.1782],
          [ 0.0883,  0.2132, -0.1338],
          [ 0.0065,  0.0709,  0.0306]]],


        [[[-0.1161,  0.1856,  0.0765],
          [ 0.1139,  0.0738, -0.1067],
          [-0.1815,  0.0413, -0.1836]],

         [[ 0.0857,  0.0363,  0.0151],
          [ 0.0514,  0.1743,  0.0754],
          [-0.0315,  0.0020, -0.2810]],

         [[-0.0900,  0.0264,  0.1794],
          [ 0.0029,  0.1949,  0.0726],
          [-0.1857, -0.1533, -0.1997]]],


        ...,


        [[[-0.1472, -0.1067,  0.0214],
          [ 0.1599, -0.1528, -0.0441],
          [ 0.1404, -0.0539,  0.0896]],

         [[ 0.1805,  0.0402, -0.0044],
          [-0.0904, -0.3101, -0.2090],
          [ 0.0942,  0.0154, -0.1469]],

         [[ 0.2080, -0.0085,  0.0548],
          [-0.0395, -0.1489, -0.1628],
          [ 0.0507, -0.0881, -0.1046]]],


        [[[ 0.0928,  0.0730,  0.0223],
          [-0.0225, -0.0519,  0.0484],
          [-0.0034, -0.0882,  0.0244]],

         [[ 0.0392,  0.0935, -0.0963],
          [-0.0471, -0.0604, -0.0822],
          [-0.0292, -0.0898,  0.0023]],

         [[ 0.0275,  0.0975, -0.0536],
          [-0.0547,  0.0506,  0.0522],
          [ 0.0476,  0.0013, -0.0122]]],


        [[[ 0.0011, -0.0007,  0.0007],
          [-0.0017, -0.0007, -0.0048],
          [-0.0035, -0.0038, -0.0070]],

         [[ 0.0005,  0.0004,  0.0003],
          [-0.0000, -0.0010, -0.0004],
          [ 0.0009, -0.0000, -0.0007]],

         [[-0.0003, -0.0007, -0.0007],
          [-0.0013, -0.0019, -0.0021],
          [-0.0022, -0.0021, -0.0000]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4763]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0363]], device='cuda:0')

Epoch: 28 | Batch_idx: 0 |  Loss: (0.2693) | Acc: (89.00%) (114/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.3247) | Acc: (88.00%) (1248/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.3316) | Acc: (88.00%) (2383/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.3329) | Acc: (89.00%) (3533/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.3340) | Acc: (88.00%) (4664/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.3315) | Acc: (88.00%) (5804/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.3301) | Acc: (88.00%) (6943/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.3218) | Acc: (89.00%) (8102/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.3213) | Acc: (89.00%) (9245/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.3170) | Acc: (89.00%) (10399/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.3193) | Acc: (89.00%) (11520/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.3182) | Acc: (89.00%) (12664/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.3166) | Acc: (89.00%) (13813/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.3168) | Acc: (89.00%) (14964/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.3169) | Acc: (89.00%) (16106/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.3141) | Acc: (89.00%) (17270/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.3125) | Acc: (89.00%) (18421/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.3139) | Acc: (89.00%) (19549/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.3135) | Acc: (89.00%) (20703/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.3132) | Acc: (89.00%) (21849/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.3141) | Acc: (89.00%) (22985/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.3130) | Acc: (89.00%) (24141/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.3130) | Acc: (89.00%) (25289/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.3121) | Acc: (89.00%) (26452/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.3113) | Acc: (89.00%) (27616/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.3120) | Acc: (89.00%) (28755/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.3122) | Acc: (89.00%) (29906/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.3127) | Acc: (89.00%) (31043/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.3126) | Acc: (89.00%) (32192/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.3137) | Acc: (89.00%) (33318/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.3137) | Acc: (89.00%) (34464/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.3128) | Acc: (89.00%) (35615/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.3118) | Acc: (89.00%) (36783/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.3115) | Acc: (89.00%) (37933/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.3111) | Acc: (89.00%) (39092/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.3105) | Acc: (89.00%) (40247/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.3097) | Acc: (89.00%) (41407/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.3090) | Acc: (89.00%) (42584/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.3083) | Acc: (89.00%) (43742/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.3081) | Acc: (89.00%) (44846/50000)
# TEST : Loss: (0.3502) | Acc: (87.00%) (8794/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0697,  0.1547, -0.0667],
          [-0.0750,  0.0382, -0.0040],
          [ 0.0461, -0.1932,  0.1938]],

         [[-0.1038,  0.2398,  0.0646],
          [-0.0467,  0.0763, -0.1463],
          [ 0.0716, -0.2326, -0.0610]],

         [[-0.0581,  0.2293, -0.1407],
          [ 0.0856, -0.1589, -0.0416],
          [ 0.1112, -0.1686,  0.1967]]],


        [[[-0.1049, -0.2262, -0.1468],
          [-0.1411,  0.1766,  0.1444],
          [ 0.1268,  0.0271,  0.1711]],

         [[-0.1962, -0.1625, -0.1322],
          [-0.1455,  0.0907,  0.1827],
          [ 0.2053, -0.0436,  0.0410]],

         [[-0.1077,  0.1466, -0.1777],
          [ 0.0880,  0.2126, -0.1335],
          [ 0.0065,  0.0707,  0.0305]]],


        [[[-0.1159,  0.1852,  0.0764],
          [ 0.1137,  0.0737, -0.1065],
          [-0.1812,  0.0413, -0.1833]],

         [[ 0.0855,  0.0363,  0.0151],
          [ 0.0513,  0.1740,  0.0753],
          [-0.0314,  0.0020, -0.2805]],

         [[-0.0898,  0.0263,  0.1790],
          [ 0.0029,  0.1945,  0.0724],
          [-0.1853, -0.1530, -0.1993]]],


        ...,


        [[[-0.1463, -0.1058,  0.0212],
          [ 0.1588, -0.1512, -0.0436],
          [ 0.1395, -0.0534,  0.0889]],

         [[ 0.1793,  0.0399, -0.0044],
          [-0.0896, -0.3051, -0.2051],
          [ 0.0936,  0.0152, -0.1452]],

         [[ 0.2066, -0.0085,  0.0544],
          [-0.0391, -0.1472, -0.1608],
          [ 0.0503, -0.0873, -0.1035]]],


        [[[ 0.0846,  0.0663,  0.0202],
          [-0.0202, -0.0461,  0.0431],
          [-0.0030, -0.0769,  0.0214]],

         [[ 0.0356,  0.0844, -0.0865],
          [-0.0419, -0.0531, -0.0723],
          [-0.0255, -0.0773,  0.0020]],

         [[ 0.0249,  0.0878, -0.0481],
          [-0.0487,  0.0447,  0.0462],
          [ 0.0419,  0.0011, -0.0107]]],


        [[[ 0.0005, -0.0003,  0.0003],
          [-0.0007, -0.0003, -0.0021],
          [-0.0016, -0.0018, -0.0034]],

         [[ 0.0001,  0.0001,  0.0001],
          [-0.0000, -0.0003, -0.0002],
          [ 0.0004, -0.0000, -0.0003]],

         [[-0.0001, -0.0002, -0.0002],
          [-0.0004, -0.0006, -0.0008],
          [-0.0010, -0.0009, -0.0000]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5073]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0387]], device='cuda:0')

Epoch: 29 | Batch_idx: 0 |  Loss: (0.3403) | Acc: (89.00%) (115/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.2901) | Acc: (90.00%) (1271/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.2813) | Acc: (90.00%) (2439/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.2823) | Acc: (90.00%) (3593/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.2824) | Acc: (90.00%) (4763/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.2963) | Acc: (90.00%) (5889/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.2982) | Acc: (90.00%) (7035/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.2995) | Acc: (90.00%) (8180/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.3023) | Acc: (89.00%) (9330/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.3014) | Acc: (90.00%) (10485/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.3006) | Acc: (90.00%) (11642/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.3011) | Acc: (90.00%) (12791/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.3019) | Acc: (89.00%) (13933/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.3022) | Acc: (89.00%) (15087/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.3060) | Acc: (89.00%) (16217/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.3081) | Acc: (89.00%) (17343/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.3088) | Acc: (89.00%) (18492/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.3092) | Acc: (89.00%) (19646/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.3082) | Acc: (89.00%) (20814/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.3084) | Acc: (89.00%) (21957/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.3076) | Acc: (89.00%) (23116/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.3065) | Acc: (89.00%) (24282/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.3054) | Acc: (89.00%) (25430/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.3050) | Acc: (89.00%) (26588/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.3050) | Acc: (89.00%) (27744/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.3057) | Acc: (89.00%) (28883/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.3060) | Acc: (89.00%) (30026/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.3054) | Acc: (89.00%) (31188/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.3052) | Acc: (89.00%) (32324/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.3058) | Acc: (89.00%) (33473/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.3044) | Acc: (89.00%) (34642/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.3039) | Acc: (89.00%) (35802/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.3052) | Acc: (89.00%) (36949/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.3048) | Acc: (89.00%) (38099/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.3051) | Acc: (89.00%) (39252/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.3045) | Acc: (89.00%) (40408/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.3044) | Acc: (89.00%) (41566/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.3043) | Acc: (89.00%) (42722/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.3034) | Acc: (90.00%) (43900/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.3033) | Acc: (90.00%) (45007/50000)
# TEST : Loss: (0.3461) | Acc: (88.00%) (8811/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0696,  0.1544, -0.0665],
          [-0.0749,  0.0382, -0.0040],
          [ 0.0460, -0.1929,  0.1935]],

         [[-0.1036,  0.2393,  0.0645],
          [-0.0466,  0.0762, -0.1461],
          [ 0.0715, -0.2321, -0.0608]],

         [[-0.0580,  0.2289, -0.1404],
          [ 0.0854, -0.1586, -0.0415],
          [ 0.1110, -0.1682,  0.1963]]],


        [[[-0.1046, -0.2255, -0.1464],
          [-0.1407,  0.1761,  0.1440],
          [ 0.1264,  0.0271,  0.1706]],

         [[-0.1956, -0.1620, -0.1318],
          [-0.1450,  0.0904,  0.1821],
          [ 0.2046, -0.0435,  0.0409]],

         [[-0.1073,  0.1461, -0.1772],
          [ 0.0878,  0.2119, -0.1330],
          [ 0.0065,  0.0704,  0.0304]]],


        [[[-0.1157,  0.1848,  0.0762],
          [ 0.1135,  0.0736, -0.1063],
          [-0.1808,  0.0412, -0.1829]],

         [[ 0.0853,  0.0362,  0.0151],
          [ 0.0512,  0.1736,  0.0751],
          [-0.0314,  0.0020, -0.2799]],

         [[-0.0896,  0.0262,  0.1786],
          [ 0.0029,  0.1941,  0.0723],
          [-0.1849, -0.1526, -0.1989]]],


        ...,


        [[[-0.1452, -0.1049,  0.0210],
          [ 0.1574, -0.1493, -0.0430],
          [ 0.1384, -0.0529,  0.0879]],

         [[ 0.1779,  0.0395, -0.0043],
          [-0.0887, -0.2991, -0.2005],
          [ 0.0928,  0.0150, -0.1432]],

         [[ 0.2050, -0.0084,  0.0538],
          [-0.0388, -0.1452, -0.1584],
          [ 0.0499, -0.0862, -0.1022]]],


        [[[ 0.0755,  0.0590,  0.0178],
          [-0.0176, -0.0399,  0.0374],
          [-0.0026, -0.0652,  0.0183]],

         [[ 0.0317,  0.0746, -0.0759],
          [-0.0362, -0.0453, -0.0620],
          [-0.0217, -0.0643,  0.0017]],

         [[ 0.0220,  0.0774, -0.0421],
          [-0.0422,  0.0385,  0.0398],
          [ 0.0359,  0.0010, -0.0091]]],


        [[[ 0.0002, -0.0001,  0.0001],
          [-0.0002, -0.0001, -0.0008],
          [-0.0006, -0.0007, -0.0015]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0001, -0.0001],
          [ 0.0002, -0.0000, -0.0001]],

         [[-0.0000, -0.0000, -0.0001],
          [-0.0001, -0.0002, -0.0003],
          [-0.0003, -0.0004, -0.0000]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5191]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0176]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 30 | Batch_idx: 0 |  Loss: (0.2922) | Acc: (90.00%) (116/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.3063) | Acc: (89.00%) (1260/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.3530) | Acc: (87.00%) (2359/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.3923) | Acc: (86.00%) (3436/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.4201) | Acc: (85.00%) (4493/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.4374) | Acc: (84.00%) (5548/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.4412) | Acc: (84.00%) (6628/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.4431) | Acc: (84.00%) (7695/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.4467) | Acc: (84.00%) (8773/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.4528) | Acc: (84.00%) (9837/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.4485) | Acc: (84.00%) (10940/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.4471) | Acc: (84.00%) (12022/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.4503) | Acc: (84.00%) (13083/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.4493) | Acc: (84.00%) (14171/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.4479) | Acc: (84.00%) (15269/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.4470) | Acc: (84.00%) (16352/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.4457) | Acc: (84.00%) (17437/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.4455) | Acc: (84.00%) (18516/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.4435) | Acc: (84.00%) (19613/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.4427) | Acc: (84.00%) (20700/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.4407) | Acc: (84.00%) (21820/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.4422) | Acc: (84.00%) (22884/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.4413) | Acc: (84.00%) (23965/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.4393) | Acc: (84.00%) (25069/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.4401) | Acc: (84.00%) (26154/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.4387) | Acc: (84.00%) (27247/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.4368) | Acc: (84.00%) (28348/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.4364) | Acc: (84.00%) (29446/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.4347) | Acc: (84.00%) (30561/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.4341) | Acc: (85.00%) (31670/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.4340) | Acc: (85.00%) (32764/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.4315) | Acc: (85.00%) (33901/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.4284) | Acc: (85.00%) (35034/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.4267) | Acc: (85.00%) (36156/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.4272) | Acc: (85.00%) (37248/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.4259) | Acc: (85.00%) (38368/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.4253) | Acc: (85.00%) (39470/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.4255) | Acc: (85.00%) (40567/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.4250) | Acc: (85.00%) (41669/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.4243) | Acc: (85.00%) (42746/50000)
# TEST : Loss: (0.4750) | Acc: (84.00%) (8485/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-7.7032e-02,  1.6308e-01, -6.7512e-02],
          [-7.8428e-02,  4.5120e-02, -4.3206e-03],
          [ 4.1903e-02, -1.9976e-01,  2.0589e-01]],

         [[-1.1387e-01,  2.4963e-01,  7.6272e-02],
          [-4.5062e-02,  8.0599e-02, -1.4034e-01],
          [ 7.2012e-02, -2.3693e-01, -4.5258e-02]],

         [[-7.6789e-02,  2.2386e-01, -1.3737e-01],
          [ 8.3419e-02, -1.5710e-01, -5.0597e-02],
          [ 1.0955e-01, -1.7022e-01,  1.9564e-01]]],


        [[[-1.1540e-01, -2.3390e-01, -1.5075e-01],
          [-1.4618e-01,  1.7965e-01,  1.4446e-01],
          [ 1.2699e-01,  3.2318e-02,  1.7248e-01]],

         [[-2.0165e-01, -1.6703e-01, -1.3687e-01],
          [-1.5014e-01,  9.6293e-02,  1.8558e-01],
          [ 2.0371e-01, -3.8497e-02,  4.6265e-02]],

         [[-1.2429e-01,  1.3119e-01, -1.8781e-01],
          [ 7.5483e-02,  2.1097e-01, -1.3018e-01],
          [-8.7632e-03,  6.4687e-02,  2.9491e-02]]],


        [[[-1.1706e-01,  1.9138e-01,  7.8108e-02],
          [ 1.2185e-01,  8.4489e-02, -1.0632e-01],
          [-1.7442e-01,  4.4866e-02, -1.8511e-01]],

         [[ 8.4712e-02,  4.5061e-02,  1.7642e-02],
          [ 5.8869e-02,  1.8589e-01,  7.6013e-02],
          [-3.2286e-02,  3.4937e-03, -2.8127e-01]],

         [[-9.0096e-02,  3.6174e-02,  1.7942e-01],
          [ 7.8494e-03,  2.0415e-01,  7.1307e-02],
          [-1.8703e-01, -1.5184e-01, -2.0378e-01]]],


        ...,


        [[[-1.6244e-01, -1.1989e-01,  2.1995e-02],
          [ 1.3341e-01, -1.8121e-01, -4.9952e-02],
          [ 1.2021e-01, -7.6791e-02,  8.3781e-02]],

         [[ 1.6755e-01,  2.5664e-02, -5.8398e-03],
          [-1.0113e-01, -3.3092e-01, -2.1180e-01],
          [ 9.1652e-02,  8.3053e-03, -1.3296e-01]],

         [[ 1.9592e-01, -1.1404e-02,  5.7886e-02],
          [-5.1684e-02, -1.6182e-01, -1.6275e-01],
          [ 4.3922e-02, -9.6529e-02, -9.9890e-02]]],


        [[[ 6.5648e-02,  5.0915e-02,  1.5075e-02],
          [-1.5141e-02, -3.3626e-02,  3.1217e-02],
          [-2.4030e-03, -5.3476e-02,  1.4720e-02]],

         [[ 2.7288e-02,  6.4045e-02, -6.4996e-02],
          [-3.0586e-02, -3.7490e-02, -5.1586e-02],
          [-1.8039e-02, -5.1769e-02,  9.5463e-04]],

         [[ 1.8880e-02,  6.6251e-02, -3.6035e-02],
          [-3.5605e-02,  3.2021e-02,  3.3030e-02],
          [ 2.9535e-02,  6.0671e-04, -7.7610e-03]]],


        [[[ 3.9423e-05, -2.2547e-05,  2.1763e-05],
          [-6.5233e-05, -2.3281e-05, -2.2188e-04],
          [-2.0547e-04, -2.3143e-04, -5.1262e-04]],

         [[ 6.0551e-06,  4.1533e-06,  4.4203e-06],
          [-6.5636e-07, -1.9521e-05, -1.5262e-05],
          [ 4.4628e-05, -3.5473e-07, -4.7592e-05]],

         [[-1.9368e-06, -4.4920e-06, -1.0178e-05],
          [-1.9474e-05, -3.4800e-05, -7.3257e-05],
          [-9.7125e-05, -1.0693e-04, -1.5910e-06]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0498,  0.0850,  0.1113],
          [ 0.0320,  0.0786,  0.1229],
          [ 0.0487,  0.0791,  0.1190]],

         [[ 0.0385,  0.0750,  0.0987],
          [ 0.0221,  0.0830,  0.1214],
          [ 0.0425,  0.0851,  0.1203]],

         [[ 0.0018,  0.0323,  0.0516],
          [-0.0138,  0.0291,  0.0669],
          [ 0.0090,  0.0357,  0.0647]]],


        [[[-0.0080, -0.0317, -0.0596],
          [ 0.0148, -0.0127, -0.0442],
          [-0.0120, -0.0358, -0.0665]],

         [[-0.0226, -0.0421, -0.0674],
          [-0.0050, -0.0298, -0.0571],
          [-0.0310, -0.0527, -0.0823]],

         [[-0.0133, -0.0326, -0.0588],
          [ 0.0074, -0.0142, -0.0404],
          [-0.0114, -0.0302, -0.0582]]],


        [[[ 0.0352,  0.0327,  0.0402],
          [ 0.0430,  0.0376,  0.0346],
          [ 0.0198,  0.0197,  0.0341]],

         [[-0.0116, -0.0148, -0.0054],
          [ 0.0066,  0.0040,  0.0052],
          [-0.0064,  0.0010,  0.0142]],

         [[-0.0052, -0.0034,  0.0086],
          [ 0.0086,  0.0123,  0.0149],
          [-0.0075,  0.0032,  0.0180]]],


        ...,


        [[[-0.0034, -0.0013,  0.0020],
          [-0.0154, -0.0096, -0.0052],
          [-0.0177, -0.0119, -0.0071]],

         [[ 0.0019,  0.0053,  0.0070],
          [-0.0111, -0.0040, -0.0004],
          [-0.0187, -0.0116, -0.0072]],

         [[ 0.0094,  0.0130,  0.0136],
          [-0.0005,  0.0065,  0.0097],
          [-0.0081, -0.0001,  0.0056]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5187]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 31 | Batch_idx: 0 |  Loss: (0.3643) | Acc: (91.00%) (117/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.3345) | Acc: (88.00%) (1252/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.3243) | Acc: (89.00%) (2395/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.3429) | Acc: (88.00%) (3496/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.3429) | Acc: (88.00%) (4634/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.3382) | Acc: (88.00%) (5773/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.3418) | Acc: (88.00%) (6887/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.3405) | Acc: (88.00%) (8019/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.3374) | Acc: (88.00%) (9148/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.3386) | Acc: (88.00%) (10276/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.3450) | Acc: (88.00%) (11382/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.3464) | Acc: (88.00%) (12513/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.3468) | Acc: (88.00%) (13651/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.3496) | Acc: (88.00%) (14763/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.3487) | Acc: (88.00%) (15897/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.3462) | Acc: (88.00%) (17040/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.3445) | Acc: (88.00%) (18179/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.3438) | Acc: (88.00%) (19305/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.3436) | Acc: (88.00%) (20432/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.3437) | Acc: (88.00%) (21563/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.3455) | Acc: (88.00%) (22683/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.3454) | Acc: (88.00%) (23821/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.3440) | Acc: (88.00%) (24966/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.3432) | Acc: (88.00%) (26107/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.3418) | Acc: (88.00%) (27259/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.3422) | Acc: (88.00%) (28378/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.3424) | Acc: (88.00%) (29490/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.3425) | Acc: (88.00%) (30625/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.3423) | Acc: (88.00%) (31763/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.3429) | Acc: (88.00%) (32899/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.3436) | Acc: (88.00%) (34012/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.3437) | Acc: (88.00%) (35135/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.3440) | Acc: (88.00%) (36261/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.3450) | Acc: (88.00%) (37369/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.3447) | Acc: (88.00%) (38497/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.3442) | Acc: (88.00%) (39626/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.3448) | Acc: (88.00%) (40741/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.3449) | Acc: (88.00%) (41874/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.3445) | Acc: (88.00%) (43002/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.3444) | Acc: (88.00%) (44084/50000)
# TEST : Loss: (0.4163) | Acc: (86.00%) (8663/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-8.9895e-02,  1.6408e-01, -7.1726e-02],
          [-8.4914e-02,  4.1912e-02, -1.9998e-03],
          [ 3.7560e-02, -2.0486e-01,  2.0862e-01]],

         [[-1.1467e-01,  2.6129e-01,  8.3057e-02],
          [-4.0134e-02,  7.7367e-02, -1.3468e-01],
          [ 8.0225e-02, -2.4134e-01, -3.9816e-02]],

         [[-8.3156e-02,  2.2416e-01, -1.3523e-01],
          [ 8.5594e-02, -1.5793e-01, -4.6871e-02],
          [ 1.2213e-01, -1.6322e-01,  2.0295e-01]]],


        [[[-1.2664e-01, -2.4544e-01, -1.5887e-01],
          [-1.5040e-01,  1.7561e-01,  1.3946e-01],
          [ 1.1938e-01,  2.7243e-02,  1.7071e-01]],

         [[-2.1048e-01, -1.7383e-01, -1.3899e-01],
          [-1.5030e-01,  9.8538e-02,  1.8788e-01],
          [ 1.9572e-01, -4.2552e-02,  4.8281e-02]],

         [[-1.2272e-01,  1.3634e-01, -1.7999e-01],
          [ 8.1886e-02,  2.1886e-01, -1.2183e-01],
          [-1.1530e-02,  6.5479e-02,  3.6810e-02]]],


        [[[-1.1585e-01,  1.9470e-01,  8.2174e-02],
          [ 1.2485e-01,  8.9070e-02, -1.0207e-01],
          [-1.7471e-01,  4.0371e-02, -1.8613e-01]],

         [[ 8.6019e-02,  4.9147e-02,  1.9199e-02],
          [ 6.2213e-02,  1.8933e-01,  7.5899e-02],
          [-3.3903e-02, -4.1792e-03, -2.8578e-01]],

         [[-7.9594e-02,  4.5306e-02,  1.8442e-01],
          [ 1.4472e-02,  2.0847e-01,  7.5098e-02],
          [-1.8553e-01, -1.5621e-01, -2.0348e-01]]],


        ...,


        [[[-1.5802e-01, -1.2393e-01,  1.2142e-02],
          [ 1.3701e-01, -1.8236e-01, -6.5225e-02],
          [ 1.1921e-01, -7.3849e-02,  7.5254e-02]],

         [[ 1.7250e-01,  2.4406e-02, -1.1016e-02],
          [-9.3674e-02, -3.2467e-01, -2.2701e-01],
          [ 8.8607e-02,  9.0957e-03, -1.4321e-01]],

         [[ 1.9099e-01, -2.0093e-02,  4.8148e-02],
          [-5.2890e-02, -1.6521e-01, -1.7362e-01],
          [ 3.5064e-02, -1.0347e-01, -1.1270e-01]]],


        [[[ 5.5555e-02,  4.2787e-02,  1.2573e-02],
          [-1.2402e-02, -2.7175e-02,  2.5328e-02],
          [-1.9178e-03, -4.1825e-02,  1.1633e-02]],

         [[ 2.2927e-02,  5.3321e-02, -5.3583e-02],
          [-2.4708e-02, -2.9697e-02, -4.1030e-02],
          [-1.4156e-02, -3.9475e-02,  7.3713e-04]],

         [[ 1.5754e-02,  5.4922e-02, -2.9641e-02],
          [-2.8846e-02,  2.5628e-02,  2.6516e-02],
          [ 2.3474e-02,  4.7391e-04, -6.1043e-03]]],


        [[[ 7.5747e-06, -4.0585e-06,  4.0376e-06],
          [-1.2963e-05, -4.4768e-06, -4.8674e-05],
          [-5.1043e-05, -5.8182e-05, -1.4229e-04]],

         [[ 6.9528e-07,  4.3462e-07,  5.7787e-07],
          [-9.2929e-08, -2.8430e-06, -2.9458e-06],
          [ 9.9595e-06, -8.3132e-08, -1.2846e-05]],

         [[-1.5521e-07, -3.6821e-07, -1.2214e-06],
          [-2.4249e-06, -4.8573e-06, -1.4087e-05],
          [-2.0888e-05, -2.4640e-05, -4.2506e-07]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0168,  0.0213,  0.0052],
          [ 0.0633,  0.0452,  0.0548],
          [ 0.0613,  0.0322,  0.0466]],

         [[ 0.0298,  0.0324,  0.0194],
          [ 0.0753,  0.0668,  0.0629],
          [ 0.0726,  0.0544,  0.0613]],

         [[ 0.0117,  0.0235,  0.0206],
          [ 0.0509,  0.0516,  0.0563],
          [ 0.0595,  0.0432,  0.0520]]],


        [[[-0.0006,  0.0179,  0.0095],
          [ 0.0018,  0.0112,  0.0114],
          [-0.0002,  0.0109,  0.0189]],

         [[ 0.0005,  0.0165,  0.0093],
          [ 0.0000,  0.0112,  0.0135],
          [-0.0086,  0.0053,  0.0152]],

         [[-0.0050,  0.0113,  0.0094],
          [-0.0038,  0.0056,  0.0103],
          [-0.0083,  0.0024,  0.0116]]],


        [[[-0.0086,  0.0123,  0.0323],
          [-0.0141, -0.0036,  0.0083],
          [-0.0157, -0.0081,  0.0048]],

         [[ 0.0194,  0.0385,  0.0566],
          [ 0.0216,  0.0326,  0.0463],
          [ 0.0251,  0.0381,  0.0556]],

         [[ 0.0400,  0.0552,  0.0741],
          [ 0.0463,  0.0522,  0.0658],
          [ 0.0527,  0.0569,  0.0700]]],


        ...,


        [[[-0.0062, -0.0048, -0.0120],
          [-0.0006,  0.0046,  0.0016],
          [-0.0145, -0.0083, -0.0085]],

         [[-0.0211, -0.0172, -0.0234],
          [-0.0135, -0.0064, -0.0085],
          [-0.0227, -0.0148, -0.0149]],

         [[-0.0167, -0.0133, -0.0177],
          [-0.0095, -0.0035, -0.0045],
          [-0.0184, -0.0118, -0.0108]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5174]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 32 | Batch_idx: 0 |  Loss: (0.3288) | Acc: (92.00%) (118/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.3288) | Acc: (88.00%) (1252/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.3146) | Acc: (89.00%) (2393/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.2933) | Acc: (89.00%) (3565/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.2920) | Acc: (89.00%) (4721/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.2948) | Acc: (89.00%) (5869/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.2916) | Acc: (90.00%) (7030/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.2952) | Acc: (89.00%) (8177/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.2997) | Acc: (89.00%) (9322/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.2999) | Acc: (89.00%) (10463/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.3022) | Acc: (89.00%) (11596/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.3024) | Acc: (89.00%) (12742/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.3050) | Acc: (89.00%) (13877/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.3048) | Acc: (89.00%) (15026/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.3056) | Acc: (89.00%) (16169/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.3059) | Acc: (89.00%) (17320/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.3035) | Acc: (89.00%) (18482/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.3027) | Acc: (89.00%) (19646/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.3045) | Acc: (89.00%) (20780/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.3047) | Acc: (89.00%) (21921/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.3067) | Acc: (89.00%) (23057/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.3079) | Acc: (89.00%) (24197/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.3075) | Acc: (89.00%) (25352/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.3076) | Acc: (89.00%) (26500/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.3070) | Acc: (89.00%) (27654/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.3088) | Acc: (89.00%) (28792/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.3077) | Acc: (89.00%) (29946/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.3086) | Acc: (89.00%) (31079/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.3095) | Acc: (89.00%) (32216/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.3082) | Acc: (89.00%) (33373/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.3079) | Acc: (89.00%) (34527/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.3074) | Acc: (89.00%) (35681/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.3073) | Acc: (89.00%) (36823/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.3082) | Acc: (89.00%) (37956/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.3092) | Acc: (89.00%) (39075/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.3099) | Acc: (89.00%) (40211/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.3104) | Acc: (89.00%) (41341/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.3112) | Acc: (89.00%) (42478/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.3105) | Acc: (89.00%) (43626/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.3097) | Acc: (89.00%) (44736/50000)
# TEST : Loss: (0.3728) | Acc: (87.00%) (8745/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-9.1533e-02,  1.7568e-01, -6.4221e-02],
          [-7.7803e-02,  5.2464e-02,  9.2323e-04],
          [ 4.6804e-02, -1.9237e-01,  2.1895e-01]],

         [[-1.1933e-01,  2.6716e-01,  8.6501e-02],
          [-3.5634e-02,  7.6892e-02, -1.3779e-01],
          [ 8.8148e-02, -2.4097e-01, -3.8152e-02]],

         [[-9.4070e-02,  2.2195e-01, -1.3777e-01],
          [ 8.2630e-02, -1.6046e-01, -5.4201e-02],
          [ 1.2182e-01, -1.6420e-01,  2.0050e-01]]],


        [[[-1.1696e-01, -2.4329e-01, -1.5391e-01],
          [-1.4102e-01,  1.8256e-01,  1.4542e-01],
          [ 1.3681e-01,  4.3835e-02,  1.8376e-01]],

         [[-2.0949e-01, -1.7761e-01, -1.4166e-01],
          [-1.5001e-01,  9.9227e-02,  1.8812e-01],
          [ 2.0756e-01, -3.0809e-02,  5.7355e-02]],

         [[-1.2292e-01,  1.2956e-01, -1.8638e-01],
          [ 7.8109e-02,  2.1387e-01, -1.2520e-01],
          [-8.0205e-03,  6.7719e-02,  3.9773e-02]]],


        [[[-1.1688e-01,  1.8991e-01,  7.8888e-02],
          [ 1.2472e-01,  8.6608e-02, -1.0413e-01],
          [-1.7932e-01,  3.4404e-02, -1.9155e-01]],

         [[ 8.3923e-02,  4.5657e-02,  1.7228e-02],
          [ 6.0081e-02,  1.8696e-01,  7.3870e-02],
          [-4.1504e-02, -1.1671e-02, -2.9295e-01]],

         [[-8.1466e-02,  4.2837e-02,  1.8286e-01],
          [ 1.4000e-02,  2.0771e-01,  7.3829e-02],
          [-1.9227e-01, -1.6218e-01, -2.1117e-01]]],


        ...,


        [[[-1.6156e-01, -1.2697e-01,  1.6601e-02],
          [ 1.3273e-01, -1.8739e-01, -6.4697e-02],
          [ 1.2219e-01, -6.9781e-02,  7.9073e-02]],

         [[ 1.6282e-01,  1.3854e-02, -1.0587e-02],
          [-1.0158e-01, -3.4311e-01, -2.4007e-01],
          [ 8.8144e-02,  6.4636e-03, -1.4618e-01]],

         [[ 1.9863e-01, -5.4456e-03,  7.2907e-02],
          [-4.3165e-02, -1.5174e-01, -1.5352e-01],
          [ 4.5334e-02, -9.0414e-02, -9.9729e-02]]],


        [[[ 4.5341e-02,  3.4626e-02,  1.0081e-02],
          [-9.7261e-03, -2.0967e-02,  1.9638e-02],
          [-1.4573e-03, -3.1010e-02,  8.7356e-03]],

         [[ 1.8549e-02,  4.2662e-02, -4.2361e-02],
          [-1.9053e-02, -2.2360e-02, -3.1049e-02],
          [-1.0538e-02, -2.8376e-02,  5.3846e-04]],

         [[ 1.2639e-02,  4.3714e-02, -2.3367e-02],
          [-2.2323e-02,  1.9544e-02,  2.0296e-02],
          [ 1.7748e-02,  3.5116e-04, -4.5561e-03]]],


        [[[ 9.9989e-07, -4.9406e-07,  5.1030e-07],
          [-1.7842e-06, -5.9155e-07, -7.5723e-06],
          [-9.2610e-06, -1.0713e-05, -2.9609e-05]],

         [[ 4.8351e-08,  2.6911e-08,  4.7252e-08],
          [-8.3927e-09, -2.6595e-07, -3.9104e-07],
          [ 1.5826e-06, -1.4035e-08, -2.5823e-06]],

         [[-6.8771e-09, -1.6785e-08, -8.9741e-08],
          [-1.8659e-07, -4.3095e-07, -1.8614e-06],
          [-3.1707e-06, -4.0736e-06, -8.4376e-08]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0099, -0.0051, -0.0064],
          [-0.0011, -0.0200, -0.0302],
          [ 0.0068, -0.0122, -0.0335]],

         [[ 0.0137, -0.0050, -0.0041],
          [ 0.0021, -0.0194, -0.0319],
          [ 0.0110, -0.0117, -0.0304]],

         [[-0.0044, -0.0245, -0.0176],
          [-0.0066, -0.0337, -0.0404],
          [ 0.0160, -0.0106, -0.0278]]],


        [[[-0.0634, -0.0696, -0.0719],
          [-0.0674, -0.0718, -0.0738],
          [-0.0652, -0.0728, -0.0707]],

         [[-0.0701, -0.0756, -0.0758],
          [-0.0718, -0.0759, -0.0775],
          [-0.0699, -0.0775, -0.0750]],

         [[-0.0722, -0.0761, -0.0772],
          [-0.0760, -0.0790, -0.0811],
          [-0.0774, -0.0845, -0.0824]]],


        [[[ 0.0454,  0.0603,  0.0573],
          [ 0.0389,  0.0560,  0.0650],
          [ 0.0360,  0.0525,  0.0686]],

         [[ 0.0539,  0.0671,  0.0631],
          [ 0.0467,  0.0621,  0.0691],
          [ 0.0404,  0.0547,  0.0693]],

         [[ 0.0619,  0.0712,  0.0634],
          [ 0.0529,  0.0654,  0.0693],
          [ 0.0427,  0.0544,  0.0667]]],


        ...,


        [[[ 0.0016,  0.0025,  0.0016],
          [ 0.0024,  0.0011,  0.0001],
          [ 0.0017,  0.0011,  0.0001]],

         [[ 0.0019,  0.0030,  0.0012],
          [ 0.0021,  0.0012, -0.0004],
          [ 0.0001,  0.0002, -0.0016]],

         [[ 0.0053,  0.0057,  0.0038],
          [ 0.0050,  0.0034,  0.0017],
          [ 0.0030,  0.0020, -0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5159]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 33 | Batch_idx: 0 |  Loss: (0.2210) | Acc: (90.00%) (116/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.2983) | Acc: (90.00%) (1278/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.3383) | Acc: (89.00%) (2393/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.3391) | Acc: (88.00%) (3520/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.3427) | Acc: (88.00%) (4648/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.3406) | Acc: (88.00%) (5777/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.3386) | Acc: (88.00%) (6922/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.3375) | Acc: (88.00%) (8048/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.3359) | Acc: (88.00%) (9193/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.3315) | Acc: (88.00%) (10351/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.3299) | Acc: (88.00%) (11489/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.3280) | Acc: (88.00%) (12634/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.3227) | Acc: (89.00%) (13799/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.3214) | Acc: (89.00%) (14954/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.3226) | Acc: (89.00%) (16087/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.3208) | Acc: (89.00%) (17232/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.3190) | Acc: (89.00%) (18388/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.3185) | Acc: (89.00%) (19541/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.3165) | Acc: (89.00%) (20701/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.3137) | Acc: (89.00%) (21876/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.3121) | Acc: (89.00%) (23035/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.3114) | Acc: (89.00%) (24197/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.3097) | Acc: (89.00%) (25361/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.3098) | Acc: (89.00%) (26515/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.3082) | Acc: (89.00%) (27697/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.3064) | Acc: (89.00%) (28871/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.3060) | Acc: (89.00%) (30016/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.3039) | Acc: (89.00%) (31202/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.3032) | Acc: (89.00%) (32351/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.3020) | Acc: (89.00%) (33515/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.3013) | Acc: (89.00%) (34673/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.3011) | Acc: (90.00%) (35831/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.3001) | Acc: (90.00%) (36996/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.2989) | Acc: (90.00%) (38155/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.2987) | Acc: (90.00%) (39313/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.2977) | Acc: (90.00%) (40482/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.2974) | Acc: (90.00%) (41633/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.2964) | Acc: (90.00%) (42798/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.2952) | Acc: (90.00%) (43975/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.2950) | Acc: (90.00%) (45079/50000)
# TEST : Loss: (0.3330) | Acc: (88.00%) (8865/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-9.1695e-02,  1.7602e-01, -6.3994e-02],
          [-7.7245e-02,  5.3610e-02,  3.4040e-03],
          [ 4.8290e-02, -1.8935e-01,  2.2224e-01]],

         [[-1.2011e-01,  2.6671e-01,  8.5584e-02],
          [-3.5932e-02,  7.7278e-02, -1.3624e-01],
          [ 8.8339e-02, -2.3920e-01, -3.6391e-02]],

         [[-9.5613e-02,  2.2067e-01, -1.3939e-01],
          [ 8.0940e-02, -1.6096e-01, -5.4342e-02],
          [ 1.2070e-01, -1.6409e-01,  2.0019e-01]]],


        [[[-1.1493e-01, -2.4198e-01, -1.5291e-01],
          [-1.3875e-01,  1.8346e-01,  1.4582e-01],
          [ 1.3868e-01,  4.5140e-02,  1.8475e-01]],

         [[-2.0564e-01, -1.7489e-01, -1.3927e-01],
          [-1.4637e-01,  1.0160e-01,  1.8974e-01],
          [ 2.1057e-01, -2.7904e-02,  6.0006e-02]],

         [[-1.1825e-01,  1.3268e-01, -1.8323e-01],
          [ 8.2542e-02,  2.1729e-01, -1.2183e-01],
          [-3.3433e-03,  7.1821e-02,  4.3765e-02]]],


        [[[-1.1986e-01,  1.8639e-01,  7.6125e-02],
          [ 1.2185e-01,  8.3251e-02, -1.0683e-01],
          [-1.8132e-01,  3.1297e-02, -1.9425e-01]],

         [[ 7.9283e-02,  4.0915e-02,  1.2930e-02],
          [ 5.6078e-02,  1.8213e-01,  6.9311e-02],
          [-4.4742e-02, -1.5947e-02, -2.9717e-01]],

         [[-8.5707e-02,  3.8539e-02,  1.7867e-01],
          [ 9.9598e-03,  2.0296e-01,  6.9446e-02],
          [-1.9543e-01, -1.6616e-01, -2.1549e-01]]],


        ...,


        [[[-1.6097e-01, -1.2606e-01,  1.5801e-02],
          [ 1.3152e-01, -1.8530e-01, -6.4074e-02],
          [ 1.2252e-01, -6.7941e-02,  7.9655e-02]],

         [[ 1.6181e-01,  1.4323e-02, -1.0956e-02],
          [-1.0149e-01, -3.3774e-01, -2.3692e-01],
          [ 8.8485e-02,  7.3831e-03, -1.4437e-01]],

         [[ 1.9752e-01, -5.3057e-03,  7.1523e-02],
          [-4.2746e-02, -1.4969e-01, -1.5223e-01],
          [ 4.6490e-02, -8.8232e-02, -9.8065e-02]]],


        [[[ 3.5408e-02,  2.6761e-02,  7.7036e-03],
          [-7.2356e-03, -1.5290e-02,  1.4406e-02],
          [-1.0436e-03, -2.1542e-02,  6.1626e-03]],

         [[ 1.4331e-02,  3.2519e-02, -3.1823e-02],
          [-1.3885e-02, -1.5828e-02, -2.2113e-02],
          [-7.3558e-03, -1.8981e-02,  3.6734e-04]],

         [[ 9.6649e-03,  3.3110e-02, -1.7494e-02],
          [-1.6339e-02,  1.4050e-02,  1.4656e-02],
          [ 1.2625e-02,  2.4346e-04, -3.1908e-03]]],


        [[[ 8.2754e-08, -3.6960e-08,  4.0005e-08],
          [-1.5556e-07, -4.9019e-08, -7.6899e-07],
          [-1.1386e-06, -1.3415e-06, -4.3147e-06]],

         [[ 1.7922e-09,  8.6164e-10,  2.1474e-09],
          [-4.3209e-10, -1.4310e-08, -3.2591e-08],
          [ 1.6502e-07, -1.5778e-09, -3.6053e-07]],

         [[-1.4415e-10, -3.6474e-10, -3.5651e-09],
          [-7.8562e-09, -2.1698e-08, -1.5424e-07],
          [-3.1231e-07, -4.4620e-07, -1.1598e-08]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5209]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0230]], device='cuda:0')

Epoch: 34 | Batch_idx: 0 |  Loss: (0.1885) | Acc: (92.00%) (118/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.2346) | Acc: (91.00%) (1295/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.2472) | Acc: (91.00%) (2463/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.2507) | Acc: (91.00%) (3631/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.2568) | Acc: (91.00%) (4796/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.2527) | Acc: (91.00%) (5969/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.2492) | Acc: (91.00%) (7157/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.2543) | Acc: (91.00%) (8323/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.2603) | Acc: (91.00%) (9478/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.2601) | Acc: (91.00%) (10652/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.2600) | Acc: (91.00%) (11828/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.2596) | Acc: (91.00%) (13005/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.2602) | Acc: (91.00%) (14174/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.2604) | Acc: (91.00%) (15350/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.2611) | Acc: (91.00%) (16504/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.2590) | Acc: (91.00%) (17686/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.2587) | Acc: (91.00%) (18860/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.2602) | Acc: (91.00%) (20009/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.2609) | Acc: (91.00%) (21175/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.2603) | Acc: (91.00%) (22339/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.2602) | Acc: (91.00%) (23506/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.2618) | Acc: (91.00%) (24668/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.2635) | Acc: (91.00%) (25812/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.2629) | Acc: (91.00%) (26984/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.2637) | Acc: (91.00%) (28139/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.2630) | Acc: (91.00%) (29317/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.2635) | Acc: (91.00%) (30480/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.2636) | Acc: (91.00%) (31640/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.2635) | Acc: (91.00%) (32814/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.2640) | Acc: (91.00%) (33983/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.2635) | Acc: (91.00%) (35154/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.2642) | Acc: (91.00%) (36310/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.2642) | Acc: (91.00%) (37476/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.2639) | Acc: (91.00%) (38647/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.2648) | Acc: (91.00%) (39793/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.2654) | Acc: (91.00%) (40954/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.2660) | Acc: (91.00%) (42112/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.2667) | Acc: (91.00%) (43271/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.2664) | Acc: (91.00%) (44441/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.2670) | Acc: (91.00%) (45559/50000)
# TEST : Loss: (0.3279) | Acc: (88.00%) (8886/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-9.1550e-02,  1.7573e-01, -6.3890e-02],
          [-7.7123e-02,  5.3523e-02,  3.3986e-03],
          [ 4.8212e-02, -1.8903e-01,  2.2188e-01]],

         [[-1.1991e-01,  2.6625e-01,  8.5440e-02],
          [-3.5871e-02,  7.7145e-02, -1.3600e-01],
          [ 8.8185e-02, -2.3877e-01, -3.6328e-02]],

         [[-9.5446e-02,  2.2027e-01, -1.3914e-01],
          [ 8.0796e-02, -1.6067e-01, -5.4244e-02],
          [ 1.2048e-01, -1.6378e-01,  1.9983e-01]]],


        [[[-1.1466e-01, -2.4142e-01, -1.5256e-01],
          [-1.3844e-01,  1.8305e-01,  1.4549e-01],
          [ 1.3836e-01,  4.5034e-02,  1.8433e-01]],

         [[-2.0514e-01, -1.7447e-01, -1.3894e-01],
          [-1.4602e-01,  1.0137e-01,  1.8931e-01],
          [ 2.1007e-01, -2.7837e-02,  5.9863e-02]],

         [[-1.1796e-01,  1.3235e-01, -1.8279e-01],
          [ 8.2345e-02,  2.1677e-01, -1.2154e-01],
          [-3.3353e-03,  7.1646e-02,  4.3658e-02]]],


        [[[-1.1964e-01,  1.8604e-01,  7.5984e-02],
          [ 1.2163e-01,  8.3101e-02, -1.0664e-01],
          [-1.8100e-01,  3.1241e-02, -1.9390e-01]],

         [[ 7.9130e-02,  4.0834e-02,  1.2905e-02],
          [ 5.5973e-02,  1.8178e-01,  6.9179e-02],
          [-4.4658e-02, -1.5916e-02, -2.9661e-01]],

         [[-8.5533e-02,  3.8459e-02,  1.7831e-01],
          [ 9.9398e-03,  2.0254e-01,  6.9305e-02],
          [-1.9504e-01, -1.6582e-01, -2.1505e-01]]],


        ...,


        [[[-1.5995e-01, -1.2504e-01,  1.5673e-02],
          [ 1.3055e-01, -1.8328e-01, -6.3348e-02],
          [ 1.2175e-01, -6.7369e-02,  7.8966e-02]],

         [[ 1.6067e-01,  1.4183e-02, -1.0846e-02],
          [-1.0060e-01, -3.3158e-01, -2.3207e-01],
          [ 8.7853e-02,  7.3025e-03, -1.4274e-01]],

         [[ 1.9614e-01, -5.2580e-03,  7.0861e-02],
          [-4.2391e-02, -1.4783e-01, -1.5023e-01],
          [ 4.6150e-02, -8.7340e-02, -9.7025e-02]]],


        [[[ 2.6203e-02,  1.9554e-02,  5.5518e-03],
          [-5.0468e-03, -1.0408e-02,  9.8775e-03],
          [-6.9482e-04, -1.3820e-02,  4.0286e-03]],

         [[ 1.0468e-02,  2.3365e-02, -2.2462e-02],
          [-9.4448e-03, -1.0390e-02, -1.4625e-02],
          [-4.7472e-03, -1.1629e-02,  2.3050e-04]],

         [[ 6.9715e-03,  2.3606e-02, -1.2296e-02],
          [-1.1173e-02,  9.3986e-03,  9.8579e-03],
          [ 8.3383e-03,  1.5580e-04, -2.0674e-03]]],


        [[[ 3.8183e-09, -1.5019e-09,  1.7242e-09],
          [-7.6627e-09, -2.2653e-09, -4.5861e-08],
          [-8.6230e-08, -1.0395e-07, -4.0392e-07]],

         [[ 2.9938e-11,  1.1940e-11,  4.6482e-11],
          [-1.0956e-11, -3.8366e-10, -1.5170e-09],
          [ 1.0172e-08, -1.0686e-10, -3.1999e-08]],

         [[-1.1596e-12, -3.0740e-12, -6.5044e-11],
          [-1.5433e-10, -5.3485e-10, -7.1280e-09],
          [-1.7926e-08, -2.9252e-08, -1.0095e-09]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5008]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0448]], device='cuda:0')

Epoch: 35 | Batch_idx: 0 |  Loss: (0.2008) | Acc: (94.00%) (121/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.2760) | Acc: (90.00%) (1279/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.2709) | Acc: (90.00%) (2440/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.2646) | Acc: (91.00%) (3617/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.2644) | Acc: (91.00%) (4776/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.2746) | Acc: (90.00%) (5911/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.2742) | Acc: (90.00%) (7074/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.2707) | Acc: (90.00%) (8252/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.2727) | Acc: (90.00%) (9395/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.2691) | Acc: (90.00%) (10566/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.2696) | Acc: (90.00%) (11721/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.2715) | Acc: (90.00%) (12873/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.2678) | Acc: (90.00%) (14058/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.2686) | Acc: (90.00%) (15212/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.2688) | Acc: (90.00%) (16384/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.2686) | Acc: (90.00%) (17541/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.2681) | Acc: (90.00%) (18705/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.2702) | Acc: (90.00%) (19848/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.2716) | Acc: (90.00%) (21005/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.2716) | Acc: (90.00%) (22165/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.2704) | Acc: (90.00%) (23339/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.2701) | Acc: (90.00%) (24505/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.2707) | Acc: (90.00%) (25668/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.2720) | Acc: (90.00%) (26829/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.2712) | Acc: (90.00%) (28004/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.2723) | Acc: (90.00%) (29165/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.2715) | Acc: (90.00%) (30348/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.2714) | Acc: (90.00%) (31519/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.2714) | Acc: (90.00%) (32676/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.2714) | Acc: (90.00%) (33837/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.2715) | Acc: (90.00%) (35004/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.2709) | Acc: (90.00%) (36183/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.2705) | Acc: (90.00%) (37354/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.2704) | Acc: (90.00%) (38521/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.2697) | Acc: (90.00%) (39696/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.2695) | Acc: (90.00%) (40856/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.2689) | Acc: (90.00%) (42036/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.2681) | Acc: (91.00%) (43217/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.2684) | Acc: (90.00%) (44378/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.2688) | Acc: (90.00%) (45498/50000)
# TEST : Loss: (0.3269) | Acc: (88.00%) (8896/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-9.1375e-02,  1.7538e-01, -6.3765e-02],
          [-7.6975e-02,  5.3417e-02,  3.3919e-03],
          [ 4.8118e-02, -1.8864e-01,  2.2144e-01]],

         [[-1.1967e-01,  2.6569e-01,  8.5265e-02],
          [-3.5798e-02,  7.6983e-02, -1.3572e-01],
          [ 8.7997e-02, -2.3824e-01, -3.6252e-02]],

         [[-9.5244e-02,  2.1978e-01, -1.3884e-01],
          [ 8.0622e-02, -1.6032e-01, -5.4127e-02],
          [ 1.2021e-01, -1.6340e-01,  1.9939e-01]]],


        [[[-1.1434e-01, -2.4074e-01, -1.5213e-01],
          [-1.3806e-01,  1.8254e-01,  1.4509e-01],
          [ 1.3797e-01,  4.4907e-02,  1.8381e-01]],

         [[-2.0454e-01, -1.7396e-01, -1.3855e-01],
          [-1.4561e-01,  1.0108e-01,  1.8878e-01],
          [ 2.0946e-01, -2.7756e-02,  5.9691e-02]],

         [[-1.1761e-01,  1.3196e-01, -1.8225e-01],
          [ 8.2106e-02,  2.1614e-01, -1.2120e-01],
          [-3.3255e-03,  7.1435e-02,  4.3529e-02]]],


        [[[-1.1937e-01,  1.8562e-01,  7.5813e-02],
          [ 1.2137e-01,  8.2918e-02, -1.0640e-01],
          [-1.8061e-01,  3.1173e-02, -1.9347e-01]],

         [[ 7.8945e-02,  4.0737e-02,  1.2875e-02],
          [ 5.5845e-02,  1.8136e-01,  6.9020e-02],
          [-4.4558e-02, -1.5880e-02, -2.9592e-01]],

         [[-8.5321e-02,  3.8362e-02,  1.7786e-01],
          [ 9.9155e-03,  2.0204e-01,  6.9134e-02],
          [-1.9456e-01, -1.6540e-01, -2.1451e-01]]],


        ...,


        [[[-1.5871e-01, -1.2382e-01,  1.5518e-02],
          [ 1.2938e-01, -1.8085e-01, -6.2476e-02],
          [ 1.2081e-01, -6.6680e-02,  7.8137e-02]],

         [[ 1.5930e-01,  1.4015e-02, -1.0714e-02],
          [-9.9533e-02, -3.2424e-01, -2.2630e-01],
          [ 8.7091e-02,  7.2058e-03, -1.4077e-01]],

         [[ 1.9447e-01, -5.2006e-03,  7.0066e-02],
          [-4.1962e-02, -1.4561e-01, -1.4782e-01],
          [ 4.5740e-02, -8.6266e-02, -9.5775e-02]]],


        [[[ 1.8160e-02,  1.3344e-02,  3.7251e-03],
          [-3.2538e-03, -6.5140e-03,  6.2367e-03],
          [-4.2323e-04, -8.0458e-03,  2.3998e-03]],

         [[ 7.1396e-03,  1.5620e-02, -1.4695e-02],
          [-5.9055e-03, -6.2204e-03, -8.8371e-03],
          [-2.7837e-03, -6.3993e-03,  1.3061e-04]],

         [[ 4.6829e-03,  1.5634e-02, -8.0028e-03],
          [-7.0312e-03,  5.7581e-03,  6.0800e-03],
          [ 5.0293e-03,  9.0424e-05, -1.2182e-03]]],


        [[[ 8.4258e-11, -2.8201e-11,  3.4893e-11],
          [-1.8371e-10, -5.0087e-11, -1.4004e-09],
          [-3.5587e-09, -4.4156e-09, -2.1753e-08]],

         [[ 1.7962e-13,  5.6203e-14,  3.8978e-13],
          [-1.1260e-13, -4.2360e-12, -3.3851e-11],
          [ 3.2386e-10, -3.8311e-12, -1.6118e-09]],

         [[-2.6772e-15, -7.5453e-15, -4.3746e-13],
          [-1.1420e-12, -5.3012e-12, -1.5760e-10],
          [-5.2155e-10, -1.0066e-09, -4.9621e-11]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5196]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0050]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 36 | Batch_idx: 0 |  Loss: (0.3375) | Acc: (88.00%) (113/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.3147) | Acc: (89.00%) (1255/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.3721) | Acc: (87.00%) (2355/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.4072) | Acc: (86.00%) (3426/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.4244) | Acc: (85.00%) (4495/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.4375) | Acc: (85.00%) (5559/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.4382) | Acc: (85.00%) (6648/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.4407) | Acc: (85.00%) (7738/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.4360) | Acc: (85.00%) (8848/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.4338) | Acc: (85.00%) (9946/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.4291) | Acc: (85.00%) (11069/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.4295) | Acc: (85.00%) (12156/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.4261) | Acc: (85.00%) (13269/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.4246) | Acc: (85.00%) (14378/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.4212) | Acc: (85.00%) (15503/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.4172) | Acc: (86.00%) (16640/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.4140) | Acc: (86.00%) (17753/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.4120) | Acc: (86.00%) (18877/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.4102) | Acc: (86.00%) (19987/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.4094) | Acc: (86.00%) (21099/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.4076) | Acc: (86.00%) (22217/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.4092) | Acc: (86.00%) (23303/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.4075) | Acc: (86.00%) (24416/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.4092) | Acc: (86.00%) (25504/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.4082) | Acc: (86.00%) (26613/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.4071) | Acc: (86.00%) (27718/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.4058) | Acc: (86.00%) (28827/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.4048) | Acc: (86.00%) (29941/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.4031) | Acc: (86.00%) (31061/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.4032) | Acc: (86.00%) (32163/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.4038) | Acc: (86.00%) (33261/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.4025) | Acc: (86.00%) (34381/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.4019) | Acc: (86.00%) (35496/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.4003) | Acc: (86.00%) (36622/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.3992) | Acc: (86.00%) (37741/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.3986) | Acc: (86.00%) (38854/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.3977) | Acc: (86.00%) (39963/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.3973) | Acc: (86.00%) (41084/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.3953) | Acc: (86.00%) (42228/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.3938) | Acc: (86.00%) (43326/50000)
# TEST : Loss: (0.4570) | Acc: (84.00%) (8481/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0000e-01,  1.8075e-01, -7.8775e-02],
          [-7.4377e-02,  5.1334e-02, -2.5939e-03],
          [ 5.3898e-02, -1.9943e-01,  2.2487e-01]],

         [[-1.2526e-01,  2.7082e-01,  7.4934e-02],
          [-3.3625e-02,  7.5226e-02, -1.3839e-01],
          [ 9.3475e-02, -2.5019e-01, -3.4034e-02]],

         [[-9.6962e-02,  2.2086e-01, -1.5019e-01],
          [ 8.2755e-02, -1.5659e-01, -5.8929e-02],
          [ 1.2619e-01, -1.6633e-01,  2.0073e-01]]],


        [[[-1.2255e-01, -2.5009e-01, -1.5185e-01],
          [-1.4142e-01,  1.8592e-01,  1.5364e-01],
          [ 1.3441e-01,  5.1101e-02,  1.9337e-01]],

         [[-2.1045e-01, -1.8204e-01, -1.3893e-01],
          [-1.5360e-01,  9.9591e-02,  1.9032e-01],
          [ 1.9991e-01, -2.8884e-02,  6.0817e-02]],

         [[-1.1651e-01,  1.2870e-01, -1.8072e-01],
          [ 8.0877e-02,  2.1990e-01, -1.1646e-01],
          [-9.4136e-03,  7.2509e-02,  4.5529e-02]]],


        [[[-1.1077e-01,  2.0193e-01,  8.8360e-02],
          [ 1.2687e-01,  9.6082e-02, -9.8459e-02],
          [-1.7689e-01,  3.5593e-02, -1.9101e-01]],

         [[ 8.8409e-02,  5.8489e-02,  2.4849e-02],
          [ 6.3755e-02,  1.9507e-01,  7.6375e-02],
          [-4.0609e-02, -1.0456e-02, -2.9186e-01]],

         [[-7.4509e-02,  5.6247e-02,  1.8688e-01],
          [ 1.3508e-02,  2.0876e-01,  6.9221e-02],
          [-1.9609e-01, -1.6601e-01, -2.1867e-01]]],


        ...,


        [[[-1.5675e-01, -1.2782e-01,  1.1144e-02],
          [ 1.2875e-01, -1.9442e-01, -7.3765e-02],
          [ 1.2456e-01, -7.2456e-02,  7.5984e-02]],

         [[ 1.6434e-01,  1.9805e-02, -5.1422e-03],
          [-8.9113e-02, -3.1806e-01, -2.2245e-01],
          [ 9.9210e-02,  1.3378e-02, -1.2968e-01]],

         [[ 1.8862e-01, -7.4020e-03,  6.6553e-02],
          [-4.9664e-02, -1.6136e-01, -1.6651e-01],
          [ 3.9645e-02, -1.0350e-01, -1.1265e-01]]],


        [[[ 1.1618e-02,  8.3767e-03,  2.2904e-03],
          [-1.9061e-03, -3.6796e-03,  3.5606e-03],
          [-2.3162e-04, -4.1599e-03,  1.2759e-03]],

         [[ 4.4789e-03,  9.5627e-03, -8.7616e-03],
          [-3.3320e-03, -3.3283e-03, -4.7811e-03],
          [-1.4522e-03, -3.0884e-03,  6.5401e-05]],

         [[ 2.8833e-03,  9.4612e-03, -4.7415e-03],
          [-3.9985e-03,  3.1680e-03,  3.3731e-03],
          [ 2.7147e-03,  4.6217e-05, -6.3906e-04]]],


        [[[ 7.2431e-13, -1.9686e-13,  2.6829e-13],
          [-1.7570e-12, -4.3166e-13, -1.8265e-11],
          [-6.8154e-11, -8.7718e-11, -5.8392e-10]],

         [[ 2.8114e-16,  6.3622e-17,  9.5043e-16],
          [-3.5874e-16, -1.4824e-14, -2.9520e-13],
          [ 4.4554e-12, -6.1334e-14, -3.9753e-11]],

         [[-1.1531e-18, -3.5351e-18, -7.9684e-16],
          [-2.3606e-15, -1.6105e-14, -1.3582e-12],
          [-6.3942e-12, -1.5294e-11, -1.1865e-12]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0623,  0.0709,  0.0282],
          [ 0.0677,  0.0837,  0.0715],
          [ 0.0264,  0.0380,  0.0413]],

         [[ 0.0363,  0.0505,  0.0223],
          [ 0.0535,  0.0769,  0.0736],
          [ 0.0289,  0.0403,  0.0564]],

         [[ 0.0590,  0.0768,  0.0568],
          [ 0.0680,  0.1007,  0.0985],
          [ 0.0527,  0.0680,  0.0803]]],


        [[[ 0.0129,  0.0142,  0.0168],
          [ 0.0036,  0.0098,  0.0153],
          [ 0.0099,  0.0196,  0.0200]],

         [[ 0.0444,  0.0433,  0.0418],
          [ 0.0292,  0.0358,  0.0424],
          [ 0.0340,  0.0492,  0.0508]],

         [[ 0.0683,  0.0651,  0.0635],
          [ 0.0516,  0.0527,  0.0562],
          [ 0.0525,  0.0629,  0.0607]]],


        [[[-0.0065, -0.0160, -0.0310],
          [ 0.0083, -0.0012, -0.0207],
          [ 0.0109, -0.0068, -0.0185]],

         [[-0.0106, -0.0208, -0.0345],
          [ 0.0015, -0.0069, -0.0294],
          [ 0.0058, -0.0136, -0.0321]],

         [[-0.0069, -0.0148, -0.0272],
          [ 0.0040, -0.0010, -0.0224],
          [ 0.0101, -0.0051, -0.0282]]],


        ...,


        [[[ 0.0198,  0.0129,  0.0133],
          [ 0.0178,  0.0107,  0.0115],
          [ 0.0249,  0.0161,  0.0144]],

         [[ 0.0176,  0.0084,  0.0085],
          [ 0.0133,  0.0035,  0.0036],
          [ 0.0181,  0.0063,  0.0052]],

         [[ 0.0195,  0.0125,  0.0118],
          [ 0.0140,  0.0063,  0.0049],
          [ 0.0165,  0.0076,  0.0059]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5210]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 37 | Batch_idx: 0 |  Loss: (0.3060) | Acc: (88.00%) (113/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.3016) | Acc: (89.00%) (1262/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.3143) | Acc: (89.00%) (2403/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.3178) | Acc: (89.00%) (3546/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.3256) | Acc: (89.00%) (4673/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.3277) | Acc: (89.00%) (5817/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.3330) | Acc: (88.00%) (6935/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.3351) | Acc: (88.00%) (8065/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.3362) | Acc: (88.00%) (9200/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.3356) | Acc: (88.00%) (10346/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.3356) | Acc: (88.00%) (11483/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.3361) | Acc: (88.00%) (12617/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.3347) | Acc: (88.00%) (13748/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.3327) | Acc: (88.00%) (14889/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.3323) | Acc: (88.00%) (16017/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.3319) | Acc: (88.00%) (17158/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.3324) | Acc: (88.00%) (18306/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.3312) | Acc: (88.00%) (19441/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.3303) | Acc: (88.00%) (20574/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.3322) | Acc: (88.00%) (21681/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.3332) | Acc: (88.00%) (22806/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.3339) | Acc: (88.00%) (23939/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.3333) | Acc: (88.00%) (25088/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.3344) | Acc: (88.00%) (26216/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.3346) | Acc: (88.00%) (27332/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.3338) | Acc: (88.00%) (28481/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.3337) | Acc: (88.00%) (29622/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.3331) | Acc: (88.00%) (30761/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.3316) | Acc: (88.00%) (31917/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.3314) | Acc: (88.00%) (33064/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.3313) | Acc: (88.00%) (34200/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.3314) | Acc: (88.00%) (35335/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.3303) | Acc: (88.00%) (36486/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.3293) | Acc: (88.00%) (37633/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.3290) | Acc: (88.00%) (38768/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.3280) | Acc: (88.00%) (39924/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.3286) | Acc: (88.00%) (41063/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.3295) | Acc: (88.00%) (42199/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.3293) | Acc: (88.00%) (43343/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.3282) | Acc: (88.00%) (44454/50000)
# TEST : Loss: (0.3701) | Acc: (87.00%) (8748/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0440e-01,  1.7853e-01, -8.4765e-02],
          [-7.2966e-02,  4.9644e-02, -1.3856e-02],
          [ 5.5864e-02, -2.0587e-01,  2.2321e-01]],

         [[-1.2768e-01,  2.7502e-01,  7.5557e-02],
          [-3.2994e-02,  7.1821e-02, -1.4574e-01],
          [ 9.5554e-02, -2.6108e-01, -3.4350e-02]],

         [[-8.6326e-02,  2.2771e-01, -1.4361e-01],
          [ 9.6020e-02, -1.4846e-01, -6.2835e-02],
          [ 1.4439e-01, -1.5938e-01,  2.0186e-01]]],


        [[[-1.2679e-01, -2.5804e-01, -1.6485e-01],
          [-1.3757e-01,  1.8464e-01,  1.4598e-01],
          [ 1.4033e-01,  4.9334e-02,  1.8778e-01]],

         [[-2.1473e-01, -1.8796e-01, -1.5117e-01],
          [-1.4873e-01,  1.0145e-01,  1.8581e-01],
          [ 2.0590e-01, -2.9813e-02,  5.7587e-02]],

         [[-1.2032e-01,  1.2491e-01, -1.8838e-01],
          [ 8.6442e-02,  2.2428e-01, -1.1423e-01],
          [-6.7214e-03,  7.1579e-02,  4.6014e-02]]],


        [[[-1.1261e-01,  2.0394e-01,  8.4165e-02],
          [ 1.2802e-01,  9.8015e-02, -9.8547e-02],
          [-1.7567e-01,  2.9744e-02, -1.9745e-01]],

         [[ 8.7590e-02,  6.1681e-02,  2.0419e-02],
          [ 6.4790e-02,  1.9698e-01,  7.5790e-02],
          [-4.2287e-02, -1.7367e-02, -2.9805e-01]],

         [[-7.5174e-02,  5.8870e-02,  1.8364e-01],
          [ 1.3733e-02,  2.0845e-01,  6.6677e-02],
          [-2.0053e-01, -1.7541e-01, -2.2764e-01]]],


        ...,


        [[[-1.5382e-01, -1.2891e-01,  2.1778e-02],
          [ 1.4188e-01, -1.9377e-01, -7.0299e-02],
          [ 1.3695e-01, -6.0871e-02,  7.6373e-02]],

         [[ 1.6287e-01,  1.1399e-02,  2.1052e-03],
          [-7.9525e-02, -3.2761e-01, -2.2482e-01],
          [ 1.0786e-01,  2.0162e-02, -1.3491e-01]],

         [[ 1.8649e-01, -1.3284e-02,  6.6569e-02],
          [-3.9048e-02, -1.6334e-01, -1.6839e-01],
          [ 5.1154e-02, -9.6607e-02, -1.2090e-01]]],


        [[[ 6.7402e-03,  4.7488e-03,  1.2660e-03],
          [-9.9264e-04, -1.8330e-03,  1.7973e-03],
          [-1.1080e-04, -1.8596e-03,  5.9029e-04]],

         [[ 2.5371e-03,  5.2575e-03, -4.6637e-03],
          [-1.6575e-03, -1.5516e-03, -2.2597e-03],
          [-6.5619e-04, -1.2688e-03,  2.8074e-05]],

         [[ 1.5964e-03,  5.1289e-03, -2.5043e-03],
          [-2.0084e-03,  1.5286e-03,  1.6440e-03],
          [ 1.2796e-03,  2.0567e-05, -2.9087e-04]]],


        [[[ 1.8249e-15, -3.7671e-16,  5.8344e-16],
          [-5.0936e-15, -1.0912e-15, -7.9455e-14],
          [-4.8802e-13, -6.5852e-13, -6.4566e-12]],

         [[ 7.0715e-20,  1.0151e-20,  4.4127e-19],
          [-2.3988e-19, -1.1256e-17, -7.5793e-16],
          [ 2.0776e-14, -3.4827e-16, -3.9430e-13]],

         [[-4.5262e-23, -1.5726e-22, -2.4750e-19],
          [-8.7334e-19, -1.0095e-17, -3.4335e-15],
          [-2.5659e-14, -8.1141e-14, -1.1309e-14]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0712,  0.0482,  0.0495],
          [ 0.0733,  0.0501,  0.0581],
          [ 0.0358,  0.0135,  0.0254]],

         [[ 0.0857,  0.0636,  0.0604],
          [ 0.0931,  0.0699,  0.0734],
          [ 0.0506,  0.0361,  0.0448]],

         [[ 0.1030,  0.0861,  0.0788],
          [ 0.1141,  0.0944,  0.1003],
          [ 0.0748,  0.0617,  0.0720]]],


        [[[-0.0452, -0.0494, -0.0547],
          [-0.0477, -0.0527, -0.0584],
          [-0.0392, -0.0444, -0.0481]],

         [[-0.0475, -0.0567, -0.0653],
          [-0.0555, -0.0649, -0.0724],
          [-0.0473, -0.0566, -0.0605]],

         [[-0.0360, -0.0453, -0.0567],
          [-0.0471, -0.0585, -0.0697],
          [-0.0426, -0.0577, -0.0650]]],


        [[[ 0.0441,  0.0380,  0.0630],
          [ 0.0557,  0.0497,  0.0633],
          [ 0.0550,  0.0504,  0.0541]],

         [[ 0.0495,  0.0442,  0.0666],
          [ 0.0577,  0.0528,  0.0633],
          [ 0.0563,  0.0536,  0.0537]],

         [[ 0.0350,  0.0293,  0.0450],
          [ 0.0377,  0.0318,  0.0377],
          [ 0.0355,  0.0320,  0.0319]]],


        ...,


        [[[ 0.0028,  0.0059,  0.0056],
          [ 0.0066,  0.0045,  0.0011],
          [ 0.0109,  0.0045, -0.0013]],

         [[-0.0055, -0.0003, -0.0002],
          [-0.0020, -0.0016, -0.0043],
          [ 0.0015, -0.0026, -0.0068]],

         [[-0.0009,  0.0019,  0.0012],
          [ 0.0031,  0.0036,  0.0026],
          [ 0.0075,  0.0050,  0.0035]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5197]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 38 | Batch_idx: 0 |  Loss: (0.1844) | Acc: (92.00%) (119/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.2691) | Acc: (91.00%) (1282/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.2745) | Acc: (90.00%) (2441/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.2805) | Acc: (90.00%) (3598/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.2679) | Acc: (91.00%) (4778/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.2710) | Acc: (91.00%) (5942/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.2728) | Acc: (90.00%) (7102/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.2759) | Acc: (90.00%) (8263/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.2719) | Acc: (91.00%) (9440/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.2729) | Acc: (90.00%) (10596/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.2733) | Acc: (90.00%) (11749/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.2794) | Acc: (90.00%) (12888/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.2848) | Acc: (90.00%) (14023/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.2845) | Acc: (90.00%) (15176/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.2829) | Acc: (90.00%) (16340/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.2849) | Acc: (90.00%) (17481/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.2850) | Acc: (90.00%) (18649/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.2837) | Acc: (90.00%) (19809/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.2855) | Acc: (90.00%) (20959/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.2875) | Acc: (90.00%) (22098/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.2895) | Acc: (90.00%) (23232/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.2894) | Acc: (90.00%) (24389/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.2884) | Acc: (90.00%) (25550/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.2884) | Acc: (90.00%) (26707/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.2883) | Acc: (90.00%) (27865/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.2885) | Acc: (90.00%) (29017/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.2884) | Acc: (90.00%) (30177/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.2885) | Acc: (90.00%) (31343/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.2889) | Acc: (90.00%) (32497/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.2900) | Acc: (90.00%) (33644/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.2904) | Acc: (90.00%) (34804/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.2899) | Acc: (90.00%) (35959/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.2898) | Acc: (90.00%) (37108/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.2898) | Acc: (90.00%) (38266/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.2890) | Acc: (90.00%) (39431/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.2881) | Acc: (90.00%) (40607/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.2884) | Acc: (90.00%) (41760/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.2884) | Acc: (90.00%) (42919/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.2884) | Acc: (90.00%) (44078/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.2889) | Acc: (90.00%) (45179/50000)
# TEST : Loss: (0.3686) | Acc: (87.00%) (8775/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1013e-01,  1.7937e-01, -9.0363e-02],
          [-8.1470e-02,  4.5823e-02, -1.8909e-02],
          [ 4.9671e-02, -2.0683e-01,  2.2889e-01]],

         [[-1.2481e-01,  2.8379e-01,  7.7238e-02],
          [-3.3510e-02,  7.0875e-02, -1.4913e-01],
          [ 9.1185e-02, -2.6308e-01, -2.9561e-02]],

         [[-8.4030e-02,  2.3245e-01, -1.4233e-01],
          [ 9.2636e-02, -1.4539e-01, -6.5867e-02],
          [ 1.3809e-01, -1.5687e-01,  2.0771e-01]]],


        [[[-1.2005e-01, -2.5681e-01, -1.6436e-01],
          [-1.2949e-01,  1.9080e-01,  1.5237e-01],
          [ 1.5200e-01,  5.6707e-02,  1.9488e-01]],

         [[-2.0879e-01, -1.8740e-01, -1.5133e-01],
          [-1.3996e-01,  1.0745e-01,  1.9072e-01],
          [ 2.2022e-01, -2.1091e-02,  6.3487e-02]],

         [[-1.0752e-01,  1.3380e-01, -1.7831e-01],
          [ 9.8549e-02,  2.3348e-01, -1.0416e-01],
          [ 9.2371e-03,  8.1963e-02,  5.5143e-02]]],


        [[[-1.0736e-01,  2.0638e-01,  8.9598e-02],
          [ 1.3525e-01,  1.0397e-01, -9.2841e-02],
          [-1.7148e-01,  3.3033e-02, -1.9478e-01]],

         [[ 9.1243e-02,  6.3219e-02,  2.4186e-02],
          [ 7.2450e-02,  2.0186e-01,  7.7863e-02],
          [-4.1589e-02, -1.9364e-02, -3.0092e-01]],

         [[-7.3150e-02,  6.0911e-02,  1.8770e-01],
          [ 1.9280e-02,  2.1350e-01,  7.1646e-02],
          [-2.0089e-01, -1.7528e-01, -2.2667e-01]]],


        ...,


        [[[-1.6698e-01, -1.4265e-01,  1.6574e-02],
          [ 1.3198e-01, -2.0965e-01, -7.1825e-02],
          [ 1.3080e-01, -7.3233e-02,  7.5343e-02]],

         [[ 1.6084e-01,  7.5453e-03,  1.8838e-04],
          [-7.3722e-02, -3.2770e-01, -2.1502e-01],
          [ 1.1320e-01,  1.5016e-02, -1.3114e-01]],

         [[ 1.8452e-01, -1.1603e-02,  7.0553e-02],
          [-3.6399e-02, -1.6384e-01, -1.6124e-01],
          [ 5.4311e-02, -1.0310e-01, -1.2298e-01]]],


        [[[ 3.4698e-03,  2.3765e-03,  6.1427e-04],
          [-4.4773e-04, -7.8301e-04,  7.8025e-04],
          [-4.5034e-05, -6.9562e-04,  2.3029e-04]],

         [[ 1.2684e-03,  2.5342e-03, -2.1606e-03],
          [-7.0682e-04, -6.1099e-04, -9.0500e-04],
          [-2.4871e-04, -4.2785e-04,  9.9901e-06]],

         [[ 7.7613e-04,  2.4299e-03, -1.1492e-03],
          [-8.6663e-04,  6.2795e-04,  6.8368e-04],
          [ 5.1080e-04,  7.6493e-06, -1.1123e-04]]],


        [[[ 8.8607e-19, -1.2527e-19,  2.3148e-19],
          [-2.9956e-18, -5.3228e-19, -8.0909e-17],
          [-9.6591e-16, -1.3875e-15, -2.2639e-14]],

         [[ 1.2252e-24,  8.5619e-26,  1.9368e-23],
          [-1.7992e-23, -1.0151e-21, -3.7766e-19],
          [ 2.3224e-17, -5.0655e-19, -1.1990e-15]],

         [[-3.2058e-29, -1.4226e-28, -5.9317e-24],
          [-2.7290e-23, -6.8918e-22, -1.6748e-18],
          [-2.3439e-17, -1.0780e-16, -3.2638e-17]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0510,  0.0557,  0.0886],
          [ 0.0522,  0.0431,  0.0648],
          [ 0.0123,  0.0218,  0.0505]],

         [[ 0.0530,  0.0501,  0.0774],
          [ 0.0576,  0.0449,  0.0649],
          [ 0.0199,  0.0286,  0.0613]],

         [[ 0.0419,  0.0478,  0.0732],
          [ 0.0510,  0.0482,  0.0700],
          [ 0.0250,  0.0403,  0.0652]]],


        [[[ 0.0717,  0.0643,  0.0542],
          [ 0.0695,  0.0646,  0.0519],
          [ 0.0713,  0.0725,  0.0592]],

         [[ 0.0702,  0.0627,  0.0500],
          [ 0.0614,  0.0575,  0.0430],
          [ 0.0550,  0.0595,  0.0462]],

         [[ 0.0501,  0.0421,  0.0304],
          [ 0.0444,  0.0388,  0.0272],
          [ 0.0367,  0.0381,  0.0278]]],


        [[[ 0.0325,  0.0373,  0.0381],
          [ 0.0456,  0.0515,  0.0598],
          [ 0.0476,  0.0512,  0.0550]],

         [[ 0.0387,  0.0467,  0.0453],
          [ 0.0417,  0.0493,  0.0554],
          [ 0.0424,  0.0447,  0.0473]],

         [[ 0.0518,  0.0579,  0.0548],
          [ 0.0491,  0.0546,  0.0564],
          [ 0.0529,  0.0525,  0.0498]]],


        ...,


        [[[-0.0231, -0.0145, -0.0187],
          [-0.0143, -0.0075, -0.0147],
          [-0.0111, -0.0078, -0.0146]],

         [[-0.0143, -0.0067, -0.0123],
          [-0.0054, -0.0001, -0.0093],
          [-0.0032, -0.0022, -0.0126]],

         [[-0.0072,  0.0025,  0.0009],
          [ 0.0035,  0.0112,  0.0061],
          [ 0.0086,  0.0122,  0.0058]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5181]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 39 | Batch_idx: 0 |  Loss: (0.1752) | Acc: (93.00%) (120/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.2501) | Acc: (91.00%) (1287/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.2719) | Acc: (90.00%) (2436/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.2934) | Acc: (89.00%) (3566/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.3016) | Acc: (89.00%) (4707/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.3036) | Acc: (89.00%) (5846/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.3016) | Acc: (89.00%) (6992/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.3063) | Acc: (89.00%) (8123/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.3033) | Acc: (89.00%) (9280/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.3024) | Acc: (89.00%) (10425/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.3001) | Acc: (89.00%) (11573/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.3025) | Acc: (89.00%) (12714/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.3017) | Acc: (89.00%) (13868/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.2984) | Acc: (89.00%) (15021/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.2966) | Acc: (89.00%) (16183/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.2943) | Acc: (89.00%) (17354/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.2938) | Acc: (89.00%) (18506/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.2910) | Acc: (89.00%) (19674/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.2890) | Acc: (89.00%) (20837/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.2876) | Acc: (90.00%) (22005/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.2875) | Acc: (90.00%) (23160/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.2867) | Acc: (90.00%) (24322/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.2854) | Acc: (90.00%) (25490/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.2854) | Acc: (90.00%) (26645/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.2840) | Acc: (90.00%) (27813/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.2826) | Acc: (90.00%) (28988/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.2820) | Acc: (90.00%) (30156/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.2810) | Acc: (90.00%) (31327/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.2806) | Acc: (90.00%) (32493/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.2801) | Acc: (90.00%) (33665/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.2798) | Acc: (90.00%) (34831/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.2791) | Acc: (90.00%) (35996/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.2774) | Acc: (90.00%) (37180/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.2765) | Acc: (90.00%) (38350/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.2762) | Acc: (90.00%) (39519/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.2760) | Acc: (90.00%) (40683/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.2758) | Acc: (90.00%) (41844/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.2755) | Acc: (90.00%) (43012/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.2744) | Acc: (90.00%) (44194/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.2744) | Acc: (90.00%) (45314/50000)
# TEST : Loss: (0.3346) | Acc: (89.00%) (8901/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1510e-01,  1.7314e-01, -9.5943e-02],
          [-8.7490e-02,  3.8731e-02, -2.4388e-02],
          [ 4.4600e-02, -2.1293e-01,  2.2262e-01]],

         [[-1.2998e-01,  2.7734e-01,  7.1413e-02],
          [-3.9923e-02,  6.3395e-02, -1.5514e-01],
          [ 8.5446e-02, -2.6981e-01, -3.6487e-02]],

         [[-8.8361e-02,  2.2692e-01, -1.4725e-01],
          [ 8.6677e-02, -1.5153e-01, -7.1135e-02],
          [ 1.3247e-01, -1.6324e-01,  2.0142e-01]]],


        [[[-1.2168e-01, -2.5786e-01, -1.6573e-01],
          [-1.3083e-01,  1.8887e-01,  1.5062e-01],
          [ 1.4950e-01,  5.4259e-02,  1.9264e-01]],

         [[-2.1105e-01, -1.8946e-01, -1.5325e-01],
          [-1.4154e-01,  1.0539e-01,  1.8886e-01],
          [ 2.1786e-01, -2.3131e-02,  6.1787e-02]],

         [[-1.0865e-01,  1.3246e-01, -1.7889e-01],
          [ 9.7080e-02,  2.3192e-01, -1.0467e-01],
          [ 7.7514e-03,  8.0417e-02,  5.4125e-02]]],


        [[[-1.0727e-01,  2.0583e-01,  8.9676e-02],
          [ 1.3407e-01,  1.0260e-01, -9.3671e-02],
          [-1.7209e-01,  3.1656e-02, -1.9575e-01]],

         [[ 9.1521e-02,  6.3273e-02,  2.5015e-02],
          [ 7.2159e-02,  2.0085e-01,  7.7541e-02],
          [-4.1339e-02, -1.9669e-02, -3.0054e-01]],

         [[-7.2819e-02,  6.0737e-02,  1.8788e-01],
          [ 1.9213e-02,  2.1270e-01,  7.1596e-02],
          [-2.0032e-01, -1.7514e-01, -2.2594e-01]]],


        ...,


        [[[-1.6154e-01, -1.3864e-01,  1.9376e-02],
          [ 1.3501e-01, -2.0577e-01, -6.8695e-02],
          [ 1.3433e-01, -6.9809e-02,  7.7552e-02]],

         [[ 1.6369e-01,  1.0393e-02,  3.5679e-03],
          [-7.0329e-02, -3.2119e-01, -2.0788e-01],
          [ 1.1574e-01,  1.7693e-02, -1.2653e-01]],

         [[ 1.8586e-01, -1.0861e-02,  7.0808e-02],
          [-3.4851e-02, -1.6324e-01, -1.6011e-01],
          [ 5.5263e-02, -1.0275e-01, -1.2244e-01]]],


        [[[ 1.5431e-03,  1.0208e-03,  2.5405e-04],
          [-1.6932e-04, -2.7700e-04,  2.8155e-04],
          [-1.4988e-05, -2.0905e-04,  7.2881e-05]],

         [[ 5.4421e-04,  1.0397e-03, -8.4441e-04],
          [-2.4952e-04, -1.9559e-04, -2.9578e-04],
          [-7.5965e-05, -1.1317e-04,  2.8235e-06]],

         [[ 3.2179e-04,  9.7607e-04, -4.4392e-04],
          [-3.1041e-04,  2.1173e-04,  2.3403e-04],
          [ 1.6627e-04,  2.2826e-06, -3.4346e-05]]],


        [[[ 4.1563e-23, -3.3314e-24,  8.0347e-24],
          [-1.8632e-22, -2.5138e-23, -1.1109e-20],
          [-3.3655e-19, -5.2702e-19, -1.7237e-17]],

         [[ 1.3926e-31,  6.4940e-34,  1.7071e-29],
          [-4.2580e-29, -3.3119e-27, -1.8406e-23],
          [ 3.6401e-21, -1.1501e-22, -7.5255e-19]],

         [[-3.1416e-38, -9.6431e-38, -1.4819e-30],
          [-1.2151e-29, -1.3798e-27, -7.9096e-23],
          [-2.7566e-21, -2.1556e-20, -1.9078e-20]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5622]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0234]], device='cuda:0')

Epoch: 40 | Batch_idx: 0 |  Loss: (0.2430) | Acc: (90.00%) (116/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.2446) | Acc: (92.00%) (1298/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.2436) | Acc: (92.00%) (2476/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.2465) | Acc: (92.00%) (3659/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.2485) | Acc: (91.00%) (4825/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.2460) | Acc: (92.00%) (6008/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.2520) | Acc: (91.00%) (7162/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.2479) | Acc: (91.00%) (8349/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.2514) | Acc: (91.00%) (9506/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.2484) | Acc: (91.00%) (10689/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.2488) | Acc: (91.00%) (11861/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.2470) | Acc: (91.00%) (13053/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.2511) | Acc: (91.00%) (14207/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.2490) | Acc: (91.00%) (15385/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.2491) | Acc: (91.00%) (16569/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.2478) | Acc: (91.00%) (17750/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.2505) | Acc: (91.00%) (18898/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.2547) | Acc: (91.00%) (20041/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.2563) | Acc: (91.00%) (21198/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.2574) | Acc: (91.00%) (22363/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.2570) | Acc: (91.00%) (23534/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.2567) | Acc: (91.00%) (24705/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.2564) | Acc: (91.00%) (25881/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.2559) | Acc: (91.00%) (27049/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.2553) | Acc: (91.00%) (28234/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.2547) | Acc: (91.00%) (29409/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.2552) | Acc: (91.00%) (30565/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.2549) | Acc: (91.00%) (31741/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.2539) | Acc: (91.00%) (32932/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.2541) | Acc: (91.00%) (34104/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.2537) | Acc: (91.00%) (35277/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.2542) | Acc: (91.00%) (36434/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.2535) | Acc: (91.00%) (37616/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.2543) | Acc: (91.00%) (38769/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.2548) | Acc: (91.00%) (39921/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.2545) | Acc: (91.00%) (41099/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.2546) | Acc: (91.00%) (42268/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.2547) | Acc: (91.00%) (43439/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.2548) | Acc: (91.00%) (44610/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.2549) | Acc: (91.00%) (45740/50000)
# TEST : Loss: (0.3251) | Acc: (89.00%) (8948/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1491e-01,  1.7285e-01, -9.5787e-02],
          [-8.7347e-02,  3.8668e-02, -2.4349e-02],
          [ 4.4527e-02, -2.1257e-01,  2.2225e-01]],

         [[-1.2976e-01,  2.7685e-01,  7.1292e-02],
          [-3.9856e-02,  6.3286e-02, -1.5487e-01],
          [ 8.5301e-02, -2.6933e-01, -3.6424e-02]],

         [[-8.8202e-02,  2.2650e-01, -1.4699e-01],
          [ 8.6524e-02, -1.5126e-01, -7.1008e-02],
          [ 1.3223e-01, -1.6293e-01,  2.0106e-01]]],


        [[[-1.2139e-01, -2.5725e-01, -1.6534e-01],
          [-1.3053e-01,  1.8843e-01,  1.5027e-01],
          [ 1.4915e-01,  5.4128e-02,  1.9216e-01]],

         [[-2.1053e-01, -1.8899e-01, -1.5287e-01],
          [-1.4120e-01,  1.0513e-01,  1.8841e-01],
          [ 2.1732e-01, -2.3073e-02,  6.1631e-02]],

         [[-1.0837e-01,  1.3211e-01, -1.7843e-01],
          [ 9.6835e-02,  2.3133e-01, -1.0440e-01],
          [ 7.7314e-03,  8.0207e-02,  5.3982e-02]]],


        [[[-1.0705e-01,  2.0541e-01,  8.9496e-02],
          [ 1.3380e-01,  1.0240e-01, -9.3488e-02],
          [-1.7176e-01,  3.1595e-02, -1.9537e-01]],

         [[ 9.1328e-02,  6.3140e-02,  2.4962e-02],
          [ 7.2012e-02,  2.0044e-01,  7.7384e-02],
          [-4.1257e-02, -1.9629e-02, -2.9994e-01]],

         [[-7.2661e-02,  6.0606e-02,  1.8748e-01],
          [ 1.9172e-02,  2.1225e-01,  7.1444e-02],
          [-1.9989e-01, -1.7477e-01, -2.2545e-01]]],


        ...,


        [[[-1.6055e-01, -1.3752e-01,  1.9221e-02],
          [ 1.3408e-01, -2.0352e-01, -6.7932e-02],
          [ 1.3355e-01, -6.9257e-02,  7.6926e-02]],

         [[ 1.6263e-01,  1.0296e-02,  3.5344e-03],
          [-6.9795e-02, -3.1616e-01, -2.0434e-01],
          [ 1.1502e-01,  1.7525e-02, -1.2527e-01]],

         [[ 1.8462e-01, -1.0767e-02,  7.0196e-02],
          [-3.4583e-02, -1.6131e-01, -1.5816e-01],
          [ 5.4901e-02, -1.0180e-01, -1.2125e-01]]],


        [[[ 5.7352e-04,  3.6362e-04,  8.6373e-05],
          [-5.1574e-05, -7.7724e-05,  8.0950e-05],
          [-3.9011e-06, -4.7979e-05,  1.7828e-05]],

         [[ 1.9356e-04,  3.5002e-04, -2.6780e-04],
          [-6.9828e-05, -4.8527e-05, -7.5282e-05],
          [-1.7787e-05, -2.2191e-05,  6.0078e-07]],

         [[ 1.0974e-04,  3.2017e-04, -1.3878e-04],
          [-8.8436e-05,  5.6001e-05,  6.3057e-05],
          [ 4.2110e-05,  5.1937e-07, -8.1511e-06]]],


        [[[ 4.1620e-29, -1.0498e-30,  4.4451e-30],
          [-3.1537e-28, -2.5502e-29, -7.3388e-26],
          [-9.6054e-24, -1.7135e-23, -1.5604e-21]],

         [[-6.1308e-41,  6.6939e-41,  1.2303e-38],
          [ 1.3576e-37,  1.6352e-35, -1.9822e-29],
          [ 2.9828e-26, -1.6986e-27, -5.1474e-23]],

         [[ 5.9122e-41, -2.2131e-41, -7.5862e-40],
          [-1.2331e-38,  3.0897e-36, -8.0236e-29],
          [-1.4099e-26, -2.6074e-25, -1.1760e-24]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5584]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0074]], device='cuda:0')

Epoch: 41 | Batch_idx: 0 |  Loss: (0.3070) | Acc: (89.00%) (115/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.2715) | Acc: (91.00%) (1285/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.2708) | Acc: (90.00%) (2445/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.2667) | Acc: (91.00%) (3620/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.2638) | Acc: (91.00%) (4793/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.2583) | Acc: (91.00%) (5974/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.2601) | Acc: (91.00%) (7149/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.2573) | Acc: (91.00%) (8327/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.2585) | Acc: (91.00%) (9501/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.2586) | Acc: (91.00%) (10669/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.2550) | Acc: (91.00%) (11855/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.2568) | Acc: (91.00%) (13017/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.2539) | Acc: (91.00%) (14211/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.2523) | Acc: (91.00%) (15390/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.2516) | Acc: (91.00%) (16569/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.2523) | Acc: (91.00%) (17743/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.2526) | Acc: (91.00%) (18917/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.2535) | Acc: (91.00%) (20084/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.2526) | Acc: (91.00%) (21275/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.2528) | Acc: (91.00%) (22453/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.2537) | Acc: (91.00%) (23615/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.2531) | Acc: (91.00%) (24786/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.2535) | Acc: (91.00%) (25947/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.2527) | Acc: (91.00%) (27130/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.2512) | Acc: (91.00%) (28323/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.2523) | Acc: (91.00%) (29475/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.2521) | Acc: (91.00%) (30650/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.2517) | Acc: (91.00%) (31832/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.2517) | Acc: (91.00%) (33001/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.2520) | Acc: (91.00%) (34168/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.2522) | Acc: (91.00%) (35328/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.2519) | Acc: (91.00%) (36504/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.2527) | Acc: (91.00%) (37670/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.2527) | Acc: (91.00%) (38841/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.2524) | Acc: (91.00%) (40023/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.2528) | Acc: (91.00%) (41189/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.2522) | Acc: (91.00%) (42370/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.2529) | Acc: (91.00%) (43544/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.2528) | Acc: (91.00%) (44712/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.2521) | Acc: (91.00%) (45857/50000)
# TEST : Loss: (0.3214) | Acc: (89.00%) (8938/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1468e-01,  1.7250e-01, -9.5597e-02],
          [-8.7175e-02,  3.8592e-02, -2.4300e-02],
          [ 4.4438e-02, -2.1214e-01,  2.2181e-01]],

         [[-1.2949e-01,  2.7626e-01,  7.1146e-02],
          [-3.9775e-02,  6.3154e-02, -1.5455e-01],
          [ 8.5125e-02, -2.6875e-01, -3.6348e-02]],

         [[-8.8008e-02,  2.2599e-01, -1.4667e-01],
          [ 8.6338e-02, -1.5093e-01, -7.0853e-02],
          [ 1.3195e-01, -1.6257e-01,  2.0062e-01]]],


        [[[-1.2104e-01, -2.5650e-01, -1.6487e-01],
          [-1.3017e-01,  1.8790e-01,  1.4984e-01],
          [ 1.4871e-01,  5.3968e-02,  1.9158e-01]],

         [[-2.0990e-01, -1.8842e-01, -1.5242e-01],
          [-1.4079e-01,  1.0483e-01,  1.8786e-01],
          [ 2.1667e-01, -2.3003e-02,  6.1441e-02]],

         [[-1.0803e-01,  1.3169e-01, -1.7786e-01],
          [ 9.6538e-02,  2.3061e-01, -1.0408e-01],
          [ 7.7072e-03,  7.9953e-02,  5.3809e-02]]],


        [[[-1.0679e-01,  2.0491e-01,  8.9276e-02],
          [ 1.3349e-01,  1.0216e-01, -9.3266e-02],
          [-1.7136e-01,  3.1521e-02, -1.9490e-01]],

         [[ 9.1093e-02,  6.2977e-02,  2.4899e-02],
          [ 7.1833e-02,  1.9994e-01,  7.7193e-02],
          [-4.1156e-02, -1.9581e-02, -2.9920e-01]],

         [[-7.2469e-02,  6.0446e-02,  1.8699e-01],
          [ 1.9122e-02,  2.1170e-01,  7.1261e-02],
          [-1.9938e-01, -1.7431e-01, -2.2486e-01]]],


        ...,


        [[[-1.5936e-01, -1.3617e-01,  1.9035e-02],
          [ 1.3295e-01, -2.0082e-01, -6.7015e-02],
          [ 1.3260e-01, -6.8591e-02,  7.6171e-02]],

         [[ 1.6135e-01,  1.0179e-02,  3.4941e-03],
          [-6.9152e-02, -3.1014e-01, -2.0012e-01],
          [ 1.1416e-01,  1.7322e-02, -1.2374e-01]],

         [[ 1.8313e-01, -1.0653e-02,  6.9459e-02],
          [-3.4261e-02, -1.5898e-01, -1.5581e-01],
          [ 5.4463e-02, -1.0065e-01, -1.1983e-01]]],


        [[[ 1.7100e-04,  1.0289e-04,  2.3079e-05],
          [-1.2035e-05, -1.6391e-05,  1.7593e-05],
          [-7.4981e-07, -7.8935e-06,  3.1737e-06]],

         [[ 5.4671e-05,  9.2396e-05, -6.5683e-05],
          [-1.4678e-05, -8.7909e-06, -1.4075e-05],
          [-2.9996e-06, -3.0039e-06,  8.9997e-08]],

         [[ 2.9433e-05,  8.1858e-05, -3.3442e-05],
          [-1.9004e-05,  1.0979e-05,  1.2649e-05],
          [ 7.8249e-06,  8.4535e-08, -1.3977e-06]]],


        [[[ 1.9858e-38, -7.9779e-40,  4.7607e-39],
          [ 4.3242e-37, -1.1430e-38,  1.0191e-34],
          [-3.5291e-30, -8.2867e-30, -5.1243e-27]],

         [[-2.2334e-41,  5.6607e-41, -9.4700e-42],
          [-1.9627e-41,  3.6748e-41, -6.0221e-39],
          [ 1.8296e-34, -1.2477e-34, -1.0341e-28]],

         [[-4.8667e-42,  3.2994e-41, -6.6927e-41],
          [ 2.1807e-41, -3.3110e-41, -3.5957e-38],
          [ 7.1138e-35, -1.0289e-32, -1.9585e-30]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5545]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0088]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 42 | Batch_idx: 0 |  Loss: (0.2266) | Acc: (92.00%) (119/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.2881) | Acc: (90.00%) (1268/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.3287) | Acc: (88.00%) (2380/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.3426) | Acc: (88.00%) (3501/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.3669) | Acc: (87.00%) (4586/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.3787) | Acc: (87.00%) (5687/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.3799) | Acc: (87.00%) (6795/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.3859) | Acc: (86.00%) (7888/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.3916) | Acc: (86.00%) (8990/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.3974) | Acc: (86.00%) (10086/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.3954) | Acc: (86.00%) (11196/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.3931) | Acc: (86.00%) (12308/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.3941) | Acc: (86.00%) (13422/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.3909) | Acc: (86.00%) (14557/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.3890) | Acc: (86.00%) (15685/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.3915) | Acc: (86.00%) (16790/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.3944) | Acc: (86.00%) (17896/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4002) | Acc: (86.00%) (18966/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.3991) | Acc: (86.00%) (20069/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.3986) | Acc: (86.00%) (21175/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.3965) | Acc: (86.00%) (22303/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.3954) | Acc: (86.00%) (23426/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.3959) | Acc: (86.00%) (24533/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.3964) | Acc: (86.00%) (25641/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.3947) | Acc: (86.00%) (26775/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.3930) | Acc: (86.00%) (27904/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.3922) | Acc: (86.00%) (29023/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.3903) | Acc: (86.00%) (30153/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.3893) | Acc: (86.00%) (31277/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.3884) | Acc: (86.00%) (32395/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.3863) | Acc: (87.00%) (33532/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.3836) | Acc: (87.00%) (34676/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.3815) | Acc: (87.00%) (35827/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.3814) | Acc: (87.00%) (36943/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.3818) | Acc: (87.00%) (38042/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.3814) | Acc: (87.00%) (39159/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.3799) | Acc: (87.00%) (40289/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.3791) | Acc: (87.00%) (41404/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.3780) | Acc: (87.00%) (42533/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.3775) | Acc: (87.00%) (43623/50000)
# TEST : Loss: (0.4851) | Acc: (85.00%) (8500/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0954e-01,  1.9187e-01, -9.0360e-02],
          [-7.6501e-02,  5.3372e-02, -1.6297e-02],
          [ 4.8595e-02, -2.0559e-01,  2.3303e-01]],

         [[-1.2500e-01,  2.9550e-01,  7.5348e-02],
          [-2.8092e-02,  7.2111e-02, -1.5431e-01],
          [ 8.7062e-02, -2.7222e-01, -3.3356e-02]],

         [[-8.6894e-02,  2.3495e-01, -1.4588e-01],
          [ 1.0032e-01, -1.4064e-01, -7.3552e-02],
          [ 1.4235e-01, -1.5741e-01,  2.0062e-01]]],


        [[[-1.1795e-01, -2.6197e-01, -1.7562e-01],
          [-1.2151e-01,  1.9397e-01,  1.5225e-01],
          [ 1.6388e-01,  6.6134e-02,  1.9775e-01]],

         [[-2.0454e-01, -1.9460e-01, -1.6881e-01],
          [-1.3958e-01,  1.0396e-01,  1.7909e-01],
          [ 2.2114e-01, -1.9757e-02,  5.5807e-02]],

         [[-1.0644e-01,  1.2133e-01, -1.9839e-01],
          [ 9.3741e-02,  2.2438e-01, -1.1654e-01],
          [ 3.3092e-03,  7.4152e-02,  4.3155e-02]]],


        [[[-1.2444e-01,  2.0215e-01,  8.9504e-02],
          [ 1.1545e-01,  1.0009e-01, -9.6700e-02],
          [-1.9332e-01,  2.0666e-02, -2.0249e-01]],

         [[ 7.5454e-02,  6.0286e-02,  2.4748e-02],
          [ 5.4357e-02,  1.9584e-01,  7.1426e-02],
          [-6.1651e-02, -2.9260e-02, -3.0536e-01]],

         [[-7.9843e-02,  6.3053e-02,  1.9349e-01],
          [ 9.8587e-03,  2.1309e-01,  7.3963e-02],
          [-2.1283e-01, -1.7810e-01, -2.2491e-01]]],


        ...,


        [[[-1.6493e-01, -1.4374e-01,  1.5033e-02],
          [ 1.2201e-01, -2.2404e-01, -8.8742e-02],
          [ 1.3250e-01, -7.2710e-02,  6.8659e-02]],

         [[ 1.4833e-01, -7.3725e-03, -4.0399e-03],
          [-8.8261e-02, -3.5275e-01, -2.3058e-01],
          [ 1.0523e-01,  3.1465e-03, -1.2650e-01]],

         [[ 1.8355e-01, -8.6712e-03,  7.9635e-02],
          [-3.7183e-02, -1.6978e-01, -1.5143e-01],
          [ 5.9542e-02, -9.5642e-02, -1.0184e-01]]],


        [[[ 3.8869e-05,  2.1925e-05,  4.5821e-06],
          [-2.0211e-06, -2.4284e-06,  2.7054e-06],
          [-9.9020e-08, -8.5936e-07,  3.8108e-07]],

         [[ 1.1624e-05,  1.8071e-05, -1.1731e-05],
          [-2.1659e-06, -1.0787e-06, -1.7961e-06],
          [-3.3676e-07, -2.5654e-07,  8.7198e-09]],

         [[ 5.8709e-06,  1.5390e-05, -5.8436e-06],
          [-2.8820e-06,  1.4859e-06,  1.7613e-06],
          [ 9.9095e-07,  9.0813e-09, -1.6020e-07]]],


        [[[-6.4053e-42, -1.5231e-41, -6.6279e-41],
          [-6.6859e-41, -7.1648e-42, -2.9681e-41],
          [-3.1499e-39, -8.6751e-39,  2.5453e-35]],

         [[-2.0570e-41, -5.2752e-41, -6.7080e-41],
          [-5.1146e-41,  2.2369e-41, -2.4488e-41],
          [ 5.0179e-41, -4.2356e-41,  2.3347e-37]],

         [[ 4.8767e-41, -3.9553e-41,  2.4401e-41],
          [-5.0744e-41, -6.6954e-41,  3.3344e-41],
          [ 1.9493e-41,  2.0375e-41,  2.5206e-39]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0622, -0.0550, -0.0446],
          [-0.0600, -0.0591, -0.0384],
          [-0.0744, -0.0764, -0.0652]],

         [[-0.0426, -0.0451, -0.0374],
          [-0.0342, -0.0402, -0.0323],
          [-0.0518, -0.0588, -0.0481]],

         [[-0.0301, -0.0301, -0.0230],
          [-0.0221, -0.0234, -0.0149],
          [-0.0341, -0.0399, -0.0372]]],


        [[[ 0.0311,  0.0381,  0.0487],
          [ 0.0324,  0.0353,  0.0414],
          [ 0.0364,  0.0303,  0.0353]],

         [[ 0.0129,  0.0238,  0.0410],
          [ 0.0156,  0.0232,  0.0350],
          [ 0.0230,  0.0205,  0.0276]],

         [[ 0.0095,  0.0180,  0.0312],
          [ 0.0134,  0.0190,  0.0288],
          [ 0.0195,  0.0168,  0.0233]]],


        [[[-0.0082, -0.0154, -0.0239],
          [-0.0044, -0.0011, -0.0057],
          [-0.0149, -0.0098, -0.0064]],

         [[-0.0175, -0.0169, -0.0232],
          [-0.0088, -0.0006, -0.0065],
          [-0.0129, -0.0064, -0.0060]],

         [[-0.0175, -0.0171, -0.0243],
          [-0.0127, -0.0047, -0.0108],
          [-0.0169, -0.0104, -0.0102]]],


        ...,


        [[[-0.0045, -0.0015,  0.0019],
          [-0.0060, -0.0056, -0.0024],
          [ 0.0030,  0.0020,  0.0017]],

         [[ 0.0041,  0.0050,  0.0065],
          [ 0.0015,  0.0006,  0.0033],
          [ 0.0101,  0.0082,  0.0082]],

         [[ 0.0050,  0.0066,  0.0095],
          [ 0.0031,  0.0031,  0.0070],
          [ 0.0111,  0.0102,  0.0119]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5538]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 43 | Batch_idx: 0 |  Loss: (0.2465) | Acc: (92.00%) (119/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.3395) | Acc: (88.00%) (1245/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.3338) | Acc: (89.00%) (2394/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.3213) | Acc: (89.00%) (3550/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.3133) | Acc: (89.00%) (4691/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.3011) | Acc: (89.00%) (5860/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.3083) | Acc: (89.00%) (6994/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.3067) | Acc: (89.00%) (8149/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.3031) | Acc: (89.00%) (9296/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.3034) | Acc: (89.00%) (10439/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.3017) | Acc: (89.00%) (11592/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.3003) | Acc: (89.00%) (12738/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.3005) | Acc: (89.00%) (13884/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.3003) | Acc: (89.00%) (15031/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.3002) | Acc: (89.00%) (16174/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.3019) | Acc: (89.00%) (17311/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.3017) | Acc: (89.00%) (18463/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.3016) | Acc: (89.00%) (19607/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.3004) | Acc: (89.00%) (20780/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.2985) | Acc: (89.00%) (21951/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.3009) | Acc: (89.00%) (23085/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.3036) | Acc: (89.00%) (24208/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.3033) | Acc: (89.00%) (25350/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.3048) | Acc: (89.00%) (26487/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.3041) | Acc: (89.00%) (27647/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.3035) | Acc: (89.00%) (28814/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.3038) | Acc: (89.00%) (29948/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.3044) | Acc: (89.00%) (31081/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.3040) | Acc: (89.00%) (32238/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.3047) | Acc: (89.00%) (33374/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.3044) | Acc: (89.00%) (34532/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.3043) | Acc: (89.00%) (35686/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.3047) | Acc: (89.00%) (36835/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.3047) | Acc: (89.00%) (37970/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.3047) | Acc: (89.00%) (39121/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.3051) | Acc: (89.00%) (40261/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.3058) | Acc: (89.00%) (41393/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.3070) | Acc: (89.00%) (42510/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.3067) | Acc: (89.00%) (43665/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.3084) | Acc: (89.00%) (44747/50000)
# TEST : Loss: (0.3710) | Acc: (87.00%) (8768/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1388e-01,  1.9135e-01, -9.4734e-02],
          [-7.9448e-02,  4.1723e-02, -1.7809e-02],
          [ 4.0633e-02, -2.1632e-01,  2.3275e-01]],

         [[-1.3061e-01,  2.9635e-01,  7.3938e-02],
          [-2.9484e-02,  5.9652e-02, -1.5203e-01],
          [ 7.7644e-02, -2.8555e-01, -3.4334e-02]],

         [[-9.7388e-02,  2.2814e-01, -1.4991e-01],
          [ 9.3174e-02, -1.5313e-01, -7.5618e-02],
          [ 1.2574e-01, -1.7051e-01,  2.0126e-01]]],


        [[[-1.2388e-01, -2.6431e-01, -1.7326e-01],
          [-1.2171e-01,  2.0116e-01,  1.5844e-01],
          [ 1.5656e-01,  6.4060e-02,  1.9533e-01]],

         [[-2.0550e-01, -1.9073e-01, -1.6047e-01],
          [-1.3323e-01,  1.1920e-01,  1.9351e-01],
          [ 2.2147e-01, -1.2609e-02,  6.3781e-02]],

         [[-1.0820e-01,  1.2592e-01, -1.8928e-01],
          [ 9.5848e-02,  2.3485e-01, -1.0540e-01],
          [ 5.8361e-04,  7.6161e-02,  4.5466e-02]]],


        [[[-1.2188e-01,  2.0833e-01,  9.4669e-02],
          [ 1.2068e-01,  1.0501e-01, -9.1354e-02],
          [-1.9063e-01,  1.7061e-02, -2.0694e-01]],

         [[ 7.5317e-02,  6.4600e-02,  2.7747e-02],
          [ 5.9200e-02,  1.9948e-01,  7.5746e-02],
          [-5.9593e-02, -3.2273e-02, -3.0808e-01]],

         [[-7.7211e-02,  6.8566e-02,  1.9991e-01],
          [ 1.7090e-02,  2.1693e-01,  7.9586e-02],
          [-2.0762e-01, -1.7992e-01, -2.2674e-01]]],


        ...,


        [[[-1.6182e-01, -1.5128e-01,  1.1964e-02],
          [ 1.3352e-01, -2.2223e-01, -8.6068e-02],
          [ 1.4397e-01, -6.4281e-02,  7.9418e-02]],

         [[ 1.5077e-01, -1.5410e-02, -6.2711e-03],
          [-7.5690e-02, -3.5001e-01, -2.2744e-01],
          [ 1.1505e-01,  8.0107e-03, -1.1789e-01]],

         [[ 1.9073e-01, -1.0180e-02,  7.8259e-02],
          [-2.2890e-02, -1.6723e-01, -1.5354e-01],
          [ 6.7977e-02, -9.6425e-02, -1.0229e-01]]],


        [[[ 6.3186e-06,  3.2904e-06,  6.2993e-07],
          [-2.2573e-07, -2.3206e-07,  2.7081e-07],
          [-8.1995e-09, -5.5911e-08,  2.8023e-08]],

         [[ 1.7396e-06,  2.4386e-06, -1.4143e-06],
          [-2.0595e-07, -8.1501e-08, -1.4251e-07],
          [-2.2769e-08, -1.2313e-08,  4.9028e-10]],

         [[ 8.1179e-07,  1.9774e-06, -6.8563e-07],
          [-2.8352e-07,  1.2687e-07,  1.5581e-07],
          [ 7.7878e-08,  5.8107e-10, -1.1115e-08]]],


        [[[-6.1880e-41, -4.4530e-41,  6.8439e-42],
          [-2.9182e-41,  4.5539e-41, -3.8743e-41],
          [-1.4010e-41,  2.3444e-42,  3.2917e-41]],

         [[-2.8338e-41, -6.3690e-41, -7.3414e-42],
          [ 5.1178e-41,  1.7096e-43,  2.4629e-41],
          [ 3.4862e-41, -3.2636e-42, -1.8724e-41]],

         [[-5.6795e-41,  5.9276e-41, -6.5875e-42],
          [-6.4754e-42,  2.5334e-41,  5.5323e-41],
          [ 2.5890e-41,  5.5388e-41, -6.5759e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0267,  0.0305,  0.0377],
          [-0.0040,  0.0240,  0.0378],
          [-0.0510, -0.0330, -0.0028]],

         [[-0.0135, -0.0094, -0.0057],
          [-0.0359,  0.0006,  0.0195],
          [-0.0747, -0.0460, -0.0015]],

         [[-0.0289, -0.0376, -0.0156],
          [-0.0371, -0.0050,  0.0142],
          [-0.0524, -0.0157,  0.0133]]],


        [[[-0.0378, -0.0254, -0.0056],
          [-0.0391, -0.0234, -0.0055],
          [-0.0191, -0.0154, -0.0186]],

         [[-0.0040,  0.0003,  0.0144],
          [-0.0118, -0.0024,  0.0113],
          [ 0.0022,  0.0004, -0.0064]],

         [[-0.0026, -0.0001,  0.0114],
          [-0.0124, -0.0047,  0.0086],
          [-0.0029, -0.0058, -0.0103]]],


        [[[ 0.0734,  0.0705,  0.0633],
          [ 0.0847,  0.0710,  0.0620],
          [ 0.0873,  0.0679,  0.0558]],

         [[ 0.0819,  0.0775,  0.0739],
          [ 0.0904,  0.0791,  0.0768],
          [ 0.0892,  0.0717,  0.0635]],

         [[ 0.0510,  0.0397,  0.0340],
          [ 0.0534,  0.0385,  0.0384],
          [ 0.0566,  0.0428,  0.0393]]],


        ...,


        [[[ 0.0108,  0.0121,  0.0165],
          [ 0.0149,  0.0129,  0.0148],
          [ 0.0190,  0.0200,  0.0199]],

         [[-0.0063, -0.0062,  0.0002],
          [-0.0017, -0.0062, -0.0040],
          [ 0.0019,  0.0015, -0.0007]],

         [[-0.0114, -0.0106, -0.0052],
          [-0.0063, -0.0084, -0.0063],
          [ 0.0009,  0.0020,  0.0008]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5524]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 44 | Batch_idx: 0 |  Loss: (0.3358) | Acc: (89.00%) (114/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.2569) | Acc: (92.00%) (1297/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.2571) | Acc: (91.00%) (2466/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.2539) | Acc: (91.00%) (3637/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.2471) | Acc: (91.00%) (4814/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.2500) | Acc: (91.00%) (5982/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.2616) | Acc: (91.00%) (7128/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.2590) | Acc: (91.00%) (8294/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.2563) | Acc: (91.00%) (9481/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.2579) | Acc: (91.00%) (10649/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.2593) | Acc: (91.00%) (11808/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.2630) | Acc: (91.00%) (12962/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.2618) | Acc: (91.00%) (14147/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.2624) | Acc: (91.00%) (15308/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.2634) | Acc: (91.00%) (16473/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.2651) | Acc: (91.00%) (17621/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.2655) | Acc: (91.00%) (18788/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.2654) | Acc: (91.00%) (19953/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.2683) | Acc: (91.00%) (21107/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.2682) | Acc: (91.00%) (22270/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.2675) | Acc: (91.00%) (23427/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.2669) | Acc: (91.00%) (24588/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.2661) | Acc: (91.00%) (25763/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.2661) | Acc: (91.00%) (26919/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.2647) | Acc: (91.00%) (28097/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.2658) | Acc: (91.00%) (29250/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.2683) | Acc: (90.00%) (30385/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.2683) | Acc: (90.00%) (31540/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.2681) | Acc: (90.00%) (32709/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.2693) | Acc: (90.00%) (33852/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.2704) | Acc: (90.00%) (34993/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.2700) | Acc: (90.00%) (36158/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.2704) | Acc: (90.00%) (37312/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.2708) | Acc: (90.00%) (38473/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.2710) | Acc: (90.00%) (39630/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.2716) | Acc: (90.00%) (40772/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.2719) | Acc: (90.00%) (41920/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.2719) | Acc: (90.00%) (43084/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.2723) | Acc: (90.00%) (44229/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.2718) | Acc: (90.00%) (45353/50000)
# TEST : Loss: (0.3580) | Acc: (88.00%) (8842/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1346e-01,  1.9825e-01, -9.8530e-02],
          [-8.0110e-02,  4.8295e-02, -1.8725e-02],
          [ 4.7578e-02, -2.1069e-01,  2.3449e-01]],

         [[-1.2736e-01,  3.1022e-01,  7.8782e-02],
          [-2.6448e-02,  6.8637e-02, -1.4855e-01],
          [ 8.9068e-02, -2.7771e-01, -3.0179e-02]],

         [[-9.9392e-02,  2.3094e-01, -1.5390e-01],
          [ 9.1682e-02, -1.4933e-01, -8.1331e-02],
          [ 1.3350e-01, -1.6245e-01,  2.0057e-01]]],


        [[[-1.1902e-01, -2.6800e-01, -1.7646e-01],
          [-1.2251e-01,  2.0224e-01,  1.6011e-01],
          [ 1.5431e-01,  6.6759e-02,  2.0221e-01]],

         [[-2.0820e-01, -2.0291e-01, -1.7155e-01],
          [-1.4084e-01,  1.1201e-01,  1.8732e-01],
          [ 2.1643e-01, -1.5087e-02,  6.4953e-02]],

         [[-1.1292e-01,  1.1132e-01, -2.0238e-01],
          [ 8.7855e-02,  2.2681e-01, -1.0989e-01],
          [-4.3183e-03,  7.2465e-02,  4.5571e-02]]],


        [[[-1.2215e-01,  2.0802e-01,  9.1913e-02],
          [ 1.1900e-01,  1.0352e-01, -9.5693e-02],
          [-1.9675e-01,  1.1728e-02, -2.1397e-01]],

         [[ 7.9268e-02,  6.8646e-02,  2.6977e-02],
          [ 6.5230e-02,  2.0551e-01,  7.4567e-02],
          [-5.7326e-02, -2.8629e-02, -3.0969e-01]],

         [[-7.0503e-02,  7.6336e-02,  2.0331e-01],
          [ 2.3377e-02,  2.2459e-01,  8.0884e-02],
          [-2.0462e-01, -1.7382e-01, -2.2579e-01]]],


        ...,


        [[[-1.6706e-01, -1.6074e-01,  1.3088e-02],
          [ 1.2655e-01, -2.3827e-01, -9.2826e-02],
          [ 1.4165e-01, -6.9105e-02,  8.0166e-02]],

         [[ 1.5644e-01, -1.1019e-02,  9.1652e-03],
          [-7.2158e-02, -3.4862e-01, -2.1430e-01],
          [ 1.1506e-01,  9.7886e-03, -1.0652e-01]],

         [[ 1.9672e-01, -1.0556e-03,  9.4774e-02],
          [-1.9562e-02, -1.6283e-01, -1.4161e-01],
          [ 6.4568e-02, -9.7991e-02, -9.7510e-02]]],


        [[[ 6.7772e-07,  3.1953e-07,  5.4844e-08],
          [-1.5163e-08, -1.2825e-08,  1.5862e-08],
          [-3.7858e-10, -1.9056e-09,  1.1144e-09]],

         [[ 1.6835e-07,  2.0745e-07, -1.0453e-07],
          [-1.1311e-08, -3.3534e-09, -6.2354e-09],
          [-8.1456e-10, -2.8562e-10,  1.3898e-11]],

         [[ 7.1186e-08,  1.5824e-07, -4.8984e-08],
          [-1.6249e-08,  6.0875e-09,  7.8162e-09],
          [ 3.3671e-09,  1.9392e-11, -4.1081e-10]]],


        [[[ 3.7008e-42, -6.6957e-41, -5.3179e-41],
          [-3.6379e-41, -2.3727e-41,  3.9678e-41],
          [-5.3737e-41, -6.7131e-41,  1.2783e-41]],

         [[-1.8845e-41, -2.6731e-41, -4.7623e-41],
          [-3.8012e-41, -9.6886e-42, -4.9211e-41],
          [-3.3478e-41, -2.5233e-41, -5.0179e-41]],

         [[ 2.0696e-41,  1.5947e-42, -1.6897e-41],
          [ 1.6660e-41, -7.0623e-41,  2.3640e-41],
          [-4.0374e-41, -6.8854e-41, -3.9248e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0392, -0.0664, -0.0726],
          [-0.0525, -0.0795, -0.0766],
          [-0.0335, -0.0596, -0.0630]],

         [[-0.0606, -0.0903, -0.0898],
          [-0.0706, -0.0934, -0.0878],
          [-0.0507, -0.0708, -0.0744]],

         [[-0.0594, -0.0886, -0.0852],
          [-0.0641, -0.0924, -0.0893],
          [-0.0461, -0.0754, -0.0781]]],


        [[[-0.0560, -0.0559, -0.0446],
          [-0.0694, -0.0604, -0.0506],
          [-0.0666, -0.0545, -0.0422]],

         [[-0.0565, -0.0548, -0.0409],
          [-0.0637, -0.0547, -0.0437],
          [-0.0561, -0.0438, -0.0325]],

         [[-0.0479, -0.0468, -0.0333],
          [-0.0509, -0.0427, -0.0322],
          [-0.0393, -0.0275, -0.0175]]],


        [[[ 0.0059,  0.0039, -0.0080],
          [ 0.0170,  0.0082, -0.0054],
          [ 0.0196,  0.0054, -0.0031]],

         [[ 0.0056, -0.0011, -0.0136],
          [ 0.0129,  0.0027, -0.0093],
          [ 0.0105, -0.0028, -0.0091]],

         [[ 0.0054,  0.0008, -0.0071],
          [ 0.0128,  0.0083, -0.0003],
          [ 0.0109,  0.0042,  0.0003]]],


        ...,


        [[[ 0.0032,  0.0036,  0.0056],
          [-0.0084, -0.0065, -0.0040],
          [-0.0188, -0.0160, -0.0117]],

         [[ 0.0037,  0.0053,  0.0087],
          [-0.0060, -0.0029,  0.0002],
          [-0.0129, -0.0097, -0.0058]],

         [[ 0.0039,  0.0063,  0.0109],
          [-0.0029,  0.0002,  0.0028],
          [-0.0069, -0.0046, -0.0018]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5508]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 45 | Batch_idx: 0 |  Loss: (0.2551) | Acc: (90.00%) (116/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.2933) | Acc: (89.00%) (1258/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.2934) | Acc: (89.00%) (2398/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.2928) | Acc: (89.00%) (3552/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.2989) | Acc: (89.00%) (4686/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.3047) | Acc: (89.00%) (5820/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.3059) | Acc: (89.00%) (6978/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.3063) | Acc: (89.00%) (8122/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.3062) | Acc: (89.00%) (9284/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.3049) | Acc: (89.00%) (10436/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.3064) | Acc: (89.00%) (11579/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.3054) | Acc: (89.00%) (12732/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.3014) | Acc: (89.00%) (13907/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.3008) | Acc: (89.00%) (15051/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.2998) | Acc: (89.00%) (16202/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.2986) | Acc: (89.00%) (17365/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.2970) | Acc: (89.00%) (18520/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.2940) | Acc: (89.00%) (19695/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.2915) | Acc: (90.00%) (20869/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.2903) | Acc: (90.00%) (22036/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.2872) | Acc: (90.00%) (23215/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.2856) | Acc: (90.00%) (24397/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.2850) | Acc: (90.00%) (25551/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.2838) | Acc: (90.00%) (26723/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.2824) | Acc: (90.00%) (27896/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.2797) | Acc: (90.00%) (29083/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.2791) | Acc: (90.00%) (30236/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.2787) | Acc: (90.00%) (31382/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.2771) | Acc: (90.00%) (32552/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.2756) | Acc: (90.00%) (33723/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.2743) | Acc: (90.00%) (34897/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.2745) | Acc: (90.00%) (36049/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.2737) | Acc: (90.00%) (37218/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.2741) | Acc: (90.00%) (38380/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.2733) | Acc: (90.00%) (39555/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.2724) | Acc: (90.00%) (40736/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.2718) | Acc: (90.00%) (41912/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.2704) | Acc: (90.00%) (43098/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.2692) | Acc: (90.00%) (44276/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.2674) | Acc: (90.00%) (45433/50000)
# TEST : Loss: (0.3373) | Acc: (88.00%) (8886/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0958e-01,  2.0386e-01, -9.1830e-02],
          [-7.6312e-02,  5.3565e-02, -1.3507e-02],
          [ 5.0169e-02, -2.0721e-01,  2.3678e-01]],

         [[-1.2327e-01,  3.1571e-01,  8.4813e-02],
          [-2.2148e-02,  7.4150e-02, -1.4348e-01],
          [ 9.2384e-02, -2.7347e-01, -2.7618e-02]],

         [[-9.5940e-02,  2.3523e-01, -1.4855e-01],
          [ 9.5193e-02, -1.4419e-01, -7.7383e-02],
          [ 1.3672e-01, -1.5830e-01,  2.0219e-01]]],


        [[[-1.1784e-01, -2.6724e-01, -1.7666e-01],
          [-1.2044e-01,  2.0293e-01,  1.6001e-01],
          [ 1.5588e-01,  6.7533e-02,  2.0135e-01]],

         [[-2.0653e-01, -2.0184e-01, -1.7118e-01],
          [-1.3904e-01,  1.1276e-01,  1.8733e-01],
          [ 2.1677e-01, -1.4973e-02,  6.3902e-02]],

         [[-1.1143e-01,  1.1162e-01, -2.0199e-01],
          [ 8.9369e-02,  2.2742e-01, -1.0915e-01],
          [-3.9412e-03,  7.2337e-02,  4.4622e-02]]],


        [[[-1.2238e-01,  2.0735e-01,  9.1391e-02],
          [ 1.1805e-01,  1.0281e-01, -9.6069e-02],
          [-1.9708e-01,  1.1496e-02, -2.1401e-01]],

         [[ 7.9238e-02,  6.8781e-02,  2.7405e-02],
          [ 6.4718e-02,  2.0498e-01,  7.4419e-02],
          [-5.7189e-02, -2.8128e-02, -3.0894e-01]],

         [[-7.1249e-02,  7.5575e-02,  2.0277e-01],
          [ 2.1569e-02,  2.2263e-01,  7.9612e-02],
          [-2.0538e-01, -1.7438e-01, -2.2642e-01]]],


        ...,


        [[[-1.6752e-01, -1.6084e-01,  1.2925e-02],
          [ 1.2726e-01, -2.3510e-01, -8.9871e-02],
          [ 1.4438e-01, -6.5632e-02,  8.2611e-02]],

         [[ 1.5439e-01, -1.2581e-02,  8.0776e-03],
          [-7.0707e-02, -3.4421e-01, -2.1046e-01],
          [ 1.1735e-01,  1.2115e-02, -1.0385e-01]],

         [[ 1.9357e-01, -3.5791e-03,  9.1897e-02],
          [-1.9373e-02, -1.6249e-01, -1.4135e-01],
          [ 6.5913e-02, -9.6654e-02, -9.6940e-02]]],


        [[[ 4.3279e-08,  1.8017e-08,  2.6967e-09],
          [-5.3803e-10, -3.5568e-10,  4.7345e-10],
          [-8.3610e-12, -2.8600e-11,  2.0358e-11]],

         [[ 9.4518e-09,  9.9077e-09, -4.1833e-09],
          [-3.1122e-10, -6.3977e-11, -1.2863e-10],
          [-1.3005e-11, -2.6185e-12,  1.6479e-13]],

         [[ 3.5320e-09,  6.9991e-09, -1.8784e-09],
          [-4.7186e-10,  1.4117e-10,  1.9177e-10],
          [ 6.8411e-11,  2.8333e-13, -6.8369e-12]]],


        [[[-3.3005e-41,  6.5033e-41,  5.2458e-41],
          [-5.6683e-42,  4.7149e-41, -5.0993e-42],
          [-5.9024e-41, -3.4986e-41,  2.8601e-41]],

         [[ 7.7660e-42,  5.0846e-41,  4.4067e-41],
          [-5.0501e-41,  1.1401e-41,  7.2027e-41],
          [-6.4726e-41, -3.4269e-41,  4.6878e-41]],

         [[ 5.3570e-41, -1.5015e-41, -1.9778e-41],
          [ 6.7531e-41, -4.8122e-41, -2.8320e-42],
          [-5.5697e-41, -6.9590e-41, -2.3816e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5122]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0161]], device='cuda:0')

Epoch: 46 | Batch_idx: 0 |  Loss: (0.2115) | Acc: (92.00%) (119/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.2737) | Acc: (90.00%) (1276/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.2537) | Acc: (91.00%) (2457/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.2516) | Acc: (91.00%) (3634/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.2485) | Acc: (91.00%) (4802/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.2502) | Acc: (91.00%) (5969/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.2495) | Acc: (91.00%) (7142/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.2438) | Acc: (91.00%) (8334/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.2440) | Acc: (91.00%) (9506/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.2451) | Acc: (91.00%) (10677/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.2449) | Acc: (91.00%) (11859/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.2450) | Acc: (91.00%) (13037/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.2461) | Acc: (91.00%) (14209/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.2445) | Acc: (91.00%) (15398/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.2449) | Acc: (91.00%) (16568/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.2455) | Acc: (91.00%) (17731/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.2434) | Acc: (91.00%) (18919/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.2427) | Acc: (91.00%) (20089/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.2441) | Acc: (91.00%) (21248/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.2425) | Acc: (91.00%) (22434/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.2417) | Acc: (91.00%) (23612/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.2409) | Acc: (91.00%) (24792/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.2403) | Acc: (91.00%) (25971/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.2410) | Acc: (91.00%) (27154/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.2401) | Acc: (91.00%) (28344/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.2410) | Acc: (91.00%) (29511/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.2406) | Acc: (91.00%) (30703/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.2407) | Acc: (91.00%) (31882/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.2412) | Acc: (91.00%) (33048/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.2418) | Acc: (91.00%) (34215/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.2418) | Acc: (91.00%) (35390/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.2422) | Acc: (91.00%) (36567/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.2418) | Acc: (91.00%) (37745/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.2422) | Acc: (91.00%) (38910/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.2431) | Acc: (91.00%) (40077/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.2420) | Acc: (91.00%) (41276/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.2418) | Acc: (91.00%) (42451/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.2415) | Acc: (91.00%) (43631/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.2411) | Acc: (91.00%) (44807/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.2409) | Acc: (91.00%) (45948/50000)
# TEST : Loss: (0.3260) | Acc: (89.00%) (8913/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0938e-01,  2.0348e-01, -9.1666e-02],
          [-7.6171e-02,  5.3466e-02, -1.3483e-02],
          [ 5.0077e-02, -2.0682e-01,  2.3635e-01]],

         [[-1.2303e-01,  3.1509e-01,  8.4653e-02],
          [-2.2106e-02,  7.4006e-02, -1.4321e-01],
          [ 9.2209e-02, -2.7292e-01, -2.7565e-02]],

         [[-9.5743e-02,  2.3473e-01, -1.4825e-01],
          [ 9.5000e-02, -1.4389e-01, -7.7225e-02],
          [ 1.3645e-01, -1.5797e-01,  2.0178e-01]]],


        [[[-1.1757e-01, -2.6663e-01, -1.7626e-01],
          [-1.2017e-01,  2.0247e-01,  1.5965e-01],
          [ 1.5551e-01,  6.7373e-02,  2.0086e-01]],

         [[-2.0602e-01, -2.0134e-01, -1.7076e-01],
          [-1.3870e-01,  1.1249e-01,  1.8688e-01],
          [ 2.1625e-01, -1.4936e-02,  6.3743e-02]],

         [[-1.1115e-01,  1.1133e-01, -2.0149e-01],
          [ 8.9148e-02,  2.2685e-01, -1.0888e-01],
          [-3.9314e-03,  7.2155e-02,  4.4508e-02]]],


        [[[-1.2213e-01,  2.0693e-01,  9.1208e-02],
          [ 1.1782e-01,  1.0261e-01, -9.5880e-02],
          [-1.9669e-01,  1.1473e-02, -2.1357e-01]],

         [[ 7.9068e-02,  6.8634e-02,  2.7348e-02],
          [ 6.4584e-02,  2.0456e-01,  7.4264e-02],
          [-5.7072e-02, -2.8069e-02, -3.0828e-01]],

         [[-7.1087e-02,  7.5402e-02,  2.0232e-01],
          [ 2.1521e-02,  2.2213e-01,  7.9431e-02],
          [-2.0492e-01, -1.7398e-01, -2.2589e-01]]],


        ...,


        [[[-1.6666e-01, -1.5974e-01,  1.2836e-02],
          [ 1.2652e-01, -2.3291e-01, -8.8991e-02],
          [ 1.4367e-01, -6.5192e-02,  8.2027e-02]],

         [[ 1.5353e-01, -1.2483e-02,  8.0148e-03],
          [-7.0245e-02, -3.3976e-01, -2.0749e-01],
          [ 1.1671e-01,  1.2015e-02, -1.0294e-01]],

         [[ 1.9249e-01, -3.5540e-03,  9.1259e-02],
          [-1.9249e-02, -1.6096e-01, -1.3999e-01],
          [ 6.5537e-02, -9.5909e-02, -9.6165e-02]]],


        [[[ 1.4408e-09,  5.1255e-10,  6.4507e-11],
          [-8.5005e-12, -4.1012e-12,  5.9976e-12],
          [-7.1952e-14, -1.4935e-13,  1.3715e-13]],

         [[ 2.6742e-10,  2.2841e-10, -7.7044e-11],
          [-3.5523e-12, -4.5585e-13, -1.0138e-12],
          [-7.3583e-14, -7.1800e-15,  6.3308e-16]],

         [[ 8.5457e-11,  1.4637e-10, -3.2766e-11],
          [-5.7708e-12,  1.2936e-12,  1.8893e-12],
          [ 5.2871e-13,  1.4287e-15, -4.0825e-14]]],


        [[[-3.9937e-43, -5.1685e-41, -2.6620e-41],
          [ 3.4031e-41, -1.2680e-41,  4.1359e-41],
          [ 6.8406e-41,  3.6898e-41,  4.1331e-41]],

         [[ 5.7083e-41, -5.1386e-41,  6.6056e-41],
          [-1.2036e-41, -2.2787e-41,  2.4413e-41],
          [-1.4893e-41, -3.4067e-41, -5.8829e-41]],

         [[ 5.7942e-41,  2.4663e-42, -2.1105e-41],
          [ 2.9553e-41, -7.2561e-41, -6.3611e-41],
          [-6.6829e-41, -4.6131e-42, -2.0530e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4974]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0002]], device='cuda:0')

Epoch: 47 | Batch_idx: 0 |  Loss: (0.2235) | Acc: (92.00%) (118/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.2497) | Acc: (91.00%) (1291/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.2439) | Acc: (91.00%) (2466/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.2365) | Acc: (92.00%) (3654/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.2382) | Acc: (92.00%) (4832/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.2346) | Acc: (92.00%) (6017/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.2367) | Acc: (92.00%) (7191/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.2398) | Acc: (91.00%) (8356/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.2375) | Acc: (92.00%) (9539/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.2375) | Acc: (92.00%) (10719/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.2378) | Acc: (92.00%) (11895/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.2353) | Acc: (92.00%) (13088/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.2352) | Acc: (92.00%) (14276/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.2354) | Acc: (92.00%) (15455/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.2369) | Acc: (92.00%) (16618/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.2365) | Acc: (92.00%) (17793/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.2374) | Acc: (91.00%) (18956/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.2370) | Acc: (92.00%) (20137/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.2359) | Acc: (92.00%) (21324/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.2357) | Acc: (92.00%) (22507/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.2366) | Acc: (92.00%) (23687/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.2365) | Acc: (92.00%) (24879/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.2360) | Acc: (92.00%) (26060/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.2359) | Acc: (92.00%) (27234/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.2344) | Acc: (92.00%) (28431/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.2348) | Acc: (92.00%) (29607/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.2345) | Acc: (92.00%) (30801/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.2351) | Acc: (92.00%) (31976/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.2349) | Acc: (92.00%) (33155/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.2343) | Acc: (92.00%) (34344/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.2346) | Acc: (92.00%) (35529/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.2350) | Acc: (92.00%) (36707/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.2352) | Acc: (92.00%) (37879/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.2357) | Acc: (92.00%) (39051/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.2359) | Acc: (92.00%) (40232/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.2366) | Acc: (92.00%) (41401/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.2366) | Acc: (92.00%) (42581/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.2362) | Acc: (92.00%) (43770/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.2367) | Acc: (92.00%) (44944/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.2367) | Acc: (92.00%) (46082/50000)
# TEST : Loss: (0.3187) | Acc: (89.00%) (8942/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.0913e-01,  2.0302e-01, -9.1466e-02],
          [-7.6001e-02,  5.3345e-02, -1.3453e-02],
          [ 4.9965e-02, -2.0634e-01,  2.3583e-01]],

         [[-1.2274e-01,  3.1433e-01,  8.4460e-02],
          [-2.2055e-02,  7.3831e-02, -1.4288e-01],
          [ 9.1997e-02, -2.7225e-01, -2.7501e-02]],

         [[-9.5505e-02,  2.3413e-01, -1.4788e-01],
          [ 9.4766e-02, -1.4353e-01, -7.7032e-02],
          [ 1.3612e-01, -1.5756e-01,  2.0128e-01]]],


        [[[-1.1724e-01, -2.6588e-01, -1.7577e-01],
          [-1.1984e-01,  2.0191e-01,  1.5920e-01],
          [ 1.5507e-01,  6.7179e-02,  2.0028e-01]],

         [[-2.0541e-01, -2.0074e-01, -1.7026e-01],
          [-1.3830e-01,  1.1216e-01,  1.8633e-01],
          [ 2.1561e-01, -1.4892e-02,  6.3550e-02]],

         [[-1.1081e-01,  1.1099e-01, -2.0087e-01],
          [ 8.8879e-02,  2.2616e-01, -1.0854e-01],
          [-3.9196e-03,  7.1935e-02,  4.4371e-02]]],


        [[[-1.2183e-01,  2.0642e-01,  9.0987e-02],
          [ 1.1754e-01,  1.0236e-01, -9.5651e-02],
          [-1.9623e-01,  1.1445e-02, -2.1305e-01]],

         [[ 7.8862e-02,  6.8455e-02,  2.7278e-02],
          [ 6.4422e-02,  2.0404e-01,  7.4075e-02],
          [-5.6929e-02, -2.7997e-02, -3.0748e-01]],

         [[-7.0890e-02,  7.5193e-02,  2.0177e-01],
          [ 2.1462e-02,  2.2152e-01,  7.9212e-02],
          [-2.0435e-01, -1.7349e-01, -2.2524e-01]]],


        ...,


        [[[-1.6562e-01, -1.5842e-01,  1.2730e-02],
          [ 1.2563e-01, -2.3028e-01, -8.7933e-02],
          [ 1.4280e-01, -6.4659e-02,  8.1322e-02]],

         [[ 1.5249e-01, -1.2364e-02,  7.9389e-03],
          [-6.9687e-02, -3.3442e-01, -2.0393e-01],
          [ 1.1593e-01,  1.1894e-02, -1.0184e-01]],

         [[ 1.9120e-01, -3.5237e-03,  9.0489e-02],
          [-1.9099e-02, -1.5912e-01, -1.3835e-01],
          [ 6.5082e-02, -9.5011e-02, -9.5230e-02]]],


        [[[ 2.0984e-11,  6.1056e-12,  6.1516e-13],
          [-4.7449e-14, -1.5190e-14,  2.5117e-14],
          [-1.8154e-16, -1.9424e-16,  2.5037e-16]],

         [[ 3.1633e-12,  2.0773e-12, -5.2450e-13],
          [-1.2983e-14, -8.9635e-16, -2.2778e-15],
          [-1.0652e-16, -3.9141e-18,  5.4532e-19]],

         [[ 8.2701e-13,  1.1742e-12, -2.0792e-13],
          [-2.3083e-14,  3.5448e-15,  5.6948e-15],
          [ 1.1576e-15,  1.7735e-18, -6.3493e-17]]],


        [[[ 1.2019e-41, -6.2355e-41, -6.0920e-41],
          [ 1.3402e-41, -2.0966e-41, -1.4125e-42],
          [-1.9746e-41,  2.4996e-41,  3.6912e-41]],

         [[-2.5795e-41,  2.9335e-41,  5.4314e-41],
          [ 7.0369e-41, -3.8204e-41,  2.4080e-41],
          [ 6.5230e-41,  1.9313e-41, -7.3441e-41]],

         [[ 4.5059e-41,  4.5001e-41,  2.2845e-41],
          [-1.1198e-41, -2.4709e-41, -7.0054e-41],
          [ 1.7909e-41,  2.5441e-41,  2.4516e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4988]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0313]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 48 | Batch_idx: 0 |  Loss: (0.2373) | Acc: (90.00%) (116/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.2381) | Acc: (91.00%) (1291/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.2760) | Acc: (90.00%) (2430/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.3120) | Acc: (89.00%) (3543/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.3442) | Acc: (88.00%) (4621/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.3615) | Acc: (87.00%) (5711/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.3750) | Acc: (87.00%) (6805/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.3767) | Acc: (86.00%) (7902/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.3757) | Acc: (86.00%) (9017/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.3780) | Acc: (86.00%) (10133/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.3752) | Acc: (87.00%) (11265/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.3716) | Acc: (87.00%) (12400/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.3737) | Acc: (87.00%) (13505/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.3732) | Acc: (87.00%) (14621/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.3747) | Acc: (87.00%) (15730/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.3750) | Acc: (87.00%) (16853/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.3739) | Acc: (87.00%) (17977/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.3736) | Acc: (87.00%) (19103/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.3744) | Acc: (87.00%) (20212/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.3743) | Acc: (87.00%) (21334/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.3724) | Acc: (87.00%) (22466/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.3722) | Acc: (87.00%) (23586/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.3702) | Acc: (87.00%) (24720/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.3689) | Acc: (87.00%) (25846/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.3691) | Acc: (87.00%) (26970/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.3685) | Acc: (87.00%) (28094/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.3676) | Acc: (87.00%) (29222/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.3653) | Acc: (87.00%) (30366/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.3643) | Acc: (87.00%) (31510/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.3622) | Acc: (87.00%) (32658/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.3610) | Acc: (87.00%) (33788/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.3609) | Acc: (87.00%) (34913/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.3607) | Acc: (87.00%) (36031/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.3599) | Acc: (87.00%) (37163/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.3596) | Acc: (87.00%) (38281/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.3602) | Acc: (87.00%) (39392/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.3593) | Acc: (87.00%) (40534/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.3587) | Acc: (87.00%) (41670/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.3581) | Acc: (87.00%) (42807/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.3587) | Acc: (87.00%) (43883/50000)
# TEST : Loss: (0.5015) | Acc: (84.00%) (8446/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1325e-01,  2.0022e-01, -1.0186e-01],
          [-7.2612e-02,  4.1671e-02, -1.8141e-02],
          [ 4.5691e-02, -2.0969e-01,  2.5198e-01]],

         [[-1.2138e-01,  3.2111e-01,  8.5788e-02],
          [-1.7665e-02,  6.4956e-02, -1.4203e-01],
          [ 8.6276e-02, -2.7727e-01, -1.1072e-02]],

         [[-9.4186e-02,  2.3346e-01, -1.5544e-01],
          [ 9.7554e-02, -1.5697e-01, -8.3987e-02],
          [ 1.3646e-01, -1.6191e-01,  2.1317e-01]]],


        [[[-1.3858e-01, -2.9192e-01, -1.9362e-01],
          [-1.2984e-01,  1.9051e-01,  1.4900e-01],
          [ 1.5596e-01,  6.0948e-02,  1.8484e-01]],

         [[-2.2313e-01, -2.2506e-01, -1.8516e-01],
          [-1.4639e-01,  1.0272e-01,  1.7833e-01],
          [ 2.1673e-01, -1.9342e-02,  5.1060e-02]],

         [[-1.1766e-01,  9.7394e-02, -2.0417e-01],
          [ 8.7577e-02,  2.2507e-01, -1.0473e-01],
          [ 1.1374e-03,  7.2427e-02,  4.0745e-02]]],


        [[[-1.1880e-01,  2.1575e-01,  9.6136e-02],
          [ 1.3028e-01,  1.1537e-01, -8.8167e-02],
          [-1.9103e-01,  1.5839e-02, -2.0833e-01]],

         [[ 8.1170e-02,  7.3990e-02,  2.7003e-02],
          [ 7.6023e-02,  2.1325e-01,  7.5807e-02],
          [-5.7315e-02, -2.9970e-02, -3.0899e-01]],

         [[-7.1434e-02,  7.7255e-02,  1.9963e-01],
          [ 3.0400e-02,  2.2824e-01,  8.1694e-02],
          [-2.0600e-01, -1.7612e-01, -2.2496e-01]]],


        ...,


        [[[-1.5975e-01, -1.5161e-01,  1.8181e-02],
          [ 1.2835e-01, -2.3631e-01, -9.6024e-02],
          [ 1.3960e-01, -7.7410e-02,  6.7505e-02]],

         [[ 1.4914e-01, -1.9214e-02, -1.7989e-03],
          [-6.6166e-02, -3.4998e-01, -2.2871e-01],
          [ 1.1678e-01, -3.7433e-03, -1.1755e-01]],

         [[ 1.9292e-01,  1.0500e-05,  8.9581e-02],
          [-1.1358e-02, -1.6385e-01, -1.4940e-01],
          [ 7.0130e-02, -1.0248e-01, -1.0396e-01]]],


        [[[ 1.0538e-13,  2.3596e-14,  1.7766e-15],
          [-6.7457e-17, -1.2454e-17,  2.4302e-17],
          [-8.8319e-20, -3.7699e-20,  7.8006e-20]],

         [[ 1.2114e-14,  5.6363e-15, -9.7092e-16],
          [-1.0456e-17, -3.0950e-19, -9.4522e-19],
          [-2.4024e-20, -2.1779e-22,  5.8957e-23]],

         [[ 2.4349e-15,  2.7005e-15, -3.5060e-16],
          [-2.0996e-17,  1.9308e-18,  3.5316e-18],
          [ 4.6356e-19,  3.2232e-22, -1.5830e-20]]],


        [[[-1.1259e-41, -1.1451e-41, -7.5515e-41],
          [-4.4410e-41, -4.7532e-42, -1.5015e-41],
          [-7.1831e-41, -1.0239e-41,  6.6831e-41]],

         [[-4.8495e-41, -2.0441e-41,  4.7067e-41],
          [ 2.3179e-41,  6.7196e-41,  4.9960e-41],
          [-7.0076e-41,  3.5094e-41, -4.2581e-41]],

         [[ 7.7406e-41,  3.9082e-42,  7.1019e-41],
          [ 1.8360e-41,  5.9499e-41, -5.2414e-41],
          [ 2.2365e-41,  1.7948e-41,  2.5718e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0334,  0.0112, -0.0093],
          [-0.0025,  0.0490,  0.0074],
          [ 0.0356,  0.0758,  0.0386]],

         [[-0.0463,  0.0053, -0.0157],
          [-0.0196,  0.0343, -0.0040],
          [ 0.0158,  0.0477,  0.0179]],

         [[-0.0030,  0.0496,  0.0374],
          [ 0.0087,  0.0577,  0.0365],
          [ 0.0393,  0.0644,  0.0404]]],


        [[[ 0.0306,  0.0325,  0.0338],
          [ 0.0275,  0.0344,  0.0399],
          [ 0.0271,  0.0248,  0.0335]],

         [[ 0.0020,  0.0088,  0.0161],
          [ 0.0010,  0.0121,  0.0242],
          [ 0.0052,  0.0063,  0.0189]],

         [[-0.0147, -0.0101, -0.0052],
          [-0.0181, -0.0118, -0.0043],
          [-0.0077, -0.0097, -0.0018]]],


        [[[ 0.0418,  0.0340,  0.0406],
          [ 0.0254,  0.0340,  0.0464],
          [ 0.0129,  0.0310,  0.0388]],

         [[ 0.0125,  0.0020,  0.0100],
          [-0.0064,  0.0001,  0.0143],
          [-0.0180, -0.0012,  0.0107]],

         [[-0.0360, -0.0448, -0.0289],
          [-0.0519, -0.0449, -0.0205],
          [-0.0526, -0.0358, -0.0166]]],


        ...,


        [[[-0.0230, -0.0215, -0.0230],
          [-0.0127, -0.0140, -0.0164],
          [-0.0076, -0.0084, -0.0132]],

         [[-0.0161, -0.0085, -0.0065],
          [-0.0052, -0.0002,  0.0010],
          [-0.0022,  0.0026,  0.0012]],

         [[ 0.0023,  0.0083,  0.0118],
          [ 0.0120,  0.0150,  0.0170],
          [ 0.0136,  0.0168,  0.0164]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4983]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 49 | Batch_idx: 0 |  Loss: (0.2720) | Acc: (90.00%) (116/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.3145) | Acc: (89.00%) (1261/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.3257) | Acc: (88.00%) (2392/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.3264) | Acc: (88.00%) (3526/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.3246) | Acc: (88.00%) (4652/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.3152) | Acc: (88.00%) (5809/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.3115) | Acc: (89.00%) (6958/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.3127) | Acc: (88.00%) (8087/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.3088) | Acc: (89.00%) (9245/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.3081) | Acc: (89.00%) (10392/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.3059) | Acc: (89.00%) (11538/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.3064) | Acc: (89.00%) (12681/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.3025) | Acc: (89.00%) (13845/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.3031) | Acc: (89.00%) (14981/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.3028) | Acc: (89.00%) (16131/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.3025) | Acc: (89.00%) (17279/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.3035) | Acc: (89.00%) (18420/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.3047) | Acc: (89.00%) (19551/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.3046) | Acc: (89.00%) (20687/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.3049) | Acc: (89.00%) (21829/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.3022) | Acc: (89.00%) (23004/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.3014) | Acc: (89.00%) (24164/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.2995) | Acc: (89.00%) (25326/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.2980) | Acc: (89.00%) (26493/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.2965) | Acc: (89.00%) (27664/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.2959) | Acc: (89.00%) (28821/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.2960) | Acc: (89.00%) (29972/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.2964) | Acc: (89.00%) (31126/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.2966) | Acc: (89.00%) (32280/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.2967) | Acc: (89.00%) (33427/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.2956) | Acc: (89.00%) (34605/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.2950) | Acc: (89.00%) (35769/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.2935) | Acc: (89.00%) (36931/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.2930) | Acc: (89.00%) (38088/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.2924) | Acc: (89.00%) (39249/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.2927) | Acc: (89.00%) (40402/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.2913) | Acc: (89.00%) (41579/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.2909) | Acc: (89.00%) (42733/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.2904) | Acc: (90.00%) (43894/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.2896) | Acc: (90.00%) (45025/50000)
# TEST : Loss: (0.3700) | Acc: (87.00%) (8772/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1719e-01,  2.0464e-01, -1.0636e-01],
          [-7.4449e-02,  4.7605e-02, -1.6147e-02],
          [ 5.7042e-02, -2.0932e-01,  2.5047e-01]],

         [[-1.2398e-01,  3.2640e-01,  8.8113e-02],
          [-1.7769e-02,  6.8893e-02, -1.3430e-01],
          [ 9.2175e-02, -2.8427e-01, -1.4298e-02]],

         [[-8.8681e-02,  2.4192e-01, -1.4967e-01],
          [ 1.0618e-01, -1.4349e-01, -7.4912e-02],
          [ 1.5064e-01, -1.5755e-01,  2.1759e-01]]],


        [[[-1.3693e-01, -2.8543e-01, -1.8482e-01],
          [-1.2448e-01,  2.0077e-01,  1.6209e-01],
          [ 1.5895e-01,  6.8610e-02,  1.9388e-01]],

         [[-2.2388e-01, -2.1954e-01, -1.7645e-01],
          [-1.4456e-01,  1.1091e-01,  1.9121e-01],
          [ 2.2307e-01, -8.5494e-03,  6.4393e-02]],

         [[-1.1296e-01,  1.0812e-01, -1.8781e-01],
          [ 9.1065e-02,  2.3754e-01, -8.3498e-02],
          [ 7.8171e-03,  8.6068e-02,  6.0948e-02]]],


        [[[-1.2145e-01,  2.1543e-01,  9.8848e-02],
          [ 1.3149e-01,  1.1335e-01, -8.8092e-02],
          [-1.9426e-01,  1.3345e-02, -2.0964e-01]],

         [[ 7.3153e-02,  7.0113e-02,  2.5334e-02],
          [ 7.5878e-02,  2.0927e-01,  7.1507e-02],
          [-6.2736e-02, -3.6267e-02, -3.1593e-01]],

         [[-8.2191e-02,  6.8379e-02,  1.9256e-01],
          [ 2.5338e-02,  2.1804e-01,  7.1129e-02],
          [-2.1587e-01, -1.8868e-01, -2.3996e-01]]],


        ...,


        [[[-1.5312e-01, -1.4711e-01,  1.9935e-02],
          [ 1.2884e-01, -2.3867e-01, -9.5537e-02],
          [ 1.4223e-01, -7.4015e-02,  7.4997e-02]],

         [[ 1.6321e-01, -1.2513e-02, -3.8888e-03],
          [-5.8200e-02, -3.4896e-01, -2.3272e-01],
          [ 1.2191e-01,  2.2512e-03, -1.0537e-01]],

         [[ 2.0415e-01,  3.0174e-03,  8.6605e-02],
          [-5.3834e-03, -1.6733e-01, -1.5391e-01],
          [ 7.5452e-02, -9.9019e-02, -9.6223e-02]]],


        [[[ 1.3009e-16,  2.0490e-17,  1.0394e-18],
          [-1.4834e-20, -1.2544e-21,  3.1025e-21],
          [-4.1548e-24, -4.3496e-25,  1.8784e-24]],

         [[ 1.0391e-17,  3.0287e-18, -3.0838e-19],
          [-1.0263e-21, -8.7133e-24, -3.5093e-23],
          [-3.5117e-25, -3.0061e-28,  2.6189e-28]],

         [[ 1.4625e-18,  1.1571e-18, -9.7833e-20],
          [-2.4541e-21,  1.0731e-22,  2.3736e-22],
          [ 1.6317e-23,  3.3501e-27, -2.7052e-25]]],


        [[[-4.5094e-41,  1.1855e-41, -7.0341e-41],
          [ 7.2450e-41,  5.2721e-41,  1.3203e-41],
          [-7.2891e-41, -3.3392e-41, -4.3292e-41]],

         [[ 8.6031e-41,  6.4968e-41,  6.4570e-41],
          [-4.0223e-41,  9.4910e-42,  8.1645e-41],
          [ 5.0322e-41, -5.3199e-41,  2.1946e-41]],

         [[ 2.8544e-41, -5.6471e-41, -2.2131e-41],
          [ 7.3965e-41,  7.2369e-41, -2.1890e-41],
          [-5.1283e-41, -7.6650e-41,  7.1966e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0112, -0.0233, -0.0447],
          [ 0.0115,  0.0034, -0.0343],
          [ 0.0416,  0.0084, -0.0155]],

         [[-0.0178, -0.0336, -0.0572],
          [ 0.0004, -0.0053, -0.0431],
          [ 0.0309, -0.0003, -0.0173]],

         [[-0.0025, -0.0194, -0.0450],
          [ 0.0118,  0.0087, -0.0281],
          [ 0.0407,  0.0129, -0.0057]]],


        [[[ 0.0300,  0.0285,  0.0332],
          [ 0.0290,  0.0318,  0.0293],
          [ 0.0292,  0.0315,  0.0249]],

         [[ 0.0380,  0.0357,  0.0410],
          [ 0.0370,  0.0386,  0.0343],
          [ 0.0335,  0.0343,  0.0264]],

         [[ 0.0464,  0.0441,  0.0499],
          [ 0.0459,  0.0473,  0.0437],
          [ 0.0439,  0.0443,  0.0372]]],


        [[[-0.0074, -0.0163, -0.0139],
          [-0.0068, -0.0169, -0.0150],
          [-0.0089, -0.0150, -0.0121]],

         [[-0.0207, -0.0291, -0.0261],
          [-0.0207, -0.0310, -0.0280],
          [-0.0273, -0.0324, -0.0270]],

         [[-0.0312, -0.0376, -0.0337],
          [-0.0314, -0.0380, -0.0337],
          [-0.0359, -0.0373, -0.0309]]],


        ...,


        [[[ 0.0095,  0.0061, -0.0025],
          [ 0.0061,  0.0039, -0.0007],
          [ 0.0150,  0.0132,  0.0093]],

         [[ 0.0072,  0.0051, -0.0028],
          [ 0.0039,  0.0024, -0.0019],
          [ 0.0135,  0.0117,  0.0077]],

         [[ 0.0078,  0.0073, -0.0001],
          [ 0.0067,  0.0058,  0.0018],
          [ 0.0155,  0.0136,  0.0095]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4972]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 50 | Batch_idx: 0 |  Loss: (0.2517) | Acc: (90.00%) (116/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.2793) | Acc: (90.00%) (1270/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.2685) | Acc: (90.00%) (2430/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.2667) | Acc: (90.00%) (3596/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.2664) | Acc: (90.00%) (4752/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.2700) | Acc: (90.00%) (5914/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.2695) | Acc: (90.00%) (7073/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.2656) | Acc: (90.00%) (8245/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.2627) | Acc: (90.00%) (9427/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.2626) | Acc: (90.00%) (10598/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.2611) | Acc: (91.00%) (11771/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.2584) | Acc: (91.00%) (12945/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.2595) | Acc: (91.00%) (14101/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.2610) | Acc: (91.00%) (15263/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.2622) | Acc: (90.00%) (16416/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.2638) | Acc: (90.00%) (17572/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.2647) | Acc: (90.00%) (18732/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.2646) | Acc: (90.00%) (19896/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.2661) | Acc: (90.00%) (21052/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.2663) | Acc: (90.00%) (22205/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.2662) | Acc: (90.00%) (23365/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.2650) | Acc: (90.00%) (24543/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.2663) | Acc: (90.00%) (25695/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.2664) | Acc: (90.00%) (26854/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.2669) | Acc: (90.00%) (28019/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.2668) | Acc: (90.00%) (29169/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.2655) | Acc: (90.00%) (30355/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.2664) | Acc: (90.00%) (31495/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.2660) | Acc: (90.00%) (32660/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.2664) | Acc: (90.00%) (33819/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.2671) | Acc: (90.00%) (34975/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.2662) | Acc: (90.00%) (36142/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.2652) | Acc: (90.00%) (37322/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.2647) | Acc: (90.00%) (38498/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.2647) | Acc: (90.00%) (39660/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.2643) | Acc: (90.00%) (40831/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.2640) | Acc: (90.00%) (42002/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.2634) | Acc: (90.00%) (43178/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.2628) | Acc: (90.00%) (44357/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.2631) | Acc: (90.00%) (45481/50000)
# TEST : Loss: (0.3690) | Acc: (88.00%) (8825/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1576e-01,  2.0287e-01, -1.1045e-01],
          [-7.4197e-02,  4.1885e-02, -2.1863e-02],
          [ 4.3773e-02, -2.2311e-01,  2.4737e-01]],

         [[-1.1970e-01,  3.2628e-01,  8.6702e-02],
          [-1.6911e-02,  5.7861e-02, -1.4010e-01],
          [ 8.2394e-02, -3.0228e-01, -1.8538e-02]],

         [[-8.2626e-02,  2.4217e-01, -1.4121e-01],
          [ 1.0702e-01, -1.4591e-01, -7.0804e-02],
          [ 1.4943e-01, -1.5732e-01,  2.2647e-01]]],


        [[[-1.3383e-01, -2.8244e-01, -1.7804e-01],
          [-1.2076e-01,  2.0670e-01,  1.6963e-01],
          [ 1.6524e-01,  7.5861e-02,  1.9903e-01]],

         [[-2.2745e-01, -2.2274e-01, -1.7789e-01],
          [-1.4432e-01,  1.1291e-01,  1.9395e-01],
          [ 2.2502e-01, -6.6656e-03,  6.5585e-02]],

         [[-1.2481e-01,  9.3368e-02, -2.0159e-01],
          [ 8.4385e-02,  2.2886e-01, -9.1076e-02],
          [ 3.0843e-03,  7.8878e-02,  5.4363e-02]]],


        [[[-1.1943e-01,  2.1763e-01,  1.0243e-01],
          [ 1.3873e-01,  1.1893e-01, -8.5075e-02],
          [-1.9327e-01,  1.0795e-02, -2.0968e-01]],

         [[ 7.4271e-02,  7.4034e-02,  3.1846e-02],
          [ 8.4752e-02,  2.1676e-01,  7.7513e-02],
          [-5.9154e-02, -3.6019e-02, -3.1158e-01]],

         [[-8.2174e-02,  7.1300e-02,  1.9983e-01],
          [ 3.0363e-02,  2.2170e-01,  7.6988e-02],
          [-2.1451e-01, -1.9074e-01, -2.3694e-01]]],


        ...,


        [[[-1.5078e-01, -1.4139e-01,  9.0369e-03],
          [ 1.2214e-01, -2.3814e-01, -1.0565e-01],
          [ 1.3561e-01, -7.0156e-02,  7.2619e-02]],

         [[ 1.6384e-01, -1.2803e-02, -2.7039e-02],
          [-6.6286e-02, -3.5906e-01, -2.6415e-01],
          [ 1.1309e-01, -6.0962e-04, -1.1753e-01]],

         [[ 2.0531e-01,  5.4980e-03,  7.2975e-02],
          [-1.1796e-02, -1.7174e-01, -1.6777e-01],
          [ 6.9360e-02, -9.9253e-02, -1.0456e-01]]],


        [[[ 2.3460e-20,  2.2412e-21,  6.4157e-23],
          [-2.0840e-25, -4.9431e-27,  1.8182e-26],
          [-4.1835e-30, -1.4556e-32,  4.7431e-31]],

         [[ 1.1166e-21,  1.6500e-22, -7.6469e-24],
          [-3.8711e-27, -3.1084e-30, -2.2245e-29],
          [-2.5037e-32,  1.4643e-37, -1.4651e-36]],

         [[ 9.3811e-23,  4.5067e-23, -1.9897e-24],
          [-1.2423e-26,  1.4777e-28,  4.6211e-28],
          [ 9.2875e-30,  7.5131e-35, -2.9662e-32]]],


        [[[-3.1892e-41,  8.2146e-41, -4.6373e-41],
          [ 7.3116e-41,  5.3738e-41, -2.1911e-41],
          [-3.4381e-41, -4.8954e-41, -2.1251e-41]],

         [[-9.1019e-41, -7.0006e-41, -1.4237e-41],
          [-8.1408e-41, -1.5029e-41,  7.6245e-41],
          [-5.0119e-41, -2.8294e-41,  7.9709e-41]],

         [[-9.2510e-41, -6.8071e-41,  3.1043e-41],
          [-5.8192e-41,  5.1817e-41, -1.6471e-41],
          [ 8.2057e-41,  2.4825e-41,  3.2349e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0185, -0.0331, -0.0022],
          [-0.0034, -0.0369, -0.0065],
          [-0.0105, -0.0558, -0.0482]],

         [[-0.0111, -0.0294, -0.0080],
          [ 0.0053, -0.0327, -0.0101],
          [-0.0006, -0.0475, -0.0456]],

         [[ 0.0007, -0.0138, -0.0055],
          [ 0.0117, -0.0180, -0.0067],
          [ 0.0084, -0.0287, -0.0346]]],


        [[[ 0.0169,  0.0110,  0.0022],
          [ 0.0176,  0.0108,  0.0032],
          [ 0.0188,  0.0221,  0.0137]],

         [[ 0.0102, -0.0005, -0.0108],
          [ 0.0075, -0.0021, -0.0104],
          [ 0.0074,  0.0075, -0.0017]],

         [[ 0.0029, -0.0077, -0.0171],
          [-0.0035, -0.0129, -0.0205],
          [-0.0063, -0.0058, -0.0144]]],


        [[[ 0.0402,  0.0428,  0.0374],
          [ 0.0422,  0.0379,  0.0310],
          [ 0.0510,  0.0417,  0.0361]],

         [[ 0.0480,  0.0490,  0.0422],
          [ 0.0505,  0.0446,  0.0336],
          [ 0.0569,  0.0466,  0.0388]],

         [[ 0.0421,  0.0411,  0.0338],
          [ 0.0404,  0.0331,  0.0233],
          [ 0.0461,  0.0360,  0.0292]]],


        ...,


        [[[ 0.0014,  0.0031,  0.0048],
          [-0.0042, -0.0053, -0.0041],
          [-0.0065, -0.0062, -0.0073]],

         [[ 0.0023,  0.0051,  0.0084],
          [-0.0034, -0.0021,  0.0013],
          [-0.0063, -0.0032, -0.0018]],

         [[ 0.0014,  0.0057,  0.0084],
          [-0.0029,  0.0004,  0.0030],
          [-0.0065, -0.0017, -0.0003]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4958]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 51 | Batch_idx: 0 |  Loss: (0.1966) | Acc: (93.00%) (120/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.2401) | Acc: (91.00%) (1293/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.2580) | Acc: (91.00%) (2459/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.2596) | Acc: (91.00%) (3625/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.2753) | Acc: (90.00%) (4768/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.2838) | Acc: (90.00%) (5909/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.2749) | Acc: (90.00%) (7094/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.2743) | Acc: (90.00%) (8257/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.2748) | Acc: (90.00%) (9406/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.2767) | Acc: (90.00%) (10564/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.2778) | Acc: (90.00%) (11716/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.2770) | Acc: (90.00%) (12876/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.2742) | Acc: (90.00%) (14052/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.2732) | Acc: (90.00%) (15224/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.2741) | Acc: (90.00%) (16370/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.2721) | Acc: (90.00%) (17539/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.2725) | Acc: (90.00%) (18699/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.2707) | Acc: (90.00%) (19868/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.2703) | Acc: (90.00%) (21038/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.2678) | Acc: (90.00%) (22218/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.2669) | Acc: (90.00%) (23381/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.2647) | Acc: (90.00%) (24562/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.2637) | Acc: (90.00%) (25736/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.2620) | Acc: (91.00%) (26915/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.2615) | Acc: (91.00%) (28089/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.2600) | Acc: (91.00%) (29276/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.2581) | Acc: (91.00%) (30470/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.2573) | Acc: (91.00%) (31638/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.2574) | Acc: (91.00%) (32795/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.2572) | Acc: (91.00%) (33972/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.2557) | Acc: (91.00%) (35163/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.2550) | Acc: (91.00%) (36342/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.2541) | Acc: (91.00%) (37524/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.2538) | Acc: (91.00%) (38694/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.2534) | Acc: (91.00%) (39856/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.2528) | Acc: (91.00%) (41043/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.2526) | Acc: (91.00%) (42225/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.2510) | Acc: (91.00%) (43422/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.2505) | Acc: (91.00%) (44601/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.2502) | Acc: (91.00%) (45730/50000)
# TEST : Loss: (0.3252) | Acc: (89.00%) (8954/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1198e-01,  2.0533e-01, -1.0694e-01],
          [-7.0167e-02,  4.5056e-02, -1.9068e-02],
          [ 4.5135e-02, -2.1987e-01,  2.5037e-01]],

         [[-1.1625e-01,  3.2857e-01,  8.9643e-02],
          [-1.3802e-02,  6.0748e-02, -1.3813e-01],
          [ 8.2391e-02, -3.0021e-01, -1.6562e-02]],

         [[-7.9962e-02,  2.4405e-01, -1.3834e-01],
          [ 1.0923e-01, -1.4372e-01, -6.9708e-02],
          [ 1.4890e-01, -1.5652e-01,  2.2734e-01]]],


        [[[-1.3358e-01, -2.8179e-01, -1.7704e-01],
          [-1.2081e-01,  2.0607e-01,  1.6953e-01],
          [ 1.6528e-01,  7.5613e-02,  1.9870e-01]],

         [[-2.2758e-01, -2.2237e-01, -1.7709e-01],
          [-1.4473e-01,  1.1249e-01,  1.9377e-01],
          [ 2.2458e-01, -6.6475e-03,  6.5478e-02]],

         [[-1.2576e-01,  9.2609e-02, -2.0121e-01],
          [ 8.3018e-02,  2.2789e-01, -9.0859e-02],
          [ 2.8554e-03,  7.8480e-02,  5.4272e-02]]],


        [[[-1.1972e-01,  2.1708e-01,  1.0257e-01],
          [ 1.3916e-01,  1.1957e-01, -8.3841e-02],
          [-1.9312e-01,  1.0844e-02, -2.0880e-01]],

         [[ 7.3046e-02,  7.3060e-02,  3.1595e-02],
          [ 8.4493e-02,  2.1651e-01,  7.7921e-02],
          [-5.9734e-02, -3.6311e-02, -3.1096e-01]],

         [[-8.2323e-02,  7.0982e-02,  1.9989e-01],
          [ 3.0829e-02,  2.2193e-01,  7.7922e-02],
          [-2.1420e-01, -1.9027e-01, -2.3579e-01]]],


        ...,


        [[[-1.5162e-01, -1.4209e-01,  6.0529e-03],
          [ 1.1978e-01, -2.3642e-01, -1.0653e-01],
          [ 1.3194e-01, -7.1758e-02,  6.9889e-02]],

         [[ 1.6085e-01, -1.5628e-02, -3.1516e-02],
          [-6.8122e-02, -3.5691e-01, -2.6534e-01],
          [ 1.0934e-01, -3.6210e-03, -1.1997e-01]],

         [[ 2.0154e-01,  2.5932e-03,  6.8805e-02],
          [-1.4187e-02, -1.7193e-01, -1.6875e-01],
          [ 6.5653e-02, -1.0133e-01, -1.0635e-01]]],


        [[[ 2.4083e-25,  1.0151e-26,  1.0710e-28],
          [-1.3224e-32,  2.7493e-35, -6.6111e-35],
          [-1.9417e-39, -7.4899e-42,  2.6161e-40]],

         [[ 4.9094e-27,  2.1898e-28, -2.0632e-30],
          [ 2.1165e-35, -2.6963e-39, -2.3221e-38],
          [ 6.3196e-41, -3.2628e-41, -6.1335e-41]],

         [[ 1.6791e-28,  3.1432e-29, -3.3833e-31],
          [ 6.3518e-35, -7.0675e-38, -9.6445e-37],
          [ 9.9076e-39,  5.1268e-41,  2.9076e-41]]],


        [[[ 6.1939e-41, -4.6541e-41,  5.6010e-41],
          [ 5.5489e-41,  3.9152e-42,  7.8512e-41],
          [ 1.0520e-41, -8.2496e-41,  8.5321e-41]],

         [[ 3.9222e-41, -8.1024e-41,  2.7821e-41],
          [-5.9033e-41,  7.3511e-41,  7.3918e-41],
          [ 7.3694e-41,  8.7147e-41,  2.3061e-41]],

         [[ 9.2092e-41,  7.9470e-41, -2.8591e-41],
          [ 3.2126e-41,  9.4987e-41, -7.7747e-41],
          [-4.0610e-41, -3.6247e-41,  1.9534e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5658]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0053]], device='cuda:0')

Epoch: 52 | Batch_idx: 0 |  Loss: (0.1545) | Acc: (94.00%) (121/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.2109) | Acc: (92.00%) (1306/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.2068) | Acc: (92.00%) (2499/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.2224) | Acc: (92.00%) (3664/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.2287) | Acc: (92.00%) (4838/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.2281) | Acc: (92.00%) (6023/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.2219) | Acc: (92.00%) (7222/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.2178) | Acc: (92.00%) (8414/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.2175) | Acc: (92.00%) (9604/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.2220) | Acc: (92.00%) (10772/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.2220) | Acc: (92.00%) (11963/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.2227) | Acc: (92.00%) (13139/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.2216) | Acc: (92.00%) (14333/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.2230) | Acc: (92.00%) (15510/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.2222) | Acc: (92.00%) (16709/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.2226) | Acc: (92.00%) (17901/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.2226) | Acc: (92.00%) (19078/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.2234) | Acc: (92.00%) (20259/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.2237) | Acc: (92.00%) (21438/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.2227) | Acc: (92.00%) (22636/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.2236) | Acc: (92.00%) (23801/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.2230) | Acc: (92.00%) (24989/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.2232) | Acc: (92.00%) (26174/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.2234) | Acc: (92.00%) (27355/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.2225) | Acc: (92.00%) (28545/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.2231) | Acc: (92.00%) (29727/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.2237) | Acc: (92.00%) (30908/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.2241) | Acc: (92.00%) (32085/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.2236) | Acc: (92.00%) (33275/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.2240) | Acc: (92.00%) (34457/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.2238) | Acc: (92.00%) (35642/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.2237) | Acc: (92.00%) (36827/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.2241) | Acc: (92.00%) (38000/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.2240) | Acc: (92.00%) (39185/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.2247) | Acc: (92.00%) (40356/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.2243) | Acc: (92.00%) (41536/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.2244) | Acc: (92.00%) (42706/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.2240) | Acc: (92.00%) (43901/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.2251) | Acc: (92.00%) (45064/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.2247) | Acc: (92.00%) (46204/50000)
# TEST : Loss: (0.3113) | Acc: (89.00%) (8975/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1174e-01,  2.0490e-01, -1.0673e-01],
          [-7.0023e-02,  4.4961e-02, -1.9029e-02],
          [ 4.5040e-02, -2.1939e-01,  2.4986e-01]],

         [[-1.1600e-01,  3.2784e-01,  8.9456e-02],
          [-1.3773e-02,  6.0615e-02, -1.3784e-01],
          [ 8.2216e-02, -2.9955e-01, -1.6527e-02]],

         [[-7.9782e-02,  2.4348e-01, -1.3803e-01],
          [ 1.0899e-01, -1.4339e-01, -6.9553e-02],
          [ 1.4857e-01, -1.5616e-01,  2.2684e-01]]],


        [[[-1.3324e-01, -2.8106e-01, -1.7659e-01],
          [-1.2050e-01,  2.0556e-01,  1.6910e-01],
          [ 1.6485e-01,  7.5416e-02,  1.9818e-01]],

         [[-2.2698e-01, -2.2178e-01, -1.7663e-01],
          [-1.4435e-01,  1.1219e-01,  1.9326e-01],
          [ 2.2398e-01, -6.6296e-03,  6.5300e-02]],

         [[-1.2542e-01,  9.2354e-02, -2.0066e-01],
          [ 8.2792e-02,  2.2727e-01, -9.0610e-02],
          [ 2.8475e-03,  7.8261e-02,  5.4118e-02]]],


        [[[-1.1948e-01,  2.1665e-01,  1.0236e-01],
          [ 1.3889e-01,  1.1934e-01, -8.3678e-02],
          [-1.9273e-01,  1.0822e-02, -2.0838e-01]],

         [[ 7.2896e-02,  7.2910e-02,  3.1531e-02],
          [ 8.4323e-02,  2.1607e-01,  7.7765e-02],
          [-5.9613e-02, -3.6237e-02, -3.1032e-01]],

         [[-8.2150e-02,  7.0833e-02,  1.9947e-01],
          [ 3.0764e-02,  2.2147e-01,  7.7759e-02],
          [-2.1375e-01, -1.8986e-01, -2.3528e-01]]],


        ...,


        [[[-1.5081e-01, -1.4107e-01,  6.0098e-03],
          [ 1.1904e-01, -2.3403e-01, -1.0541e-01],
          [ 1.3124e-01, -7.1230e-02,  6.9348e-02]],

         [[ 1.5991e-01, -1.5496e-02, -3.1252e-02],
          [-6.7659e-02, -3.5196e-01, -2.6142e-01],
          [ 1.0870e-01, -3.5892e-03, -1.1885e-01]],

         [[ 2.0039e-01,  2.5746e-03,  6.8314e-02],
          [-1.4097e-02, -1.7037e-01, -1.6720e-01],
          [ 6.5275e-02, -1.0055e-01, -1.0552e-01]]],


        [[[ 5.1295e-33, -5.6457e-35, -1.3976e-37],
          [ 6.0368e-41,  6.7355e-41,  1.6482e-41],
          [ 8.6320e-42,  1.6842e-41,  3.5994e-41]],

         [[-2.7526e-35, -7.4687e-38, -1.2312e-39],
          [ 6.6119e-41, -3.2135e-41,  5.1742e-41],
          [ 4.0498e-41,  1.4313e-41, -6.7585e-41]],

         [[-2.7663e-37,  3.1158e-38, -7.8263e-42],
          [ 2.3312e-41,  2.8284e-41,  3.9105e-41],
          [-5.0640e-41,  3.1845e-41, -2.1808e-41]]],


        [[[-8.0524e-41,  3.6069e-41, -2.3176e-41],
          [-7.4056e-41, -8.7606e-41, -1.7672e-41],
          [ 9.4418e-41, -3.3885e-41,  2.7702e-41]],

         [[ 8.1078e-41, -8.2588e-41,  4.7054e-41],
          [-5.8364e-41, -7.3457e-41, -1.0325e-41],
          [-5.9707e-41, -8.4696e-41, -7.9440e-42]],

         [[-7.9906e-41, -5.6136e-41, -3.4119e-41],
          [-5.7553e-41,  5.8347e-41, -3.8347e-41],
          [-8.4044e-41,  2.5979e-41,  2.9238e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5746]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0137]], device='cuda:0')

Epoch: 53 | Batch_idx: 0 |  Loss: (0.3179) | Acc: (89.00%) (115/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.2151) | Acc: (92.00%) (1302/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.2139) | Acc: (92.00%) (2497/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.2166) | Acc: (92.00%) (3675/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.2139) | Acc: (92.00%) (4868/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.2124) | Acc: (92.00%) (6057/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.2151) | Acc: (92.00%) (7244/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.2183) | Acc: (92.00%) (8418/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.2197) | Acc: (92.00%) (9606/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.2200) | Acc: (92.00%) (10792/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.2186) | Acc: (92.00%) (11983/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.2187) | Acc: (92.00%) (13173/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.2197) | Acc: (92.00%) (14355/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.2202) | Acc: (92.00%) (15536/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.2189) | Acc: (92.00%) (16729/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.2179) | Acc: (92.00%) (17929/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.2179) | Acc: (92.00%) (19119/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.2185) | Acc: (92.00%) (20304/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.2202) | Acc: (92.00%) (21478/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.2207) | Acc: (92.00%) (22657/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.2215) | Acc: (92.00%) (23832/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.2213) | Acc: (92.00%) (25016/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.2219) | Acc: (92.00%) (26189/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.2212) | Acc: (92.00%) (27388/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.2204) | Acc: (92.00%) (28583/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.2208) | Acc: (92.00%) (29761/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.2204) | Acc: (92.00%) (30958/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.2203) | Acc: (92.00%) (32149/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.2199) | Acc: (92.00%) (33343/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.2198) | Acc: (92.00%) (34529/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.2199) | Acc: (92.00%) (35711/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.2195) | Acc: (92.00%) (36902/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.2187) | Acc: (92.00%) (38100/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.2187) | Acc: (92.00%) (39276/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.2189) | Acc: (92.00%) (40453/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.2191) | Acc: (92.00%) (41634/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.2186) | Acc: (92.00%) (42828/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.2187) | Acc: (92.00%) (44006/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.2191) | Acc: (92.00%) (45187/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.2202) | Acc: (92.00%) (46309/50000)
# TEST : Loss: (0.3072) | Acc: (89.00%) (8971/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1146e-01,  2.0437e-01, -1.0646e-01],
          [-6.9847e-02,  4.4846e-02, -1.8981e-02],
          [ 4.4926e-02, -2.1882e-01,  2.4923e-01]],

         [[-1.1569e-01,  3.2696e-01,  8.9229e-02],
          [-1.3737e-02,  6.0453e-02, -1.3748e-01],
          [ 8.2003e-02, -2.9873e-01, -1.6484e-02]],

         [[-7.9564e-02,  2.4280e-01, -1.3766e-01],
          [ 1.0870e-01, -1.4299e-01, -6.9366e-02],
          [ 1.4817e-01, -1.5572e-01,  2.2623e-01]]],


        [[[-1.3282e-01, -2.8019e-01, -1.7605e-01],
          [-1.2013e-01,  2.0493e-01,  1.6858e-01],
          [ 1.6433e-01,  7.5177e-02,  1.9755e-01]],

         [[-2.2625e-01, -2.2106e-01, -1.7606e-01],
          [-1.4389e-01,  1.1184e-01,  1.9265e-01],
          [ 2.2325e-01, -6.6078e-03,  6.5083e-02]],

         [[-1.2500e-01,  9.2045e-02, -1.9999e-01],
          [ 8.2518e-02,  2.2651e-01, -9.0308e-02],
          [ 2.8379e-03,  7.7995e-02,  5.3932e-02]]],


        [[[-1.1919e-01,  2.1612e-01,  1.0211e-01],
          [ 1.3855e-01,  1.1905e-01, -8.3479e-02],
          [-1.9227e-01,  1.0796e-02, -2.0788e-01]],

         [[ 7.2716e-02,  7.2729e-02,  3.1453e-02],
          [ 8.4116e-02,  2.1555e-01,  7.7576e-02],
          [-5.9467e-02, -3.6148e-02, -3.0955e-01]],

         [[-8.1941e-02,  7.0653e-02,  1.9896e-01],
          [ 3.0686e-02,  2.2091e-01,  7.7560e-02],
          [-2.1319e-01, -1.8936e-01, -2.3465e-01]]],


        ...,


        [[[-1.4982e-01, -1.3983e-01,  5.9577e-03],
          [ 1.1815e-01, -2.3116e-01, -1.0407e-01],
          [ 1.3038e-01, -7.0593e-02,  6.8696e-02]],

         [[ 1.5878e-01, -1.5338e-02, -3.0934e-02],
          [-6.7100e-02, -3.4602e-01, -2.5673e-01],
          [ 1.0794e-01, -3.5509e-03, -1.1750e-01]],

         [[ 1.9901e-01,  2.5520e-03,  6.7720e-02],
          [-1.3987e-02, -1.6849e-01, -1.6534e-01],
          [ 6.4818e-02, -9.9619e-02, -1.0452e-01]]],


        [[[ 3.8568e-41, -5.6034e-41,  5.4386e-41],
          [ 4.6051e-41, -6.6555e-41,  1.7803e-41],
          [ 6.4526e-41, -3.5241e-41,  1.5486e-41]],

         [[-3.6065e-41,  1.6968e-41, -6.5904e-41],
          [ 6.5301e-41, -3.2716e-41, -1.3939e-41],
          [-1.3307e-41, -6.1233e-41,  4.6142e-41]],

         [[ 4.2719e-41, -5.9170e-41, -3.1015e-41],
          [ 3.0571e-41, -1.9523e-41,  6.8575e-41],
          [ 2.0766e-41, -1.3685e-41,  5.5870e-41]]],


        [[[-8.3999e-41, -3.1074e-41, -6.4254e-41],
          [-2.3906e-41,  2.8816e-41, -3.8044e-41],
          [-9.9621e-41,  7.5900e-41, -4.4222e-41]],

         [[ 8.0649e-41, -9.4043e-41, -8.9892e-41],
          [ 7.0670e-41, -4.2378e-41, -4.7504e-41],
          [-8.4540e-41,  1.2504e-41,  3.3620e-41]],

         [[ 6.0881e-41, -4.8090e-41, -2.9981e-41],
          [ 6.3623e-41, -1.3530e-41,  1.0125e-40],
          [-8.8994e-41, -2.8728e-41,  1.3277e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5839]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0056]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 54 | Batch_idx: 0 |  Loss: (0.2266) | Acc: (90.00%) (116/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.2344) | Acc: (92.00%) (1304/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.2756) | Acc: (90.00%) (2444/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3036) | Acc: (90.00%) (3582/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3270) | Acc: (89.00%) (4688/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.3358) | Acc: (89.00%) (5818/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.3399) | Acc: (88.00%) (6929/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.3486) | Acc: (88.00%) (8031/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.3514) | Acc: (88.00%) (9150/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.3513) | Acc: (88.00%) (10272/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.3513) | Acc: (88.00%) (11399/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.3520) | Acc: (88.00%) (12529/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.3518) | Acc: (88.00%) (13656/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.3508) | Acc: (88.00%) (14786/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.3531) | Acc: (88.00%) (15895/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.3570) | Acc: (87.00%) (17000/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.3575) | Acc: (87.00%) (18125/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.3569) | Acc: (87.00%) (19249/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.3564) | Acc: (87.00%) (20361/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.3563) | Acc: (87.00%) (21486/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.3549) | Acc: (87.00%) (22611/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.3543) | Acc: (87.00%) (23750/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.3540) | Acc: (87.00%) (24878/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.3534) | Acc: (87.00%) (26013/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.3528) | Acc: (87.00%) (27146/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.3539) | Acc: (87.00%) (28258/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.3536) | Acc: (88.00%) (29403/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.3517) | Acc: (88.00%) (30551/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.3508) | Acc: (88.00%) (31685/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.3491) | Acc: (88.00%) (32836/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.3487) | Acc: (88.00%) (33961/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.3482) | Acc: (88.00%) (35090/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.3456) | Acc: (88.00%) (36260/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.3440) | Acc: (88.00%) (37410/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.3448) | Acc: (88.00%) (38544/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.3426) | Acc: (88.00%) (39716/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.3422) | Acc: (88.00%) (40860/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.3409) | Acc: (88.00%) (42023/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.3405) | Acc: (88.00%) (43157/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.3398) | Acc: (88.00%) (44256/50000)
# TEST : Loss: (0.4584) | Acc: (85.00%) (8576/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2980e-01,  2.1510e-01, -1.0224e-01],
          [-8.6921e-02,  3.9561e-02, -1.2782e-02],
          [ 4.8911e-02, -2.1186e-01,  2.6492e-01]],

         [[-1.3094e-01,  3.3300e-01,  8.7620e-02],
          [-2.8884e-02,  4.3570e-02, -1.4170e-01],
          [ 8.0790e-02, -3.0882e-01, -1.9038e-02]],

         [[-1.0564e-01,  2.3317e-01, -1.4367e-01],
          [ 8.1389e-02, -1.6894e-01, -8.2616e-02],
          [ 1.4478e-01, -1.6746e-01,  2.0788e-01]]],


        [[[-1.4116e-01, -2.8764e-01, -1.8545e-01],
          [-1.2106e-01,  2.1180e-01,  1.6921e-01],
          [ 1.6487e-01,  8.0413e-02,  1.9746e-01]],

         [[-2.3222e-01, -2.2203e-01, -1.7769e-01],
          [-1.4809e-01,  1.1977e-01,  1.9597e-01],
          [ 2.2478e-01,  3.0250e-03,  7.0517e-02]],

         [[-1.2874e-01,  8.9768e-02, -2.0582e-01],
          [ 7.5978e-02,  2.2707e-01, -9.4760e-02],
          [-7.4342e-04,  7.9769e-02,  5.2591e-02]]],


        [[[-1.2872e-01,  2.1826e-01,  9.9587e-02],
          [ 1.3253e-01,  1.2248e-01, -8.3329e-02],
          [-2.0143e-01,  6.0182e-03, -2.1479e-01]],

         [[ 5.8042e-02,  7.2699e-02,  2.5884e-02],
          [ 7.4051e-02,  2.1588e-01,  7.2613e-02],
          [-7.2160e-02, -4.3577e-02, -3.1859e-01]],

         [[-8.9197e-02,  7.9350e-02,  2.0267e-01],
          [ 2.6187e-02,  2.2956e-01,  8.4562e-02],
          [-2.1943e-01, -1.8830e-01, -2.3509e-01]]],


        ...,


        [[[-1.3672e-01, -1.3076e-01,  3.4035e-02],
          [ 1.2457e-01, -2.3919e-01, -8.6594e-02],
          [ 1.3398e-01, -7.1779e-02,  9.3423e-02]],

         [[ 1.6678e-01, -1.5511e-02, -1.2351e-02],
          [-6.8085e-02, -3.6970e-01, -2.4872e-01],
          [ 1.0494e-01, -1.1980e-02, -9.4948e-02]],

         [[ 2.1720e-01,  1.7752e-02,  1.0169e-01],
          [-5.6733e-03, -1.7181e-01, -1.4619e-01],
          [ 6.8584e-02, -9.9839e-02, -7.9458e-02]]],


        [[[ 1.6289e-41, -6.5422e-41,  5.5229e-41],
          [-1.2259e-41, -4.3007e-41, -6.5917e-42],
          [-2.9708e-43, -1.8866e-41,  4.8744e-41]],

         [[-4.1172e-41, -3.3211e-41,  6.5385e-42],
          [-3.9330e-41, -6.8203e-41,  4.4502e-41],
          [-1.2710e-41, -1.8221e-41, -1.9837e-41]],

         [[ 6.6010e-41,  1.0038e-41, -1.4156e-41],
          [-5.2364e-41,  6.1074e-41, -1.6315e-41],
          [-2.9680e-41, -3.3551e-41,  6.8926e-41]]],


        [[[-1.6273e-02, -8.0464e-03, -7.6903e-03],
          [-4.7215e-02, -3.8960e-02, -3.0254e-02],
          [-4.9678e-02, -4.9067e-02, -4.2084e-02]],

         [[-1.5974e-02, -6.6537e-03, -1.9211e-03],
          [-4.4774e-02, -3.4290e-02, -2.1827e-02],
          [-4.8076e-02, -4.6270e-02, -3.4395e-02]],

         [[-1.9631e-02, -1.2242e-02, -1.3453e-03],
          [-3.5583e-02, -2.8224e-02, -1.4904e-02],
          [-3.7411e-02, -4.6799e-02, -3.5831e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0015,  0.0067,  0.0045],
          [ 0.0229,  0.0304,  0.0352],
          [ 0.0183,  0.0267,  0.0352]],

         [[-0.0257, -0.0055, -0.0118],
          [ 0.0005,  0.0162,  0.0183],
          [ 0.0022,  0.0142,  0.0160]],

         [[-0.0156,  0.0082, -0.0014],
          [ 0.0095,  0.0207,  0.0205],
          [ 0.0070,  0.0114,  0.0151]]],


        [[[-0.0520, -0.0307, -0.0234],
          [-0.0528, -0.0317, -0.0240],
          [-0.0565, -0.0442, -0.0355]],

         [[-0.0534, -0.0333, -0.0240],
          [-0.0538, -0.0343, -0.0242],
          [-0.0517, -0.0402, -0.0293]],

         [[-0.0523, -0.0366, -0.0346],
          [-0.0584, -0.0416, -0.0390],
          [-0.0546, -0.0460, -0.0433]]],


        [[[ 0.0033, -0.0088, -0.0193],
          [-0.0255, -0.0280, -0.0305],
          [-0.0303, -0.0249, -0.0191]],

         [[-0.0130, -0.0221, -0.0289],
          [-0.0404, -0.0403, -0.0412],
          [-0.0429, -0.0351, -0.0266]],

         [[-0.0153, -0.0222, -0.0288],
          [-0.0357, -0.0358, -0.0383],
          [-0.0378, -0.0346, -0.0289]]],


        ...,


        [[[-0.0059, -0.0029, -0.0011],
          [-0.0094, -0.0020, -0.0010],
          [-0.0041,  0.0018, -0.0010]],

         [[-0.0042, -0.0005,  0.0005],
          [-0.0088, -0.0011, -0.0008],
          [-0.0043,  0.0019, -0.0009]],

         [[ 0.0002,  0.0026,  0.0046],
          [-0.0052, -0.0000,  0.0009],
          [-0.0031,  0.0018,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5829]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 55 | Batch_idx: 0 |  Loss: (0.2618) | Acc: (89.00%) (115/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.2862) | Acc: (89.00%) (1261/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.2729) | Acc: (89.00%) (2416/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.2706) | Acc: (90.00%) (3586/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.2644) | Acc: (90.00%) (4760/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.2643) | Acc: (90.00%) (5919/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.2636) | Acc: (90.00%) (7088/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.2641) | Acc: (90.00%) (8242/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.2639) | Acc: (90.00%) (9402/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.2639) | Acc: (90.00%) (10564/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.2686) | Acc: (90.00%) (11700/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.2697) | Acc: (90.00%) (12859/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.2707) | Acc: (90.00%) (14016/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.2712) | Acc: (90.00%) (15175/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.2743) | Acc: (90.00%) (16320/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.2752) | Acc: (90.00%) (17471/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.2756) | Acc: (90.00%) (18638/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.2754) | Acc: (90.00%) (19800/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.2762) | Acc: (90.00%) (20953/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.2757) | Acc: (90.00%) (22113/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.2754) | Acc: (90.00%) (23276/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.2765) | Acc: (90.00%) (24416/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.2766) | Acc: (90.00%) (25573/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.2767) | Acc: (90.00%) (26723/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.2776) | Acc: (90.00%) (27869/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.2783) | Acc: (90.00%) (29022/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.2780) | Acc: (90.00%) (30182/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.2786) | Acc: (90.00%) (31328/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.2779) | Acc: (90.00%) (32494/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.2774) | Acc: (90.00%) (33664/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.2775) | Acc: (90.00%) (34825/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.2775) | Acc: (90.00%) (35986/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.2769) | Acc: (90.00%) (37143/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.2758) | Acc: (90.00%) (38313/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.2771) | Acc: (90.00%) (39450/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.2780) | Acc: (90.00%) (40594/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.2786) | Acc: (90.00%) (41747/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.2780) | Acc: (90.00%) (42924/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.2778) | Acc: (90.00%) (44090/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.2777) | Acc: (90.00%) (45202/50000)
# TEST : Loss: (0.4208) | Acc: (86.00%) (8627/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3595e-01,  2.1991e-01, -1.0888e-01],
          [-8.4839e-02,  4.4344e-02, -1.6733e-02],
          [ 4.9572e-02, -2.1473e-01,  2.5930e-01]],

         [[-1.3023e-01,  3.4589e-01,  8.9482e-02],
          [-2.1691e-02,  5.2276e-02, -1.4212e-01],
          [ 8.7610e-02, -3.1204e-01, -2.4220e-02]],

         [[-1.0108e-01,  2.3825e-01, -1.4480e-01],
          [ 9.3626e-02, -1.5482e-01, -8.1540e-02],
          [ 1.5776e-01, -1.5524e-01,  2.0554e-01]]],


        [[[-1.3167e-01, -2.8632e-01, -1.8563e-01],
          [-1.0965e-01,  2.1738e-01,  1.7326e-01],
          [ 1.8082e-01,  8.9311e-02,  2.0844e-01]],

         [[-2.2707e-01, -2.2646e-01, -1.8427e-01],
          [-1.3694e-01,  1.2519e-01,  1.9648e-01],
          [ 2.4118e-01,  1.2879e-02,  8.0017e-02]],

         [[-1.2890e-01,  8.1956e-02, -2.1391e-01],
          [ 8.1981e-02,  2.2805e-01, -9.5230e-02],
          [ 1.1432e-02,  8.5493e-02,  5.9373e-02]]],


        [[[-1.2131e-01,  2.1788e-01,  9.4618e-02],
          [ 1.4079e-01,  1.2441e-01, -8.5935e-02],
          [-2.0517e-01, -2.4858e-03, -2.2377e-01]],

         [[ 6.1749e-02,  6.8250e-02,  1.6940e-02],
          [ 7.9946e-02,  2.1499e-01,  6.8010e-02],
          [-7.6309e-02, -5.1124e-02, -3.2591e-01]],

         [[-8.5206e-02,  7.4656e-02,  1.9055e-01],
          [ 2.8517e-02,  2.2414e-01,  7.5295e-02],
          [-2.2334e-01, -1.9641e-01, -2.4550e-01]]],


        ...,


        [[[-1.3889e-01, -1.3505e-01,  3.2409e-02],
          [ 1.2492e-01, -2.4600e-01, -8.8388e-02],
          [ 1.3473e-01, -7.6484e-02,  8.4288e-02]],

         [[ 1.6019e-01, -2.7898e-02, -1.6807e-02],
          [-6.7292e-02, -3.8513e-01, -2.5161e-01],
          [ 1.0893e-01, -1.4827e-02, -9.9058e-02]],

         [[ 2.0143e-01, -3.8701e-04,  8.9441e-02],
          [-1.3132e-02, -1.9028e-01, -1.5834e-01],
          [ 6.6742e-02, -1.1024e-01, -9.3557e-02]]],


        [[[-4.0750e-42,  6.5490e-41,  5.7888e-42],
          [-2.4799e-41,  2.4786e-41,  4.5263e-41],
          [ 2.9530e-41, -5.6908e-41, -2.0261e-41]],

         [[ 6.3676e-41,  5.0773e-41, -2.1888e-41],
          [ 2.8658e-41,  6.5945e-41, -5.4578e-41],
          [ 6.8535e-41,  5.0094e-41, -2.1033e-42]],

         [[-5.0545e-42, -4.8970e-41, -6.4121e-41],
          [-4.1491e-41, -5.8665e-41,  6.8498e-41],
          [ 2.5784e-41,  3.9309e-41, -1.9140e-41]]],


        [[[-1.4960e-02, -7.4521e-03, -5.3260e-03],
          [-3.9570e-02, -3.2630e-02, -2.3774e-02],
          [-3.9038e-02, -3.8680e-02, -3.1979e-02]],

         [[-1.2365e-02, -4.9501e-03,  6.8185e-05],
          [-3.3856e-02, -2.5684e-02, -1.4582e-02],
          [-3.3421e-02, -3.2166e-02, -2.1881e-02]],

         [[-1.6769e-02, -1.1791e-02, -3.3778e-03],
          [-2.8460e-02, -2.3421e-02, -1.3101e-02],
          [-2.8007e-02, -3.5587e-02, -2.6612e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0215, -0.0041, -0.0232],
          [-0.0054,  0.0043, -0.0151],
          [-0.0042, -0.0005, -0.0093]],

         [[-0.0095,  0.0003, -0.0117],
          [ 0.0079,  0.0140,  0.0058],
          [ 0.0046,  0.0161,  0.0105]],

         [[ 0.0023,  0.0061, -0.0063],
          [ 0.0169,  0.0185,  0.0132],
          [ 0.0097,  0.0218,  0.0193]]],


        [[[-0.0147, -0.0195, -0.0195],
          [-0.0224, -0.0238, -0.0216],
          [-0.0138, -0.0100, -0.0051]],

         [[-0.0307, -0.0316, -0.0287],
          [-0.0370, -0.0365, -0.0311],
          [-0.0274, -0.0241, -0.0192]],

         [[-0.0433, -0.0424, -0.0351],
          [-0.0461, -0.0462, -0.0408],
          [-0.0359, -0.0341, -0.0326]]],


        [[[ 0.0279,  0.0232,  0.0210],
          [ 0.0164,  0.0061,  0.0023],
          [ 0.0124,  0.0002, -0.0018]],

         [[ 0.0404,  0.0337,  0.0248],
          [ 0.0326,  0.0203,  0.0118],
          [ 0.0340,  0.0214,  0.0171]],

         [[ 0.0433,  0.0348,  0.0207],
          [ 0.0382,  0.0231,  0.0096],
          [ 0.0400,  0.0255,  0.0164]]],


        ...,


        [[[ 0.0096,  0.0085,  0.0156],
          [ 0.0049,  0.0047,  0.0100],
          [-0.0014,  0.0008,  0.0056]],

         [[ 0.0024,  0.0004,  0.0072],
          [-0.0025, -0.0035,  0.0011],
          [-0.0094, -0.0079, -0.0029]],

         [[-0.0011, -0.0035,  0.0025],
          [-0.0043, -0.0057, -0.0018],
          [-0.0105, -0.0098, -0.0054]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5815]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 56 | Batch_idx: 0 |  Loss: (0.2872) | Acc: (89.00%) (115/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.2376) | Acc: (92.00%) (1299/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.2377) | Acc: (92.00%) (2476/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.2430) | Acc: (91.00%) (3638/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.2365) | Acc: (91.00%) (4820/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.2390) | Acc: (91.00%) (5998/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.2422) | Acc: (91.00%) (7173/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.2440) | Acc: (91.00%) (8347/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.2457) | Acc: (91.00%) (9515/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.2445) | Acc: (91.00%) (10684/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.2460) | Acc: (91.00%) (11850/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.2452) | Acc: (91.00%) (13027/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.2426) | Acc: (91.00%) (14209/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.2470) | Acc: (91.00%) (15364/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.2462) | Acc: (91.00%) (16532/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.2465) | Acc: (91.00%) (17695/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.2460) | Acc: (91.00%) (18864/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.2487) | Acc: (91.00%) (20017/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.2469) | Acc: (91.00%) (21204/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.2479) | Acc: (91.00%) (22372/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.2480) | Acc: (91.00%) (23543/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.2497) | Acc: (91.00%) (24693/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.2492) | Acc: (91.00%) (25871/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.2487) | Acc: (91.00%) (27045/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.2491) | Acc: (91.00%) (28211/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.2500) | Acc: (91.00%) (29374/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.2500) | Acc: (91.00%) (30544/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.2504) | Acc: (91.00%) (31717/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.2499) | Acc: (91.00%) (32894/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.2502) | Acc: (91.00%) (34065/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.2523) | Acc: (91.00%) (35213/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.2526) | Acc: (91.00%) (36380/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.2525) | Acc: (91.00%) (37560/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.2516) | Acc: (91.00%) (38743/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.2522) | Acc: (91.00%) (39900/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.2528) | Acc: (91.00%) (41045/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.2528) | Acc: (91.00%) (42205/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.2530) | Acc: (91.00%) (43376/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.2527) | Acc: (91.00%) (44551/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.2517) | Acc: (91.00%) (45691/50000)
# TEST : Loss: (0.3487) | Acc: (88.00%) (8881/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2590e-01,  2.3081e-01, -9.8889e-02],
          [-7.9062e-02,  4.6458e-02, -8.2510e-03],
          [ 5.1448e-02, -2.1393e-01,  2.7158e-01]],

         [[-1.2055e-01,  3.5493e-01,  9.7724e-02],
          [-1.9705e-02,  4.9644e-02, -1.3948e-01],
          [ 8.0754e-02, -3.2133e-01, -2.1708e-02]],

         [[-9.7132e-02,  2.3781e-01, -1.4044e-01],
          [ 9.1147e-02, -1.5628e-01, -7.7590e-02],
          [ 1.4936e-01, -1.5704e-01,  2.1092e-01]]],


        [[[-1.4044e-01, -2.9760e-01, -1.9060e-01],
          [-1.1440e-01,  2.1315e-01,  1.7391e-01],
          [ 1.7645e-01,  8.6023e-02,  2.0523e-01]],

         [[-2.3667e-01, -2.3908e-01, -1.8860e-01],
          [-1.4316e-01,  1.1808e-01,  1.9410e-01],
          [ 2.3648e-01,  6.4841e-03,  7.4212e-02]],

         [[-1.2798e-01,  7.8557e-02, -2.1091e-01],
          [ 8.3632e-02,  2.2845e-01, -8.9343e-02],
          [ 1.1961e-02,  8.2657e-02,  5.8678e-02]]],


        [[[-1.2325e-01,  2.1926e-01,  9.5118e-02],
          [ 1.3748e-01,  1.2327e-01, -9.0302e-02],
          [-2.0643e-01, -6.5882e-03, -2.2950e-01]],

         [[ 6.1051e-02,  7.5763e-02,  2.6162e-02],
          [ 7.8023e-02,  2.1692e-01,  6.9302e-02],
          [-7.7214e-02, -5.2299e-02, -3.2655e-01]],

         [[-8.6599e-02,  7.9843e-02,  1.9967e-01],
          [ 2.7810e-02,  2.2652e-01,  8.0958e-02],
          [-2.2050e-01, -1.9254e-01, -2.3910e-01]]],


        ...,


        [[[-1.5200e-01, -1.5016e-01,  1.6756e-02],
          [ 1.1498e-01, -2.5822e-01, -1.0464e-01],
          [ 1.2520e-01, -8.6319e-02,  6.5406e-02]],

         [[ 1.5442e-01, -3.1911e-02, -2.3405e-02],
          [-7.1588e-02, -3.8330e-01, -2.5583e-01],
          [ 1.0176e-01, -1.8841e-02, -1.1151e-01]],

         [[ 1.9697e-01, -1.9976e-03,  8.3126e-02],
          [-1.7398e-02, -1.8973e-01, -1.6436e-01],
          [ 5.8568e-02, -1.1578e-01, -1.0967e-01]]],


        [[[-2.8962e-41,  1.1715e-41,  3.6270e-41],
          [ 7.1707e-41,  4.6487e-41,  1.6049e-41],
          [-3.3951e-41,  6.9542e-41,  7.3613e-41]],

         [[-6.3811e-41, -6.3508e-41, -3.4654e-42],
          [ 2.1424e-41, -2.1322e-41,  3.3195e-41],
          [-6.9504e-41,  4.8119e-41,  7.5094e-41]],

         [[ 5.3289e-41,  5.6640e-41, -2.2253e-42],
          [-6.3700e-41, -6.1666e-41,  4.3307e-41],
          [-6.6981e-41, -3.3411e-41,  3.5809e-41]]],


        [[[-1.1050e-02, -5.2715e-03, -1.1330e-03],
          [-2.9615e-02, -2.4341e-02, -1.5018e-02],
          [-2.8816e-02, -2.7840e-02, -2.0781e-02]],

         [[-9.6396e-03, -4.4006e-03,  1.8781e-03],
          [-2.4670e-02, -1.8435e-02, -7.4639e-03],
          [-2.4243e-02, -2.2266e-02, -1.2567e-02]],

         [[-1.3572e-02, -1.0114e-02, -2.5075e-03],
          [-2.2450e-02, -1.8630e-02, -9.3755e-03],
          [-2.2934e-02, -2.7445e-02, -1.9290e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0403,  0.0485,  0.0559],
          [ 0.0391,  0.0588,  0.0484],
          [ 0.0458,  0.0633,  0.0585]],

         [[ 0.0414,  0.0497,  0.0556],
          [ 0.0332,  0.0537,  0.0424],
          [ 0.0365,  0.0552,  0.0499]],

         [[ 0.0324,  0.0409,  0.0485],
          [ 0.0256,  0.0475,  0.0376],
          [ 0.0253,  0.0452,  0.0398]]],


        [[[-0.0077, -0.0140, -0.0124],
          [-0.0044, -0.0132, -0.0127],
          [-0.0094, -0.0178, -0.0162]],

         [[-0.0097, -0.0176, -0.0152],
          [-0.0044, -0.0126, -0.0102],
          [-0.0081, -0.0159, -0.0127]],

         [[-0.0056, -0.0138, -0.0128],
          [-0.0011, -0.0083, -0.0069],
          [-0.0051, -0.0097, -0.0050]]],


        [[[-0.0286, -0.0302, -0.0266],
          [-0.0365, -0.0323, -0.0317],
          [-0.0300, -0.0212, -0.0230]],

         [[-0.0168, -0.0166, -0.0108],
          [-0.0235, -0.0207, -0.0213],
          [-0.0208, -0.0130, -0.0174]],

         [[-0.0161, -0.0140, -0.0048],
          [-0.0198, -0.0154, -0.0131],
          [-0.0170, -0.0089, -0.0121]]],


        ...,


        [[[-0.0070, -0.0076, -0.0108],
          [-0.0022, -0.0015, -0.0053],
          [ 0.0011,  0.0003, -0.0029]],

         [[-0.0016, -0.0007, -0.0037],
          [ 0.0017,  0.0042,  0.0006],
          [ 0.0033,  0.0036,  0.0000]],

         [[-0.0043, -0.0029, -0.0052],
          [-0.0011,  0.0015, -0.0020],
          [ 0.0000,  0.0002, -0.0034]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000,  0.0000]],

         [[-0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5797]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 57 | Batch_idx: 0 |  Loss: (0.1855) | Acc: (92.00%) (119/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.2307) | Acc: (92.00%) (1297/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.2481) | Acc: (91.00%) (2468/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.2644) | Acc: (91.00%) (3619/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.2779) | Acc: (90.00%) (4763/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.2702) | Acc: (91.00%) (5941/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.2656) | Acc: (91.00%) (7110/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.2680) | Acc: (90.00%) (8264/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.2648) | Acc: (91.00%) (9449/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.2594) | Acc: (91.00%) (10634/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.2554) | Acc: (91.00%) (11815/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.2556) | Acc: (91.00%) (12977/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.2569) | Acc: (91.00%) (14141/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.2534) | Acc: (91.00%) (15328/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.2516) | Acc: (91.00%) (16515/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.2491) | Acc: (91.00%) (17706/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.2473) | Acc: (91.00%) (18892/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.2471) | Acc: (91.00%) (20072/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.2458) | Acc: (91.00%) (21255/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.2441) | Acc: (91.00%) (22439/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.2424) | Acc: (91.00%) (23616/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.2419) | Acc: (91.00%) (24796/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.2420) | Acc: (91.00%) (25980/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.2422) | Acc: (91.00%) (27148/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.2418) | Acc: (91.00%) (28332/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.2408) | Acc: (91.00%) (29519/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.2389) | Acc: (91.00%) (30715/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.2379) | Acc: (91.00%) (31907/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.2370) | Acc: (91.00%) (33090/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.2361) | Acc: (92.00%) (34282/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.2344) | Acc: (92.00%) (35477/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.2326) | Acc: (92.00%) (36684/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.2309) | Acc: (92.00%) (37885/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.2305) | Acc: (92.00%) (39069/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.2298) | Acc: (92.00%) (40256/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.2296) | Acc: (92.00%) (41426/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.2292) | Acc: (92.00%) (42618/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.2290) | Acc: (92.00%) (43796/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.2285) | Acc: (92.00%) (44981/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.2281) | Acc: (92.00%) (46130/50000)
# TEST : Loss: (0.3070) | Acc: (90.00%) (9027/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2654e-01,  2.2928e-01, -1.0091e-01],
          [-8.0266e-02,  4.4056e-02, -1.0560e-02],
          [ 4.8491e-02, -2.1673e-01,  2.6824e-01]],

         [[-1.2130e-01,  3.5265e-01,  9.4660e-02],
          [-2.1231e-02,  4.7040e-02, -1.4175e-01],
          [ 7.7756e-02, -3.2360e-01, -2.4540e-02]],

         [[-9.9245e-02,  2.3486e-01, -1.4389e-01],
          [ 8.8473e-02, -1.5890e-01, -8.0562e-02],
          [ 1.4606e-01, -1.5931e-01,  2.0777e-01]]],


        [[[-1.4039e-01, -2.9684e-01, -1.8946e-01],
          [-1.1377e-01,  2.1340e-01,  1.7462e-01],
          [ 1.7700e-01,  8.6914e-02,  2.0592e-01]],

         [[-2.3572e-01, -2.3764e-01, -1.8667e-01],
          [-1.4223e-01,  1.1878e-01,  1.9497e-01],
          [ 2.3647e-01,  7.3190e-03,  7.5049e-02]],

         [[-1.2700e-01,  7.9607e-02, -2.0865e-01],
          [ 8.3966e-02,  2.2870e-01, -8.8179e-02],
          [ 1.1705e-02,  8.2699e-02,  5.8890e-02]]],


        [[[-1.2301e-01,  2.1909e-01,  9.5770e-02],
          [ 1.3750e-01,  1.2322e-01, -9.0065e-02],
          [-2.0547e-01, -6.6961e-03, -2.2953e-01]],

         [[ 6.0554e-02,  7.5255e-02,  2.6154e-02],
          [ 7.7606e-02,  2.1614e-01,  6.8701e-02],
          [-7.6941e-02, -5.2804e-02, -3.2673e-01]],

         [[-8.7927e-02,  7.8105e-02,  1.9793e-01],
          [ 2.6013e-02,  2.2431e-01,  7.8831e-02],
          [-2.2102e-01, -1.9348e-01, -2.4024e-01]]],


        ...,


        [[[-1.5298e-01, -1.5006e-01,  1.7278e-02],
          [ 1.1403e-01, -2.5555e-01, -1.0101e-01],
          [ 1.2553e-01, -8.3521e-02,  6.8052e-02]],

         [[ 1.5086e-01, -3.4211e-02, -2.4485e-02],
          [-7.2739e-02, -3.8087e-01, -2.5232e-01],
          [ 1.0152e-01, -1.7800e-02, -1.0953e-01]],

         [[ 1.9364e-01, -4.3455e-03,  8.0285e-02],
          [-1.8795e-02, -1.9010e-01, -1.6441e-01],
          [ 5.8160e-02, -1.1496e-01, -1.0919e-01]]],


        [[[ 4.5042e-41,  3.6336e-41,  2.8516e-42],
          [-7.3623e-41, -1.1873e-41, -7.2835e-41],
          [-3.5520e-41, -5.9084e-41,  2.2582e-41]],

         [[-6.7593e-41, -5.8273e-41, -5.2145e-41],
          [-5.4781e-41, -7.3806e-41,  5.7347e-41],
          [ 3.8918e-41,  2.4088e-42, -3.4677e-41]],

         [[ 2.3601e-41, -2.1049e-41, -1.7502e-42],
          [-1.4314e-41, -6.8002e-41,  6.8011e-41],
          [-5.9419e-41,  6.9045e-41, -5.8798e-41]]],


        [[[-8.0135e-03, -3.8989e-03, -9.2570e-04],
          [-2.1053e-02, -1.7716e-02, -1.0595e-02],
          [-2.0169e-02, -1.9750e-02, -1.4482e-02]],

         [[-6.5847e-03, -2.9572e-03,  1.0018e-03],
          [-1.6312e-02, -1.2054e-02, -4.3899e-03],
          [-1.5858e-02, -1.4323e-02, -7.5293e-03]],

         [[-8.9773e-03, -6.4517e-03, -1.4846e-03],
          [-1.4859e-02, -1.2300e-02, -5.6585e-03],
          [-1.5464e-02, -1.8319e-02, -1.2142e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5661]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0070]], device='cuda:0')

Epoch: 58 | Batch_idx: 0 |  Loss: (0.1867) | Acc: (92.00%) (119/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.2176) | Acc: (93.00%) (1310/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.2194) | Acc: (92.00%) (2492/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.2115) | Acc: (93.00%) (3694/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.2152) | Acc: (93.00%) (4881/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.2104) | Acc: (93.00%) (6086/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.2121) | Acc: (93.00%) (7266/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.2089) | Acc: (93.00%) (8460/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.2117) | Acc: (92.00%) (9633/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.2147) | Acc: (92.00%) (10804/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.2125) | Acc: (92.00%) (12003/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.2097) | Acc: (92.00%) (13201/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.2107) | Acc: (92.00%) (14386/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.2132) | Acc: (92.00%) (15566/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.2131) | Acc: (92.00%) (16750/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.2134) | Acc: (92.00%) (17931/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.2131) | Acc: (92.00%) (19118/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.2106) | Acc: (92.00%) (20332/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.2093) | Acc: (92.00%) (21529/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.2090) | Acc: (92.00%) (22724/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.2075) | Acc: (92.00%) (23926/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.2072) | Acc: (92.00%) (25115/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.2085) | Acc: (92.00%) (26287/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.2081) | Acc: (92.00%) (27488/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.2077) | Acc: (93.00%) (28690/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.2073) | Acc: (93.00%) (29884/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.2069) | Acc: (93.00%) (31082/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.2070) | Acc: (93.00%) (32270/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.2075) | Acc: (93.00%) (33457/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.2078) | Acc: (92.00%) (34637/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.2072) | Acc: (93.00%) (35837/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.2076) | Acc: (93.00%) (37026/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.2071) | Acc: (93.00%) (38230/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.2069) | Acc: (93.00%) (39417/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.2073) | Acc: (93.00%) (40606/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.2072) | Acc: (93.00%) (41790/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.2065) | Acc: (93.00%) (42989/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.2065) | Acc: (93.00%) (44178/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.2069) | Acc: (93.00%) (45364/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.2063) | Acc: (93.00%) (46520/50000)
# TEST : Loss: (0.3008) | Acc: (90.00%) (9029/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2624e-01,  2.2873e-01, -1.0068e-01],
          [-8.0086e-02,  4.3955e-02, -1.0536e-02],
          [ 4.8383e-02, -2.1623e-01,  2.6764e-01]],

         [[-1.2101e-01,  3.5179e-01,  9.4436e-02],
          [-2.1182e-02,  4.6929e-02, -1.4141e-01],
          [ 7.7577e-02, -3.2282e-01, -2.4483e-02]],

         [[-9.9000e-02,  2.3427e-01, -1.4353e-01],
          [ 8.8258e-02, -1.5851e-01, -8.0362e-02],
          [ 1.4571e-01, -1.5891e-01,  2.0726e-01]]],


        [[[-1.4008e-01, -2.9618e-01, -1.8904e-01],
          [-1.1352e-01,  2.1293e-01,  1.7423e-01],
          [ 1.7659e-01,  8.6713e-02,  2.0544e-01]],

         [[-2.3516e-01, -2.3708e-01, -1.8623e-01],
          [-1.4190e-01,  1.1850e-01,  1.9451e-01],
          [ 2.3590e-01,  7.3013e-03,  7.4866e-02]],

         [[-1.2668e-01,  7.9410e-02, -2.0813e-01],
          [ 8.3759e-02,  2.2814e-01, -8.7962e-02],
          [ 1.1676e-02,  8.2490e-02,  5.8741e-02]]],


        [[[-1.2275e-01,  2.1862e-01,  9.5566e-02],
          [ 1.3721e-01,  1.2297e-01, -8.9878e-02],
          [-2.0504e-01, -6.6820e-03, -2.2904e-01]],

         [[ 6.0420e-02,  7.5087e-02,  2.6096e-02],
          [ 7.7440e-02,  2.1568e-01,  6.8555e-02],
          [-7.6776e-02, -5.2689e-02, -3.2601e-01]],

         [[-8.7726e-02,  7.7926e-02,  1.9748e-01],
          [ 2.5955e-02,  2.2382e-01,  7.8656e-02],
          [-2.2052e-01, -1.9304e-01, -2.3969e-01]]],


        ...,


        [[[-1.5213e-01, -1.4897e-01,  1.7156e-02],
          [ 1.1329e-01, -2.5295e-01, -9.9986e-02],
          [ 1.2484e-01, -8.2907e-02,  6.7544e-02]],

         [[ 1.4993e-01, -3.3907e-02, -2.4271e-02],
          [-7.2194e-02, -3.7495e-01, -2.4825e-01],
          [ 1.0089e-01, -1.7640e-02, -1.0851e-01]],

         [[ 1.9245e-01, -4.3119e-03,  7.9665e-02],
          [-1.8664e-02, -1.8826e-01, -1.6278e-01],
          [ 5.7801e-02, -1.1405e-01, -1.0830e-01]]],


        [[[-3.6585e-41,  3.4124e-41,  3.1414e-41],
          [ 4.1818e-41, -2.4887e-41,  5.4837e-41],
          [-8.8030e-42,  3.5159e-42, -3.6913e-41]],

         [[-1.4501e-41, -7.2345e-41,  1.6830e-42],
          [ 4.6229e-42, -6.6197e-41,  6.2609e-41],
          [ 4.6857e-41, -2.8051e-41, -1.1321e-41]],

         [[ 5.6535e-41, -4.2615e-41,  6.7512e-41],
          [ 6.0336e-41, -5.7327e-41,  3.0967e-41],
          [-5.1052e-41, -7.0373e-41, -2.7016e-41]]],


        [[[-5.3959e-03, -2.5961e-03, -5.8713e-04],
          [-1.3972e-02, -1.2053e-02, -7.0112e-03],
          [-1.2967e-02, -1.2893e-02, -9.3183e-03]],

         [[-4.0879e-03, -1.7338e-03,  5.3087e-04],
          [-9.8997e-03, -7.2309e-03, -2.4334e-03],
          [-9.3506e-03, -8.3045e-03, -4.0806e-03]],

         [[-5.4288e-03, -3.7148e-03, -7.6929e-04],
          [-9.0437e-03, -7.4945e-03, -3.2111e-03],
          [-9.4818e-03, -1.1165e-02, -6.9772e-03]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5908]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0419]], device='cuda:0')

Epoch: 59 | Batch_idx: 0 |  Loss: (0.1876) | Acc: (94.00%) (121/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.2001) | Acc: (93.00%) (1316/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.2015) | Acc: (93.00%) (2509/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.2043) | Acc: (93.00%) (3706/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.2065) | Acc: (93.00%) (4888/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.2042) | Acc: (93.00%) (6086/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.2060) | Acc: (93.00%) (7272/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.2055) | Acc: (93.00%) (8467/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.2023) | Acc: (93.00%) (9671/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.2023) | Acc: (93.00%) (10875/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.2032) | Acc: (93.00%) (12061/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.2025) | Acc: (93.00%) (13264/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.2035) | Acc: (93.00%) (14460/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.2048) | Acc: (93.00%) (15644/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.2056) | Acc: (93.00%) (16838/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.2050) | Acc: (93.00%) (18032/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.2044) | Acc: (93.00%) (19230/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.2059) | Acc: (93.00%) (20416/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.2062) | Acc: (93.00%) (21607/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.2068) | Acc: (93.00%) (22799/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.2075) | Acc: (93.00%) (23980/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.2075) | Acc: (93.00%) (25166/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.2074) | Acc: (93.00%) (26355/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.2073) | Acc: (93.00%) (27550/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.2079) | Acc: (93.00%) (28741/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.2069) | Acc: (93.00%) (29950/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.2077) | Acc: (93.00%) (31125/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.2071) | Acc: (93.00%) (32324/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.2073) | Acc: (93.00%) (33517/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.2071) | Acc: (93.00%) (34707/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.2073) | Acc: (93.00%) (35902/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.2074) | Acc: (93.00%) (37086/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.2072) | Acc: (93.00%) (38286/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.2071) | Acc: (93.00%) (39490/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.2074) | Acc: (93.00%) (40681/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.2078) | Acc: (93.00%) (41867/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.2075) | Acc: (93.00%) (43064/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.2071) | Acc: (93.00%) (44257/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.2069) | Acc: (93.00%) (45462/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.2066) | Acc: (93.00%) (46609/50000)
# TEST : Loss: (0.2959) | Acc: (90.00%) (9044/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2589e-01,  2.2807e-01, -1.0040e-01],
          [-7.9869e-02,  4.3833e-02, -1.0507e-02],
          [ 4.8252e-02, -2.1562e-01,  2.6691e-01]],

         [[-1.2066e-01,  3.5074e-01,  9.4164e-02],
          [-2.1122e-02,  4.6794e-02, -1.4101e-01],
          [ 7.7360e-02, -3.2188e-01, -2.4414e-02]],

         [[-9.8703e-02,  2.3355e-01, -1.4310e-01],
          [ 8.7999e-02, -1.5804e-01, -8.0120e-02],
          [ 1.4528e-01, -1.5842e-01,  2.0665e-01]]],


        [[[-1.3970e-01, -2.9538e-01, -1.8852e-01],
          [-1.1322e-01,  2.1235e-01,  1.7375e-01],
          [ 1.7610e-01,  8.6468e-02,  2.0485e-01]],

         [[-2.3449e-01, -2.3640e-01, -1.8569e-01],
          [-1.4149e-01,  1.1816e-01,  1.9395e-01],
          [ 2.3521e-01,  7.2799e-03,  7.4646e-02]],

         [[-1.2630e-01,  7.9171e-02, -2.0751e-01],
          [ 8.3507e-02,  2.2746e-01, -8.7697e-02],
          [ 1.1640e-02,  8.2238e-02,  5.8561e-02]]],


        [[[-1.2243e-01,  2.1805e-01,  9.5319e-02],
          [ 1.3687e-01,  1.2266e-01, -8.9652e-02],
          [-2.0452e-01, -6.6648e-03, -2.2845e-01]],

         [[ 6.0258e-02,  7.4884e-02,  2.6027e-02],
          [ 7.7239e-02,  2.1512e-01,  6.8377e-02],
          [-7.6576e-02, -5.2550e-02, -3.2514e-01]],

         [[-8.7483e-02,  7.7709e-02,  1.9694e-01],
          [ 2.5885e-02,  2.2321e-01,  7.8444e-02],
          [-2.1991e-01, -1.9251e-01, -2.3902e-01]]],


        ...,


        [[[-1.5111e-01, -1.4766e-01,  1.7009e-02],
          [ 1.1241e-01, -2.4983e-01, -9.8758e-02],
          [ 1.2400e-01, -8.2167e-02,  6.6932e-02]],

         [[ 1.4881e-01, -3.3542e-02, -2.4013e-02],
          [-7.1538e-02, -3.6788e-01, -2.4339e-01],
          [ 1.0014e-01, -1.7446e-02, -1.0728e-01]],

         [[ 1.9101e-01, -4.2713e-03,  7.8917e-02],
          [-1.8505e-02, -1.8605e-01, -1.6082e-01],
          [ 5.7368e-02, -1.1296e-01, -1.0723e-01]]],


        [[[ 7.4541e-41, -7.8477e-41,  7.5386e-41],
          [ 5.7776e-42,  7.0774e-41, -4.1462e-41],
          [ 3.0974e-41,  2.1793e-41, -8.3463e-41]],

         [[ 6.0673e-41, -5.2395e-41,  3.7646e-41],
          [ 4.1750e-41, -3.7050e-41,  6.7379e-41],
          [-8.1596e-41, -4.1572e-41,  6.2808e-41]],

         [[ 6.8899e-41, -4.4724e-41,  1.2972e-41],
          [-7.7064e-41, -1.2064e-41, -3.5659e-41],
          [-7.0522e-41,  5.8591e-41,  2.4715e-41]]],


        [[[-3.3324e-03, -1.5815e-03, -3.3704e-04],
          [-8.4779e-03, -7.5387e-03, -4.2390e-03],
          [-7.5691e-03, -7.6668e-03, -5.4443e-03]],

         [[-2.2861e-03, -9.0411e-04,  2.4459e-04],
          [-5.3850e-03, -3.8779e-03, -1.1848e-03],
          [-4.9103e-03, -4.2717e-03, -1.9327e-03]],

         [[-2.9401e-03, -1.8947e-03, -3.4487e-04],
          [-4.9365e-03, -4.0965e-03, -1.6089e-03],
          [-5.2230e-03, -6.1051e-03, -3.5501e-03]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5786]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0110]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.2764) | Acc: (89.00%) (115/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.2389) | Acc: (92.00%) (1299/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.2525) | Acc: (91.00%) (2469/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.2773) | Acc: (90.00%) (3602/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3035) | Acc: (90.00%) (4727/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3124) | Acc: (89.00%) (5859/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3214) | Acc: (89.00%) (6984/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3257) | Acc: (89.00%) (8113/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3221) | Acc: (89.00%) (9265/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3288) | Acc: (89.00%) (10378/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3331) | Acc: (89.00%) (11514/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3355) | Acc: (88.00%) (12629/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3328) | Acc: (88.00%) (13779/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3347) | Acc: (88.00%) (14898/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3336) | Acc: (88.00%) (16041/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3333) | Acc: (88.00%) (17169/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3333) | Acc: (88.00%) (18310/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3333) | Acc: (88.00%) (19445/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3320) | Acc: (88.00%) (20590/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3309) | Acc: (88.00%) (21723/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3312) | Acc: (88.00%) (22853/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3312) | Acc: (88.00%) (23996/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3324) | Acc: (88.00%) (25118/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3318) | Acc: (88.00%) (26261/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3322) | Acc: (88.00%) (27390/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3318) | Acc: (88.00%) (28534/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3302) | Acc: (88.00%) (29688/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3296) | Acc: (88.00%) (30841/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3286) | Acc: (88.00%) (31991/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3287) | Acc: (88.00%) (33129/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3281) | Acc: (88.00%) (34268/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3277) | Acc: (88.00%) (35408/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3253) | Acc: (89.00%) (36570/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3256) | Acc: (88.00%) (37706/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3261) | Acc: (88.00%) (38827/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3257) | Acc: (88.00%) (39964/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3261) | Acc: (88.00%) (41096/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3248) | Acc: (88.00%) (42264/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3245) | Acc: (89.00%) (43407/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3229) | Acc: (89.00%) (44530/50000)
# TEST : Loss: (0.4123) | Acc: (86.00%) (8645/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4621e-01,  2.1920e-01, -1.1698e-01],
          [-8.3555e-02,  3.5768e-02, -2.5803e-02],
          [ 4.0741e-02, -2.2615e-01,  2.5982e-01]],

         [[-1.4260e-01,  3.5008e-01,  8.5621e-02],
          [-2.4769e-02,  4.3835e-02, -1.5005e-01],
          [ 7.5073e-02, -3.2955e-01, -2.7953e-02]],

         [[-1.1866e-01,  2.2987e-01, -1.4857e-01],
          [ 8.6322e-02, -1.6343e-01, -9.1638e-02],
          [ 1.4147e-01, -1.6833e-01,  1.9760e-01]]],


        [[[-1.4520e-01, -3.0160e-01, -1.9206e-01],
          [-1.2115e-01,  2.1317e-01,  1.7621e-01],
          [ 1.6986e-01,  8.7181e-02,  2.0743e-01]],

         [[-2.3441e-01, -2.3632e-01, -1.8355e-01],
          [-1.4317e-01,  1.2642e-01,  2.0112e-01],
          [ 2.3891e-01,  1.8467e-02,  8.5733e-02]],

         [[-1.2824e-01,  7.8256e-02, -2.0568e-01],
          [ 7.9020e-02,  2.3387e-01, -8.0021e-02],
          [ 1.2798e-02,  9.0560e-02,  6.6346e-02]]],


        [[[-1.2009e-01,  2.2520e-01,  1.0005e-01],
          [ 1.4339e-01,  1.3701e-01, -7.8767e-02],
          [-2.0624e-01, -6.1161e-03, -2.2655e-01]],

         [[ 5.2873e-02,  7.1428e-02,  2.5203e-02],
          [ 7.8147e-02,  2.2226e-01,  7.4020e-02],
          [-8.1459e-02, -5.4743e-02, -3.2608e-01]],

         [[-8.9418e-02,  7.7370e-02,  1.9998e-01],
          [ 2.9346e-02,  2.3114e-01,  8.5946e-02],
          [-2.2409e-01, -1.9547e-01, -2.4000e-01]]],


        ...,


        [[[-1.4104e-01, -1.4832e-01,  6.6944e-03],
          [ 1.0934e-01, -2.7272e-01, -1.2869e-01],
          [ 1.1989e-01, -9.9869e-02,  5.2714e-02]],

         [[ 1.6247e-01, -2.5009e-02, -2.5242e-02],
          [-5.6601e-02, -3.6288e-01, -2.5443e-01],
          [ 1.1631e-01, -6.2361e-03, -9.2684e-02]],

         [[ 1.9703e-01,  7.7838e-04,  7.3691e-02],
          [-1.2787e-02, -1.8705e-01, -1.7189e-01],
          [ 6.7960e-02, -1.0561e-01, -9.6506e-02]]],


        [[[-6.1954e-41,  5.7334e-41,  3.8530e-41],
          [-7.5463e-41, -1.4288e-41,  2.4240e-41],
          [ 4.7840e-41, -3.8899e-41, -9.0244e-43]],

         [[-7.1630e-41, -5.7762e-42,  8.4278e-41],
          [-5.7235e-41,  4.8769e-41,  8.4072e-41],
          [ 5.8506e-41,  3.1297e-41, -7.3598e-41]],

         [[-2.2157e-41, -4.5787e-41, -5.6491e-41],
          [ 7.6650e-41,  1.5498e-41, -7.5531e-41],
          [-1.3402e-41, -6.1879e-41, -2.8306e-42]]],


        [[[-2.2528e-03, -1.2107e-03, -2.8927e-04],
          [-4.6460e-03, -4.4473e-03, -2.4329e-03],
          [-3.8001e-03, -4.1921e-03, -2.9863e-03]],

         [[-1.4724e-03, -6.3205e-04,  2.4309e-04],
          [-2.5596e-03, -1.9165e-03, -4.7232e-04],
          [-2.1938e-03, -2.0395e-03, -9.2673e-04]],

         [[-1.5021e-03, -7.4809e-04,  3.0558e-04],
          [-2.1576e-03, -1.7632e-03, -3.7598e-04],
          [-2.2392e-03, -2.7603e-03, -1.4405e-03]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0050, -0.0076, -0.0197],
          [-0.0035,  0.0091, -0.0007],
          [ 0.0066,  0.0113, -0.0053]],

         [[-0.0156, -0.0175, -0.0387],
          [-0.0164, -0.0048, -0.0274],
          [-0.0063, -0.0084, -0.0228]],

         [[-0.0105, -0.0087, -0.0317],
          [-0.0097,  0.0026, -0.0229],
          [ 0.0002, -0.0032, -0.0196]]],


        [[[-0.0075, -0.0184, -0.0224],
          [-0.0075, -0.0195, -0.0241],
          [-0.0021, -0.0112, -0.0205]],

         [[ 0.0114,  0.0035, -0.0026],
          [ 0.0106,  0.0027, -0.0068],
          [ 0.0120,  0.0055, -0.0087]],

         [[ 0.0249,  0.0171,  0.0111],
          [ 0.0275,  0.0214,  0.0123],
          [ 0.0303,  0.0244,  0.0122]]],


        [[[ 0.0055, -0.0004, -0.0090],
          [ 0.0037, -0.0037, -0.0145],
          [ 0.0015, -0.0048, -0.0111]],

         [[-0.0135, -0.0206, -0.0321],
          [ 0.0001, -0.0101, -0.0245],
          [ 0.0031, -0.0120, -0.0221]],

         [[-0.0195, -0.0250, -0.0343],
          [-0.0094, -0.0174, -0.0309],
          [-0.0031, -0.0182, -0.0308]]],


        ...,


        [[[ 0.0051,  0.0086,  0.0155],
          [-0.0025, -0.0015,  0.0048],
          [ 0.0034,  0.0042,  0.0078]],

         [[ 0.0054,  0.0071,  0.0126],
          [-0.0009, -0.0017,  0.0045],
          [ 0.0049,  0.0038,  0.0073]],

         [[-0.0008,  0.0013,  0.0057],
          [-0.0057, -0.0066, -0.0019],
          [-0.0012, -0.0030, -0.0005]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0000, -0.0000, -0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [ 0.0000,  0.0000, -0.0000],
          [ 0.0000,  0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5789]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 61 | Batch_idx: 0 |  Loss: (0.3020) | Acc: (91.00%) (117/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.2771) | Acc: (91.00%) (1283/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.2678) | Acc: (91.00%) (2449/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.2709) | Acc: (91.00%) (3622/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.2686) | Acc: (91.00%) (4790/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.2697) | Acc: (91.00%) (5951/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.2664) | Acc: (91.00%) (7134/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.2714) | Acc: (91.00%) (8286/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.2685) | Acc: (91.00%) (9458/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.2700) | Acc: (91.00%) (10618/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.2704) | Acc: (91.00%) (11769/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.2686) | Acc: (91.00%) (12946/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.2686) | Acc: (91.00%) (14107/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.2698) | Acc: (91.00%) (15259/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.2679) | Acc: (91.00%) (16433/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.2696) | Acc: (91.00%) (17594/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.2706) | Acc: (90.00%) (18746/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.2700) | Acc: (91.00%) (19920/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.2697) | Acc: (90.00%) (21082/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.2700) | Acc: (90.00%) (22233/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.2696) | Acc: (90.00%) (23394/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.2703) | Acc: (90.00%) (24548/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.2709) | Acc: (90.00%) (25710/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.2714) | Acc: (90.00%) (26871/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.2712) | Acc: (90.00%) (28024/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.2717) | Acc: (90.00%) (29179/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.2715) | Acc: (90.00%) (30338/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.2717) | Acc: (90.00%) (31491/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.2712) | Acc: (90.00%) (32657/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.2715) | Acc: (90.00%) (33815/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.2715) | Acc: (90.00%) (34970/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.2708) | Acc: (90.00%) (36141/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.2712) | Acc: (90.00%) (37293/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.2725) | Acc: (90.00%) (38435/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.2725) | Acc: (90.00%) (39599/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.2726) | Acc: (90.00%) (40757/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.2732) | Acc: (90.00%) (41914/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.2724) | Acc: (90.00%) (43102/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.2717) | Acc: (90.00%) (44268/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.2713) | Acc: (90.00%) (45405/50000)
# TEST : Loss: (0.3633) | Acc: (88.00%) (8842/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3440e-01,  2.2651e-01, -1.1967e-01],
          [-7.6362e-02,  2.9849e-02, -3.6727e-02],
          [ 4.5447e-02, -2.3372e-01,  2.5396e-01]],

         [[-1.2324e-01,  3.6675e-01,  9.5411e-02],
          [-6.2029e-03,  4.3281e-02, -1.5375e-01],
          [ 8.6526e-02, -3.3293e-01, -2.8704e-02]],

         [[-1.0597e-01,  2.4102e-01, -1.3895e-01],
          [ 9.9411e-02, -1.5980e-01, -9.2869e-02],
          [ 1.5592e-01, -1.5880e-01,  2.0808e-01]]],


        [[[-1.5292e-01, -3.0699e-01, -1.9584e-01],
          [-1.2854e-01,  2.0996e-01,  1.7103e-01],
          [ 1.6822e-01,  9.1733e-02,  2.0919e-01]],

         [[-2.3878e-01, -2.3765e-01, -1.8200e-01],
          [-1.5098e-01,  1.2725e-01,  2.0305e-01],
          [ 2.3695e-01,  2.7159e-02,  9.5162e-02]],

         [[-1.2601e-01,  8.1242e-02, -2.0054e-01],
          [ 7.4165e-02,  2.3562e-01, -7.5027e-02],
          [ 7.7592e-03,  9.3589e-02,  7.1309e-02]]],


        [[[-1.1943e-01,  2.2445e-01,  9.5392e-02],
          [ 1.4701e-01,  1.3654e-01, -8.6180e-02],
          [-2.0754e-01, -9.6349e-03, -2.3652e-01]],

         [[ 5.7169e-02,  7.3088e-02,  2.2731e-02],
          [ 8.7227e-02,  2.2589e-01,  6.8723e-02],
          [-7.7249e-02, -5.3585e-02, -3.3283e-01]],

         [[-8.2861e-02,  7.9948e-02,  1.9583e-01],
          [ 3.6630e-02,  2.3323e-01,  8.0178e-02],
          [-2.1897e-01, -1.9333e-01, -2.4552e-01]]],


        ...,


        [[[-1.2583e-01, -1.3477e-01,  1.8115e-02],
          [ 1.2101e-01, -2.6797e-01, -1.1802e-01],
          [ 1.2237e-01, -9.4675e-02,  6.7087e-02]],

         [[ 1.6668e-01, -2.2568e-02, -2.5577e-02],
          [-5.6160e-02, -3.8022e-01, -2.6471e-01],
          [ 1.0573e-01, -1.9900e-02, -9.1780e-02]],

         [[ 2.0247e-01,  1.9892e-03,  6.5648e-02],
          [-7.8924e-03, -1.9786e-01, -1.8334e-01],
          [ 6.4548e-02, -1.1386e-01, -9.8213e-02]]],


        [[[ 3.4670e-41, -2.4985e-41,  1.6895e-41],
          [ 7.6940e-41, -6.0870e-41,  2.9950e-41],
          [-3.2496e-42, -2.1021e-41,  7.4934e-41]],

         [[ 1.0255e-41,  2.2789e-41,  2.0599e-42],
          [-7.8167e-41,  3.3277e-41,  6.1269e-41],
          [-6.0840e-41, -2.8281e-41, -9.6341e-41]],

         [[-7.4049e-41, -6.5544e-41,  2.7599e-41],
          [ 4.4533e-42, -1.7418e-41, -7.9590e-41],
          [ 8.6333e-41, -2.4769e-41,  5.5505e-41]]],


        [[[-9.8663e-04, -2.0276e-04,  6.0806e-04],
          [-2.2532e-03, -2.2313e-03, -7.5864e-04],
          [-1.8458e-03, -2.0706e-03, -1.1573e-03]],

         [[-5.4611e-04,  2.0297e-04,  1.0059e-03],
          [-1.1130e-03, -7.7957e-04,  4.0025e-04],
          [-1.0218e-03, -9.2400e-04, -5.7956e-05]],

         [[-4.0244e-04,  2.9841e-04,  1.1097e-03],
          [-7.6094e-04, -5.2290e-04,  5.5183e-04],
          [-9.1449e-04, -1.0813e-03, -1.2846e-04]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0470, -0.0369, -0.0262],
          [-0.0566, -0.0249, -0.0370],
          [-0.0426, -0.0127, -0.0108]],

         [[-0.0642, -0.0478, -0.0355],
          [-0.0702, -0.0392, -0.0499],
          [-0.0481, -0.0221, -0.0194]],

         [[-0.0439, -0.0337, -0.0324],
          [-0.0480, -0.0277, -0.0479],
          [-0.0295, -0.0117, -0.0181]]],


        [[[ 0.0284,  0.0203,  0.0308],
          [ 0.0277,  0.0269,  0.0442],
          [ 0.0139,  0.0146,  0.0177]],

         [[ 0.0273,  0.0174,  0.0261],
          [ 0.0272,  0.0264,  0.0417],
          [ 0.0073,  0.0086,  0.0112]],

         [[ 0.0311,  0.0201,  0.0219],
          [ 0.0332,  0.0330,  0.0422],
          [ 0.0204,  0.0230,  0.0199]]],


        [[[-0.0212, -0.0099, -0.0162],
          [-0.0263, -0.0174, -0.0161],
          [-0.0215, -0.0174, -0.0250]],

         [[-0.0383, -0.0291, -0.0346],
          [-0.0382, -0.0296, -0.0285],
          [-0.0225, -0.0231, -0.0345]],

         [[-0.0322, -0.0301, -0.0373],
          [-0.0283, -0.0268, -0.0284],
          [-0.0131, -0.0202, -0.0320]]],


        ...,


        [[[ 0.0083,  0.0129,  0.0237],
          [ 0.0093,  0.0058,  0.0128],
          [ 0.0046,  0.0006,  0.0030]],

         [[ 0.0028,  0.0039,  0.0127],
          [ 0.0053, -0.0023,  0.0022],
          [ 0.0038, -0.0039, -0.0043]],

         [[ 0.0035,  0.0016,  0.0073],
          [ 0.0066, -0.0027, -0.0009],
          [ 0.0082, -0.0004, -0.0022]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5775]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 62 | Batch_idx: 0 |  Loss: (0.3257) | Acc: (93.00%) (120/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.2366) | Acc: (92.00%) (1304/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.2246) | Acc: (92.00%) (2483/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.2301) | Acc: (92.00%) (3656/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.2281) | Acc: (92.00%) (4841/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.2267) | Acc: (92.00%) (6025/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.2226) | Acc: (92.00%) (7211/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.2237) | Acc: (92.00%) (8392/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.2218) | Acc: (92.00%) (9585/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.2251) | Acc: (92.00%) (10754/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.2251) | Acc: (92.00%) (11939/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.2221) | Acc: (92.00%) (13143/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.2219) | Acc: (92.00%) (14318/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.2241) | Acc: (92.00%) (15492/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.2266) | Acc: (92.00%) (16659/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.2306) | Acc: (92.00%) (17808/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.2328) | Acc: (92.00%) (18966/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.2344) | Acc: (91.00%) (20120/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.2370) | Acc: (91.00%) (21269/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.2363) | Acc: (91.00%) (22448/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.2372) | Acc: (91.00%) (23617/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.2386) | Acc: (91.00%) (24785/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.2391) | Acc: (91.00%) (25956/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.2400) | Acc: (91.00%) (27128/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.2398) | Acc: (91.00%) (28305/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.2398) | Acc: (91.00%) (29485/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.2402) | Acc: (91.00%) (30659/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.2391) | Acc: (91.00%) (31843/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.2400) | Acc: (91.00%) (33003/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.2408) | Acc: (91.00%) (34175/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.2408) | Acc: (91.00%) (35351/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.2409) | Acc: (91.00%) (36525/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.2424) | Acc: (91.00%) (37690/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.2428) | Acc: (91.00%) (38854/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.2427) | Acc: (91.00%) (40042/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.2423) | Acc: (91.00%) (41215/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.2418) | Acc: (91.00%) (42391/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.2426) | Acc: (91.00%) (43557/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.2421) | Acc: (91.00%) (44741/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.2422) | Acc: (91.00%) (45874/50000)
# TEST : Loss: (0.3621) | Acc: (88.00%) (8827/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3940e-01,  2.3405e-01, -1.1655e-01],
          [-7.8558e-02,  3.5417e-02, -3.3148e-02],
          [ 5.7500e-02, -2.1814e-01,  2.6171e-01]],

         [[-1.3395e-01,  3.6773e-01,  9.5020e-02],
          [-1.4900e-02,  3.5343e-02, -1.5758e-01],
          [ 8.9557e-02, -3.3492e-01, -3.5539e-02]],

         [[-1.1193e-01,  2.4898e-01, -1.3573e-01],
          [ 9.2821e-02, -1.6355e-01, -9.6747e-02],
          [ 1.5421e-01, -1.6167e-01,  1.9484e-01]]],


        [[[-1.5562e-01, -3.0638e-01, -1.9212e-01],
          [-1.2606e-01,  2.1700e-01,  1.7545e-01],
          [ 1.6926e-01,  9.3617e-02,  2.0686e-01]],

         [[-2.4406e-01, -2.4029e-01, -1.8393e-01],
          [-1.5121e-01,  1.3095e-01,  2.0222e-01],
          [ 2.3642e-01,  2.6667e-02,  8.9198e-02]],

         [[-1.4114e-01,  6.7187e-02, -2.1286e-01],
          [ 6.4503e-02,  2.2889e-01, -8.5453e-02],
          [-4.7364e-03,  8.0419e-02,  5.2917e-02]]],


        [[[-1.2412e-01,  2.2599e-01,  9.7402e-02],
          [ 1.4181e-01,  1.3931e-01, -8.0560e-02],
          [-2.1328e-01, -1.1373e-02, -2.3154e-01]],

         [[ 5.6345e-02,  7.7921e-02,  2.5046e-02],
          [ 8.3605e-02,  2.2902e-01,  7.2626e-02],
          [-8.3013e-02, -5.6064e-02, -3.3075e-01]],

         [[-8.3561e-02,  8.3340e-02,  1.9567e-01],
          [ 3.4501e-02,  2.3562e-01,  8.1412e-02],
          [-2.2422e-01, -1.9670e-01, -2.4721e-01]]],


        ...,


        [[[-1.1809e-01, -1.2636e-01,  3.7359e-02],
          [ 1.1896e-01, -2.7742e-01, -1.1049e-01],
          [ 1.2786e-01, -9.3767e-02,  7.6956e-02]],

         [[ 1.7440e-01, -1.3997e-02,  1.7029e-03],
          [-5.4780e-02, -3.8930e-01, -2.4115e-01],
          [ 1.1123e-01, -1.9838e-02, -7.3994e-02]],

         [[ 2.0571e-01,  2.6541e-03,  8.0104e-02],
          [-5.4632e-03, -2.0685e-01, -1.7533e-01],
          [ 7.4803e-02, -1.1383e-01, -8.7751e-02]]],


        [[[-4.6873e-41,  2.1279e-41,  4.7288e-41],
          [-8.7955e-41, -1.1631e-43, -8.4350e-41],
          [-9.6161e-41, -8.1429e-41, -6.3185e-41]],

         [[ 5.5758e-41,  1.5581e-41, -7.3427e-41],
          [-6.2959e-41, -5.1048e-41, -9.4651e-41],
          [ 6.9478e-41,  5.6416e-42, -7.4288e-41]],

         [[-8.6855e-41, -5.4358e-41, -4.4259e-41],
          [-8.1378e-41, -8.2967e-41, -8.5331e-41],
          [-3.5202e-41,  6.7265e-41,  5.5398e-41]]],


        [[[-5.7507e-04, -5.7206e-04,  4.3064e-05],
          [-1.8602e-03, -2.0720e-03, -1.3476e-03],
          [-1.1625e-03, -1.0787e-03, -1.0148e-03]],

         [[-4.1454e-04, -4.9407e-04,  2.7499e-05],
          [-1.3489e-03, -1.3862e-03, -9.5460e-04],
          [-6.6416e-04, -3.7381e-04, -4.7498e-04]],

         [[-1.5138e-04, -1.8683e-04,  2.6060e-04],
          [-9.2873e-04, -9.4720e-04, -5.1048e-04],
          [-5.3501e-04, -2.1442e-04, -2.1767e-04]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0121, -0.0144, -0.0370],
          [ 0.0119, -0.0065, -0.0333],
          [ 0.0311,  0.0249, -0.0076]],

         [[-0.0198, -0.0218, -0.0437],
          [ 0.0022, -0.0141, -0.0438],
          [ 0.0161,  0.0097, -0.0197]],

         [[-0.0152, -0.0195, -0.0386],
          [-0.0041, -0.0261, -0.0470],
          [ 0.0045, -0.0076, -0.0272]]],


        [[[ 0.0402,  0.0431,  0.0438],
          [ 0.0462,  0.0443,  0.0446],
          [ 0.0313,  0.0373,  0.0379]],

         [[ 0.0472,  0.0508,  0.0550],
          [ 0.0576,  0.0571,  0.0613],
          [ 0.0468,  0.0523,  0.0521]],

         [[ 0.0341,  0.0350,  0.0386],
          [ 0.0468,  0.0453,  0.0480],
          [ 0.0404,  0.0443,  0.0443]]],


        [[[-0.0081,  0.0098,  0.0129],
          [ 0.0176,  0.0258,  0.0089],
          [ 0.0286,  0.0291,  0.0070]],

         [[-0.0089,  0.0042,  0.0021],
          [ 0.0201,  0.0253,  0.0046],
          [ 0.0309,  0.0307,  0.0031]],

         [[-0.0094,  0.0031, -0.0010],
          [ 0.0176,  0.0197, -0.0019],
          [ 0.0275,  0.0238, -0.0022]]],


        ...,


        [[[-0.0188, -0.0053, -0.0044],
          [-0.0245, -0.0078, -0.0079],
          [-0.0370, -0.0212, -0.0225]],

         [[-0.0260, -0.0128, -0.0122],
          [-0.0264, -0.0103, -0.0112],
          [-0.0350, -0.0206, -0.0226]],

         [[-0.0233, -0.0121, -0.0123],
          [-0.0224, -0.0086, -0.0111],
          [-0.0289, -0.0164, -0.0207]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0000, -0.0000, -0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5758]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 63 | Batch_idx: 0 |  Loss: (0.2294) | Acc: (92.00%) (119/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.2483) | Acc: (90.00%) (1278/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.2998) | Acc: (89.00%) (2406/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3073) | Acc: (89.00%) (3550/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.2961) | Acc: (89.00%) (4719/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.2901) | Acc: (90.00%) (5879/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.2871) | Acc: (90.00%) (7041/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.2855) | Acc: (90.00%) (8200/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.2807) | Acc: (90.00%) (9372/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.2790) | Acc: (90.00%) (10533/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.2767) | Acc: (90.00%) (11703/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.2732) | Acc: (90.00%) (12880/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.2684) | Acc: (90.00%) (14077/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.2674) | Acc: (90.00%) (15251/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.2616) | Acc: (91.00%) (16453/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.2617) | Acc: (91.00%) (17621/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.2604) | Acc: (91.00%) (18798/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.2565) | Acc: (91.00%) (19993/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.2552) | Acc: (91.00%) (21167/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.2538) | Acc: (91.00%) (22348/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.2510) | Acc: (91.00%) (23546/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.2486) | Acc: (91.00%) (24740/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.2473) | Acc: (91.00%) (25923/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.2447) | Acc: (91.00%) (27126/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.2446) | Acc: (91.00%) (28305/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.2428) | Acc: (91.00%) (29501/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.2411) | Acc: (91.00%) (30700/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.2396) | Acc: (91.00%) (31891/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.2387) | Acc: (91.00%) (33076/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.2376) | Acc: (91.00%) (34267/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.2372) | Acc: (91.00%) (35440/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.2368) | Acc: (91.00%) (36620/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.2360) | Acc: (92.00%) (37813/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.2351) | Acc: (92.00%) (39009/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.2350) | Acc: (92.00%) (40180/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.2343) | Acc: (92.00%) (41370/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.2333) | Acc: (92.00%) (42567/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.2322) | Acc: (92.00%) (43771/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.2318) | Acc: (92.00%) (44951/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.2304) | Acc: (92.00%) (46111/50000)
# TEST : Loss: (0.3154) | Acc: (89.00%) (8973/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3515e-01,  2.3724e-01, -1.1160e-01],
          [-7.5738e-02,  3.8695e-02, -2.9082e-02],
          [ 6.0053e-02, -2.1555e-01,  2.6499e-01]],

         [[-1.2883e-01,  3.7183e-01,  1.0042e-01],
          [-1.1533e-02,  3.9428e-02, -1.5237e-01],
          [ 9.2071e-02, -3.3186e-01, -3.1024e-02]],

         [[-1.0720e-01,  2.5267e-01, -1.3026e-01],
          [ 9.5875e-02, -1.5884e-01, -9.1730e-02],
          [ 1.5659e-01, -1.5854e-01,  1.9862e-01]]],


        [[[-1.6115e-01, -3.1216e-01, -1.9846e-01],
          [-1.3152e-01,  2.1052e-01,  1.6866e-01],
          [ 1.6351e-01,  8.7666e-02,  2.0007e-01]],

         [[-2.5039e-01, -2.4732e-01, -1.9147e-01],
          [-1.5799e-01,  1.2307e-01,  1.9367e-01],
          [ 2.2948e-01,  1.9607e-02,  8.1206e-02]],

         [[-1.4585e-01,  6.1477e-02, -2.1822e-01],
          [ 5.8710e-02,  2.2231e-01, -9.1690e-02],
          [-9.8149e-03,  7.4594e-02,  4.6401e-02]]],


        [[[-1.2739e-01,  2.2200e-01,  9.3943e-02],
          [ 1.3795e-01,  1.3549e-01, -8.3288e-02],
          [-2.1744e-01, -1.5325e-02, -2.3392e-01]],

         [[ 5.2067e-02,  7.3682e-02,  2.1621e-02],
          [ 7.9413e-02,  2.2482e-01,  6.9480e-02],
          [-8.7727e-02, -6.0116e-02, -3.3308e-01]],

         [[-8.7575e-02,  7.9312e-02,  1.9234e-01],
          [ 3.0490e-02,  2.3170e-01,  7.8752e-02],
          [-2.2844e-01, -2.0010e-01, -2.4926e-01]]],


        ...,


        [[[-1.1633e-01, -1.2607e-01,  3.7152e-02],
          [ 1.1999e-01, -2.7601e-01, -1.0948e-01],
          [ 1.2958e-01, -9.1847e-02,  7.9086e-02]],

         [[ 1.7533e-01, -1.2700e-02,  4.1097e-03],
          [-5.2487e-02, -3.8433e-01, -2.3489e-01],
          [ 1.1298e-01, -1.7646e-02, -6.9126e-02]],

         [[ 2.0729e-01,  5.8191e-03,  8.4398e-02],
          [-2.5636e-03, -2.0239e-01, -1.6849e-01],
          [ 7.7424e-02, -1.0986e-01, -8.1339e-02]]],


        [[[ 8.3913e-41,  7.7710e-41, -8.4162e-42],
          [ 4.4795e-41, -6.9364e-43, -5.6216e-41],
          [ 5.3443e-41,  1.3106e-41, -9.9985e-41]],

         [[-5.7649e-42, -5.4439e-41,  8.4128e-41],
          [ 5.1032e-41,  4.8931e-41,  5.3332e-41],
          [ 5.0360e-41, -2.4821e-41,  8.8590e-41]],

         [[-5.4171e-41,  8.7669e-41, -4.1934e-41],
          [-8.9979e-41, -4.2794e-41, -7.2013e-42],
          [ 3.0792e-41,  1.7904e-41, -4.7598e-41]]],


        [[[-1.9826e-04, -1.9176e-04,  1.1170e-05],
          [-6.1388e-04, -7.3293e-04, -4.4168e-04],
          [-3.5136e-04, -3.4026e-04, -3.0769e-04]],

         [[-1.1467e-04, -1.1735e-04,  3.3880e-06],
          [-3.4762e-04, -3.4669e-04, -1.9173e-04],
          [-1.5773e-04, -8.4889e-05, -8.9485e-05]],

         [[-3.8940e-05, -4.2715e-05,  4.2101e-05],
          [-2.4105e-04, -2.4715e-04, -1.0955e-04],
          [-1.4157e-04, -5.5870e-05, -4.8285e-05]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5602]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0052]], device='cuda:0')

Epoch: 64 | Batch_idx: 0 |  Loss: (0.1970) | Acc: (93.00%) (120/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.2040) | Acc: (93.00%) (1311/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.2155) | Acc: (92.00%) (2491/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.2198) | Acc: (92.00%) (3668/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.2192) | Acc: (92.00%) (4846/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.2226) | Acc: (92.00%) (6028/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.2189) | Acc: (92.00%) (7228/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.2168) | Acc: (92.00%) (8422/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.2162) | Acc: (92.00%) (9611/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.2150) | Acc: (92.00%) (10801/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.2150) | Acc: (92.00%) (11987/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.2146) | Acc: (92.00%) (13177/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.2132) | Acc: (92.00%) (14367/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.2130) | Acc: (92.00%) (15560/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.2139) | Acc: (92.00%) (16742/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.2127) | Acc: (92.00%) (17937/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.2152) | Acc: (92.00%) (19105/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.2161) | Acc: (92.00%) (20280/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.2154) | Acc: (92.00%) (21473/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.2158) | Acc: (92.00%) (22656/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.2146) | Acc: (92.00%) (23856/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.2127) | Acc: (92.00%) (25065/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.2138) | Acc: (92.00%) (26238/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.2133) | Acc: (92.00%) (27446/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.2123) | Acc: (92.00%) (28642/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.2118) | Acc: (92.00%) (29839/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.2115) | Acc: (92.00%) (31029/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.2107) | Acc: (92.00%) (32231/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.2096) | Acc: (92.00%) (33439/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.2090) | Acc: (92.00%) (34639/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.2085) | Acc: (93.00%) (35840/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.2076) | Acc: (93.00%) (37045/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.2077) | Acc: (93.00%) (38229/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.2078) | Acc: (93.00%) (39411/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.2073) | Acc: (93.00%) (40599/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.2074) | Acc: (93.00%) (41795/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.2074) | Acc: (93.00%) (42984/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.2068) | Acc: (93.00%) (44196/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.2065) | Acc: (93.00%) (45396/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.2063) | Acc: (93.00%) (46545/50000)
# TEST : Loss: (0.3041) | Acc: (90.00%) (9008/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3483e-01,  2.3667e-01, -1.1135e-01],
          [-7.5564e-02,  3.8604e-02, -2.9016e-02],
          [ 5.9916e-02, -2.1503e-01,  2.6438e-01]],

         [[-1.2851e-01,  3.7090e-01,  1.0018e-01],
          [-1.1505e-02,  3.9331e-02, -1.5201e-01],
          [ 9.1849e-02, -3.3100e-01, -3.0950e-02]],

         [[-1.0693e-01,  2.5201e-01, -1.2994e-01],
          [ 9.5633e-02, -1.5843e-01, -9.1503e-02],
          [ 1.5620e-01, -1.5811e-01,  1.9812e-01]]],


        [[[-1.6079e-01, -3.1146e-01, -1.9801e-01],
          [-1.3123e-01,  2.1005e-01,  1.6827e-01],
          [ 1.6314e-01,  8.7461e-02,  1.9960e-01]],

         [[-2.4980e-01, -2.4674e-01, -1.9101e-01],
          [-1.5762e-01,  1.2278e-01,  1.9321e-01],
          [ 2.2893e-01,  1.9560e-02,  8.1009e-02]],

         [[-1.4550e-01,  6.1325e-02, -2.1768e-01],
          [ 5.8569e-02,  2.2177e-01, -9.1465e-02],
          [-9.7909e-03,  7.4412e-02,  4.6286e-02]]],


        [[[-1.2712e-01,  2.2153e-01,  9.3751e-02],
          [ 1.3767e-01,  1.3522e-01, -8.3123e-02],
          [-2.1701e-01, -1.5295e-02, -2.3344e-01]],

         [[ 5.1957e-02,  7.3524e-02,  2.1575e-02],
          [ 7.9250e-02,  2.2435e-01,  6.9335e-02],
          [-8.7547e-02, -5.9990e-02, -3.3237e-01]],

         [[-8.7383e-02,  7.9136e-02,  1.9191e-01],
          [ 3.0423e-02,  2.3119e-01,  7.8578e-02],
          [-2.2794e-01, -1.9965e-01, -2.4869e-01]]],


        ...,


        [[[-1.1565e-01, -1.2513e-01,  3.6882e-02],
          [ 1.1918e-01, -2.7305e-01, -1.0834e-01],
          [ 1.2883e-01, -9.1125e-02,  7.8467e-02]],

         [[ 1.7420e-01, -1.2584e-02,  4.0728e-03],
          [-5.2087e-02, -3.7839e-01, -2.3105e-01],
          [ 1.1227e-01, -1.7481e-02, -6.8463e-02]],

         [[ 2.0597e-01,  5.7724e-03,  8.3727e-02],
          [-2.5452e-03, -2.0032e-01, -1.6676e-01],
          [ 7.6931e-02, -1.0894e-01, -8.0651e-02]]],


        [[[ 1.2763e-41, -5.7497e-41,  7.7879e-41],
          [ 9.7892e-41, -1.6086e-41,  3.2945e-41],
          [ 3.1864e-41, -7.2184e-41,  3.1154e-41]],

         [[ 4.4053e-41, -1.1833e-41,  4.1422e-42],
          [ 4.6191e-41,  1.1478e-40, -6.7010e-41],
          [ 4.3471e-41, -8.8336e-41,  8.1959e-41]],

         [[ 8.7833e-41, -2.5705e-41, -2.2063e-41],
          [ 2.7757e-41, -8.9256e-41, -5.1174e-41],
          [-1.0082e-40, -2.3163e-42,  2.8348e-41]]],


        [[[-5.3778e-05, -5.0092e-05,  2.4739e-06],
          [-1.5823e-04, -2.0563e-04, -1.1272e-04],
          [-8.1287e-05, -8.2909e-05, -7.1371e-05]],

         [[-2.3641e-05, -1.9922e-05,  4.0592e-07],
          [-6.6060e-05, -6.3427e-05, -2.6683e-05],
          [-2.7141e-05, -1.3788e-05, -1.1512e-05]],

         [[-7.3381e-06, -6.8095e-06,  4.6658e-06],
          [-4.6257e-05, -4.7657e-05, -1.6543e-05],
          [-2.7861e-05, -1.0772e-05, -7.6122e-06]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5592]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0532]], device='cuda:0')

Epoch: 65 | Batch_idx: 0 |  Loss: (0.1731) | Acc: (95.00%) (122/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.1746) | Acc: (94.00%) (1331/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.1968) | Acc: (93.00%) (2511/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.1966) | Acc: (93.00%) (3707/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.1961) | Acc: (93.00%) (4911/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.1965) | Acc: (93.00%) (6115/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.2007) | Acc: (93.00%) (7307/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.1978) | Acc: (93.00%) (8509/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.1979) | Acc: (93.00%) (9705/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.2015) | Acc: (93.00%) (10882/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.2005) | Acc: (93.00%) (12079/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.2004) | Acc: (93.00%) (13268/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.2005) | Acc: (93.00%) (14460/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.2005) | Acc: (93.00%) (15649/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.2000) | Acc: (93.00%) (16841/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.2000) | Acc: (93.00%) (18043/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.2013) | Acc: (93.00%) (19222/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.2017) | Acc: (93.00%) (20408/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.2013) | Acc: (93.00%) (21605/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.1999) | Acc: (93.00%) (22803/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.2003) | Acc: (93.00%) (23992/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.2013) | Acc: (93.00%) (25176/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.2014) | Acc: (93.00%) (26379/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.2004) | Acc: (93.00%) (27584/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.2014) | Acc: (93.00%) (28766/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.2008) | Acc: (93.00%) (29970/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.2003) | Acc: (93.00%) (31174/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.2008) | Acc: (93.00%) (32361/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.2011) | Acc: (93.00%) (33550/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.2008) | Acc: (93.00%) (34746/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.2005) | Acc: (93.00%) (35944/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.2018) | Acc: (93.00%) (37117/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.2024) | Acc: (93.00%) (38302/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.2026) | Acc: (93.00%) (39500/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.2021) | Acc: (93.00%) (40697/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.2023) | Acc: (93.00%) (41890/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.2026) | Acc: (93.00%) (43071/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.2024) | Acc: (93.00%) (44263/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.2027) | Acc: (93.00%) (45447/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.2030) | Acc: (93.00%) (46590/50000)
# TEST : Loss: (0.2960) | Acc: (90.00%) (9030/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3445e-01,  2.3598e-01, -1.1104e-01],
          [-7.5352e-02,  3.8494e-02, -2.8936e-02],
          [ 5.9749e-02, -2.1439e-01,  2.6365e-01]],

         [[-1.2814e-01,  3.6977e-01,  9.9899e-02],
          [-1.1471e-02,  3.9213e-02, -1.5158e-01],
          [ 9.1580e-02, -3.2996e-01, -3.0860e-02]],

         [[-1.0660e-01,  2.5122e-01, -1.2955e-01],
          [ 9.5340e-02, -1.5794e-01, -9.1228e-02],
          [ 1.5572e-01, -1.5760e-01,  1.9752e-01]]],


        [[[-1.6035e-01, -3.1060e-01, -1.9747e-01],
          [-1.3087e-01,  2.0948e-01,  1.6781e-01],
          [ 1.6267e-01,  8.7212e-02,  1.9902e-01]],

         [[-2.4909e-01, -2.4603e-01, -1.9046e-01],
          [-1.5718e-01,  1.2243e-01,  1.9266e-01],
          [ 2.2827e-01,  1.9504e-02,  8.0770e-02]],

         [[-1.4507e-01,  6.1142e-02, -2.1703e-01],
          [ 5.8399e-02,  2.2112e-01, -9.1193e-02],
          [-9.7619e-03,  7.4191e-02,  4.6146e-02]]],


        [[[-1.2681e-01,  2.2098e-01,  9.3518e-02],
          [ 1.3734e-01,  1.3489e-01, -8.2922e-02],
          [-2.1649e-01, -1.5257e-02, -2.3286e-01]],

         [[ 5.1823e-02,  7.3332e-02,  2.1520e-02],
          [ 7.9051e-02,  2.2379e-01,  6.9160e-02],
          [-8.7329e-02, -5.9837e-02, -3.3150e-01]],

         [[-8.7149e-02,  7.8922e-02,  1.9140e-01],
          [ 3.0342e-02,  2.3058e-01,  7.8367e-02],
          [-2.2732e-01, -1.9910e-01, -2.4800e-01]]],


        ...,


        [[[-1.1482e-01, -1.2400e-01,  3.6555e-02],
          [ 1.1819e-01, -2.6950e-01, -1.0697e-01],
          [ 1.2792e-01, -9.0254e-02,  7.7721e-02]],

         [[ 1.7283e-01, -1.2446e-02,  4.0283e-03],
          [-5.1605e-02, -3.7130e-01, -2.2646e-01],
          [ 1.1141e-01, -1.7283e-02, -6.7665e-02]],

         [[ 2.0439e-01,  5.7162e-03,  8.2919e-02],
          [-2.5230e-03, -1.9782e-01, -1.6468e-01],
          [ 7.6336e-02, -1.0783e-01, -7.9822e-02]]],


        [[[-4.2796e-41, -3.8896e-41, -4.4006e-41],
          [ 1.0028e-40, -7.4925e-41,  1.4957e-41],
          [ 1.8957e-41, -6.5637e-41, -2.3172e-41]],

         [[ 6.8459e-41,  6.5836e-41, -1.1284e-40],
          [ 8.6958e-41, -1.0964e-40, -5.4035e-41],
          [-1.0527e-41,  1.0482e-41, -4.8163e-42]],

         [[-5.8346e-41,  7.8312e-41, -7.7808e-41],
          [ 5.8337e-41, -6.1893e-41, -1.2496e-40],
          [ 7.1200e-41, -8.0886e-41,  3.4821e-41]]],


        [[[-1.0877e-05, -9.6707e-06,  3.8943e-07],
          [-3.0047e-05, -4.3357e-05, -2.1145e-05],
          [-1.3506e-05, -1.4688e-05, -1.1897e-05]],

         [[-3.4056e-06, -2.2552e-06,  2.9767e-08],
          [-8.6021e-06, -7.8788e-06, -2.3589e-06],
          [-3.1244e-06, -1.4773e-06, -9.2266e-07]],

         [[-9.4563e-07, -7.1286e-07,  3.1040e-07],
          [-6.0967e-06, -6.3192e-06, -1.6189e-06],
          [-3.7889e-06, -1.4280e-06, -7.8594e-07]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5418]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0514]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 66 | Batch_idx: 0 |  Loss: (0.1700) | Acc: (94.00%) (121/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.2327) | Acc: (92.00%) (1300/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.2556) | Acc: (91.00%) (2456/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.2715) | Acc: (90.00%) (3609/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.2884) | Acc: (90.00%) (4736/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.2971) | Acc: (89.00%) (5865/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3091) | Acc: (89.00%) (6992/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3188) | Acc: (89.00%) (8106/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3225) | Acc: (88.00%) (9227/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3313) | Acc: (88.00%) (10344/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3317) | Acc: (88.00%) (11478/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3282) | Acc: (88.00%) (12640/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3282) | Acc: (88.00%) (13771/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3264) | Acc: (88.00%) (14922/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3263) | Acc: (89.00%) (16063/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3275) | Acc: (89.00%) (17205/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3267) | Acc: (89.00%) (18347/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3261) | Acc: (89.00%) (19495/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3273) | Acc: (89.00%) (20624/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3275) | Acc: (89.00%) (21765/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3274) | Acc: (89.00%) (22910/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3270) | Acc: (89.00%) (24060/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3258) | Acc: (89.00%) (25200/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3242) | Acc: (89.00%) (26357/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3229) | Acc: (89.00%) (27513/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3222) | Acc: (89.00%) (28655/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3227) | Acc: (89.00%) (29787/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3223) | Acc: (89.00%) (30928/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3226) | Acc: (89.00%) (32061/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3231) | Acc: (89.00%) (33196/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3226) | Acc: (89.00%) (34335/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3220) | Acc: (89.00%) (35487/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3227) | Acc: (89.00%) (36616/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3219) | Acc: (89.00%) (37770/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3217) | Acc: (89.00%) (38909/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3210) | Acc: (89.00%) (40060/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3189) | Acc: (89.00%) (41232/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3184) | Acc: (89.00%) (42379/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3178) | Acc: (89.00%) (43526/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3178) | Acc: (89.00%) (44633/50000)
# TEST : Loss: (0.3865) | Acc: (87.00%) (8746/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3331e-01,  2.4669e-01, -1.0632e-01],
          [-8.3874e-02,  3.4781e-02, -3.1396e-02],
          [ 4.6246e-02, -2.2215e-01,  2.5811e-01]],

         [[-1.2598e-01,  3.8712e-01,  1.1219e-01],
          [-1.4282e-02,  3.9031e-02, -1.5049e-01],
          [ 7.8721e-02, -3.4149e-01, -3.1088e-02]],

         [[-1.0625e-01,  2.6027e-01, -1.1647e-01],
          [ 8.4610e-02, -1.5512e-01, -8.1064e-02],
          [ 1.4146e-01, -1.5763e-01,  2.0933e-01]]],


        [[[-1.5183e-01, -3.1308e-01, -1.9834e-01],
          [-1.1914e-01,  2.1445e-01,  1.6857e-01],
          [ 1.7912e-01,  1.0035e-01,  2.1508e-01]],

         [[-2.4012e-01, -2.4582e-01, -1.8772e-01],
          [-1.4842e-01,  1.2973e-01,  1.9741e-01],
          [ 2.4399e-01,  3.3674e-02,  9.7613e-02]],

         [[-1.3513e-01,  6.2965e-02, -2.1411e-01],
          [ 7.2257e-02,  2.2928e-01, -8.6645e-02],
          [ 7.2109e-03,  8.5940e-02,  6.0224e-02]]],


        [[[-1.1662e-01,  2.2822e-01,  9.3682e-02],
          [ 1.4930e-01,  1.4381e-01, -8.3151e-02],
          [-2.1000e-01, -1.4586e-02, -2.4086e-01]],

         [[ 5.8974e-02,  8.0641e-02,  2.2904e-02],
          [ 9.1015e-02,  2.3575e-01,  7.1040e-02],
          [-8.0707e-02, -5.5311e-02, -3.3515e-01]],

         [[-7.8598e-02,  9.0439e-02,  1.9996e-01],
          [ 3.7968e-02,  2.4424e-01,  8.7348e-02],
          [-2.2425e-01, -1.9085e-01, -2.4284e-01]]],


        ...,


        [[[-1.1918e-01, -1.3360e-01,  2.7326e-02],
          [ 1.1346e-01, -2.7560e-01, -1.1379e-01],
          [ 1.1396e-01, -9.9673e-02,  6.6994e-02]],

         [[ 1.7184e-01, -2.2479e-02, -8.5680e-03],
          [-4.9638e-02, -3.7941e-01, -2.4333e-01],
          [ 1.0282e-01, -2.6107e-02, -7.9494e-02]],

         [[ 2.0585e-01,  9.6123e-04,  7.4256e-02],
          [-5.0986e-03, -2.0992e-01, -1.8152e-01],
          [ 6.2177e-02, -1.2454e-01, -9.8961e-02]]],


        [[[ 1.8293e-41, -7.1611e-41,  1.0034e-40],
          [ 1.2167e-40, -1.5882e-41, -9.1241e-41],
          [ 7.0227e-41, -7.8617e-41, -9.3475e-41]],

         [[ 4.5511e-41,  9.1938e-41, -7.5976e-41],
          [ 8.2368e-41,  8.5828e-41,  1.3359e-40],
          [ 1.1318e-40,  6.8225e-41, -5.8761e-41]],

         [[ 8.3052e-41, -9.6053e-41,  2.9179e-41],
          [-1.2195e-40,  8.0307e-41, -9.6823e-41],
          [ 5.3205e-41, -2.0431e-41, -1.0830e-40]]],


        [[[-1.5301e-06, -1.2842e-06,  4.0133e-08],
          [-3.9090e-06, -6.4223e-06, -2.7094e-06],
          [-1.4885e-06, -1.7531e-06, -1.3165e-06]],

         [[-3.1427e-07, -1.5406e-07,  1.1797e-09],
          [-6.9993e-07, -6.0444e-07, -1.1823e-07],
          [-2.1796e-07, -9.4220e-08, -4.0888e-08]],

         [[-7.5948e-08, -4.4161e-08,  1.0880e-08],
          [-5.0361e-07, -5.2592e-07, -9.2174e-08],
          [-3.2543e-07, -1.1882e-07, -4.7852e-08]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0049, -0.0035,  0.0077],
          [-0.0018,  0.0089,  0.0271],
          [ 0.0459,  0.0421,  0.0424]],

         [[-0.0075,  0.0008, -0.0014],
          [-0.0196, -0.0033,  0.0107],
          [ 0.0356,  0.0250,  0.0207]],

         [[-0.0062,  0.0051,  0.0078],
          [-0.0196, -0.0012,  0.0141],
          [ 0.0321,  0.0252,  0.0253]]],


        [[[-0.1132, -0.1220, -0.1252],
          [-0.0941, -0.1072, -0.1094],
          [-0.1023, -0.1190, -0.1136]],

         [[-0.0919, -0.1011, -0.1018],
          [-0.0822, -0.0954, -0.0946],
          [-0.0980, -0.1125, -0.1042]],

         [[-0.0748, -0.0868, -0.0898],
          [-0.0650, -0.0787, -0.0789],
          [-0.0841, -0.0950, -0.0892]]],


        [[[ 0.0457,  0.0345,  0.0099],
          [ 0.0241,  0.0229,  0.0184],
          [ 0.0233,  0.0266,  0.0251]],

         [[ 0.0606,  0.0488,  0.0221],
          [ 0.0385,  0.0366,  0.0287],
          [ 0.0368,  0.0400,  0.0341]],

         [[ 0.0635,  0.0579,  0.0379],
          [ 0.0460,  0.0451,  0.0416],
          [ 0.0406,  0.0438,  0.0425]]],


        ...,


        [[[-0.0006,  0.0082,  0.0080],
          [-0.0070,  0.0008,  0.0012],
          [-0.0004,  0.0056,  0.0036]],

         [[-0.0027,  0.0062,  0.0095],
          [-0.0141, -0.0054, -0.0000],
          [-0.0067, -0.0009,  0.0013]],

         [[-0.0090,  0.0022,  0.0090],
          [-0.0214, -0.0096, -0.0003],
          [-0.0174, -0.0086, -0.0007]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5429]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 67 | Batch_idx: 0 |  Loss: (0.1941) | Acc: (93.00%) (120/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.2590) | Acc: (91.00%) (1290/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.2500) | Acc: (91.00%) (2460/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.2503) | Acc: (91.00%) (3625/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.2588) | Acc: (91.00%) (4788/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.2614) | Acc: (91.00%) (5954/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.2608) | Acc: (91.00%) (7116/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.2626) | Acc: (91.00%) (8281/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.2628) | Acc: (91.00%) (9444/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.2610) | Acc: (91.00%) (10608/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.2612) | Acc: (91.00%) (11770/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.2594) | Acc: (91.00%) (12938/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.2596) | Acc: (91.00%) (14109/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.2628) | Acc: (90.00%) (15252/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.2633) | Acc: (90.00%) (16419/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.2645) | Acc: (90.00%) (17576/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.2639) | Acc: (90.00%) (18734/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.2617) | Acc: (90.00%) (19909/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.2640) | Acc: (90.00%) (21056/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.2660) | Acc: (90.00%) (22208/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.2669) | Acc: (90.00%) (23361/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.2697) | Acc: (90.00%) (24498/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.2692) | Acc: (90.00%) (25668/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.2704) | Acc: (90.00%) (26822/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.2703) | Acc: (90.00%) (27987/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.2695) | Acc: (90.00%) (29155/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.2680) | Acc: (90.00%) (30327/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.2658) | Acc: (90.00%) (31530/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.2652) | Acc: (90.00%) (32702/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.2639) | Acc: (90.00%) (33886/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.2629) | Acc: (91.00%) (35063/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.2612) | Acc: (91.00%) (36246/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.2610) | Acc: (91.00%) (37410/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.2606) | Acc: (91.00%) (38576/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.2609) | Acc: (91.00%) (39734/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.2602) | Acc: (91.00%) (40906/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.2598) | Acc: (91.00%) (42081/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.2596) | Acc: (91.00%) (43258/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.2596) | Acc: (91.00%) (44435/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.2599) | Acc: (91.00%) (45547/50000)
# TEST : Loss: (0.3489) | Acc: (89.00%) (8902/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1788e-01,  2.5529e-01, -1.1664e-01],
          [-7.0676e-02,  3.9957e-02, -3.8011e-02],
          [ 5.0987e-02, -2.1672e-01,  2.6672e-01]],

         [[-1.1897e-01,  3.8748e-01,  9.4768e-02],
          [-9.2635e-03,  3.4246e-02, -1.6081e-01],
          [ 7.7120e-02, -3.4871e-01, -2.8051e-02]],

         [[-8.7700e-02,  2.6537e-01, -1.2816e-01],
          [ 1.0360e-01, -1.4862e-01, -8.8612e-02],
          [ 1.4899e-01, -1.5180e-01,  2.1306e-01]]],


        [[[-1.5774e-01, -3.1827e-01, -2.0109e-01],
          [-1.2336e-01,  2.1305e-01,  1.6792e-01],
          [ 1.7643e-01,  9.8686e-02,  2.1350e-01]],

         [[-2.4657e-01, -2.4907e-01, -1.8976e-01],
          [-1.5034e-01,  1.3292e-01,  1.9986e-01],
          [ 2.4368e-01,  3.4993e-02,  9.9307e-02]],

         [[-1.3981e-01,  5.8476e-02, -2.2060e-01],
          [ 6.8594e-02,  2.2783e-01, -9.0063e-02],
          [ 2.3031e-03,  8.1328e-02,  5.5533e-02]]],


        [[[-1.2543e-01,  2.2349e-01,  8.8630e-02],
          [ 1.4494e-01,  1.4176e-01, -8.7488e-02],
          [-2.1782e-01, -1.9616e-02, -2.4785e-01]],

         [[ 5.0526e-02,  8.0149e-02,  2.2340e-02],
          [ 8.0673e-02,  2.3178e-01,  6.7490e-02],
          [-9.4174e-02, -6.2533e-02, -3.4214e-01]],

         [[-7.7528e-02,  9.8794e-02,  2.0635e-01],
          [ 3.8578e-02,  2.5047e-01,  9.2008e-02],
          [-2.2596e-01, -1.8677e-01, -2.4112e-01]]],


        ...,


        [[[-1.2276e-01, -1.3567e-01,  3.1667e-02],
          [ 1.0938e-01, -2.8356e-01, -1.0980e-01],
          [ 1.1844e-01, -9.9964e-02,  7.1748e-02]],

         [[ 1.5886e-01, -3.4148e-02, -6.8662e-03],
          [-6.0157e-02, -3.9691e-01, -2.3884e-01],
          [ 1.0407e-01, -2.6563e-02, -7.2307e-02]],

         [[ 1.9359e-01, -8.3898e-03,  7.1117e-02],
          [-1.8141e-02, -2.2496e-01, -1.8710e-01],
          [ 5.5567e-02, -1.3356e-01, -1.0425e-01]]],


        [[[ 5.1611e-41,  4.6777e-41,  2.9122e-41],
          [ 1.4518e-40,  3.4602e-41, -4.8579e-41],
          [-5.6859e-41,  4.8306e-41,  2.5740e-41]],

         [[-9.3122e-41, -6.7800e-41, -2.6234e-41],
          [-2.6426e-41,  1.0168e-40, -6.9060e-41],
          [-1.0617e-40, -8.6264e-41,  8.9200e-41]],

         [[-1.2322e-40,  8.2346e-41, -8.8210e-41],
          [ 1.3779e-41,  9.5552e-41,  1.2242e-40],
          [-1.4808e-40,  3.7370e-41,  2.0142e-41]]],


        [[[-1.3709e-07, -1.0707e-07,  2.4379e-09],
          [-3.1770e-07, -6.1359e-07, -2.1608e-07],
          [-9.8343e-08, -1.2795e-07, -8.7418e-08]],

         [[-1.6623e-08, -5.5841e-09,  2.1456e-11],
          [-3.1612e-08, -2.5353e-08, -2.8977e-09],
          [-8.1117e-09, -3.1315e-09, -8.5722e-10]],

         [[-3.3746e-09, -1.4149e-09,  1.6925e-10],
          [-2.3180e-08, -2.4436e-08, -2.6545e-09],
          [-1.5731e-08, -5.5194e-09, -1.5000e-09]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0689,  0.0590,  0.0609],
          [ 0.0497,  0.0514,  0.0479],
          [ 0.0425,  0.0474,  0.0581]],

         [[ 0.0403,  0.0339,  0.0360],
          [ 0.0215,  0.0391,  0.0317],
          [ 0.0256,  0.0407,  0.0426]],

         [[ 0.0142,  0.0109,  0.0092],
          [ 0.0027,  0.0236,  0.0168],
          [ 0.0153,  0.0304,  0.0380]]],


        [[[-0.0275, -0.0357, -0.0459],
          [-0.0307, -0.0354, -0.0459],
          [-0.0247, -0.0297, -0.0460]],

         [[-0.0347, -0.0459, -0.0571],
          [-0.0397, -0.0487, -0.0587],
          [-0.0325, -0.0416, -0.0544]],

         [[-0.0338, -0.0439, -0.0533],
          [-0.0388, -0.0476, -0.0554],
          [-0.0323, -0.0398, -0.0478]]],


        [[[ 0.0409,  0.0514,  0.0370],
          [ 0.0437,  0.0377,  0.0164],
          [ 0.0343,  0.0313,  0.0195]],

         [[ 0.0038,  0.0096,  0.0066],
          [ 0.0066, -0.0029, -0.0133],
          [ 0.0021,  0.0012, -0.0038]],

         [[-0.0460, -0.0397, -0.0389],
          [-0.0322, -0.0398, -0.0463],
          [-0.0240, -0.0222, -0.0252]]],


        ...,


        [[[-0.0017, -0.0007,  0.0007],
          [-0.0038, -0.0010,  0.0002],
          [-0.0089, -0.0052, -0.0029]],

         [[ 0.0025,  0.0033,  0.0022],
          [-0.0029, -0.0000, -0.0002],
          [-0.0094, -0.0059, -0.0044]],

         [[ 0.0043,  0.0044,  0.0027],
          [-0.0001,  0.0021,  0.0014],
          [-0.0052, -0.0028, -0.0021]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5416]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 68 | Batch_idx: 0 |  Loss: (0.2696) | Acc: (89.00%) (114/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.2502) | Acc: (91.00%) (1287/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.2488) | Acc: (91.00%) (2451/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.2456) | Acc: (91.00%) (3626/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.2403) | Acc: (91.00%) (4808/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.2297) | Acc: (92.00%) (6009/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.2220) | Acc: (92.00%) (7211/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.2167) | Acc: (92.00%) (8404/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.2181) | Acc: (92.00%) (9580/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.2184) | Acc: (92.00%) (10760/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.2175) | Acc: (92.00%) (11955/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.2180) | Acc: (92.00%) (13131/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.2202) | Acc: (92.00%) (14300/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.2228) | Acc: (92.00%) (15467/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.2238) | Acc: (92.00%) (16634/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.2263) | Acc: (92.00%) (17797/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.2277) | Acc: (92.00%) (18976/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.2282) | Acc: (92.00%) (20148/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.2284) | Acc: (92.00%) (21322/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.2301) | Acc: (92.00%) (22493/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.2304) | Acc: (92.00%) (23672/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.2315) | Acc: (91.00%) (24832/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.2316) | Acc: (91.00%) (26014/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.2318) | Acc: (91.00%) (27193/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.2314) | Acc: (92.00%) (28385/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.2308) | Acc: (92.00%) (29563/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.2315) | Acc: (91.00%) (30723/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.2303) | Acc: (91.00%) (31906/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.2301) | Acc: (92.00%) (33092/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.2302) | Acc: (92.00%) (34272/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.2324) | Acc: (91.00%) (35423/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.2331) | Acc: (91.00%) (36595/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.2344) | Acc: (91.00%) (37750/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.2345) | Acc: (91.00%) (38928/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.2349) | Acc: (91.00%) (40100/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.2353) | Acc: (91.00%) (41272/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.2358) | Acc: (91.00%) (42444/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.2363) | Acc: (91.00%) (43608/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.2368) | Acc: (91.00%) (44783/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.2370) | Acc: (91.00%) (45913/50000)
# TEST : Loss: (0.3474) | Acc: (89.00%) (8901/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2465e-01,  2.5125e-01, -1.1785e-01],
          [-6.7046e-02,  3.6143e-02, -3.2256e-02],
          [ 6.8217e-02, -2.1300e-01,  2.7451e-01]],

         [[-1.3198e-01,  3.7871e-01,  8.6271e-02],
          [-1.2265e-02,  2.0639e-02, -1.6630e-01],
          [ 8.0770e-02, -3.6466e-01, -3.7124e-02]],

         [[-9.9396e-02,  2.5562e-01, -1.3048e-01],
          [ 9.8321e-02, -1.5984e-01, -9.0945e-02],
          [ 1.4923e-01, -1.5720e-01,  2.0608e-01]]],


        [[[-1.4792e-01, -3.1073e-01, -1.9680e-01],
          [-1.1307e-01,  2.2494e-01,  1.7954e-01],
          [ 1.8380e-01,  1.1019e-01,  2.2576e-01]],

         [[-2.4348e-01, -2.4596e-01, -1.8762e-01],
          [-1.4752e-01,  1.3848e-01,  2.0620e-01],
          [ 2.4578e-01,  4.2016e-02,  1.0787e-01]],

         [[-1.4193e-01,  5.6725e-02, -2.2288e-01],
          [ 6.7676e-02,  2.2877e-01, -8.8114e-02],
          [ 2.9315e-04,  8.1060e-02,  5.5939e-02]]],


        [[[-1.1534e-01,  2.3494e-01,  9.7110e-02],
          [ 1.5330e-01,  1.4779e-01, -8.4554e-02],
          [-2.0804e-01, -1.4771e-02, -2.4655e-01]],

         [[ 5.6464e-02,  8.4580e-02,  2.0321e-02],
          [ 8.5470e-02,  2.3172e-01,  6.0700e-02],
          [-9.3662e-02, -6.7072e-02, -3.5055e-01]],

         [[-7.8103e-02,  9.5690e-02,  1.9826e-01],
          [ 3.8784e-02,  2.4655e-01,  8.4038e-02],
          [-2.3003e-01, -1.9375e-01, -2.4983e-01]]],


        ...,


        [[[-1.2760e-01, -1.3911e-01,  2.7159e-02],
          [ 1.0227e-01, -2.8999e-01, -1.1519e-01],
          [ 1.1868e-01, -9.7763e-02,  7.4399e-02]],

         [[ 1.6200e-01, -2.7523e-02, -6.0360e-03],
          [-5.9986e-02, -3.9474e-01, -2.4298e-01],
          [ 1.0707e-01, -2.1573e-02, -6.9336e-02]],

         [[ 2.0603e-01,  8.1140e-03,  8.0346e-02],
          [-7.1975e-03, -2.1186e-01, -1.7974e-01],
          [ 6.5484e-02, -1.2312e-01, -1.0002e-01]]],


        [[[ 1.4579e-40,  5.6718e-41,  1.1728e-40],
          [-1.3858e-40, -2.3072e-41, -1.5270e-40],
          [ 8.9748e-41, -6.4046e-41,  8.8142e-41]],

         [[-1.3902e-41,  5.8064e-41,  1.0606e-40],
          [ 9.7298e-41,  1.1347e-40,  1.1174e-40],
          [ 1.1435e-40, -6.2433e-41, -1.2368e-40]],

         [[ 4.7561e-41,  9.7910e-41, -9.6303e-41],
          [-2.6776e-41, -6.2970e-41,  1.3711e-40],
          [-1.3985e-41, -5.4073e-41,  2.3452e-41]]],


        [[[-6.9875e-09, -4.9863e-09,  7.6193e-11],
          [-1.4329e-08, -3.3899e-08, -9.5158e-09],
          [-3.4172e-09, -5.0403e-09, -3.0571e-09]],

         [[-4.3617e-10, -9.0649e-11,  1.4372e-13],
          [-6.7890e-10, -4.9565e-10, -2.8510e-11],
          [-1.3619e-10, -4.5513e-11, -6.8983e-12]],

         [[-7.0984e-11, -1.9622e-11,  9.2586e-13],
          [-5.0994e-10, -5.4404e-10, -3.2120e-11],
          [-3.6826e-10, -1.2284e-10, -2.0229e-11]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0037,  0.0058,  0.0254],
          [ 0.0062,  0.0087,  0.0195],
          [ 0.0148,  0.0127,  0.0238]],

         [[-0.0068, -0.0007,  0.0195],
          [ 0.0058,  0.0070,  0.0154],
          [ 0.0158,  0.0118,  0.0182]],

         [[-0.0093, -0.0037,  0.0083],
          [ 0.0027,  0.0062,  0.0147],
          [ 0.0073,  0.0085,  0.0207]]],


        [[[ 0.0165,  0.0092, -0.0011],
          [ 0.0134,  0.0090,  0.0020],
          [ 0.0174,  0.0118,  0.0055]],

         [[ 0.0288,  0.0223,  0.0120],
          [ 0.0231,  0.0202,  0.0140],
          [ 0.0229,  0.0204,  0.0151]],

         [[ 0.0264,  0.0187,  0.0061],
          [ 0.0213,  0.0149,  0.0048],
          [ 0.0288,  0.0215,  0.0113]]],


        [[[-0.0554, -0.0516, -0.0389],
          [-0.0474, -0.0465, -0.0385],
          [-0.0436, -0.0463, -0.0367]],

         [[-0.0396, -0.0322, -0.0186],
          [-0.0276, -0.0250, -0.0175],
          [-0.0219, -0.0262, -0.0193]],

         [[-0.0419, -0.0375, -0.0299],
          [-0.0318, -0.0308, -0.0286],
          [-0.0315, -0.0366, -0.0337]]],


        ...,


        [[[ 0.0079,  0.0119,  0.0097],
          [-0.0020,  0.0016,  0.0011],
          [-0.0001,  0.0065,  0.0064]],

         [[ 0.0092,  0.0119,  0.0095],
          [ 0.0008,  0.0036,  0.0028],
          [ 0.0038,  0.0099,  0.0100]],

         [[-0.0019,  0.0028,  0.0039],
          [-0.0147, -0.0106, -0.0084],
          [-0.0164, -0.0106, -0.0085]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5401]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 69 | Batch_idx: 0 |  Loss: (0.2051) | Acc: (92.00%) (119/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.2295) | Acc: (92.00%) (1305/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.2601) | Acc: (91.00%) (2458/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.2767) | Acc: (90.00%) (3607/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.2779) | Acc: (90.00%) (4772/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.2767) | Acc: (90.00%) (5932/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.2796) | Acc: (90.00%) (7090/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.2736) | Acc: (90.00%) (8257/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.2654) | Acc: (91.00%) (9449/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.2633) | Acc: (91.00%) (10621/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.2574) | Acc: (91.00%) (11820/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.2526) | Acc: (91.00%) (13013/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.2486) | Acc: (91.00%) (14202/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.2478) | Acc: (91.00%) (15379/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.2431) | Acc: (91.00%) (16577/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.2414) | Acc: (91.00%) (17753/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.2390) | Acc: (91.00%) (18948/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.2380) | Acc: (91.00%) (20120/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.2367) | Acc: (91.00%) (21306/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.2352) | Acc: (92.00%) (22493/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.2335) | Acc: (92.00%) (23690/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.2325) | Acc: (92.00%) (24876/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.2324) | Acc: (92.00%) (26062/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.2306) | Acc: (92.00%) (27270/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.2295) | Acc: (92.00%) (28459/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.2287) | Acc: (92.00%) (29644/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.2279) | Acc: (92.00%) (30835/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.2275) | Acc: (92.00%) (32024/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.2265) | Acc: (92.00%) (33219/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.2269) | Acc: (92.00%) (34395/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.2261) | Acc: (92.00%) (35589/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.2251) | Acc: (92.00%) (36783/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.2240) | Acc: (92.00%) (37981/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.2225) | Acc: (92.00%) (39194/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.2223) | Acc: (92.00%) (40387/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.2210) | Acc: (92.00%) (41593/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.2211) | Acc: (92.00%) (42772/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.2201) | Acc: (92.00%) (43975/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.2193) | Acc: (92.00%) (45172/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.2193) | Acc: (92.00%) (46308/50000)
# TEST : Loss: (0.3023) | Acc: (90.00%) (9031/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2463e-01,  2.5049e-01, -1.1814e-01],
          [-6.5467e-02,  3.6318e-02, -3.1816e-02],
          [ 6.7795e-02, -2.1345e-01,  2.7451e-01]],

         [[-1.3013e-01,  3.7927e-01,  8.7124e-02],
          [-9.5136e-03,  2.2024e-02, -1.6411e-01],
          [ 8.1808e-02, -3.6322e-01, -3.5091e-02]],

         [[-9.8088e-02,  2.5513e-01, -1.3003e-01],
          [ 9.9924e-02, -1.5858e-01, -9.0038e-02],
          [ 1.4880e-01, -1.5717e-01,  2.0605e-01]]],


        [[[-1.4906e-01, -3.1152e-01, -1.9753e-01],
          [-1.1417e-01,  2.2321e-01,  1.7805e-01],
          [ 1.8225e-01,  1.0888e-01,  2.2398e-01]],

         [[-2.4505e-01, -2.4762e-01, -1.8932e-01],
          [-1.4869e-01,  1.3637e-01,  2.0393e-01],
          [ 2.4420e-01,  4.0600e-02,  1.0595e-01]],

         [[-1.4285e-01,  5.4854e-02, -2.2427e-01],
          [ 6.6369e-02,  2.2646e-01, -8.9812e-02],
          [-8.6902e-04,  7.9415e-02,  5.4033e-02]]],


        [[[-1.1305e-01,  2.3694e-01,  9.8385e-02],
          [ 1.5479e-01,  1.4941e-01, -8.3565e-02],
          [-2.0579e-01, -1.2754e-02, -2.4515e-01]],

         [[ 5.9738e-02,  8.7972e-02,  2.2607e-02],
          [ 8.7962e-02,  2.3403e-01,  6.2170e-02],
          [-9.0919e-02, -6.4187e-02, -3.4821e-01]],

         [[-7.3850e-02,  9.9851e-02,  2.0136e-01],
          [ 4.2726e-02,  2.5019e-01,  8.7102e-02],
          [-2.2537e-01, -1.8882e-01, -2.4563e-01]]],


        ...,


        [[[-1.2825e-01, -1.4042e-01,  2.5008e-02],
          [ 1.0121e-01, -2.8927e-01, -1.1495e-01],
          [ 1.1551e-01, -1.0098e-01,  7.1109e-02]],

         [[ 1.6004e-01, -2.9059e-02, -7.3603e-03],
          [-6.0241e-02, -3.9126e-01, -2.3956e-01],
          [ 1.0383e-01, -2.5572e-02, -7.1966e-02]],

         [[ 2.0705e-01,  1.0766e-02,  8.2093e-02],
          [-3.8513e-03, -2.0581e-01, -1.7388e-01],
          [ 6.6492e-02, -1.2131e-01, -9.8698e-02]]],


        [[[-1.2222e-40, -6.0067e-41, -2.4912e-41],
          [ 4.1048e-41,  8.8320e-41,  1.5946e-40],
          [-8.1567e-41, -9.1747e-41, -9.0106e-41]],

         [[-1.6866e-41,  1.0435e-40,  9.1104e-41],
          [-3.7921e-41,  1.3427e-40,  2.4028e-41],
          [-6.5533e-41, -7.4891e-41,  3.6833e-41]],

         [[-1.3340e-40, -1.2014e-40,  8.6620e-41],
          [ 6.7781e-41,  1.2461e-40,  3.1480e-41],
          [ 1.3437e-40,  2.4265e-41, -9.9667e-41]]],


        [[[-1.7493e-10, -1.1133e-10,  1.0237e-12],
          [-3.0716e-10, -9.3981e-10, -1.9792e-10],
          [-5.2569e-11, -9.0978e-11, -4.7412e-11]],

         [[-4.6841e-12, -5.2410e-13,  2.6040e-16],
          [-5.6356e-12, -3.6448e-12, -8.5782e-14],
          [-8.2251e-13, -2.2795e-13, -1.5931e-14]],

         [[-5.7369e-13, -9.2463e-14,  1.2813e-15],
          [-4.3662e-12, -4.7305e-12, -1.2670e-13],
          [-3.4158e-12, -1.0676e-12, -9.1917e-14]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5587]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0248]], device='cuda:0')

Epoch: 70 | Batch_idx: 0 |  Loss: (0.1533) | Acc: (94.00%) (121/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.2044) | Acc: (92.00%) (1299/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.2034) | Acc: (92.00%) (2499/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.2029) | Acc: (92.00%) (3680/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.2022) | Acc: (92.00%) (4875/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.1996) | Acc: (93.00%) (6072/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.1997) | Acc: (93.00%) (7274/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.2056) | Acc: (92.00%) (8443/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.2039) | Acc: (93.00%) (9644/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.2033) | Acc: (93.00%) (10842/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.2022) | Acc: (93.00%) (12048/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.2013) | Acc: (93.00%) (13250/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.2007) | Acc: (93.00%) (14446/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.2021) | Acc: (93.00%) (15633/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.2022) | Acc: (93.00%) (16816/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.2009) | Acc: (93.00%) (18021/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.2003) | Acc: (93.00%) (19214/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.1997) | Acc: (93.00%) (20409/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.1991) | Acc: (93.00%) (21615/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.1992) | Acc: (93.00%) (22806/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.1983) | Acc: (93.00%) (24008/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.1984) | Acc: (93.00%) (25207/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.1992) | Acc: (93.00%) (26397/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.1981) | Acc: (93.00%) (27611/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.1979) | Acc: (93.00%) (28818/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.1985) | Acc: (93.00%) (30004/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.1985) | Acc: (93.00%) (31207/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.1976) | Acc: (93.00%) (32418/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.1966) | Acc: (93.00%) (33622/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.1966) | Acc: (93.00%) (34812/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.1964) | Acc: (93.00%) (36009/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.1964) | Acc: (93.00%) (37202/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.1961) | Acc: (93.00%) (38400/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.1958) | Acc: (93.00%) (39601/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.1960) | Acc: (93.00%) (40798/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.1958) | Acc: (93.00%) (41995/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.1962) | Acc: (93.00%) (43184/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.1961) | Acc: (93.00%) (44386/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.1962) | Acc: (93.00%) (45566/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.1968) | Acc: (93.00%) (46711/50000)
# TEST : Loss: (0.2948) | Acc: (90.00%) (9031/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2433e-01,  2.4988e-01, -1.1786e-01],
          [-6.5311e-02,  3.6230e-02, -3.1741e-02],
          [ 6.7631e-02, -2.1291e-01,  2.7386e-01]],

         [[-1.2981e-01,  3.7830e-01,  8.6910e-02],
          [-9.4903e-03,  2.1968e-02, -1.6371e-01],
          [ 8.1602e-02, -3.6224e-01, -3.5004e-02]],

         [[-9.7837e-02,  2.5444e-01, -1.2969e-01],
          [ 9.9670e-02, -1.5815e-01, -8.9803e-02],
          [ 1.4841e-01, -1.5673e-01,  2.0550e-01]]],


        [[[-1.4874e-01, -3.1084e-01, -1.9710e-01],
          [-1.1392e-01,  2.2272e-01,  1.7766e-01],
          [ 1.8184e-01,  1.0863e-01,  2.2347e-01]],

         [[-2.4450e-01, -2.4707e-01, -1.8890e-01],
          [-1.4836e-01,  1.3608e-01,  2.0348e-01],
          [ 2.4365e-01,  4.0508e-02,  1.0571e-01]],

         [[-1.4252e-01,  5.4726e-02, -2.2375e-01],
          [ 6.6216e-02,  2.2594e-01, -8.9605e-02],
          [-8.6698e-04,  7.9229e-02,  5.3906e-02]]],


        [[[-1.1283e-01,  2.3648e-01,  9.8192e-02],
          [ 1.5450e-01,  1.4913e-01, -8.3406e-02],
          [-2.0540e-01, -1.2729e-02, -2.4467e-01]],

         [[ 5.9620e-02,  8.7795e-02,  2.2562e-02],
          [ 8.7793e-02,  2.3357e-01,  6.2049e-02],
          [-9.0741e-02, -6.4059e-02, -3.4750e-01]],

         [[-7.3699e-02,  9.9646e-02,  2.0094e-01],
          [ 4.2641e-02,  2.4969e-01,  8.6926e-02],
          [-2.2491e-01, -1.8843e-01, -2.4512e-01]]],


        ...,


        [[[-1.2750e-01, -1.3936e-01,  2.4823e-02],
          [ 1.0053e-01, -2.8624e-01, -1.1376e-01],
          [ 1.1483e-01, -1.0018e-01,  7.0545e-02]],

         [[ 1.5903e-01, -2.8800e-02, -7.2961e-03],
          [-5.9778e-02, -3.8502e-01, -2.3574e-01],
          [ 1.0316e-01, -2.5329e-02, -7.1274e-02]],

         [[ 2.0577e-01,  1.0682e-02,  8.1448e-02],
          [-3.8237e-03, -2.0370e-01, -1.7204e-01],
          [ 6.6065e-02, -1.2028e-01, -9.7844e-02]]],


        [[[ 8.9024e-41, -8.4763e-41,  5.0238e-41],
          [ 6.4576e-41, -1.3719e-42, -1.7262e-40],
          [-9.7327e-41,  9.9883e-41, -1.0640e-40]],

         [[ 5.6994e-41, -3.6355e-41,  3.9482e-41],
          [-1.2226e-40,  1.0911e-40, -1.0030e-40],
          [ 2.5317e-41,  1.1796e-40,  1.3620e-40]],

         [[-1.6153e-40,  5.3866e-42, -2.4726e-41],
          [-3.8267e-41, -4.3229e-41,  3.7059e-41],
          [ 4.4058e-41, -4.2528e-41,  1.3808e-40]]],


        [[[-1.7688e-12, -9.7169e-13,  4.6290e-15],
          [-2.5439e-12, -1.0831e-11, -1.5765e-12],
          [-2.8344e-13, -6.0346e-13, -2.5835e-13]],

         [[-1.5808e-14, -7.8084e-16,  8.0285e-20],
          [-1.3560e-14, -7.4725e-15, -5.3068e-17],
          [-1.2987e-15, -2.8038e-16, -6.8656e-18]],

         [[-1.3325e-15, -1.0482e-16,  2.7133e-19],
          [-1.0943e-14, -1.2099e-14, -1.1310e-16],
          [-9.5112e-15, -2.7288e-15, -9.9237e-17]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5651]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0114]], device='cuda:0')

Epoch: 71 | Batch_idx: 0 |  Loss: (0.1327) | Acc: (94.00%) (121/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.1873) | Acc: (94.00%) (1325/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.1811) | Acc: (94.00%) (2535/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.1801) | Acc: (94.00%) (3745/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.1832) | Acc: (94.00%) (4952/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.1864) | Acc: (94.00%) (6154/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.1876) | Acc: (94.00%) (7345/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.1848) | Acc: (94.00%) (8564/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.1853) | Acc: (94.00%) (9767/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.1851) | Acc: (94.00%) (10965/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.1845) | Acc: (94.00%) (12166/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.1862) | Acc: (94.00%) (13363/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.1864) | Acc: (94.00%) (14573/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.1873) | Acc: (94.00%) (15777/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.1880) | Acc: (94.00%) (16972/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.1866) | Acc: (94.00%) (18172/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.1875) | Acc: (93.00%) (19364/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.1869) | Acc: (94.00%) (20579/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.1892) | Acc: (93.00%) (21765/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.1905) | Acc: (93.00%) (22960/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.1911) | Acc: (93.00%) (24158/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.1918) | Acc: (93.00%) (25349/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.1918) | Acc: (93.00%) (26555/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.1921) | Acc: (93.00%) (27750/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.1913) | Acc: (93.00%) (28962/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.1910) | Acc: (93.00%) (30163/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.1909) | Acc: (93.00%) (31363/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.1910) | Acc: (93.00%) (32570/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.1914) | Acc: (93.00%) (33764/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.1920) | Acc: (93.00%) (34954/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.1921) | Acc: (93.00%) (36152/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.1917) | Acc: (93.00%) (37358/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.1919) | Acc: (93.00%) (38557/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.1922) | Acc: (93.00%) (39748/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.1932) | Acc: (93.00%) (40923/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.1931) | Acc: (93.00%) (42124/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.1938) | Acc: (93.00%) (43305/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.1940) | Acc: (93.00%) (44494/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.1938) | Acc: (93.00%) (45690/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.1934) | Acc: (93.00%) (46853/50000)
# TEST : Loss: (0.2921) | Acc: (90.00%) (9043/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2398e-01,  2.4914e-01, -1.1753e-01],
          [-6.5122e-02,  3.6122e-02, -3.1650e-02],
          [ 6.7433e-02, -2.1225e-01,  2.7308e-01]],

         [[-1.2943e-01,  3.7712e-01,  8.6652e-02],
          [-9.4621e-03,  2.1900e-02, -1.6322e-01],
          [ 8.1352e-02, -3.6106e-01, -3.4898e-02]],

         [[-9.7533e-02,  2.5360e-01, -1.2928e-01],
          [ 9.9362e-02, -1.5764e-01, -8.9517e-02],
          [ 1.4794e-01, -1.5620e-01,  2.0484e-01]]],


        [[[-1.4834e-01, -3.1002e-01, -1.9658e-01],
          [-1.1362e-01,  2.2213e-01,  1.7719e-01],
          [ 1.8134e-01,  1.0833e-01,  2.2285e-01]],

         [[-2.4385e-01, -2.4641e-01, -1.8840e-01],
          [-1.4797e-01,  1.3571e-01,  2.0294e-01],
          [ 2.4298e-01,  4.0398e-02,  1.0542e-01]],

         [[-1.4211e-01,  5.4571e-02, -2.2312e-01],
          [ 6.6031e-02,  2.2531e-01, -8.9354e-02],
          [-8.6450e-04,  7.9004e-02,  5.3752e-02]]],


        [[[-1.1256e-01,  2.3591e-01,  9.7958e-02],
          [ 1.5415e-01,  1.4878e-01, -8.3214e-02],
          [-2.0493e-01, -1.2700e-02, -2.4409e-01]],

         [[ 5.9476e-02,  8.7581e-02,  2.2507e-02],
          [ 8.7588e-02,  2.3302e-01,  6.1903e-02],
          [-9.0525e-02, -6.3905e-02, -3.4665e-01]],

         [[-7.3516e-02,  9.9396e-02,  2.0044e-01],
          [ 4.2537e-02,  2.4908e-01,  8.6714e-02],
          [-2.2435e-01, -1.8796e-01, -2.4449e-01]]],


        ...,


        [[[-1.2660e-01, -1.3809e-01,  2.4600e-02],
          [ 9.9703e-02, -2.8260e-01, -1.1233e-01],
          [ 1.1401e-01, -9.9216e-02,  6.9866e-02]],

         [[ 1.5781e-01, -2.8489e-02, -7.2187e-03],
          [-5.9219e-02, -3.7756e-01, -2.3117e-01],
          [ 1.0236e-01, -2.5036e-02, -7.0441e-02]],

         [[ 2.0423e-01,  1.0581e-02,  8.0670e-02],
          [-3.7903e-03, -2.0115e-01, -1.6983e-01],
          [ 6.5549e-02, -1.1903e-01, -9.6816e-02]]],


        [[[ 1.0603e-40,  5.2633e-42, -1.3201e-40],
          [-1.1195e-40, -2.6597e-42,  4.4966e-41],
          [ 1.5187e-40, -8.7475e-41, -6.9434e-42]],

         [[-1.1556e-40, -1.2397e-40, -1.5287e-40],
          [ 1.0965e-40,  2.2786e-40,  1.5071e-40],
          [ 2.9752e-41, -5.9600e-41, -7.8009e-41]],

         [[ 1.7333e-40,  1.5197e-40,  7.1416e-41],
          [ 9.8406e-41, -1.4689e-40,  4.3994e-41],
          [-1.0276e-40,  3.3113e-41, -1.4078e-40]]],


        [[[-5.5162e-15, -2.4975e-15,  4.9650e-18],
          [-6.1019e-15, -4.0091e-14, -3.5919e-15],
          [-3.8477e-16, -1.0792e-15, -3.5568e-16]],

         [[-1.1429e-17, -1.8334e-19,  1.9026e-24],
          [-6.1813e-18, -2.7333e-18, -3.5543e-21],
          [-3.3069e-19, -5.0306e-20, -2.6970e-22]],

         [[-5.7872e-19, -1.6758e-20,  3.5927e-24],
          [-5.2755e-18, -5.9970e-18, -1.2870e-20],
          [-5.2947e-18, -1.3514e-18, -1.4806e-20]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5633]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0086]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 72 | Batch_idx: 0 |  Loss: (0.2023) | Acc: (95.00%) (122/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.2139) | Acc: (92.00%) (1305/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.2420) | Acc: (91.00%) (2467/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.2720) | Acc: (90.00%) (3588/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.2881) | Acc: (90.00%) (4726/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.2995) | Acc: (89.00%) (5854/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.3161) | Acc: (89.00%) (6958/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.3234) | Acc: (88.00%) (8078/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.3307) | Acc: (88.00%) (9196/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.3370) | Acc: (88.00%) (10308/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.3370) | Acc: (88.00%) (11438/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.3363) | Acc: (88.00%) (12573/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.3372) | Acc: (88.00%) (13692/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.3386) | Acc: (88.00%) (14810/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.3381) | Acc: (88.00%) (15952/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.3379) | Acc: (88.00%) (17085/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.3366) | Acc: (88.00%) (18227/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.3359) | Acc: (88.00%) (19357/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.3327) | Acc: (88.00%) (20524/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.3306) | Acc: (88.00%) (21685/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.3298) | Acc: (88.00%) (22837/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.3282) | Acc: (88.00%) (23995/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.3263) | Acc: (88.00%) (25151/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.3265) | Acc: (88.00%) (26296/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.3269) | Acc: (88.00%) (27435/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.3261) | Acc: (88.00%) (28590/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.3251) | Acc: (88.00%) (29733/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.3235) | Acc: (89.00%) (30886/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.3222) | Acc: (89.00%) (32048/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.3218) | Acc: (89.00%) (33185/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.3203) | Acc: (89.00%) (34332/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.3194) | Acc: (89.00%) (35481/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.3187) | Acc: (89.00%) (36627/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.3183) | Acc: (89.00%) (37777/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.3165) | Acc: (89.00%) (38943/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.3161) | Acc: (89.00%) (40084/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.3149) | Acc: (89.00%) (41237/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.3139) | Acc: (89.00%) (42400/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.3135) | Acc: (89.00%) (43543/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.3127) | Acc: (89.00%) (44664/50000)
# TEST : Loss: (0.3863) | Acc: (87.00%) (8781/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3314e-01,  2.4284e-01, -1.2818e-01],
          [-7.5282e-02,  2.6974e-02, -5.6514e-02],
          [ 6.7854e-02, -2.2441e-01,  2.6592e-01]],

         [[-1.3439e-01,  3.8547e-01,  9.0519e-02],
          [-1.6913e-02,  2.2930e-02, -1.6864e-01],
          [ 7.7550e-02, -3.7132e-01, -2.7020e-02]],

         [[-9.9050e-02,  2.5602e-01, -1.2906e-01],
          [ 9.7469e-02, -1.5348e-01, -9.9782e-02],
          [ 1.4131e-01, -1.6580e-01,  2.0620e-01]]],


        [[[-1.6415e-01, -3.2749e-01, -2.1044e-01],
          [-1.2515e-01,  2.1131e-01,  1.7097e-01],
          [ 1.7300e-01,  1.0144e-01,  2.1647e-01]],

         [[-2.4658e-01, -2.5012e-01, -1.8797e-01],
          [-1.4681e-01,  1.3671e-01,  2.0694e-01],
          [ 2.5081e-01,  4.6873e-02,  1.1018e-01]],

         [[-1.4509e-01,  4.8974e-02, -2.2602e-01],
          [ 6.4093e-02,  2.2213e-01, -9.0595e-02],
          [ 2.0843e-03,  7.9170e-02,  5.1056e-02]]],


        [[[-1.2543e-01,  2.3132e-01,  9.5463e-02],
          [ 1.4420e-01,  1.5000e-01, -8.2337e-02],
          [-2.1568e-01, -2.1665e-02, -2.5973e-01]],

         [[ 4.3259e-02,  8.3137e-02,  2.1153e-02],
          [ 7.5503e-02,  2.3522e-01,  6.4774e-02],
          [-1.0157e-01, -6.8214e-02, -3.5656e-01]],

         [[-8.4642e-02,  9.6786e-02,  1.9790e-01],
          [ 3.6658e-02,  2.5639e-01,  9.2771e-02],
          [-2.2824e-01, -1.8398e-01, -2.4847e-01]]],


        ...,


        [[[-1.0317e-01, -1.1050e-01,  3.9415e-02],
          [ 1.1480e-01, -2.7335e-01, -1.2665e-01],
          [ 1.1839e-01, -1.0416e-01,  4.7876e-02]],

         [[ 1.8095e-01, -5.7829e-03,  5.8963e-03],
          [-4.1626e-02, -3.7414e-01, -2.5221e-01],
          [ 1.1352e-01, -2.4597e-02, -8.2960e-02]],

         [[ 2.2866e-01,  2.8205e-02,  8.7706e-02],
          [ 2.0201e-02, -1.9359e-01, -1.7871e-01],
          [ 8.4540e-02, -1.1433e-01, -1.0648e-01]]],


        [[[-1.3772e-40, -2.8455e-41, -1.0061e-40],
          [ 1.5234e-40,  4.0356e-41, -2.2280e-40],
          [ 1.3320e-40,  6.4186e-41,  1.2766e-40]],

         [[ 1.3452e-40,  1.1696e-40, -2.9553e-42],
          [-1.2783e-40, -3.3369e-41, -1.6575e-40],
          [-1.0822e-40,  3.5502e-41,  2.0778e-40]],

         [[-1.3139e-40,  6.3845e-41, -3.4734e-41],
          [ 2.2393e-40, -1.2549e-40,  1.3915e-40],
          [ 6.1214e-41,  8.9165e-41,  1.6517e-40]]],


        [[[-3.5829e-18, -1.2463e-18,  7.3394e-22],
          [-2.7700e-18, -3.2843e-17, -1.5194e-18],
          [-7.9303e-20, -3.2676e-19, -7.4770e-20]],

         [[-9.6002e-22, -2.8538e-24,  4.6329e-31],
          [-2.6403e-22, -8.3961e-23, -6.8760e-27],
          [-5.8390e-24, -5.1222e-25, -1.9132e-28]],

         [[-2.3000e-23, -1.4181e-25,  1.9028e-31],
          [-2.4485e-22, -2.9002e-22, -6.2290e-26],
          [-3.0384e-22, -6.5269e-23, -1.1202e-25]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0338,  0.0341,  0.0114],
          [ 0.0563,  0.0690,  0.0623],
          [ 0.0485,  0.0638,  0.0798]],

         [[ 0.0093,  0.0181, -0.0035],
          [ 0.0357,  0.0480,  0.0444],
          [ 0.0297,  0.0409,  0.0645]],

         [[ 0.0138,  0.0301,  0.0036],
          [ 0.0370,  0.0495,  0.0473],
          [ 0.0303,  0.0395,  0.0700]]],


        [[[ 0.0327,  0.0215,  0.0131],
          [ 0.0298,  0.0184,  0.0102],
          [ 0.0388,  0.0264,  0.0173]],

         [[ 0.0287,  0.0152,  0.0067],
          [ 0.0211,  0.0135,  0.0085],
          [ 0.0286,  0.0224,  0.0181]],

         [[-0.0307, -0.0394, -0.0434],
          [-0.0344, -0.0356, -0.0371],
          [-0.0285, -0.0305, -0.0320]]],


        [[[-0.0390, -0.0390, -0.0256],
          [-0.0336, -0.0351, -0.0302],
          [-0.0340, -0.0292, -0.0291]],

         [[-0.0337, -0.0311, -0.0160],
          [-0.0283, -0.0304, -0.0252],
          [-0.0262, -0.0226, -0.0239]],

         [[-0.0110, -0.0042,  0.0090],
          [-0.0119, -0.0081, -0.0039],
          [-0.0073, -0.0002,  0.0004]]],


        ...,


        [[[-0.0017, -0.0052,  0.0018],
          [ 0.0086,  0.0005,  0.0045],
          [ 0.0031, -0.0054, -0.0065]],

         [[-0.0086, -0.0103, -0.0023],
          [ 0.0011, -0.0044,  0.0006],
          [-0.0035, -0.0088, -0.0084]],

         [[ 0.0038, -0.0018,  0.0032],
          [ 0.0174,  0.0080,  0.0111],
          [ 0.0139,  0.0063,  0.0057]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5628]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 73 | Batch_idx: 0 |  Loss: (0.1861) | Acc: (94.00%) (121/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.2482) | Acc: (91.00%) (1293/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.2405) | Acc: (92.00%) (2473/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.2434) | Acc: (92.00%) (3653/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.2507) | Acc: (91.00%) (4806/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.2535) | Acc: (91.00%) (5974/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.2594) | Acc: (91.00%) (7126/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.2598) | Acc: (91.00%) (8295/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.2597) | Acc: (91.00%) (9466/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.2596) | Acc: (91.00%) (10629/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.2605) | Acc: (91.00%) (11785/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.2599) | Acc: (91.00%) (12962/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.2590) | Acc: (91.00%) (14130/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.2573) | Acc: (91.00%) (15307/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.2558) | Acc: (91.00%) (16479/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.2568) | Acc: (91.00%) (17636/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.2542) | Acc: (91.00%) (18822/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.2543) | Acc: (91.00%) (19979/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.2535) | Acc: (91.00%) (21152/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.2547) | Acc: (91.00%) (22317/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.2543) | Acc: (91.00%) (23488/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.2544) | Acc: (91.00%) (24655/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.2561) | Acc: (91.00%) (25813/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.2568) | Acc: (91.00%) (26981/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.2553) | Acc: (91.00%) (28176/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.2539) | Acc: (91.00%) (29369/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.2536) | Acc: (91.00%) (30540/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.2543) | Acc: (91.00%) (31701/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.2561) | Acc: (91.00%) (32842/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.2550) | Acc: (91.00%) (34022/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.2539) | Acc: (91.00%) (35194/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.2535) | Acc: (91.00%) (36361/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.2537) | Acc: (91.00%) (37526/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.2540) | Acc: (91.00%) (38695/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.2530) | Acc: (91.00%) (39879/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.2532) | Acc: (91.00%) (41042/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.2530) | Acc: (91.00%) (42215/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.2533) | Acc: (91.00%) (43373/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.2533) | Acc: (91.00%) (44542/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.2532) | Acc: (91.00%) (45670/50000)
# TEST : Loss: (0.3437) | Acc: (89.00%) (8915/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3540e-01,  2.5806e-01, -1.2625e-01],
          [-7.0488e-02,  3.6827e-02, -4.6841e-02],
          [ 6.8737e-02, -2.0816e-01,  2.7903e-01]],

         [[-1.2932e-01,  4.0304e-01,  9.4965e-02],
          [-5.0385e-03,  2.9073e-02, -1.5859e-01],
          [ 8.3606e-02, -3.5872e-01, -1.1987e-02]],

         [[-1.0400e-01,  2.5474e-01, -1.4219e-01],
          [ 9.6168e-02, -1.6273e-01, -1.0604e-01],
          [ 1.4707e-01, -1.5676e-01,  2.1296e-01]]],


        [[[-1.5836e-01, -3.2235e-01, -2.0332e-01],
          [-1.1975e-01,  2.1834e-01,  1.7521e-01],
          [ 1.8330e-01,  1.1312e-01,  2.2311e-01]],

         [[-2.4868e-01, -2.5241e-01, -1.8722e-01],
          [-1.4700e-01,  1.3972e-01,  2.0803e-01],
          [ 2.5743e-01,  5.5169e-02,  1.1399e-01]],

         [[-1.4636e-01,  4.6449e-02, -2.2576e-01],
          [ 6.2270e-02,  2.2274e-01, -9.0203e-02],
          [ 3.4358e-03,  8.0807e-02,  5.0083e-02]]],


        [[[-1.1444e-01,  2.4481e-01,  1.1044e-01],
          [ 1.5308e-01,  1.6119e-01, -7.1643e-02],
          [-2.0852e-01, -1.4115e-02, -2.5122e-01]],

         [[ 5.2138e-02,  9.7377e-02,  3.8625e-02],
          [ 8.3394e-02,  2.4713e-01,  7.7104e-02],
          [-9.4302e-02, -5.8412e-02, -3.4432e-01]],

         [[-8.3470e-02,  1.0163e-01,  2.0568e-01],
          [ 3.6135e-02,  2.5756e-01,  9.3759e-02],
          [-2.2959e-01, -1.8385e-01, -2.4786e-01]]],


        ...,


        [[[-1.1721e-01, -1.2931e-01,  2.4695e-02],
          [ 1.1078e-01, -2.7873e-01, -1.2553e-01],
          [ 1.2504e-01, -9.8192e-02,  5.7749e-02]],

         [[ 1.6234e-01, -3.4598e-02, -1.5328e-02],
          [-5.3108e-02, -3.9859e-01, -2.6570e-01],
          [ 1.1140e-01, -3.2073e-02, -8.2887e-02]],

         [[ 2.1416e-01,  1.1882e-02,  7.5918e-02],
          [ 9.0471e-03, -2.0524e-01, -1.8393e-01],
          [ 8.0543e-02, -1.1916e-01, -1.0610e-01]]],


        [[[ 1.8812e-40, -7.7883e-41,  1.7449e-41],
          [-1.8040e-40,  9.8630e-41,  2.3653e-40],
          [ 1.3046e-40, -1.2214e-40, -1.8031e-40]],

         [[-1.4063e-40,  1.1944e-40, -1.4778e-40],
          [-1.2540e-40, -9.1997e-41,  1.8019e-40],
          [ 1.8211e-40, -8.2897e-41, -1.6954e-40]],

         [[ 5.8574e-43, -5.7477e-41, -3.9777e-41],
          [-2.6315e-40, -6.6817e-41, -1.4789e-40],
          [-8.8803e-41,  4.7748e-41,  5.3254e-41]]],


        [[[-2.5763e-22, -6.0871e-23,  5.4695e-27],
          [-1.1758e-22, -3.3039e-21, -5.8055e-23],
          [-1.0062e-24, -7.5322e-24, -9.7868e-25]],

         [[-2.7703e-27, -2.4316e-31,  2.2112e-40],
          [-2.2074e-28, -3.6064e-29,  1.4117e-35],
          [-6.9727e-31, -1.0539e-32, -1.8728e-37]],

         [[-1.6696e-29, -1.1000e-33, -1.7666e-40],
          [-2.4027e-28, -3.0777e-28,  3.3338e-34],
          [-4.4389e-28, -6.9097e-29, -3.0435e-34]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0530,  0.0417,  0.0274],
          [ 0.0697,  0.0631,  0.0481],
          [ 0.0599,  0.0505,  0.0551]],

         [[ 0.0261,  0.0173,  0.0083],
          [ 0.0449,  0.0410,  0.0351],
          [ 0.0330,  0.0285,  0.0391]],

         [[ 0.0456,  0.0333,  0.0302],
          [ 0.0623,  0.0577,  0.0541],
          [ 0.0582,  0.0530,  0.0616]]],


        [[[-0.0162,  0.0062,  0.0191],
          [-0.0074,  0.0107,  0.0219],
          [-0.0214, -0.0093, -0.0003]],

         [[-0.0118,  0.0107,  0.0145],
          [ 0.0001,  0.0183,  0.0206],
          [-0.0123,  0.0004,  0.0008]],

         [[-0.0231, -0.0005,  0.0050],
          [-0.0140,  0.0069,  0.0117],
          [-0.0324, -0.0156, -0.0099]]],


        [[[ 0.0663,  0.0622,  0.0570],
          [ 0.0796,  0.0774,  0.0770],
          [ 0.0706,  0.0695,  0.0772]],

         [[ 0.0740,  0.0704,  0.0660],
          [ 0.0848,  0.0811,  0.0823],
          [ 0.0760,  0.0722,  0.0804]],

         [[ 0.0637,  0.0649,  0.0635],
          [ 0.0774,  0.0764,  0.0800],
          [ 0.0738,  0.0719,  0.0812]]],


        ...,


        [[[ 0.0086,  0.0138,  0.0148],
          [-0.0062, -0.0007,  0.0054],
          [-0.0046, -0.0035,  0.0042]],

         [[ 0.0033,  0.0077,  0.0085],
          [-0.0111, -0.0066, -0.0010],
          [-0.0074, -0.0077, -0.0011]],

         [[ 0.0081,  0.0134,  0.0142],
          [-0.0035,  0.0020,  0.0070],
          [-0.0011,  0.0005,  0.0062]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5614]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 74 | Batch_idx: 0 |  Loss: (0.1067) | Acc: (96.00%) (124/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.2166) | Acc: (92.00%) (1305/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2322) | Acc: (92.00%) (2475/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2330) | Acc: (92.00%) (3663/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2271) | Acc: (92.00%) (4855/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2300) | Acc: (92.00%) (6028/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2359) | Acc: (92.00%) (7199/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2398) | Acc: (92.00%) (8365/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2346) | Acc: (92.00%) (9557/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2323) | Acc: (92.00%) (10748/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2311) | Acc: (92.00%) (11937/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2281) | Acc: (92.00%) (13133/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2256) | Acc: (92.00%) (14328/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2236) | Acc: (92.00%) (15520/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2220) | Acc: (92.00%) (16704/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2240) | Acc: (92.00%) (17877/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2266) | Acc: (92.00%) (19045/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2264) | Acc: (92.00%) (20228/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2266) | Acc: (92.00%) (21409/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2282) | Acc: (92.00%) (22571/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2285) | Acc: (92.00%) (23751/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2276) | Acc: (92.00%) (24940/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2266) | Acc: (92.00%) (26132/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2271) | Acc: (92.00%) (27308/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2275) | Acc: (92.00%) (28481/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2267) | Acc: (92.00%) (29662/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2272) | Acc: (92.00%) (30834/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2277) | Acc: (92.00%) (32016/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2282) | Acc: (92.00%) (33194/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2279) | Acc: (92.00%) (34382/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2277) | Acc: (92.00%) (35565/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2276) | Acc: (92.00%) (36749/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2281) | Acc: (92.00%) (37929/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2271) | Acc: (92.00%) (39116/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2279) | Acc: (92.00%) (40278/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2280) | Acc: (92.00%) (41455/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2280) | Acc: (92.00%) (42637/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2279) | Acc: (92.00%) (43824/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2277) | Acc: (92.00%) (45007/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2289) | Acc: (92.00%) (46121/50000)
# TEST : Loss: (0.3542) | Acc: (88.00%) (8895/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2695e-01,  2.6274e-01, -1.2303e-01],
          [-6.6040e-02,  3.7362e-02, -5.3323e-02],
          [ 6.6089e-02, -2.1626e-01,  2.7491e-01]],

         [[-1.2828e-01,  4.0243e-01,  9.8524e-02],
          [-4.7917e-03,  2.5813e-02, -1.6172e-01],
          [ 7.8091e-02, -3.7119e-01, -1.6433e-02]],

         [[-1.0724e-01,  2.5546e-01, -1.3778e-01],
          [ 9.1387e-02, -1.6626e-01, -1.0688e-01],
          [ 1.3850e-01, -1.6738e-01,  2.1200e-01]]],


        [[[-1.7012e-01, -3.2941e-01, -2.0292e-01],
          [-1.2751e-01,  2.1523e-01,  1.7872e-01],
          [ 1.7133e-01,  1.0579e-01,  2.2339e-01]],

         [[-2.5019e-01, -2.4859e-01, -1.7733e-01],
          [-1.4576e-01,  1.4568e-01,  2.2078e-01],
          [ 2.5674e-01,  5.8350e-02,  1.2520e-01]],

         [[-1.4520e-01,  4.9783e-02, -2.1663e-01],
          [ 6.7002e-02,  2.2885e-01, -7.7966e-02],
          [ 7.9070e-03,  8.4755e-02,  6.1000e-02]]],


        [[[-1.1320e-01,  2.4422e-01,  1.0655e-01],
          [ 1.5942e-01,  1.6498e-01, -7.0651e-02],
          [-2.0403e-01, -1.4942e-02, -2.5297e-01]],

         [[ 5.5679e-02,  9.4663e-02,  2.7919e-02],
          [ 9.0657e-02,  2.4866e-01,  7.3386e-02],
          [-9.1455e-02, -6.2013e-02, -3.5050e-01]],

         [[-7.6522e-02,  1.0669e-01,  2.0454e-01],
          [ 4.6848e-02,  2.6471e-01,  9.7273e-02],
          [-2.2566e-01, -1.8445e-01, -2.4895e-01]]],


        ...,


        [[[-1.0387e-01, -1.1754e-01,  3.1042e-02],
          [ 1.0888e-01, -2.9259e-01, -1.3802e-01],
          [ 1.2521e-01, -1.0324e-01,  5.8934e-02]],

         [[ 1.7190e-01, -1.8664e-02, -1.6288e-03],
          [-5.1240e-02, -3.9659e-01, -2.5844e-01],
          [ 1.1354e-01, -2.9163e-02, -6.6749e-02]],

         [[ 2.1574e-01,  1.9298e-02,  8.1607e-02],
          [ 1.0983e-03, -2.1631e-01, -1.9134e-01],
          [ 7.3347e-02, -1.2815e-01, -1.0574e-01]]],


        [[[-2.2194e-41, -1.1827e-40, -5.5567e-41],
          [-4.2402e-41,  1.4555e-40,  7.4218e-41],
          [ 9.0944e-41,  1.2376e-40, -1.5843e-41]],

         [[ 1.1232e-40, -6.8610e-41, -3.5620e-41],
          [-8.7699e-41, -1.6924e-40,  2.1074e-40],
          [-4.9934e-41,  1.5166e-40, -1.2710e-40]],

         [[ 7.8669e-41,  9.5047e-41, -1.2957e-40],
          [-1.3388e-40,  1.1884e-41, -2.9215e-40],
          [-8.0939e-42,  5.2626e-41,  6.2404e-41]]],


        [[[-5.6579e-28, -6.5826e-29,  1.1821e-35],
          [-9.7115e-29, -1.2993e-26, -3.8975e-29],
          [-4.6533e-32, -1.7213e-30, -4.9998e-32]],

         [[ 1.1965e-35,  1.5436e-40,  4.6572e-41],
          [-1.7696e-37, -3.5889e-38,  6.3339e-42],
          [ 2.0039e-40,  3.8736e-41,  2.7976e-41]],

         [[-1.6013e-38, -6.7489e-41, -3.5572e-41],
          [-1.2520e-37, -1.0492e-37,  1.1840e-41],
          [ 3.1631e-37, -2.3982e-38, -6.1803e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0673, -0.0553, -0.0820],
          [-0.0213, -0.0319, -0.0580],
          [-0.0062, -0.0433, -0.0640]],

         [[-0.0612, -0.0557, -0.0762],
          [-0.0093, -0.0239, -0.0546],
          [ 0.0049, -0.0273, -0.0584]],

         [[-0.0494, -0.0395, -0.0626],
          [-0.0006, -0.0039, -0.0397],
          [ 0.0146, -0.0100, -0.0408]]],


        [[[ 0.0436,  0.0415,  0.0399],
          [ 0.0440,  0.0472,  0.0500],
          [ 0.0369,  0.0371,  0.0521]],

         [[ 0.0442,  0.0385,  0.0349],
          [ 0.0354,  0.0380,  0.0427],
          [ 0.0251,  0.0276,  0.0453]],

         [[ 0.0217,  0.0156,  0.0152],
          [ 0.0087,  0.0116,  0.0189],
          [-0.0040, -0.0013,  0.0162]]],


        [[[-0.0468, -0.0443, -0.0349],
          [-0.0589, -0.0526, -0.0420],
          [-0.0568, -0.0527, -0.0403]],

         [[-0.0259, -0.0235, -0.0156],
          [-0.0272, -0.0272, -0.0182],
          [-0.0251, -0.0315, -0.0225]],

         [[ 0.0142,  0.0120,  0.0165],
          [ 0.0109,  0.0095,  0.0156],
          [ 0.0113,  0.0009,  0.0048]]],


        ...,


        [[[ 0.0054,  0.0095,  0.0074],
          [ 0.0062,  0.0079,  0.0021],
          [ 0.0041,  0.0051, -0.0063]],

         [[-0.0065, -0.0023, -0.0029],
          [-0.0042, -0.0017, -0.0054],
          [-0.0079, -0.0057, -0.0145]],

         [[-0.0207, -0.0144, -0.0126],
          [-0.0143, -0.0110, -0.0132],
          [-0.0194, -0.0166, -0.0231]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5598]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 75 | Batch_idx: 0 |  Loss: (0.1644) | Acc: (93.00%) (120/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2371) | Acc: (91.00%) (1295/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.2626) | Acc: (90.00%) (2439/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.2782) | Acc: (90.00%) (3583/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.2699) | Acc: (90.00%) (4764/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.2671) | Acc: (90.00%) (5932/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.2637) | Acc: (90.00%) (7100/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.2594) | Acc: (91.00%) (8277/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.2553) | Acc: (91.00%) (9458/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.2577) | Acc: (91.00%) (10616/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.2564) | Acc: (91.00%) (11790/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.2532) | Acc: (91.00%) (12973/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.2485) | Acc: (91.00%) (14172/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.2481) | Acc: (91.00%) (15343/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.2467) | Acc: (91.00%) (16524/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.2453) | Acc: (91.00%) (17705/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.2427) | Acc: (91.00%) (18897/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.2415) | Acc: (91.00%) (20078/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.2409) | Acc: (91.00%) (21255/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.2409) | Acc: (91.00%) (22433/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.2392) | Acc: (91.00%) (23614/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.2381) | Acc: (91.00%) (24793/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.2381) | Acc: (91.00%) (25976/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.2378) | Acc: (91.00%) (27158/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.2377) | Acc: (91.00%) (28339/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.2363) | Acc: (91.00%) (29529/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.2350) | Acc: (91.00%) (30715/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.2331) | Acc: (91.00%) (31909/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.2321) | Acc: (92.00%) (33103/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.2315) | Acc: (92.00%) (34278/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.2310) | Acc: (92.00%) (35475/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.2296) | Acc: (92.00%) (36678/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.2296) | Acc: (92.00%) (37851/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.2287) | Acc: (92.00%) (39041/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.2270) | Acc: (92.00%) (40249/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.2259) | Acc: (92.00%) (41447/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.2252) | Acc: (92.00%) (42643/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.2246) | Acc: (92.00%) (43837/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.2242) | Acc: (92.00%) (45025/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.2233) | Acc: (92.00%) (46184/50000)
# TEST : Loss: (0.3129) | Acc: (89.00%) (8983/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2825e-01,  2.5963e-01, -1.2542e-01],
          [-6.8447e-02,  3.4331e-02, -5.5243e-02],
          [ 6.1519e-02, -2.1776e-01,  2.7475e-01]],

         [[-1.2880e-01,  4.0047e-01,  9.6478e-02],
          [-6.7092e-03,  2.3976e-02, -1.6218e-01],
          [ 7.3762e-02, -3.7207e-01, -1.5225e-02]],

         [[-1.0838e-01,  2.5351e-01, -1.3940e-01],
          [ 8.8828e-02, -1.6813e-01, -1.0755e-01],
          [ 1.3364e-01, -1.6964e-01,  2.1217e-01]]],


        [[[-1.7158e-01, -3.3049e-01, -2.0423e-01],
          [-1.2919e-01,  2.1294e-01,  1.7699e-01],
          [ 1.6970e-01,  1.0362e-01,  2.2081e-01]],

         [[-2.5147e-01, -2.4958e-01, -1.7850e-01],
          [-1.4730e-01,  1.4370e-01,  2.1902e-01],
          [ 2.5498e-01,  5.6437e-02,  1.2288e-01]],

         [[-1.4458e-01,  5.0461e-02, -2.1560e-01],
          [ 6.7380e-02,  2.2920e-01, -7.6693e-02],
          [ 9.2501e-03,  8.5713e-02,  6.1902e-02]]],


        [[[-1.1252e-01,  2.4529e-01,  1.0786e-01],
          [ 1.6124e-01,  1.6623e-01, -7.0058e-02],
          [-2.0155e-01, -1.3437e-02, -2.5185e-01]],

         [[ 5.5285e-02,  9.5273e-02,  2.8678e-02],
          [ 9.1519e-02,  2.4917e-01,  7.3359e-02],
          [-8.9744e-02, -6.0518e-02, -3.4900e-01]],

         [[-7.7870e-02,  1.0590e-01,  2.0364e-01],
          [ 4.6248e-02,  2.6361e-01,  9.5682e-02],
          [-2.2558e-01, -1.8440e-01, -2.4907e-01]]],


        ...,


        [[[-1.0766e-01, -1.2159e-01,  2.5848e-02],
          [ 1.0350e-01, -2.9597e-01, -1.4224e-01],
          [ 1.1974e-01, -1.0717e-01,  5.5182e-02]],

         [[ 1.6862e-01, -2.0216e-02, -3.7767e-03],
          [-5.2924e-02, -3.9288e-01, -2.5647e-01],
          [ 1.1103e-01, -2.9481e-02, -6.5828e-02]],

         [[ 2.1519e-01,  2.0694e-02,  8.1268e-02],
          [ 2.0347e-03, -2.1177e-01, -1.8799e-01],
          [ 7.3821e-02, -1.2451e-01, -1.0202e-01]]],


        [[[-2.4723e-41, -4.9679e-41,  2.0864e-40],
          [ 1.4702e-40,  1.6556e-40,  8.7452e-41],
          [-2.1794e-40, -1.2328e-40,  2.0428e-40]],

         [[ 1.3115e-40,  1.3313e-40,  8.7840e-41],
          [ 1.0533e-40,  1.7203e-40,  2.4397e-40],
          [ 1.7005e-40, -1.5501e-40,  1.7012e-40]],

         [[ 1.5276e-40,  1.7107e-40, -5.4893e-41],
          [-1.5673e-40,  1.3919e-41, -2.9981e-40],
          [-1.1866e-40, -9.6066e-41, -3.9874e-41]]],


        [[[ 1.5602e-36, -1.9297e-38,  6.5635e-41],
          [-7.9472e-38,  7.2219e-35, -3.9597e-38],
          [ 5.9065e-41, -7.0614e-40,  3.8253e-41]],

         [[ 2.3290e-42, -3.4061e-41,  6.7066e-42],
          [ 1.2163e-42,  3.9135e-41, -2.5062e-41],
          [-6.7430e-41,  5.9072e-41,  5.4162e-41]],

         [[ 4.6506e-41, -4.5532e-41,  1.4012e-41],
          [-4.2377e-41, -5.5765e-41,  1.6542e-41],
          [-5.3335e-41,  7.9594e-43, -6.6929e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5711]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0072]], device='cuda:0')

Epoch: 76 | Batch_idx: 0 |  Loss: (0.2375) | Acc: (89.00%) (114/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.1840) | Acc: (93.00%) (1323/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.1857) | Acc: (93.00%) (2519/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.1839) | Acc: (93.00%) (3717/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.1920) | Acc: (93.00%) (4897/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.1893) | Acc: (93.00%) (6100/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.1915) | Acc: (93.00%) (7294/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.1893) | Acc: (93.00%) (8497/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.1875) | Acc: (93.00%) (9701/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.1886) | Acc: (93.00%) (10902/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.1891) | Acc: (93.00%) (12097/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.1913) | Acc: (93.00%) (13281/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.1921) | Acc: (93.00%) (14477/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.1935) | Acc: (93.00%) (15668/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.1954) | Acc: (93.00%) (16853/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.1950) | Acc: (93.00%) (18042/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.1964) | Acc: (93.00%) (19234/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.1970) | Acc: (93.00%) (20430/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.1975) | Acc: (93.00%) (21615/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.1968) | Acc: (93.00%) (22817/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.1975) | Acc: (93.00%) (24013/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.1967) | Acc: (93.00%) (25211/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.1962) | Acc: (93.00%) (26407/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.1958) | Acc: (93.00%) (27614/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.1955) | Acc: (93.00%) (28808/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.1942) | Acc: (93.00%) (30029/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.1941) | Acc: (93.00%) (31227/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.1935) | Acc: (93.00%) (32431/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.1944) | Acc: (93.00%) (33619/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.1953) | Acc: (93.00%) (34797/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.1956) | Acc: (93.00%) (35991/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.1957) | Acc: (93.00%) (37192/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.1951) | Acc: (93.00%) (38401/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.1952) | Acc: (93.00%) (39591/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.1961) | Acc: (93.00%) (40774/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.1958) | Acc: (93.00%) (41980/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.1956) | Acc: (93.00%) (43182/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.1955) | Acc: (93.00%) (44379/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.1954) | Acc: (93.00%) (45578/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.1966) | Acc: (93.00%) (46699/50000)
# TEST : Loss: (0.3005) | Acc: (90.00%) (9028/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2795e-01,  2.5902e-01, -1.2513e-01],
          [-6.8291e-02,  3.4252e-02, -5.5118e-02],
          [ 6.1378e-02, -2.1724e-01,  2.7412e-01]],

         [[-1.2848e-01,  3.9948e-01,  9.6249e-02],
          [-6.6935e-03,  2.3919e-02, -1.6180e-01],
          [ 7.3588e-02, -3.7114e-01, -1.5189e-02]],

         [[-1.0810e-01,  2.5285e-01, -1.3906e-01],
          [ 8.8612e-02, -1.6772e-01, -1.0729e-01],
          [ 1.3331e-01, -1.6921e-01,  2.1165e-01]]],


        [[[-1.7122e-01, -3.2982e-01, -2.0382e-01],
          [-1.2893e-01,  2.1250e-01,  1.7663e-01],
          [ 1.6934e-01,  1.0340e-01,  2.2034e-01]],

         [[-2.5094e-01, -2.4905e-01, -1.7813e-01],
          [-1.4699e-01,  1.4340e-01,  2.1855e-01],
          [ 2.5442e-01,  5.6313e-02,  1.2261e-01]],

         [[-1.4425e-01,  5.0347e-02, -2.1511e-01],
          [ 6.7228e-02,  2.2869e-01, -7.6522e-02],
          [ 9.2287e-03,  8.5516e-02,  6.1759e-02]]],


        [[[-1.1230e-01,  2.4480e-01,  1.0765e-01],
          [ 1.6094e-01,  1.6592e-01, -6.9925e-02],
          [-2.0117e-01, -1.3412e-02, -2.5137e-01]],

         [[ 5.5173e-02,  9.5078e-02,  2.8620e-02],
          [ 9.1342e-02,  2.4869e-01,  7.3215e-02],
          [-8.9569e-02, -6.0399e-02, -3.4830e-01]],

         [[-7.7707e-02,  1.0568e-01,  2.0321e-01],
          [ 4.6154e-02,  2.6307e-01,  9.5485e-02],
          [-2.2512e-01, -1.8401e-01, -2.4855e-01]]],


        ...,


        [[[-1.0708e-01, -1.2074e-01,  2.5674e-02],
          [ 1.0285e-01, -2.9290e-01, -1.4076e-01],
          [ 1.1909e-01, -1.0636e-01,  5.4760e-02]],

         [[ 1.6764e-01, -2.0054e-02, -3.7481e-03],
          [-5.2557e-02, -3.8733e-01, -2.5291e-01],
          [ 1.1037e-01, -2.9221e-02, -6.5233e-02]],

         [[ 2.1397e-01,  2.0546e-02,  8.0707e-02],
          [ 2.0214e-03, -2.0972e-01, -1.8618e-01],
          [ 7.3388e-02, -1.2351e-01, -1.0118e-01]]],


        [[[-2.6081e-40,  8.2842e-41,  2.7956e-41],
          [-5.7279e-41,  1.1176e-40,  1.7950e-40],
          [ 1.2130e-40,  3.5309e-41, -2.3468e-40]],

         [[ 2.2134e-40, -1.3229e-40, -1.5637e-40],
          [-1.9763e-40, -1.4365e-41, -2.6192e-40],
          [-1.1045e-40,  1.4994e-40, -2.5841e-40]],

         [[-1.0533e-40,  1.2581e-40,  1.6198e-40],
          [ 2.1351e-40,  1.5878e-41, -1.0314e-40],
          [-2.2066e-40, -1.5675e-40,  2.1535e-40]]],


        [[[-1.5197e-41, -8.0995e-42,  5.5590e-41],
          [-1.7726e-42,  4.8418e-41,  5.7400e-41],
          [ 5.8230e-41, -6.3358e-41,  6.6820e-41]],

         [[-2.4380e-41,  6.7582e-41,  3.8206e-41],
          [ 6.1134e-41, -3.5390e-41,  6.9469e-41],
          [ 3.6159e-41, -6.9343e-41,  4.0835e-41]],

         [[ 3.4710e-41,  4.3430e-41,  1.3413e-41],
          [ 1.3653e-41, -2.6190e-42, -3.4218e-41],
          [-5.8291e-41,  5.5004e-41,  6.9340e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5862]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0326]], device='cuda:0')

Epoch: 77 | Batch_idx: 0 |  Loss: (0.0813) | Acc: (97.00%) (125/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.1810) | Acc: (93.00%) (1317/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.1851) | Acc: (93.00%) (2514/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.1852) | Acc: (93.00%) (3718/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.1847) | Acc: (93.00%) (4916/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.1841) | Acc: (93.00%) (6121/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.1832) | Acc: (93.00%) (7334/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.1822) | Acc: (94.00%) (8547/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.1838) | Acc: (94.00%) (9748/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.1850) | Acc: (93.00%) (10930/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.1851) | Acc: (93.00%) (12128/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.1887) | Acc: (93.00%) (13302/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.1884) | Acc: (93.00%) (14508/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.1890) | Acc: (93.00%) (15702/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.1910) | Acc: (93.00%) (16891/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.1913) | Acc: (93.00%) (18090/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.1915) | Acc: (93.00%) (19292/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.1913) | Acc: (93.00%) (20484/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.1915) | Acc: (93.00%) (21685/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.1914) | Acc: (93.00%) (22879/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.1918) | Acc: (93.00%) (24080/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.1919) | Acc: (93.00%) (25276/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.1921) | Acc: (93.00%) (26475/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.1927) | Acc: (93.00%) (27669/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.1927) | Acc: (93.00%) (28868/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.1943) | Acc: (93.00%) (30055/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.1944) | Acc: (93.00%) (31258/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.1943) | Acc: (93.00%) (32460/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.1941) | Acc: (93.00%) (33661/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.1947) | Acc: (93.00%) (34844/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.1950) | Acc: (93.00%) (36041/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.1950) | Acc: (93.00%) (37232/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.1940) | Acc: (93.00%) (38451/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.1937) | Acc: (93.00%) (39658/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.1942) | Acc: (93.00%) (40854/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.1942) | Acc: (93.00%) (42057/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.1942) | Acc: (93.00%) (43260/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.1937) | Acc: (93.00%) (44465/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.1939) | Acc: (93.00%) (45668/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.1937) | Acc: (93.00%) (46826/50000)
# TEST : Loss: (0.2964) | Acc: (90.00%) (9020/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2759e-01,  2.5828e-01, -1.2479e-01],
          [-6.8101e-02,  3.4157e-02, -5.4965e-02],
          [ 6.1206e-02, -2.1661e-01,  2.7336e-01]],

         [[-1.2810e-01,  3.9829e-01,  9.5972e-02],
          [-6.6744e-03,  2.3850e-02, -1.6134e-01],
          [ 7.3376e-02, -3.7002e-01, -1.5146e-02]],

         [[-1.0777e-01,  2.5206e-01, -1.3863e-01],
          [ 8.8351e-02, -1.6722e-01, -1.0697e-01],
          [ 1.3291e-01, -1.6868e-01,  2.1101e-01]]],


        [[[-1.7080e-01, -3.2901e-01, -2.0332e-01],
          [-1.2861e-01,  2.1198e-01,  1.7619e-01],
          [ 1.6891e-01,  1.0314e-01,  2.1976e-01]],

         [[-2.5028e-01, -2.4841e-01, -1.7767e-01],
          [-1.4661e-01,  1.4303e-01,  2.1798e-01],
          [ 2.5374e-01,  5.6162e-02,  1.2228e-01]],

         [[-1.4384e-01,  5.0208e-02, -2.1453e-01],
          [ 6.7043e-02,  2.2806e-01, -7.6314e-02],
          [ 9.2029e-03,  8.5277e-02,  6.1585e-02]]],


        [[[-1.1203e-01,  2.4421e-01,  1.0739e-01],
          [ 1.6058e-01,  1.6553e-01, -6.9763e-02],
          [-2.0072e-01, -1.3381e-02, -2.5078e-01]],

         [[ 5.5038e-02,  9.4842e-02,  2.8550e-02],
          [ 9.1127e-02,  2.4810e-01,  7.3040e-02],
          [-8.9357e-02, -6.0254e-02, -3.4745e-01]],

         [[-7.7510e-02,  1.0541e-01,  2.0269e-01],
          [ 4.6041e-02,  2.6242e-01,  9.5246e-02],
          [-2.2456e-01, -1.8354e-01, -2.4791e-01]]],


        ...,


        [[[-1.0638e-01, -1.1972e-01,  2.5463e-02],
          [ 1.0207e-01, -2.8922e-01, -1.3898e-01],
          [ 1.1830e-01, -1.0539e-01,  5.4252e-02]],

         [[ 1.6647e-01, -1.9859e-02, -3.7135e-03],
          [-5.2114e-02, -3.8068e-01, -2.4865e-01],
          [ 1.0959e-01, -2.8907e-02, -6.4517e-02]],

         [[ 2.1251e-01,  2.0368e-02,  8.0031e-02],
          [ 2.0054e-03, -2.0726e-01, -1.8400e-01],
          [ 7.2864e-02, -1.2231e-01, -1.0017e-01]]],


        [[[ 2.7957e-40, -1.7856e-40, -8.9645e-41],
          [-6.6898e-41,  1.2912e-40,  2.0553e-40],
          [ 2.3364e-40, -1.5921e-40,  1.2325e-40]],

         [[-2.5949e-40,  1.3350e-40,  1.6230e-40],
          [-2.2622e-40,  2.2665e-40, -1.9964e-40],
          [-7.9007e-41, -1.4839e-40, -2.9024e-40]],

         [[ 2.0472e-40,  2.2876e-40, -7.3407e-41],
          [ 2.4512e-40,  2.5224e-40,  6.6441e-41],
          [ 2.2816e-40, -1.7505e-40, -2.9434e-40]]],


        [[[-4.5956e-41,  4.4197e-41, -1.4658e-42],
          [ 5.7586e-41,  2.9926e-41,  2.1580e-41],
          [-3.1465e-41,  1.0846e-41, -5.0022e-41]],

         [[ 6.7342e-41,  6.9423e-41, -8.9823e-42],
          [-4.9984e-42,  1.2497e-41, -2.9209e-41],
          [ 4.0329e-41, -6.7642e-41, -3.6598e-41]],

         [[ 5.5573e-41,  7.1784e-41,  4.7777e-41],
          [-6.2851e-41, -6.7611e-41, -6.2732e-41],
          [-5.8967e-41, -1.8176e-41,  3.6291e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6002]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0265]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 78 | Batch_idx: 0 |  Loss: (0.1481) | Acc: (93.00%) (120/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.1939) | Acc: (93.00%) (1321/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2129) | Acc: (92.00%) (2498/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2481) | Acc: (91.00%) (3633/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2576) | Acc: (91.00%) (4792/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2737) | Acc: (90.00%) (5923/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2890) | Acc: (90.00%) (7051/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2913) | Acc: (90.00%) (8207/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2969) | Acc: (90.00%) (9337/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.3054) | Acc: (89.00%) (10452/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.3109) | Acc: (89.00%) (11577/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.3095) | Acc: (89.00%) (12723/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.3139) | Acc: (89.00%) (13846/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.3138) | Acc: (89.00%) (14998/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.3128) | Acc: (89.00%) (16162/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.3133) | Acc: (89.00%) (17302/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.3141) | Acc: (89.00%) (18442/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.3132) | Acc: (89.00%) (19593/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.3126) | Acc: (89.00%) (20746/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.3129) | Acc: (89.00%) (21894/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.3122) | Acc: (89.00%) (23031/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.3116) | Acc: (89.00%) (24178/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.3103) | Acc: (89.00%) (25343/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.3092) | Acc: (89.00%) (26490/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.3096) | Acc: (89.00%) (27639/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.3096) | Acc: (89.00%) (28788/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.3089) | Acc: (89.00%) (29936/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.3097) | Acc: (89.00%) (31077/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.3103) | Acc: (89.00%) (32217/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.3080) | Acc: (89.00%) (33396/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.3077) | Acc: (89.00%) (34536/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.3077) | Acc: (89.00%) (35670/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.3073) | Acc: (89.00%) (36826/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.3066) | Acc: (89.00%) (37975/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.3053) | Acc: (89.00%) (39131/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.3046) | Acc: (89.00%) (40289/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.3037) | Acc: (89.00%) (41457/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.3018) | Acc: (89.00%) (42639/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.3012) | Acc: (89.00%) (43791/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.3007) | Acc: (89.00%) (44909/50000)
# TEST : Loss: (0.3992) | Acc: (86.00%) (8695/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3138e-01,  2.6202e-01, -1.3635e-01],
          [-7.2488e-02,  1.4057e-02, -7.4044e-02],
          [ 5.7671e-02, -2.3254e-01,  2.5225e-01]],

         [[-1.2719e-01,  4.0697e-01,  9.4594e-02],
          [-2.1441e-03,  1.2124e-02, -1.6554e-01],
          [ 8.6526e-02, -3.6892e-01, -2.0894e-02]],

         [[-9.9471e-02,  2.6306e-01, -1.3628e-01],
          [ 1.0218e-01, -1.6406e-01, -1.0864e-01],
          [ 1.5029e-01, -1.5109e-01,  2.1512e-01]]],


        [[[-1.7309e-01, -3.3441e-01, -2.0551e-01],
          [-1.2839e-01,  2.1040e-01,  1.7292e-01],
          [ 1.8049e-01,  1.1004e-01,  2.2015e-01]],

         [[-2.5218e-01, -2.5514e-01, -1.8617e-01],
          [-1.4736e-01,  1.3981e-01,  2.0998e-01],
          [ 2.6336e-01,  5.9257e-02,  1.1713e-01]],

         [[-1.4425e-01,  4.5217e-02, -2.1967e-01],
          [ 6.3022e-02,  2.2265e-01, -8.1528e-02],
          [ 1.4372e-02,  8.3561e-02,  5.4351e-02]]],


        [[[-1.1652e-01,  2.4080e-01,  9.9216e-02],
          [ 1.6044e-01,  1.6456e-01, -7.6045e-02],
          [-2.0875e-01, -2.2203e-02, -2.5907e-01]],

         [[ 4.7394e-02,  9.3238e-02,  2.5284e-02],
          [ 8.6780e-02,  2.4496e-01,  6.5737e-02],
          [-9.7259e-02, -6.8560e-02, -3.5574e-01]],

         [[-9.0883e-02,  9.6430e-02,  1.9411e-01],
          [ 3.5773e-02,  2.5387e-01,  8.5496e-02],
          [-2.3798e-01, -1.9512e-01, -2.5897e-01]]],


        ...,


        [[[-1.0708e-01, -1.3155e-01,  2.3648e-02],
          [ 9.5208e-02, -3.1454e-01, -1.5004e-01],
          [ 1.1120e-01, -1.2298e-01,  4.0954e-02]],

         [[ 1.7662e-01, -1.5575e-02,  1.1329e-02],
          [-4.1250e-02, -3.7182e-01, -2.2745e-01],
          [ 1.1640e-01, -2.6106e-02, -5.9988e-02]],

         [[ 2.1565e-01,  2.7248e-02,  9.7800e-02],
          [ 5.8601e-03, -2.0557e-01, -1.7999e-01],
          [ 7.3813e-02, -1.2419e-01, -1.0713e-01]]],


        [[[-2.0640e-40,  1.1358e-40,  3.5812e-41],
          [-1.2875e-40,  9.5906e-41,  2.3632e-40],
          [ 2.6511e-40,  1.5705e-40, -2.2851e-41]],

         [[ 6.4757e-41, -3.6584e-41, -1.5395e-40],
          [-2.5720e-40,  1.4892e-40,  2.0808e-40],
          [ 2.0275e-41, -1.6355e-40, -2.0745e-40]],

         [[ 2.3417e-40,  1.6464e-40, -1.3447e-40],
          [ 2.7597e-40,  2.8361e-40, -2.6651e-41],
          [ 1.5126e-40, -1.3769e-40,  2.2790e-40]]],


        [[[ 5.1764e-41, -3.1309e-41, -4.8495e-41],
          [-3.0520e-42, -1.8231e-42,  6.9235e-41],
          [-3.4492e-41, -1.0098e-41, -5.7243e-41]],

         [[-6.2049e-42, -2.4270e-41,  4.6824e-41],
          [ 2.3940e-41, -7.5376e-42, -4.8877e-41],
          [-6.8571e-41, -2.4688e-41, -6.2767e-41]],

         [[-4.9488e-41,  2.1514e-41, -3.2178e-41],
          [ 7.0576e-41,  5.6904e-41, -6.6569e-41],
          [ 6.1901e-41,  3.8408e-41,  6.9171e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0139,  0.0041,  0.0063],
          [ 0.0029, -0.0051, -0.0167],
          [ 0.0100, -0.0006, -0.0215]],

         [[ 0.0040, -0.0110, -0.0088],
          [-0.0100, -0.0202, -0.0322],
          [-0.0027, -0.0197, -0.0342]],

         [[ 0.0003, -0.0115, -0.0052],
          [-0.0072, -0.0160, -0.0273],
          [-0.0009, -0.0196, -0.0321]]],


        [[[ 0.0005, -0.0081, -0.0150],
          [-0.0015, -0.0061, -0.0098],
          [-0.0050, -0.0077, -0.0093]],

         [[-0.0016, -0.0072, -0.0095],
          [-0.0013, -0.0040, -0.0043],
          [-0.0071, -0.0100, -0.0094]],

         [[ 0.0091,  0.0019, -0.0043],
          [ 0.0121,  0.0056,  0.0009],
          [ 0.0057,  0.0010, -0.0022]]],


        [[[-0.0060,  0.0010,  0.0009],
          [-0.0013,  0.0020, -0.0007],
          [ 0.0011,  0.0014, -0.0029]],

         [[-0.0165, -0.0076, -0.0079],
          [-0.0126, -0.0053, -0.0083],
          [-0.0082, -0.0021, -0.0069]],

         [[-0.0182, -0.0160, -0.0169],
          [-0.0169, -0.0140, -0.0166],
          [-0.0120, -0.0091, -0.0138]]],


        ...,


        [[[ 0.0065, -0.0014, -0.0040],
          [ 0.0071,  0.0003, -0.0004],
          [ 0.0037, -0.0001, -0.0007]],

         [[ 0.0160,  0.0076,  0.0037],
          [ 0.0148,  0.0068,  0.0054],
          [ 0.0091,  0.0051,  0.0044]],

         [[ 0.0169,  0.0097,  0.0086],
          [ 0.0152,  0.0086,  0.0084],
          [ 0.0120,  0.0087,  0.0087]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6024]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 79 | Batch_idx: 0 |  Loss: (0.2447) | Acc: (89.00%) (115/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2423) | Acc: (92.00%) (1296/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2375) | Acc: (91.00%) (2472/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2445) | Acc: (91.00%) (3633/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2487) | Acc: (91.00%) (4804/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2435) | Acc: (91.00%) (5982/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2445) | Acc: (91.00%) (7148/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2440) | Acc: (91.00%) (8323/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2484) | Acc: (91.00%) (9482/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2531) | Acc: (91.00%) (10634/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2518) | Acc: (91.00%) (11807/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2507) | Acc: (91.00%) (12982/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2492) | Acc: (91.00%) (14163/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2491) | Acc: (91.00%) (15334/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2488) | Acc: (91.00%) (16504/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2481) | Acc: (91.00%) (17673/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2473) | Acc: (91.00%) (18843/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2455) | Acc: (91.00%) (20027/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2461) | Acc: (91.00%) (21185/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2456) | Acc: (91.00%) (22364/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2457) | Acc: (91.00%) (23534/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2464) | Acc: (91.00%) (24700/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2457) | Acc: (91.00%) (25884/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2439) | Acc: (91.00%) (27077/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2436) | Acc: (91.00%) (28250/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2438) | Acc: (91.00%) (29414/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2431) | Acc: (91.00%) (30599/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2416) | Acc: (91.00%) (31799/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2416) | Acc: (91.00%) (32967/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2407) | Acc: (91.00%) (34162/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2411) | Acc: (91.00%) (35332/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2413) | Acc: (91.00%) (36513/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2417) | Acc: (91.00%) (37685/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2429) | Acc: (91.00%) (38848/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2433) | Acc: (91.00%) (40025/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2439) | Acc: (91.00%) (41185/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2446) | Acc: (91.00%) (42360/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2457) | Acc: (91.00%) (43514/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2465) | Acc: (91.00%) (44667/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2468) | Acc: (91.00%) (45793/50000)
# TEST : Loss: (0.3606) | Acc: (88.00%) (8833/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3823e-01,  2.6914e-01, -1.3165e-01],
          [-7.0129e-02,  3.4174e-02, -5.7106e-02],
          [ 6.3225e-02, -2.1635e-01,  2.7512e-01]],

         [[-1.3149e-01,  4.2397e-01,  1.0442e-01],
          [ 1.3119e-03,  3.4291e-02, -1.5097e-01],
          [ 8.9921e-02, -3.5709e-01, -4.4983e-03]],

         [[-1.0383e-01,  2.7507e-01, -1.3463e-01],
          [ 1.0682e-01, -1.4219e-01, -1.0392e-01],
          [ 1.5472e-01, -1.3487e-01,  2.2074e-01]]],


        [[[-1.7540e-01, -3.3482e-01, -1.9657e-01],
          [-1.3101e-01,  2.1458e-01,  1.8433e-01],
          [ 1.7662e-01,  1.1666e-01,  2.3335e-01]],

         [[-2.5944e-01, -2.6159e-01, -1.8347e-01],
          [-1.5759e-01,  1.3769e-01,  2.1567e-01],
          [ 2.5318e-01,  6.0107e-02,  1.2481e-01]],

         [[-1.5119e-01,  3.6817e-02, -2.2033e-01],
          [ 5.1920e-02,  2.1700e-01, -8.0954e-02],
          [-4.6739e-04,  7.7230e-02,  5.3557e-02]]],


        [[[-1.1582e-01,  2.3991e-01,  1.0503e-01],
          [ 1.5820e-01,  1.6249e-01, -7.1376e-02],
          [-2.1332e-01, -2.8054e-02, -2.6000e-01]],

         [[ 5.3126e-02,  9.7411e-02,  3.3750e-02],
          [ 9.2296e-02,  2.5062e-01,  7.5378e-02],
          [-9.8705e-02, -7.0881e-02, -3.5372e-01]],

         [[-8.3423e-02,  1.0331e-01,  2.0178e-01],
          [ 4.5327e-02,  2.6326e-01,  9.5705e-02],
          [-2.3683e-01, -1.9424e-01, -2.5763e-01]]],


        ...,


        [[[-1.0218e-01, -1.2113e-01,  4.3272e-02],
          [ 1.0390e-01, -2.9733e-01, -1.3147e-01],
          [ 1.2047e-01, -1.0751e-01,  5.7202e-02]],

         [[ 1.7258e-01, -1.9961e-02,  1.6444e-02],
          [-4.5858e-02, -3.8225e-01, -2.3949e-01],
          [ 1.0645e-01, -3.9177e-02, -7.4590e-02]],

         [[ 2.2569e-01,  3.3872e-02,  1.0564e-01],
          [ 1.2882e-02, -2.0421e-01, -1.8621e-01],
          [ 7.0204e-02, -1.3123e-01, -1.1848e-01]]],


        [[[-2.8715e-40,  1.7752e-40, -1.2227e-40],
          [-1.4800e-40, -7.7184e-42,  1.5340e-40],
          [ 1.7762e-40, -8.0262e-41, -2.0905e-40]],

         [[-2.6124e-41,  1.2336e-41, -6.6110e-41],
          [-1.7300e-40, -1.5339e-41, -7.3268e-41],
          [ 2.0904e-40,  8.7175e-41,  1.5731e-40]],

         [[ 1.5965e-40,  2.1455e-41, -1.5362e-40],
          [ 1.9262e-40,  1.9685e-40, -2.6693e-41],
          [-1.1579e-41,  1.0113e-40, -2.4278e-40]]],


        [[[-4.5025e-41,  5.3296e-41, -6.2183e-41],
          [ 1.8682e-41,  1.8468e-41, -6.7911e-41],
          [ 5.4013e-41, -1.3111e-41,  1.7575e-41]],

         [[-1.1848e-41,  3.9636e-41, -2.0058e-41],
          [-4.1080e-41,  7.2959e-41, -9.5863e-42],
          [ 6.7852e-41,  4.2357e-41, -4.7484e-41]],

         [[-3.1214e-41, -6.7359e-41,  6.1335e-41],
          [ 2.3454e-41,  4.0753e-41,  1.8399e-41],
          [-4.4323e-42, -4.4856e-42, -5.3890e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0040,  0.0032,  0.0238],
          [ 0.0119, -0.0118, -0.0053],
          [ 0.0029, -0.0230, -0.0443]],

         [[ 0.0055,  0.0085,  0.0295],
          [ 0.0073, -0.0114, -0.0040],
          [-0.0053, -0.0322, -0.0542]],

         [[ 0.0060,  0.0129,  0.0320],
          [ 0.0018, -0.0095,  0.0025],
          [-0.0053, -0.0270, -0.0429]]],


        [[[-0.0190, -0.0096, -0.0151],
          [-0.0238, -0.0214, -0.0158],
          [-0.0158, -0.0075,  0.0070]],

         [[-0.0032,  0.0045,  0.0007],
          [-0.0124, -0.0115, -0.0031],
          [-0.0079, -0.0009,  0.0179]],

         [[ 0.0021,  0.0083,  0.0062],
          [-0.0062, -0.0067,  0.0005],
          [-0.0060, -0.0027,  0.0169]]],


        [[[-0.0890, -0.0961, -0.0841],
          [-0.0821, -0.0841, -0.0779],
          [-0.0873, -0.0886, -0.0831]],

         [[-0.1090, -0.1141, -0.0978],
          [-0.0985, -0.0965, -0.0869],
          [-0.1035, -0.1001, -0.0917]],

         [[-0.1301, -0.1295, -0.1115],
          [-0.1187, -0.1133, -0.1008],
          [-0.1247, -0.1157, -0.1048]]],


        ...,


        [[[ 0.0075,  0.0039, -0.0081],
          [ 0.0008,  0.0020, -0.0085],
          [ 0.0027,  0.0054, -0.0038]],

         [[ 0.0044,  0.0039, -0.0072],
          [-0.0010,  0.0028, -0.0070],
          [ 0.0017,  0.0062, -0.0029]],

         [[-0.0029, -0.0015, -0.0098],
          [-0.0060, -0.0011, -0.0090],
          [-0.0013,  0.0036, -0.0044]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6010]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 80 | Batch_idx: 0 |  Loss: (0.1321) | Acc: (93.00%) (120/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.1963) | Acc: (92.00%) (1309/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2078) | Acc: (92.00%) (2497/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2104) | Acc: (92.00%) (3681/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2125) | Acc: (92.00%) (4865/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2099) | Acc: (92.00%) (6050/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2102) | Acc: (92.00%) (7245/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2117) | Acc: (92.00%) (8433/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2126) | Acc: (92.00%) (9620/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2122) | Acc: (92.00%) (10807/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2144) | Acc: (92.00%) (11986/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2167) | Acc: (92.00%) (13162/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2172) | Acc: (92.00%) (14345/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2191) | Acc: (92.00%) (15521/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2182) | Acc: (92.00%) (16713/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2211) | Acc: (92.00%) (17878/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2206) | Acc: (92.00%) (19066/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2193) | Acc: (92.00%) (20260/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2204) | Acc: (92.00%) (21439/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2223) | Acc: (92.00%) (22603/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2213) | Acc: (92.00%) (23799/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2206) | Acc: (92.00%) (24979/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2206) | Acc: (92.00%) (26163/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2210) | Acc: (92.00%) (27346/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2224) | Acc: (92.00%) (28520/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2231) | Acc: (92.00%) (29698/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2233) | Acc: (92.00%) (30882/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2232) | Acc: (92.00%) (32073/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2238) | Acc: (92.00%) (33250/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2240) | Acc: (92.00%) (34436/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2245) | Acc: (92.00%) (35608/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2252) | Acc: (92.00%) (36776/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2260) | Acc: (92.00%) (37949/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2259) | Acc: (92.00%) (39132/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2258) | Acc: (92.00%) (40313/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2259) | Acc: (92.00%) (41497/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2243) | Acc: (92.00%) (42705/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2242) | Acc: (92.00%) (43894/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2241) | Acc: (92.00%) (45078/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2239) | Acc: (92.00%) (46213/50000)
# TEST : Loss: (0.3331) | Acc: (89.00%) (8944/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3482e-01,  2.7342e-01, -1.3635e-01],
          [-7.3899e-02,  2.9253e-02, -6.3712e-02],
          [ 5.8813e-02, -2.2415e-01,  2.6662e-01]],

         [[-1.2895e-01,  4.2220e-01,  9.5340e-02],
          [-6.9998e-03,  2.0647e-02, -1.6673e-01],
          [ 8.0080e-02, -3.7092e-01, -1.7220e-02]],

         [[-9.8666e-02,  2.7607e-01, -1.3919e-01],
          [ 1.0239e-01, -1.5271e-01, -1.1264e-01],
          [ 1.5193e-01, -1.4260e-01,  2.1300e-01]]],


        [[[-1.7421e-01, -3.4004e-01, -2.0310e-01],
          [-1.2695e-01,  2.1512e-01,  1.8012e-01],
          [ 1.8072e-01,  1.1903e-01,  2.3156e-01]],

         [[-2.5657e-01, -2.6617e-01, -1.8773e-01],
          [-1.5268e-01,  1.3954e-01,  2.1414e-01],
          [ 2.5899e-01,  6.4832e-02,  1.2631e-01]],

         [[-1.4941e-01,  3.2561e-02, -2.2244e-01],
          [ 5.4313e-02,  2.1757e-01, -8.0217e-02],
          [ 1.8819e-03,  7.8604e-02,  5.4924e-02]]],


        [[[-1.1299e-01,  2.4258e-01,  1.0007e-01],
          [ 1.5928e-01,  1.6558e-01, -7.3962e-02],
          [-2.1359e-01, -2.7530e-02, -2.6419e-01]],

         [[ 6.1717e-02,  1.0727e-01,  3.6177e-02],
          [ 1.0111e-01,  2.6051e-01,  8.1095e-02],
          [-9.1745e-02, -6.4175e-02, -3.4981e-01]],

         [[-7.5899e-02,  1.1182e-01,  2.0402e-01],
          [ 5.3504e-02,  2.7093e-01,  9.9897e-02],
          [-2.3103e-01, -1.8903e-01, -2.5392e-01]]],


        ...,


        [[[-1.1142e-01, -1.3442e-01,  2.1854e-02],
          [ 1.0433e-01, -3.0840e-01, -1.4846e-01],
          [ 1.2633e-01, -1.0927e-01,  5.5676e-02]],

         [[ 1.6606e-01, -3.1532e-02, -2.4510e-03],
          [-4.2377e-02, -3.8582e-01, -2.4884e-01],
          [ 1.0996e-01, -3.6916e-02, -6.7397e-02]],

         [[ 2.2047e-01,  2.9182e-02,  9.6358e-02],
          [ 1.5177e-02, -2.0316e-01, -1.8837e-01],
          [ 7.4537e-02, -1.2505e-01, -1.0928e-01]]],


        [[[ 1.2829e-40,  1.9704e-40, -2.5858e-40],
          [ 1.4673e-40, -1.3786e-40, -2.1796e-41],
          [-2.0423e-40,  4.8563e-41,  1.7738e-40]],

         [[-1.4243e-40,  7.5527e-41,  4.6278e-41],
          [ 2.2253e-42,  1.8585e-40,  5.0689e-41],
          [-1.8568e-40, -4.8460e-41, -4.2110e-41]],

         [[ 9.1785e-43, -2.8169e-40, -1.1151e-40],
          [-1.7301e-40,  2.0448e-41,  1.0318e-40],
          [-1.3815e-41, -1.6831e-40,  1.4795e-40]]],


        [[[-6.6934e-41, -5.1428e-42,  1.9450e-42],
          [-4.7482e-41, -6.9785e-43, -7.5600e-42],
          [-4.5193e-41, -2.4908e-41, -8.1457e-42]],

         [[ 4.5587e-41, -6.6759e-41, -7.7817e-41],
          [-5.5416e-41,  2.8805e-41,  6.2319e-41],
          [-1.2732e-41, -2.3711e-41, -6.4631e-41]],

         [[-9.2906e-42,  5.6423e-41, -3.1404e-41],
          [-5.2053e-41,  4.3904e-41,  2.2876e-41],
          [-9.4153e-42,  2.7886e-43,  5.7728e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0073, -0.0055, -0.0029],
          [ 0.0087,  0.0046, -0.0081],
          [ 0.0082, -0.0125, -0.0152]],

         [[ 0.0080,  0.0065,  0.0135],
          [ 0.0198,  0.0210,  0.0095],
          [ 0.0183,  0.0079,  0.0013]],

         [[ 0.0203,  0.0212,  0.0272],
          [ 0.0268,  0.0312,  0.0228],
          [ 0.0243,  0.0177,  0.0189]]],


        [[[-0.0328, -0.0288, -0.0252],
          [-0.0334, -0.0279, -0.0234],
          [-0.0435, -0.0409, -0.0295]],

         [[-0.0505, -0.0409, -0.0325],
          [-0.0462, -0.0363, -0.0307],
          [-0.0548, -0.0476, -0.0364]],

         [[-0.0608, -0.0539, -0.0442],
          [-0.0533, -0.0451, -0.0392],
          [-0.0541, -0.0498, -0.0435]]],


        [[[ 0.0177,  0.0228,  0.0252],
          [ 0.0459,  0.0512,  0.0333],
          [ 0.0513,  0.0602,  0.0332]],

         [[ 0.0473,  0.0471,  0.0483],
          [ 0.0689,  0.0718,  0.0558],
          [ 0.0749,  0.0840,  0.0586]],

         [[ 0.0563,  0.0581,  0.0584],
          [ 0.0747,  0.0768,  0.0614],
          [ 0.0792,  0.0856,  0.0626]]],


        ...,


        [[[ 0.0220,  0.0116,  0.0075],
          [ 0.0173,  0.0093,  0.0146],
          [ 0.0104,  0.0048,  0.0140]],

         [[ 0.0046, -0.0066, -0.0117],
          [ 0.0018, -0.0058, -0.0016],
          [-0.0029, -0.0074,  0.0008]],

         [[-0.0044, -0.0125, -0.0170],
          [-0.0079, -0.0122, -0.0069],
          [-0.0126, -0.0141, -0.0051]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5994]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 81 | Batch_idx: 0 |  Loss: (0.1467) | Acc: (93.00%) (120/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2098) | Acc: (92.00%) (1301/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2344) | Acc: (91.00%) (2472/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2502) | Acc: (91.00%) (3630/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2532) | Acc: (91.00%) (4788/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2487) | Acc: (91.00%) (5960/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2451) | Acc: (91.00%) (7134/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2417) | Acc: (91.00%) (8316/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2401) | Acc: (91.00%) (9494/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2360) | Acc: (91.00%) (10684/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2317) | Acc: (91.00%) (11887/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2266) | Acc: (92.00%) (13085/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2240) | Acc: (92.00%) (14279/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2212) | Acc: (92.00%) (15477/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2211) | Acc: (92.00%) (16660/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2180) | Acc: (92.00%) (17866/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2172) | Acc: (92.00%) (19051/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2173) | Acc: (92.00%) (20239/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2134) | Acc: (92.00%) (21465/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2134) | Acc: (92.00%) (22658/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2143) | Acc: (92.00%) (23833/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2120) | Acc: (92.00%) (25045/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2117) | Acc: (92.00%) (26234/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2102) | Acc: (92.00%) (27427/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2092) | Acc: (92.00%) (28629/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2084) | Acc: (92.00%) (29830/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2080) | Acc: (92.00%) (31024/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2083) | Acc: (92.00%) (32207/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2081) | Acc: (92.00%) (33402/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2090) | Acc: (92.00%) (34585/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2087) | Acc: (92.00%) (35784/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2089) | Acc: (92.00%) (36972/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2074) | Acc: (92.00%) (38185/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2062) | Acc: (92.00%) (39397/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2060) | Acc: (93.00%) (40593/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2059) | Acc: (92.00%) (41780/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2058) | Acc: (92.00%) (42965/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2051) | Acc: (93.00%) (44166/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2048) | Acc: (93.00%) (45359/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2049) | Acc: (93.00%) (46503/50000)
# TEST : Loss: (0.3027) | Acc: (90.00%) (9041/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3510e-01,  2.7088e-01, -1.3914e-01],
          [-7.4321e-02,  2.7504e-02, -6.5144e-02],
          [ 5.8781e-02, -2.2375e-01,  2.6649e-01]],

         [[-1.2917e-01,  4.1951e-01,  9.2165e-02],
          [-7.3449e-03,  1.8824e-02, -1.6812e-01],
          [ 8.0247e-02, -3.7036e-01, -1.6372e-02]],

         [[-9.8943e-02,  2.7468e-01, -1.4049e-01],
          [ 1.0193e-01, -1.5324e-01, -1.1347e-01],
          [ 1.5215e-01, -1.4234e-01,  2.1327e-01]]],


        [[[-1.7132e-01, -3.3700e-01, -2.0015e-01],
          [-1.2416e-01,  2.1687e-01,  1.8219e-01],
          [ 1.8323e-01,  1.2158e-01,  2.3404e-01]],

         [[-2.5395e-01, -2.6398e-01, -1.8566e-01],
          [-1.5056e-01,  1.4072e-01,  2.1554e-01],
          [ 2.6059e-01,  6.6704e-02,  1.2807e-01]],

         [[-1.4719e-01,  3.4027e-02, -2.2063e-01],
          [ 5.5670e-02,  2.1818e-01, -7.8784e-02],
          [ 3.5367e-03,  8.0036e-02,  5.6508e-02]]],


        [[[-1.1402e-01,  2.4032e-01,  9.8100e-02],
          [ 1.5889e-01,  1.6405e-01, -7.5358e-02],
          [-2.1293e-01, -2.8596e-02, -2.6511e-01]],

         [[ 6.0277e-02,  1.0542e-01,  3.4498e-02],
          [ 1.0058e-01,  2.5855e-01,  7.8988e-02],
          [-9.1898e-02, -6.6053e-02, -3.5147e-01]],

         [[-7.6300e-02,  1.1077e-01,  2.0281e-01],
          [ 5.3337e-02,  2.6942e-01,  9.8186e-02],
          [-2.3123e-01, -1.9073e-01, -2.5586e-01]]],


        ...,


        [[[-1.1033e-01, -1.3143e-01,  2.5328e-02],
          [ 1.0206e-01, -3.0646e-01, -1.4648e-01],
          [ 1.2381e-01, -1.1015e-01,  5.4385e-02]],

         [[ 1.6459e-01, -3.0025e-02,  6.7619e-04],
          [-4.5631e-02, -3.8465e-01, -2.4670e-01],
          [ 1.0585e-01, -3.9993e-02, -6.9231e-02]],

         [[ 2.1975e-01,  3.1322e-02,  9.9859e-02],
          [ 1.3206e-02, -2.0214e-01, -1.8597e-01],
          [ 7.2142e-02, -1.2569e-01, -1.0936e-01]]],


        [[[-3.6455e-40,  2.4269e-41,  2.4299e-40],
          [-1.1607e-40, -2.2531e-40, -2.6131e-41],
          [-3.0004e-40, -1.0267e-40, -1.8372e-40]],

         [[ 1.0176e-40,  8.5734e-41,  4.8399e-41],
          [-2.8468e-40,  3.5268e-40,  5.2829e-41],
          [ 1.7803e-40, -2.1256e-40, -3.6100e-40]],

         [[-1.9784e-40,  2.2870e-40,  1.5209e-40],
          [ 2.5766e-41, -1.9516e-40, -1.7724e-40],
          [-1.6647e-40,  2.0101e-40, -2.9453e-40]]],


        [[[-3.3420e-41, -5.4931e-43, -6.4123e-42],
          [-6.3133e-41,  4.3536e-41,  1.9402e-41],
          [ 7.6769e-41,  4.6625e-41,  6.2994e-41]],

         [[ 4.2667e-41, -6.9617e-42, -5.5007e-41],
          [-4.6432e-41, -2.0319e-43,  5.9760e-41],
          [-7.5365e-41, -1.3026e-41, -8.0615e-41]],

         [[-4.3749e-42, -3.8442e-41, -2.4069e-41],
          [-3.7304e-41,  7.2269e-41, -6.6440e-41],
          [ 2.4234e-41,  1.4778e-41, -5.6324e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6101]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0560]], device='cuda:0')

Epoch: 82 | Batch_idx: 0 |  Loss: (0.1563) | Acc: (94.00%) (121/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.1726) | Acc: (93.00%) (1319/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.1734) | Acc: (94.00%) (2529/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.1801) | Acc: (93.00%) (3723/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.1782) | Acc: (93.00%) (4925/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.1826) | Acc: (93.00%) (6108/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.1838) | Acc: (93.00%) (7303/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.1853) | Acc: (93.00%) (8503/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.1871) | Acc: (93.00%) (9695/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.1857) | Acc: (93.00%) (10906/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.1860) | Acc: (93.00%) (12103/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.1864) | Acc: (93.00%) (13294/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.1873) | Acc: (93.00%) (14484/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.1864) | Acc: (93.00%) (15694/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.1866) | Acc: (93.00%) (16895/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.1857) | Acc: (93.00%) (18103/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.1837) | Acc: (93.00%) (19321/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.1838) | Acc: (93.00%) (20515/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.1841) | Acc: (93.00%) (21717/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.1839) | Acc: (93.00%) (22920/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.1830) | Acc: (93.00%) (24134/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.1824) | Acc: (93.00%) (25334/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.1843) | Acc: (93.00%) (26520/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.1832) | Acc: (93.00%) (27735/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.1821) | Acc: (93.00%) (28951/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.1822) | Acc: (93.00%) (30149/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.1820) | Acc: (93.00%) (31349/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.1816) | Acc: (93.00%) (32557/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.1822) | Acc: (93.00%) (33752/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.1821) | Acc: (93.00%) (34945/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.1829) | Acc: (93.00%) (36141/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.1833) | Acc: (93.00%) (37343/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.1828) | Acc: (93.00%) (38553/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.1819) | Acc: (93.00%) (39768/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.1822) | Acc: (93.00%) (40960/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.1827) | Acc: (93.00%) (42154/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.1823) | Acc: (93.00%) (43361/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.1823) | Acc: (93.00%) (44567/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.1823) | Acc: (93.00%) (45767/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.1819) | Acc: (93.00%) (46934/50000)
# TEST : Loss: (0.2914) | Acc: (90.00%) (9076/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3478e-01,  2.7022e-01, -1.3880e-01],
          [-7.4147e-02,  2.7438e-02, -6.4988e-02],
          [ 5.8642e-02, -2.2319e-01,  2.6585e-01]],

         [[-1.2884e-01,  4.1842e-01,  9.1935e-02],
          [-7.3267e-03,  1.8776e-02, -1.6769e-01],
          [ 8.0047e-02, -3.6939e-01, -1.6332e-02]],

         [[-9.8678e-02,  2.7394e-01, -1.4012e-01],
          [ 1.0167e-01, -1.5283e-01, -1.1318e-01],
          [ 1.5175e-01, -1.4195e-01,  2.1271e-01]]],


        [[[-1.7093e-01, -3.3623e-01, -1.9970e-01],
          [-1.2388e-01,  2.1638e-01,  1.8177e-01],
          [ 1.8280e-01,  1.2129e-01,  2.3347e-01]],

         [[-2.5335e-01, -2.6335e-01, -1.8521e-01],
          [-1.5021e-01,  1.4039e-01,  2.1502e-01],
          [ 2.5995e-01,  6.6539e-02,  1.2775e-01]],

         [[-1.4681e-01,  3.3939e-02, -2.2007e-01],
          [ 5.5530e-02,  2.1763e-01, -7.8584e-02],
          [ 3.5276e-03,  7.9829e-02,  5.6361e-02]]],


        [[[-1.1379e-01,  2.3985e-01,  9.7910e-02],
          [ 1.5860e-01,  1.6374e-01, -7.5216e-02],
          [-2.1254e-01, -2.8543e-02, -2.6460e-01]],

         [[ 6.0158e-02,  1.0522e-01,  3.4431e-02],
          [ 1.0039e-01,  2.5806e-01,  7.8839e-02],
          [-9.1726e-02, -6.5928e-02, -3.5079e-01]],

         [[-7.6143e-02,  1.1054e-01,  2.0240e-01],
          [ 5.3232e-02,  2.6889e-01,  9.7990e-02],
          [-2.3077e-01, -1.9035e-01, -2.5534e-01]]],


        ...,


        [[[-1.0976e-01, -1.3054e-01,  2.5160e-02],
          [ 1.0143e-01, -3.0326e-01, -1.4497e-01],
          [ 1.2313e-01, -1.0931e-01,  5.3963e-02]],

         [[ 1.6368e-01, -2.9803e-02,  6.7133e-04],
          [-4.5324e-02, -3.7958e-01, -2.4347e-01],
          [ 1.0524e-01, -3.9656e-02, -6.8636e-02]],

         [[ 2.1854e-01,  3.1112e-02,  9.9207e-02],
          [ 1.3121e-02, -2.0030e-01, -1.8429e-01],
          [ 7.1724e-02, -1.2474e-01, -1.0851e-01]]],


        [[[ 1.7253e-41, -1.1671e-40, -1.7127e-40],
          [ 2.5495e-40, -1.6704e-40,  2.0530e-40],
          [-2.4656e-40, -1.9465e-40,  4.6826e-41]],

         [[-1.7370e-40,  2.2508e-41, -9.9824e-41],
          [-2.3318e-40,  5.7684e-41, -1.8584e-40],
          [ 2.7462e-40, -2.3065e-40, -3.9180e-40]],

         [[ 2.9169e-40, -1.9223e-40,  1.5762e-41],
          [ 2.8072e-41, -3.7498e-40,  1.2633e-40],
          [-1.8269e-41, -3.0494e-41, -2.3867e-40]]],


        [[[ 4.6226e-41,  3.3763e-41,  1.4547e-41],
          [-5.5889e-41,  1.4361e-41,  3.0417e-41],
          [-4.4613e-41,  6.8832e-41, -4.9742e-41]],

         [[-5.2243e-41,  8.2689e-41,  4.9271e-41],
          [-3.1222e-41, -4.2932e-41,  3.4192e-42],
          [-9.1042e-42,  5.6720e-41, -5.4139e-41]],

         [[-3.0620e-41,  2.7725e-41,  1.9411e-41],
          [-2.6501e-41,  7.7404e-41,  8.5283e-41],
          [ 7.0845e-41, -1.3441e-41,  5.7033e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5955]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0056]], device='cuda:0')

Epoch: 83 | Batch_idx: 0 |  Loss: (0.0739) | Acc: (97.00%) (125/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.1957) | Acc: (93.00%) (1310/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.1837) | Acc: (93.00%) (2517/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.1787) | Acc: (93.00%) (3720/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.1803) | Acc: (93.00%) (4923/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.1791) | Acc: (93.00%) (6123/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.1801) | Acc: (93.00%) (7325/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.1806) | Acc: (93.00%) (8523/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.1810) | Acc: (93.00%) (9716/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.1817) | Acc: (93.00%) (10924/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.1834) | Acc: (93.00%) (12110/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.1816) | Acc: (93.00%) (13321/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.1820) | Acc: (93.00%) (14526/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.1829) | Acc: (93.00%) (15720/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.1813) | Acc: (93.00%) (16946/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.1809) | Acc: (93.00%) (18149/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.1812) | Acc: (93.00%) (19349/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.1806) | Acc: (93.00%) (20557/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.1801) | Acc: (93.00%) (21763/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.1793) | Acc: (93.00%) (22968/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.1798) | Acc: (93.00%) (24163/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.1802) | Acc: (93.00%) (25368/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.1798) | Acc: (93.00%) (26571/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.1795) | Acc: (93.00%) (27786/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.1796) | Acc: (93.00%) (28988/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.1790) | Acc: (93.00%) (30198/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.1776) | Acc: (94.00%) (31422/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.1769) | Acc: (94.00%) (32626/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.1767) | Acc: (94.00%) (33838/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.1773) | Acc: (94.00%) (35027/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.1779) | Acc: (94.00%) (36220/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.1773) | Acc: (94.00%) (37427/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.1770) | Acc: (94.00%) (38637/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.1773) | Acc: (94.00%) (39842/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.1774) | Acc: (94.00%) (41050/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.1774) | Acc: (94.00%) (42257/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.1773) | Acc: (94.00%) (43471/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.1776) | Acc: (94.00%) (44671/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.1782) | Acc: (94.00%) (45857/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.1788) | Acc: (94.00%) (47011/50000)
# TEST : Loss: (0.2870) | Acc: (90.00%) (9086/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3438e-01,  2.6941e-01, -1.3840e-01],
          [-7.3937e-02,  2.7358e-02, -6.4799e-02],
          [ 5.8474e-02, -2.2252e-01,  2.6508e-01]],

         [[-1.2844e-01,  4.1710e-01,  9.1657e-02],
          [-7.3046e-03,  1.8718e-02, -1.6718e-01],
          [ 7.9805e-02, -3.6822e-01, -1.6282e-02]],

         [[-9.8357e-02,  2.7303e-01, -1.3967e-01],
          [ 1.0134e-01, -1.5234e-01, -1.1282e-01],
          [ 1.5126e-01, -1.4147e-01,  2.1203e-01]]],


        [[[-1.7046e-01, -3.3530e-01, -1.9915e-01],
          [-1.2354e-01,  2.1579e-01,  1.8126e-01],
          [ 1.8228e-01,  1.2094e-01,  2.3279e-01]],

         [[-2.5261e-01, -2.6258e-01, -1.8467e-01],
          [-1.4978e-01,  1.3999e-01,  2.1439e-01],
          [ 2.5918e-01,  6.6340e-02,  1.2736e-01]],

         [[-1.4635e-01,  3.3833e-02, -2.1938e-01],
          [ 5.5361e-02,  2.1696e-01, -7.8341e-02],
          [ 3.5166e-03,  7.9578e-02,  5.6183e-02]]],


        [[[-1.1352e-01,  2.3927e-01,  9.7679e-02],
          [ 1.5824e-01,  1.6337e-01, -7.5045e-02],
          [-2.1206e-01, -2.8477e-02, -2.6399e-01]],

         [[ 6.0013e-02,  1.0496e-01,  3.4349e-02],
          [ 1.0016e-01,  2.5747e-01,  7.8657e-02],
          [-9.1518e-02, -6.5776e-02, -3.4996e-01]],

         [[-7.5953e-02,  1.1027e-01,  2.0190e-01],
          [ 5.3106e-02,  2.6825e-01,  9.7752e-02],
          [-2.3022e-01, -1.8989e-01, -2.5470e-01]]],


        ...,


        [[[-1.0907e-01, -1.2947e-01,  2.4957e-02],
          [ 1.0067e-01, -2.9941e-01, -1.4316e-01],
          [ 1.2231e-01, -1.0829e-01,  5.3454e-02]],

         [[ 1.6258e-01, -2.9534e-02,  6.6547e-04],
          [-4.4952e-02, -3.7351e-01, -2.3960e-01],
          [ 1.0451e-01, -3.9249e-02, -6.7919e-02]],

         [[ 2.1706e-01,  3.0858e-02,  9.8419e-02],
          [ 1.3017e-02, -1.9808e-01, -1.8226e-01],
          [ 7.1219e-02, -1.2358e-01, -1.0748e-01]]],


        [[[ 1.7184e-40,  1.8545e-40,  2.9428e-40],
          [ 1.9192e-40, -9.5849e-42, -3.1096e-41],
          [-2.6621e-40, -1.2006e-40,  3.1580e-40]],

         [[ 2.0313e-40, -5.4391e-41,  2.1965e-40],
          [-2.5309e-40, -2.0234e-40, -2.0063e-40],
          [-1.5362e-40, -5.9705e-41, -2.3667e-40]],

         [[ 1.5571e-40, -2.1023e-40, -1.4921e-40],
          [ 2.8525e-40, -4.0565e-40, -3.3913e-41],
          [-3.7178e-40, -3.2104e-41, -2.5809e-40]]],


        [[[ 4.0404e-41,  6.6091e-41,  4.2613e-42],
          [-4.2709e-41, -6.5731e-41,  1.1559e-41],
          [-3.5559e-41,  7.1550e-42, -5.7958e-42]],

         [[-2.5121e-41, -4.3126e-41,  8.1528e-42],
          [-4.7926e-41, -8.0388e-41, -3.1839e-41],
          [ 7.1679e-41, -6.3620e-41, -3.7726e-41]],

         [[-6.5805e-42, -7.5628e-41,  6.3382e-41],
          [-5.4672e-41,  8.3824e-41, -3.9852e-41],
          [ 7.3347e-41, -8.7231e-42, -4.0296e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5975]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0410]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 84 | Batch_idx: 0 |  Loss: (0.2245) | Acc: (92.00%) (119/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.1913) | Acc: (93.00%) (1321/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2096) | Acc: (93.00%) (2504/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2313) | Acc: (92.00%) (3670/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2513) | Acc: (91.00%) (4825/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2667) | Acc: (91.00%) (5945/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2793) | Acc: (90.00%) (7067/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2905) | Acc: (90.00%) (8194/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2968) | Acc: (89.00%) (9307/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2936) | Acc: (89.00%) (10470/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2927) | Acc: (89.00%) (11633/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2947) | Acc: (89.00%) (12781/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.3012) | Acc: (89.00%) (13899/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.3048) | Acc: (89.00%) (15024/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.3031) | Acc: (89.00%) (16179/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.3052) | Acc: (89.00%) (17300/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.3050) | Acc: (89.00%) (18453/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.3048) | Acc: (89.00%) (19603/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.3045) | Acc: (89.00%) (20739/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.3028) | Acc: (89.00%) (21897/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.3030) | Acc: (89.00%) (23043/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.3003) | Acc: (89.00%) (24220/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.3003) | Acc: (89.00%) (25363/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.3019) | Acc: (89.00%) (26504/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.3021) | Acc: (89.00%) (27651/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.3031) | Acc: (89.00%) (28786/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.3035) | Acc: (89.00%) (29934/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.3043) | Acc: (89.00%) (31079/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.3026) | Acc: (89.00%) (32245/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.3027) | Acc: (89.00%) (33394/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.3011) | Acc: (89.00%) (34561/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2994) | Acc: (89.00%) (35730/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2984) | Acc: (89.00%) (36890/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2979) | Acc: (89.00%) (38053/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2975) | Acc: (89.00%) (39204/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2967) | Acc: (89.00%) (40367/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2960) | Acc: (89.00%) (41526/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2956) | Acc: (89.00%) (42674/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2951) | Acc: (89.00%) (43842/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2946) | Acc: (89.00%) (44954/50000)
# TEST : Loss: (0.3771) | Acc: (88.00%) (8826/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3902e-01,  2.8559e-01, -1.1262e-01],
          [-8.0346e-02,  2.4595e-02, -5.2698e-02],
          [ 7.1372e-02, -2.1366e-01,  2.7628e-01]],

         [[-1.3073e-01,  4.3661e-01,  1.2024e-01],
          [-1.4692e-02,  1.6981e-02, -1.5843e-01],
          [ 9.2341e-02, -3.5962e-01, -1.2883e-02]],

         [[-1.0766e-01,  2.7522e-01, -1.2431e-01],
          [ 8.7090e-02, -1.5838e-01, -1.0970e-01],
          [ 1.6038e-01, -1.2988e-01,  2.0935e-01]]],


        [[[-1.6996e-01, -3.3509e-01, -1.9555e-01],
          [-1.2500e-01,  2.1869e-01,  1.8386e-01],
          [ 1.8522e-01,  1.3125e-01,  2.4129e-01]],

         [[-2.5865e-01, -2.6556e-01, -1.8479e-01],
          [-1.5763e-01,  1.4042e-01,  2.1529e-01],
          [ 2.5572e-01,  7.2722e-02,  1.3331e-01]],

         [[-1.5561e-01,  2.5835e-02, -2.2473e-01],
          [ 4.3655e-02,  2.1105e-01, -8.1915e-02],
          [-6.2719e-03,  7.9415e-02,  5.4866e-02]]],


        [[[-1.2085e-01,  2.4512e-01,  9.9944e-02],
          [ 1.5641e-01,  1.7055e-01, -7.3604e-02],
          [-2.1583e-01, -2.8006e-02, -2.6717e-01]],

         [[ 4.8516e-02,  1.0343e-01,  2.4428e-02],
          [ 9.3574e-02,  2.5625e-01,  6.6810e-02],
          [-1.0196e-01, -7.1620e-02, -3.6242e-01]],

         [[-8.9463e-02,  1.0964e-01,  1.9123e-01],
          [ 4.4456e-02,  2.6853e-01,  9.1703e-02],
          [-2.4135e-01, -1.9389e-01, -2.6272e-01]]],


        ...,


        [[[-1.0209e-01, -1.3400e-01,  1.8511e-02],
          [ 1.0665e-01, -3.0446e-01, -1.5747e-01],
          [ 1.3161e-01, -1.0027e-01,  5.8550e-02]],

         [[ 1.6132e-01, -4.0764e-02, -1.5462e-02],
          [-5.1033e-02, -3.9461e-01, -2.7447e-01],
          [ 9.8707e-02, -4.8510e-02, -7.9736e-02]],

         [[ 2.1904e-01,  2.9668e-02,  9.4249e-02],
          [ 1.9253e-02, -1.9456e-01, -1.8632e-01],
          [ 7.4638e-02, -1.1971e-01, -1.0552e-01]]],


        [[[-1.4990e-40,  2.8397e-40,  3.1839e-40],
          [-1.5349e-40,  1.7392e-40, -1.2584e-40],
          [ 2.7595e-40,  6.2590e-41,  5.2320e-41]],

         [[ 1.3791e-40, -1.4458e-40,  2.3724e-40],
          [-3.6395e-40,  3.5021e-40,  1.6128e-40],
          [-2.5902e-40,  1.3582e-40,  4.0952e-41]],

         [[-9.3881e-41,  2.1147e-40, -2.5124e-40],
          [ 3.9829e-40, -3.4030e-40,  1.4878e-40],
          [-3.0335e-40,  1.5790e-40,  9.9520e-42]]],


        [[[-1.9618e-44, -5.5808e-41, -6.2645e-41],
          [-4.1585e-41,  4.2145e-41,  4.4536e-41],
          [ 2.2003e-41, -7.8208e-41,  3.6161e-41]],

         [[ 4.8121e-42,  5.2829e-41,  1.0489e-41],
          [-8.8517e-41, -2.4708e-41,  4.8051e-42],
          [-8.1934e-41,  2.6388e-41, -2.3546e-41]],

         [[ 7.5264e-41,  5.3657e-41,  5.2483e-41],
          [-2.9283e-41,  8.6324e-41, -9.7082e-41],
          [ 3.4372e-41,  7.1597e-41, -5.9196e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0002,  0.0023,  0.0077],
          [ 0.0001,  0.0010,  0.0062],
          [-0.0023,  0.0075,  0.0118]],

         [[-0.0090, -0.0068, -0.0022],
          [-0.0128, -0.0113, -0.0040],
          [-0.0129, -0.0026,  0.0059]],

         [[-0.0040, -0.0161, -0.0166],
          [-0.0062, -0.0185, -0.0195],
          [-0.0106, -0.0108, -0.0076]]],


        [[[-0.0120, -0.0076, -0.0030],
          [-0.0085, -0.0038, -0.0076],
          [-0.0108, -0.0072, -0.0094]],

         [[-0.0054, -0.0000,  0.0054],
          [-0.0014,  0.0041, -0.0004],
          [-0.0038,  0.0003, -0.0030]],

         [[-0.0189, -0.0144, -0.0103],
          [-0.0170, -0.0105, -0.0122],
          [-0.0202, -0.0129, -0.0122]]],


        [[[ 0.0045,  0.0013, -0.0071],
          [ 0.0016, -0.0026, -0.0082],
          [ 0.0064,  0.0002, -0.0045]],

         [[ 0.0065,  0.0055, -0.0032],
          [ 0.0049,  0.0018, -0.0036],
          [ 0.0111,  0.0047,  0.0003]],

         [[-0.0010,  0.0014,  0.0003],
          [-0.0085, -0.0050, -0.0004],
          [-0.0053, -0.0055,  0.0004]]],


        ...,


        [[[ 0.0020,  0.0042,  0.0025],
          [ 0.0037,  0.0034,  0.0004],
          [ 0.0073,  0.0047,  0.0011]],

         [[ 0.0008,  0.0027,  0.0004],
          [ 0.0028,  0.0025, -0.0018],
          [ 0.0053,  0.0037, -0.0016]],

         [[ 0.0011,  0.0034,  0.0029],
          [ 0.0023,  0.0017, -0.0010],
          [ 0.0045,  0.0015, -0.0033]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5962]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 85 | Batch_idx: 0 |  Loss: (0.1770) | Acc: (91.00%) (117/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2303) | Acc: (91.00%) (1295/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2270) | Acc: (92.00%) (2478/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2273) | Acc: (92.00%) (3661/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2267) | Acc: (92.00%) (4846/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2269) | Acc: (92.00%) (6025/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2240) | Acc: (92.00%) (7219/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2247) | Acc: (92.00%) (8407/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2225) | Acc: (92.00%) (9602/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2210) | Acc: (92.00%) (10793/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2222) | Acc: (92.00%) (11972/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2245) | Acc: (92.00%) (13149/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2271) | Acc: (92.00%) (14319/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2274) | Acc: (92.00%) (15491/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2274) | Acc: (92.00%) (16675/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2297) | Acc: (92.00%) (17846/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2304) | Acc: (92.00%) (19023/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2332) | Acc: (92.00%) (20180/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2354) | Acc: (92.00%) (21344/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2367) | Acc: (92.00%) (22516/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2374) | Acc: (92.00%) (23685/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2379) | Acc: (92.00%) (24849/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2365) | Acc: (92.00%) (26035/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2377) | Acc: (92.00%) (27205/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2367) | Acc: (92.00%) (28403/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2360) | Acc: (92.00%) (29589/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2365) | Acc: (92.00%) (30756/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2367) | Acc: (92.00%) (31926/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2364) | Acc: (92.00%) (33111/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2366) | Acc: (92.00%) (34277/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2372) | Acc: (92.00%) (35451/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2380) | Acc: (91.00%) (36613/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2381) | Acc: (91.00%) (37783/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2373) | Acc: (91.00%) (38970/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2375) | Acc: (91.00%) (40148/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2382) | Acc: (91.00%) (41308/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2385) | Acc: (91.00%) (42484/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2381) | Acc: (91.00%) (43665/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2382) | Acc: (91.00%) (44832/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2382) | Acc: (91.00%) (45962/50000)
# TEST : Loss: (0.3610) | Acc: (89.00%) (8904/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5011e-01,  2.8093e-01, -1.2931e-01],
          [-8.5062e-02,  1.9799e-02, -5.9802e-02],
          [ 6.2991e-02, -2.2073e-01,  2.7896e-01]],

         [[-1.4129e-01,  4.3176e-01,  1.0130e-01],
          [-2.2775e-02,  7.6778e-03, -1.6727e-01],
          [ 7.8218e-02, -3.7012e-01, -1.4536e-02]],

         [[-1.1429e-01,  2.7234e-01, -1.3950e-01],
          [ 8.1281e-02, -1.6094e-01, -1.1694e-01],
          [ 1.5030e-01, -1.3092e-01,  2.1253e-01]]],


        [[[-1.7621e-01, -3.4817e-01, -2.0617e-01],
          [-1.2294e-01,  2.1316e-01,  1.7707e-01],
          [ 1.9097e-01,  1.3264e-01,  2.3196e-01]],

         [[-2.5962e-01, -2.7476e-01, -1.9281e-01],
          [-1.5353e-01,  1.3709e-01,  2.0877e-01],
          [ 2.6105e-01,  7.2922e-02,  1.2141e-01]],

         [[-1.5199e-01,  2.2605e-02, -2.2577e-01],
          [ 5.5793e-02,  2.1782e-01, -7.6767e-02],
          [ 3.4247e-03,  8.5317e-02,  5.1480e-02]]],


        [[[-1.2053e-01,  2.4561e-01,  9.8417e-02],
          [ 1.5610e-01,  1.7035e-01, -7.3679e-02],
          [-2.2423e-01, -3.2018e-02, -2.7003e-01]],

         [[ 4.6949e-02,  1.0256e-01,  2.2606e-02],
          [ 9.3397e-02,  2.5433e-01,  6.4544e-02],
          [-1.1054e-01, -7.6309e-02, -3.6526e-01]],

         [[-8.6108e-02,  1.1103e-01,  1.9053e-01],
          [ 4.6590e-02,  2.6590e-01,  8.9064e-02],
          [-2.4764e-01, -1.9839e-01, -2.6604e-01]]],


        ...,


        [[[-1.1524e-01, -1.3754e-01,  2.9029e-02],
          [ 9.9980e-02, -3.0461e-01, -1.5423e-01],
          [ 1.4015e-01, -9.4564e-02,  5.2087e-02]],

         [[ 1.4550e-01, -4.8482e-02, -6.9227e-03],
          [-5.9447e-02, -4.0025e-01, -2.7953e-01],
          [ 1.0458e-01, -4.8066e-02, -9.5833e-02]],

         [[ 2.0501e-01,  2.7115e-02,  1.0620e-01],
          [ 7.8826e-03, -2.0115e-01, -1.8946e-01],
          [ 7.3750e-02, -1.2334e-01, -1.2209e-01]]],


        [[[-4.3354e-40, -2.4433e-40,  3.4002e-40],
          [-2.5894e-40,  1.8549e-40,  3.5121e-40],
          [ 9.4746e-41,  1.6820e-40, -3.4716e-40]],

         [[-2.1837e-40, -1.5403e-40,  6.2746e-41],
          [ 1.9890e-40, -2.3024e-40,  7.1483e-41],
          [-1.7229e-40,  1.4242e-40, -3.7086e-40]],

         [[ 3.6305e-40,  3.2156e-40,  2.0660e-40],
          [ 1.3228e-40,  4.2959e-40,  2.5677e-40],
          [ 7.9679e-41,  2.6880e-40,  1.1186e-40]]],


        [[[-3.5723e-41, -1.2449e-41, -7.5656e-41],
          [-9.3212e-41,  7.4472e-41,  7.5282e-41],
          [ 2.7086e-41,  4.9355e-41, -8.5325e-42]],

         [[ 6.2802e-41, -9.0691e-41, -2.9946e-41],
          [ 4.7182e-42,  3.0422e-41,  1.0195e-40],
          [ 7.7511e-41, -7.3256e-41, -6.9139e-41]],

         [[ 4.6467e-42,  8.5593e-41, -7.6413e-41],
          [ 8.4821e-42, -1.7596e-41, -2.4823e-41],
          [-6.7673e-41, -7.9643e-41,  6.3931e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0159, -0.0177, -0.0299],
          [-0.0059, -0.0020, -0.0056],
          [-0.0169, -0.0183, -0.0043]],

         [[-0.0031, -0.0130, -0.0289],
          [ 0.0024,  0.0023, -0.0019],
          [-0.0102, -0.0128,  0.0007]],

         [[-0.0009, -0.0169, -0.0295],
          [ 0.0036,  0.0007, -0.0034],
          [-0.0076, -0.0136, -0.0039]]],


        [[[ 0.0194,  0.0057, -0.0004],
          [ 0.0012, -0.0029, -0.0047],
          [ 0.0037,  0.0049,  0.0016]],

         [[-0.0014, -0.0105, -0.0139],
          [-0.0113, -0.0112, -0.0117],
          [-0.0011,  0.0019, -0.0047]],

         [[-0.0081, -0.0140, -0.0114],
          [-0.0097, -0.0094, -0.0073],
          [ 0.0058,  0.0072,  0.0025]]],


        [[[-0.0864, -0.0888, -0.0840],
          [-0.1079, -0.1086, -0.0982],
          [-0.1025, -0.1034, -0.0930]],

         [[-0.0343, -0.0422, -0.0426],
          [-0.0560, -0.0603, -0.0557],
          [-0.0534, -0.0551, -0.0475]],

         [[-0.0131, -0.0205, -0.0209],
          [-0.0273, -0.0302, -0.0257],
          [-0.0242, -0.0261, -0.0192]]],


        ...,


        [[[-0.0030, -0.0062, -0.0021],
          [ 0.0045,  0.0011,  0.0042],
          [ 0.0028, -0.0013, -0.0019]],

         [[-0.0114, -0.0138, -0.0086],
          [-0.0008, -0.0038,  0.0004],
          [ 0.0012, -0.0025, -0.0024]],

         [[-0.0120, -0.0140, -0.0094],
          [-0.0020, -0.0051, -0.0015],
          [ 0.0021, -0.0012, -0.0017]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5948]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 86 | Batch_idx: 0 |  Loss: (0.3263) | Acc: (86.00%) (111/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.1978) | Acc: (93.00%) (1319/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2016) | Acc: (93.00%) (2507/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2000) | Acc: (93.00%) (3692/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2019) | Acc: (93.00%) (4891/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2069) | Acc: (93.00%) (6080/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2067) | Acc: (93.00%) (7264/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2095) | Acc: (92.00%) (8449/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2083) | Acc: (93.00%) (9648/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2071) | Acc: (93.00%) (10839/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2068) | Acc: (93.00%) (12025/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2101) | Acc: (92.00%) (13200/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2109) | Acc: (92.00%) (14385/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2104) | Acc: (92.00%) (15577/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2091) | Acc: (92.00%) (16770/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2122) | Acc: (92.00%) (17941/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2112) | Acc: (92.00%) (19136/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2099) | Acc: (92.00%) (20326/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2095) | Acc: (92.00%) (21517/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2089) | Acc: (92.00%) (22706/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2099) | Acc: (92.00%) (23889/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2104) | Acc: (92.00%) (25072/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2093) | Acc: (92.00%) (26275/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2106) | Acc: (92.00%) (27448/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2106) | Acc: (92.00%) (28633/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2112) | Acc: (92.00%) (29810/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2103) | Acc: (92.00%) (31013/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2111) | Acc: (92.00%) (32190/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2109) | Acc: (92.00%) (33376/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2104) | Acc: (92.00%) (34565/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2105) | Acc: (92.00%) (35757/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2114) | Acc: (92.00%) (36933/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2125) | Acc: (92.00%) (38102/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2135) | Acc: (92.00%) (39280/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2142) | Acc: (92.00%) (40452/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2151) | Acc: (92.00%) (41630/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2154) | Acc: (92.00%) (42807/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2148) | Acc: (92.00%) (44001/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2153) | Acc: (92.00%) (45177/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2162) | Acc: (92.00%) (46305/50000)
# TEST : Loss: (0.4040) | Acc: (87.00%) (8747/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4228e-01,  2.8559e-01, -1.3674e-01],
          [-8.7405e-02,  2.3481e-02, -5.8927e-02],
          [ 5.2689e-02, -2.2572e-01,  2.8429e-01]],

         [[-1.3765e-01,  4.3398e-01,  9.7749e-02],
          [-3.0519e-02,  6.3958e-03, -1.6792e-01],
          [ 6.4037e-02, -3.7698e-01, -9.1183e-03]],

         [[-1.1078e-01,  2.7725e-01, -1.3613e-01],
          [ 7.3920e-02, -1.5851e-01, -1.1757e-01],
          [ 1.4099e-01, -1.2824e-01,  2.2137e-01]]],


        [[[-1.7353e-01, -3.4961e-01, -2.0914e-01],
          [-1.2158e-01,  2.1429e-01,  1.7436e-01],
          [ 1.9504e-01,  1.3435e-01,  2.3135e-01]],

         [[-2.5821e-01, -2.7770e-01, -1.9615e-01],
          [-1.5236e-01,  1.3824e-01,  2.0833e-01],
          [ 2.6493e-01,  7.4274e-02,  1.2274e-01]],

         [[-1.6146e-01,  9.1861e-03, -2.3822e-01],
          [ 4.6270e-02,  2.0978e-01, -8.2745e-02],
          [-4.0347e-03,  7.7581e-02,  4.5487e-02]]],


        [[[-1.1048e-01,  2.5404e-01,  1.0412e-01],
          [ 1.6959e-01,  1.8177e-01, -6.5580e-02],
          [-2.1341e-01, -2.4396e-02, -2.6781e-01]],

         [[ 5.5380e-02,  1.1052e-01,  2.9080e-02],
          [ 1.0475e-01,  2.6377e-01,  7.1391e-02],
          [-1.0130e-01, -7.0291e-02, -3.6416e-01]],

         [[-7.8716e-02,  1.1916e-01,  1.9668e-01],
          [ 5.5835e-02,  2.7367e-01,  9.3833e-02],
          [-2.3665e-01, -1.9081e-01, -2.6431e-01]]],


        ...,


        [[[-1.1271e-01, -1.4575e-01,  2.4954e-02],
          [ 9.6781e-02, -3.2616e-01, -1.5705e-01],
          [ 1.3256e-01, -1.0197e-01,  5.7805e-02]],

         [[ 1.4937e-01, -5.3876e-02, -3.3127e-03],
          [-5.7554e-02, -4.1359e-01, -2.6205e-01],
          [ 1.0205e-01, -4.5519e-02, -6.9928e-02]],

         [[ 2.0906e-01,  2.7412e-02,  1.1565e-01],
          [ 5.6271e-03, -2.0935e-01, -1.7550e-01],
          [ 6.6203e-02, -1.2494e-01, -1.0185e-01]]],


        [[[ 3.0749e-40, -1.6226e-40,  3.6227e-40],
          [-1.7212e-40,  2.9753e-40,  4.7563e-40],
          [ 3.0898e-40,  1.7714e-40,  2.6976e-40]],

         [[-2.3300e-40,  3.4507e-41, -1.3309e-40],
          [-9.9568e-41,  2.8641e-40, -1.3508e-40],
          [ 3.2841e-41,  1.4735e-40, -4.9870e-40]],

         [[-4.0333e-40, -3.5616e-40,  2.2061e-40],
          [-1.6948e-40,  1.3872e-40,  1.6676e-40],
          [ 4.0173e-40,  1.7500e-40,  4.3724e-40]]],


        [[[-1.5554e-43,  6.6127e-42,  4.4360e-41],
          [ 4.3855e-41,  1.9856e-41, -7.0233e-41],
          [-8.3506e-41, -6.4306e-41, -9.8559e-41]],

         [[-1.1196e-42, -9.0480e-41,  7.6505e-41],
          [ 4.1469e-41,  7.3998e-41, -8.8243e-41],
          [ 9.8569e-41,  6.8124e-41,  4.7777e-41]],

         [[-3.0021e-41,  1.0839e-40, -9.7766e-41],
          [ 4.6295e-41, -2.0902e-41,  1.0152e-40],
          [-7.7584e-41, -6.9701e-41, -2.7038e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0125, -0.0064, -0.0091],
          [-0.0140, -0.0105, -0.0143],
          [-0.0193, -0.0038, -0.0112]],

         [[ 0.0272,  0.0134,  0.0103],
          [ 0.0010,  0.0009, -0.0007],
          [-0.0116, -0.0027,  0.0028]],

         [[ 0.0378,  0.0253,  0.0189],
          [ 0.0180,  0.0122,  0.0106],
          [ 0.0011,  0.0025,  0.0097]]],


        [[[ 0.0005,  0.0110,  0.0170],
          [ 0.0066,  0.0113,  0.0067],
          [ 0.0044,  0.0087,  0.0116]],

         [[-0.0078, -0.0034, -0.0010],
          [-0.0036, -0.0040, -0.0101],
          [-0.0018, -0.0034, -0.0055]],

         [[-0.0031,  0.0022,  0.0064],
          [ 0.0004,  0.0020, -0.0020],
          [ 0.0052,  0.0060,  0.0063]]],


        [[[ 0.0248,  0.0062,  0.0152],
          [ 0.0335,  0.0170,  0.0209],
          [ 0.0275,  0.0170,  0.0162]],

         [[ 0.0461,  0.0486,  0.0728],
          [ 0.0634,  0.0661,  0.0836],
          [ 0.0557,  0.0653,  0.0794]],

         [[ 0.0632,  0.0652,  0.0816],
          [ 0.0809,  0.0805,  0.0901],
          [ 0.0689,  0.0739,  0.0835]]],


        ...,


        [[[ 0.0393,  0.0250,  0.0250],
          [ 0.0351,  0.0219,  0.0235],
          [ 0.0367,  0.0208,  0.0193]],

         [[ 0.0208,  0.0051,  0.0023],
          [ 0.0192,  0.0033,  0.0006],
          [ 0.0218,  0.0033, -0.0015]],

         [[ 0.0111, -0.0023, -0.0044],
          [ 0.0057, -0.0089, -0.0104],
          [ 0.0071, -0.0098, -0.0139]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5932]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 87 | Batch_idx: 0 |  Loss: (0.3364) | Acc: (88.00%) (113/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2207) | Acc: (92.00%) (1302/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2380) | Acc: (91.00%) (2461/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2380) | Acc: (91.00%) (3631/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2381) | Acc: (91.00%) (4810/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2338) | Acc: (91.00%) (5998/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2284) | Acc: (92.00%) (7199/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2257) | Acc: (92.00%) (8383/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2232) | Acc: (92.00%) (9572/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2225) | Acc: (92.00%) (10767/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2190) | Acc: (92.00%) (11970/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2168) | Acc: (92.00%) (13169/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2157) | Acc: (92.00%) (14358/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2153) | Acc: (92.00%) (15544/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2146) | Acc: (92.00%) (16733/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2139) | Acc: (92.00%) (17920/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2144) | Acc: (92.00%) (19100/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2146) | Acc: (92.00%) (20280/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2132) | Acc: (92.00%) (21477/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2121) | Acc: (92.00%) (22665/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2118) | Acc: (92.00%) (23856/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2103) | Acc: (92.00%) (25064/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2100) | Acc: (92.00%) (26258/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2096) | Acc: (92.00%) (27446/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2094) | Acc: (92.00%) (28633/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2092) | Acc: (92.00%) (29815/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2087) | Acc: (92.00%) (31017/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2072) | Acc: (92.00%) (32224/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2063) | Acc: (92.00%) (33422/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2046) | Acc: (93.00%) (34642/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2033) | Acc: (93.00%) (35850/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2026) | Acc: (93.00%) (37049/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2022) | Acc: (93.00%) (38245/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2019) | Acc: (93.00%) (39442/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2011) | Acc: (93.00%) (40650/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2006) | Acc: (93.00%) (41849/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2005) | Acc: (93.00%) (43040/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2001) | Acc: (93.00%) (44239/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.1998) | Acc: (93.00%) (45437/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.1993) | Acc: (93.00%) (46597/50000)
# TEST : Loss: (0.3084) | Acc: (90.00%) (9028/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4144e-01,  2.8661e-01, -1.3390e-01],
          [-8.5439e-02,  2.5507e-02, -5.5193e-02],
          [ 5.5952e-02, -2.2319e-01,  2.8697e-01]],

         [[-1.3832e-01,  4.3316e-01,  9.8727e-02],
          [-3.0281e-02,  7.1429e-03, -1.6533e-01],
          [ 6.6055e-02, -3.7522e-01, -7.6146e-03]],

         [[-1.1314e-01,  2.7502e-01, -1.3594e-01],
          [ 7.2398e-02, -1.5881e-01, -1.1626e-01],
          [ 1.4202e-01, -1.2776e-01,  2.2158e-01]]],


        [[[-1.7530e-01, -3.5192e-01, -2.1297e-01],
          [-1.2310e-01,  2.1129e-01,  1.7011e-01],
          [ 1.9290e-01,  1.3176e-01,  2.2742e-01]],

         [[-2.5890e-01, -2.7887e-01, -1.9862e-01],
          [-1.5280e-01,  1.3674e-01,  2.0540e-01],
          [ 2.6350e-01,  7.3082e-02,  1.2045e-01]],

         [[-1.6138e-01,  8.2871e-03, -2.4012e-01],
          [ 4.6091e-02,  2.0871e-01, -8.4725e-02],
          [-4.8576e-03,  7.6598e-02,  4.3619e-02]]],


        [[[-1.1346e-01,  2.5205e-01,  1.0192e-01],
          [ 1.6642e-01,  1.8044e-01, -6.6595e-02],
          [-2.1599e-01, -2.5619e-02, -2.6854e-01]],

         [[ 5.1994e-02,  1.0786e-01,  2.5462e-02],
          [ 1.0135e-01,  2.6123e-01,  6.8506e-02],
          [-1.0434e-01, -7.2448e-02, -3.6638e-01]],

         [[-8.2600e-02,  1.1569e-01,  1.9209e-01],
          [ 5.1637e-02,  2.7012e-01,  9.0031e-02],
          [-2.3996e-01, -1.9340e-01, -2.6753e-01]]],


        ...,


        [[[-1.1441e-01, -1.4651e-01,  2.2971e-02],
          [ 9.4185e-02, -3.2507e-01, -1.5830e-01],
          [ 1.3047e-01, -1.0203e-01,  5.5726e-02]],

         [[ 1.4693e-01, -5.4308e-02, -3.7340e-03],
          [-5.8451e-02, -4.0869e-01, -2.5876e-01],
          [ 1.0091e-01, -4.4434e-02, -6.9156e-02]],

         [[ 2.0563e-01,  2.5058e-02,  1.1308e-01],
          [ 3.3104e-03, -2.1010e-01, -1.7647e-01],
          [ 6.3849e-02, -1.2581e-01, -1.0312e-01]]],


        [[[ 4.2781e-40,  3.5222e-41,  4.8768e-40],
          [ 3.3127e-41,  2.0222e-40,  2.8473e-40],
          [ 3.2306e-40,  7.3490e-41,  6.0393e-41]],

         [[-4.0231e-41,  1.3901e-40, -3.2524e-41],
          [-3.2074e-40,  5.2123e-40, -2.5145e-40],
          [ 2.5768e-40,  3.7930e-41,  3.8202e-40]],

         [[-4.2604e-40,  2.5572e-40,  2.1091e-41],
          [-1.7771e-40, -2.9331e-40, -4.3607e-41],
          [ 5.3149e-40, -4.1310e-41,  4.5695e-40]]],


        [[[ 9.0702e-41,  4.8207e-41, -5.0685e-41],
          [-8.7023e-41, -1.0944e-42,  6.0581e-41],
          [-1.0583e-40,  5.3174e-41, -3.2852e-41]],

         [[ 4.5472e-41, -8.5992e-41,  3.8141e-41],
          [ 5.0630e-41, -9.9442e-41,  6.5059e-41],
          [ 1.0179e-40,  2.8769e-41,  7.7667e-41]],

         [[-8.0240e-41, -7.2069e-41, -5.4958e-41],
          [-8.5073e-42,  6.0395e-41,  1.2253e-40],
          [-2.7171e-42,  1.3225e-41,  9.3280e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5787]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0151]], device='cuda:0')

Epoch: 88 | Batch_idx: 0 |  Loss: (0.1515) | Acc: (93.00%) (120/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.1962) | Acc: (93.00%) (1315/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2014) | Acc: (93.00%) (2504/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.1840) | Acc: (93.00%) (3719/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.1829) | Acc: (93.00%) (4921/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.1870) | Acc: (93.00%) (6105/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.1901) | Acc: (93.00%) (7294/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.1922) | Acc: (93.00%) (8477/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.1950) | Acc: (93.00%) (9669/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.1950) | Acc: (93.00%) (10869/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.1926) | Acc: (93.00%) (12072/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.1916) | Acc: (93.00%) (13276/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.1896) | Acc: (93.00%) (14483/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.1921) | Acc: (93.00%) (15665/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.1909) | Acc: (93.00%) (16875/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.1902) | Acc: (93.00%) (18073/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.1892) | Acc: (93.00%) (19285/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.1875) | Acc: (93.00%) (20494/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.1877) | Acc: (93.00%) (21692/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.1877) | Acc: (93.00%) (22897/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.1880) | Acc: (93.00%) (24093/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.1880) | Acc: (93.00%) (25291/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.1886) | Acc: (93.00%) (26482/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.1879) | Acc: (93.00%) (27682/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.1881) | Acc: (93.00%) (28880/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.1885) | Acc: (93.00%) (30061/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.1871) | Acc: (93.00%) (31276/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.1878) | Acc: (93.00%) (32469/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.1871) | Acc: (93.00%) (33675/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.1864) | Acc: (93.00%) (34886/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.1864) | Acc: (93.00%) (36083/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.1865) | Acc: (93.00%) (37287/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.1859) | Acc: (93.00%) (38489/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.1867) | Acc: (93.00%) (39681/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.1859) | Acc: (93.00%) (40897/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.1857) | Acc: (93.00%) (42091/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.1863) | Acc: (93.00%) (43274/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.1861) | Acc: (93.00%) (44477/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.1859) | Acc: (93.00%) (45677/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.1862) | Acc: (93.00%) (46826/50000)
# TEST : Loss: (0.2982) | Acc: (90.00%) (9032/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4112e-01,  2.8594e-01, -1.3359e-01],
          [-8.5244e-02,  2.5448e-02, -5.5068e-02],
          [ 5.5825e-02, -2.2265e-01,  2.8631e-01]],

         [[-1.3798e-01,  4.3208e-01,  9.8495e-02],
          [-3.0209e-02,  7.1255e-03, -1.6493e-01],
          [ 6.5896e-02, -3.7425e-01, -7.5963e-03]],

         [[-1.1285e-01,  2.7427e-01, -1.3560e-01],
          [ 7.2212e-02, -1.5840e-01, -1.1597e-01],
          [ 1.4166e-01, -1.2742e-01,  2.2102e-01]]],


        [[[-1.7494e-01, -3.5120e-01, -2.1252e-01],
          [-1.2286e-01,  2.1085e-01,  1.6975e-01],
          [ 1.9250e-01,  1.3148e-01,  2.2692e-01]],

         [[-2.5834e-01, -2.7826e-01, -1.9818e-01],
          [-1.5248e-01,  1.3645e-01,  2.0495e-01],
          [ 2.6293e-01,  7.2919e-02,  1.2017e-01]],

         [[-1.6100e-01,  8.2678e-03, -2.3955e-01],
          [ 4.5987e-02,  2.0823e-01, -8.4527e-02],
          [-4.8466e-03,  7.6420e-02,  4.3514e-02]]],


        [[[-1.1322e-01,  2.5150e-01,  1.0171e-01],
          [ 1.6608e-01,  1.8007e-01, -6.6459e-02],
          [-2.1555e-01, -2.5566e-02, -2.6798e-01]],

         [[ 5.1883e-02,  1.0763e-01,  2.5408e-02],
          [ 1.0114e-01,  2.6069e-01,  6.8366e-02],
          [-1.0412e-01, -7.2298e-02, -3.6561e-01]],

         [[-8.2417e-02,  1.1543e-01,  1.9166e-01],
          [ 5.1525e-02,  2.6954e-01,  8.9835e-02],
          [-2.3944e-01, -1.9298e-01, -2.6693e-01]]],


        ...,


        [[[-1.1381e-01, -1.4550e-01,  2.2818e-02],
          [ 9.3595e-02, -3.2150e-01, -1.5669e-01],
          [ 1.2974e-01, -1.0121e-01,  5.5285e-02]],

         [[ 1.4612e-01, -5.3899e-02, -3.7061e-03],
          [-5.8063e-02, -4.0305e-01, -2.5516e-01],
          [ 1.0033e-01, -4.4046e-02, -6.8521e-02]],

         [[ 2.0454e-01,  2.4893e-02,  1.1234e-01],
          [ 3.2900e-03, -2.0826e-01, -1.7489e-01],
          [ 6.3488e-02, -1.2487e-01, -1.0233e-01]]],


        [[[ 4.4933e-40,  2.5381e-40,  2.9335e-40],
          [ 2.5808e-40, -1.4758e-41,  2.9742e-40],
          [-2.3501e-40, -1.5529e-40, -3.9755e-40]],

         [[ 1.7406e-40,  1.4393e-40,  7.8155e-41],
          [-2.2077e-40,  8.2542e-41, -1.4698e-40],
          [ 2.6793e-40, -7.9826e-41,  5.1252e-40]],

         [[-1.1916e-40, -3.9210e-40, -1.9879e-40],
          [ 3.7821e-40, -3.0561e-40, -2.7266e-40],
          [ 3.2365e-40, -2.7509e-40,  1.2823e-40]]],


        [[[ 9.9101e-41, -3.8393e-41, -5.5440e-41],
          [-2.3409e-41, -1.6517e-41, -1.0751e-40],
          [-6.9077e-41,  6.4090e-41, -1.5585e-41]],

         [[-3.9075e-41, -1.1766e-40, -2.8053e-41],
          [-9.0573e-41, -1.1993e-40, -8.2196e-41],
          [ 1.2293e-40,  9.1784e-41, -2.5725e-41]],

         [[ 1.0725e-40, -1.0827e-40,  1.1136e-40],
          [ 4.1654e-41,  1.0602e-40,  9.5979e-41],
          [-9.3142e-41, -4.2168e-41, -8.2343e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6270]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0453]], device='cuda:0')

Epoch: 89 | Batch_idx: 0 |  Loss: (0.1345) | Acc: (93.00%) (120/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.1745) | Acc: (94.00%) (1324/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2023) | Acc: (93.00%) (2503/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.1931) | Acc: (93.00%) (3706/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.1909) | Acc: (93.00%) (4902/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.1849) | Acc: (93.00%) (6112/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.1844) | Acc: (93.00%) (7308/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.1835) | Acc: (93.00%) (8511/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.1805) | Acc: (93.00%) (9721/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.1805) | Acc: (93.00%) (10918/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.1795) | Acc: (93.00%) (12126/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.1811) | Acc: (93.00%) (13319/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.1801) | Acc: (93.00%) (14525/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.1793) | Acc: (93.00%) (15731/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.1777) | Acc: (93.00%) (16943/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.1799) | Acc: (93.00%) (18131/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.1787) | Acc: (93.00%) (19343/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.1791) | Acc: (93.00%) (20540/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.1801) | Acc: (93.00%) (21737/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.1801) | Acc: (93.00%) (22946/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.1794) | Acc: (93.00%) (24161/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.1787) | Acc: (93.00%) (25371/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.1788) | Acc: (93.00%) (26575/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.1786) | Acc: (93.00%) (27781/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.1794) | Acc: (93.00%) (28968/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.1788) | Acc: (93.00%) (30181/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.1782) | Acc: (93.00%) (31397/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.1776) | Acc: (93.00%) (32606/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.1784) | Acc: (93.00%) (33801/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.1786) | Acc: (93.00%) (35009/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.1781) | Acc: (94.00%) (36219/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.1788) | Acc: (94.00%) (37422/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.1800) | Acc: (93.00%) (38612/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.1794) | Acc: (93.00%) (39822/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.1794) | Acc: (94.00%) (41034/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.1790) | Acc: (94.00%) (42242/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.1802) | Acc: (93.00%) (43429/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.1804) | Acc: (93.00%) (44636/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.1811) | Acc: (93.00%) (45816/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.1807) | Acc: (93.00%) (46974/50000)
# TEST : Loss: (0.2932) | Acc: (90.00%) (9055/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4072e-01,  2.8511e-01, -1.3322e-01],
          [-8.5007e-02,  2.5377e-02, -5.4916e-02],
          [ 5.5670e-02, -2.2200e-01,  2.8552e-01]],

         [[-1.3757e-01,  4.3076e-01,  9.8213e-02],
          [-3.0120e-02,  7.1045e-03, -1.6446e-01],
          [ 6.5702e-02, -3.7308e-01, -7.5742e-03]],

         [[-1.1248e-01,  2.7337e-01, -1.3518e-01],
          [ 7.1987e-02, -1.5789e-01, -1.1560e-01],
          [ 1.4122e-01, -1.2700e-01,  2.2033e-01]]],


        [[[-1.7451e-01, -3.5033e-01, -2.1199e-01],
          [-1.2256e-01,  2.1033e-01,  1.6932e-01],
          [ 1.9201e-01,  1.3113e-01,  2.2631e-01]],

         [[-2.5766e-01, -2.7752e-01, -1.9765e-01],
          [-1.5208e-01,  1.3609e-01,  2.0440e-01],
          [ 2.6223e-01,  7.2721e-02,  1.1983e-01]],

         [[-1.6055e-01,  8.2444e-03, -2.3887e-01],
          [ 4.5860e-02,  2.0765e-01, -8.4287e-02],
          [-4.8331e-03,  7.6205e-02,  4.3388e-02]]],


        [[[-1.1292e-01,  2.5084e-01,  1.0144e-01],
          [ 1.6567e-01,  1.7962e-01, -6.6293e-02],
          [-2.1502e-01, -2.5503e-02, -2.6731e-01]],

         [[ 5.1748e-02,  1.0735e-01,  2.5343e-02],
          [ 1.0089e-01,  2.6004e-01,  6.8196e-02],
          [-1.0386e-01, -7.2117e-02, -3.6468e-01]],

         [[-8.2195e-02,  1.1512e-01,  1.9115e-01],
          [ 5.1390e-02,  2.6882e-01,  8.9597e-02],
          [-2.3881e-01, -1.9246e-01, -2.6621e-01]]],


        ...,


        [[[-1.1308e-01, -1.4427e-01,  2.2634e-02],
          [ 9.2882e-02, -3.1721e-01, -1.5476e-01],
          [ 1.2886e-01, -1.0022e-01,  5.4753e-02]],

         [[ 1.4514e-01, -5.3405e-02, -3.6726e-03],
          [-5.7595e-02, -3.9631e-01, -2.5084e-01],
          [ 9.9634e-02, -4.3578e-02, -6.7757e-02]],

         [[ 2.0321e-01,  2.4695e-02,  1.1144e-01],
          [ 3.2655e-03, -2.0604e-01, -1.7299e-01],
          [ 6.3053e-02, -1.2374e-01, -1.0137e-01]]],


        [[[ 1.3319e-40,  2.6493e-40,  7.8233e-41],
          [ 2.6832e-40,  2.1910e-40, -1.5818e-40],
          [ 1.1046e-40, -2.7959e-40,  1.8376e-40]],

         [[ 2.9405e-40,  3.4469e-41,  8.2433e-41],
          [-3.4501e-40,  4.4071e-40,  8.4634e-41],
          [ 3.8307e-41, -8.3244e-41,  1.6693e-40]],

         [[ 3.3029e-40, -1.7918e-40,  2.5473e-40],
          [-3.0819e-40, -5.5139e-40, -2.8230e-40],
          [-3.7612e-40, -2.8400e-40, -4.6300e-40]]],


        [[[ 9.4272e-41, -8.5219e-41,  6.3176e-41],
          [-1.6143e-42, -8.8282e-41,  1.0728e-40],
          [-5.5242e-41,  9.8422e-41, -4.7863e-41]],

         [[-4.0058e-41, -6.5952e-41,  1.0460e-40],
          [-8.5006e-41,  3.3156e-41,  3.8794e-41],
          [-3.5286e-41,  6.8033e-41, -1.1648e-40]],

         [[ 1.2161e-40,  1.7389e-41,  9.2952e-41],
          [-5.9837e-41, -1.1536e-40,  5.2951e-41],
          [ 8.0758e-41,  4.2155e-41,  1.0011e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6076]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0027]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.2322) | Acc: (91.00%) (117/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2132) | Acc: (92.00%) (1307/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2194) | Acc: (92.00%) (2484/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2392) | Acc: (91.00%) (3638/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2498) | Acc: (91.00%) (4799/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2632) | Acc: (90.00%) (5940/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2759) | Acc: (90.00%) (7073/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2858) | Acc: (90.00%) (8204/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2867) | Acc: (90.00%) (9347/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2900) | Acc: (90.00%) (10489/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2923) | Acc: (90.00%) (11637/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2968) | Acc: (89.00%) (12759/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2945) | Acc: (89.00%) (13920/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2961) | Acc: (89.00%) (15065/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2983) | Acc: (89.00%) (16203/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2979) | Acc: (89.00%) (17340/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2974) | Acc: (89.00%) (18494/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2989) | Acc: (89.00%) (19627/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.3010) | Acc: (89.00%) (20771/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.3012) | Acc: (89.00%) (21911/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.3015) | Acc: (89.00%) (23046/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.3005) | Acc: (89.00%) (24210/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2993) | Acc: (89.00%) (25361/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2980) | Acc: (89.00%) (26514/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2978) | Acc: (89.00%) (27668/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2970) | Acc: (89.00%) (28829/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2964) | Acc: (89.00%) (29988/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2944) | Acc: (89.00%) (31169/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2942) | Acc: (89.00%) (32315/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2931) | Acc: (89.00%) (33485/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2929) | Acc: (89.00%) (34643/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2914) | Acc: (89.00%) (35821/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2916) | Acc: (89.00%) (36967/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2910) | Acc: (89.00%) (38130/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2904) | Acc: (89.00%) (39283/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2890) | Acc: (90.00%) (40455/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2881) | Acc: (90.00%) (41629/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2869) | Acc: (90.00%) (42801/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2854) | Acc: (90.00%) (43983/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2847) | Acc: (90.00%) (45097/50000)
# TEST : Loss: (0.3868) | Acc: (87.00%) (8766/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3733e-01,  2.9535e-01, -1.3335e-01],
          [-7.2096e-02,  3.0582e-02, -6.6465e-02],
          [ 6.0213e-02, -2.1368e-01,  2.9228e-01]],

         [[-1.3679e-01,  4.4385e-01,  1.0558e-01],
          [-1.9713e-02,  9.2343e-03, -1.7607e-01],
          [ 6.5851e-02, -3.7032e-01, -5.2316e-03]],

         [[-1.1480e-01,  2.7442e-01, -1.3918e-01],
          [ 7.8688e-02, -1.6236e-01, -1.3360e-01],
          [ 1.3770e-01, -1.2682e-01,  2.2022e-01]]],


        [[[-1.7053e-01, -3.5022e-01, -2.1268e-01],
          [-1.1735e-01,  2.1585e-01,  1.7466e-01],
          [ 1.9636e-01,  1.4072e-01,  2.3792e-01]],

         [[-2.4977e-01, -2.7399e-01, -1.9722e-01],
          [-1.4611e-01,  1.4370e-01,  2.1169e-01],
          [ 2.6840e-01,  8.6541e-02,  1.3679e-01]],

         [[-1.5553e-01,  6.2248e-03, -2.4274e-01],
          [ 5.4845e-02,  2.1552e-01, -7.7813e-02],
          [ 6.5976e-03,  8.9988e-02,  5.7831e-02]]],


        [[[-1.2532e-01,  2.5007e-01,  9.1804e-02],
          [ 1.6045e-01,  1.8401e-01, -7.2251e-02],
          [-2.1711e-01, -2.5519e-02, -2.7310e-01]],

         [[ 4.2459e-02,  1.1181e-01,  2.5172e-02],
          [ 9.6219e-02,  2.6597e-01,  6.6763e-02],
          [-1.0734e-01, -7.1909e-02, -3.6744e-01]],

         [[-9.0846e-02,  1.2230e-01,  1.9311e-01],
          [ 4.6861e-02,  2.7395e-01,  8.8408e-02],
          [-2.4198e-01, -1.9350e-01, -2.7002e-01]]],


        ...,


        [[[-9.3550e-02, -1.3011e-01,  1.9170e-02],
          [ 1.0538e-01, -3.0390e-01, -1.6166e-01],
          [ 1.4127e-01, -8.1630e-02,  5.7900e-02]],

         [[ 1.5831e-01, -4.4466e-02, -1.2301e-02],
          [-5.4125e-02, -3.9687e-01, -2.7377e-01],
          [ 1.0023e-01, -3.9676e-02, -7.1127e-02]],

         [[ 2.1618e-01,  3.5370e-02,  1.0916e-01],
          [ 5.2764e-03, -2.0788e-01, -1.8542e-01],
          [ 5.8768e-02, -1.2878e-01, -1.1160e-01]]],


        [[[-9.4022e-41,  4.1172e-41, -3.8987e-40],
          [ 3.8604e-41,  2.2617e-40, -5.2360e-40],
          [-2.5032e-40,  2.0427e-40,  1.8944e-40]],

         [[ 1.8764e-40, -8.3338e-41, -3.2544e-41],
          [-1.1458e-40,  4.5270e-40,  2.0964e-40],
          [ 2.8418e-40,  3.7979e-41, -3.2270e-40]],

         [[ 5.7679e-40, -1.8582e-40,  2.6223e-40],
          [-7.6952e-41, -3.2478e-40, -4.8754e-41],
          [ 9.9370e-41, -4.6070e-41, -2.3053e-40]]],


        [[[ 9.0731e-41,  3.7873e-41,  6.6295e-42],
          [ 1.3969e-40, -2.6414e-42,  4.2246e-41],
          [-3.2207e-41, -9.5343e-41, -1.1523e-40]],

         [[ 8.8038e-41,  1.1163e-40,  6.5050e-41],
          [-1.0051e-40, -1.2492e-40, -1.8881e-41],
          [-1.2151e-41,  1.0209e-40,  3.1075e-41]],

         [[-2.4591e-41,  1.0341e-40, -9.4192e-41],
          [-3.4053e-41, -8.0224e-42, -2.1197e-41],
          [-3.2196e-41,  9.8890e-41, -1.1950e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0200,  0.0117, -0.0026],
          [ 0.0251,  0.0081,  0.0013],
          [-0.0060, -0.0090, -0.0084]],

         [[ 0.0236,  0.0119,  0.0045],
          [ 0.0262,  0.0096,  0.0083],
          [-0.0007,  0.0026,  0.0040]],

         [[ 0.0332,  0.0310,  0.0158],
          [ 0.0268,  0.0185,  0.0160],
          [ 0.0001,  0.0035,  0.0130]]],


        [[[-0.0540, -0.0504, -0.0462],
          [-0.0532, -0.0579, -0.0492],
          [-0.0565, -0.0580, -0.0434]],

         [[-0.0731, -0.0729, -0.0695],
          [-0.0681, -0.0789, -0.0707],
          [-0.0683, -0.0763, -0.0619]],

         [[-0.0776, -0.0804, -0.0782],
          [-0.0649, -0.0790, -0.0753],
          [-0.0610, -0.0738, -0.0647]]],


        [[[ 0.0114, -0.0033, -0.0112],
          [ 0.0035, -0.0166, -0.0260],
          [ 0.0021, -0.0148, -0.0164]],

         [[ 0.0157,  0.0033, -0.0039],
          [ 0.0078, -0.0097, -0.0177],
          [ 0.0062, -0.0081, -0.0108]],

         [[ 0.0217,  0.0080, -0.0011],
          [ 0.0127, -0.0047, -0.0162],
          [ 0.0092, -0.0046, -0.0088]]],


        ...,


        [[[-0.0019, -0.0062, -0.0119],
          [ 0.0078,  0.0070,  0.0012],
          [ 0.0023,  0.0009, -0.0040]],

         [[-0.0106, -0.0130, -0.0158],
          [-0.0017, -0.0006, -0.0037],
          [-0.0057, -0.0059, -0.0089]],

         [[-0.0157, -0.0182, -0.0200],
          [-0.0092, -0.0085, -0.0094],
          [-0.0149, -0.0143, -0.0158]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6075]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 91 | Batch_idx: 0 |  Loss: (0.2652) | Acc: (90.00%) (116/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2249) | Acc: (92.00%) (1296/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2240) | Acc: (92.00%) (2487/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2286) | Acc: (92.00%) (3661/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2259) | Acc: (92.00%) (4838/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2363) | Acc: (91.00%) (6000/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2351) | Acc: (92.00%) (7188/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2347) | Acc: (92.00%) (8369/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2347) | Acc: (92.00%) (9544/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2341) | Acc: (92.00%) (10727/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2330) | Acc: (92.00%) (11910/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2331) | Acc: (92.00%) (13092/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2344) | Acc: (92.00%) (14268/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2325) | Acc: (92.00%) (15454/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2352) | Acc: (92.00%) (16616/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2360) | Acc: (91.00%) (17775/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2351) | Acc: (91.00%) (18957/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2346) | Acc: (91.00%) (20134/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2360) | Acc: (91.00%) (21297/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2343) | Acc: (91.00%) (22492/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2335) | Acc: (92.00%) (23678/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2331) | Acc: (92.00%) (24862/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2331) | Acc: (92.00%) (26039/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2339) | Acc: (92.00%) (27214/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2334) | Acc: (92.00%) (28397/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2344) | Acc: (92.00%) (29563/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2337) | Acc: (92.00%) (30747/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2355) | Acc: (91.00%) (31901/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2363) | Acc: (91.00%) (33072/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2369) | Acc: (91.00%) (34246/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2371) | Acc: (91.00%) (35427/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2382) | Acc: (91.00%) (36588/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2376) | Acc: (91.00%) (37765/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2379) | Acc: (91.00%) (38940/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2383) | Acc: (91.00%) (40104/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2374) | Acc: (91.00%) (41285/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2373) | Acc: (91.00%) (42460/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2378) | Acc: (91.00%) (43623/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2375) | Acc: (91.00%) (44811/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2368) | Acc: (91.00%) (45952/50000)
# TEST : Loss: (0.3686) | Acc: (88.00%) (8884/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3156e-01,  3.0075e-01, -1.4182e-01],
          [-6.6762e-02,  3.1219e-02, -6.7117e-02],
          [ 6.5710e-02, -2.1784e-01,  2.9123e-01]],

         [[-1.3496e-01,  4.4600e-01,  9.8326e-02],
          [-1.8195e-02,  6.2016e-03, -1.7604e-01],
          [ 7.0944e-02, -3.7601e-01, -1.1378e-02]],

         [[-1.0766e-01,  2.7875e-01, -1.3775e-01],
          [ 8.7177e-02, -1.5698e-01, -1.2728e-01],
          [ 1.4821e-01, -1.2256e-01,  2.2015e-01]]],


        [[[-1.7044e-01, -3.4885e-01, -2.0219e-01],
          [-1.0805e-01,  2.2513e-01,  1.8661e-01],
          [ 2.0382e-01,  1.4644e-01,  2.4071e-01]],

         [[-2.5628e-01, -2.8015e-01, -1.9443e-01],
          [-1.4321e-01,  1.4706e-01,  2.1858e-01],
          [ 2.6950e-01,  8.6707e-02,  1.3534e-01]],

         [[-1.6065e-01, -2.2883e-04, -2.3979e-01],
          [ 5.5372e-02,  2.1604e-01, -7.2428e-02],
          [ 8.6063e-03,  9.0133e-02,  5.6494e-02]]],


        [[[-1.2059e-01,  2.4888e-01,  8.8697e-02],
          [ 1.6503e-01,  1.8435e-01, -7.2095e-02],
          [-2.1792e-01, -3.1012e-02, -2.7916e-01]],

         [[ 4.4815e-02,  1.1101e-01,  2.3267e-02],
          [ 9.5750e-02,  2.6304e-01,  6.4577e-02],
          [-1.1414e-01, -8.0730e-02, -3.7489e-01]],

         [[-8.1859e-02,  1.2783e-01,  1.9730e-01],
          [ 5.2200e-02,  2.7738e-01,  9.3576e-02],
          [-2.4017e-01, -1.9315e-01, -2.6764e-01]]],


        ...,


        [[[-9.7433e-02, -1.3743e-01,  8.3749e-03],
          [ 1.0773e-01, -3.0456e-01, -1.6658e-01],
          [ 1.4266e-01, -7.6028e-02,  6.1502e-02]],

         [[ 1.4675e-01, -6.2789e-02, -3.4265e-02],
          [-5.6592e-02, -4.1224e-01, -2.9874e-01],
          [ 9.8227e-02, -4.1508e-02, -7.6412e-02]],

         [[ 2.1422e-01,  3.1872e-02,  1.0354e-01],
          [ 1.5665e-02, -2.0140e-01, -1.8675e-01],
          [ 6.6319e-02, -1.2145e-01, -1.0677e-01]]],


        [[[-4.5525e-40, -1.9804e-40, -5.2262e-40],
          [-2.0577e-40, -1.4803e-41, -4.1399e-40],
          [-3.8056e-40,  8.4280e-41,  6.9387e-41]],

         [[-4.7554e-41, -8.6753e-41, -1.5460e-40],
          [ 2.5309e-40,  8.8617e-41,  9.0887e-41],
          [ 2.8975e-40,  1.6472e-40, -5.8192e-40]],

         [[ 4.7234e-40, -7.0007e-41,  2.4266e-41],
          [ 4.1478e-40,  1.6419e-40,  1.9795e-40],
          [-3.9691e-40,  2.0418e-40,  5.1568e-40]]],


        [[[-7.4473e-41,  7.4351e-41,  8.0926e-41],
          [-6.9678e-41,  1.0485e-40, -1.5802e-40],
          [-1.4084e-40,  1.2171e-40, -6.7657e-41]],

         [[ 2.9562e-41,  1.3379e-40, -1.1800e-40],
          [-1.1204e-40, -9.2193e-41, -2.2489e-41],
          [-1.5437e-41, -1.2476e-40, -1.2612e-40]],

         [[ 1.7377e-40, -1.2548e-40, -2.7081e-41],
          [-1.7523e-41,  1.5002e-40, -2.5804e-41],
          [ 6.0444e-41,  6.0483e-41, -2.9614e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0158,  0.0008,  0.0068],
          [ 0.0005,  0.0090,  0.0120],
          [-0.0114,  0.0024,  0.0108]],

         [[-0.0187, -0.0010,  0.0127],
          [ 0.0021,  0.0064,  0.0150],
          [-0.0087,  0.0010,  0.0114]],

         [[-0.0150,  0.0046,  0.0175],
          [-0.0006,  0.0083,  0.0200],
          [-0.0132,  0.0018,  0.0150]]],


        [[[ 0.0251,  0.0240,  0.0291],
          [ 0.0245,  0.0279,  0.0243],
          [ 0.0243,  0.0265,  0.0186]],

         [[ 0.0060,  0.0057,  0.0158],
          [ 0.0016,  0.0082,  0.0116],
          [ 0.0033,  0.0085,  0.0071]],

         [[ 0.0074,  0.0081,  0.0154],
          [ 0.0002,  0.0083,  0.0104],
          [-0.0010,  0.0075,  0.0078]]],


        [[[-0.0057,  0.0036,  0.0071],
          [ 0.0235,  0.0302,  0.0275],
          [ 0.0262,  0.0304,  0.0190]],

         [[ 0.0138,  0.0210,  0.0232],
          [ 0.0417,  0.0447,  0.0403],
          [ 0.0437,  0.0444,  0.0303]],

         [[ 0.0120,  0.0166,  0.0210],
          [ 0.0338,  0.0352,  0.0336],
          [ 0.0309,  0.0319,  0.0231]]],


        ...,


        [[[-0.0014,  0.0084,  0.0053],
          [-0.0083, -0.0001, -0.0062],
          [ 0.0053,  0.0096, -0.0000]],

         [[ 0.0009,  0.0099,  0.0054],
          [-0.0055,  0.0023, -0.0046],
          [ 0.0055,  0.0102,  0.0016]],

         [[-0.0006,  0.0071,  0.0041],
          [-0.0059,  0.0009, -0.0050],
          [ 0.0030,  0.0067, -0.0010]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6061]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 92 | Batch_idx: 0 |  Loss: (0.1292) | Acc: (96.00%) (123/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.1776) | Acc: (94.00%) (1327/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.1831) | Acc: (94.00%) (2528/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.1996) | Acc: (93.00%) (3709/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2025) | Acc: (93.00%) (4902/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2014) | Acc: (93.00%) (6087/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2060) | Acc: (93.00%) (7263/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2026) | Acc: (93.00%) (8463/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2056) | Acc: (92.00%) (9637/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2025) | Acc: (93.00%) (10842/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2019) | Acc: (93.00%) (12034/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2030) | Acc: (93.00%) (13216/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2084) | Acc: (92.00%) (14385/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2080) | Acc: (92.00%) (15577/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2080) | Acc: (92.00%) (16766/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2078) | Acc: (92.00%) (17958/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2078) | Acc: (92.00%) (19150/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2074) | Acc: (92.00%) (20334/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2089) | Acc: (92.00%) (21510/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2095) | Acc: (92.00%) (22687/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2101) | Acc: (92.00%) (23871/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2088) | Acc: (92.00%) (25082/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2099) | Acc: (92.00%) (26258/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2103) | Acc: (92.00%) (27438/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2106) | Acc: (92.00%) (28621/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2099) | Acc: (92.00%) (29813/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2101) | Acc: (92.00%) (30991/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2099) | Acc: (92.00%) (32191/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2102) | Acc: (92.00%) (33372/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2108) | Acc: (92.00%) (34547/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2100) | Acc: (92.00%) (35739/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2100) | Acc: (92.00%) (36924/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2102) | Acc: (92.00%) (38117/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2102) | Acc: (92.00%) (39301/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2103) | Acc: (92.00%) (40488/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2098) | Acc: (92.00%) (41680/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2102) | Acc: (92.00%) (42871/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2103) | Acc: (92.00%) (44049/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2098) | Acc: (92.00%) (45250/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2103) | Acc: (92.00%) (46391/50000)
# TEST : Loss: (0.3307) | Acc: (89.00%) (8971/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2453e-01,  3.0621e-01, -1.4176e-01],
          [-7.1034e-02,  2.5893e-02, -8.0008e-02],
          [ 6.4775e-02, -2.1981e-01,  2.8248e-01]],

         [[-1.2242e-01,  4.5604e-01,  1.0415e-01],
          [-1.7561e-02,  4.9588e-03, -1.8488e-01],
          [ 7.4856e-02, -3.7344e-01, -1.7140e-02]],

         [[-1.0098e-01,  2.8035e-01, -1.3296e-01],
          [ 8.3955e-02, -1.6189e-01, -1.3591e-01],
          [ 1.4890e-01, -1.2165e-01,  2.1630e-01]]],


        [[[-1.7739e-01, -3.5231e-01, -2.0319e-01],
          [-1.1119e-01,  2.2247e-01,  1.8559e-01],
          [ 1.9839e-01,  1.4586e-01,  2.4243e-01]],

         [[-2.6695e-01, -2.8580e-01, -1.9653e-01],
          [-1.4912e-01,  1.4344e-01,  2.1789e-01],
          [ 2.6340e-01,  8.6772e-02,  1.3934e-01]],

         [[-1.6625e-01, -7.5685e-04, -2.3673e-01],
          [ 5.6536e-02,  2.1744e-01, -6.9342e-02],
          [ 8.9563e-03,  9.2156e-02,  6.1315e-02]]],


        [[[-1.2412e-01,  2.5216e-01,  8.5541e-02],
          [ 1.6131e-01,  1.8981e-01, -7.1075e-02],
          [-2.2087e-01, -2.5802e-02, -2.7553e-01]],

         [[ 4.3694e-02,  1.1502e-01,  2.0094e-02],
          [ 9.1262e-02,  2.6631e-01,  6.2883e-02],
          [-1.2057e-01, -7.9635e-02, -3.7663e-01]],

         [[-8.6525e-02,  1.2846e-01,  1.9245e-01],
          [ 4.0865e-02,  2.7409e-01,  8.9797e-02],
          [-2.5128e-01, -1.9605e-01, -2.7090e-01]]],


        ...,


        [[[-1.0075e-01, -1.3669e-01,  8.9561e-03],
          [ 9.8812e-02, -3.2246e-01, -1.7580e-01],
          [ 1.4467e-01, -7.5448e-02,  6.4695e-02]],

         [[ 1.5382e-01, -4.9414e-02, -1.8913e-02],
          [-5.2649e-02, -4.0905e-01, -2.8054e-01],
          [ 1.0848e-01, -2.4414e-02, -5.2422e-02]],

         [[ 2.2133e-01,  4.2174e-02,  1.1481e-01],
          [ 1.6942e-02, -2.0381e-01, -1.8021e-01],
          [ 7.2413e-02, -1.1284e-01, -9.3705e-02]]],


        [[[-2.2107e-40, -3.2637e-40, -1.6349e-40],
          [ 3.9414e-41, -2.6722e-40,  8.0789e-41],
          [-1.3438e-40, -1.6914e-40, -1.8367e-40]],

         [[-2.9586e-40,  3.4475e-41, -1.5745e-40],
          [ 3.8459e-40,  9.0273e-41, -1.6075e-40],
          [ 3.9054e-41,  1.6691e-40, -3.3557e-40]],

         [[-1.3650e-40,  1.7697e-40, -2.2591e-40],
          [-8.0701e-41,  5.4799e-40,  3.2862e-40],
          [-1.5056e-40,  2.0887e-40,  3.9767e-40]]],


        [[[ 1.1968e-40, -1.0339e-40,  8.4500e-41],
          [ 1.0964e-40, -6.7943e-41,  5.9498e-41],
          [ 1.1519e-42, -5.3147e-41,  1.4712e-40]],

         [[-1.6839e-41, -1.1349e-40, -5.6025e-41],
          [ 1.5114e-40,  1.5290e-40, -9.1351e-41],
          [-1.0291e-40, -1.4714e-40, -3.4906e-42]],

         [[ 7.1190e-41, -1.4276e-41, -3.2376e-41],
          [-7.6144e-41,  4.6398e-41,  9.1177e-41],
          [ 9.9216e-41, -4.8461e-41, -1.1148e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0355,  0.0199,  0.0096],
          [ 0.0350,  0.0122,  0.0022],
          [ 0.0227,  0.0042, -0.0147]],

         [[ 0.0474,  0.0323,  0.0221],
          [ 0.0440,  0.0239,  0.0119],
          [ 0.0353,  0.0210, -0.0040]],

         [[ 0.0526,  0.0379,  0.0254],
          [ 0.0531,  0.0305,  0.0154],
          [ 0.0410,  0.0243, -0.0009]]],


        [[[-0.0018,  0.0047,  0.0035],
          [-0.0092, -0.0003,  0.0032],
          [-0.0035, -0.0050,  0.0006]],

         [[-0.0121, -0.0054, -0.0039],
          [-0.0163, -0.0074, -0.0014],
          [-0.0093, -0.0102, -0.0025]],

         [[-0.0122, -0.0046, -0.0011],
          [-0.0177, -0.0080,  0.0010],
          [-0.0073, -0.0066,  0.0012]]],


        [[[ 0.0554,  0.0664,  0.0805],
          [ 0.0601,  0.0604,  0.0724],
          [ 0.0630,  0.0555,  0.0604]],

         [[ 0.0629,  0.0747,  0.0846],
          [ 0.0646,  0.0681,  0.0771],
          [ 0.0692,  0.0652,  0.0687]],

         [[ 0.0665,  0.0740,  0.0809],
          [ 0.0713,  0.0692,  0.0743],
          [ 0.0737,  0.0691,  0.0718]]],


        ...,


        [[[ 0.0016, -0.0014, -0.0001],
          [-0.0041, -0.0040, -0.0017],
          [ 0.0001,  0.0090,  0.0162]],

         [[-0.0001, -0.0034, -0.0035],
          [-0.0045, -0.0042, -0.0031],
          [ 0.0003,  0.0092,  0.0151]],

         [[-0.0006, -0.0035, -0.0029],
          [-0.0014, -0.0005,  0.0017],
          [ 0.0029,  0.0116,  0.0181]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6043]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 93 | Batch_idx: 0 |  Loss: (0.1168) | Acc: (96.00%) (124/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.1872) | Acc: (93.00%) (1314/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2200) | Acc: (91.00%) (2469/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2304) | Acc: (91.00%) (3630/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2364) | Acc: (91.00%) (4794/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2315) | Acc: (91.00%) (5965/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2314) | Acc: (91.00%) (7133/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2295) | Acc: (91.00%) (8316/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2282) | Acc: (91.00%) (9496/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2233) | Acc: (91.00%) (10699/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2228) | Acc: (91.00%) (11884/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2197) | Acc: (92.00%) (13084/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2174) | Acc: (92.00%) (14284/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2170) | Acc: (92.00%) (15477/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2140) | Acc: (92.00%) (16679/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2138) | Acc: (92.00%) (17866/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2131) | Acc: (92.00%) (19051/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2095) | Acc: (92.00%) (20267/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2097) | Acc: (92.00%) (21448/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2090) | Acc: (92.00%) (22631/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2080) | Acc: (92.00%) (23828/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2070) | Acc: (92.00%) (25026/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2050) | Acc: (92.00%) (26230/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2043) | Acc: (92.00%) (27417/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2024) | Acc: (92.00%) (28627/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2020) | Acc: (92.00%) (29828/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2015) | Acc: (92.00%) (31035/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2005) | Acc: (92.00%) (32243/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.1991) | Acc: (93.00%) (33453/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.1989) | Acc: (93.00%) (34656/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.1977) | Acc: (93.00%) (35864/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.1972) | Acc: (93.00%) (37066/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.1964) | Acc: (93.00%) (38265/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.1951) | Acc: (93.00%) (39484/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.1948) | Acc: (93.00%) (40687/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.1941) | Acc: (93.00%) (41900/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.1934) | Acc: (93.00%) (43102/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.1928) | Acc: (93.00%) (44306/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.1922) | Acc: (93.00%) (45510/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.1913) | Acc: (93.00%) (46673/50000)
# TEST : Loss: (0.3048) | Acc: (90.00%) (9063/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2654e-01,  3.0561e-01, -1.4111e-01],
          [-7.1330e-02,  2.7790e-02, -7.7945e-02],
          [ 6.4504e-02, -2.1796e-01,  2.8400e-01]],

         [[-1.2513e-01,  4.5476e-01,  1.0377e-01],
          [-1.8961e-02,  5.8868e-03, -1.8370e-01],
          [ 7.3561e-02, -3.7266e-01, -1.6106e-02]],

         [[-1.0437e-01,  2.7873e-01, -1.3332e-01],
          [ 8.1110e-02, -1.6149e-01, -1.3499e-01],
          [ 1.4640e-01, -1.2211e-01,  2.1663e-01]]],


        [[[-1.7343e-01, -3.4825e-01, -1.9986e-01],
          [-1.0755e-01,  2.2507e-01,  1.8811e-01],
          [ 2.0146e-01,  1.4915e-01,  2.4534e-01]],

         [[-2.6491e-01, -2.8404e-01, -1.9535e-01],
          [-1.4770e-01,  1.4391e-01,  2.1832e-01],
          [ 2.6408e-01,  8.7842e-02,  1.4026e-01]],

         [[-1.6671e-01, -1.9135e-03, -2.3769e-01],
          [ 5.5388e-02,  2.1555e-01, -7.0739e-02],
          [ 8.0683e-03,  9.1222e-02,  6.0329e-02]]],


        [[[-1.2531e-01,  2.4854e-01,  8.1070e-02],
          [ 1.5996e-01,  1.8766e-01, -7.3986e-02],
          [-2.2245e-01, -2.7342e-02, -2.7733e-01]],

         [[ 4.3116e-02,  1.1241e-01,  1.6651e-02],
          [ 9.0699e-02,  2.6458e-01,  6.0392e-02],
          [-1.2213e-01, -8.1084e-02, -3.7817e-01]],

         [[-8.6334e-02,  1.2666e-01,  1.8953e-01],
          [ 4.0895e-02,  2.7315e-01,  8.8251e-02],
          [-2.5198e-01, -1.9664e-01, -2.7200e-01]]],


        ...,


        [[[-9.6986e-02, -1.3409e-01,  9.8222e-03],
          [ 1.0279e-01, -3.1616e-01, -1.7299e-01],
          [ 1.4807e-01, -7.3352e-02,  6.3623e-02]],

         [[ 1.5596e-01, -4.7484e-02, -1.7303e-02],
          [-4.8259e-02, -4.0027e-01, -2.7503e-01],
          [ 1.1131e-01, -2.3279e-02, -5.2876e-02]],

         [[ 2.2226e-01,  4.2753e-02,  1.1528e-01],
          [ 1.9366e-02, -2.0162e-01, -1.7851e-01],
          [ 7.4812e-02, -1.1190e-01, -9.4393e-02]]],


        [[[-4.7723e-40,  2.9634e-40,  3.3959e-40],
          [ 2.9494e-40, -2.7174e-40,  4.6701e-40],
          [ 2.5063e-40, -3.0106e-40, -3.1586e-40]],

         [[-3.0235e-40,  1.6124e-40, -3.2531e-41],
          [ 1.3438e-40, -5.5507e-40, -2.9209e-40],
          [-2.2050e-40,  3.7963e-41,  1.8078e-40]],

         [[ 3.6743e-40,  3.0726e-40, -2.3075e-40],
          [ 3.0260e-40, -3.4512e-40, -5.1470e-41],
          [ 3.6432e-40, -4.7042e-41, -1.1494e-40]]],


        [[[ 1.4370e-40, -1.6170e-41, -1.8833e-41],
          [-1.4111e-40, -8.0973e-41, -1.1994e-40],
          [ 1.9017e-40, -2.0336e-40, -1.8489e-40]],

         [[-9.7442e-41,  1.8147e-42, -6.6145e-41],
          [-1.0877e-40,  3.3962e-41,  9.7598e-41],
          [-8.8622e-41, -6.9534e-41,  1.7031e-40]],

         [[ 8.7091e-41,  3.6423e-41,  8.5060e-41],
          [-2.5561e-41, -1.5649e-40,  1.0781e-40],
          [-1.0269e-40,  1.3660e-40,  1.1367e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5912]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0351]], device='cuda:0')

Epoch: 94 | Batch_idx: 0 |  Loss: (0.1352) | Acc: (95.00%) (122/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.1409) | Acc: (95.00%) (1348/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.1759) | Acc: (94.00%) (2541/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.1778) | Acc: (94.00%) (3740/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.1828) | Acc: (93.00%) (4930/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.1786) | Acc: (94.00%) (6150/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.1813) | Acc: (93.00%) (7339/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.1813) | Acc: (93.00%) (8541/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.1824) | Acc: (93.00%) (9741/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.1804) | Acc: (93.00%) (10944/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.1798) | Acc: (93.00%) (12147/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.1802) | Acc: (93.00%) (13338/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.1784) | Acc: (93.00%) (14549/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.1787) | Acc: (93.00%) (15751/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.1767) | Acc: (94.00%) (16970/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.1761) | Acc: (94.00%) (18172/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.1757) | Acc: (94.00%) (19380/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.1757) | Acc: (94.00%) (20582/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.1757) | Acc: (94.00%) (21783/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.1750) | Acc: (93.00%) (22980/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.1742) | Acc: (94.00%) (24191/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.1742) | Acc: (94.00%) (25398/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.1750) | Acc: (94.00%) (26606/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.1758) | Acc: (94.00%) (27807/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.1767) | Acc: (94.00%) (29000/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.1770) | Acc: (93.00%) (30200/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.1775) | Acc: (93.00%) (31402/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.1776) | Acc: (93.00%) (32601/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.1770) | Acc: (94.00%) (33815/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.1776) | Acc: (93.00%) (35004/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.1772) | Acc: (93.00%) (36209/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.1773) | Acc: (93.00%) (37412/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.1774) | Acc: (93.00%) (38613/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.1771) | Acc: (94.00%) (39830/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.1766) | Acc: (94.00%) (41039/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.1760) | Acc: (94.00%) (42251/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.1759) | Acc: (94.00%) (43458/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.1762) | Acc: (94.00%) (44659/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.1757) | Acc: (94.00%) (45870/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.1750) | Acc: (94.00%) (47041/50000)
# TEST : Loss: (0.2900) | Acc: (90.00%) (9091/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2626e-01,  3.0490e-01, -1.4079e-01],
          [-7.1174e-02,  2.7727e-02, -7.7767e-02],
          [ 6.4359e-02, -2.1744e-01,  2.8335e-01]],

         [[-1.2484e-01,  4.5368e-01,  1.0353e-01],
          [-1.8917e-02,  5.8731e-03, -1.8327e-01],
          [ 7.3389e-02, -3.7174e-01, -1.6068e-02]],

         [[-1.0411e-01,  2.7803e-01, -1.3300e-01],
          [ 8.0913e-02, -1.6109e-01, -1.3465e-01],
          [ 1.4604e-01, -1.2179e-01,  2.1609e-01]]],


        [[[-1.7306e-01, -3.4750e-01, -1.9942e-01],
          [-1.0732e-01,  2.2459e-01,  1.8770e-01],
          [ 2.0101e-01,  1.4881e-01,  2.4478e-01]],

         [[-2.6432e-01, -2.8341e-01, -1.9492e-01],
          [-1.4737e-01,  1.4359e-01,  2.1784e-01],
          [ 2.6348e-01,  8.7641e-02,  1.3994e-01]],

         [[-1.6632e-01, -1.9089e-03, -2.3712e-01],
          [ 5.5258e-02,  2.1504e-01, -7.0573e-02],
          [ 8.0491e-03,  9.1005e-02,  6.0184e-02]]],


        [[[-1.2504e-01,  2.4800e-01,  8.0895e-02],
          [ 1.5963e-01,  1.8727e-01, -7.3834e-02],
          [-2.2199e-01, -2.7286e-02, -2.7675e-01]],

         [[ 4.3022e-02,  1.1217e-01,  1.6615e-02],
          [ 9.0506e-02,  2.6402e-01,  6.0266e-02],
          [-1.2187e-01, -8.0914e-02, -3.7737e-01]],

         [[-8.6140e-02,  1.2637e-01,  1.8911e-01],
          [ 4.0804e-02,  2.7254e-01,  8.8055e-02],
          [-2.5141e-01, -1.9620e-01, -2.7138e-01]]],


        ...,


        [[[-9.6454e-02, -1.3315e-01,  9.7550e-03],
          [ 1.0213e-01, -3.1270e-01, -1.7115e-01],
          [ 1.4724e-01, -7.2777e-02,  6.3112e-02]],

         [[ 1.5506e-01, -4.7109e-02, -1.7171e-02],
          [-4.7914e-02, -3.9410e-01, -2.7101e-01],
          [ 1.1065e-01, -2.3072e-02, -5.2400e-02]],

         [[ 2.2098e-01,  4.2450e-02,  1.1447e-01],
          [ 1.9236e-02, -1.9967e-01, -1.7678e-01],
          [ 7.4373e-02, -1.1104e-01, -9.3647e-02]]],


        [[[-1.0245e-40,  4.4092e-41, -4.2770e-40],
          [ 2.9900e-40, -1.4787e-41,  8.3390e-41],
          [ 3.8517e-40, -1.7286e-40, -3.1958e-40]],

         [[-5.0311e-41,  1.6341e-40,  9.6943e-41],
          [-2.5496e-40,  4.8705e-40, -1.6468e-40],
          [-2.2395e-40, -9.4398e-41, -4.7702e-40]],

         [[ 5.0288e-40, -2.0482e-40,  2.4303e-41],
          [-8.4091e-41, -3.5033e-40, -3.1282e-40],
          [ 5.0080e-40, -3.1034e-40, -5.1097e-40]]],


        [[[-1.5796e-40, -6.4832e-41, -2.1437e-41],
          [ 1.1070e-41, -9.6051e-41,  8.7072e-41],
          [ 7.1845e-41, -1.0106e-41, -2.1863e-40]],

         [[ 1.0598e-40,  2.0465e-40,  1.7493e-40],
          [-1.2981e-40, -7.8470e-41,  9.2561e-41],
          [-8.4254e-41,  1.4313e-40,  1.7469e-40]],

         [[ 1.0225e-40,  4.0957e-41, -1.6302e-40],
          [-6.8110e-41,  2.3338e-40,  4.2186e-41],
          [-6.4464e-41, -6.6211e-41,  1.1624e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6140]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0662]], device='cuda:0')

Epoch: 95 | Batch_idx: 0 |  Loss: (0.1773) | Acc: (95.00%) (122/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.1635) | Acc: (94.00%) (1327/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.1671) | Acc: (94.00%) (2544/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.1637) | Acc: (94.00%) (3757/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.1667) | Acc: (94.00%) (4967/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.1712) | Acc: (94.00%) (6159/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.1724) | Acc: (94.00%) (7366/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.1710) | Acc: (94.00%) (8584/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.1717) | Acc: (94.00%) (9797/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.1722) | Acc: (94.00%) (11002/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.1709) | Acc: (94.00%) (12216/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.1689) | Acc: (94.00%) (13439/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.1683) | Acc: (94.00%) (14651/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.1679) | Acc: (94.00%) (15867/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.1680) | Acc: (94.00%) (17075/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.1688) | Acc: (94.00%) (18270/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.1687) | Acc: (94.00%) (19475/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.1679) | Acc: (94.00%) (20688/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.1670) | Acc: (94.00%) (21902/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.1668) | Acc: (94.00%) (23116/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.1662) | Acc: (94.00%) (24340/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.1674) | Acc: (94.00%) (25534/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.1672) | Acc: (94.00%) (26745/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.1665) | Acc: (94.00%) (27958/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.1670) | Acc: (94.00%) (29157/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.1667) | Acc: (94.00%) (30361/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.1670) | Acc: (94.00%) (31563/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.1679) | Acc: (94.00%) (32764/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.1684) | Acc: (94.00%) (33966/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.1681) | Acc: (94.00%) (35178/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.1691) | Acc: (94.00%) (36367/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.1692) | Acc: (94.00%) (37575/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.1692) | Acc: (94.00%) (38779/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.1691) | Acc: (94.00%) (39991/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.1685) | Acc: (94.00%) (41209/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.1686) | Acc: (94.00%) (42411/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.1691) | Acc: (94.00%) (43615/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.1683) | Acc: (94.00%) (44837/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.1688) | Acc: (94.00%) (46029/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.1684) | Acc: (94.00%) (47198/50000)
# TEST : Loss: (0.2863) | Acc: (91.00%) (9111/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2592e-01,  3.0405e-01, -1.4040e-01],
          [-7.0985e-02,  2.7651e-02, -7.7551e-02],
          [ 6.4183e-02, -2.1681e-01,  2.8256e-01]],

         [[-1.2449e-01,  4.5237e-01,  1.0324e-01],
          [-1.8865e-02,  5.8564e-03, -1.8275e-01],
          [ 7.3181e-02, -3.7063e-01, -1.6021e-02]],

         [[-1.0380e-01,  2.7718e-01, -1.3260e-01],
          [ 8.0674e-02, -1.6061e-01, -1.3424e-01],
          [ 1.4561e-01, -1.2141e-01,  2.1543e-01]]],


        [[[-1.7261e-01, -3.4659e-01, -1.9890e-01],
          [-1.0704e-01,  2.2400e-01,  1.8720e-01],
          [ 2.0047e-01,  1.4841e-01,  2.4410e-01]],

         [[-2.6361e-01, -2.8264e-01, -1.9438e-01],
          [-1.4697e-01,  1.4321e-01,  2.1724e-01],
          [ 2.6274e-01,  8.7396e-02,  1.3954e-01]],

         [[-1.6583e-01, -1.9034e-03, -2.3644e-01],
          [ 5.5101e-02,  2.1443e-01, -7.0371e-02],
          [ 8.0258e-03,  9.0743e-02,  6.0009e-02]]],


        [[[-1.2472e-01,  2.4734e-01,  8.0682e-02],
          [ 1.5923e-01,  1.8680e-01, -7.3649e-02],
          [-2.2144e-01, -2.7218e-02, -2.7605e-01]],

         [[ 4.2909e-02,  1.1186e-01,  1.6571e-02],
          [ 9.0273e-02,  2.6334e-01,  6.0113e-02],
          [-1.2156e-01, -8.0707e-02, -3.7639e-01]],

         [[-8.5905e-02,  1.2602e-01,  1.8858e-01],
          [ 4.0693e-02,  2.7180e-01,  8.7818e-02],
          [-2.5073e-01, -1.9566e-01, -2.7063e-01]]],


        ...,


        [[[-9.5811e-02, -1.3201e-01,  9.6739e-03],
          [ 1.0132e-01, -3.0854e-01, -1.6894e-01],
          [ 1.4624e-01, -7.2083e-02,  6.2497e-02]],

         [[ 1.5396e-01, -4.6658e-02, -1.7011e-02],
          [-4.7498e-02, -3.8673e-01, -2.6621e-01],
          [ 1.0985e-01, -2.2823e-02, -5.1827e-02]],

         [[ 2.1943e-01,  4.2085e-02,  1.1350e-01],
          [ 1.9079e-02, -1.9732e-01, -1.7469e-01],
          [ 7.3843e-02, -1.0999e-01, -9.2746e-02]]],


        [[[-4.9434e-40, -2.1659e-40, -3.0300e-40],
          [ 3.9385e-41,  2.4927e-40,  4.8038e-40],
          [ 1.2493e-40,  9.1800e-41, -1.8982e-40]],

         [[-3.1102e-40,  3.4462e-41,  9.8700e-41],
          [-3.9023e-40,  9.4997e-41,  9.8904e-41],
          [ 3.9060e-41, -9.5713e-41, -2.1553e-40]],

         [[ 1.1822e-40, -7.7437e-41,  2.8698e-40],
          [-3.4959e-40, -9.0182e-41, -3.1598e-40],
          [ 1.0912e-40, -3.1320e-40, -3.8393e-40]]],


        [[[-3.8103e-41,  3.6208e-41, -8.8975e-41],
          [ 1.3853e-41,  1.4132e-40, -1.2918e-40],
          [-1.4030e-40, -1.1796e-41, -1.9774e-40]],

         [[ 1.5082e-41, -2.1246e-40,  9.4711e-41],
          [-6.1789e-41,  1.5930e-40,  5.6221e-41],
          [-5.1258e-41, -1.7377e-40,  1.2459e-40]],

         [[-1.3217e-40, -1.0046e-40,  3.4874e-41],
          [-1.0453e-40,  7.6420e-41,  2.5091e-40],
          [ 1.6499e-40,  5.3615e-41, -1.8053e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5963]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0055]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 96 | Batch_idx: 0 |  Loss: (0.1261) | Acc: (96.00%) (123/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.1814) | Acc: (93.00%) (1320/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2181) | Acc: (92.00%) (2492/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2273) | Acc: (92.00%) (3653/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2417) | Acc: (91.00%) (4809/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2511) | Acc: (91.00%) (5964/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2610) | Acc: (91.00%) (7118/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2753) | Acc: (90.00%) (8251/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2830) | Acc: (90.00%) (9379/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2836) | Acc: (90.00%) (10532/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2830) | Acc: (90.00%) (11689/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2852) | Acc: (90.00%) (12835/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2837) | Acc: (90.00%) (14002/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2854) | Acc: (90.00%) (15155/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2852) | Acc: (90.00%) (16314/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2872) | Acc: (90.00%) (17450/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2904) | Acc: (90.00%) (18591/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2914) | Acc: (90.00%) (19734/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2929) | Acc: (90.00%) (20883/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2948) | Acc: (90.00%) (22027/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2979) | Acc: (89.00%) (23148/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2984) | Acc: (89.00%) (24291/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2975) | Acc: (89.00%) (25452/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2970) | Acc: (89.00%) (26598/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2948) | Acc: (90.00%) (27769/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2935) | Acc: (90.00%) (28934/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2913) | Acc: (90.00%) (30098/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2920) | Acc: (90.00%) (31228/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2921) | Acc: (90.00%) (32374/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2917) | Acc: (90.00%) (33536/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2914) | Acc: (90.00%) (34691/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2903) | Acc: (90.00%) (35861/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2896) | Acc: (90.00%) (37031/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2888) | Acc: (90.00%) (38186/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2877) | Acc: (90.00%) (39357/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2868) | Acc: (90.00%) (40523/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2870) | Acc: (90.00%) (41670/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2856) | Acc: (90.00%) (42865/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2846) | Acc: (90.00%) (44035/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2845) | Acc: (90.00%) (45144/50000)
# TEST : Loss: (0.3964) | Acc: (87.00%) (8768/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2058e-01,  3.1640e-01, -1.3120e-01],
          [-5.8242e-02,  3.5972e-02, -6.5444e-02],
          [ 7.0892e-02, -2.2137e-01,  2.8950e-01]],

         [[-1.2637e-01,  4.5675e-01,  1.0264e-01],
          [-1.3173e-02,  7.8773e-03, -1.8038e-01],
          [ 7.5601e-02, -3.7780e-01, -1.2968e-02]],

         [[-1.2358e-01,  2.6594e-01, -1.4546e-01],
          [ 7.5083e-02, -1.6686e-01, -1.4218e-01],
          [ 1.4676e-01, -1.3147e-01,  2.0802e-01]]],


        [[[-1.6634e-01, -3.4327e-01, -1.9330e-01],
          [-1.0445e-01,  2.3149e-01,  1.9677e-01],
          [ 2.0366e-01,  1.6106e-01,  2.5908e-01]],

         [[-2.5807e-01, -2.8187e-01, -1.9145e-01],
          [-1.4737e-01,  1.4856e-01,  2.2496e-01],
          [ 2.6359e-01,  9.8536e-02,  1.5367e-01]],

         [[-1.5607e-01,  3.5231e-03, -2.2875e-01],
          [ 5.3622e-02,  2.1853e-01, -6.2895e-02],
          [ 3.5063e-03,  9.6459e-02,  7.1173e-02]]],


        [[[-1.2775e-01,  2.5470e-01,  8.5563e-02],
          [ 1.6577e-01,  1.9653e-01, -7.1214e-02],
          [-2.1423e-01, -2.1298e-02, -2.7864e-01]],

         [[ 3.6940e-02,  1.1768e-01,  2.0435e-02],
          [ 9.5009e-02,  2.7044e-01,  6.0769e-02],
          [-1.1859e-01, -7.8116e-02, -3.7986e-01]],

         [[-9.1254e-02,  1.2633e-01,  1.8822e-01],
          [ 4.2779e-02,  2.7219e-01,  8.5533e-02],
          [-2.4805e-01, -1.9673e-01, -2.7871e-01]]],


        ...,


        [[[-8.2300e-02, -1.1883e-01,  2.2208e-02],
          [ 1.0630e-01, -3.0233e-01, -1.6523e-01],
          [ 1.5805e-01, -5.1798e-02,  7.6376e-02]],

         [[ 1.5685e-01, -4.7630e-02, -1.7159e-02],
          [-5.6501e-02, -4.1436e-01, -2.9632e-01],
          [ 1.1132e-01, -1.8347e-02, -5.1653e-02]],

         [[ 2.0774e-01,  2.9650e-02,  1.0311e-01],
          [ 4.2083e-03, -2.1771e-01, -1.9758e-01],
          [ 7.2043e-02, -1.0844e-01, -9.6022e-02]]],


        [[[-3.6946e-40, -2.1986e-40, -4.3858e-40],
          [-2.2656e-40,  2.5200e-40,  8.5946e-41],
          [-2.7501e-40,  2.2725e-40,  7.6942e-41]],

         [[-3.1429e-40, -9.7900e-41, -3.2552e-41],
          [-1.2751e-40, -4.3953e-40,  2.3403e-40],
          [ 3.0740e-40,  3.7958e-41, -3.5228e-40]],

         [[-4.0934e-40,  1.8609e-40,  2.8994e-40],
          [-2.2041e-40, -4.9253e-40, -5.1465e-41],
          [-4.2506e-40, -4.7040e-41,  1.4888e-40]]],


        [[[-4.2856e-41,  4.1048e-41, -3.2364e-41],
          [ 1.2743e-40, -7.0541e-42,  1.6407e-40],
          [-1.6557e-40, -2.2555e-40,  1.2790e-40]],

         [[-1.1145e-40, -1.9367e-40, -1.1116e-40],
          [-1.5313e-40,  2.1326e-40, -2.5589e-41],
          [-3.7961e-42,  1.9562e-40,  8.4619e-41]],

         [[-2.3350e-41, -3.2107e-41,  1.3875e-40],
          [-1.2435e-40,  1.2167e-41,  2.6450e-40],
          [-1.8311e-41,  2.1905e-40,  1.9325e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0131, -0.0254, -0.0178],
          [-0.0235, -0.0324, -0.0160],
          [-0.0402, -0.0324, -0.0166]],

         [[-0.0277, -0.0368, -0.0358],
          [-0.0377, -0.0448, -0.0306],
          [-0.0506, -0.0454, -0.0201]],

         [[-0.0230, -0.0275, -0.0215],
          [-0.0390, -0.0397, -0.0299],
          [-0.0563, -0.0450, -0.0182]]],


        [[[ 0.0213,  0.0253,  0.0347],
          [ 0.0198,  0.0178,  0.0245],
          [ 0.0182,  0.0213,  0.0320]],

         [[ 0.0317,  0.0401,  0.0508],
          [ 0.0255,  0.0324,  0.0413],
          [ 0.0195,  0.0329,  0.0458]],

         [[ 0.0397,  0.0441,  0.0546],
          [ 0.0394,  0.0453,  0.0519],
          [ 0.0400,  0.0523,  0.0608]]],


        [[[ 0.0001,  0.0033,  0.0033],
          [-0.0032, -0.0006,  0.0111],
          [ 0.0077, -0.0099,  0.0036]],

         [[ 0.0008,  0.0094,  0.0228],
          [-0.0054,  0.0012,  0.0179],
          [ 0.0055, -0.0047,  0.0119]],

         [[ 0.0246,  0.0347,  0.0444],
          [ 0.0175,  0.0251,  0.0371],
          [ 0.0210,  0.0151,  0.0281]]],


        ...,


        [[[ 0.0037, -0.0071, -0.0105],
          [ 0.0059, -0.0009, -0.0009],
          [ 0.0058,  0.0040,  0.0064]],

         [[-0.0073, -0.0144, -0.0157],
          [-0.0065, -0.0075, -0.0035],
          [-0.0081, -0.0026,  0.0058]],

         [[-0.0015, -0.0047, -0.0019],
          [ 0.0011,  0.0025,  0.0110],
          [ 0.0010,  0.0072,  0.0181]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5940]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 97 | Batch_idx: 0 |  Loss: (0.1597) | Acc: (95.00%) (122/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2768) | Acc: (90.00%) (1275/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2808) | Acc: (90.00%) (2423/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2700) | Acc: (90.00%) (3593/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2730) | Acc: (90.00%) (4750/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2640) | Acc: (90.00%) (5933/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2592) | Acc: (90.00%) (7105/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2506) | Acc: (91.00%) (8301/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2494) | Acc: (91.00%) (9471/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2458) | Acc: (91.00%) (10661/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2440) | Acc: (91.00%) (11846/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2425) | Acc: (91.00%) (13027/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2385) | Acc: (91.00%) (14222/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2393) | Acc: (91.00%) (15391/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2355) | Acc: (91.00%) (16601/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2351) | Acc: (91.00%) (17774/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2352) | Acc: (91.00%) (18951/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2339) | Acc: (91.00%) (20128/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2331) | Acc: (91.00%) (21306/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2330) | Acc: (92.00%) (22497/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2313) | Acc: (92.00%) (23677/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2316) | Acc: (92.00%) (24857/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2316) | Acc: (92.00%) (26030/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2312) | Acc: (92.00%) (27220/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2330) | Acc: (92.00%) (28383/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2335) | Acc: (91.00%) (29548/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2337) | Acc: (91.00%) (30725/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2342) | Acc: (92.00%) (31917/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2349) | Acc: (91.00%) (33086/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2350) | Acc: (91.00%) (34260/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2356) | Acc: (91.00%) (35430/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2356) | Acc: (91.00%) (36596/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2355) | Acc: (91.00%) (37769/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2356) | Acc: (91.00%) (38943/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2360) | Acc: (91.00%) (40112/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2366) | Acc: (91.00%) (41288/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2363) | Acc: (91.00%) (42466/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2371) | Acc: (91.00%) (43631/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2371) | Acc: (91.00%) (44810/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2365) | Acc: (91.00%) (45948/50000)
# TEST : Loss: (0.3436) | Acc: (89.00%) (8912/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2946e-01,  3.2052e-01, -1.4284e-01],
          [-6.9421e-02,  3.6881e-02, -7.1858e-02],
          [ 6.5752e-02, -2.2229e-01,  2.7689e-01]],

         [[-1.4030e-01,  4.5938e-01,  9.3186e-02],
          [-2.9897e-02,  2.0438e-03, -1.8396e-01],
          [ 6.3876e-02, -3.8369e-01, -2.2784e-02]],

         [[-1.2937e-01,  2.7511e-01, -1.4565e-01],
          [ 6.9961e-02, -1.6135e-01, -1.3486e-01],
          [ 1.4743e-01, -1.2288e-01,  2.1042e-01]]],


        [[[-1.7724e-01, -3.6108e-01, -2.1369e-01],
          [-1.0944e-01,  2.2121e-01,  1.8360e-01],
          [ 1.9465e-01,  1.4526e-01,  2.4496e-01]],

         [[-2.6692e-01, -2.9849e-01, -2.1153e-01],
          [-1.5043e-01,  1.3942e-01,  2.1320e-01],
          [ 2.5910e-01,  8.5781e-02,  1.4277e-01]],

         [[-1.5770e-01, -6.3151e-03, -2.4275e-01],
          [ 5.4454e-02,  2.1335e-01, -7.0784e-02],
          [ 1.8936e-03,  8.6548e-02,  6.1930e-02]]],


        [[[-1.3040e-01,  2.5282e-01,  8.1672e-02],
          [ 1.6010e-01,  1.9258e-01, -7.2696e-02],
          [-2.2869e-01, -3.2494e-02, -2.8618e-01]],

         [[ 4.0232e-02,  1.2078e-01,  1.9236e-02],
          [ 9.5747e-02,  2.7136e-01,  6.3206e-02],
          [-1.2707e-01, -8.4155e-02, -3.8053e-01]],

         [[-8.9337e-02,  1.2670e-01,  1.8599e-01],
          [ 4.4290e-02,  2.7265e-01,  9.0627e-02],
          [-2.5266e-01, -1.9914e-01, -2.7438e-01]]],


        ...,


        [[[-8.9236e-02, -1.1991e-01,  2.4776e-02],
          [ 9.9266e-02, -3.1248e-01, -1.7573e-01],
          [ 1.5336e-01, -6.2193e-02,  6.5771e-02]],

         [[ 1.4298e-01, -5.7872e-02, -1.7424e-02],
          [-6.7217e-02, -4.2974e-01, -3.0247e-01],
          [ 1.0609e-01, -2.4531e-02, -5.1999e-02]],

         [[ 2.0025e-01,  2.6446e-02,  1.0622e-01],
          [ 1.0867e-03, -2.2204e-01, -1.9650e-01],
          [ 7.3881e-02, -1.0919e-01, -9.3000e-02]]],


        [[[ 1.5861e-40,  4.4103e-41, -5.7617e-40],
          [-2.2899e-40, -1.4796e-41, -4.5067e-40],
          [-4.1203e-40,  9.4008e-41,  2.1304e-40]],

         [[-5.0298e-41, -9.9211e-41, -1.6653e-40],
          [ 2.7503e-40, -5.7770e-40,  1.0125e-40],
          [ 3.0943e-40,  1.7366e-40,  1.8677e-40]],

         [[-5.4692e-40,  3.2119e-40,  2.4297e-41],
          [ 1.8072e-40, -3.6214e-40,  2.1794e-40],
          [-5.6320e-40,  2.2353e-40,  5.5536e-40]]],


        [[[ 1.0610e-40,  4.7508e-41, -3.6766e-41],
          [-9.0424e-41, -8.6990e-41,  1.9070e-40],
          [-1.0993e-40, -1.5888e-41,  1.4933e-40]],

         [[ 8.0774e-41,  1.3402e-40,  2.1911e-41],
          [-2.4317e-40, -3.5827e-41, -6.3451e-41],
          [ 1.2355e-40, -1.3742e-40, -1.1948e-40]],

         [[-1.2014e-40,  1.3081e-40,  8.7847e-42],
          [ 1.0468e-40,  1.0489e-40,  3.2231e-41],
          [ 7.2548e-41, -1.4395e-40, -7.9817e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0134,  0.0368,  0.0395],
          [ 0.0142,  0.0369,  0.0502],
          [ 0.0087,  0.0193,  0.0232]],

         [[ 0.0267,  0.0475,  0.0477],
          [ 0.0298,  0.0490,  0.0570],
          [ 0.0319,  0.0414,  0.0390]],

         [[ 0.0362,  0.0585,  0.0533],
          [ 0.0463,  0.0611,  0.0622],
          [ 0.0540,  0.0514,  0.0438]]],


        [[[ 0.0462,  0.0428,  0.0419],
          [ 0.0452,  0.0401,  0.0396],
          [ 0.0450,  0.0424,  0.0469]],

         [[ 0.0287,  0.0255,  0.0248],
          [ 0.0270,  0.0223,  0.0219],
          [ 0.0253,  0.0223,  0.0269]],

         [[ 0.0192,  0.0156,  0.0113],
          [ 0.0177,  0.0115,  0.0072],
          [ 0.0151,  0.0136,  0.0164]]],


        [[[-0.0218, -0.0261, -0.0237],
          [-0.0174, -0.0132, -0.0114],
          [-0.0193, -0.0132, -0.0165]],

         [[ 0.0226,  0.0179,  0.0197],
          [ 0.0252,  0.0276,  0.0296],
          [ 0.0223,  0.0267,  0.0215]],

         [[ 0.0306,  0.0300,  0.0337],
          [ 0.0340,  0.0408,  0.0429],
          [ 0.0344,  0.0390,  0.0326]]],


        ...,


        [[[-0.0043, -0.0038, -0.0070],
          [-0.0039, -0.0045, -0.0065],
          [ 0.0020, -0.0011, -0.0056]],

         [[ 0.0039,  0.0037,  0.0015],
          [ 0.0030,  0.0017,  0.0006],
          [ 0.0094,  0.0056,  0.0023]],

         [[ 0.0083,  0.0114,  0.0134],
          [ 0.0076,  0.0094,  0.0126],
          [ 0.0121,  0.0117,  0.0133]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5926]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 98 | Batch_idx: 0 |  Loss: (0.1321) | Acc: (96.00%) (123/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.1843) | Acc: (93.00%) (1315/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.1974) | Acc: (93.00%) (2501/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2023) | Acc: (92.00%) (3683/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2005) | Acc: (93.00%) (4882/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.1978) | Acc: (92.00%) (6064/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.1967) | Acc: (93.00%) (7262/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.1983) | Acc: (92.00%) (8447/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.1973) | Acc: (92.00%) (9641/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.1962) | Acc: (92.00%) (10827/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.1986) | Acc: (92.00%) (12014/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.1981) | Acc: (92.00%) (13213/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2004) | Acc: (92.00%) (14384/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2002) | Acc: (92.00%) (15583/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.1990) | Acc: (92.00%) (16776/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.1989) | Acc: (92.00%) (17965/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2003) | Acc: (92.00%) (19144/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.1988) | Acc: (92.00%) (20344/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2004) | Acc: (92.00%) (21529/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.1991) | Acc: (93.00%) (22737/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.1996) | Acc: (92.00%) (23924/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.1997) | Acc: (92.00%) (25115/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.1995) | Acc: (93.00%) (26314/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2003) | Acc: (93.00%) (27505/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.1994) | Acc: (93.00%) (28701/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2006) | Acc: (93.00%) (29882/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2011) | Acc: (93.00%) (31081/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2018) | Acc: (93.00%) (32262/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2026) | Acc: (92.00%) (33436/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2021) | Acc: (92.00%) (34636/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2027) | Acc: (92.00%) (35816/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2024) | Acc: (92.00%) (37008/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2036) | Acc: (92.00%) (38178/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2052) | Acc: (92.00%) (39341/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2057) | Acc: (92.00%) (40520/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2075) | Acc: (92.00%) (41684/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2074) | Acc: (92.00%) (42878/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2073) | Acc: (92.00%) (44074/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2080) | Acc: (92.00%) (45257/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2085) | Acc: (92.00%) (46392/50000)
# TEST : Loss: (0.3248) | Acc: (89.00%) (8977/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1795e-01,  3.3231e-01, -1.3936e-01],
          [-6.1527e-02,  4.0185e-02, -7.4949e-02],
          [ 7.2678e-02, -2.2237e-01,  2.7729e-01]],

         [[-1.3842e-01,  4.6326e-01,  9.3359e-02],
          [-2.4665e-02,  4.7523e-03, -1.8836e-01],
          [ 6.3566e-02, -3.8611e-01, -2.2994e-02]],

         [[-1.2695e-01,  2.8218e-01, -1.3813e-01],
          [ 6.9158e-02, -1.5656e-01, -1.3075e-01],
          [ 1.4114e-01, -1.2230e-01,  2.1489e-01]]],


        [[[-1.7783e-01, -3.5880e-01, -2.0983e-01],
          [-1.0671e-01,  2.2995e-01,  1.9359e-01],
          [ 1.9584e-01,  1.5063e-01,  2.4887e-01]],

         [[-2.6647e-01, -2.9560e-01, -2.0841e-01],
          [-1.4935e-01,  1.4523e-01,  2.1876e-01],
          [ 2.6017e-01,  8.8815e-02,  1.4122e-01]],

         [[-1.5975e-01, -7.9764e-03, -2.4205e-01],
          [ 5.1370e-02,  2.1373e-01, -6.8391e-02],
          [ 3.7825e-04,  8.4976e-02,  5.9137e-02]]],


        [[[-1.2503e-01,  2.5368e-01,  8.7411e-02],
          [ 1.6798e-01,  1.9305e-01, -6.6668e-02],
          [-2.3174e-01, -3.9413e-02, -2.8440e-01]],

         [[ 4.1709e-02,  1.1886e-01,  2.2973e-02],
          [ 9.9702e-02,  2.6803e-01,  6.5322e-02],
          [-1.3371e-01, -9.4111e-02, -3.8161e-01]],

         [[-7.9234e-02,  1.3361e-01,  1.9647e-01],
          [ 5.5209e-02,  2.7706e-01,  1.0061e-01],
          [-2.5248e-01, -2.0027e-01, -2.6650e-01]]],


        ...,


        [[[-9.2036e-02, -1.1891e-01,  4.0174e-02],
          [ 9.6047e-02, -3.1800e-01, -1.6660e-01],
          [ 1.4456e-01, -7.3202e-02,  6.9243e-02]],

         [[ 1.4146e-01, -5.0474e-02,  5.4673e-03],
          [-7.2389e-02, -4.3614e-01, -2.8786e-01],
          [ 9.2159e-02, -4.5530e-02, -5.4399e-02]],

         [[ 1.9869e-01,  2.9836e-02,  1.2148e-01],
          [-4.6781e-03, -2.3208e-01, -1.9787e-01],
          [ 6.3275e-02, -1.2585e-01, -1.0158e-01]]],


        [[[ 5.6267e-40,  3.1313e-40, -1.7637e-40],
          [ 3.9395e-41, -2.8581e-40, -5.8902e-40],
          [-1.4326e-40, -1.7736e-40,  7.8838e-41]],

         [[ 2.1874e-40,  3.4489e-41, -1.6759e-40],
          [ 4.1245e-40, -1.7355e-40, -1.6948e-40],
          [ 3.9022e-41,  1.7443e-40,  5.9642e-40]],

         [[-1.4719e-40,  1.8844e-40, -2.4591e-40],
          [ 4.5259e-40,  1.7790e-40,  2.1980e-40],
          [-1.5927e-40,  2.2519e-40,  4.2277e-40]]],


        [[[-5.7387e-41, -1.3001e-40,  9.3300e-41],
          [ 1.1405e-40, -1.5923e-40,  6.8119e-41],
          [-2.6953e-41, -2.7563e-40,  2.7025e-40]],

         [[-4.3736e-41, -2.6154e-40,  2.7699e-41],
          [ 3.9386e-41,  1.0598e-40, -3.3564e-41],
          [-1.0967e-41, -4.8275e-42,  2.3783e-40]],

         [[-1.3841e-40, -4.1690e-41, -7.8646e-41],
          [-1.2696e-40,  1.2195e-40,  3.7836e-41],
          [-1.6162e-40,  8.7221e-41,  1.4127e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0238,  0.0236,  0.0341],
          [ 0.0487,  0.0184,  0.0467],
          [ 0.0437,  0.0213,  0.0316]],

         [[ 0.0365,  0.0387,  0.0468],
          [ 0.0532,  0.0297,  0.0562],
          [ 0.0455,  0.0320,  0.0446]],

         [[ 0.0120,  0.0140,  0.0244],
          [ 0.0351,  0.0142,  0.0417],
          [ 0.0338,  0.0220,  0.0335]]],


        [[[ 0.0205,  0.0209,  0.0034],
          [ 0.0191,  0.0212,  0.0117],
          [ 0.0108,  0.0128,  0.0109]],

         [[ 0.0001,  0.0034, -0.0085],
          [-0.0009,  0.0024, -0.0042],
          [-0.0050, -0.0038, -0.0049]],

         [[ 0.0072,  0.0128, -0.0000],
          [ 0.0083,  0.0143,  0.0090],
          [ 0.0007,  0.0029,  0.0016]]],


        [[[-0.0008,  0.0006, -0.0020],
          [-0.0088, -0.0118, -0.0136],
          [-0.0068, -0.0138, -0.0152]],

         [[ 0.0097,  0.0058, -0.0021],
          [ 0.0016, -0.0018, -0.0057],
          [ 0.0027, -0.0037, -0.0060]],

         [[-0.0100, -0.0086, -0.0193],
          [-0.0108, -0.0102, -0.0151],
          [ 0.0007, -0.0046, -0.0077]]],


        ...,


        [[[ 0.0060, -0.0062,  0.0004],
          [ 0.0032, -0.0067, -0.0032],
          [-0.0070, -0.0201, -0.0183]],

         [[ 0.0177,  0.0067,  0.0178],
          [ 0.0138,  0.0049,  0.0122],
          [ 0.0024, -0.0096, -0.0050]],

         [[ 0.0153,  0.0082,  0.0177],
          [ 0.0135,  0.0078,  0.0156],
          [ 0.0053, -0.0037,  0.0021]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5909]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 99 | Batch_idx: 0 |  Loss: (0.2043) | Acc: (94.00%) (121/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2330) | Acc: (91.00%) (1289/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2662) | Acc: (90.00%) (2440/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2592) | Acc: (90.00%) (3610/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2618) | Acc: (91.00%) (4778/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2551) | Acc: (91.00%) (5961/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2544) | Acc: (91.00%) (7132/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2497) | Acc: (91.00%) (8315/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2462) | Acc: (91.00%) (9498/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2480) | Acc: (91.00%) (10673/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2466) | Acc: (91.00%) (11845/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2414) | Acc: (91.00%) (13045/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2399) | Acc: (91.00%) (14231/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2388) | Acc: (91.00%) (15425/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2359) | Acc: (92.00%) (16621/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2346) | Acc: (92.00%) (17812/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2326) | Acc: (92.00%) (19001/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2307) | Acc: (92.00%) (20196/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2291) | Acc: (92.00%) (21386/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2274) | Acc: (92.00%) (22565/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2269) | Acc: (92.00%) (23755/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2255) | Acc: (92.00%) (24950/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2246) | Acc: (92.00%) (26139/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2231) | Acc: (92.00%) (27348/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2223) | Acc: (92.00%) (28542/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2205) | Acc: (92.00%) (29748/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2197) | Acc: (92.00%) (30945/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2182) | Acc: (92.00%) (32148/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2190) | Acc: (92.00%) (33329/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2179) | Acc: (92.00%) (34523/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2176) | Acc: (92.00%) (35714/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2172) | Acc: (92.00%) (36910/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2161) | Acc: (92.00%) (38108/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2153) | Acc: (92.00%) (39310/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2146) | Acc: (92.00%) (40508/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2142) | Acc: (92.00%) (41696/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2133) | Acc: (92.00%) (42900/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2128) | Acc: (92.00%) (44097/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2123) | Acc: (92.00%) (45288/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2125) | Acc: (92.00%) (46423/50000)
# TEST : Loss: (0.3129) | Acc: (89.00%) (8979/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2049e-01,  3.2957e-01, -1.4164e-01],
          [-6.3821e-02,  3.8737e-02, -7.7591e-02],
          [ 7.0433e-02, -2.2430e-01,  2.7392e-01]],

         [[-1.4103e-01,  4.5938e-01,  9.0180e-02],
          [-2.7333e-02,  3.0972e-03, -1.9074e-01],
          [ 6.1615e-02, -3.8702e-01, -2.5206e-02]],

         [[-1.2792e-01,  2.8071e-01, -1.3937e-01],
          [ 6.7452e-02, -1.5657e-01, -1.3223e-01],
          [ 1.3966e-01, -1.2279e-01,  2.1341e-01]]],


        [[[-1.7994e-01, -3.6000e-01, -2.0935e-01],
          [-1.0930e-01,  2.2807e-01,  1.9342e-01],
          [ 1.9253e-01,  1.4827e-01,  2.4773e-01]],

         [[-2.6945e-01, -2.9776e-01, -2.0874e-01],
          [-1.5254e-01,  1.4266e-01,  2.1767e-01],
          [ 2.5583e-01,  8.5446e-02,  1.3902e-01]],

         [[-1.6353e-01, -1.1527e-02, -2.4299e-01],
          [ 4.6924e-02,  2.0969e-01, -7.0290e-02],
          [-3.9434e-03,  8.0544e-02,  5.5776e-02]]],


        [[[-1.2500e-01,  2.5426e-01,  8.8936e-02],
          [ 1.6777e-01,  1.9374e-01, -6.5294e-02],
          [-2.3102e-01, -3.8089e-02, -2.8261e-01]],

         [[ 4.3337e-02,  1.2151e-01,  2.6494e-02],
          [ 1.0138e-01,  2.7015e-01,  6.8069e-02],
          [-1.3137e-01, -9.0921e-02, -3.7786e-01]],

         [[-7.5554e-02,  1.3775e-01,  2.0150e-01],
          [ 5.8839e-02,  2.8081e-01,  1.0511e-01],
          [-2.4846e-01, -1.9552e-01, -2.6135e-01]]],


        ...,


        [[[-8.9133e-02, -1.1363e-01,  4.3524e-02],
          [ 9.8691e-02, -3.1044e-01, -1.6236e-01],
          [ 1.4681e-01, -6.7975e-02,  7.1537e-02]],

         [[ 1.3938e-01, -5.0621e-02,  4.0535e-03],
          [-7.2385e-02, -4.3221e-01, -2.8895e-01],
          [ 9.2661e-02, -4.3304e-02, -5.5143e-02]],

         [[ 1.9653e-01,  2.8986e-02,  1.1931e-01],
          [-4.7870e-03, -2.3153e-01, -1.9986e-01],
          [ 6.3730e-02, -1.2409e-01, -1.0285e-01]]],


        [[[ 4.3137e-40,  3.1505e-40,  3.6536e-40],
          [ 3.1151e-40, -2.8739e-40, -1.8356e-40],
          [ 2.6551e-40, -3.1486e-40, -1.9375e-40]],

         [[ 2.2067e-40,  1.7019e-40, -3.2540e-41],
          [ 1.4222e-40,  3.7220e-40, -3.0678e-40],
          [-2.3448e-40,  3.7950e-41,  4.6213e-40]],

         [[ 3.9451e-40, -8.2252e-41, -2.4763e-40],
          [ 3.1874e-40,  5.8805e-40, -5.1494e-41],
          [ 3.8628e-40, -4.7060e-41, -1.2200e-40]]],


        [[[ 3.7775e-41, -7.9110e-41, -1.6347e-40],
          [-1.5487e-40, -1.8449e-40, -1.7105e-40],
          [-3.1322e-41,  2.4110e-40, -2.6300e-40]],

         [[-4.9306e-41, -3.0096e-40,  1.2979e-40],
          [ 2.1008e-40,  1.2256e-40,  7.1046e-42],
          [-9.7403e-41,  8.3473e-41,  1.2948e-40]],

         [[ 9.0998e-41,  1.7622e-40, -1.4061e-40],
          [ 2.2127e-41,  1.4019e-40,  2.6770e-40],
          [ 1.4454e-40, -6.1565e-41, -1.0595e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6739]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0756]], device='cuda:0')

Epoch: 100 | Batch_idx: 0 |  Loss: (0.3082) | Acc: (88.00%) (113/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2037) | Acc: (92.00%) (1305/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.1956) | Acc: (93.00%) (2504/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.1902) | Acc: (93.00%) (3702/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.1969) | Acc: (92.00%) (4878/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.1938) | Acc: (93.00%) (6088/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.1898) | Acc: (93.00%) (7287/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.1926) | Acc: (93.00%) (8477/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.1934) | Acc: (93.00%) (9661/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.1909) | Acc: (93.00%) (10866/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.1910) | Acc: (93.00%) (12063/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.1924) | Acc: (93.00%) (13250/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.1938) | Acc: (93.00%) (14444/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.1929) | Acc: (93.00%) (15644/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.1905) | Acc: (93.00%) (16860/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.1907) | Acc: (93.00%) (18059/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.1919) | Acc: (93.00%) (19246/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.1920) | Acc: (93.00%) (20440/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.1912) | Acc: (93.00%) (21651/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.1914) | Acc: (93.00%) (22845/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.1908) | Acc: (93.00%) (24050/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.1898) | Acc: (93.00%) (25259/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.1910) | Acc: (93.00%) (26452/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.1915) | Acc: (93.00%) (27642/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.1911) | Acc: (93.00%) (28854/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.1899) | Acc: (93.00%) (30066/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.1888) | Acc: (93.00%) (31278/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.1880) | Acc: (93.00%) (32487/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.1874) | Acc: (93.00%) (33693/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.1878) | Acc: (93.00%) (34890/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.1878) | Acc: (93.00%) (36092/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.1874) | Acc: (93.00%) (37297/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.1868) | Acc: (93.00%) (38514/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.1875) | Acc: (93.00%) (39708/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.1880) | Acc: (93.00%) (40901/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.1887) | Acc: (93.00%) (42091/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.1878) | Acc: (93.00%) (43314/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.1881) | Acc: (93.00%) (44513/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.1879) | Acc: (93.00%) (45717/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.1879) | Acc: (93.00%) (46877/50000)
# TEST : Loss: (0.3026) | Acc: (90.00%) (9002/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2017e-01,  3.2866e-01, -1.4128e-01],
          [-6.3660e-02,  3.8636e-02, -7.7395e-02],
          [ 7.0255e-02, -2.2370e-01,  2.7324e-01]],

         [[-1.4065e-01,  4.5809e-01,  8.9939e-02],
          [-2.7262e-02,  3.0889e-03, -1.9024e-01],
          [ 6.1455e-02, -3.8595e-01, -2.5140e-02]],

         [[-1.2756e-01,  2.7989e-01, -1.3898e-01],
          [ 6.7266e-02, -1.5612e-01, -1.3186e-01],
          [ 1.3928e-01, -1.2243e-01,  2.1282e-01]]],


        [[[-1.7956e-01, -3.5923e-01, -2.0890e-01],
          [-1.0907e-01,  2.2758e-01,  1.9300e-01],
          [ 1.9210e-01,  1.4794e-01,  2.4717e-01]],

         [[-2.6884e-01, -2.9708e-01, -2.0827e-01],
          [-1.5220e-01,  1.4233e-01,  2.1717e-01],
          [ 2.5523e-01,  8.5244e-02,  1.3869e-01]],

         [[-1.6313e-01, -1.1499e-02, -2.4239e-01],
          [ 4.6811e-02,  2.0919e-01, -7.0121e-02],
          [-3.9339e-03,  8.0348e-02,  5.5640e-02]]],


        [[[-1.2473e-01,  2.5371e-01,  8.8741e-02],
          [ 1.6742e-01,  1.9333e-01, -6.5156e-02],
          [-2.3054e-01, -3.8009e-02, -2.8200e-01]],

         [[ 4.3242e-02,  1.2124e-01,  2.6435e-02],
          [ 1.0117e-01,  2.6957e-01,  6.7922e-02],
          [-1.3109e-01, -9.0725e-02, -3.7703e-01]],

         [[-7.5379e-02,  1.3743e-01,  2.0103e-01],
          [ 5.8705e-02,  2.8017e-01,  1.0487e-01],
          [-2.4788e-01, -1.9506e-01, -2.6073e-01]]],


        ...,


        [[[-8.8630e-02, -1.1279e-01,  4.3214e-02],
          [ 9.8034e-02, -3.0698e-01, -1.6062e-01],
          [ 1.4595e-01, -6.7441e-02,  7.0980e-02]],

         [[ 1.3852e-01, -5.0184e-02,  4.0200e-03],
          [-7.1839e-02, -4.2502e-01, -2.8441e-01],
          [ 9.2071e-02, -4.2887e-02, -5.4617e-02]],

         [[ 1.9530e-01,  2.8759e-02,  1.1840e-01],
          [-4.7519e-03, -2.2909e-01, -1.9779e-01],
          [ 6.3322e-02, -1.2305e-01, -1.0197e-01]]],


        [[[-1.1063e-40,  4.4082e-41,  5.0412e-40],
          [ 3.1291e-40, -1.4784e-41,  3.6341e-40],
          [ 4.0389e-40, -1.7864e-40, -3.3162e-40]],

         [[-5.0304e-41,  1.7095e-40,  1.0410e-40],
          [-2.6803e-40,  5.1127e-40, -1.7084e-40],
          [-2.3566e-40, -9.9669e-41, -8.6236e-41]],

         [[ 5.3327e-40, -2.1954e-40,  2.4308e-41],
          [-9.0728e-41,  4.5349e-40, -3.2562e-40],
          [ 5.2533e-40, -3.2186e-40, -5.3454e-40]]],


        [[[ 4.3444e-41, -7.3806e-42,  1.7080e-40],
          [ 1.1427e-40, -1.3340e-40, -1.1404e-40],
          [-3.4874e-41,  1.0960e-40, -2.1404e-40]],

         [[ 1.2913e-40, -4.6773e-41,  1.9763e-40],
          [ 2.8720e-40,  9.2266e-41,  5.9900e-41],
          [-1.5876e-40,  1.4593e-40, -1.3629e-41]],

         [[-3.7162e-41, -3.0242e-40, -1.5988e-40],
          [-1.1732e-40, -2.1845e-40,  4.3481e-41],
          [ 1.1797e-40, -7.2273e-41,  2.8863e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6890]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0311]], device='cuda:0')

Epoch: 101 | Batch_idx: 0 |  Loss: (0.1963) | Acc: (92.00%) (119/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.1764) | Acc: (93.00%) (1322/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.1743) | Acc: (93.00%) (2525/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.1753) | Acc: (94.00%) (3738/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.1748) | Acc: (94.00%) (4943/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.1818) | Acc: (93.00%) (6135/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.1775) | Acc: (94.00%) (7354/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.1799) | Acc: (94.00%) (8548/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.1831) | Acc: (93.00%) (9738/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.1853) | Acc: (93.00%) (10943/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.1850) | Acc: (93.00%) (12150/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.1866) | Acc: (93.00%) (13343/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.1880) | Acc: (93.00%) (14533/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.1877) | Acc: (93.00%) (15736/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.1857) | Acc: (93.00%) (16960/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.1850) | Acc: (94.00%) (18177/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.1872) | Acc: (93.00%) (19359/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.1864) | Acc: (93.00%) (20570/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.1845) | Acc: (94.00%) (21785/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.1843) | Acc: (94.00%) (22984/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.1839) | Acc: (94.00%) (24195/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.1846) | Acc: (94.00%) (25395/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.1853) | Acc: (94.00%) (26598/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.1855) | Acc: (93.00%) (27788/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.1849) | Acc: (93.00%) (28997/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.1854) | Acc: (93.00%) (30199/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.1850) | Acc: (94.00%) (31406/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.1859) | Acc: (93.00%) (32593/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.1861) | Acc: (93.00%) (33789/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.1858) | Acc: (93.00%) (34996/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.1860) | Acc: (93.00%) (36190/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.1860) | Acc: (93.00%) (37382/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.1856) | Acc: (93.00%) (38594/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.1853) | Acc: (93.00%) (39798/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.1851) | Acc: (93.00%) (41004/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.1850) | Acc: (93.00%) (42204/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.1852) | Acc: (93.00%) (43408/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.1850) | Acc: (93.00%) (44617/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.1848) | Acc: (93.00%) (45821/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.1843) | Acc: (93.00%) (46987/50000)
# TEST : Loss: (0.2976) | Acc: (90.00%) (9034/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1979e-01,  3.2757e-01, -1.4083e-01],
          [-6.3465e-02,  3.8514e-02, -7.7158e-02],
          [ 7.0040e-02, -2.2298e-01,  2.7241e-01]],

         [[-1.4019e-01,  4.5653e-01,  8.9646e-02],
          [-2.7175e-02,  3.0788e-03, -1.8964e-01],
          [ 6.1261e-02, -3.8465e-01, -2.5060e-02]],

         [[-1.2713e-01,  2.7889e-01, -1.3851e-01],
          [ 6.7041e-02, -1.5559e-01, -1.3141e-01],
          [ 1.3881e-01, -1.2199e-01,  2.1210e-01]]],


        [[[-1.7910e-01, -3.5831e-01, -2.0835e-01],
          [-1.0878e-01,  2.2699e-01,  1.9249e-01],
          [ 1.9158e-01,  1.4753e-01,  2.4650e-01]],

         [[-2.6810e-01, -2.9626e-01, -2.0769e-01],
          [-1.5177e-01,  1.4193e-01,  2.1656e-01],
          [ 2.5449e-01,  8.4999e-02,  1.3829e-01]],

         [[-1.6265e-01, -1.1465e-02, -2.4167e-01],
          [ 4.6674e-02,  2.0857e-01, -6.9916e-02],
          [-3.9222e-03,  8.0111e-02,  5.5475e-02]]],


        [[[-1.2441e-01,  2.5304e-01,  8.8505e-02],
          [ 1.6701e-01,  1.9285e-01, -6.4989e-02],
          [-2.2996e-01, -3.7912e-02, -2.8126e-01]],

         [[ 4.3126e-02,  1.2091e-01,  2.6363e-02],
          [ 1.0091e-01,  2.6887e-01,  6.7743e-02],
          [-1.3075e-01, -9.0486e-02, -3.7601e-01]],

         [[-7.5167e-02,  1.3704e-01,  2.0045e-01],
          [ 5.8543e-02,  2.7939e-01,  1.0458e-01],
          [-2.4719e-01, -1.9451e-01, -2.5998e-01]]],


        ...,


        [[[-8.8022e-02, -1.1178e-01,  4.2841e-02],
          [ 9.7240e-02, -3.0282e-01, -1.5853e-01],
          [ 1.4492e-01, -6.6798e-02,  7.0309e-02]],

         [[ 1.3749e-01, -4.9658e-02,  3.9795e-03],
          [-7.1180e-02, -4.1644e-01, -2.7899e-01],
          [ 9.1359e-02, -4.2386e-02, -5.3983e-02]],

         [[ 1.9382e-01,  2.8487e-02,  1.1731e-01],
          [-4.7096e-03, -2.2615e-01, -1.9529e-01],
          [ 6.2830e-02, -1.2178e-01, -1.0091e-01]]],


        [[[-5.2176e-40, -2.2981e-40,  9.5427e-41],
          [ 3.9371e-41,  2.6026e-40,  5.0258e-40],
          [ 1.3014e-40,  9.6597e-41, -1.9485e-40]],

         [[-3.2421e-40,  3.4493e-41,  1.0471e-40],
          [-4.0664e-40,  1.0006e-40,  1.0405e-40],
          [ 3.9026e-41, -1.0012e-40, -5.0058e-40]],

         [[ 1.2462e-40, -8.3603e-41,  2.9889e-40],
          [-3.6627e-40, -9.5449e-41, -3.2668e-40],
          [ 1.1425e-40, -3.2281e-40, -3.9869e-40]]],


        [[[ 2.7873e-40,  8.7071e-41, -2.1163e-40],
          [-5.7848e-41,  2.1187e-40, -1.3185e-40],
          [ 1.1269e-40,  1.7502e-40, -2.9424e-40]],

         [[ 4.1753e-41, -2.7693e-40,  1.5733e-40],
          [ 2.7119e-40, -4.1633e-42,  6.8168e-41],
          [-1.7796e-40,  1.6527e-40, -1.9556e-40]],

         [[-3.0755e-40, -2.8162e-40, -1.1696e-40],
          [-8.2562e-41, -2.4990e-40,  2.7853e-40],
          [ 2.4188e-41, -1.3841e-40,  2.0064e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.7012]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0155]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 102 | Batch_idx: 0 |  Loss: (0.1975) | Acc: (92.00%) (119/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.1672) | Acc: (94.00%) (1329/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.1909) | Acc: (93.00%) (2519/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2078) | Acc: (93.00%) (3696/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2347) | Acc: (92.00%) (4837/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2502) | Acc: (91.00%) (5980/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2677) | Acc: (91.00%) (7121/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2803) | Acc: (90.00%) (8242/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2839) | Acc: (90.00%) (9383/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2913) | Acc: (90.00%) (10504/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2956) | Acc: (89.00%) (11632/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2963) | Acc: (89.00%) (12783/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2940) | Acc: (90.00%) (13949/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2936) | Acc: (90.00%) (15104/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2912) | Acc: (90.00%) (16266/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2907) | Acc: (90.00%) (17413/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2882) | Acc: (90.00%) (18587/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2880) | Acc: (90.00%) (19741/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2882) | Acc: (90.00%) (20894/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2867) | Acc: (90.00%) (22046/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2861) | Acc: (90.00%) (23198/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2848) | Acc: (90.00%) (24369/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2851) | Acc: (90.00%) (25528/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2849) | Acc: (90.00%) (26686/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2860) | Acc: (90.00%) (27830/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2848) | Acc: (90.00%) (28991/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2849) | Acc: (90.00%) (30145/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2848) | Acc: (90.00%) (31302/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2846) | Acc: (90.00%) (32457/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2840) | Acc: (90.00%) (33616/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2842) | Acc: (90.00%) (34767/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2842) | Acc: (90.00%) (35920/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2840) | Acc: (90.00%) (37075/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2841) | Acc: (90.00%) (38235/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2829) | Acc: (90.00%) (39411/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2825) | Acc: (90.00%) (40575/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2812) | Acc: (90.00%) (41757/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2803) | Acc: (90.00%) (42926/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2798) | Acc: (90.00%) (44089/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2791) | Acc: (90.00%) (45212/50000)
# TEST : Loss: (0.3897) | Acc: (87.00%) (8778/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1544e-01,  3.3584e-01, -1.4055e-01],
          [-5.5785e-02,  3.9110e-02, -7.2526e-02],
          [ 6.1288e-02, -2.2244e-01,  2.7642e-01]],

         [[-1.4196e-01,  4.6716e-01,  9.4253e-02],
          [-2.4999e-02,  5.7564e-03, -1.7866e-01],
          [ 5.4803e-02, -3.9074e-01, -1.8611e-02]],

         [[-1.3123e-01,  2.8514e-01, -1.4131e-01],
          [ 6.4323e-02, -1.5141e-01, -1.3122e-01],
          [ 1.3266e-01, -1.3512e-01,  2.0594e-01]]],


        [[[-1.8545e-01, -3.7096e-01, -2.1470e-01],
          [-1.1153e-01,  2.2363e-01,  1.8546e-01],
          [ 1.8987e-01,  1.4667e-01,  2.4187e-01]],

         [[-2.7372e-01, -3.0827e-01, -2.1246e-01],
          [-1.5280e-01,  1.4260e-01,  2.1322e-01],
          [ 2.5154e-01,  8.6901e-02,  1.3940e-01]],

         [[-1.7029e-01, -2.2589e-02, -2.4410e-01],
          [ 4.3204e-02,  2.0924e-01, -6.9049e-02],
          [-8.7081e-03,  7.9973e-02,  5.5477e-02]]],


        [[[-1.1987e-01,  2.5449e-01,  8.6488e-02],
          [ 1.7753e-01,  2.0001e-01, -6.5137e-02],
          [-2.2407e-01, -4.0865e-02, -2.8962e-01]],

         [[ 4.4633e-02,  1.2129e-01,  1.9224e-02],
          [ 1.0551e-01,  2.7282e-01,  6.1684e-02],
          [-1.2765e-01, -9.5331e-02, -3.8948e-01]],

         [[-8.3003e-02,  1.2946e-01,  1.8599e-01],
          [ 5.3555e-02,  2.7916e-01,  9.4921e-02],
          [-2.5272e-01, -2.0099e-01, -2.7845e-01]]],


        ...,


        [[[-9.9080e-02, -1.3171e-01,  2.2287e-02],
          [ 8.0013e-02, -3.4118e-01, -1.7562e-01],
          [ 1.4021e-01, -6.4343e-02,  8.5917e-02]],

         [[ 1.3693e-01, -5.7856e-02,  1.5773e-03],
          [-7.0950e-02, -4.3220e-01, -2.6356e-01],
          [ 1.0395e-01, -1.6016e-02, -1.3085e-02]],

         [[ 2.1412e-01,  4.7476e-02,  1.3793e-01],
          [ 1.7761e-02, -2.1191e-01, -1.6446e-01],
          [ 9.3600e-02, -8.7225e-02, -5.9756e-02]]],


        [[[-3.8667e-40, -2.3092e-40, -4.5450e-40],
          [-2.3630e-40,  2.6117e-40,  9.0636e-41],
          [-2.8371e-40,  2.3525e-40,  8.1085e-41]],

         [[-3.2530e-40, -1.0315e-40, -3.2551e-41],
          [-1.3205e-40, -4.5215e-40,  2.4259e-40],
          [ 3.1550e-40,  3.7944e-41, -3.6375e-40]],

         [[-4.2527e-40,  1.9126e-40,  2.9988e-40],
          [-2.2969e-40, -5.1009e-40, -5.1485e-41],
          [-4.3784e-40, -4.7065e-41,  1.5295e-40]]],


        [[[-2.1333e-40,  1.5319e-40, -6.8903e-41],
          [-6.8046e-41,  2.4282e-40, -9.6716e-41],
          [-2.0666e-40,  2.5249e-40, -2.7653e-40]],

         [[-1.3260e-40,  3.8056e-40, -1.6959e-40],
          [ 2.1468e-42, -1.2656e-40,  7.8352e-41],
          [-1.3556e-40,  1.2191e-40,  1.8588e-40]],

         [[ 1.4062e-40,  2.6110e-40,  1.5008e-40],
          [ 2.4859e-41, -1.6252e-40, -2.7277e-40],
          [-1.5497e-40, -1.5817e-40, -1.5924e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0240, -0.0139, -0.0236],
          [-0.0033, -0.0072, -0.0040],
          [ 0.0138, -0.0044, -0.0095]],

         [[-0.0167, -0.0167, -0.0239],
          [-0.0012, -0.0115, -0.0071],
          [ 0.0154, -0.0035, -0.0078]],

         [[-0.0191, -0.0212, -0.0279],
          [-0.0067, -0.0150, -0.0132],
          [ 0.0060, -0.0115, -0.0156]]],


        [[[-0.0130, -0.0167, -0.0170],
          [-0.0103, -0.0178, -0.0215],
          [-0.0123, -0.0224, -0.0274]],

         [[-0.0402, -0.0423, -0.0398],
          [-0.0359, -0.0431, -0.0442],
          [-0.0347, -0.0455, -0.0492]],

         [[-0.0379, -0.0418, -0.0417],
          [-0.0349, -0.0423, -0.0439],
          [-0.0352, -0.0463, -0.0504]]],


        [[[ 0.0023, -0.0001, -0.0009],
          [ 0.0019, -0.0051, -0.0198],
          [ 0.0040, -0.0001, -0.0118]],

         [[ 0.0131,  0.0105,  0.0103],
          [ 0.0138,  0.0087, -0.0035],
          [ 0.0193,  0.0153,  0.0056]],

         [[ 0.0206,  0.0149,  0.0136],
          [ 0.0201,  0.0127, -0.0009],
          [ 0.0223,  0.0152,  0.0034]]],


        ...,


        [[[ 0.0101,  0.0021,  0.0128],
          [ 0.0088, -0.0001,  0.0111],
          [ 0.0089,  0.0004,  0.0105]],

         [[ 0.0189,  0.0107,  0.0196],
          [ 0.0153,  0.0060,  0.0143],
          [ 0.0136,  0.0049,  0.0127]],

         [[ 0.0189,  0.0140,  0.0239],
          [ 0.0116,  0.0058,  0.0156],
          [ 0.0083,  0.0030,  0.0127]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6966]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 103 | Batch_idx: 0 |  Loss: (0.3064) | Acc: (94.00%) (121/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.2187) | Acc: (93.00%) (1310/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.2134) | Acc: (92.00%) (2495/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2132) | Acc: (92.00%) (3683/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2175) | Acc: (92.00%) (4865/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2154) | Acc: (92.00%) (6060/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.2208) | Acc: (92.00%) (7226/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.2203) | Acc: (92.00%) (8415/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2191) | Acc: (92.00%) (9604/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.2198) | Acc: (92.00%) (10788/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.2238) | Acc: (92.00%) (11954/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.2272) | Acc: (92.00%) (13116/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.2274) | Acc: (92.00%) (14301/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2285) | Acc: (92.00%) (15484/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.2279) | Acc: (92.00%) (16673/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2290) | Acc: (92.00%) (17837/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.2302) | Acc: (92.00%) (19003/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.2301) | Acc: (92.00%) (20183/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.2304) | Acc: (92.00%) (21358/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.2308) | Acc: (92.00%) (22530/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2307) | Acc: (92.00%) (23699/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2315) | Acc: (92.00%) (24876/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2311) | Acc: (92.00%) (26058/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2302) | Acc: (92.00%) (27242/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2300) | Acc: (92.00%) (28430/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2302) | Acc: (92.00%) (29607/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2311) | Acc: (92.00%) (30780/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2322) | Acc: (92.00%) (31945/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2336) | Acc: (92.00%) (33123/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2328) | Acc: (92.00%) (34313/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2317) | Acc: (92.00%) (35503/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2317) | Acc: (92.00%) (36676/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2313) | Acc: (92.00%) (37864/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2311) | Acc: (92.00%) (39039/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2305) | Acc: (92.00%) (40222/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2300) | Acc: (92.00%) (41410/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2300) | Acc: (92.00%) (42599/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2314) | Acc: (92.00%) (43756/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2314) | Acc: (92.00%) (44933/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2312) | Acc: (92.00%) (46077/50000)
# TEST : Loss: (0.3683) | Acc: (88.00%) (8855/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1466e-01,  3.3427e-01, -1.5231e-01],
          [-4.8198e-02,  3.8825e-02, -8.2278e-02],
          [ 6.6528e-02, -2.2588e-01,  2.7502e-01]],

         [[-1.3864e-01,  4.6266e-01,  7.9897e-02],
          [-1.4774e-02,  3.5378e-03, -1.8975e-01],
          [ 6.5997e-02, -3.9691e-01, -2.3829e-02]],

         [[-1.2660e-01,  2.7957e-01, -1.5368e-01],
          [ 7.1605e-02, -1.5288e-01, -1.3992e-01],
          [ 1.4579e-01, -1.3616e-01,  2.0305e-01]]],


        [[[-1.8658e-01, -3.7468e-01, -2.1513e-01],
          [-1.0680e-01,  2.2990e-01,  1.9006e-01],
          [ 1.9160e-01,  1.5160e-01,  2.4410e-01]],

         [[-2.6403e-01, -3.0200e-01, -2.0219e-01],
          [-1.3866e-01,  1.5767e-01,  2.2631e-01],
          [ 2.6170e-01,  9.9490e-02,  1.5000e-01]],

         [[-1.5235e-01, -9.8648e-03, -2.2809e-01],
          [ 6.4676e-02,  2.2988e-01, -5.1074e-02],
          [ 2.5543e-03,  9.2385e-02,  6.7083e-02]]],


        [[[-1.0903e-01,  2.6393e-01,  1.0089e-01],
          [ 1.7792e-01,  1.9918e-01, -5.8475e-02],
          [-2.2808e-01, -4.6631e-02, -2.8950e-01]],

         [[ 5.8027e-02,  1.3641e-01,  3.7315e-02],
          [ 1.0653e-01,  2.7430e-01,  6.9199e-02],
          [-1.3061e-01, -9.7486e-02, -3.8650e-01]],

         [[-7.2231e-02,  1.4123e-01,  2.0120e-01],
          [ 5.4712e-02,  2.7881e-01,  1.0196e-01],
          [-2.5392e-01, -2.0051e-01, -2.7340e-01]]],


        ...,


        [[[-9.0483e-02, -1.1545e-01,  3.3286e-02],
          [ 8.8600e-02, -3.3145e-01, -1.6869e-01],
          [ 1.3548e-01, -7.1574e-02,  8.3412e-02]],

         [[ 1.4243e-01, -4.9293e-02,  7.3462e-04],
          [-6.7513e-02, -4.4017e-01, -2.7826e-01],
          [ 9.1677e-02, -3.8867e-02, -3.2001e-02]],

         [[ 2.0614e-01,  3.4613e-02,  1.1415e-01],
          [ 4.5440e-03, -2.4331e-01, -2.0282e-01],
          [ 6.7459e-02, -1.2729e-01, -9.8745e-02]]],


        [[[ 1.6338e-40,  4.4100e-41, -5.9386e-40],
          [-2.3709e-40, -1.4788e-41, -4.6227e-40],
          [-4.2287e-40,  9.7316e-41,  2.1995e-40]],

         [[-5.0276e-41, -1.0358e-40, -1.7072e-40],
          [ 2.8265e-40, -5.9169e-40,  1.0482e-40],
          [ 3.1617e-40,  1.7667e-40,  1.8994e-40]],

         [[-5.6465e-40,  3.2981e-40,  2.4314e-41],
          [ 1.8454e-40, -3.7311e-40,  2.2532e-40],
          [-5.7737e-40,  2.3013e-40,  5.6894e-40]]],


        [[[ 2.9096e-40,  1.7294e-40,  1.7581e-40],
          [-7.9288e-41,  1.5875e-40,  1.1484e-41],
          [ 2.7287e-40,  2.2209e-40, -2.4671e-40]],

         [[ 2.4274e-40,  7.7615e-41,  2.6465e-40],
          [-1.3207e-40, -2.0866e-40,  1.5647e-41],
          [ 1.9504e-40, -1.4673e-40,  5.3953e-41]],

         [[-2.4786e-40, -2.0366e-40, -2.1879e-40],
          [-1.0685e-40,  2.2215e-40,  2.7040e-40],
          [ 1.5970e-40,  1.5846e-40,  2.4955e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0260, -0.0257, -0.0167],
          [-0.0072, -0.0114, -0.0061],
          [ 0.0087, -0.0020,  0.0054]],

         [[ 0.0054, -0.0058,  0.0045],
          [ 0.0244, -0.0039,  0.0046],
          [ 0.0248, -0.0108, -0.0045]],

         [[ 0.0198,  0.0104,  0.0235],
          [ 0.0358,  0.0094,  0.0137],
          [ 0.0285,  0.0008, -0.0082]]],


        [[[-0.0439, -0.0359, -0.0078],
          [-0.0521, -0.0380, -0.0264],
          [-0.0369, -0.0382, -0.0372]],

         [[-0.0523, -0.0363, -0.0111],
          [-0.0481, -0.0290, -0.0222],
          [-0.0247, -0.0247, -0.0307]],

         [[-0.0398, -0.0233, -0.0039],
          [-0.0414, -0.0246, -0.0156],
          [-0.0212, -0.0207, -0.0207]]],


        [[[ 0.0222,  0.0112,  0.0020],
          [ 0.0283,  0.0362,  0.0311],
          [ 0.0266,  0.0433,  0.0350]],

         [[ 0.0339,  0.0254,  0.0059],
          [ 0.0195,  0.0304,  0.0193],
          [ 0.0136,  0.0296,  0.0179]],

         [[ 0.0309,  0.0255,  0.0022],
          [ 0.0230,  0.0336,  0.0150],
          [ 0.0151,  0.0291,  0.0115]]],


        ...,


        [[[-0.0049,  0.0024, -0.0008],
          [-0.0004,  0.0112,  0.0111],
          [-0.0039,  0.0156,  0.0186]],

         [[-0.0276, -0.0225, -0.0260],
          [-0.0226, -0.0139, -0.0153],
          [-0.0201, -0.0038, -0.0042]],

         [[-0.0238, -0.0205, -0.0262],
          [-0.0223, -0.0142, -0.0160],
          [-0.0196, -0.0056, -0.0057]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6949]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 104 | Batch_idx: 0 |  Loss: (0.1769) | Acc: (90.00%) (116/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.1912) | Acc: (92.00%) (1306/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.1944) | Acc: (93.00%) (2500/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.1898) | Acc: (93.00%) (3698/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.1875) | Acc: (93.00%) (4895/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.1891) | Acc: (93.00%) (6076/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.1911) | Acc: (93.00%) (7275/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.1957) | Acc: (93.00%) (8456/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.1964) | Acc: (93.00%) (9649/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.1948) | Acc: (93.00%) (10847/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.1950) | Acc: (93.00%) (12041/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.1957) | Acc: (93.00%) (13231/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.1973) | Acc: (93.00%) (14417/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.1962) | Acc: (93.00%) (15615/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.1972) | Acc: (93.00%) (16810/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.1957) | Acc: (93.00%) (18014/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.1955) | Acc: (93.00%) (19207/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.1947) | Acc: (93.00%) (20402/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.1940) | Acc: (93.00%) (21597/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.1946) | Acc: (93.00%) (22791/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.1934) | Acc: (93.00%) (23996/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.1924) | Acc: (93.00%) (25203/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.1937) | Acc: (93.00%) (26396/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.1931) | Acc: (93.00%) (27602/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.1923) | Acc: (93.00%) (28803/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.1918) | Acc: (93.00%) (30004/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.1932) | Acc: (93.00%) (31187/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.1926) | Acc: (93.00%) (32386/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.1927) | Acc: (93.00%) (33573/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.1930) | Acc: (93.00%) (34761/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.1930) | Acc: (93.00%) (35957/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.1931) | Acc: (93.00%) (37148/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.1935) | Acc: (93.00%) (38327/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.1928) | Acc: (93.00%) (39540/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.1938) | Acc: (93.00%) (40724/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.1940) | Acc: (93.00%) (41909/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.1948) | Acc: (93.00%) (43084/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.1961) | Acc: (93.00%) (44267/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.1962) | Acc: (93.00%) (45459/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.1963) | Acc: (93.00%) (46613/50000)
# TEST : Loss: (0.3537) | Acc: (89.00%) (8924/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1739e-01,  3.4537e-01, -1.4189e-01],
          [-5.5529e-02,  3.5362e-02, -8.3284e-02],
          [ 5.9140e-02, -2.4077e-01,  2.6139e-01]],

         [[-1.3682e-01,  4.7126e-01,  9.3461e-02],
          [-1.5372e-02,  5.5278e-03, -1.8468e-01],
          [ 6.5211e-02, -4.0212e-01, -2.7821e-02]],

         [[-1.3517e-01,  2.7716e-01, -1.4075e-01],
          [ 6.5232e-02, -1.5373e-01, -1.3606e-01],
          [ 1.4212e-01, -1.4332e-01,  1.9845e-01]]],


        [[[-1.8382e-01, -3.7684e-01, -2.1303e-01],
          [-1.0133e-01,  2.3078e-01,  1.9376e-01],
          [ 1.9329e-01,  1.5532e-01,  2.5211e-01]],

         [[-2.6717e-01, -3.0862e-01, -2.0354e-01],
          [-1.4191e-01,  1.5128e-01,  2.2421e-01],
          [ 2.5767e-01,  9.7559e-02,  1.5308e-01]],

         [[-1.5392e-01, -1.6371e-02, -2.2770e-01],
          [ 6.2702e-02,  2.2417e-01, -4.9555e-02],
          [ 3.6860e-04,  9.1284e-02,  7.2007e-02]]],


        [[[-1.1557e-01,  2.6082e-01,  9.8522e-02],
          [ 1.7445e-01,  1.9748e-01, -5.8237e-02],
          [-2.3175e-01, -5.1577e-02, -2.9561e-01]],

         [[ 5.0887e-02,  1.3368e-01,  3.3948e-02],
          [ 1.0584e-01,  2.7442e-01,  7.0055e-02],
          [-1.3236e-01, -1.0145e-01, -3.9221e-01]],

         [[-7.2566e-02,  1.4319e-01,  2.0271e-01],
          [ 5.7638e-02,  2.8095e-01,  1.0568e-01],
          [-2.4862e-01, -1.9959e-01, -2.7542e-01]]],


        ...,


        [[[-9.2071e-02, -1.2414e-01,  2.7280e-02],
          [ 9.2358e-02, -3.3744e-01, -1.7969e-01],
          [ 1.5094e-01, -5.9747e-02,  8.4195e-02]],

         [[ 1.3924e-01, -5.4229e-02,  2.1146e-03],
          [-6.4184e-02, -4.3425e-01, -2.7641e-01],
          [ 1.0573e-01, -1.9514e-02, -1.8195e-02]],

         [[ 2.1357e-01,  3.6150e-02,  1.1917e-01],
          [ 2.2774e-02, -2.2958e-01, -1.9518e-01],
          [ 9.3728e-02, -1.0047e-01, -8.0397e-02]]],


        [[[ 5.7857e-40,  3.2078e-40, -1.8007e-40],
          [ 3.9381e-41, -2.9210e-40, -6.0186e-40],
          [-1.4626e-40, -1.8014e-40,  8.1728e-41]],

         [[ 2.2641e-40,  3.4503e-41, -1.7106e-40],
          [ 4.2194e-40, -1.7645e-40, -1.7240e-40],
          [ 3.9030e-41,  1.7693e-40,  6.0695e-40]],

         [[-1.5087e-40,  1.9204e-40, -2.5275e-40],
          [ 4.6216e-40,  1.8092e-40,  2.2593e-40],
          [-1.6223e-40,  2.3067e-40,  4.3120e-40]]],


        [[[-2.7118e-40,  1.2580e-40, -1.6240e-40],
          [ 4.4062e-41,  1.1256e-40,  1.4755e-40],
          [-3.2620e-40,  2.4600e-40, -2.7324e-40]],

         [[-1.6892e-40, -6.7142e-41,  2.0495e-40],
          [-3.6799e-40, -5.1736e-42, -6.0742e-41],
          [-1.6570e-40, -6.2035e-42,  3.0379e-40]],

         [[-1.9892e-40, -3.0163e-40, -1.5565e-40],
          [ 1.7722e-40, -3.4304e-40,  2.9717e-40],
          [-1.1795e-40, -1.2089e-40, -2.6883e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0105,  0.0100,  0.0033],
          [-0.0013,  0.0217,  0.0061],
          [ 0.0093,  0.0224,  0.0153]],

         [[-0.0212, -0.0051, -0.0074],
          [-0.0115,  0.0089,  0.0027],
          [ 0.0040,  0.0152,  0.0166]],

         [[-0.0318, -0.0153, -0.0154],
          [-0.0179, -0.0015, -0.0051],
          [-0.0014,  0.0106,  0.0144]]],


        [[[-0.0018,  0.0016, -0.0002],
          [-0.0002,  0.0046,  0.0034],
          [-0.0117,  0.0051,  0.0016]],

         [[-0.0029,  0.0027, -0.0006],
          [-0.0023,  0.0050,  0.0030],
          [-0.0141,  0.0036,  0.0006]],

         [[-0.0028,  0.0028,  0.0008],
          [-0.0037,  0.0041,  0.0044],
          [-0.0152,  0.0013,  0.0018]]],


        [[[ 0.0405,  0.0353,  0.0283],
          [ 0.0400,  0.0403,  0.0333],
          [ 0.0429,  0.0288,  0.0242]],

         [[ 0.0360,  0.0325,  0.0266],
          [ 0.0412,  0.0427,  0.0389],
          [ 0.0458,  0.0355,  0.0360]],

         [[ 0.0384,  0.0345,  0.0288],
          [ 0.0428,  0.0430,  0.0386],
          [ 0.0487,  0.0376,  0.0385]]],


        ...,


        [[[-0.0359, -0.0280, -0.0376],
          [-0.0286, -0.0133, -0.0217],
          [-0.0419, -0.0267, -0.0303]],

         [[-0.0314, -0.0211, -0.0280],
          [-0.0265, -0.0086, -0.0153],
          [-0.0430, -0.0264, -0.0291]],

         [[-0.0175, -0.0074, -0.0125],
          [-0.0125,  0.0051, -0.0002],
          [-0.0278, -0.0110, -0.0126]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6928]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 105 | Batch_idx: 0 |  Loss: (0.1715) | Acc: (94.00%) (121/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.1985) | Acc: (93.00%) (1321/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2149) | Acc: (93.00%) (2507/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2275) | Acc: (92.00%) (3683/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2297) | Acc: (92.00%) (4854/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2236) | Acc: (92.00%) (6044/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2195) | Acc: (92.00%) (7237/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2188) | Acc: (92.00%) (8421/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2124) | Acc: (92.00%) (9629/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2103) | Acc: (92.00%) (10825/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2071) | Acc: (93.00%) (12027/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2036) | Acc: (93.00%) (13225/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2010) | Acc: (93.00%) (14427/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2010) | Acc: (93.00%) (15619/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.1988) | Acc: (93.00%) (16830/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.1990) | Acc: (93.00%) (18027/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.1983) | Acc: (93.00%) (19228/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.1964) | Acc: (93.00%) (20432/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.1961) | Acc: (93.00%) (21624/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.1945) | Acc: (93.00%) (22835/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.1926) | Acc: (93.00%) (24046/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.1925) | Acc: (93.00%) (25243/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.1913) | Acc: (93.00%) (26446/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.1905) | Acc: (93.00%) (27652/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.1898) | Acc: (93.00%) (28857/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.1880) | Acc: (93.00%) (30075/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.1872) | Acc: (93.00%) (31284/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.1861) | Acc: (93.00%) (32496/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.1850) | Acc: (93.00%) (33705/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.1855) | Acc: (93.00%) (34905/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.1848) | Acc: (93.00%) (36113/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.1846) | Acc: (93.00%) (37315/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.1845) | Acc: (93.00%) (38515/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.1845) | Acc: (93.00%) (39714/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.1839) | Acc: (93.00%) (40919/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.1840) | Acc: (93.00%) (42112/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.1835) | Acc: (93.00%) (43323/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.1831) | Acc: (93.00%) (44531/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.1826) | Acc: (93.00%) (45740/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.1818) | Acc: (93.00%) (46911/50000)
# TEST : Loss: (0.2989) | Acc: (90.00%) (9076/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1787e-01,  3.4366e-01, -1.4173e-01],
          [-5.6851e-02,  3.3502e-02, -8.2153e-02],
          [ 5.7724e-02, -2.4188e-01,  2.6056e-01]],

         [[-1.3712e-01,  4.6955e-01,  9.2786e-02],
          [-1.6548e-02,  3.9148e-03, -1.8394e-01],
          [ 6.3797e-02, -4.0291e-01, -2.8521e-02]],

         [[-1.3408e-01,  2.7673e-01, -1.4055e-01],
          [ 6.4952e-02, -1.5382e-01, -1.3452e-01],
          [ 1.4125e-01, -1.4374e-01,  1.9820e-01]]],


        [[[-1.8449e-01, -3.7702e-01, -2.1368e-01],
          [-1.0189e-01,  2.2901e-01,  1.9188e-01],
          [ 1.9314e-01,  1.5445e-01,  2.5118e-01]],

         [[-2.6779e-01, -3.0904e-01, -2.0419e-01],
          [-1.4257e-01,  1.4936e-01,  2.2204e-01],
          [ 2.5694e-01,  9.6435e-02,  1.5210e-01]],

         [[-1.5494e-01, -1.7575e-02, -2.2833e-01],
          [ 6.1467e-02,  2.2182e-01, -5.1408e-02],
          [-1.4273e-04,  8.9737e-02,  7.0581e-02]]],


        [[[-1.1365e-01,  2.6239e-01,  1.0038e-01],
          [ 1.7619e-01,  1.9937e-01, -5.5593e-02],
          [-2.2962e-01, -4.9272e-02, -2.9235e-01]],

         [[ 5.2164e-02,  1.3481e-01,  3.5096e-02],
          [ 1.0729e-01,  2.7545e-01,  7.1434e-02],
          [-1.3097e-01, -1.0017e-01, -3.9047e-01]],

         [[-7.2064e-02,  1.4317e-01,  2.0263e-01],
          [ 5.8328e-02,  2.8098e-01,  1.0604e-01],
          [-2.4768e-01, -1.9894e-01, -2.7475e-01]]],


        ...,


        [[[-8.4498e-02, -1.1734e-01,  3.4220e-02],
          [ 9.9419e-02, -3.2694e-01, -1.7038e-01],
          [ 1.5707e-01, -5.3176e-02,  9.0025e-02]],

         [[ 1.4242e-01, -5.2284e-02,  4.7331e-03],
          [-6.0174e-02, -4.2829e-01, -2.7140e-01],
          [ 1.0904e-01, -1.7153e-02, -1.5283e-02]],

         [[ 2.1376e-01,  3.4143e-02,  1.1695e-01],
          [ 2.2920e-02, -2.3206e-01, -1.9768e-01],
          [ 9.4837e-02, -1.0105e-01, -8.1317e-02]]],


        [[[ 4.4127e-40,  3.2140e-40,  3.7449e-40],
          [ 3.1707e-40, -2.9262e-40, -1.8622e-40],
          [ 2.7047e-40, -3.1943e-40, -1.9611e-40]],

         [[ 2.2702e-40,  1.7323e-40, -3.2531e-41],
          [ 1.4485e-40,  3.7942e-40, -3.1164e-40],
          [-2.3910e-40,  3.7957e-41,  4.6867e-40]],

         [[ 4.0369e-40, -8.5184e-41, -2.5331e-40],
          [ 3.2403e-40,  5.9810e-40, -5.1484e-41],
          [ 3.9357e-40, -4.7058e-41, -1.2436e-40]]],


        [[[-3.0028e-40,  2.1205e-40, -1.7979e-40],
          [ 4.6192e-41,  2.6672e-40,  2.3732e-40],
          [-2.0521e-40,  1.1904e-40, -4.5395e-40]],

         [[ 2.1010e-40,  2.5818e-40,  2.2082e-40],
          [-1.5929e-40,  1.5807e-40,  2.1287e-41],
          [-1.3670e-41,  1.6141e-40, -2.8445e-40]],

         [[-5.5245e-41, -2.4421e-40,  1.0958e-41],
          [ 3.0886e-41, -2.1458e-40, -3.5665e-40],
          [-1.2992e-40, -1.3325e-40,  2.1417e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6483]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0123]], device='cuda:0')

Epoch: 106 | Batch_idx: 0 |  Loss: (0.1342) | Acc: (95.00%) (122/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.1779) | Acc: (93.00%) (1321/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.1719) | Acc: (93.00%) (2524/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.1661) | Acc: (94.00%) (3739/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.1681) | Acc: (94.00%) (4947/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.1642) | Acc: (94.00%) (6157/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.1646) | Acc: (94.00%) (7365/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.1653) | Acc: (94.00%) (8575/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.1643) | Acc: (94.00%) (9789/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.1671) | Acc: (94.00%) (10985/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.1676) | Acc: (94.00%) (12192/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.1689) | Acc: (94.00%) (13395/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.1683) | Acc: (94.00%) (14619/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.1687) | Acc: (94.00%) (15830/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.1697) | Acc: (94.00%) (17034/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.1683) | Acc: (94.00%) (18249/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.1695) | Acc: (94.00%) (19449/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.1695) | Acc: (94.00%) (20664/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.1691) | Acc: (94.00%) (21874/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.1699) | Acc: (94.00%) (23065/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.1681) | Acc: (94.00%) (24281/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.1681) | Acc: (94.00%) (25482/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.1679) | Acc: (94.00%) (26692/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.1673) | Acc: (94.00%) (27910/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.1671) | Acc: (94.00%) (29118/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.1678) | Acc: (94.00%) (30320/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.1677) | Acc: (94.00%) (31527/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.1672) | Acc: (94.00%) (32746/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.1672) | Acc: (94.00%) (33952/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.1677) | Acc: (94.00%) (35154/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.1676) | Acc: (94.00%) (36366/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.1673) | Acc: (94.00%) (37568/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.1681) | Acc: (94.00%) (38772/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.1671) | Acc: (94.00%) (39999/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.1669) | Acc: (94.00%) (41217/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.1670) | Acc: (94.00%) (42431/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.1680) | Acc: (94.00%) (43622/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.1681) | Acc: (94.00%) (44825/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.1680) | Acc: (94.00%) (46033/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.1675) | Acc: (94.00%) (47197/50000)
# TEST : Loss: (0.2940) | Acc: (90.00%) (9077/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1759e-01,  3.4279e-01, -1.4139e-01],
          [-5.6715e-02,  3.3419e-02, -8.1956e-02],
          [ 5.7583e-02, -2.4125e-01,  2.5993e-01]],

         [[-1.3678e-01,  4.6835e-01,  9.2558e-02],
          [-1.6508e-02,  3.9049e-03, -1.8348e-01],
          [ 6.3638e-02, -4.0185e-01, -2.8450e-02]],

         [[-1.3374e-01,  2.7599e-01, -1.4019e-01],
          [ 6.4787e-02, -1.5342e-01, -1.3417e-01],
          [ 1.4088e-01, -1.4334e-01,  1.9769e-01]]],


        [[[-1.8407e-01, -3.7617e-01, -2.1320e-01],
          [-1.0165e-01,  2.2848e-01,  1.9144e-01],
          [ 1.9268e-01,  1.5408e-01,  2.5058e-01]],

         [[-2.6715e-01, -3.0830e-01, -2.0371e-01],
          [-1.4222e-01,  1.4899e-01,  2.2150e-01],
          [ 2.5630e-01,  9.6193e-02,  1.5172e-01]],

         [[-1.5454e-01, -1.7530e-02, -2.2775e-01],
          [ 6.1311e-02,  2.2125e-01, -5.1278e-02],
          [-1.4236e-04,  8.9505e-02,  7.0399e-02]]],


        [[[-1.1343e-01,  2.6188e-01,  1.0018e-01],
          [ 1.7586e-01,  1.9899e-01, -5.5488e-02],
          [-2.2919e-01, -4.9180e-02, -2.9179e-01]],

         [[ 5.2060e-02,  1.3454e-01,  3.5025e-02],
          [ 1.0708e-01,  2.7493e-01,  7.1297e-02],
          [-1.3072e-01, -9.9981e-02, -3.8971e-01]],

         [[-7.1915e-02,  1.4287e-01,  2.0221e-01],
          [ 5.8211e-02,  2.8042e-01,  1.0582e-01],
          [-2.4718e-01, -1.9854e-01, -2.7418e-01]]],


        ...,


        [[[-8.4067e-02, -1.1656e-01,  3.4004e-02],
          [ 9.8786e-02, -3.2340e-01, -1.6871e-01],
          [ 1.5620e-01, -5.2780e-02,  8.9373e-02]],

         [[ 1.4164e-01, -5.1888e-02,  4.6989e-03],
          [-5.9752e-02, -4.2196e-01, -2.6782e-01],
          [ 1.0840e-01, -1.7010e-02, -1.5158e-02]],

         [[ 2.1257e-01,  3.3906e-02,  1.1616e-01],
          [ 2.2766e-02, -2.2986e-01, -1.9586e-01],
          [ 9.4273e-02, -1.0028e-01, -8.0704e-02]]],


        [[[-1.1340e-40,  4.4086e-41,  5.1419e-40],
          [ 3.1751e-40, -1.4761e-41,  3.7005e-40],
          [ 4.1006e-40, -1.8053e-40, -3.3553e-40]],

         [[-5.0295e-41,  1.7347e-40,  1.0650e-40],
          [-2.7236e-40,  5.1922e-40, -1.7283e-40],
          [-2.3947e-40, -1.0139e-40, -8.8041e-41]],

         [[ 5.4341e-40, -2.2443e-40,  2.4324e-41],
          [-9.2920e-41,  4.5974e-40, -3.2981e-40],
          [ 5.3335e-40, -3.2560e-40, -5.4229e-40]]],


        [[[-8.8659e-41,  1.5187e-40, -1.9486e-40],
          [ 2.1150e-40,  2.9061e-40,  1.7652e-40],
          [-3.9076e-40, -1.1750e-40, -3.2705e-40]],

         [[ 5.6692e-41, -3.4744e-40,  4.6139e-41],
          [ 1.7730e-40,  2.5934e-40,  1.1399e-40],
          [ 1.6485e-40,  2.6458e-40, -2.1068e-40]],

         [[-1.4722e-40,  9.8642e-41,  2.0278e-40],
          [ 3.1333e-41,  2.9412e-41,  2.5792e-40],
          [ 2.0409e-40, -2.3360e-40, -4.1375e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6600]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0150]], device='cuda:0')

Epoch: 107 | Batch_idx: 0 |  Loss: (0.0849) | Acc: (97.00%) (125/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.1526) | Acc: (94.00%) (1335/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.1523) | Acc: (94.00%) (2544/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.1534) | Acc: (94.00%) (3757/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.1567) | Acc: (94.00%) (4964/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.1566) | Acc: (94.00%) (6181/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.1590) | Acc: (94.00%) (7396/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.1617) | Acc: (94.00%) (8602/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.1633) | Acc: (94.00%) (9804/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.1622) | Acc: (94.00%) (11014/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.1613) | Acc: (94.00%) (12220/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.1611) | Acc: (94.00%) (13433/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.1616) | Acc: (94.00%) (14641/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.1615) | Acc: (94.00%) (15850/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.1627) | Acc: (94.00%) (17045/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.1639) | Acc: (94.00%) (18247/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.1637) | Acc: (94.00%) (19459/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.1641) | Acc: (94.00%) (20673/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.1651) | Acc: (94.00%) (21872/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.1648) | Acc: (94.00%) (23078/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.1646) | Acc: (94.00%) (24286/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.1651) | Acc: (94.00%) (25491/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.1652) | Acc: (94.00%) (26696/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.1650) | Acc: (94.00%) (27912/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.1643) | Acc: (94.00%) (29137/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.1640) | Acc: (94.00%) (30349/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.1646) | Acc: (94.00%) (31556/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.1644) | Acc: (94.00%) (32763/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.1645) | Acc: (94.00%) (33975/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.1654) | Acc: (94.00%) (35171/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.1659) | Acc: (94.00%) (36369/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.1655) | Acc: (94.00%) (37590/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.1646) | Acc: (94.00%) (38815/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.1655) | Acc: (94.00%) (40007/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.1652) | Acc: (94.00%) (41223/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.1653) | Acc: (94.00%) (42433/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.1654) | Acc: (94.00%) (43635/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.1651) | Acc: (94.00%) (44854/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.1644) | Acc: (94.00%) (46069/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.1638) | Acc: (94.00%) (47248/50000)
# TEST : Loss: (0.2873) | Acc: (90.00%) (9088/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1725e-01,  3.4174e-01, -1.4098e-01],
          [-5.6549e-02,  3.3318e-02, -8.1716e-02],
          [ 5.7412e-02, -2.4049e-01,  2.5917e-01]],

         [[-1.3637e-01,  4.6688e-01,  9.2281e-02],
          [-1.6459e-02,  3.8929e-03, -1.8293e-01],
          [ 6.3446e-02, -4.0056e-01, -2.8364e-02]],

         [[-1.3332e-01,  2.7510e-01, -1.3975e-01],
          [ 6.4587e-02, -1.5292e-01, -1.3374e-01],
          [ 1.4044e-01, -1.4287e-01,  1.9707e-01]]],


        [[[-1.8356e-01, -3.7513e-01, -2.1262e-01],
          [-1.0137e-01,  2.2785e-01,  1.9091e-01],
          [ 1.9212e-01,  1.5363e-01,  2.4985e-01]],

         [[-2.6636e-01, -3.0739e-01, -2.0313e-01],
          [-1.4181e-01,  1.4856e-01,  2.2086e-01],
          [ 2.5553e-01,  9.5900e-02,  1.5126e-01]],

         [[-1.5406e-01, -1.7475e-02, -2.2705e-01],
          [ 6.1122e-02,  2.2056e-01, -5.1119e-02],
          [-1.4192e-04,  8.9223e-02,  7.0177e-02]]],


        [[[-1.1316e-01,  2.6125e-01,  9.9938e-02],
          [ 1.7546e-01,  1.9854e-01, -5.5360e-02],
          [-2.2867e-01, -4.9068e-02, -2.9112e-01]],

         [[ 5.1934e-02,  1.3421e-01,  3.4939e-02],
          [ 1.0684e-01,  2.7430e-01,  7.1130e-02],
          [-1.3042e-01, -9.9751e-02, -3.8879e-01]],

         [[-7.1734e-02,  1.4251e-01,  2.0169e-01],
          [ 5.8068e-02,  2.7974e-01,  1.0556e-01],
          [-2.4657e-01, -1.9805e-01, -2.7350e-01]]],


        ...,


        [[[-8.3546e-02, -1.1562e-01,  3.3743e-02],
          [ 9.8021e-02, -3.1915e-01, -1.6669e-01],
          [ 1.5515e-01, -5.2301e-02,  8.8588e-02]],

         [[ 1.4070e-01, -5.1411e-02,  4.6577e-03],
          [-5.9244e-02, -4.1440e-01, -2.6352e-01],
          [ 1.0764e-01, -1.6838e-02, -1.5006e-02]],

         [[ 2.1113e-01,  3.3621e-02,  1.1520e-01],
          [ 2.2580e-02, -2.2722e-01, -1.9368e-01],
          [ 9.3592e-02, -9.9352e-02, -7.9965e-02]]],


        [[[-5.3088e-40, -2.3417e-40,  9.7494e-41],
          [ 3.9368e-41,  2.6387e-40,  5.0988e-40],
          [ 1.3183e-40,  9.8155e-41, -1.9646e-40]],

         [[-3.2855e-40,  3.4485e-41,  1.0669e-40],
          [-4.1202e-40,  1.0172e-40,  1.0575e-40],
          [ 3.9050e-41, -1.0153e-40, -5.0653e-40]],

         [[ 1.2672e-40, -8.5624e-41,  3.0280e-40],
          [-3.7170e-40, -9.7148e-41, -3.3015e-40],
          [ 1.1590e-40, -3.2590e-40, -4.0351e-40]]],


        [[[ 4.2144e-40, -9.2276e-42, -1.1944e-40],
          [ 2.2893e-40,  1.4314e-40,  1.4302e-41],
          [ 2.0840e-40, -3.0478e-40,  2.7674e-40]],

         [[-2.1685e-40,  2.9724e-40, -1.5268e-40],
          [ 4.7096e-40,  1.8368e-40,  1.1991e-40],
          [-1.3835e-41,  1.8655e-40, -2.2491e-40]],

         [[ 2.1805e-40, -3.7838e-40,  1.3413e-41],
          [-1.5303e-40, -1.5477e-40, -1.7596e-41],
          [ 3.3285e-41,  3.0372e-41, -3.3417e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6555]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0048]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 108 | Batch_idx: 0 |  Loss: (0.1304) | Acc: (94.00%) (121/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.1919) | Acc: (93.00%) (1317/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.2355) | Acc: (92.00%) (2483/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.2467) | Acc: (91.00%) (3639/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.2590) | Acc: (91.00%) (4798/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.2704) | Acc: (90.00%) (5937/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.2695) | Acc: (91.00%) (7107/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.2751) | Acc: (90.00%) (8258/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.2814) | Acc: (90.00%) (9402/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.2839) | Acc: (90.00%) (10545/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.2856) | Acc: (90.00%) (11701/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.2832) | Acc: (90.00%) (12870/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.2860) | Acc: (90.00%) (14012/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.2868) | Acc: (90.00%) (15159/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.2832) | Acc: (90.00%) (16336/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.2848) | Acc: (90.00%) (17484/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.2845) | Acc: (90.00%) (18643/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.2851) | Acc: (90.00%) (19790/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.2843) | Acc: (90.00%) (20946/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.2838) | Acc: (90.00%) (22093/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.2846) | Acc: (90.00%) (23241/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.2836) | Acc: (90.00%) (24410/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.2833) | Acc: (90.00%) (25562/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.2820) | Acc: (90.00%) (26715/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.2837) | Acc: (90.00%) (27858/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.2818) | Acc: (90.00%) (29035/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.2816) | Acc: (90.00%) (30203/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.2820) | Acc: (90.00%) (31348/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.2815) | Acc: (90.00%) (32502/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.2800) | Acc: (90.00%) (33669/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.2789) | Acc: (90.00%) (34839/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.2783) | Acc: (90.00%) (36005/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.2780) | Acc: (90.00%) (37167/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.2761) | Acc: (90.00%) (38350/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.2761) | Acc: (90.00%) (39505/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.2751) | Acc: (90.00%) (40673/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.2756) | Acc: (90.00%) (41820/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.2742) | Acc: (90.00%) (43011/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.2734) | Acc: (90.00%) (44186/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.2724) | Acc: (90.00%) (45316/50000)
# TEST : Loss: (0.3673) | Acc: (88.00%) (8819/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1253e-01,  3.4627e-01, -1.3582e-01],
          [-4.9603e-02,  3.1527e-02, -7.2864e-02],
          [ 6.5148e-02, -2.3485e-01,  2.7156e-01]],

         [[-1.3988e-01,  4.6677e-01,  9.0491e-02],
          [-2.2207e-02, -1.0276e-02, -1.8283e-01],
          [ 5.3751e-02, -4.0951e-01, -2.3710e-02]],

         [[-1.3819e-01,  2.7388e-01, -1.4995e-01],
          [ 5.0852e-02, -1.6799e-01, -1.3851e-01],
          [ 1.2709e-01, -1.4954e-01,  2.0057e-01]]],


        [[[-1.8011e-01, -3.7235e-01, -2.1204e-01],
          [-9.3983e-02,  2.4100e-01,  1.9840e-01],
          [ 1.9688e-01,  1.6578e-01,  2.5670e-01]],

         [[-2.6489e-01, -3.0711e-01, -2.0689e-01],
          [-1.3311e-01,  1.6204e-01,  2.2580e-01],
          [ 2.5925e-01,  1.0391e-01,  1.5460e-01]],

         [[-1.6441e-01, -2.6745e-02, -2.3646e-01],
          [ 5.6374e-02,  2.1977e-01, -5.8172e-02],
          [-1.2964e-02,  8.0035e-02,  5.7534e-02]]],


        [[[-1.1733e-01,  2.6301e-01,  9.6534e-02],
          [ 1.6840e-01,  1.9257e-01, -6.5307e-02],
          [-2.3605e-01, -6.2738e-02, -3.0638e-01]],

         [[ 4.4208e-02,  1.3191e-01,  2.6560e-02],
          [ 9.7300e-02,  2.6412e-01,  5.8657e-02],
          [-1.4041e-01, -1.1639e-01, -4.0360e-01]],

         [[-7.8088e-02,  1.3882e-01,  1.9057e-01],
          [ 4.4680e-02,  2.6411e-01,  8.8097e-02],
          [-2.6056e-01, -2.1684e-01, -2.9015e-01]]],


        ...,


        [[[-8.0051e-02, -1.1859e-01,  2.6561e-02],
          [ 7.8485e-02, -3.4388e-01, -1.7434e-01],
          [ 1.4578e-01, -6.0263e-02,  9.0316e-02]],

         [[ 1.5436e-01, -4.3696e-02,  3.3564e-03],
          [-6.1997e-02, -4.0990e-01, -2.5007e-01],
          [ 1.1268e-01, -2.3143e-03,  1.3138e-03]],

         [[ 2.2031e-01,  3.1236e-02,  9.8449e-02],
          [ 1.7024e-02, -2.3810e-01, -2.0962e-01],
          [ 9.4860e-02, -9.9837e-02, -9.0725e-02]]],


        [[[-3.9235e-40, -2.3452e-40, -4.5971e-40],
          [-2.3945e-40,  2.6416e-40,  9.2135e-41],
          [-2.8652e-40,  2.3784e-40,  8.2448e-41]],

         [[-3.2890e-40, -1.0486e-40, -3.2535e-41],
          [-1.3355e-40, -4.5620e-40,  2.4537e-40],
          [ 3.1812e-40,  3.7958e-41, -3.6744e-40]],

         [[-4.3047e-40,  1.9294e-40,  3.0312e-40],
          [-2.3268e-40, -5.1575e-40, -5.1480e-41],
          [-4.4198e-40, -4.7054e-41,  1.5423e-40]]],


        [[[-3.8039e-40, -1.9606e-40,  6.6919e-41],
          [ 2.4417e-40, -1.2256e-40, -1.7356e-40],
          [-3.5320e-40, -3.2647e-40,  1.9925e-40]],

         [[-1.3406e-40,  5.1631e-40, -2.6699e-40],
          [-4.9494e-40,  1.9475e-40,  2.1270e-41],
          [-2.1859e-40,  1.9632e-40, -2.7810e-41]],

         [[ 2.3118e-40,  3.1563e-40, -1.9799e-40],
          [-2.6169e-40, -2.6335e-40,  2.9045e-40],
          [-1.6211e-40, -1.6576e-40, -3.5323e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0139, -0.0145, -0.0113],
          [-0.0140, -0.0207, -0.0135],
          [-0.0350, -0.0398, -0.0378]],

         [[-0.0016, -0.0028, -0.0026],
          [ 0.0028, -0.0032, -0.0014],
          [-0.0101, -0.0205, -0.0230]],

         [[-0.0034, -0.0033, -0.0024],
          [ 0.0014,  0.0014,  0.0039],
          [-0.0103, -0.0120, -0.0145]]],


        [[[ 0.0031,  0.0076,  0.0043],
          [ 0.0028,  0.0028,  0.0039],
          [ 0.0072,  0.0077,  0.0095]],

         [[-0.0037,  0.0028,  0.0054],
          [-0.0082, -0.0055,  0.0020],
          [-0.0034,  0.0019,  0.0105]],

         [[ 0.0172,  0.0221,  0.0192],
          [ 0.0123,  0.0140,  0.0158],
          [ 0.0160,  0.0199,  0.0217]]],


        [[[-0.0516, -0.0422, -0.0232],
          [-0.0360, -0.0402, -0.0263],
          [-0.0428, -0.0450, -0.0291]],

         [[-0.0534, -0.0472, -0.0303],
          [-0.0378, -0.0412, -0.0279],
          [-0.0397, -0.0431, -0.0293]],

         [[-0.0461, -0.0404, -0.0236],
          [-0.0291, -0.0313, -0.0177],
          [-0.0310, -0.0284, -0.0136]]],


        ...,


        [[[-0.0015, -0.0046,  0.0060],
          [ 0.0063, -0.0017,  0.0084],
          [ 0.0029, -0.0029,  0.0068]],

         [[-0.0108, -0.0122, -0.0011],
          [-0.0001, -0.0064,  0.0043],
          [ 0.0013, -0.0014,  0.0101]],

         [[ 0.0000, -0.0032,  0.0058],
          [ 0.0078,  0.0004,  0.0090],
          [ 0.0097,  0.0052,  0.0138]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6581]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 109 | Batch_idx: 0 |  Loss: (0.1666) | Acc: (94.00%) (121/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.2181) | Acc: (92.00%) (1302/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.2294) | Acc: (91.00%) (2472/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.2430) | Acc: (91.00%) (3628/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.2401) | Acc: (91.00%) (4810/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.2374) | Acc: (91.00%) (5995/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.2322) | Acc: (91.00%) (7183/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.2345) | Acc: (91.00%) (8360/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.2348) | Acc: (92.00%) (9539/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.2342) | Acc: (91.00%) (10713/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.2334) | Acc: (92.00%) (11896/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.2345) | Acc: (92.00%) (13077/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.2311) | Acc: (92.00%) (14275/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.2288) | Acc: (92.00%) (15465/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.2276) | Acc: (92.00%) (16651/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.2269) | Acc: (92.00%) (17851/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.2264) | Acc: (92.00%) (19034/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.2271) | Acc: (92.00%) (20214/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.2269) | Acc: (92.00%) (21397/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.2268) | Acc: (92.00%) (22582/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.2262) | Acc: (92.00%) (23777/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.2249) | Acc: (92.00%) (24971/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.2251) | Acc: (92.00%) (26151/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.2242) | Acc: (92.00%) (27342/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.2254) | Acc: (92.00%) (28510/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.2257) | Acc: (92.00%) (29683/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.2262) | Acc: (92.00%) (30859/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.2260) | Acc: (92.00%) (32042/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.2263) | Acc: (92.00%) (33215/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.2257) | Acc: (92.00%) (34389/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.2250) | Acc: (92.00%) (35584/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.2258) | Acc: (92.00%) (36764/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.2254) | Acc: (92.00%) (37952/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.2249) | Acc: (92.00%) (39139/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.2245) | Acc: (92.00%) (40328/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.2254) | Acc: (92.00%) (41496/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.2260) | Acc: (92.00%) (42675/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.2260) | Acc: (92.00%) (43835/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.2252) | Acc: (92.00%) (45026/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.2255) | Acc: (92.00%) (46163/50000)
# TEST : Loss: (0.3602) | Acc: (88.00%) (8895/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1810e-01,  3.4673e-01, -1.3809e-01],
          [-4.4220e-02,  2.6762e-02, -7.7413e-02],
          [ 6.7380e-02, -2.3273e-01,  2.7832e-01]],

         [[-1.3580e-01,  4.8024e-01,  1.0309e-01],
          [-8.0383e-03, -4.9249e-03, -1.7656e-01],
          [ 6.7143e-02, -3.9945e-01, -9.4216e-03]],

         [[-1.3349e-01,  2.8687e-01, -1.3129e-01],
          [ 6.6958e-02, -1.6079e-01, -1.2900e-01],
          [ 1.4836e-01, -1.3250e-01,  2.1627e-01]]],


        [[[-1.8392e-01, -3.8399e-01, -2.2781e-01],
          [-9.3442e-02,  2.3534e-01,  1.8567e-01],
          [ 1.9591e-01,  1.6094e-01,  2.4565e-01]],

         [[-2.6765e-01, -3.1620e-01, -2.1656e-01],
          [-1.3042e-01,  1.5969e-01,  2.1886e-01],
          [ 2.6195e-01,  1.0321e-01,  1.4883e-01]],

         [[-1.6251e-01, -3.2623e-02, -2.4240e-01],
          [ 6.2899e-02,  2.2139e-01, -5.9130e-02],
          [-7.6505e-03,  8.2075e-02,  5.6624e-02]]],


        [[[-1.1036e-01,  2.6815e-01,  9.6073e-02],
          [ 1.7513e-01,  2.0171e-01, -6.1043e-02],
          [-2.3431e-01, -5.9672e-02, -3.0689e-01]],

         [[ 5.6882e-02,  1.4301e-01,  3.1056e-02],
          [ 1.1190e-01,  2.8090e-01,  7.0026e-02],
          [-1.3039e-01, -1.0462e-01, -3.9636e-01]],

         [[-6.9110e-02,  1.4509e-01,  1.9233e-01],
          [ 5.4701e-02,  2.7354e-01,  9.6004e-02],
          [-2.5069e-01, -2.1075e-01, -2.8719e-01]]],


        ...,


        [[[-8.4497e-02, -1.2125e-01,  3.1435e-02],
          [ 7.9779e-02, -3.4657e-01, -1.6550e-01],
          [ 1.4994e-01, -6.2348e-02,  8.6234e-02]],

         [[ 1.4467e-01, -5.3468e-02, -1.1201e-03],
          [-6.5783e-02, -4.2375e-01, -2.5381e-01],
          [ 1.1221e-01, -9.2280e-03, -1.0038e-02]],

         [[ 2.0967e-01,  2.3063e-02,  9.5126e-02],
          [ 8.4065e-03, -2.5075e-01, -2.1507e-01],
          [ 8.7573e-02, -1.0912e-01, -1.0078e-01]]],


        [[[ 1.6489e-40,  4.4090e-41, -5.9961e-40],
          [-2.3970e-40, -1.4765e-41, -4.6601e-40],
          [-4.2637e-40,  9.8389e-41,  2.2218e-40]],

         [[-5.0288e-41, -1.0500e-40, -1.7205e-40],
          [ 2.8506e-40, -5.9615e-40,  1.0597e-40],
          [ 3.1833e-40,  1.7762e-40,  1.9097e-40]],

         [[-5.7038e-40,  3.3256e-40,  2.4328e-41],
          [ 1.8579e-40, -3.7661e-40,  2.2770e-40],
          [-5.8193e-40,  2.3225e-40,  5.7325e-40]]],


        [[[ 2.8453e-40, -1.0300e-41, -2.9911e-41],
          [ 5.9295e-41, -4.2399e-40,  2.1611e-40],
          [ 1.3398e-40,  5.6842e-41,  4.1510e-40]],

         [[-1.4058e-40,  3.2865e-40, -1.6862e-40],
          [-3.1142e-40,  3.0870e-40, -8.7831e-41],
          [-2.3140e-40, -2.2385e-40,  1.9008e-40]],

         [[-2.8220e-40,  2.2443e-40, -2.0605e-40],
          [-1.7083e-40, -1.7258e-40, -1.2747e-40],
          [-2.7511e-40, -2.7903e-40,  2.7416e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0553,  0.0417,  0.0276],
          [ 0.0458,  0.0492,  0.0229],
          [ 0.0524,  0.0506,  0.0327]],

         [[ 0.0591,  0.0424,  0.0266],
          [ 0.0451,  0.0438,  0.0176],
          [ 0.0515,  0.0485,  0.0286]],

         [[ 0.0635,  0.0504,  0.0358],
          [ 0.0499,  0.0481,  0.0252],
          [ 0.0549,  0.0511,  0.0317]]],


        [[[-0.0751, -0.0814, -0.0904],
          [-0.0878, -0.0845, -0.0862],
          [-0.0893, -0.0809, -0.0799]],

         [[-0.0776, -0.0855, -0.0958],
          [-0.0873, -0.0855, -0.0893],
          [-0.0875, -0.0794, -0.0799]],

         [[-0.0512, -0.0618, -0.0738],
          [-0.0604, -0.0618, -0.0682],
          [-0.0597, -0.0542, -0.0605]]],


        [[[ 0.0752,  0.0880,  0.0940],
          [ 0.0827,  0.0843,  0.0875],
          [ 0.0855,  0.0898,  0.0874]],

         [[ 0.0655,  0.0759,  0.0790],
          [ 0.0740,  0.0737,  0.0730],
          [ 0.0740,  0.0776,  0.0729]],

         [[ 0.0560,  0.0666,  0.0682],
          [ 0.0630,  0.0653,  0.0654],
          [ 0.0612,  0.0685,  0.0686]]],


        ...,


        [[[ 0.0111,  0.0015,  0.0036],
          [ 0.0063,  0.0018,  0.0024],
          [-0.0092, -0.0089, -0.0018]],

         [[ 0.0062, -0.0030, -0.0001],
          [ 0.0012, -0.0017,  0.0005],
          [-0.0135, -0.0112, -0.0021]],

         [[ 0.0076, -0.0035, -0.0028],
          [ 0.0039, -0.0015, -0.0013],
          [-0.0066, -0.0075, -0.0012]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6566]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 110 | Batch_idx: 0 |  Loss: (0.2741) | Acc: (91.00%) (117/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.2083) | Acc: (93.00%) (1311/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.2073) | Acc: (93.00%) (2507/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.2072) | Acc: (93.00%) (3695/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.2173) | Acc: (92.00%) (4868/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.2138) | Acc: (92.00%) (6057/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.2094) | Acc: (92.00%) (7256/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.2060) | Acc: (93.00%) (8453/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.2069) | Acc: (92.00%) (9635/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.2055) | Acc: (92.00%) (10822/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.2030) | Acc: (92.00%) (12021/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.2030) | Acc: (93.00%) (13216/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.2045) | Acc: (92.00%) (14403/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.2043) | Acc: (92.00%) (15591/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.2025) | Acc: (93.00%) (16789/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.1999) | Acc: (93.00%) (17994/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.1998) | Acc: (93.00%) (19181/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.2016) | Acc: (92.00%) (20354/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.2008) | Acc: (92.00%) (21545/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.2011) | Acc: (93.00%) (22738/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.2012) | Acc: (92.00%) (23926/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.2036) | Acc: (92.00%) (25094/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.2034) | Acc: (92.00%) (26280/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.2037) | Acc: (92.00%) (27475/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.2031) | Acc: (92.00%) (28669/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.2044) | Acc: (92.00%) (29834/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.2037) | Acc: (92.00%) (31030/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.2035) | Acc: (92.00%) (32219/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.2033) | Acc: (92.00%) (33417/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.2024) | Acc: (92.00%) (34614/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.2030) | Acc: (92.00%) (35799/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.2028) | Acc: (92.00%) (36991/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.2041) | Acc: (92.00%) (38157/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.2048) | Acc: (92.00%) (39337/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.2046) | Acc: (92.00%) (40536/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.2045) | Acc: (92.00%) (41720/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.2040) | Acc: (92.00%) (42927/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.2040) | Acc: (92.00%) (44121/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.2037) | Acc: (92.00%) (45332/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.2030) | Acc: (92.00%) (46490/50000)
# TEST : Loss: (0.3371) | Acc: (89.00%) (8970/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1830e-01,  3.5206e-01, -1.3104e-01],
          [-5.1975e-02,  2.8867e-02, -8.0392e-02],
          [ 5.6876e-02, -2.3095e-01,  2.8345e-01]],

         [[-1.3475e-01,  4.8807e-01,  1.1550e-01],
          [-1.7651e-02, -3.8542e-03, -1.7634e-01],
          [ 5.5841e-02, -3.9692e-01,  7.2024e-04]],

         [[-1.3676e-01,  2.8684e-01, -1.2753e-01],
          [ 5.5689e-02, -1.6044e-01, -1.3081e-01],
          [ 1.3961e-01, -1.2427e-01,  2.2494e-01]]],


        [[[-1.8391e-01, -3.9005e-01, -2.2879e-01],
          [-9.3704e-02,  2.3275e-01,  1.8551e-01],
          [ 1.9916e-01,  1.6240e-01,  2.4566e-01]],

         [[-2.7013e-01, -3.2560e-01, -2.1988e-01],
          [-1.3293e-01,  1.5390e-01,  2.1522e-01],
          [ 2.6396e-01,  1.0209e-01,  1.4651e-01]],

         [[-1.6270e-01, -3.9765e-02, -2.4316e-01],
          [ 6.1067e-02,  2.1650e-01, -6.1471e-02],
          [-7.4874e-03,  7.8347e-02,  5.3208e-02]]],


        [[[-1.1299e-01,  2.6105e-01,  8.8576e-02],
          [ 1.7624e-01,  1.9663e-01, -6.5794e-02],
          [-2.3477e-01, -6.9281e-02, -3.1767e-01]],

         [[ 5.5751e-02,  1.3606e-01,  2.1791e-02],
          [ 1.1553e-01,  2.7652e-01,  6.4201e-02],
          [-1.3038e-01, -1.1412e-01, -4.0840e-01]],

         [[-6.2020e-02,  1.4676e-01,  1.9150e-01],
          [ 6.7828e-02,  2.7752e-01,  9.7756e-02],
          [-2.3986e-01, -2.0896e-01, -2.8974e-01]]],


        ...,


        [[[-9.2441e-02, -1.2694e-01,  1.8931e-02],
          [ 6.7257e-02, -3.5751e-01, -1.7373e-01],
          [ 1.4363e-01, -6.6269e-02,  9.0515e-02]],

         [[ 1.4014e-01, -5.1505e-02, -4.4736e-03],
          [-7.1770e-02, -4.2446e-01, -2.5489e-01],
          [ 1.1314e-01, -6.8689e-03, -8.2173e-04]],

         [[ 2.1527e-01,  3.0586e-02,  9.4939e-02],
          [ 1.2550e-02, -2.4478e-01, -2.1441e-01],
          [ 9.2669e-02, -1.0474e-01, -9.5136e-02]]],


        [[[ 5.8366e-40,  3.2323e-40, -1.8128e-40],
          [ 3.9379e-41, -2.9412e-40, -6.0598e-40],
          [-1.4723e-40, -1.8100e-40,  8.2629e-41]],

         [[ 2.2886e-40,  3.4483e-41, -1.7216e-40],
          [ 4.2493e-40, -1.7734e-40, -1.7335e-40],
          [ 3.9044e-41,  1.7770e-40,  6.1031e-40]],

         [[-1.5205e-40,  1.9316e-40, -2.5494e-40],
          [ 4.6523e-40,  1.8188e-40,  2.2789e-40],
          [-1.6318e-40,  2.3242e-40,  4.3387e-40]]],


        [[[-1.1570e-40,  1.9681e-40, -1.3748e-40],
          [-1.4833e-40,  3.7866e-40,  1.8892e-41],
          [ 4.6074e-40,  2.7155e-40,  1.1623e-40]],

         [[-1.4559e-40, -1.0310e-40,  5.4700e-41],
          [ 1.1398e-40,  2.1283e-40, -9.2278e-41],
          [-2.0659e-41, -9.4868e-42,  3.1133e-40]],

         [[ 1.4370e-40, -2.1382e-40, -2.1442e-40],
          [ 4.0874e-41,  3.8973e-41, -4.7080e-40],
          [-1.7850e-40, -1.8206e-40,  6.1416e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0066, -0.0064,  0.0008],
          [ 0.0095,  0.0099, -0.0025],
          [ 0.0028,  0.0078,  0.0116]],

         [[ 0.0036,  0.0055,  0.0077],
          [ 0.0187,  0.0182,  0.0028],
          [ 0.0134,  0.0145,  0.0215]],

         [[ 0.0026,  0.0082,  0.0123],
          [ 0.0145,  0.0165,  0.0045],
          [ 0.0144,  0.0155,  0.0207]]],


        [[[-0.0025, -0.0035, -0.0079],
          [ 0.0039, -0.0022, -0.0086],
          [-0.0017, -0.0032, -0.0026]],

         [[ 0.0139,  0.0149,  0.0138],
          [ 0.0208,  0.0176,  0.0153],
          [ 0.0150,  0.0156,  0.0192]],

         [[ 0.0117,  0.0128,  0.0123],
          [ 0.0182,  0.0157,  0.0139],
          [ 0.0137,  0.0150,  0.0194]]],


        [[[ 0.0814,  0.0721,  0.0705],
          [ 0.0690,  0.0660,  0.0725],
          [ 0.0586,  0.0618,  0.0729]],

         [[ 0.0720,  0.0655,  0.0657],
          [ 0.0612,  0.0596,  0.0655],
          [ 0.0530,  0.0541,  0.0642]],

         [[ 0.0560,  0.0532,  0.0552],
          [ 0.0486,  0.0512,  0.0583],
          [ 0.0431,  0.0475,  0.0569]]],


        ...,


        [[[-0.0135, -0.0183, -0.0136],
          [-0.0047, -0.0095, -0.0048],
          [-0.0140, -0.0146, -0.0034]],

         [[-0.0042, -0.0074, -0.0010],
          [ 0.0039,  0.0002,  0.0067],
          [-0.0066, -0.0064,  0.0066]],

         [[-0.0052, -0.0065,  0.0006],
          [ 0.0014, -0.0009,  0.0065],
          [-0.0091, -0.0079,  0.0051]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6547]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 111 | Batch_idx: 0 |  Loss: (0.2417) | Acc: (92.00%) (119/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.2065) | Acc: (93.00%) (1310/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.2220) | Acc: (92.00%) (2490/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.2197) | Acc: (92.00%) (3687/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.2160) | Acc: (92.00%) (4879/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.2175) | Acc: (92.00%) (6052/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.2125) | Acc: (92.00%) (7243/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.2152) | Acc: (92.00%) (8419/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.2131) | Acc: (92.00%) (9614/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.2153) | Acc: (92.00%) (10786/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.2140) | Acc: (92.00%) (11978/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.2096) | Acc: (92.00%) (13192/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.2087) | Acc: (92.00%) (14389/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.2084) | Acc: (92.00%) (15580/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.2075) | Acc: (92.00%) (16774/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.2065) | Acc: (92.00%) (17972/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.2050) | Acc: (93.00%) (19169/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.2014) | Acc: (93.00%) (20382/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.2009) | Acc: (93.00%) (21579/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.2000) | Acc: (93.00%) (22778/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.1982) | Acc: (93.00%) (23983/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.1983) | Acc: (93.00%) (25179/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.1964) | Acc: (93.00%) (26384/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.1955) | Acc: (93.00%) (27588/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.1959) | Acc: (93.00%) (28779/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.1942) | Acc: (93.00%) (29993/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.1934) | Acc: (93.00%) (31197/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.1922) | Acc: (93.00%) (32408/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.1930) | Acc: (93.00%) (33592/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.1920) | Acc: (93.00%) (34800/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.1912) | Acc: (93.00%) (36016/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.1911) | Acc: (93.00%) (37222/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.1908) | Acc: (93.00%) (38431/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.1897) | Acc: (93.00%) (39650/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.1887) | Acc: (93.00%) (40866/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.1883) | Acc: (93.00%) (42071/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.1876) | Acc: (93.00%) (43280/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.1862) | Acc: (93.00%) (44499/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.1859) | Acc: (93.00%) (45706/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.1853) | Acc: (93.00%) (46870/50000)
# TEST : Loss: (0.2907) | Acc: (90.00%) (9098/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1710e-01,  3.5172e-01, -1.3088e-01],
          [-5.2439e-02,  2.8383e-02, -7.9766e-02],
          [ 5.6540e-02, -2.3038e-01,  2.8290e-01]],

         [[-1.3395e-01,  4.8683e-01,  1.1463e-01],
          [-1.8681e-02, -4.9229e-03, -1.7602e-01],
          [ 5.5228e-02, -3.9649e-01,  2.1833e-04]],

         [[-1.3612e-01,  2.8546e-01, -1.2847e-01],
          [ 5.4653e-02, -1.6126e-01, -1.3079e-01],
          [ 1.3886e-01, -1.2450e-01,  2.2404e-01]]],


        [[[-1.8261e-01, -3.8848e-01, -2.2723e-01],
          [-9.2975e-02,  2.3296e-01,  1.8645e-01],
          [ 1.9976e-01,  1.6301e-01,  2.4660e-01]],

         [[-2.6864e-01, -3.2420e-01, -2.1855e-01],
          [-1.3210e-01,  1.5413e-01,  2.1567e-01],
          [ 2.6432e-01,  1.0258e-01,  1.4712e-01]],

         [[-1.6186e-01, -3.9427e-02, -2.4242e-01],
          [ 6.1306e-02,  2.1621e-01, -6.1146e-02],
          [-7.0951e-03,  7.8221e-02,  5.2973e-02]]],


        [[[-1.1775e-01,  2.5588e-01,  8.3782e-02],
          [ 1.7147e-01,  1.9116e-01, -7.1371e-02],
          [-2.3837e-01, -7.3946e-02, -3.2242e-01]],

         [[ 5.1123e-02,  1.3149e-01,  1.7683e-02],
          [ 1.1124e-01,  2.7129e-01,  5.9014e-02],
          [-1.3385e-01, -1.1836e-01, -4.1249e-01]],

         [[-6.5114e-02,  1.4307e-01,  1.8785e-01],
          [ 6.4613e-02,  2.7289e-01,  9.3163e-02],
          [-2.4210e-01, -2.1240e-01, -2.9335e-01]]],


        ...,


        [[[-8.9712e-02, -1.2388e-01,  1.8007e-02],
          [ 6.8963e-02, -3.5116e-01, -1.7304e-01],
          [ 1.4510e-01, -6.4188e-02,  8.8231e-02]],

         [[ 1.4123e-01, -4.9807e-02, -6.8266e-03],
          [-7.0275e-02, -4.1753e-01, -2.5563e-01],
          [ 1.1352e-01, -6.5323e-03, -4.3027e-03]],

         [[ 2.1471e-01,  3.0256e-02,  9.1537e-02],
          [ 1.2164e-02, -2.4360e-01, -2.1648e-01],
          [ 9.2251e-02, -1.0513e-01, -9.8846e-02]]],


        [[[ 4.4440e-40,  3.2343e-40,  3.7737e-40],
          [ 3.1884e-40, -2.9428e-40, -1.8706e-40],
          [ 2.7201e-40, -3.2088e-40, -1.9688e-40]],

         [[ 2.2906e-40,  1.7421e-40, -3.2558e-41],
          [ 1.4566e-40,  3.8174e-40, -3.1321e-40],
          [-2.4056e-40,  3.7922e-41,  4.7076e-40]],

         [[ 4.0661e-40, -8.6146e-41, -2.5511e-40],
          [ 3.2572e-40,  6.0127e-40, -5.1481e-41],
          [ 3.9587e-40, -4.7056e-41, -1.2509e-40]]],


        [[[-4.4838e-40, -1.4288e-41, -1.4210e-40],
          [-4.5370e-41,  2.8974e-40, -1.9908e-40],
          [ 1.4549e-40, -3.8120e-40, -3.2458e-40]],

         [[-3.6892e-41,  3.5548e-40,  2.9396e-40],
          [ 4.6175e-40, -7.9047e-42,  2.1294e-41],
          [-2.5184e-40,  2.2252e-40,  2.0306e-40]],

         [[ 3.7790e-40,  1.2749e-40,  1.7034e-41],
          [ 2.7102e-40,  2.6899e-40, -4.8787e-40],
          [ 4.2109e-41,  3.9128e-41, -4.0179e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6798]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0085]], device='cuda:0')

Epoch: 112 | Batch_idx: 0 |  Loss: (0.1645) | Acc: (94.00%) (121/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1773) | Acc: (93.00%) (1321/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1732) | Acc: (94.00%) (2529/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1755) | Acc: (94.00%) (3736/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.1723) | Acc: (94.00%) (4946/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.1662) | Acc: (94.00%) (6165/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1660) | Acc: (94.00%) (7367/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1668) | Acc: (94.00%) (8568/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1631) | Acc: (94.00%) (9794/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1642) | Acc: (94.00%) (11001/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1667) | Acc: (94.00%) (12196/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.1680) | Acc: (94.00%) (13388/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.1692) | Acc: (94.00%) (14595/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.1678) | Acc: (94.00%) (15804/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.1667) | Acc: (94.00%) (17027/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.1675) | Acc: (94.00%) (18226/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.1663) | Acc: (94.00%) (19446/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.1640) | Acc: (94.00%) (20676/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1635) | Acc: (94.00%) (21881/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.1635) | Acc: (94.00%) (23097/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.1631) | Acc: (94.00%) (24307/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.1627) | Acc: (94.00%) (25519/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.1641) | Acc: (94.00%) (26699/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.1638) | Acc: (94.00%) (27911/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.1650) | Acc: (94.00%) (29120/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.1658) | Acc: (94.00%) (30314/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.1661) | Acc: (94.00%) (31523/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.1661) | Acc: (94.00%) (32732/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.1659) | Acc: (94.00%) (33946/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.1655) | Acc: (94.00%) (35153/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.1654) | Acc: (94.00%) (36366/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.1654) | Acc: (94.00%) (37576/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.1653) | Acc: (94.00%) (38779/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.1651) | Acc: (94.00%) (39989/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.1656) | Acc: (94.00%) (41191/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.1648) | Acc: (94.00%) (42410/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.1644) | Acc: (94.00%) (43636/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.1642) | Acc: (94.00%) (44850/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.1645) | Acc: (94.00%) (46049/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.1642) | Acc: (94.00%) (47222/50000)
# TEST : Loss: (0.2839) | Acc: (91.00%) (9108/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1679e-01,  3.5075e-01, -1.3053e-01],
          [-5.2302e-02,  2.8309e-02, -7.9559e-02],
          [ 5.6394e-02, -2.2977e-01,  2.8217e-01]],

         [[-1.3359e-01,  4.8546e-01,  1.1432e-01],
          [-1.8631e-02, -4.9097e-03, -1.7555e-01],
          [ 5.5081e-02, -3.9541e-01,  2.1775e-04]],

         [[-1.3573e-01,  2.8463e-01, -1.2811e-01],
          [ 5.4500e-02, -1.6081e-01, -1.3042e-01],
          [ 1.3847e-01, -1.2414e-01,  2.2342e-01]]],


        [[[-1.8220e-01, -3.8761e-01, -2.2672e-01],
          [-9.2764e-02,  2.3243e-01,  1.8602e-01],
          [ 1.9929e-01,  1.6262e-01,  2.4601e-01]],

         [[-2.6798e-01, -3.2341e-01, -2.1802e-01],
          [-1.3178e-01,  1.5376e-01,  2.1515e-01],
          [ 2.6365e-01,  1.0232e-01,  1.4675e-01]],

         [[-1.6143e-01, -3.9323e-02, -2.4178e-01],
          [ 6.1144e-02,  2.1564e-01, -6.0987e-02],
          [-7.0762e-03,  7.8014e-02,  5.2835e-02]]],


        [[[-1.1752e-01,  2.5537e-01,  8.3614e-02],
          [ 1.7114e-01,  1.9079e-01, -7.1233e-02],
          [-2.3790e-01, -7.3802e-02, -3.2178e-01]],

         [[ 5.1018e-02,  1.3122e-01,  1.7647e-02],
          [ 1.1101e-01,  2.7075e-01,  5.8896e-02],
          [-1.3357e-01, -1.1813e-01, -4.1165e-01]],

         [[-6.4974e-02,  1.4276e-01,  1.8744e-01],
          [ 6.4474e-02,  2.7231e-01,  9.2963e-02],
          [-2.4157e-01, -2.1194e-01, -2.9270e-01]]],


        ...,


        [[[-8.9259e-02, -1.2306e-01,  1.7892e-02],
          [ 6.8559e-02, -3.4763e-01, -1.7136e-01],
          [ 1.4438e-01, -6.3756e-02,  8.7630e-02]],

         [[ 1.4048e-01, -4.9435e-02, -6.7787e-03],
          [-6.9824e-02, -4.1180e-01, -2.5236e-01],
          [ 1.1291e-01, -6.4818e-03, -4.2694e-03]],

         [[ 2.1357e-01,  3.0053e-02,  9.0930e-02],
          [ 1.2089e-02, -2.4138e-01, -2.1446e-01],
          [ 9.1751e-02, -1.0438e-01, -9.8118e-02]]],


        [[[-1.1428e-40,  4.4079e-41,  5.1736e-40],
          [ 3.1899e-40, -1.4774e-41,  3.7212e-40],
          [ 4.1197e-40, -1.8114e-40, -3.3679e-40]],

         [[-5.0280e-41,  1.7429e-40,  1.0723e-40],
          [-2.7373e-40,  5.2176e-40, -1.7349e-40],
          [-2.4068e-40, -1.0196e-40, -8.8576e-41]],

         [[ 5.4661e-40, -2.2600e-40,  2.4332e-41],
          [-9.3590e-41,  4.6168e-40, -3.3114e-40],
          [ 5.3589e-40, -3.2678e-40, -5.4472e-40]]],


        [[[-4.6698e-40,  2.1379e-40, -2.9883e-41],
          [-1.5962e-40, -1.4911e-40, -2.0674e-40],
          [ 1.5102e-40,  6.4523e-41, -5.6808e-40]],

         [[ 8.0293e-41, -4.6759e-40,  3.0200e-40],
          [-4.6739e-40, -2.4492e-40,  1.4229e-40],
          [-2.5929e-40,  2.2982e-40, -3.3424e-41]],

         [[-8.1837e-41,  2.5141e-40,  2.6229e-40],
          [ 2.8048e-40,  2.7848e-40, -1.4253e-40],
          [ 2.7926e-40,  2.7673e-40,  3.0555e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6635]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0233]], device='cuda:0')

Epoch: 113 | Batch_idx: 0 |  Loss: (0.1526) | Acc: (95.00%) (122/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.1516) | Acc: (94.00%) (1330/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1682) | Acc: (93.00%) (2524/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1669) | Acc: (94.00%) (3734/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1661) | Acc: (94.00%) (4936/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1709) | Acc: (93.00%) (6135/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1686) | Acc: (94.00%) (7346/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1684) | Acc: (94.00%) (8563/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1679) | Acc: (94.00%) (9769/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1665) | Acc: (94.00%) (10990/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1664) | Acc: (94.00%) (12198/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1676) | Acc: (94.00%) (13402/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1682) | Acc: (94.00%) (14608/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1682) | Acc: (94.00%) (15809/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.1687) | Acc: (94.00%) (17007/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1694) | Acc: (94.00%) (18216/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.1689) | Acc: (94.00%) (19424/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.1683) | Acc: (94.00%) (20631/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.1686) | Acc: (94.00%) (21840/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.1674) | Acc: (94.00%) (23054/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.1661) | Acc: (94.00%) (24283/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.1670) | Acc: (94.00%) (25485/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1677) | Acc: (94.00%) (26682/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1676) | Acc: (94.00%) (27895/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1681) | Acc: (94.00%) (29099/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1682) | Acc: (94.00%) (30313/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1665) | Acc: (94.00%) (31543/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.1670) | Acc: (94.00%) (32751/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.1662) | Acc: (94.00%) (33976/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1670) | Acc: (94.00%) (35177/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.1665) | Acc: (94.00%) (36394/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.1667) | Acc: (94.00%) (37604/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.1670) | Acc: (94.00%) (38807/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.1670) | Acc: (94.00%) (40027/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.1661) | Acc: (94.00%) (41255/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.1665) | Acc: (94.00%) (42465/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.1657) | Acc: (94.00%) (43687/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.1654) | Acc: (94.00%) (44903/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.1656) | Acc: (94.00%) (46108/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.1650) | Acc: (94.00%) (47286/50000)
# TEST : Loss: (0.2794) | Acc: (91.00%) (9101/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1641e-01,  3.4957e-01, -1.3011e-01],
          [-5.2136e-02,  2.8219e-02, -7.9308e-02],
          [ 5.6218e-02, -2.2903e-01,  2.8127e-01]],

         [[-1.3314e-01,  4.8380e-01,  1.1395e-01],
          [-1.8569e-02, -4.8937e-03, -1.7498e-01],
          [ 5.4903e-02, -3.9410e-01,  2.1704e-04]],

         [[-1.3526e-01,  2.8362e-01, -1.2767e-01],
          [ 5.4314e-02, -1.6026e-01, -1.2998e-01],
          [ 1.3800e-01, -1.2371e-01,  2.2266e-01]]],


        [[[-1.8170e-01, -3.8656e-01, -2.2610e-01],
          [-9.2508e-02,  2.3178e-01,  1.8550e-01],
          [ 1.9871e-01,  1.6214e-01,  2.4530e-01]],

         [[-2.6719e-01, -3.2246e-01, -2.1738e-01],
          [-1.3139e-01,  1.5330e-01,  2.1451e-01],
          [ 2.6284e-01,  1.0200e-01,  1.4631e-01]],

         [[-1.6090e-01, -3.9196e-02, -2.4101e-01],
          [ 6.0948e-02,  2.1495e-01, -6.0793e-02],
          [-7.0533e-03,  7.7763e-02,  5.2667e-02]]],


        [[[-1.1723e-01,  2.5475e-01,  8.3411e-02],
          [ 1.7074e-01,  1.9034e-01, -7.1064e-02],
          [-2.3733e-01, -7.3627e-02, -3.2101e-01]],

         [[ 5.0891e-02,  1.3090e-01,  1.7603e-02],
          [ 1.1074e-01,  2.7009e-01,  5.8753e-02],
          [-1.3324e-01, -1.1784e-01, -4.1063e-01]],

         [[-6.4803e-02,  1.4238e-01,  1.8695e-01],
          [ 6.4305e-02,  2.7160e-01,  9.2720e-02],
          [-2.4092e-01, -2.1138e-01, -2.9192e-01]]],


        ...,


        [[[-8.8712e-02, -1.2206e-01,  1.7754e-02],
          [ 6.8071e-02, -3.4339e-01, -1.6934e-01],
          [ 1.4350e-01, -6.3235e-02,  8.6905e-02]],

         [[ 1.3957e-01, -4.8987e-02, -6.7209e-03],
          [-6.9280e-02, -4.0494e-01, -2.4845e-01],
          [ 1.1218e-01, -6.4210e-03, -4.2294e-03]],

         [[ 2.1220e-01,  2.9806e-02,  9.0198e-02],
          [ 1.2000e-02, -2.3870e-01, -2.1203e-01],
          [ 9.1148e-02, -1.0346e-01, -9.7240e-02]]],


        [[[-5.3377e-40, -2.3556e-40,  9.8134e-41],
          [ 3.9388e-41,  2.6497e-40,  5.1215e-40],
          [ 1.3234e-40,  9.8625e-41, -1.9699e-40]],

         [[-3.2991e-40,  3.4520e-41,  1.0729e-40],
          [-4.1372e-40,  1.0227e-40,  1.0624e-40],
          [ 3.9064e-41, -1.0202e-40, -5.0837e-40]],

         [[ 1.2739e-40, -8.6286e-41,  3.0404e-40],
          [-3.7339e-40, -9.7708e-41, -3.3124e-40],
          [ 1.1641e-40, -3.2689e-40, -4.0501e-40]]],


        [[[-1.3118e-40,  2.2157e-40,  9.0067e-41],
          [-1.6349e-40,  3.1303e-40, -2.1444e-40],
          [-3.2172e-40, -1.7047e-40, -4.6651e-40]],

         [[ 8.3791e-41,  2.5510e-40,  5.8999e-41],
          [ 3.7004e-40, -2.5158e-40,  1.4530e-40],
          [-2.1035e-41, -9.5316e-42,  2.1561e-40]],

         [[-4.4864e-40, -1.1128e-40,  2.6785e-40],
          [ 4.5928e-41,  4.4030e-41, -5.1687e-40],
          [ 2.8765e-40,  2.8503e-40, -5.5491e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6738]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0303]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 114 | Batch_idx: 0 |  Loss: (0.1626) | Acc: (95.00%) (122/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1787) | Acc: (94.00%) (1330/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1801) | Acc: (94.00%) (2530/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.2120) | Acc: (93.00%) (3691/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.2233) | Acc: (92.00%) (4868/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.2373) | Acc: (92.00%) (6026/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.2486) | Acc: (91.00%) (7171/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.2567) | Acc: (91.00%) (8320/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.2626) | Acc: (91.00%) (9471/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.2722) | Acc: (91.00%) (10603/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.2773) | Acc: (90.00%) (11747/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.2779) | Acc: (90.00%) (12905/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.2785) | Acc: (90.00%) (14068/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.2783) | Acc: (90.00%) (15235/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.2804) | Acc: (90.00%) (16388/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.2794) | Acc: (90.00%) (17557/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.2789) | Acc: (90.00%) (18713/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.2771) | Acc: (90.00%) (19892/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.2774) | Acc: (90.00%) (21048/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.2779) | Acc: (90.00%) (22201/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.2757) | Acc: (90.00%) (23373/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.2752) | Acc: (90.00%) (24546/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.2752) | Acc: (90.00%) (25706/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.2748) | Acc: (90.00%) (26873/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.2751) | Acc: (90.00%) (28023/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.2761) | Acc: (90.00%) (29176/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.2768) | Acc: (90.00%) (30315/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.2772) | Acc: (90.00%) (31461/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.2768) | Acc: (90.00%) (32624/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.2761) | Acc: (90.00%) (33790/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.2745) | Acc: (90.00%) (34970/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.2734) | Acc: (90.00%) (36160/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.2732) | Acc: (90.00%) (37316/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.2722) | Acc: (90.00%) (38491/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.2729) | Acc: (90.00%) (39652/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.2722) | Acc: (90.00%) (40814/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.2723) | Acc: (90.00%) (41967/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.2712) | Acc: (90.00%) (43144/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.2703) | Acc: (90.00%) (44320/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.2705) | Acc: (90.00%) (45439/50000)
# TEST : Loss: (0.3549) | Acc: (88.00%) (8866/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2950e-01,  3.4380e-01, -1.4374e-01],
          [-5.1149e-02,  2.0894e-02, -8.8536e-02],
          [ 6.0757e-02, -2.4228e-01,  2.7147e-01]],

         [[-1.4131e-01,  4.7831e-01,  1.0537e-01],
          [-1.5608e-02, -1.1254e-02, -1.7968e-01],
          [ 6.2787e-02, -4.1103e-01, -1.2289e-02]],

         [[-1.4929e-01,  2.7331e-01, -1.3730e-01],
          [ 4.6462e-02, -1.6745e-01, -1.4102e-01],
          [ 1.4080e-01, -1.3706e-01,  2.0586e-01]]],


        [[[-1.8521e-01, -3.9273e-01, -2.3071e-01],
          [-9.0945e-02,  2.3296e-01,  1.8708e-01],
          [ 2.0093e-01,  1.6526e-01,  2.5020e-01]],

         [[-2.6608e-01, -3.2221e-01, -2.1461e-01],
          [-1.2749e-01,  1.5762e-01,  2.1987e-01],
          [ 2.6603e-01,  1.0759e-01,  1.5431e-01]],

         [[-1.5597e-01, -3.4252e-02, -2.3649e-01],
          [ 6.3338e-02,  2.1793e-01, -5.6503e-02],
          [-6.6482e-03,  7.9639e-02,  5.7178e-02]]],


        [[[-1.1018e-01,  2.6635e-01,  9.9019e-02],
          [ 1.7837e-01,  2.0270e-01, -6.0656e-02],
          [-2.3070e-01, -6.0701e-02, -3.1305e-01]],

         [[ 5.5243e-02,  1.4163e-01,  3.3050e-02],
          [ 1.1524e-01,  2.7964e-01,  6.5596e-02],
          [-1.3018e-01, -1.0855e-01, -4.0726e-01]],

         [[-5.5419e-02,  1.5594e-01,  2.0526e-01],
          [ 7.1286e-02,  2.8102e-01,  1.0111e-01],
          [-2.3626e-01, -1.9959e-01, -2.8628e-01]]],


        ...,


        [[[-7.2562e-02, -1.0761e-01,  2.6360e-02],
          [ 7.9221e-02, -3.4033e-01, -1.7134e-01],
          [ 1.4933e-01, -5.9447e-02,  8.7326e-02]],

         [[ 1.5435e-01, -3.8226e-02, -4.9985e-03],
          [-5.5141e-02, -3.9332e-01, -2.5227e-01],
          [ 1.1843e-01, -2.0798e-03, -6.5748e-03]],

         [[ 2.1541e-01,  2.3898e-02,  7.8796e-02],
          [ 1.1394e-02, -2.5523e-01, -2.3701e-01],
          [ 9.0916e-02, -1.1218e-01, -1.1574e-01]]],


        [[[-3.9413e-40, -2.3568e-40, -4.6135e-40],
          [-2.4039e-40,  2.6509e-40,  9.2570e-41],
          [-2.8739e-40,  2.3861e-40,  8.2852e-41]],

         [[-3.3002e-40, -1.0537e-40, -3.2569e-41],
          [-1.3400e-40, -4.5744e-40,  2.4622e-40],
          [ 3.1895e-40,  3.7905e-41, -3.6857e-40]],

         [[-4.3208e-40,  1.9345e-40,  3.0414e-40],
          [-2.3363e-40, -5.1754e-40, -5.1498e-41],
          [-4.4330e-40, -4.7071e-41,  1.5465e-40]]],


        [[[ 1.0610e-40, -1.4324e-41,  9.3210e-41],
          [-4.5368e-41,  5.6322e-40,  2.2076e-41],
          [-5.7542e-40, -2.9686e-40, -2.3346e-40]],

         [[-3.6937e-41,  1.3559e-40, -1.9480e-40],
          [ 1.3007e-40, -7.8585e-42,  2.1293e-41],
          [ 2.2934e-40, -2.6073e-40,  2.2063e-40]],

         [[-4.5920e-40, -3.6545e-40,  1.6998e-41],
          [-2.0155e-40,  2.9386e-40, -1.4990e-40],
          [ 4.6596e-41,  4.3046e-41, -3.0823e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0273, -0.0484, -0.0570],
          [-0.0140, -0.0356, -0.0482],
          [-0.0111, -0.0391, -0.0604]],

         [[-0.0400, -0.0492, -0.0669],
          [-0.0221, -0.0388, -0.0623],
          [-0.0204, -0.0451, -0.0716]],

         [[-0.0404, -0.0438, -0.0631],
          [-0.0236, -0.0327, -0.0573],
          [-0.0204, -0.0400, -0.0732]]],


        [[[ 0.0544,  0.0738,  0.0874],
          [ 0.0428,  0.0690,  0.0800],
          [ 0.0531,  0.0724,  0.0779]],

         [[ 0.0449,  0.0558,  0.0639],
          [ 0.0316,  0.0506,  0.0552],
          [ 0.0402,  0.0542,  0.0547]],

         [[ 0.0420,  0.0439,  0.0496],
          [ 0.0255,  0.0363,  0.0383],
          [ 0.0222,  0.0349,  0.0361]]],


        [[[-0.0260, -0.0275, -0.0208],
          [-0.0155, -0.0182, -0.0131],
          [-0.0230, -0.0208, -0.0119]],

         [[-0.0338, -0.0364, -0.0245],
          [-0.0213, -0.0234, -0.0192],
          [-0.0318, -0.0304, -0.0277]],

         [[-0.0349, -0.0362, -0.0225],
          [-0.0164, -0.0164, -0.0127],
          [-0.0233, -0.0237, -0.0230]]],


        ...,


        [[[-0.0473, -0.0288, -0.0315],
          [-0.0383, -0.0142, -0.0133],
          [-0.0350, -0.0123, -0.0161]],

         [[-0.0451, -0.0236, -0.0284],
          [-0.0356, -0.0118, -0.0151],
          [-0.0357, -0.0159, -0.0240]],

         [[-0.0266, -0.0065, -0.0135],
          [-0.0189,  0.0005, -0.0072],
          [-0.0207, -0.0060, -0.0194]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6739]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 115 | Batch_idx: 0 |  Loss: (0.2211) | Acc: (93.00%) (120/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.2077) | Acc: (93.00%) (1314/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.2102) | Acc: (92.00%) (2498/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.2136) | Acc: (92.00%) (3678/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.2115) | Acc: (92.00%) (4863/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.2113) | Acc: (92.00%) (6044/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.2070) | Acc: (92.00%) (7246/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.2100) | Acc: (92.00%) (8422/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.2124) | Acc: (92.00%) (9606/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.2117) | Acc: (92.00%) (10794/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.2125) | Acc: (92.00%) (11974/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.2144) | Acc: (92.00%) (13160/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.2134) | Acc: (92.00%) (14346/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.2140) | Acc: (92.00%) (15534/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.2138) | Acc: (92.00%) (16716/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.2149) | Acc: (92.00%) (17899/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.2185) | Acc: (92.00%) (19061/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.2186) | Acc: (92.00%) (20250/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.2189) | Acc: (92.00%) (21426/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.2177) | Acc: (92.00%) (22616/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.2184) | Acc: (92.00%) (23797/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.2197) | Acc: (92.00%) (24979/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.2203) | Acc: (92.00%) (26152/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.2201) | Acc: (92.00%) (27336/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.2203) | Acc: (92.00%) (28512/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.2194) | Acc: (92.00%) (29701/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.2185) | Acc: (92.00%) (30899/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.2177) | Acc: (92.00%) (32088/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.2178) | Acc: (92.00%) (33259/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.2186) | Acc: (92.00%) (34435/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.2198) | Acc: (92.00%) (35600/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.2201) | Acc: (92.00%) (36773/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.2203) | Acc: (92.00%) (37954/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.2204) | Acc: (92.00%) (39137/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.2206) | Acc: (92.00%) (40311/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.2209) | Acc: (92.00%) (41488/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.2213) | Acc: (92.00%) (42659/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.2210) | Acc: (92.00%) (43847/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.2207) | Acc: (92.00%) (45031/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.2208) | Acc: (92.00%) (46173/50000)
# TEST : Loss: (0.3138) | Acc: (90.00%) (9005/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3908e-01,  3.4617e-01, -1.4732e-01],
          [-4.9690e-02,  2.1301e-02, -8.8758e-02],
          [ 7.0855e-02, -2.3430e-01,  2.8190e-01]],

         [[-1.4319e-01,  4.8605e-01,  1.0673e-01],
          [-1.0717e-02, -1.0598e-02, -1.7607e-01],
          [ 7.8142e-02, -3.9720e-01,  3.1018e-03]],

         [[-1.4582e-01,  2.8267e-01, -1.3427e-01],
          [ 5.5732e-02, -1.5768e-01, -1.3558e-01],
          [ 1.6420e-01, -1.0656e-01,  2.2827e-01]]],


        [[[-1.9306e-01, -4.0430e-01, -2.4179e-01],
          [-9.8117e-02,  2.2326e-01,  1.7682e-01],
          [ 1.9364e-01,  1.6095e-01,  2.4802e-01]],

         [[-2.6995e-01, -3.2762e-01, -2.1879e-01],
          [-1.2948e-01,  1.5512e-01,  2.1673e-01],
          [ 2.6753e-01,  1.1214e-01,  1.6008e-01]],

         [[-1.4902e-01, -2.7637e-02, -2.2659e-01],
          [ 6.7118e-02,  2.2267e-01, -4.8353e-02],
          [-2.2885e-03,  8.6642e-02,  6.8889e-02]]],


        [[[-1.1103e-01,  2.6897e-01,  1.0203e-01],
          [ 1.7240e-01,  2.0081e-01, -5.9680e-02],
          [-2.3869e-01, -6.8757e-02, -3.1784e-01]],

         [[ 5.2404e-02,  1.4120e-01,  3.2155e-02],
          [ 1.0842e-01,  2.7617e-01,  6.5173e-02],
          [-1.4179e-01, -1.1887e-01, -4.1296e-01]],

         [[-5.7340e-02,  1.5638e-01,  2.0534e-01],
          [ 6.6822e-02,  2.8072e-01,  1.0582e-01],
          [-2.4360e-01, -2.0277e-01, -2.8315e-01]]],


        ...,


        [[[-8.1732e-02, -1.0964e-01,  2.7664e-02],
          [ 6.7138e-02, -3.5710e-01, -1.7807e-01],
          [ 1.3751e-01, -7.5098e-02,  7.6147e-02]],

         [[ 1.4421e-01, -4.3090e-02, -3.4372e-03],
          [-7.2892e-02, -4.2352e-01, -2.6572e-01],
          [ 1.0281e-01, -2.1881e-02, -1.8146e-02]],

         [[ 2.2295e-01,  4.3228e-02,  1.0040e-01],
          [ 1.7149e-02, -2.3826e-01, -2.1316e-01],
          [ 9.4894e-02, -1.0357e-01, -1.0190e-01]]],


        [[[ 1.6537e-40,  4.4093e-41, -6.0141e-40],
          [-2.4048e-40, -1.4754e-41, -4.6721e-40],
          [-4.2744e-40,  9.8702e-41,  2.2286e-40]],

         [[-5.0297e-41, -1.0540e-40, -1.7251e-40],
          [ 2.8585e-40, -5.9751e-40,  1.0632e-40],
          [ 3.1902e-40,  1.7790e-40,  1.9127e-40]],

         [[-5.7215e-40,  3.3343e-40,  2.4349e-41],
          [ 1.8617e-40, -3.7772e-40,  2.2843e-40],
          [-5.8337e-40,  2.3289e-40,  5.7462e-40]]],


        [[[ 4.8031e-40, -2.6295e-40, -2.9891e-41],
          [ 7.9078e-41,  3.3029e-40,  2.7117e-40],
          [-3.3730e-40, -1.7840e-40,  5.1383e-40]],

         [[-1.6332e-40, -3.7280e-40, -3.2760e-40],
          [-3.7526e-40,  2.4658e-40, -1.0750e-40],
          [ 2.3415e-40, -2.6543e-40, -3.3449e-41]],

         [[-8.7204e-41, -2.4438e-40, -2.4267e-40],
          [ 4.7577e-41,  4.5213e-41, -4.0908e-40],
          [ 4.6983e-41,  2.9679e-40,  4.5501e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0303,  0.0171,  0.0124],
          [ 0.0261,  0.0179,  0.0139],
          [ 0.0211,  0.0202,  0.0226]],

         [[ 0.0295,  0.0148,  0.0082],
          [ 0.0294,  0.0196,  0.0122],
          [ 0.0271,  0.0203,  0.0225]],

         [[ 0.0244,  0.0179,  0.0088],
          [ 0.0243,  0.0200,  0.0115],
          [ 0.0224,  0.0172,  0.0214]]],


        [[[ 0.0173,  0.0138,  0.0201],
          [ 0.0200,  0.0162,  0.0192],
          [ 0.0231,  0.0186,  0.0143]],

         [[ 0.0161,  0.0128,  0.0170],
          [ 0.0176,  0.0134,  0.0154],
          [ 0.0185,  0.0148,  0.0103]],

         [[ 0.0102,  0.0078,  0.0116],
          [ 0.0111,  0.0076,  0.0093],
          [ 0.0122,  0.0084,  0.0034]]],


        [[[ 0.0016,  0.0126,  0.0041],
          [ 0.0004,  0.0095,  0.0035],
          [ 0.0059,  0.0086,  0.0015]],

         [[ 0.0027,  0.0160,  0.0088],
          [ 0.0030,  0.0145,  0.0100],
          [ 0.0115,  0.0167,  0.0109]],

         [[ 0.0063,  0.0177,  0.0091],
          [ 0.0081,  0.0186,  0.0129],
          [ 0.0178,  0.0232,  0.0172]]],


        ...,


        [[[-0.0022, -0.0067, -0.0013],
          [ 0.0039,  0.0004,  0.0062],
          [ 0.0056,  0.0022,  0.0058]],

         [[-0.0091, -0.0125, -0.0070],
          [-0.0018, -0.0044,  0.0013],
          [ 0.0006, -0.0024,  0.0011]],

         [[-0.0120, -0.0146, -0.0078],
          [-0.0058, -0.0076, -0.0003],
          [-0.0031, -0.0054, -0.0008]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6723]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 116 | Batch_idx: 0 |  Loss: (0.2678) | Acc: (92.00%) (118/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1912) | Acc: (94.00%) (1325/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1771) | Acc: (94.00%) (2529/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1758) | Acc: (94.00%) (3735/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1892) | Acc: (93.00%) (4913/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1864) | Acc: (93.00%) (6123/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1897) | Acc: (93.00%) (7311/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1864) | Acc: (93.00%) (8516/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1856) | Acc: (93.00%) (9721/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1842) | Acc: (93.00%) (10932/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1844) | Acc: (93.00%) (12132/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.1830) | Acc: (93.00%) (13345/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.1843) | Acc: (93.00%) (14541/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.1840) | Acc: (93.00%) (15742/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.1860) | Acc: (93.00%) (16926/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.1856) | Acc: (93.00%) (18131/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.1864) | Acc: (93.00%) (19330/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.1873) | Acc: (93.00%) (20523/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1872) | Acc: (93.00%) (21722/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1902) | Acc: (93.00%) (22893/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1912) | Acc: (93.00%) (24086/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1930) | Acc: (93.00%) (25264/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1931) | Acc: (93.00%) (26456/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1930) | Acc: (93.00%) (27643/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1933) | Acc: (93.00%) (28831/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1924) | Acc: (93.00%) (30037/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1926) | Acc: (93.00%) (31236/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1927) | Acc: (93.00%) (32435/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1944) | Acc: (93.00%) (33610/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1953) | Acc: (93.00%) (34794/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1947) | Acc: (93.00%) (35998/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1948) | Acc: (93.00%) (37189/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1945) | Acc: (93.00%) (38391/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1942) | Acc: (93.00%) (39594/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1943) | Acc: (93.00%) (40793/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1945) | Acc: (93.00%) (41976/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1946) | Acc: (93.00%) (43165/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1954) | Acc: (93.00%) (44347/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1952) | Acc: (93.00%) (45549/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1956) | Acc: (93.00%) (46691/50000)
# TEST : Loss: (0.3167) | Acc: (90.00%) (9038/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2046e-01,  3.5495e-01, -1.5613e-01],
          [-4.3486e-02,  2.6721e-02, -8.8612e-02],
          [ 7.2526e-02, -2.2716e-01,  2.8586e-01]],

         [[-1.2810e-01,  4.9473e-01,  9.4298e-02],
          [-4.6177e-03, -1.0937e-02, -1.8145e-01],
          [ 8.3916e-02, -3.9576e-01,  5.7706e-03]],

         [[-1.3808e-01,  2.8319e-01, -1.4824e-01],
          [ 5.6902e-02, -1.5983e-01, -1.4166e-01],
          [ 1.6384e-01, -1.0188e-01,  2.3107e-01]]],


        [[[-1.8939e-01, -3.9866e-01, -2.3885e-01],
          [-8.9034e-02,  2.3153e-01,  1.8034e-01],
          [ 2.0230e-01,  1.6678e-01,  2.4932e-01]],

         [[-2.6822e-01, -3.2364e-01, -2.1732e-01],
          [-1.2158e-01,  1.6372e-01,  2.2001e-01],
          [ 2.7277e-01,  1.1588e-01,  1.6104e-01]],

         [[-1.4956e-01, -2.6058e-02, -2.2695e-01],
          [ 7.4357e-02,  2.3002e-01, -4.6796e-02],
          [ 3.5089e-03,  8.9651e-02,  6.6838e-02]]],


        [[[-1.0202e-01,  2.7362e-01,  1.0568e-01],
          [ 1.8098e-01,  2.0532e-01, -5.9307e-02],
          [-2.3286e-01, -6.3320e-02, -3.1703e-01]],

         [[ 6.0717e-02,  1.4418e-01,  3.3431e-02],
          [ 1.1240e-01,  2.7533e-01,  6.0492e-02],
          [-1.3998e-01, -1.1970e-01, -4.1836e-01]],

         [[-4.6905e-02,  1.6066e-01,  2.0970e-01],
          [ 7.3847e-02,  2.8002e-01,  1.0374e-01],
          [-2.3830e-01, -2.0086e-01, -2.8239e-01]]],


        ...,


        [[[-8.8467e-02, -1.1368e-01,  2.6910e-02],
          [ 6.5899e-02, -3.5389e-01, -1.6203e-01],
          [ 1.4279e-01, -6.5580e-02,  8.5086e-02]],

         [[ 1.3483e-01, -4.7970e-02, -6.1555e-03],
          [-7.6902e-02, -4.3069e-01, -2.6075e-01],
          [ 1.0461e-01, -1.9236e-02, -1.7019e-02]],

         [[ 2.1688e-01,  3.6871e-02,  8.7524e-02],
          [ 1.1912e-02, -2.5068e-01, -2.2794e-01],
          [ 9.1689e-02, -1.1295e-01, -1.2011e-01]]],


        [[[ 5.8526e-40,  3.2401e-40, -1.8167e-40],
          [ 3.9414e-41, -2.9473e-40, -6.0728e-40],
          [-1.4751e-40, -1.8129e-40,  8.2927e-41]],

         [[ 2.2962e-40,  3.4539e-41, -1.7255e-40],
          [ 4.2590e-40, -1.7761e-40, -1.7365e-40],
          [ 3.9057e-41,  1.7792e-40,  6.1133e-40]],

         [[-1.5240e-40,  1.9353e-40, -2.5560e-40],
          [ 4.6619e-40,  1.8220e-40,  2.2848e-40],
          [-1.6350e-40,  2.3294e-40,  4.3472e-40]]],


        [[[ 3.6399e-40, -2.6802e-40, -1.5804e-40],
          [ 8.1588e-41, -1.6761e-40,  2.7618e-40],
          [ 2.9563e-40,  7.3340e-41,  2.6772e-40]],

         [[-1.6556e-40, -5.0866e-40, -2.0088e-40],
          [-5.1083e-40,  2.5081e-40, -1.0937e-40],
          [-2.1088e-41, -9.4896e-42, -2.9543e-40]],

         [[ 5.5708e-40,  1.4183e-40, -2.4610e-40],
          [-2.1055e-40, -2.1286e-40, -5.4520e-40],
          [ 3.0481e-40,  3.0112e-40, -1.8841e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0136, -0.0122, -0.0196],
          [-0.0106, -0.0020, -0.0124],
          [ 0.0078,  0.0026, -0.0078]],

         [[-0.0065, -0.0037, -0.0129],
          [-0.0064,  0.0056, -0.0092],
          [ 0.0084,  0.0063, -0.0016]],

         [[ 0.0098,  0.0159,  0.0081],
          [ 0.0114,  0.0235,  0.0087],
          [ 0.0238,  0.0237,  0.0161]]],


        [[[-0.0245, -0.0287, -0.0325],
          [-0.0216, -0.0286, -0.0312],
          [-0.0167, -0.0237, -0.0308]],

         [[-0.0230, -0.0300, -0.0347],
          [-0.0222, -0.0307, -0.0324],
          [-0.0140, -0.0238, -0.0324]],

         [[-0.0272, -0.0331, -0.0351],
          [-0.0296, -0.0357, -0.0343],
          [-0.0185, -0.0264, -0.0327]]],


        [[[ 0.0183,  0.0144,  0.0197],
          [ 0.0073,  0.0115,  0.0198],
          [ 0.0003,  0.0099,  0.0163]],

         [[ 0.0016, -0.0038,  0.0010],
          [-0.0058, -0.0023,  0.0035],
          [-0.0113, -0.0014,  0.0029]],

         [[-0.0182, -0.0235, -0.0161],
          [-0.0222, -0.0191, -0.0125],
          [-0.0280, -0.0192, -0.0147]]],


        ...,


        [[[-0.0071, -0.0066,  0.0022],
          [-0.0035, -0.0011,  0.0082],
          [-0.0034, -0.0055,  0.0022]],

         [[-0.0106, -0.0106, -0.0020],
          [-0.0066, -0.0046,  0.0039],
          [-0.0056, -0.0087, -0.0020]],

         [[-0.0098, -0.0112, -0.0043],
          [-0.0062, -0.0057,  0.0005],
          [-0.0054, -0.0092, -0.0049]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6704]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 117 | Batch_idx: 0 |  Loss: (0.1509) | Acc: (92.00%) (118/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1955) | Acc: (93.00%) (1318/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1960) | Acc: (93.00%) (2513/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.2166) | Acc: (92.00%) (3689/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.2140) | Acc: (92.00%) (4880/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.2116) | Acc: (93.00%) (6073/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.2096) | Acc: (93.00%) (7264/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.2038) | Acc: (93.00%) (8471/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.2034) | Acc: (93.00%) (9663/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.2020) | Acc: (93.00%) (10855/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.2005) | Acc: (93.00%) (12056/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.1976) | Acc: (93.00%) (13262/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1969) | Acc: (93.00%) (14468/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1962) | Acc: (93.00%) (15673/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1948) | Acc: (93.00%) (16875/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1941) | Acc: (93.00%) (18067/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1948) | Acc: (93.00%) (19247/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1924) | Acc: (93.00%) (20468/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1914) | Acc: (93.00%) (21668/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1906) | Acc: (93.00%) (22869/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1900) | Acc: (93.00%) (24070/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1891) | Acc: (93.00%) (25279/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1891) | Acc: (93.00%) (26472/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1881) | Acc: (93.00%) (27686/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1874) | Acc: (93.00%) (28890/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1860) | Acc: (93.00%) (30102/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1851) | Acc: (93.00%) (31315/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1836) | Acc: (93.00%) (32531/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1826) | Acc: (93.00%) (33750/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1818) | Acc: (93.00%) (34961/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1822) | Acc: (93.00%) (36158/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1816) | Acc: (93.00%) (37377/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1813) | Acc: (93.00%) (38581/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1807) | Acc: (93.00%) (39796/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1806) | Acc: (93.00%) (40994/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1799) | Acc: (93.00%) (42207/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1800) | Acc: (93.00%) (43414/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1797) | Acc: (93.00%) (44615/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1790) | Acc: (93.00%) (45822/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1784) | Acc: (93.00%) (46984/50000)
# TEST : Loss: (0.2881) | Acc: (90.00%) (9092/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1764e-01,  3.5623e-01, -1.5361e-01],
          [-4.0803e-02,  2.8240e-02, -8.7079e-02],
          [ 7.2714e-02, -2.2697e-01,  2.8512e-01]],

         [[-1.2404e-01,  4.9652e-01,  9.7430e-02],
          [-7.8842e-04, -8.5592e-03, -1.7861e-01],
          [ 8.5115e-02, -3.9423e-01,  6.6421e-03]],

         [[-1.3349e-01,  2.8535e-01, -1.4451e-01],
          [ 6.0962e-02, -1.5625e-01, -1.3831e-01],
          [ 1.6575e-01, -9.9452e-02,  2.3206e-01]]],


        [[[-1.8790e-01, -3.9726e-01, -2.3796e-01],
          [-8.8601e-02,  2.3141e-01,  1.8036e-01],
          [ 2.0218e-01,  1.6766e-01,  2.5090e-01]],

         [[-2.6853e-01, -3.2407e-01, -2.1804e-01],
          [-1.2302e-01,  1.6192e-01,  2.1828e-01],
          [ 2.7036e-01,  1.1494e-01,  1.6112e-01]],

         [[-1.5153e-01, -2.8561e-02, -2.2889e-01],
          [ 7.1163e-02,  2.2644e-01, -4.9486e-02],
          [ 1.3055e-04,  8.6891e-02,  6.5152e-02]]],


        [[[-1.0598e-01,  2.6902e-01,  1.0097e-01],
          [ 1.7800e-01,  2.0167e-01, -6.3593e-02],
          [-2.3515e-01, -6.6925e-02, -3.2091e-01]],

         [[ 5.9484e-02,  1.4276e-01,  3.1501e-02],
          [ 1.1244e-01,  2.7439e-01,  5.8701e-02],
          [-1.3948e-01, -1.2036e-01, -4.1926e-01]],

         [[-4.7357e-02,  1.5959e-01,  2.0792e-01],
          [ 7.4378e-02,  2.7930e-01,  1.0246e-01],
          [-2.3717e-01, -2.0087e-01, -2.8283e-01]]],


        ...,


        [[[-8.6548e-02, -1.1132e-01,  2.4419e-02],
          [ 6.6411e-02, -3.4948e-01, -1.6428e-01],
          [ 1.4368e-01, -6.2542e-02,  8.4749e-02]],

         [[ 1.3534e-01, -4.5882e-02, -8.3090e-03],
          [-7.6473e-02, -4.2461e-01, -2.6175e-01],
          [ 1.0474e-01, -1.6724e-02, -1.6665e-02]],

         [[ 2.1692e-01,  3.8562e-02,  8.5815e-02],
          [ 1.1628e-02, -2.4761e-01, -2.2790e-01],
          [ 9.1480e-02, -1.1033e-01, -1.1879e-01]]],


        [[[ 4.4540e-40,  3.2408e-40,  3.7827e-40],
          [ 3.1942e-40, -2.9478e-40, -1.8735e-40],
          [ 2.7253e-40, -3.2135e-40, -1.9711e-40]],

         [[ 2.2968e-40,  1.7453e-40, -3.2572e-41],
          [ 1.4595e-40,  3.8246e-40, -3.1368e-40],
          [-2.4099e-40,  3.7901e-41,  4.7137e-40]],

         [[ 4.0754e-40, -8.6440e-41, -2.5566e-40],
          [ 3.2625e-40,  6.0228e-40, -5.1509e-41],
          [ 3.9655e-40, -4.7082e-41, -1.2531e-40]]],


        [[[-1.4433e-40, -1.4297e-41, -1.6001e-40],
          [-4.5388e-41, -5.5616e-40,  2.2068e-41],
          [-4.7903e-40, -1.8401e-40, -2.4758e-40]],

         [[-3.6928e-41, -1.2114e-40, -2.0323e-40],
          [-1.2530e-40, -7.8851e-42,  2.1314e-41],
          [-2.8392e-40,  2.5383e-40, -2.9849e-40]],

         [[-2.2120e-40,  4.0698e-40,  1.6999e-41],
          [-2.1421e-40, -2.1652e-40, -1.5588e-40],
          [ 3.0853e-40,  4.3039e-41,  2.0474e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5994]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0027]], device='cuda:0')

Epoch: 118 | Batch_idx: 0 |  Loss: (0.1407) | Acc: (92.00%) (119/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1760) | Acc: (94.00%) (1325/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1693) | Acc: (94.00%) (2535/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1699) | Acc: (94.00%) (3743/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1691) | Acc: (94.00%) (4950/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1685) | Acc: (94.00%) (6158/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1694) | Acc: (94.00%) (7358/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1671) | Acc: (94.00%) (8570/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1691) | Acc: (94.00%) (9773/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1688) | Acc: (94.00%) (10977/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1688) | Acc: (94.00%) (12193/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1698) | Acc: (94.00%) (13390/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1662) | Acc: (94.00%) (14617/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1662) | Acc: (94.00%) (15825/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1667) | Acc: (94.00%) (17038/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1663) | Acc: (94.00%) (18246/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1668) | Acc: (94.00%) (19447/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1645) | Acc: (94.00%) (20675/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1638) | Acc: (94.00%) (21891/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1644) | Acc: (94.00%) (23096/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1649) | Acc: (94.00%) (24296/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1638) | Acc: (94.00%) (25524/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1627) | Acc: (94.00%) (26743/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1627) | Acc: (94.00%) (27951/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1636) | Acc: (94.00%) (29154/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1629) | Acc: (94.00%) (30361/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1635) | Acc: (94.00%) (31564/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1633) | Acc: (94.00%) (32771/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1635) | Acc: (94.00%) (33973/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1636) | Acc: (94.00%) (35177/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1626) | Acc: (94.00%) (36400/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1623) | Acc: (94.00%) (37605/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1621) | Acc: (94.00%) (38816/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1623) | Acc: (94.00%) (40021/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1632) | Acc: (94.00%) (41222/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1628) | Acc: (94.00%) (42431/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1628) | Acc: (94.00%) (43642/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1630) | Acc: (94.00%) (44849/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1628) | Acc: (94.00%) (46055/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1629) | Acc: (94.00%) (47226/50000)
# TEST : Loss: (0.2816) | Acc: (91.00%) (9105/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1732e-01,  3.5522e-01, -1.5319e-01],
          [-4.0692e-02,  2.8162e-02, -8.6843e-02],
          [ 7.2518e-02, -2.2632e-01,  2.8436e-01]],

         [[-1.2369e-01,  4.9505e-01,  9.7155e-02],
          [-7.8621e-04, -8.5346e-03, -1.7812e-01],
          [ 8.4876e-02, -3.9304e-01,  6.6240e-03]],

         [[-1.3310e-01,  2.8449e-01, -1.4409e-01],
          [ 6.0786e-02, -1.5578e-01, -1.3791e-01],
          [ 1.6528e-01, -9.9148e-02,  2.3140e-01]]],


        [[[-1.8745e-01, -3.9633e-01, -2.3741e-01],
          [-8.8390e-02,  2.3086e-01,  1.7993e-01],
          [ 2.0168e-01,  1.6724e-01,  2.5027e-01]],

         [[-2.6787e-01, -3.2328e-01, -2.1750e-01],
          [-1.2272e-01,  1.6152e-01,  2.1774e-01],
          [ 2.6966e-01,  1.1464e-01,  1.6070e-01]],

         [[-1.5114e-01, -2.8487e-02, -2.2830e-01],
          [ 7.0982e-02,  2.2587e-01, -4.9359e-02],
          [ 1.3021e-04,  8.6664e-02,  6.4980e-02]]],


        [[[-1.0576e-01,  2.6846e-01,  1.0076e-01],
          [ 1.7764e-01,  2.0126e-01, -6.3462e-02],
          [-2.3467e-01, -6.6787e-02, -3.2024e-01]],

         [[ 5.9354e-02,  1.4245e-01,  3.1433e-02],
          [ 1.1220e-01,  2.7381e-01,  5.8576e-02],
          [-1.3918e-01, -1.2010e-01, -4.1835e-01]],

         [[-4.7249e-02,  1.5923e-01,  2.0744e-01],
          [ 7.4212e-02,  2.7868e-01,  1.0222e-01],
          [-2.3663e-01, -2.0042e-01, -2.8217e-01]]],


        ...,


        [[[-8.6137e-02, -1.1060e-01,  2.4263e-02],
          [ 6.6034e-02, -3.4602e-01, -1.6264e-01],
          [ 1.4299e-01, -6.2137e-02,  8.4183e-02]],

         [[ 1.3467e-01, -4.5552e-02, -8.2508e-03],
          [-7.5999e-02, -4.1910e-01, -2.5851e-01],
          [ 1.0420e-01, -1.6600e-02, -1.6540e-02]],

         [[ 2.1584e-01,  3.8311e-02,  8.5264e-02],
          [ 1.1559e-02, -2.4537e-01, -2.2587e-01],
          [ 9.1003e-02, -1.0956e-01, -1.1796e-01]]],


        [[[-1.1456e-40,  4.4096e-41,  5.1834e-40],
          [ 3.1946e-40, -1.4756e-41,  3.7275e-40],
          [ 4.1261e-40, -1.8134e-40, -3.3717e-40]],

         [[-5.0297e-41,  1.7456e-40,  1.0745e-40],
          [-2.7413e-40,  5.2256e-40, -1.7368e-40],
          [-2.4103e-40, -1.0215e-40, -8.8781e-41]],

         [[ 5.4761e-40, -2.2647e-40,  2.4329e-41],
          [-9.3807e-41,  4.6232e-40, -3.3159e-40],
          [ 5.3665e-40, -3.2718e-40, -5.4546e-40]]],


        [[[-5.3810e-40,  2.4744e-40, -2.9892e-41],
          [-1.7635e-40,  2.1813e-40, -2.3994e-40],
          [-4.8566e-40, -3.1705e-40, -5.1411e-40]],

         [[ 9.5221e-41,  4.0912e-40, -2.0572e-40],
          [ 4.0314e-40, -2.7317e-40,  1.5491e-40],
          [-2.8685e-40,  2.5667e-40, -3.3418e-41]],

         [[-9.1736e-41,  2.7805e-40,  2.8542e-40],
          [ 4.7598e-41,  4.5230e-41,  3.7610e-40],
          [ 4.6977e-41, -2.2181e-40, -1.9236e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5971]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0049]], device='cuda:0')

Epoch: 119 | Batch_idx: 0 |  Loss: (0.1974) | Acc: (93.00%) (120/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1698) | Acc: (94.00%) (1334/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1469) | Acc: (95.00%) (2563/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1404) | Acc: (95.00%) (3792/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1466) | Acc: (95.00%) (5002/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1523) | Acc: (95.00%) (6207/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1554) | Acc: (94.00%) (7414/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1568) | Acc: (94.00%) (8620/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1565) | Acc: (94.00%) (9840/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1585) | Acc: (94.00%) (11042/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1607) | Acc: (94.00%) (12236/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1618) | Acc: (94.00%) (13435/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1613) | Acc: (94.00%) (14648/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1623) | Acc: (94.00%) (15860/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1630) | Acc: (94.00%) (17066/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1632) | Acc: (94.00%) (18266/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1642) | Acc: (94.00%) (19470/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1645) | Acc: (94.00%) (20676/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1653) | Acc: (94.00%) (21881/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1648) | Acc: (94.00%) (23095/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1651) | Acc: (94.00%) (24298/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1636) | Acc: (94.00%) (25524/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1635) | Acc: (94.00%) (26729/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1631) | Acc: (94.00%) (27949/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1623) | Acc: (94.00%) (29170/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1619) | Acc: (94.00%) (30388/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1612) | Acc: (94.00%) (31604/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1603) | Acc: (94.00%) (32822/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1599) | Acc: (94.00%) (34035/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1601) | Acc: (94.00%) (35235/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1599) | Acc: (94.00%) (36448/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1604) | Acc: (94.00%) (37653/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1601) | Acc: (94.00%) (38868/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1596) | Acc: (94.00%) (40081/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1588) | Acc: (94.00%) (41307/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1587) | Acc: (94.00%) (42519/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1588) | Acc: (94.00%) (43729/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1585) | Acc: (94.00%) (44957/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1586) | Acc: (94.00%) (46167/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1587) | Acc: (94.00%) (47329/50000)
# TEST : Loss: (0.2771) | Acc: (91.00%) (9109/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1693e-01,  3.5400e-01, -1.5267e-01],
          [-4.0558e-02,  2.8067e-02, -8.6556e-02],
          [ 7.2282e-02, -2.2554e-01,  2.8344e-01]],

         [[-1.2326e-01,  4.9328e-01,  9.6821e-02],
          [-7.8353e-04, -8.5048e-03, -1.7751e-01],
          [ 8.4586e-02, -3.9161e-01,  6.6020e-03]],

         [[-1.3262e-01,  2.8344e-01, -1.4357e-01],
          [ 6.0573e-02, -1.5522e-01, -1.3742e-01],
          [ 1.6469e-01, -9.8779e-02,  2.3061e-01]]],


        [[[-1.8691e-01, -3.9520e-01, -2.3673e-01],
          [-8.8133e-02,  2.3019e-01,  1.7941e-01],
          [ 2.0106e-01,  1.6673e-01,  2.4950e-01]],

         [[-2.6707e-01, -3.2231e-01, -2.1685e-01],
          [-1.2235e-01,  1.6103e-01,  2.1708e-01],
          [ 2.6881e-01,  1.1428e-01,  1.6019e-01]],

         [[-1.5066e-01, -2.8398e-02, -2.2759e-01],
          [ 7.0762e-02,  2.2517e-01, -4.9205e-02],
          [ 1.2979e-04,  8.6388e-02,  6.4773e-02]]],


        [[[-1.0549e-01,  2.6778e-01,  1.0051e-01],
          [ 1.7721e-01,  2.0077e-01, -6.3303e-02],
          [-2.3409e-01, -6.6621e-02, -3.1942e-01]],

         [[ 5.9196e-02,  1.4207e-01,  3.1350e-02],
          [ 1.1191e-01,  2.7311e-01,  5.8424e-02],
          [-1.3883e-01, -1.1979e-01, -4.1724e-01]],

         [[-4.7118e-02,  1.5879e-01,  2.0687e-01],
          [ 7.4011e-02,  2.7792e-01,  1.0194e-01],
          [-2.3599e-01, -1.9987e-01, -2.8138e-01]]],


        ...,


        [[[-8.5641e-02, -1.0973e-01,  2.4074e-02],
          [ 6.5579e-02, -3.4186e-01, -1.6067e-01],
          [ 1.4215e-01, -6.1648e-02,  8.3501e-02]],

         [[ 1.3385e-01, -4.5154e-02, -8.1805e-03],
          [-7.5427e-02, -4.1251e-01, -2.5461e-01],
          [ 1.0354e-01, -1.6450e-02, -1.6390e-02]],

         [[ 2.1453e-01,  3.8009e-02,  8.4598e-02],
          [ 1.1476e-02, -2.4267e-01, -2.2344e-01],
          [ 9.0426e-02, -1.0864e-01, -1.1696e-01]]],


        [[[-5.3466e-40, -2.3598e-40,  9.8305e-41],
          [ 3.9403e-41,  2.6534e-40,  5.1286e-40],
          [ 1.3254e-40,  9.8766e-41, -1.9714e-40]],

         [[-3.3036e-40,  3.4543e-41,  1.0747e-40],
          [-4.1422e-40,  1.0245e-40,  1.0642e-40],
          [ 3.9056e-41, -1.0216e-40, -5.0899e-40]],

         [[ 1.2758e-40, -8.6464e-41,  3.0442e-40],
          [-3.7392e-40, -9.7850e-41, -3.3161e-40],
          [ 1.1653e-40, -3.2720e-40, -4.0546e-40]]],


        [[[-4.1223e-40,  2.5055e-40,  1.0330e-40],
          [-1.7789e-40,  3.5319e-40, -2.4300e-40],
          [-2.2541e-40, -1.8726e-40, -2.5388e-40]],

         [[ 9.6570e-41,  5.4694e-40,  6.2296e-41],
          [ 5.4081e-40, -2.7572e-40,  1.5603e-40],
          [-2.1076e-41, -9.5176e-42,  2.3639e-40]],

         [[ 4.4223e-40, -1.2262e-40,  2.8744e-40],
          [ 3.1510e-40,  3.1270e-40,  5.1406e-40],
          [-2.2034e-40, -2.2442e-40,  2.0935e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5861]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0063]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1741) | Acc: (93.00%) (120/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1640) | Acc: (94.00%) (1333/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1909) | Acc: (93.00%) (2510/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.2038) | Acc: (92.00%) (3678/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.2216) | Acc: (92.00%) (4845/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.2410) | Acc: (91.00%) (5990/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.2513) | Acc: (91.00%) (7135/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.2593) | Acc: (91.00%) (8281/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.2677) | Acc: (90.00%) (9421/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.2748) | Acc: (90.00%) (10558/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.2830) | Acc: (90.00%) (11674/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.2849) | Acc: (90.00%) (12825/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.2855) | Acc: (90.00%) (13976/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.2870) | Acc: (90.00%) (15118/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.2868) | Acc: (90.00%) (16272/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.2868) | Acc: (90.00%) (17427/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.2882) | Acc: (90.00%) (18571/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.2893) | Acc: (90.00%) (19715/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.2866) | Acc: (90.00%) (20889/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.2867) | Acc: (90.00%) (22032/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.2858) | Acc: (90.00%) (23196/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.2848) | Acc: (90.00%) (24358/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.2838) | Acc: (90.00%) (25524/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.2826) | Acc: (90.00%) (26695/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.2825) | Acc: (90.00%) (27858/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.2811) | Acc: (90.00%) (29039/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.2804) | Acc: (90.00%) (30211/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.2804) | Acc: (90.00%) (31371/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.2786) | Acc: (90.00%) (32552/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.2771) | Acc: (90.00%) (33752/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.2765) | Acc: (90.00%) (34918/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.2754) | Acc: (90.00%) (36088/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.2739) | Acc: (90.00%) (37264/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.2726) | Acc: (90.00%) (38445/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.2720) | Acc: (90.00%) (39613/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.2713) | Acc: (90.00%) (40788/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.2704) | Acc: (90.00%) (41961/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.2699) | Acc: (90.00%) (43134/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.2697) | Acc: (90.00%) (44290/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.2700) | Acc: (90.00%) (45398/50000)
# TEST : Loss: (0.3546) | Acc: (88.00%) (8878/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2613e-01,  3.5700e-01, -1.6742e-01],
          [-4.6806e-02,  1.6676e-02, -9.5842e-02],
          [ 5.7953e-02, -2.3840e-01,  2.6982e-01]],

         [[-1.2477e-01,  5.0621e-01,  9.8119e-02],
          [ 1.0918e-04, -1.4411e-02, -1.7324e-01],
          [ 7.7990e-02, -4.0012e-01,  6.0555e-03]],

         [[-1.3626e-01,  2.9101e-01, -1.4415e-01],
          [ 5.8288e-02, -1.5921e-01, -1.3738e-01],
          [ 1.6396e-01, -1.0411e-01,  2.2337e-01]]],


        [[[-2.0086e-01, -4.0554e-01, -2.4361e-01],
          [-9.3026e-02,  2.2812e-01,  1.7337e-01],
          [ 1.9878e-01,  1.6702e-01,  2.4752e-01]],

         [[-2.7478e-01, -3.2700e-01, -2.2031e-01],
          [-1.2637e-01,  1.6169e-01,  2.1381e-01],
          [ 2.6778e-01,  1.1537e-01,  1.5672e-01]],

         [[-1.5182e-01, -2.8817e-02, -2.2870e-01],
          [ 7.1615e-02,  2.2959e-01, -4.7721e-02],
          [ 4.9764e-04,  8.9297e-02,  6.7089e-02]]],


        [[[-1.0336e-01,  2.7239e-01,  1.0453e-01],
          [ 1.8544e-01,  2.0650e-01, -5.9332e-02],
          [-2.3260e-01, -6.8792e-02, -3.2108e-01]],

         [[ 5.4871e-02,  1.4531e-01,  3.2253e-02],
          [ 1.1478e-01,  2.7927e-01,  6.2247e-02],
          [-1.4493e-01, -1.2208e-01, -4.1760e-01]],

         [[-5.9695e-02,  1.5314e-01,  2.0101e-01],
          [ 6.6740e-02,  2.7682e-01,  1.0259e-01],
          [-2.4803e-01, -2.0469e-01, -2.8577e-01]]],


        ...,


        [[[-8.1330e-02, -1.1996e-01,  1.9516e-02],
          [ 5.9755e-02, -3.6769e-01, -1.6104e-01],
          [ 1.2528e-01, -8.5639e-02,  7.0016e-02]],

         [[ 1.4762e-01, -5.1192e-02, -1.4394e-02],
          [-6.2920e-02, -4.2043e-01, -2.3881e-01],
          [ 1.0513e-01, -2.2273e-02, -1.4443e-02]],

         [[ 2.1133e-01,  2.4519e-02,  7.8072e-02],
          [ 7.8980e-03, -2.6086e-01, -2.2361e-01],
          [ 8.7240e-02, -1.1991e-01, -1.2269e-01]]],


        [[[-2.7115e-02, -4.5651e-02, -4.5581e-02],
          [-5.5588e-02, -6.2312e-02, -5.4930e-02],
          [-4.0364e-02, -4.9959e-02, -3.6906e-02]],

         [[-2.3010e-02, -4.3963e-02, -3.2273e-02],
          [-4.9090e-02, -6.7021e-02, -4.9673e-02],
          [-2.8256e-02, -4.7375e-02, -2.9492e-02]],

         [[ 8.6894e-04, -1.0012e-02, -2.6651e-03],
          [-1.5649e-02, -1.9277e-02, -1.1360e-02],
          [ 2.8224e-03, -5.5982e-03,  2.7789e-04]]],


        [[[ 1.1802e-40, -1.4311e-41,  1.0449e-40],
          [-4.5399e-41,  4.9070e-40,  2.2091e-41],
          [ 3.0906e-40,  7.9546e-41,  2.8056e-40]],

         [[-3.6914e-41,  1.4548e-40,  3.3417e-40],
          [ 1.4053e-40, -7.8739e-42,  2.1318e-41],
          [ 2.4922e-40, -2.8011e-40,  2.3818e-40]],

         [[ 5.8035e-40, -3.9428e-40,  1.6980e-41],
          [ 3.1728e-40,  3.1487e-40,  1.1153e-40],
          [-2.2255e-40,  4.3049e-41, -1.9477e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0057, -0.0047, -0.0074],
          [ 0.0394,  0.0180,  0.0076],
          [ 0.0440,  0.0218,  0.0256]],

         [[ 0.0128,  0.0015, -0.0056],
          [ 0.0444,  0.0238,  0.0077],
          [ 0.0510,  0.0299,  0.0332]],

         [[ 0.0245,  0.0166,  0.0096],
          [ 0.0509,  0.0312,  0.0222],
          [ 0.0542,  0.0362,  0.0425]]],


        [[[-0.0321, -0.0381, -0.0356],
          [-0.0344, -0.0397, -0.0316],
          [-0.0278, -0.0340, -0.0278]],

         [[-0.0199, -0.0260, -0.0214],
          [-0.0257, -0.0290, -0.0181],
          [-0.0218, -0.0266, -0.0184]],

         [[ 0.0114,  0.0071,  0.0128],
          [ 0.0052,  0.0043,  0.0166],
          [ 0.0088,  0.0053,  0.0137]]],


        [[[ 0.0188,  0.0178,  0.0172],
          [ 0.0071,  0.0105,  0.0034],
          [ 0.0091,  0.0139,  0.0075]],

         [[ 0.0058,  0.0022,  0.0049],
          [-0.0058, -0.0068, -0.0130],
          [-0.0020, -0.0006, -0.0061]],

         [[-0.0237, -0.0283, -0.0192],
          [-0.0301, -0.0309, -0.0316],
          [-0.0258, -0.0229, -0.0228]]],


        ...,


        [[[ 0.0167,  0.0133,  0.0097],
          [ 0.0086,  0.0063,  0.0009],
          [-0.0016, -0.0060, -0.0060]],

         [[ 0.0120,  0.0084,  0.0054],
          [ 0.0039,  0.0016, -0.0018],
          [-0.0035, -0.0065, -0.0045]],

         [[ 0.0113,  0.0077,  0.0027],
          [ 0.0046,  0.0016, -0.0033],
          [-0.0030, -0.0056, -0.0048]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.0000],
          [ 0.0000,  0.0000, -0.0000]],

         [[-0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5875]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 121 | Batch_idx: 0 |  Loss: (0.1392) | Acc: (95.00%) (122/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.2181) | Acc: (92.00%) (1304/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.2110) | Acc: (92.00%) (2494/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.2130) | Acc: (92.00%) (3679/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.2093) | Acc: (92.00%) (4869/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.2049) | Acc: (92.00%) (6071/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.2080) | Acc: (92.00%) (7253/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.2102) | Acc: (92.00%) (8432/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.2102) | Acc: (92.00%) (9625/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.2143) | Acc: (92.00%) (10802/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.2131) | Acc: (92.00%) (11989/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.2122) | Acc: (92.00%) (13176/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.2116) | Acc: (92.00%) (14364/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.2144) | Acc: (92.00%) (15528/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.2139) | Acc: (92.00%) (16715/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.2135) | Acc: (92.00%) (17903/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.2163) | Acc: (92.00%) (19082/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.2157) | Acc: (92.00%) (20276/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.2160) | Acc: (92.00%) (21453/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.2163) | Acc: (92.00%) (22638/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.2177) | Acc: (92.00%) (23815/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.2173) | Acc: (92.00%) (24996/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.2188) | Acc: (92.00%) (26158/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.2196) | Acc: (92.00%) (27335/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.2182) | Acc: (92.00%) (28540/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.2183) | Acc: (92.00%) (29714/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.2175) | Acc: (92.00%) (30898/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.2170) | Acc: (92.00%) (32092/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.2173) | Acc: (92.00%) (33277/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.2179) | Acc: (92.00%) (34454/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.2176) | Acc: (92.00%) (35641/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.2174) | Acc: (92.00%) (36823/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.2169) | Acc: (92.00%) (38021/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.2176) | Acc: (92.00%) (39184/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.2172) | Acc: (92.00%) (40372/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.2167) | Acc: (92.00%) (41561/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.2177) | Acc: (92.00%) (42735/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.2176) | Acc: (92.00%) (43912/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.2174) | Acc: (92.00%) (45098/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.2183) | Acc: (92.00%) (46213/50000)
# TEST : Loss: (0.3209) | Acc: (89.00%) (8998/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1371,  0.3557, -0.1769],
          [-0.0502,  0.0160, -0.1069],
          [ 0.0621, -0.2320,  0.2642]],

         [[-0.1417,  0.5030,  0.0873],
          [-0.0093, -0.0197, -0.1847],
          [ 0.0760, -0.3996,  0.0009]],

         [[-0.1439,  0.2994, -0.1401],
          [ 0.0604, -0.1509, -0.1380],
          [ 0.1689, -0.0923,  0.2245]]],


        [[[-0.1997, -0.4034, -0.2297],
          [-0.0921,  0.2354,  0.1909],
          [ 0.1985,  0.1757,  0.2590]],

         [[-0.2677, -0.3210, -0.2063],
          [-0.1189,  0.1720,  0.2299],
          [ 0.2755,  0.1264,  0.1672]],

         [[-0.1564, -0.0360, -0.2305],
          [ 0.0649,  0.2238, -0.0489],
          [-0.0063,  0.0823,  0.0578]]],


        [[[-0.1101,  0.2686,  0.1000],
          [ 0.1731,  0.2016, -0.0632],
          [-0.2455, -0.0776, -0.3294]],

         [[ 0.0559,  0.1497,  0.0340],
          [ 0.1098,  0.2817,  0.0635],
          [-0.1501, -0.1225, -0.4187]],

         [[-0.0553,  0.1581,  0.2014],
          [ 0.0670,  0.2819,  0.1048],
          [-0.2492, -0.2011, -0.2843]]],


        ...,


        [[[-0.0800, -0.1148,  0.0381],
          [ 0.0550, -0.3750, -0.1479],
          [ 0.1425, -0.0648,  0.0966]],

         [[ 0.1507, -0.0444,  0.0048],
          [-0.0632, -0.4199, -0.2248],
          [ 0.1265,  0.0062,  0.0099]],

         [[ 0.2146,  0.0354,  0.1029],
          [ 0.0069, -0.2591, -0.2086],
          [ 0.1060, -0.0959, -0.1002]]],


        [[[-0.0156, -0.0290, -0.0295],
          [-0.0234, -0.0254, -0.0232],
          [-0.0182, -0.0210, -0.0131]],

         [[-0.0180, -0.0344, -0.0273],
          [-0.0317, -0.0433, -0.0328],
          [-0.0187, -0.0304, -0.0182]],

         [[-0.0033, -0.0133, -0.0080],
          [-0.0125, -0.0153, -0.0091],
          [ 0.0002, -0.0046,  0.0010]]],


        [[[ 0.0219, -0.0036, -0.0240],
          [ 0.0129, -0.0110, -0.0261],
          [ 0.0033, -0.0113, -0.0212]],

         [[ 0.0045, -0.0161, -0.0312],
          [ 0.0007, -0.0199, -0.0302],
          [-0.0042, -0.0158, -0.0227]],

         [[-0.0151, -0.0320, -0.0408],
          [-0.0195, -0.0364, -0.0415],
          [-0.0234, -0.0339, -0.0380]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0411,  0.0281,  0.0191],
          [ 0.0362,  0.0322,  0.0283],
          [ 0.0398,  0.0244,  0.0170]],

         [[ 0.0331,  0.0239,  0.0148],
          [ 0.0255,  0.0259,  0.0196],
          [ 0.0295,  0.0148,  0.0068]],

         [[ 0.0284,  0.0272,  0.0101],
          [ 0.0184,  0.0253,  0.0144],
          [ 0.0240,  0.0107,  0.0008]]],


        [[[-0.0539, -0.0629, -0.0684],
          [-0.0532, -0.0655, -0.0661],
          [-0.0483, -0.0567, -0.0527]],

         [[-0.0436, -0.0537, -0.0625],
          [-0.0403, -0.0548, -0.0592],
          [-0.0406, -0.0504, -0.0489]],

         [[-0.0369, -0.0463, -0.0573],
          [-0.0306, -0.0420, -0.0481],
          [-0.0319, -0.0393, -0.0379]]],


        [[[ 0.0967,  0.1063,  0.0960],
          [ 0.1063,  0.1182,  0.1124],
          [ 0.1022,  0.1075,  0.1084]],

         [[ 0.0778,  0.0871,  0.0784],
          [ 0.0884,  0.1042,  0.0990],
          [ 0.0872,  0.0970,  0.0972]],

         [[ 0.0653,  0.0757,  0.0698],
          [ 0.0703,  0.0874,  0.0838],
          [ 0.0675,  0.0780,  0.0780]]],


        ...,


        [[[-0.0084, -0.0126, -0.0053],
          [-0.0096, -0.0136, -0.0042],
          [-0.0236, -0.0227, -0.0074]],

         [[ 0.0014, -0.0029,  0.0033],
          [ 0.0029, -0.0008,  0.0075],
          [-0.0075, -0.0072,  0.0059]],

         [[ 0.0163,  0.0126,  0.0156],
          [ 0.0168,  0.0119,  0.0176],
          [ 0.0089,  0.0067,  0.0176]]],


        [[[-0.0000, -0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[-0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [ 0.0000,  0.0000, -0.0000]],

         [[-0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000],
          [ 0.0000,  0.0000, -0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5861]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 122 | Batch_idx: 0 |  Loss: (0.1016) | Acc: (96.00%) (123/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1826) | Acc: (93.00%) (1314/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1703) | Acc: (93.00%) (2522/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1801) | Acc: (93.00%) (3704/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1784) | Acc: (93.00%) (4908/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1789) | Acc: (93.00%) (6103/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1796) | Acc: (93.00%) (7304/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1783) | Acc: (93.00%) (8515/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1797) | Acc: (93.00%) (9714/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1799) | Acc: (93.00%) (10912/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1813) | Acc: (93.00%) (12108/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1832) | Acc: (93.00%) (13294/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1877) | Acc: (93.00%) (14466/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1875) | Acc: (93.00%) (15669/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1881) | Acc: (93.00%) (16862/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1893) | Acc: (93.00%) (18054/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1891) | Acc: (93.00%) (19244/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1902) | Acc: (93.00%) (20440/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1931) | Acc: (93.00%) (21614/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1930) | Acc: (93.00%) (22806/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1938) | Acc: (93.00%) (23997/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1944) | Acc: (93.00%) (25186/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1931) | Acc: (93.00%) (26390/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1939) | Acc: (93.00%) (27575/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1944) | Acc: (93.00%) (28761/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1935) | Acc: (93.00%) (29971/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1932) | Acc: (93.00%) (31169/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1940) | Acc: (93.00%) (32357/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1941) | Acc: (93.00%) (33547/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1937) | Acc: (93.00%) (34745/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1949) | Acc: (93.00%) (35920/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1952) | Acc: (93.00%) (37108/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1947) | Acc: (93.00%) (38310/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1940) | Acc: (93.00%) (39519/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1944) | Acc: (93.00%) (40699/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1937) | Acc: (93.00%) (41900/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1934) | Acc: (93.00%) (43104/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1932) | Acc: (93.00%) (44296/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1937) | Acc: (93.00%) (45485/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1948) | Acc: (93.00%) (46620/50000)
# TEST : Loss: (0.3249) | Acc: (89.00%) (8976/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1407,  0.3557, -0.1756],
          [-0.0490,  0.0162, -0.1065],
          [ 0.0639, -0.2354,  0.2643]],

         [[-0.1431,  0.5033,  0.0939],
          [-0.0127, -0.0249, -0.1831],
          [ 0.0705, -0.4097, -0.0037]],

         [[-0.1406,  0.2996, -0.1324],
          [ 0.0603, -0.1511, -0.1341],
          [ 0.1679, -0.0945,  0.2240]]],


        [[[-0.2097, -0.4131, -0.2389],
          [-0.1017,  0.2271,  0.1865],
          [ 0.1897,  0.1697,  0.2575]],

         [[-0.2808, -0.3298, -0.2141],
          [-0.1327,  0.1624,  0.2250],
          [ 0.2646,  0.1205,  0.1663]],

         [[-0.1542, -0.0332, -0.2267],
          [ 0.0631,  0.2245, -0.0424],
          [-0.0065,  0.0861,  0.0676]]],


        [[[-0.1093,  0.2686,  0.0978],
          [ 0.1754,  0.2044, -0.0641],
          [-0.2451, -0.0751, -0.3311]],

         [[ 0.0530,  0.1451,  0.0276],
          [ 0.1083,  0.2788,  0.0567],
          [-0.1559, -0.1272, -0.4270]],

         [[-0.0559,  0.1587,  0.2011],
          [ 0.0677,  0.2826,  0.1039],
          [-0.2514, -0.2001, -0.2857]]],


        ...,


        [[[-0.0928, -0.1270,  0.0322],
          [ 0.0431, -0.3886, -0.1538],
          [ 0.1366, -0.0722,  0.0959]],

         [[ 0.1497, -0.0436,  0.0103],
          [-0.0649, -0.4185, -0.2196],
          [ 0.1278,  0.0061,  0.0198]],

         [[ 0.2105,  0.0301,  0.1000],
          [ 0.0049, -0.2617, -0.2106],
          [ 0.1087, -0.0974, -0.0933]]],


        [[[-0.0099, -0.0142, -0.0141],
          [-0.0135, -0.0100, -0.0090],
          [-0.0128, -0.0106, -0.0073]],

         [[-0.0102, -0.0179, -0.0149],
          [-0.0188, -0.0224, -0.0171],
          [-0.0125, -0.0169, -0.0107]],

         [[-0.0042, -0.0099, -0.0066],
          [-0.0105, -0.0113, -0.0076],
          [-0.0024, -0.0050, -0.0024]]],


        [[[ 0.0118, -0.0019, -0.0123],
          [ 0.0065, -0.0057, -0.0138],
          [ 0.0017, -0.0058, -0.0114]],

         [[ 0.0018, -0.0068, -0.0133],
          [ 0.0003, -0.0085, -0.0137],
          [-0.0018, -0.0073, -0.0109]],

         [[-0.0061, -0.0146, -0.0198],
          [-0.0071, -0.0162, -0.0196],
          [-0.0091, -0.0147, -0.0172]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0634, -0.0479, -0.0514],
          [-0.0670, -0.0510, -0.0534],
          [-0.0400, -0.0451, -0.0613]],

         [[-0.0553, -0.0412, -0.0400],
          [-0.0548, -0.0379, -0.0418],
          [-0.0276, -0.0276, -0.0491]],

         [[-0.0206, -0.0100, -0.0075],
          [-0.0241, -0.0105, -0.0138],
          [-0.0114, -0.0076, -0.0241]]],


        [[[-0.0493, -0.0375, -0.0284],
          [-0.0381, -0.0313, -0.0287],
          [-0.0437, -0.0246, -0.0181]],

         [[-0.0444, -0.0350, -0.0248],
          [-0.0405, -0.0365, -0.0326],
          [-0.0595, -0.0422, -0.0336]],

         [[-0.0330, -0.0245, -0.0148],
          [-0.0306, -0.0291, -0.0246],
          [-0.0471, -0.0322, -0.0219]]],


        [[[-0.0354, -0.0487, -0.0496],
          [-0.0393, -0.0500, -0.0579],
          [-0.0239, -0.0499, -0.0649]],

         [[-0.0367, -0.0551, -0.0573],
          [-0.0390, -0.0538, -0.0623],
          [-0.0210, -0.0494, -0.0675]],

         [[-0.0193, -0.0377, -0.0396],
          [-0.0218, -0.0383, -0.0457],
          [-0.0029, -0.0341, -0.0498]]],


        ...,


        [[[ 0.0055,  0.0041,  0.0082],
          [ 0.0053,  0.0041,  0.0030],
          [ 0.0178,  0.0182,  0.0095]],

         [[ 0.0023, -0.0012, -0.0005],
          [ 0.0023,  0.0008, -0.0023],
          [ 0.0166,  0.0171,  0.0082]],

         [[ 0.0099,  0.0058,  0.0070],
          [ 0.0117,  0.0093,  0.0079],
          [ 0.0265,  0.0251,  0.0173]]],


        [[[-0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0000, -0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5845]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 123 | Batch_idx: 0 |  Loss: (0.1782) | Acc: (94.00%) (121/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1883) | Acc: (93.00%) (1323/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1980) | Acc: (93.00%) (2500/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.2087) | Acc: (92.00%) (3680/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.2116) | Acc: (92.00%) (4865/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.2130) | Acc: (92.00%) (6047/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.2127) | Acc: (92.00%) (7227/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.2085) | Acc: (92.00%) (8431/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.2086) | Acc: (92.00%) (9615/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.2050) | Acc: (92.00%) (10822/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.2033) | Acc: (92.00%) (12015/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.2008) | Acc: (93.00%) (13222/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1987) | Acc: (93.00%) (14429/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1976) | Acc: (93.00%) (15626/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1958) | Acc: (93.00%) (16837/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1948) | Acc: (93.00%) (18039/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1926) | Acc: (93.00%) (19256/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1911) | Acc: (93.00%) (20471/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1908) | Acc: (93.00%) (21660/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1894) | Acc: (93.00%) (22870/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1891) | Acc: (93.00%) (24069/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1882) | Acc: (93.00%) (25278/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1870) | Acc: (93.00%) (26492/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1870) | Acc: (93.00%) (27687/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1877) | Acc: (93.00%) (28875/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1879) | Acc: (93.00%) (30066/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1876) | Acc: (93.00%) (31277/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1883) | Acc: (93.00%) (32461/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1875) | Acc: (93.00%) (33663/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1868) | Acc: (93.00%) (34877/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1861) | Acc: (93.00%) (36090/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1859) | Acc: (93.00%) (37291/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1844) | Acc: (93.00%) (38515/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1844) | Acc: (93.00%) (39713/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1843) | Acc: (93.00%) (40909/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1831) | Acc: (93.00%) (42136/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1818) | Acc: (93.00%) (43362/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1820) | Acc: (93.00%) (44569/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1817) | Acc: (93.00%) (45769/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1823) | Acc: (93.00%) (46923/50000)
# TEST : Loss: (0.2952) | Acc: (90.00%) (9091/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1355,  0.3603, -0.1700],
          [-0.0436,  0.0223, -0.1002],
          [ 0.0674, -0.2287,  0.2709]],

         [[-0.1381,  0.5072,  0.0977],
          [-0.0077, -0.0193, -0.1776],
          [ 0.0734, -0.4036,  0.0024]],

         [[-0.1391,  0.3006, -0.1315],
          [ 0.0627, -0.1478, -0.1313],
          [ 0.1695, -0.0915,  0.2274]]],


        [[[-0.2065, -0.4104, -0.2380],
          [-0.0994,  0.2282,  0.1869],
          [ 0.1927,  0.1711,  0.2573]],

         [[-0.2771, -0.3267, -0.2131],
          [-0.1295,  0.1644,  0.2258],
          [ 0.2687,  0.1233,  0.1675]],

         [[-0.1520, -0.0321, -0.2267],
          [ 0.0646,  0.2251, -0.0421],
          [-0.0038,  0.0871,  0.0674]]],


        [[[-0.1063,  0.2720,  0.1014],
          [ 0.1784,  0.2085, -0.0594],
          [-0.2425, -0.0707, -0.3256]],

         [[ 0.0548,  0.1479,  0.0304],
          [ 0.1103,  0.2820,  0.0603],
          [-0.1547, -0.1238, -0.4222]],

         [[-0.0544,  0.1611,  0.2034],
          [ 0.0691,  0.2852,  0.1071],
          [-0.2505, -0.1966, -0.2812]]],


        ...,


        [[[-0.0921, -0.1281,  0.0316],
          [ 0.0441, -0.3875, -0.1527],
          [ 0.1343, -0.0768,  0.0924]],

         [[ 0.1510, -0.0430,  0.0119],
          [-0.0613, -0.4123, -0.2137],
          [ 0.1277,  0.0036,  0.0194]],

         [[ 0.2109,  0.0299,  0.1010],
          [ 0.0079, -0.2584, -0.2067],
          [ 0.1090, -0.0987, -0.0931]]],


        [[[-0.0045, -0.0058, -0.0060],
          [-0.0054, -0.0033, -0.0030],
          [-0.0058, -0.0042, -0.0029]],

         [[-0.0054, -0.0088, -0.0074],
          [-0.0100, -0.0110, -0.0084],
          [-0.0069, -0.0085, -0.0054]],

         [[-0.0025, -0.0059, -0.0039],
          [-0.0064, -0.0067, -0.0045],
          [-0.0015, -0.0030, -0.0014]]],


        [[[ 0.0055, -0.0009, -0.0055],
          [ 0.0028, -0.0026, -0.0063],
          [ 0.0007, -0.0026, -0.0054]],

         [[ 0.0006, -0.0024, -0.0047],
          [ 0.0001, -0.0030, -0.0052],
          [-0.0007, -0.0028, -0.0045]],

         [[-0.0020, -0.0056, -0.0082],
          [-0.0021, -0.0060, -0.0079],
          [-0.0028, -0.0053, -0.0065]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.6167]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0075]], device='cuda:0')

Epoch: 124 | Batch_idx: 0 |  Loss: (0.2309) | Acc: (92.00%) (119/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1692) | Acc: (94.00%) (1332/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1657) | Acc: (94.00%) (2540/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1589) | Acc: (94.00%) (3763/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1578) | Acc: (94.00%) (4982/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1605) | Acc: (94.00%) (6186/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1596) | Acc: (94.00%) (7402/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1600) | Acc: (94.00%) (8617/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1624) | Acc: (94.00%) (9820/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1622) | Acc: (94.00%) (11036/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1612) | Acc: (94.00%) (12252/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1590) | Acc: (94.00%) (13481/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1583) | Acc: (94.00%) (14701/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1607) | Acc: (94.00%) (15891/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1612) | Acc: (94.00%) (17094/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1631) | Acc: (94.00%) (18294/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1636) | Acc: (94.00%) (19498/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1634) | Acc: (94.00%) (20703/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1641) | Acc: (94.00%) (21904/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1644) | Acc: (94.00%) (23108/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1647) | Acc: (94.00%) (24312/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1650) | Acc: (94.00%) (25521/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1652) | Acc: (94.00%) (26723/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1652) | Acc: (94.00%) (27935/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1653) | Acc: (94.00%) (29137/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1656) | Acc: (94.00%) (30338/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1654) | Acc: (94.00%) (31548/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1652) | Acc: (94.00%) (32763/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1660) | Acc: (94.00%) (33962/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1647) | Acc: (94.00%) (35188/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1647) | Acc: (94.00%) (36395/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1647) | Acc: (94.00%) (37604/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1638) | Acc: (94.00%) (38827/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1637) | Acc: (94.00%) (40042/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1636) | Acc: (94.00%) (41258/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1631) | Acc: (94.00%) (42479/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1628) | Acc: (94.00%) (43686/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1631) | Acc: (94.00%) (44883/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1639) | Acc: (94.00%) (46071/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1635) | Acc: (94.00%) (47231/50000)
# TEST : Loss: (0.2835) | Acc: (91.00%) (9124/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1351,  0.3591, -0.1694],
          [-0.0435,  0.0223, -0.0999],
          [ 0.0672, -0.2279,  0.2701]],

         [[-0.1376,  0.5055,  0.0974],
          [-0.0076, -0.0192, -0.1770],
          [ 0.0732, -0.4023,  0.0024]],

         [[-0.1386,  0.2996, -0.1310],
          [ 0.0625, -0.1473, -0.1309],
          [ 0.1690, -0.0912,  0.2267]]],


        [[[-0.2060, -0.4095, -0.2375],
          [-0.0991,  0.2277,  0.1864],
          [ 0.1923,  0.1707,  0.2567]],

         [[-0.2764, -0.3259, -0.2126],
          [-0.1292,  0.1640,  0.2253],
          [ 0.2681,  0.1229,  0.1670]],

         [[-0.1517, -0.0320, -0.2261],
          [ 0.0644,  0.2246, -0.0420],
          [-0.0038,  0.0869,  0.0672]]],


        [[[-0.1061,  0.2714,  0.1012],
          [ 0.1780,  0.2080, -0.0593],
          [-0.2419, -0.0705, -0.3248]],

         [[ 0.0547,  0.1475,  0.0303],
          [ 0.1101,  0.2814,  0.0602],
          [-0.1543, -0.1235, -0.4213]],

         [[-0.0543,  0.1607,  0.2029],
          [ 0.0689,  0.2846,  0.1069],
          [-0.2499, -0.1962, -0.2806]]],


        ...,


        [[[-0.0916, -0.1272,  0.0314],
          [ 0.0438, -0.3836, -0.1512],
          [ 0.1337, -0.0763,  0.0918]],

         [[ 0.1502, -0.0427,  0.0118],
          [-0.0609, -0.4069, -0.2112],
          [ 0.1270,  0.0036,  0.0193]],

         [[ 0.2098,  0.0297,  0.1004],
          [ 0.0078, -0.2559, -0.2048],
          [ 0.1085, -0.0980, -0.0925]]],


        [[[-0.0017, -0.0020, -0.0021],
          [-0.0017, -0.0009, -0.0008],
          [-0.0022, -0.0014, -0.0010]],

         [[-0.0025, -0.0037, -0.0031],
          [-0.0046, -0.0046, -0.0035],
          [-0.0034, -0.0037, -0.0023]],

         [[-0.0014, -0.0031, -0.0020],
          [-0.0035, -0.0036, -0.0023],
          [-0.0008, -0.0016, -0.0007]]],


        [[[ 0.0022, -0.0003, -0.0020],
          [ 0.0010, -0.0010, -0.0024],
          [ 0.0002, -0.0010, -0.0022]],

         [[ 0.0002, -0.0007, -0.0013],
          [ 0.0000, -0.0009, -0.0016],
          [-0.0002, -0.0009, -0.0015]],

         [[-0.0005, -0.0017, -0.0028],
          [-0.0004, -0.0018, -0.0026],
          [-0.0007, -0.0015, -0.0020]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5849]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0246]], device='cuda:0')

Epoch: 125 | Batch_idx: 0 |  Loss: (0.1766) | Acc: (95.00%) (122/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1749) | Acc: (94.00%) (1327/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1693) | Acc: (94.00%) (2536/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1736) | Acc: (94.00%) (3735/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1705) | Acc: (94.00%) (4950/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1686) | Acc: (94.00%) (6149/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1717) | Acc: (94.00%) (7357/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1705) | Acc: (94.00%) (8577/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1680) | Acc: (94.00%) (9799/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1654) | Acc: (94.00%) (11020/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1662) | Acc: (94.00%) (12229/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1685) | Acc: (94.00%) (13436/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1662) | Acc: (94.00%) (14658/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1638) | Acc: (94.00%) (15881/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1625) | Acc: (94.00%) (17099/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1620) | Acc: (94.00%) (18314/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1639) | Acc: (94.00%) (19514/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1634) | Acc: (94.00%) (20725/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1633) | Acc: (94.00%) (21935/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1630) | Acc: (94.00%) (23148/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1617) | Acc: (94.00%) (24367/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1613) | Acc: (94.00%) (25580/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1619) | Acc: (94.00%) (26791/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1619) | Acc: (94.00%) (28002/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1615) | Acc: (94.00%) (29216/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1620) | Acc: (94.00%) (30428/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1625) | Acc: (94.00%) (31634/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1619) | Acc: (94.00%) (32849/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1627) | Acc: (94.00%) (34057/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1619) | Acc: (94.00%) (35277/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1610) | Acc: (94.00%) (36501/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1612) | Acc: (94.00%) (37712/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1611) | Acc: (94.00%) (38928/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1609) | Acc: (94.00%) (40146/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1613) | Acc: (94.00%) (41352/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1606) | Acc: (94.00%) (42575/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1619) | Acc: (94.00%) (43760/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1620) | Acc: (94.00%) (44981/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1623) | Acc: (94.00%) (46189/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1624) | Acc: (94.00%) (47355/50000)
# TEST : Loss: (0.2813) | Acc: (91.00%) (9122/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3460e-01,  3.5773e-01, -1.6881e-01],
          [-4.3342e-02,  2.2178e-02, -9.9505e-02],
          [ 6.6993e-02, -2.2709e-01,  2.6913e-01]],

         [[-1.3711e-01,  5.0351e-01,  9.7004e-02],
          [-7.6103e-03, -1.9156e-02, -1.7639e-01],
          [ 7.2939e-02, -4.0076e-01,  2.3948e-03]],

         [[-1.3808e-01,  2.9833e-01, -1.3052e-01],
          [ 6.2233e-02, -1.4675e-01, -1.3038e-01],
          [ 1.6829e-01, -9.0850e-02,  2.2587e-01]]],


        [[[-2.0546e-01, -4.0838e-01, -2.3684e-01],
          [-9.8866e-02,  2.2702e-01,  1.8589e-01],
          [ 1.9173e-01,  1.7019e-01,  2.5595e-01]],

         [[-2.7560e-01, -3.2497e-01, -2.1192e-01],
          [-1.2885e-01,  1.6357e-01,  2.2463e-01],
          [ 2.6726e-01,  1.2257e-01,  1.6652e-01]],

         [[-1.5120e-01, -3.1943e-02, -2.2546e-01],
          [ 6.4211e-02,  2.2388e-01, -4.1823e-02],
          [-3.7910e-03,  8.6645e-02,  6.7000e-02]]],


        [[[-1.0582e-01,  2.7065e-01,  1.0090e-01],
          [ 1.7750e-01,  2.0750e-01, -5.9130e-02],
          [-2.4128e-01, -7.0348e-02, -3.2396e-01]],

         [[ 5.4558e-02,  1.4715e-01,  3.0256e-02],
          [ 1.0982e-01,  2.8063e-01,  6.0005e-02],
          [-1.5393e-01, -1.2316e-01, -4.2014e-01]],

         [[-5.4150e-02,  1.6026e-01,  2.0236e-01],
          [ 6.8723e-02,  2.8378e-01,  1.0655e-01],
          [-2.4918e-01, -1.9562e-01, -2.7974e-01]]],


        ...,


        [[[-9.1079e-02, -1.2624e-01,  3.1132e-02],
          [ 4.3512e-02, -3.7889e-01, -1.4941e-01],
          [ 1.3294e-01, -7.5759e-02,  9.1056e-02]],

         [[ 1.4929e-01, -4.2353e-02,  1.1744e-02],
          [-6.0465e-02, -4.0036e-01, -2.0821e-01],
          [ 1.2626e-01,  3.5284e-03,  1.9088e-02]],

         [[ 2.0847e-01,  2.9473e-02,  9.9637e-02],
          [ 7.7533e-03, -2.5303e-01, -2.0259e-01],
          [ 1.0776e-01, -9.7209e-02, -9.1687e-02]]],


        [[[-5.2251e-04, -5.2059e-04, -5.8628e-04],
          [-4.4052e-04, -1.6323e-04, -1.6236e-04],
          [-6.7875e-04, -3.4424e-04, -2.5256e-04]],

         [[-9.4700e-04, -1.2697e-03, -1.0977e-03],
          [-1.7876e-03, -1.5981e-03, -1.2078e-03],
          [-1.3959e-03, -1.3328e-03, -8.4582e-04]],

         [[-6.5689e-04, -1.4522e-03, -8.9762e-04],
          [-1.6836e-03, -1.6653e-03, -1.0503e-03],
          [-3.8606e-04, -7.1720e-04, -3.4115e-04]]],


        [[[ 7.1297e-04, -1.1012e-04, -6.0836e-04],
          [ 2.9600e-04, -3.0346e-04, -7.5121e-04],
          [ 6.7339e-05, -2.9143e-04, -7.0295e-04]],

         [[ 3.0403e-05, -1.3401e-04, -2.7861e-04],
          [ 2.9917e-06, -1.8141e-04, -3.7365e-04],
          [-4.1282e-05, -2.1418e-04, -3.9390e-04]],

         [[-1.0077e-04, -4.1402e-04, -7.5214e-04],
          [-7.0037e-05, -4.1371e-04, -6.6012e-04],
          [-1.2081e-04, -3.3517e-04, -4.6661e-04]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5825]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0127]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1319) | Acc: (96.00%) (123/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1502) | Acc: (95.00%) (1340/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1792) | Acc: (94.00%) (2531/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1947) | Acc: (93.00%) (3713/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.2139) | Acc: (92.00%) (4872/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.2313) | Acc: (92.00%) (6033/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.2490) | Acc: (91.00%) (7170/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.2626) | Acc: (91.00%) (8292/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.2663) | Acc: (91.00%) (9442/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.2700) | Acc: (90.00%) (10592/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.2741) | Acc: (90.00%) (11744/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.2751) | Acc: (90.00%) (12894/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.2748) | Acc: (90.00%) (14045/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.2764) | Acc: (90.00%) (15193/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.2773) | Acc: (90.00%) (16350/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.2760) | Acc: (90.00%) (17523/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.2769) | Acc: (90.00%) (18678/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.2754) | Acc: (90.00%) (19839/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.2772) | Acc: (90.00%) (20980/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.2776) | Acc: (90.00%) (22153/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.2777) | Acc: (90.00%) (23297/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.2761) | Acc: (90.00%) (24475/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.2764) | Acc: (90.00%) (25627/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.2751) | Acc: (90.00%) (26800/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.2753) | Acc: (90.00%) (27957/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.2751) | Acc: (90.00%) (29129/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.2760) | Acc: (90.00%) (30275/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.2743) | Acc: (90.00%) (31460/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.2743) | Acc: (90.00%) (32622/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.2733) | Acc: (90.00%) (33798/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.2728) | Acc: (90.00%) (34961/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.2723) | Acc: (90.00%) (36113/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.2718) | Acc: (90.00%) (37282/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.2708) | Acc: (90.00%) (38469/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.2700) | Acc: (90.00%) (39636/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.2695) | Acc: (90.00%) (40810/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.2684) | Acc: (90.00%) (41987/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.2680) | Acc: (90.00%) (43153/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.2672) | Acc: (90.00%) (44326/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.2661) | Acc: (90.00%) (45457/50000)
# TEST : Loss: (0.3663) | Acc: (88.00%) (8861/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5068e-01,  3.5246e-01, -1.6932e-01],
          [-6.2437e-02,  7.6584e-03, -1.0225e-01],
          [ 5.3722e-02, -2.3578e-01,  2.6602e-01]],

         [[-1.4501e-01,  5.0819e-01,  1.0510e-01],
          [-2.6525e-02, -3.5563e-02, -1.7563e-01],
          [ 5.6363e-02, -4.2119e-01, -3.5084e-03]],

         [[-1.4779e-01,  2.9371e-01, -1.2452e-01],
          [ 3.8291e-02, -1.5947e-01, -1.3053e-01],
          [ 1.5064e-01, -1.0630e-01,  2.1489e-01]]],


        [[[-1.9770e-01, -4.1011e-01, -2.3342e-01],
          [-8.9981e-02,  2.3292e-01,  1.9359e-01],
          [ 2.0334e-01,  1.7977e-01,  2.6240e-01]],

         [[-2.6612e-01, -3.2629e-01, -2.0826e-01],
          [-1.2364e-01,  1.6835e-01,  2.3233e-01],
          [ 2.7544e-01,  1.2880e-01,  1.7244e-01]],

         [[-1.4608e-01, -3.9451e-02, -2.2793e-01],
          [ 6.3519e-02,  2.2051e-01, -4.1891e-02],
          [-2.7453e-03,  8.4785e-02,  6.5817e-02]]],


        [[[-1.0713e-01,  2.7170e-01,  9.2394e-02],
          [ 1.6754e-01,  2.0574e-01, -6.2001e-02],
          [-2.5566e-01, -8.0932e-02, -3.3126e-01]],

         [[ 5.6310e-02,  1.5201e-01,  3.0050e-02],
          [ 9.9643e-02,  2.7805e-01,  5.9777e-02],
          [-1.6889e-01, -1.3271e-01, -4.2056e-01]],

         [[-5.7782e-02,  1.6073e-01,  1.9794e-01],
          [ 5.6335e-02,  2.7786e-01,  1.0468e-01],
          [-2.6441e-01, -2.0613e-01, -2.8073e-01]]],


        ...,


        [[[-9.2418e-02, -1.2426e-01,  2.3485e-02],
          [ 3.8913e-02, -3.9132e-01, -1.6078e-01],
          [ 1.3373e-01, -7.2649e-02,  1.0297e-01]],

         [[ 1.4800e-01, -4.3593e-02, -6.9066e-03],
          [-6.9313e-02, -4.2745e-01, -2.3720e-01],
          [ 1.1426e-01, -7.3855e-03,  1.7134e-02]],

         [[ 2.1396e-01,  4.4359e-02,  1.0084e-01],
          [ 8.6392e-03, -2.5051e-01, -2.0038e-01],
          [ 1.0245e-01, -1.0116e-01, -8.9623e-02]]],


        [[[ 1.0943e-02,  5.5193e-03,  1.1457e-04],
          [ 1.2740e-02,  1.0379e-02,  7.5405e-03],
          [ 1.3480e-02,  1.0025e-02,  9.6705e-03]],

         [[ 1.2699e-02,  7.6937e-03,  2.8163e-03],
          [ 1.2257e-02,  1.0635e-02,  9.7240e-03],
          [ 1.1715e-02,  9.7934e-03,  1.1657e-02]],

         [[ 1.0349e-02,  7.8016e-03,  6.8625e-03],
          [ 1.0238e-02,  1.0991e-02,  1.2736e-02],
          [ 1.2405e-02,  1.3100e-02,  1.5814e-02]]],


        [[[ 1.7943e-04, -2.7048e-05, -1.3829e-04],
          [ 6.4626e-05, -7.1435e-05, -1.7971e-04],
          [ 1.3929e-05, -6.6641e-05, -1.7827e-04]],

         [[ 4.0038e-06, -1.9297e-05, -4.1281e-05],
          [ 3.2330e-07, -2.7097e-05, -6.3273e-05],
          [-6.3770e-06, -3.7705e-05, -7.6640e-05]],

         [[-1.3232e-05, -7.1427e-05, -1.5003e-04],
          [-7.1169e-06, -6.7666e-05, -1.2402e-04],
          [-1.4255e-05, -5.1763e-05, -7.8798e-05]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0005, -0.0102, -0.0241],
          [ 0.0005, -0.0128, -0.0250],
          [ 0.0340,  0.0114,  0.0042]],

         [[ 0.0016, -0.0110, -0.0208],
          [ 0.0028, -0.0083, -0.0167],
          [ 0.0381,  0.0223,  0.0136]],

         [[ 0.0120, -0.0008, -0.0145],
          [ 0.0117,  0.0015, -0.0068],
          [ 0.0403,  0.0233,  0.0203]]],


        [[[-0.0248, -0.0155,  0.0041],
          [-0.0187, -0.0122,  0.0101],
          [-0.0433, -0.0293,  0.0040]],

         [[-0.0014,  0.0079,  0.0269],
          [ 0.0062,  0.0121,  0.0348],
          [-0.0187, -0.0036,  0.0306]],

         [[-0.0072, -0.0006,  0.0150],
          [ 0.0041,  0.0080,  0.0254],
          [-0.0096,  0.0017,  0.0286]]],


        [[[-0.0377, -0.0174,  0.0015],
          [-0.0521, -0.0423, -0.0284],
          [-0.0369, -0.0321, -0.0255]],

         [[-0.0098,  0.0102,  0.0281],
          [-0.0235, -0.0127,  0.0005],
          [-0.0066,  0.0014,  0.0080]],

         [[ 0.0041,  0.0196,  0.0300],
          [-0.0083, -0.0031,  0.0023],
          [ 0.0050,  0.0078,  0.0093]]],


        ...,


        [[[ 0.0011, -0.0144, -0.0231],
          [ 0.0280,  0.0105, -0.0021],
          [ 0.0219,  0.0023, -0.0103]],

         [[-0.0100, -0.0250, -0.0327],
          [ 0.0167,  0.0004, -0.0110],
          [ 0.0111, -0.0082, -0.0193]],

         [[-0.0128, -0.0244, -0.0291],
          [ 0.0133,  0.0003, -0.0075],
          [ 0.0087, -0.0061, -0.0140]]],


        [[[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000, -0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5808]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 127 | Batch_idx: 0 |  Loss: (0.1824) | Acc: (93.00%) (120/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.2118) | Acc: (92.00%) (1308/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.2335) | Acc: (92.00%) (2489/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.2381) | Acc: (92.00%) (3667/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.2302) | Acc: (92.00%) (4857/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.2182) | Acc: (92.00%) (6060/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.2187) | Acc: (92.00%) (7231/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.2193) | Acc: (92.00%) (8416/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.2175) | Acc: (92.00%) (9613/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.2172) | Acc: (92.00%) (10798/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.2162) | Acc: (92.00%) (11988/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.2168) | Acc: (92.00%) (13166/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.2151) | Acc: (92.00%) (14359/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.2160) | Acc: (92.00%) (15548/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.2143) | Acc: (92.00%) (16750/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.2140) | Acc: (92.00%) (17929/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.2124) | Acc: (92.00%) (19124/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.2121) | Acc: (92.00%) (20310/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.2119) | Acc: (92.00%) (21504/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.2107) | Acc: (92.00%) (22703/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.2122) | Acc: (92.00%) (23880/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.2123) | Acc: (92.00%) (25056/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.2132) | Acc: (92.00%) (26239/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.2113) | Acc: (92.00%) (27444/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.2102) | Acc: (92.00%) (28643/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.2093) | Acc: (92.00%) (29841/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.2086) | Acc: (92.00%) (31032/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.2098) | Acc: (92.00%) (32206/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.2111) | Acc: (92.00%) (33372/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.2120) | Acc: (92.00%) (34546/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.2121) | Acc: (92.00%) (35742/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.2118) | Acc: (92.00%) (36927/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.2111) | Acc: (92.00%) (38128/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.2115) | Acc: (92.00%) (39308/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.2110) | Acc: (92.00%) (40501/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.2109) | Acc: (92.00%) (41689/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.2111) | Acc: (92.00%) (42875/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.2115) | Acc: (92.00%) (44058/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.2118) | Acc: (92.00%) (45232/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.2126) | Acc: (92.00%) (46361/50000)
# TEST : Loss: (0.3794) | Acc: (88.00%) (8838/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3485e-01,  3.5777e-01, -1.7171e-01],
          [-5.3026e-02,  6.9240e-03, -1.0197e-01],
          [ 6.3206e-02, -2.3297e-01,  2.7007e-01]],

         [[-1.3227e-01,  5.1252e-01,  9.8590e-02],
          [-1.5857e-02, -3.6540e-02, -1.7099e-01],
          [ 6.6932e-02, -4.2253e-01, -2.5426e-03]],

         [[-1.4117e-01,  2.9030e-01, -1.3152e-01],
          [ 5.4152e-02, -1.5674e-01, -1.2377e-01],
          [ 1.7237e-01, -9.4079e-02,  2.2140e-01]]],


        [[[-2.0669e-01, -4.1981e-01, -2.4244e-01],
          [-1.0093e-01,  2.2534e-01,  1.8533e-01],
          [ 1.9477e-01,  1.7443e-01,  2.5328e-01]],

         [[-2.6982e-01, -3.3001e-01, -2.1192e-01],
          [-1.2871e-01,  1.6723e-01,  2.2928e-01],
          [ 2.7400e-01,  1.3101e-01,  1.7126e-01]],

         [[-1.5187e-01, -4.3762e-02, -2.3069e-01],
          [ 5.8454e-02,  2.2126e-01, -4.0387e-02],
          [-3.2978e-03,  9.0004e-02,  7.0967e-02]]],


        [[[-1.0213e-01,  2.8443e-01,  1.0970e-01],
          [ 1.7764e-01,  2.2142e-01, -4.3637e-02],
          [-2.4907e-01, -7.2880e-02, -3.1705e-01]],

         [[ 5.3079e-02,  1.5695e-01,  3.6972e-02],
          [ 1.0214e-01,  2.8494e-01,  6.6837e-02],
          [-1.6727e-01, -1.3134e-01, -4.1738e-01]],

         [[-6.5514e-02,  1.6113e-01,  1.9974e-01],
          [ 5.3316e-02,  2.7927e-01,  1.0567e-01],
          [-2.6525e-01, -2.0812e-01, -2.8255e-01]]],


        ...,


        [[[-9.7050e-02, -1.2340e-01,  1.7233e-02],
          [ 3.4975e-02, -3.8950e-01, -1.6660e-01],
          [ 1.3188e-01, -7.0243e-02,  9.9456e-02]],

         [[ 1.4740e-01, -3.7520e-02, -8.8959e-03],
          [-7.2649e-02, -4.2378e-01, -2.4273e-01],
          [ 1.1028e-01, -7.9344e-03,  9.8167e-03]],

         [[ 2.0040e-01,  3.3768e-02,  7.9328e-02],
          [-1.1792e-02, -2.7225e-01, -2.3177e-01],
          [ 8.3934e-02, -1.1955e-01, -1.1626e-01]]],


        [[[ 1.2559e-02,  2.5389e-02,  3.1868e-02],
          [ 1.5997e-02,  2.9157e-02,  3.7140e-02],
          [ 2.6324e-02,  3.1036e-02,  3.3598e-02]],

         [[ 9.4866e-03,  1.5573e-02,  1.8891e-02],
          [ 1.3969e-02,  2.0068e-02,  2.3505e-02],
          [ 2.4860e-02,  2.6858e-02,  2.7243e-02]],

         [[-1.2419e-02, -1.1165e-02, -7.0365e-03],
          [-1.4692e-02, -1.3154e-02, -8.3570e-03],
          [-6.5449e-03, -8.3337e-03, -4.8551e-03]]],


        [[[ 3.3082e-05, -4.8394e-06, -2.2482e-05],
          [ 9.9947e-06, -1.2127e-05, -3.1120e-05],
          [ 2.0147e-06, -1.0914e-05, -3.3180e-05]],

         [[ 3.3039e-07, -1.7799e-06, -3.9454e-06],
          [ 2.0841e-08, -2.6159e-06, -7.1399e-06],
          [-6.4194e-07, -4.4651e-06, -1.0276e-05]],

         [[-1.0880e-06, -8.2488e-06, -2.0746e-05],
          [-4.2476e-07, -7.3133e-06, -1.5922e-05],
          [-1.0256e-06, -5.2091e-06, -8.8615e-06]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0011,  0.0109,  0.0071],
          [ 0.0158,  0.0100,  0.0026],
          [-0.0020,  0.0058, -0.0007]],

         [[ 0.0003,  0.0065,  0.0036],
          [ 0.0159,  0.0084, -0.0044],
          [ 0.0011,  0.0075, -0.0042]],

         [[-0.0126, -0.0017, -0.0047],
          [-0.0024, -0.0046, -0.0107],
          [-0.0109, -0.0123, -0.0167]]],


        [[[-0.0378, -0.0249, -0.0262],
          [-0.0399, -0.0312, -0.0340],
          [-0.0297, -0.0269, -0.0305]],

         [[-0.0466, -0.0307, -0.0291],
          [-0.0462, -0.0328, -0.0322],
          [-0.0344, -0.0270, -0.0289]],

         [[-0.0125,  0.0026,  0.0057],
          [-0.0145, -0.0026, -0.0018],
          [-0.0056, -0.0001, -0.0036]]],


        [[[-0.0039, -0.0048, -0.0015],
          [-0.0070, -0.0164, -0.0184],
          [ 0.0012, -0.0144, -0.0153]],

         [[-0.0016, -0.0020,  0.0076],
          [-0.0031, -0.0139, -0.0140],
          [ 0.0020, -0.0142, -0.0122]],

         [[-0.0130, -0.0216, -0.0192],
          [-0.0239, -0.0370, -0.0355],
          [-0.0182, -0.0346, -0.0287]]],


        ...,


        [[[-0.0084, -0.0112, -0.0057],
          [ 0.0012, -0.0009,  0.0067],
          [-0.0027, -0.0080,  0.0015]],

         [[-0.0101, -0.0119, -0.0067],
          [-0.0028, -0.0047,  0.0032],
          [-0.0066, -0.0112, -0.0005]],

         [[-0.0179, -0.0194, -0.0142],
          [-0.0079, -0.0082, -0.0017],
          [-0.0080, -0.0107, -0.0037]]],


        [[[ 0.0002,  0.0001,  0.0000],
          [ 0.0001,  0.0000, -0.0001],
          [ 0.0000, -0.0000, -0.0001]],

         [[ 0.0002,  0.0001,  0.0001],
          [ 0.0002,  0.0001,  0.0000],
          [ 0.0002,  0.0001,  0.0000]],

         [[ 0.0003,  0.0002,  0.0002],
          [ 0.0003,  0.0002,  0.0001],
          [ 0.0003,  0.0002,  0.0001]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5795]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 128 | Batch_idx: 0 |  Loss: (0.2063) | Acc: (94.00%) (121/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.2042) | Acc: (93.00%) (1317/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1980) | Acc: (93.00%) (2515/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1933) | Acc: (93.00%) (3718/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1900) | Acc: (93.00%) (4927/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1934) | Acc: (93.00%) (6121/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1871) | Acc: (93.00%) (7333/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1859) | Acc: (93.00%) (8527/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1861) | Acc: (93.00%) (9723/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1870) | Acc: (93.00%) (10918/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1858) | Acc: (93.00%) (12127/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1875) | Acc: (93.00%) (13321/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1896) | Acc: (93.00%) (14501/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1907) | Acc: (93.00%) (15695/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1940) | Acc: (93.00%) (16874/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1924) | Acc: (93.00%) (18076/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1933) | Acc: (93.00%) (19267/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1944) | Acc: (93.00%) (20460/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1952) | Acc: (93.00%) (21645/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1953) | Acc: (93.00%) (22844/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1964) | Acc: (93.00%) (24021/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1975) | Acc: (93.00%) (25211/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1966) | Acc: (93.00%) (26408/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1969) | Acc: (93.00%) (27604/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1981) | Acc: (93.00%) (28792/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1984) | Acc: (93.00%) (29985/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1996) | Acc: (93.00%) (31167/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1994) | Acc: (93.00%) (32360/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1997) | Acc: (93.00%) (33556/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.2002) | Acc: (93.00%) (34745/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1997) | Acc: (93.00%) (35944/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1991) | Acc: (93.00%) (37142/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1990) | Acc: (93.00%) (38342/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1987) | Acc: (93.00%) (39534/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1993) | Acc: (93.00%) (40716/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1995) | Acc: (93.00%) (41895/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1996) | Acc: (93.00%) (43089/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.2006) | Acc: (93.00%) (44268/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.2005) | Acc: (93.00%) (45463/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.2001) | Acc: (93.00%) (46619/50000)
# TEST : Loss: (0.3328) | Acc: (89.00%) (8970/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2827e-01,  3.6749e-01, -1.6762e-01],
          [-4.5094e-02,  1.3206e-02, -9.4533e-02],
          [ 7.4685e-02, -2.2622e-01,  2.7031e-01]],

         [[-1.2752e-01,  5.1942e-01,  1.0017e-01],
          [-1.5007e-02, -3.9069e-02, -1.7039e-01],
          [ 7.6218e-02, -4.2404e-01, -9.8117e-03]],

         [[-1.3930e-01,  2.9053e-01, -1.3317e-01],
          [ 5.2736e-02, -1.5805e-01, -1.2600e-01],
          [ 1.7806e-01, -9.5192e-02,  2.1024e-01]]],


        [[[-2.0201e-01, -4.1900e-01, -2.3951e-01],
          [-9.6719e-02,  2.2758e-01,  1.8688e-01],
          [ 1.9942e-01,  1.7980e-01,  2.5964e-01]],

         [[-2.6610e-01, -3.2986e-01, -2.1138e-01],
          [-1.2447e-01,  1.6949e-01,  2.2857e-01],
          [ 2.7923e-01,  1.3567e-01,  1.7462e-01]],

         [[-1.5042e-01, -4.7563e-02, -2.3539e-01],
          [ 5.8609e-02,  2.1784e-01, -4.8745e-02],
          [-3.3779e-03,  8.8061e-02,  6.6424e-02]]],


        [[[-9.3572e-02,  2.8593e-01,  1.0723e-01],
          [ 1.8728e-01,  2.2718e-01, -4.3558e-02],
          [-2.4738e-01, -7.1542e-02, -3.1634e-01]],

         [[ 6.1329e-02,  1.5886e-01,  3.4419e-02],
          [ 1.0953e-01,  2.8759e-01,  6.3345e-02],
          [-1.6632e-01, -1.3141e-01, -4.1849e-01]],

         [[-5.7805e-02,  1.6576e-01,  2.0088e-01],
          [ 6.1611e-02,  2.8411e-01,  1.0761e-01],
          [-2.6072e-01, -2.0455e-01, -2.7789e-01]]],


        ...,


        [[[-8.6593e-02, -1.2289e-01,  2.3375e-02],
          [ 5.3038e-02, -3.7994e-01, -1.4444e-01],
          [ 1.5398e-01, -5.3679e-02,  1.2200e-01]],

         [[ 1.5346e-01, -4.0907e-02, -1.9545e-03],
          [-5.8567e-02, -4.2013e-01, -2.2493e-01],
          [ 1.3006e-01,  8.3620e-03,  3.1626e-02]],

         [[ 2.0674e-01,  2.9069e-02,  8.1442e-02],
          [ 2.0241e-03, -2.7287e-01, -2.2639e-01],
          [ 1.0301e-01, -1.0872e-01, -1.0284e-01]]],


        [[[-2.2815e-02, -1.6661e-02, -1.3677e-02],
          [-7.4844e-03,  1.9346e-03,  6.8198e-03],
          [-1.5602e-03,  7.8516e-03,  1.4486e-02]],

         [[-1.2429e-02, -8.3054e-03, -6.3477e-03],
          [ 4.5911e-03,  1.3516e-02,  1.8833e-02],
          [ 1.3445e-02,  2.4292e-02,  3.1812e-02]],

         [[-6.6015e-03, -1.7254e-03,  1.0659e-03],
          [ 3.2952e-03,  1.2697e-02,  1.8324e-02],
          [ 1.1466e-02,  2.1119e-02,  2.6816e-02]]],


        [[[ 4.1491e-06, -5.8475e-07, -2.4116e-06],
          [ 1.0076e-06, -1.3727e-06, -3.6107e-06],
          [ 1.8687e-07, -1.1815e-06, -4.2106e-06]],

         [[ 1.5188e-08, -9.4092e-08, -2.1807e-07],
          [ 7.0210e-10, -1.4642e-07, -4.8583e-07],
          [-3.7865e-08, -3.2271e-07, -8.6712e-07]],

         [[-4.9794e-08, -5.7775e-07, -1.8194e-06],
          [-1.2983e-08, -4.7151e-07, -1.2727e-06],
          [-3.9678e-08, -3.0713e-07, -6.0042e-07]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0027,  0.0091,  0.0101],
          [-0.0147,  0.0022, -0.0116],
          [-0.0034,  0.0084, -0.0026]],

         [[ 0.0090,  0.0137,  0.0166],
          [-0.0041,  0.0081, -0.0019],
          [ 0.0057,  0.0170,  0.0041]],

         [[ 0.0142,  0.0190,  0.0223],
          [ 0.0028,  0.0156,  0.0054],
          [ 0.0144,  0.0206,  0.0033]]],


        [[[ 0.0229,  0.0258,  0.0280],
          [ 0.0191,  0.0265,  0.0243],
          [ 0.0183,  0.0225,  0.0173]],

         [[ 0.0437,  0.0456,  0.0473],
          [ 0.0410,  0.0481,  0.0456],
          [ 0.0407,  0.0457,  0.0421]],

         [[ 0.0387,  0.0400,  0.0423],
          [ 0.0404,  0.0466,  0.0425],
          [ 0.0449,  0.0464,  0.0404]]],


        [[[-0.0095, -0.0139, -0.0118],
          [-0.0214, -0.0252, -0.0233],
          [-0.0157, -0.0127, -0.0214]],

         [[-0.0098, -0.0099, -0.0047],
          [-0.0198, -0.0211, -0.0184],
          [-0.0139, -0.0110, -0.0189]],

         [[ 0.0015,  0.0015,  0.0036],
          [-0.0104, -0.0124, -0.0117],
          [-0.0065, -0.0036, -0.0129]]],


        ...,


        [[[-0.0015,  0.0051,  0.0078],
          [-0.0017,  0.0048,  0.0120],
          [ 0.0034,  0.0135,  0.0191]],

         [[-0.0082, -0.0037, -0.0011],
          [-0.0082, -0.0038,  0.0038],
          [-0.0007,  0.0087,  0.0142]],

         [[-0.0195, -0.0181, -0.0158],
          [-0.0195, -0.0177, -0.0113],
          [-0.0133, -0.0070, -0.0031]]],


        [[[-0.0002, -0.0002, -0.0001],
          [-0.0001, -0.0001, -0.0000],
          [-0.0001, -0.0000,  0.0000]],

         [[-0.0003, -0.0003, -0.0002],
          [-0.0002, -0.0002, -0.0001],
          [-0.0002, -0.0001, -0.0000]],

         [[-0.0004, -0.0003, -0.0002],
          [-0.0003, -0.0002, -0.0001],
          [-0.0002, -0.0001, -0.0001]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5778]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 129 | Batch_idx: 0 |  Loss: (0.1795) | Acc: (93.00%) (120/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1653) | Acc: (94.00%) (1327/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1854) | Acc: (94.00%) (2528/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.2043) | Acc: (93.00%) (3700/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.2043) | Acc: (93.00%) (4892/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.2050) | Acc: (93.00%) (6091/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.2048) | Acc: (93.00%) (7285/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.2055) | Acc: (93.00%) (8472/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.2039) | Acc: (93.00%) (9659/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.2011) | Acc: (93.00%) (10864/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1984) | Acc: (93.00%) (12070/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1985) | Acc: (93.00%) (13268/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1959) | Acc: (93.00%) (14467/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1940) | Acc: (93.00%) (15668/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1944) | Acc: (93.00%) (16869/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1927) | Acc: (93.00%) (18075/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1914) | Acc: (93.00%) (19280/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1906) | Acc: (93.00%) (20488/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1896) | Acc: (93.00%) (21693/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1886) | Acc: (93.00%) (22901/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1873) | Acc: (93.00%) (24110/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1868) | Acc: (93.00%) (25309/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1870) | Acc: (93.00%) (26505/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1866) | Acc: (93.00%) (27704/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1860) | Acc: (93.00%) (28903/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1853) | Acc: (93.00%) (30112/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1833) | Acc: (93.00%) (31332/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1825) | Acc: (93.00%) (32540/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1816) | Acc: (93.00%) (33749/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1817) | Acc: (93.00%) (34963/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1808) | Acc: (93.00%) (36175/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1804) | Acc: (93.00%) (37389/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1805) | Acc: (93.00%) (38592/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1804) | Acc: (93.00%) (39788/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1797) | Acc: (93.00%) (40993/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1798) | Acc: (93.00%) (42195/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1796) | Acc: (93.00%) (43403/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1794) | Acc: (93.00%) (44613/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1789) | Acc: (93.00%) (45821/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1780) | Acc: (93.00%) (46997/50000)
# TEST : Loss: (0.2958) | Acc: (90.00%) (9065/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2980e-01,  3.6458e-01, -1.7076e-01],
          [-4.5225e-02,  1.2371e-02, -9.5749e-02],
          [ 7.4188e-02, -2.2706e-01,  2.6751e-01]],

         [[-1.2902e-01,  5.1586e-01,  9.6145e-02],
          [-1.5465e-02, -3.9835e-02, -1.7179e-01],
          [ 7.5386e-02, -4.2430e-01, -1.2132e-02]],

         [[-1.3977e-01,  2.8838e-01, -1.3543e-01],
          [ 5.3351e-02, -1.5732e-01, -1.2631e-01],
          [ 1.7817e-01, -9.4849e-02,  2.0879e-01]]],


        [[[-2.0203e-01, -4.1868e-01, -2.3869e-01],
          [-9.6950e-02,  2.2683e-01,  1.8726e-01],
          [ 1.9847e-01,  1.7923e-01,  2.6001e-01]],

         [[-2.6663e-01, -3.3023e-01, -2.1111e-01],
          [-1.2542e-01,  1.6811e-01,  2.2822e-01],
          [ 2.7698e-01,  1.3394e-01,  1.7398e-01]],

         [[-1.5139e-01, -4.8716e-02, -2.3544e-01],
          [ 5.6630e-02,  2.1572e-01, -4.9302e-02],
          [-5.9201e-03,  8.5625e-02,  6.5090e-02]]],


        [[[-9.0196e-02,  2.8808e-01,  1.0905e-01],
          [ 1.9077e-01,  2.2990e-01, -4.1470e-02],
          [-2.4375e-01, -6.9150e-02, -3.1380e-01]],

         [[ 6.4970e-02,  1.6127e-01,  3.6094e-02],
          [ 1.1380e-01,  2.9056e-01,  6.5422e-02],
          [-1.6190e-01, -1.2818e-01, -4.1517e-01]],

         [[-5.4980e-02,  1.6686e-01,  2.0102e-01],
          [ 6.5048e-02,  2.8587e-01,  1.0855e-01],
          [-2.5693e-01, -2.0218e-01, -2.7570e-01]]],


        ...,


        [[[-8.3558e-02, -1.2081e-01,  2.3594e-02],
          [ 5.4152e-02, -3.7608e-01, -1.4455e-01],
          [ 1.5435e-01, -5.3987e-02,  1.1925e-01]],

         [[ 1.5581e-01, -3.8260e-02, -5.2088e-04],
          [-5.6844e-02, -4.1456e-01, -2.2430e-01],
          [ 1.3047e-01,  7.3844e-03,  2.8522e-02]],

         [[ 2.1059e-01,  3.3891e-02,  8.5228e-02],
          [ 6.3224e-03, -2.6537e-01, -2.2113e-01],
          [ 1.0615e-01, -1.0516e-01, -1.0102e-01]]],


        [[[-7.5721e-03, -5.9757e-03, -6.5202e-03],
          [-7.3141e-04,  1.9826e-04,  1.0331e-04],
          [ 2.1603e-03,  2.7588e-03,  3.4756e-03]],

         [[-2.6127e-03, -2.5931e-03, -3.6566e-03],
          [ 4.5526e-03,  4.2489e-03,  3.9433e-03],
          [ 8.2601e-03,  7.6453e-03,  8.2279e-03]],

         [[-3.1316e-04,  6.2152e-04,  2.8184e-04],
          [ 4.7708e-03,  6.9087e-03,  7.4298e-03],
          [ 8.8385e-03,  1.0900e-02,  1.1769e-02]]],


        [[[ 3.2215e-07, -4.3338e-08, -1.5403e-07],
          [ 5.9540e-08, -9.3767e-08, -2.5438e-07],
          [ 9.9481e-09, -7.6330e-08, -3.3175e-07]],

         [[ 3.3356e-10, -2.4669e-09, -6.0490e-09],
          [ 1.0382e-11, -4.1268e-09, -1.7521e-08],
          [-1.1403e-09, -1.2557e-08, -4.0998e-08]],

         [[-1.0874e-09, -2.1610e-08, -9.0279e-08],
          [-1.6954e-10, -1.5887e-08, -5.6217e-08],
          [-6.9992e-10, -9.2447e-09, -2.1538e-08]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5552]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0254]], device='cuda:0')

Epoch: 130 | Batch_idx: 0 |  Loss: (0.1875) | Acc: (96.00%) (123/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1651) | Acc: (94.00%) (1335/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1627) | Acc: (94.00%) (2551/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1685) | Acc: (94.00%) (3753/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1658) | Acc: (94.00%) (4968/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1671) | Acc: (94.00%) (6170/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1659) | Acc: (94.00%) (7382/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1650) | Acc: (94.00%) (8592/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1657) | Acc: (94.00%) (9797/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1660) | Acc: (94.00%) (11002/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1654) | Acc: (94.00%) (12213/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1679) | Acc: (94.00%) (13412/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1699) | Acc: (94.00%) (14609/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1692) | Acc: (94.00%) (15809/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1692) | Acc: (94.00%) (17005/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1695) | Acc: (94.00%) (18208/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1706) | Acc: (94.00%) (19410/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1708) | Acc: (94.00%) (20609/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1702) | Acc: (94.00%) (21824/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1691) | Acc: (94.00%) (23039/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1683) | Acc: (94.00%) (24252/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1666) | Acc: (94.00%) (25477/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1675) | Acc: (94.00%) (26676/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1671) | Acc: (94.00%) (27893/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1666) | Acc: (94.00%) (29107/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1658) | Acc: (94.00%) (30334/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1653) | Acc: (94.00%) (31548/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1648) | Acc: (94.00%) (32761/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1643) | Acc: (94.00%) (33982/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1647) | Acc: (94.00%) (35190/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1643) | Acc: (94.00%) (36409/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1638) | Acc: (94.00%) (37623/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1644) | Acc: (94.00%) (38828/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1636) | Acc: (94.00%) (40052/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1630) | Acc: (94.00%) (41271/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1628) | Acc: (94.00%) (42477/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1627) | Acc: (94.00%) (43689/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1621) | Acc: (94.00%) (44907/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1623) | Acc: (94.00%) (46118/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1625) | Acc: (94.00%) (47285/50000)
# TEST : Loss: (0.2877) | Acc: (90.00%) (9086/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2937e-01,  3.6330e-01, -1.7020e-01],
          [-4.5072e-02,  1.2329e-02, -9.5432e-02],
          [ 7.3932e-02, -2.2625e-01,  2.6663e-01]],

         [[-1.2857e-01,  5.1397e-01,  9.5821e-02],
          [-1.5410e-02, -3.9694e-02, -1.7120e-01],
          [ 7.5117e-02, -4.2272e-01, -1.2090e-02]],

         [[-1.3926e-01,  2.8729e-01, -1.3495e-01],
          [ 5.3156e-02, -1.5674e-01, -1.2586e-01],
          [ 1.7752e-01, -9.4490e-02,  2.0804e-01]]],


        [[[-2.0157e-01, -4.1773e-01, -2.3815e-01],
          [-9.6725e-02,  2.2630e-01,  1.8683e-01],
          [ 1.9798e-01,  1.7879e-01,  2.5938e-01]],

         [[-2.6599e-01, -3.2944e-01, -2.1061e-01],
          [-1.2511e-01,  1.6771e-01,  2.2766e-01],
          [ 2.7628e-01,  1.3360e-01,  1.7354e-01]],

         [[-1.5101e-01, -4.8594e-02, -2.3486e-01],
          [ 5.6488e-02,  2.1518e-01, -4.9180e-02],
          [-5.9049e-03,  8.5405e-02,  6.4922e-02]]],


        [[[-9.0009e-02,  2.8749e-01,  1.0882e-01],
          [ 1.9039e-01,  2.2944e-01, -4.1385e-02],
          [-2.4325e-01, -6.9007e-02, -3.1314e-01]],

         [[ 6.4832e-02,  1.6093e-01,  3.6017e-02],
          [ 1.1356e-01,  2.8995e-01,  6.5284e-02],
          [-1.6156e-01, -1.2791e-01, -4.1427e-01]],

         [[-5.4857e-02,  1.6649e-01,  2.0057e-01],
          [ 6.4906e-02,  2.8524e-01,  1.0831e-01],
          [-2.5636e-01, -2.0172e-01, -2.7506e-01]]],


        ...,


        [[[-8.3143e-02, -1.2001e-01,  2.3448e-02],
          [ 5.3830e-02, -3.7215e-01, -1.4317e-01],
          [ 1.5360e-01, -5.3642e-02,  1.1849e-01]],

         [[ 1.5499e-01, -3.7983e-02, -5.1737e-04],
          [-5.6470e-02, -4.0891e-01, -2.2170e-01],
          [ 1.2979e-01,  7.3312e-03,  2.8324e-02]],

         [[ 2.0948e-01,  3.3666e-02,  8.4674e-02],
          [ 6.2824e-03, -2.6291e-01, -2.1910e-01],
          [ 1.0558e-01, -1.0444e-01, -1.0031e-01]]],


        [[[-2.4524e-03, -1.5957e-03, -1.7332e-03],
          [-1.9317e-04,  3.7485e-05,  1.8750e-05],
          [ 5.9879e-04,  5.4155e-04,  6.6273e-04]],

         [[-8.8488e-04, -7.3298e-04, -9.9945e-04],
          [ 1.2645e-03,  8.6211e-04,  7.5910e-04],
          [ 2.2762e-03,  1.4528e-03,  1.5028e-03]],

         [[-1.2958e-04,  2.3500e-04,  1.0213e-04],
          [ 1.8396e-03,  2.4006e-03,  2.4245e-03],
          [ 3.3608e-03,  3.7338e-03,  3.8461e-03]]],


        [[[ 1.3718e-08, -1.7405e-09, -5.1285e-09],
          [ 1.7971e-09, -3.3982e-09, -9.5850e-09],
          [ 2.6315e-10, -2.5784e-09, -1.4390e-08]],

         [[ 2.8501e-12, -2.6466e-11, -6.9763e-11],
          [ 5.3174e-14, -4.8576e-11, -2.8263e-10],
          [-1.4610e-11, -2.2312e-10, -9.3312e-10]],

         [[-9.2238e-12, -3.6514e-10, -2.1846e-09],
          [-7.3873e-13, -2.3497e-10, -1.1737e-09],
          [-4.5066e-12, -1.1837e-10, -3.4505e-10]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5463]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0086]], device='cuda:0')

Epoch: 131 | Batch_idx: 0 |  Loss: (0.1403) | Acc: (95.00%) (122/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1359) | Acc: (94.00%) (1337/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1392) | Acc: (94.00%) (2548/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1477) | Acc: (94.00%) (3752/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1560) | Acc: (94.00%) (4947/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1570) | Acc: (94.00%) (6159/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1576) | Acc: (94.00%) (7373/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1569) | Acc: (94.00%) (8590/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1593) | Acc: (94.00%) (9796/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1607) | Acc: (94.00%) (11007/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1618) | Acc: (94.00%) (12209/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1623) | Acc: (94.00%) (13418/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1608) | Acc: (94.00%) (14638/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1625) | Acc: (94.00%) (15840/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1630) | Acc: (94.00%) (17040/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1616) | Acc: (94.00%) (18255/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1605) | Acc: (94.00%) (19480/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1609) | Acc: (94.00%) (20686/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1598) | Acc: (94.00%) (21907/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1601) | Acc: (94.00%) (23116/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1593) | Acc: (94.00%) (24327/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1589) | Acc: (94.00%) (25540/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1583) | Acc: (94.00%) (26760/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1599) | Acc: (94.00%) (27954/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1601) | Acc: (94.00%) (29163/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1601) | Acc: (94.00%) (30377/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1609) | Acc: (94.00%) (31583/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1600) | Acc: (94.00%) (32805/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1607) | Acc: (94.00%) (34009/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1600) | Acc: (94.00%) (35231/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1601) | Acc: (94.00%) (36433/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1608) | Acc: (94.00%) (37635/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1605) | Acc: (94.00%) (38851/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1593) | Acc: (94.00%) (40082/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1596) | Acc: (94.00%) (41294/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1596) | Acc: (94.00%) (42511/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1594) | Acc: (94.00%) (43727/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1596) | Acc: (94.00%) (44934/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1601) | Acc: (94.00%) (46126/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1600) | Acc: (94.00%) (47297/50000)
# TEST : Loss: (0.2843) | Acc: (90.00%) (9068/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2884e-01,  3.6175e-01, -1.6952e-01],
          [-4.4886e-02,  1.2278e-02, -9.5048e-02],
          [ 7.3621e-02, -2.2527e-01,  2.6555e-01]],

         [[-1.2802e-01,  5.1167e-01,  9.5428e-02],
          [-1.5344e-02, -3.9524e-02, -1.7049e-01],
          [ 7.4791e-02, -4.2080e-01, -1.2040e-02]],

         [[-1.3864e-01,  2.8596e-01, -1.3437e-01],
          [ 5.2919e-02, -1.5605e-01, -1.2531e-01],
          [ 1.7673e-01, -9.4055e-02,  2.0713e-01]]],


        [[[-2.0101e-01, -4.1657e-01, -2.3748e-01],
          [-9.6453e-02,  2.2567e-01,  1.8630e-01],
          [ 1.9740e-01,  1.7826e-01,  2.5861e-01]],

         [[-2.6521e-01, -3.2849e-01, -2.1000e-01],
          [-1.2474e-01,  1.6721e-01,  2.2700e-01],
          [ 2.7543e-01,  1.3319e-01,  1.7301e-01]],

         [[-1.5055e-01, -4.8447e-02, -2.3415e-01],
          [ 5.6315e-02,  2.1453e-01, -4.9032e-02],
          [-5.8864e-03,  8.5138e-02,  6.4720e-02]]],


        [[[-8.9783e-02,  2.8676e-01,  1.0854e-01],
          [ 1.8992e-01,  2.2887e-01, -4.1282e-02],
          [-2.4265e-01, -6.8833e-02, -3.1234e-01]],

         [[ 6.4665e-02,  1.6051e-01,  3.5925e-02],
          [ 1.1328e-01,  2.8922e-01,  6.5117e-02],
          [-1.6115e-01, -1.2757e-01, -4.1318e-01]],

         [[-5.4708e-02,  1.6604e-01,  2.0003e-01],
          [ 6.4734e-02,  2.8448e-01,  1.0802e-01],
          [-2.5566e-01, -2.0116e-01, -2.7428e-01]]],


        ...,


        [[[-8.2642e-02, -1.1905e-01,  2.3271e-02],
          [ 5.3440e-02, -3.6744e-01, -1.4152e-01],
          [ 1.5269e-01, -5.3226e-02,  1.1758e-01]],

         [[ 1.5400e-01, -3.7649e-02, -5.1312e-04],
          [-5.6020e-02, -4.0215e-01, -2.1858e-01],
          [ 1.2896e-01,  7.2671e-03,  2.8084e-02]],

         [[ 2.0814e-01,  3.3394e-02,  8.4006e-02],
          [ 6.2341e-03, -2.5995e-01, -2.1666e-01],
          [ 1.0488e-01, -1.0356e-01, -9.9469e-02]]],


        [[[-6.1726e-04, -3.1656e-04, -3.4191e-04],
          [-3.7802e-05,  4.8504e-06,  2.3062e-06],
          [ 1.2438e-04,  7.3411e-05,  8.6659e-05]],

         [[-2.3532e-04, -1.5598e-04, -2.0406e-04],
          [ 2.6334e-04,  1.2176e-04,  1.0044e-04],
          [ 4.6944e-04,  1.8916e-04,  1.8631e-04]],

         [[-4.4082e-05,  7.1559e-05,  2.9515e-05],
          [ 5.7385e-04,  6.5890e-04,  6.1590e-04],
          [ 1.0306e-03,  1.0069e-03,  9.7883e-04]]],


        [[[ 2.7338e-10, -3.2199e-11, -7.4708e-11],
          [ 2.3094e-11, -5.5158e-11, -1.6349e-10],
          [ 2.8555e-12, -3.8260e-11, -2.9356e-10]],

         [[ 7.1234e-15, -8.9201e-14, -2.5846e-13],
          [ 6.7395e-17, -1.8483e-13, -1.6206e-12],
          [-6.2101e-14, -1.4502e-12, -8.3474e-12]],

         [[-2.2833e-14, -2.2236e-12, -2.1144e-11],
          [-7.5387e-16, -1.2038e-12, -9.3941e-12],
          [-7.7474e-15, -5.0273e-13, -1.9611e-12]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5267]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0572]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 132 | Batch_idx: 0 |  Loss: (0.2058) | Acc: (92.00%) (118/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1652) | Acc: (94.00%) (1324/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1849) | Acc: (93.00%) (2508/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.2126) | Acc: (92.00%) (3670/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.2327) | Acc: (91.00%) (4827/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.2455) | Acc: (91.00%) (5975/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.2560) | Acc: (91.00%) (7122/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.2577) | Acc: (91.00%) (8286/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.2605) | Acc: (91.00%) (9435/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.2646) | Acc: (90.00%) (10577/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.2685) | Acc: (90.00%) (11731/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.2719) | Acc: (90.00%) (12877/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.2732) | Acc: (90.00%) (14030/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.2761) | Acc: (90.00%) (15176/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.2784) | Acc: (90.00%) (16325/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.2786) | Acc: (90.00%) (17481/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.2752) | Acc: (90.00%) (18662/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.2730) | Acc: (90.00%) (19843/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.2720) | Acc: (90.00%) (21009/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.2694) | Acc: (90.00%) (22190/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.2676) | Acc: (90.00%) (23368/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.2663) | Acc: (90.00%) (24539/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.2671) | Acc: (90.00%) (25686/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.2660) | Acc: (90.00%) (26848/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.2652) | Acc: (90.00%) (28015/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.2654) | Acc: (90.00%) (29180/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.2649) | Acc: (90.00%) (30348/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.2640) | Acc: (90.00%) (31529/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.2636) | Acc: (90.00%) (32696/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.2624) | Acc: (90.00%) (33878/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.2621) | Acc: (90.00%) (35047/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.2614) | Acc: (90.00%) (36224/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.2611) | Acc: (90.00%) (37389/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.2613) | Acc: (91.00%) (38557/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.2604) | Acc: (91.00%) (39736/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.2597) | Acc: (91.00%) (40911/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.2594) | Acc: (91.00%) (42098/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.2590) | Acc: (91.00%) (43263/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.2586) | Acc: (91.00%) (44431/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.2581) | Acc: (91.00%) (45561/50000)
# TEST : Loss: (0.3635) | Acc: (88.00%) (8852/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4171e-01,  3.7314e-01, -1.6570e-01],
          [-4.7228e-02,  2.0269e-02, -9.3349e-02],
          [ 7.4993e-02, -2.2544e-01,  2.7038e-01]],

         [[-1.5289e-01,  5.1039e-01,  9.2750e-02],
          [-1.5957e-02, -3.8989e-02, -1.7401e-01],
          [ 7.5504e-02, -4.2181e-01, -9.1064e-03]],

         [[-1.6626e-01,  2.7814e-01, -1.3488e-01],
          [ 4.3324e-02, -1.5751e-01, -1.3462e-01],
          [ 1.7268e-01, -9.3573e-02,  1.9953e-01]]],


        [[[-1.9621e-01, -4.2070e-01, -2.4352e-01],
          [-8.6869e-02,  2.2876e-01,  1.8621e-01],
          [ 2.0239e-01,  1.8287e-01,  2.6019e-01]],

         [[-2.6749e-01, -3.3558e-01, -2.1562e-01],
          [-1.2261e-01,  1.6694e-01,  2.2646e-01],
          [ 2.7294e-01,  1.3006e-01,  1.6848e-01]],

         [[-1.5470e-01, -6.0638e-02, -2.4808e-01],
          [ 5.5069e-02,  2.0895e-01, -5.5920e-02],
          [-1.4216e-02,  7.5255e-02,  5.2512e-02]]],


        [[[-1.0559e-01,  2.8388e-01,  1.0871e-01],
          [ 1.8045e-01,  2.3124e-01, -3.3327e-02],
          [-2.5520e-01, -7.2834e-02, -3.1257e-01]],

         [[ 5.0278e-02,  1.5697e-01,  3.3701e-02],
          [ 1.0292e-01,  2.8813e-01,  7.0021e-02],
          [-1.7383e-01, -1.3298e-01, -4.1359e-01]],

         [[-6.8859e-02,  1.6165e-01,  2.0223e-01],
          [ 5.2965e-02,  2.8139e-01,  1.1619e-01],
          [-2.7028e-01, -2.0776e-01, -2.7358e-01]]],


        ...,


        [[[-8.9393e-02, -1.1545e-01,  2.7217e-02],
          [ 3.8843e-02, -3.8495e-01, -1.5412e-01],
          [ 1.4989e-01, -6.1829e-02,  1.0899e-01]],

         [[ 1.5957e-01, -2.6870e-02,  7.7460e-04],
          [-5.5045e-02, -4.0736e-01, -2.3100e-01],
          [ 1.3465e-01,  4.2023e-03,  2.2652e-02]],

         [[ 2.0743e-01,  3.6879e-02,  7.9567e-02],
          [ 3.3655e-03, -2.6589e-01, -2.2436e-01],
          [ 1.0155e-01, -1.1762e-01, -1.0812e-01]]],


        [[[ 2.0792e-02,  2.1311e-02,  1.7830e-02],
          [ 3.1457e-02,  3.1885e-02,  2.9792e-02],
          [ 5.6235e-02,  6.0847e-02,  6.5477e-02]],

         [[ 1.4130e-02,  5.8025e-03, -3.5100e-04],
          [ 2.5582e-02,  2.2004e-02,  1.6227e-02],
          [ 4.9073e-02,  5.3224e-02,  5.5200e-02]],

         [[-4.4235e-03, -6.3206e-03, -4.6839e-03],
          [ 2.9557e-03,  2.8869e-03,  3.1935e-03],
          [ 2.0511e-02,  2.2213e-02,  2.5376e-02]]],


        [[[ 2.0607e-12, -2.2047e-13, -3.7529e-13],
          [ 9.8536e-14, -3.1884e-13, -1.0078e-12],
          [ 9.7687e-15, -1.9686e-13, -2.2807e-12]],

         [[ 3.4211e-18, -6.4375e-17, -2.1200e-16],
          [ 1.2613e-20, -1.5717e-16, -2.3880e-15],
          [-6.1297e-17, -2.5245e-15, -2.2163e-14]],

         [[-1.0822e-17, -3.5499e-15, -6.2265e-14],
          [-1.0383e-19, -1.5264e-15, -2.1542e-14],
          [-2.2207e-18, -4.9566e-16, -2.8558e-15]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0027,  0.0056,  0.0112],
          [-0.0048,  0.0019,  0.0095],
          [-0.0043,  0.0001,  0.0050]],

         [[-0.0048,  0.0012,  0.0081],
          [-0.0105, -0.0026,  0.0024],
          [-0.0027,  0.0027,  0.0018]],

         [[-0.0013,  0.0044,  0.0132],
          [-0.0057,  0.0044,  0.0095],
          [ 0.0031,  0.0078,  0.0057]]],


        [[[-0.0055, -0.0051, -0.0088],
          [-0.0112, -0.0069, -0.0084],
          [-0.0091, -0.0012, -0.0018]],

         [[ 0.0080,  0.0069,  0.0029],
          [ 0.0022,  0.0051,  0.0046],
          [-0.0008,  0.0060,  0.0077]],

         [[-0.0050, -0.0063, -0.0112],
          [-0.0113, -0.0098, -0.0103],
          [-0.0147, -0.0093, -0.0060]]],


        [[[ 0.0333,  0.0351,  0.0375],
          [ 0.0349,  0.0374,  0.0376],
          [ 0.0385,  0.0405,  0.0423]],

         [[ 0.0565,  0.0568,  0.0598],
          [ 0.0517,  0.0540,  0.0560],
          [ 0.0512,  0.0536,  0.0566]],

         [[ 0.0745,  0.0749,  0.0762],
          [ 0.0677,  0.0713,  0.0733],
          [ 0.0670,  0.0709,  0.0726]]],


        ...,


        [[[ 0.0094,  0.0075,  0.0071],
          [ 0.0015, -0.0005,  0.0029],
          [ 0.0070,  0.0051,  0.0100]],

         [[ 0.0122,  0.0102,  0.0112],
          [ 0.0052,  0.0034,  0.0079],
          [ 0.0145,  0.0112,  0.0160]],

         [[ 0.0101,  0.0097,  0.0129],
          [ 0.0045,  0.0036,  0.0090],
          [ 0.0130,  0.0090,  0.0138]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5283]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 133 | Batch_idx: 0 |  Loss: (0.2322) | Acc: (92.00%) (118/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.2300) | Acc: (92.00%) (1300/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.2079) | Acc: (93.00%) (2504/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.2013) | Acc: (93.00%) (3698/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1999) | Acc: (93.00%) (4891/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.2014) | Acc: (93.00%) (6083/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.2106) | Acc: (93.00%) (7265/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.2084) | Acc: (93.00%) (8457/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.2086) | Acc: (92.00%) (9640/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.2053) | Acc: (93.00%) (10844/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.2047) | Acc: (93.00%) (12042/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.2065) | Acc: (93.00%) (13220/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.2071) | Acc: (93.00%) (14408/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.2093) | Acc: (92.00%) (15590/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.2084) | Acc: (92.00%) (16782/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.2093) | Acc: (92.00%) (17974/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.2093) | Acc: (93.00%) (19170/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.2086) | Acc: (93.00%) (20359/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.2089) | Acc: (92.00%) (21543/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.2082) | Acc: (93.00%) (22740/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.2074) | Acc: (93.00%) (23929/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.2090) | Acc: (92.00%) (25098/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.2089) | Acc: (92.00%) (26278/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.2090) | Acc: (92.00%) (27461/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.2093) | Acc: (92.00%) (28650/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.2096) | Acc: (92.00%) (29837/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.2099) | Acc: (92.00%) (31027/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.2099) | Acc: (92.00%) (32225/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.2101) | Acc: (92.00%) (33414/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.2108) | Acc: (92.00%) (34591/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.2111) | Acc: (92.00%) (35770/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.2106) | Acc: (92.00%) (36959/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.2107) | Acc: (92.00%) (38138/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.2094) | Acc: (92.00%) (39339/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.2101) | Acc: (92.00%) (40509/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.2108) | Acc: (92.00%) (41691/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.2107) | Acc: (92.00%) (42882/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.2098) | Acc: (92.00%) (44078/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.2102) | Acc: (92.00%) (45253/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.2105) | Acc: (92.00%) (46388/50000)
# TEST : Loss: (0.3862) | Acc: (88.00%) (8819/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3449e-01,  3.8132e-01, -1.6894e-01],
          [-3.1751e-02,  2.9601e-02, -9.3353e-02],
          [ 7.9332e-02, -2.2311e-01,  2.7186e-01]],

         [[-1.4429e-01,  5.1904e-01,  9.2531e-02],
          [ 6.4944e-04, -3.1189e-02, -1.7327e-01],
          [ 8.1946e-02, -4.1831e-01, -6.9595e-03]],

         [[-1.5615e-01,  2.9128e-01, -1.3134e-01],
          [ 5.8085e-02, -1.4476e-01, -1.3200e-01],
          [ 1.7893e-01, -8.0149e-02,  2.0551e-01]]],


        [[[-1.9733e-01, -4.2657e-01, -2.4776e-01],
          [-8.3172e-02,  2.2878e-01,  1.8622e-01],
          [ 2.0377e-01,  1.8363e-01,  2.6330e-01]],

         [[-2.6851e-01, -3.4041e-01, -2.1589e-01],
          [-1.1984e-01,  1.6676e-01,  2.2697e-01],
          [ 2.7149e-01,  1.2735e-01,  1.6788e-01]],

         [[-1.5766e-01, -6.6720e-02, -2.4877e-01],
          [ 5.5537e-02,  2.0760e-01, -5.5012e-02],
          [-2.2525e-02,  6.7464e-02,  4.8176e-02]]],


        [[[-1.0516e-01,  2.8168e-01,  1.1001e-01],
          [ 1.8370e-01,  2.2940e-01, -4.0011e-02],
          [-2.5266e-01, -7.6025e-02, -3.1934e-01]],

         [[ 4.5968e-02,  1.5317e-01,  3.3029e-02],
          [ 1.0149e-01,  2.8397e-01,  6.1086e-02],
          [-1.7752e-01, -1.3797e-01, -4.2063e-01]],

         [[-6.3523e-02,  1.6709e-01,  2.0913e-01],
          [ 5.9202e-02,  2.8394e-01,  1.1287e-01],
          [-2.6847e-01, -2.0724e-01, -2.7671e-01]]],


        ...,


        [[[-8.4694e-02, -1.1704e-01,  3.2777e-02],
          [ 4.3739e-02, -3.8702e-01, -1.4921e-01],
          [ 1.5495e-01, -5.4916e-02,  1.1925e-01]],

         [[ 1.5407e-01, -3.8760e-02,  5.9909e-04],
          [-6.0689e-02, -4.2499e-01, -2.3483e-01],
          [ 1.3097e-01,  6.9674e-03,  3.5204e-02]],

         [[ 2.0147e-01,  2.9205e-02,  8.9080e-02],
          [-3.5480e-03, -2.7962e-01, -2.2002e-01],
          [ 9.6974e-02, -1.1668e-01, -9.5621e-02]]],


        [[[ 1.4115e-02,  1.4337e-02,  1.2094e-02],
          [ 2.0160e-02,  2.0059e-02,  1.9387e-02],
          [ 3.5851e-02,  3.7280e-02,  4.1461e-02]],

         [[ 9.2140e-03,  3.7146e-03, -2.2575e-04],
          [ 1.5572e-02,  1.2821e-02,  9.8401e-03],
          [ 2.9712e-02,  2.9948e-02,  3.2707e-02]],

         [[-2.6478e-03, -3.6864e-03, -2.7527e-03],
          [ 1.7373e-03,  1.6205e-03,  1.8248e-03],
          [ 1.2480e-02,  1.2750e-02,  1.4750e-02]]],


        [[[ 4.3655e-15, -4.1126e-16, -4.6346e-16],
          [ 9.7761e-17, -4.7492e-16, -1.6351e-15],
          [ 7.1938e-18, -2.5103e-16, -5.0284e-15]],

         [[ 1.5789e-22, -5.3939e-21, -2.1364e-20],
          [ 1.3736e-25, -1.6680e-20, -5.5213e-19],
          [-8.0514e-21, -7.3629e-19, -1.1562e-17]],

         [[-4.8982e-22, -9.1792e-19, -3.7408e-17],
          [-6.8940e-25, -2.8583e-19, -9.1931e-18],
          [-4.7068e-23, -6.5001e-20, -6.4947e-19]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0301,  0.0129,  0.0223],
          [ 0.0265,  0.0106,  0.0188],
          [ 0.0150, -0.0087, -0.0046]],

         [[ 0.0422,  0.0162,  0.0231],
          [ 0.0413,  0.0161,  0.0212],
          [ 0.0198, -0.0101, -0.0111]],

         [[ 0.0465,  0.0210,  0.0296],
          [ 0.0482,  0.0245,  0.0324],
          [ 0.0308,  0.0055,  0.0089]]],


        [[[-0.0514, -0.0298, -0.0324],
          [-0.0514, -0.0268, -0.0123],
          [-0.0547, -0.0338, -0.0157]],

         [[-0.0163,  0.0084,  0.0047],
          [-0.0227, -0.0008,  0.0113],
          [-0.0298, -0.0127,  0.0029]],

         [[-0.0047,  0.0177,  0.0144],
          [-0.0099,  0.0115,  0.0231],
          [-0.0128,  0.0063,  0.0207]]],


        [[[ 0.1280,  0.1289,  0.1179],
          [ 0.1088,  0.1093,  0.1042],
          [ 0.1071,  0.1157,  0.1175]],

         [[ 0.1138,  0.1144,  0.1074],
          [ 0.0906,  0.0912,  0.0924],
          [ 0.0917,  0.0972,  0.1047]],

         [[ 0.0995,  0.1014,  0.0973],
          [ 0.0768,  0.0788,  0.0822],
          [ 0.0807,  0.0850,  0.0929]]],


        ...,


        [[[ 0.0310,  0.0068,  0.0120],
          [ 0.0223,  0.0001,  0.0047],
          [ 0.0266,  0.0077,  0.0140]],

         [[ 0.0326,  0.0114,  0.0204],
          [ 0.0261,  0.0090,  0.0174],
          [ 0.0282,  0.0142,  0.0239]],

         [[ 0.0332,  0.0184,  0.0274],
          [ 0.0310,  0.0172,  0.0246],
          [ 0.0308,  0.0181,  0.0270]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5272]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 134 | Batch_idx: 0 |  Loss: (0.2158) | Acc: (92.00%) (118/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.2258) | Acc: (92.00%) (1302/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.2161) | Acc: (92.00%) (2490/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.2092) | Acc: (92.00%) (3675/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.2080) | Acc: (92.00%) (4864/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.2027) | Acc: (92.00%) (6070/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1927) | Acc: (93.00%) (7293/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1898) | Acc: (93.00%) (8496/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1893) | Acc: (93.00%) (9694/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1922) | Acc: (93.00%) (10875/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1906) | Acc: (93.00%) (12077/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1905) | Acc: (93.00%) (13274/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1898) | Acc: (93.00%) (14474/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1890) | Acc: (93.00%) (15679/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1894) | Acc: (93.00%) (16882/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1887) | Acc: (93.00%) (18086/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1873) | Acc: (93.00%) (19288/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1870) | Acc: (93.00%) (20480/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1879) | Acc: (93.00%) (21674/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1873) | Acc: (93.00%) (22878/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1884) | Acc: (93.00%) (24056/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1887) | Acc: (93.00%) (25253/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1893) | Acc: (93.00%) (26447/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1900) | Acc: (93.00%) (27628/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1896) | Acc: (93.00%) (28827/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1893) | Acc: (93.00%) (30023/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1897) | Acc: (93.00%) (31211/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1906) | Acc: (93.00%) (32401/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1900) | Acc: (93.00%) (33602/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1898) | Acc: (93.00%) (34801/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1908) | Acc: (93.00%) (35996/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1923) | Acc: (93.00%) (37171/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1931) | Acc: (93.00%) (38359/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1929) | Acc: (93.00%) (39560/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1928) | Acc: (93.00%) (40756/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1934) | Acc: (93.00%) (41939/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1935) | Acc: (93.00%) (43143/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1933) | Acc: (93.00%) (44346/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1936) | Acc: (93.00%) (45538/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1934) | Acc: (93.00%) (46684/50000)
# TEST : Loss: (0.3107) | Acc: (90.00%) (9032/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3962e-01,  3.8682e-01, -1.6516e-01],
          [-3.8418e-02,  3.0599e-02, -9.2787e-02],
          [ 6.9517e-02, -2.2095e-01,  2.6788e-01]],

         [[-1.5406e-01,  5.2750e-01,  1.0087e-01],
          [-1.3427e-03, -2.9842e-02, -1.6977e-01],
          [ 7.5358e-02, -4.1942e-01, -9.5831e-03]],

         [[-1.7057e-01,  2.9142e-01, -1.2903e-01],
          [ 5.2617e-02, -1.4609e-01, -1.3123e-01],
          [ 1.6804e-01, -8.0055e-02,  2.0000e-01]]],


        [[[-2.0229e-01, -4.2824e-01, -2.4712e-01],
          [-8.4915e-02,  2.2688e-01,  1.8464e-01],
          [ 2.0670e-01,  1.8474e-01,  2.6180e-01]],

         [[-2.6798e-01, -3.3817e-01, -2.1118e-01],
          [-1.1728e-01,  1.6889e-01,  2.3025e-01],
          [ 2.8219e-01,  1.3556e-01,  1.7351e-01]],

         [[-1.6029e-01, -6.4715e-02, -2.4330e-01],
          [ 5.5012e-02,  2.0990e-01, -4.9561e-02],
          [-1.3895e-02,  7.4570e-02,  5.3212e-02]]],


        [[[-1.0535e-01,  2.7753e-01,  1.0382e-01],
          [ 1.8862e-01,  2.2812e-01, -4.3345e-02],
          [-2.5262e-01, -8.2324e-02, -3.2566e-01]],

         [[ 5.0267e-02,  1.5580e-01,  3.3157e-02],
          [ 1.1139e-01,  2.9039e-01,  6.3848e-02],
          [-1.7210e-01, -1.3641e-01, -4.1955e-01]],

         [[-5.6163e-02,  1.7454e-01,  2.1462e-01],
          [ 7.0804e-02,  2.9288e-01,  1.1970e-01],
          [-2.6192e-01, -2.0348e-01, -2.7107e-01]]],


        ...,


        [[[-9.7464e-02, -1.2676e-01,  1.9527e-02],
          [ 3.4918e-02, -3.9614e-01, -1.7036e-01],
          [ 1.5682e-01, -5.5365e-02,  1.0466e-01]],

         [[ 1.4896e-01, -3.7324e-02, -3.4681e-03],
          [-5.9558e-02, -4.1636e-01, -2.4669e-01],
          [ 1.4020e-01,  1.5643e-02,  2.6556e-02]],

         [[ 2.0363e-01,  3.8801e-02,  9.6331e-02],
          [ 3.6265e-03, -2.6325e-01, -2.1321e-01],
          [ 1.1140e-01, -1.0184e-01, -9.2163e-02]]],


        [[[ 8.8046e-03,  8.8442e-03,  7.5361e-03],
          [ 1.1722e-02,  1.1402e-02,  1.1485e-02],
          [ 2.0714e-02,  2.0521e-02,  2.3761e-02]],

         [[ 5.4717e-03,  2.1567e-03, -1.3183e-04],
          [ 8.5020e-03,  6.6350e-03,  5.3474e-03],
          [ 1.6118e-02,  1.4856e-02,  1.7282e-02]],

         [[-1.4162e-03, -1.9101e-03, -1.4395e-03],
          [ 9.0871e-04,  8.0122e-04,  9.2209e-04],
          [ 6.8098e-03,  6.4789e-03,  7.6109e-03]]],


        [[[ 1.6706e-18, -1.3201e-19, -8.3623e-20],
          [ 1.2935e-20, -1.1147e-19, -4.3242e-19],
          [ 6.2062e-22, -4.7384e-20, -2.0330e-18]],

         [[ 1.5328e-28, -1.5496e-26, -8.4273e-26],
          [ 3.7104e-33, -7.1815e-26, -8.3902e-24],
          [-4.9452e-26, -1.6027e-23, -6.0298e-22]],

         [[-4.5803e-28, -1.6598e-23, -2.4005e-21],
          [ 8.7432e-34, -3.1156e-24, -3.5591e-22],
          [-8.8366e-30, -3.9818e-25, -9.6178e-24]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0035, -0.0092, -0.0166],
          [ 0.0026, -0.0070,  0.0050],
          [ 0.0163, -0.0024, -0.0035]],

         [[ 0.0070,  0.0019, -0.0053],
          [ 0.0145,  0.0017,  0.0101],
          [ 0.0259,  0.0050,  0.0025]],

         [[ 0.0014, -0.0008, -0.0045],
          [ 0.0070,  0.0008,  0.0114],
          [ 0.0184,  0.0065,  0.0072]]],


        [[[ 0.0547,  0.0729,  0.0676],
          [ 0.0476,  0.0614,  0.0626],
          [ 0.0517,  0.0593,  0.0664]],

         [[ 0.0159,  0.0335,  0.0336],
          [ 0.0053,  0.0197,  0.0260],
          [ 0.0138,  0.0223,  0.0325]],

         [[-0.0128,  0.0028,  0.0068],
          [-0.0134, -0.0009,  0.0089],
          [-0.0020,  0.0033,  0.0137]]],


        [[[ 0.0170,  0.0090,  0.0178],
          [ 0.0206,  0.0139,  0.0203],
          [ 0.0115,  0.0159,  0.0279]],

         [[ 0.0369,  0.0325,  0.0406],
          [ 0.0384,  0.0340,  0.0370],
          [ 0.0247,  0.0306,  0.0396]],

         [[ 0.0346,  0.0290,  0.0371],
          [ 0.0333,  0.0270,  0.0309],
          [ 0.0217,  0.0262,  0.0346]]],


        ...,


        [[[-0.0092, -0.0075,  0.0004],
          [-0.0154, -0.0134, -0.0062],
          [-0.0251, -0.0172, -0.0125]],

         [[-0.0034, -0.0015,  0.0021],
          [-0.0078, -0.0069, -0.0036],
          [-0.0198, -0.0137, -0.0105]],

         [[ 0.0118,  0.0175,  0.0203],
          [ 0.0083,  0.0133,  0.0176],
          [-0.0015,  0.0056,  0.0105]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5257]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1776) | Acc: (92.00%) (119/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1703) | Acc: (93.00%) (1322/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1928) | Acc: (93.00%) (2503/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1952) | Acc: (92.00%) (3686/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.2002) | Acc: (92.00%) (4876/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1967) | Acc: (93.00%) (6084/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1964) | Acc: (93.00%) (7283/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1933) | Acc: (93.00%) (8483/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1932) | Acc: (93.00%) (9685/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1894) | Acc: (93.00%) (10898/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1891) | Acc: (93.00%) (12098/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1874) | Acc: (93.00%) (13307/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1847) | Acc: (93.00%) (14512/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1828) | Acc: (93.00%) (15734/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1827) | Acc: (93.00%) (16940/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1810) | Acc: (93.00%) (18147/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1803) | Acc: (93.00%) (19355/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1798) | Acc: (93.00%) (20552/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1791) | Acc: (93.00%) (21764/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1782) | Acc: (93.00%) (22973/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1763) | Acc: (94.00%) (24192/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1766) | Acc: (94.00%) (25393/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1764) | Acc: (94.00%) (26591/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1750) | Acc: (94.00%) (27808/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1743) | Acc: (94.00%) (29024/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1742) | Acc: (94.00%) (30237/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1743) | Acc: (94.00%) (31435/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1744) | Acc: (94.00%) (32636/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1743) | Acc: (94.00%) (33843/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1736) | Acc: (94.00%) (35061/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1736) | Acc: (94.00%) (36260/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1733) | Acc: (94.00%) (37472/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1731) | Acc: (94.00%) (38679/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1727) | Acc: (94.00%) (39890/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1722) | Acc: (94.00%) (41102/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1720) | Acc: (94.00%) (42310/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1718) | Acc: (94.00%) (43522/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1714) | Acc: (94.00%) (44736/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1706) | Acc: (94.00%) (45959/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1706) | Acc: (94.00%) (47123/50000)
# TEST : Loss: (0.2873) | Acc: (90.00%) (9083/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3798e-01,  3.8718e-01, -1.6296e-01],
          [-3.7487e-02,  3.1519e-02, -9.2338e-02],
          [ 6.7811e-02, -2.2153e-01,  2.6544e-01]],

         [[-1.5373e-01,  5.2600e-01,  1.0131e-01],
          [-1.6137e-03, -2.9953e-02, -1.6977e-01],
          [ 7.2908e-02, -4.2034e-01, -1.2123e-02]],

         [[-1.6967e-01,  2.9090e-01, -1.2793e-01],
          [ 5.2608e-02, -1.4570e-01, -1.3131e-01],
          [ 1.6628e-01, -8.1339e-02,  1.9718e-01]]],


        [[[-2.0392e-01, -4.2943e-01, -2.4823e-01],
          [-8.7345e-02,  2.2466e-01,  1.8293e-01],
          [ 2.0363e-01,  1.8253e-01,  2.5945e-01]],

         [[-2.6754e-01, -3.3743e-01, -2.1033e-01],
          [-1.1727e-01,  1.6921e-01,  2.3077e-01],
          [ 2.8144e-01,  1.3594e-01,  1.7363e-01]],

         [[-1.5866e-01, -6.3141e-02, -2.4141e-01],
          [ 5.5802e-02,  2.1121e-01, -4.7869e-02],
          [-1.2984e-02,  7.6187e-02,  5.4482e-02]]],


        [[[-1.0669e-01,  2.7602e-01,  1.0259e-01],
          [ 1.8645e-01,  2.2593e-01, -4.4917e-02],
          [-2.5349e-01, -8.4041e-02, -3.2712e-01]],

         [[ 4.8162e-02,  1.5399e-01,  3.1392e-02],
          [ 1.0904e-01,  2.8776e-01,  6.1678e-02],
          [-1.7312e-01, -1.3811e-01, -4.2106e-01]],

         [[-5.7763e-02,  1.7300e-01,  2.1281e-01],
          [ 6.9002e-02,  2.9069e-01,  1.1789e-01],
          [-2.6239e-01, -2.0463e-01, -2.7240e-01]]],


        ...,


        [[[-9.8516e-02, -1.2640e-01,  1.8051e-02],
          [ 3.4201e-02, -3.9233e-01, -1.6994e-01],
          [ 1.5724e-01, -5.2948e-02,  1.0510e-01]],

         [[ 1.4703e-01, -3.7741e-02, -5.0841e-03],
          [-6.0269e-02, -4.1265e-01, -2.4631e-01],
          [ 1.4075e-01,  1.7643e-02,  2.6960e-02]],

         [[ 2.0293e-01,  3.9085e-02,  9.5500e-02],
          [ 4.1132e-03, -2.6012e-01, -2.1218e-01],
          [ 1.1297e-01, -9.8395e-02, -9.0639e-02]]],


        [[[ 4.9528e-03,  4.9079e-03,  4.2336e-03],
          [ 6.0507e-03,  5.7245e-03,  6.0652e-03],
          [ 1.0612e-02,  9.9078e-03,  1.2052e-02]],

         [[ 2.8983e-03,  1.1113e-03, -6.8404e-05],
          [ 4.0633e-03,  2.9700e-03,  2.5411e-03],
          [ 7.6437e-03,  6.3140e-03,  7.9357e-03]],

         [[-6.5995e-04, -8.5618e-04, -6.5264e-04],
          [ 4.1208e-04,  3.3912e-04,  4.0083e-04],
          [ 3.2523e-03,  2.8357e-03,  3.3944e-03]]],


        [[[ 5.4927e-23, -3.3269e-24, -8.5914e-25],
          [ 8.0410e-26, -1.7342e-24, -8.0965e-24],
          [ 1.8756e-27, -5.2311e-25, -7.2596e-23]],

         [[ 8.3317e-38,  6.6555e-35,  4.6886e-34],
          [-7.3316e-42,  4.0378e-34, -6.6838e-31],
          [ 1.4268e-34, -3.2051e-30, -7.3773e-28]],

         [[-2.8288e-37, -2.1072e-30, -4.2995e-27],
          [-4.1277e-41, -8.4450e-32, -2.4528e-28],
          [-1.6702e-39,  1.1674e-33, -7.1190e-31]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4992]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0276]], device='cuda:0')

Epoch: 136 | Batch_idx: 0 |  Loss: (0.2268) | Acc: (91.00%) (117/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1658) | Acc: (94.00%) (1334/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1564) | Acc: (94.00%) (2550/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1624) | Acc: (94.00%) (3758/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1592) | Acc: (94.00%) (4978/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1614) | Acc: (94.00%) (6185/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1605) | Acc: (94.00%) (7404/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1610) | Acc: (94.00%) (8617/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1599) | Acc: (94.00%) (9827/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1583) | Acc: (94.00%) (11050/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1582) | Acc: (94.00%) (12265/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1561) | Acc: (94.00%) (13492/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1557) | Acc: (94.00%) (14703/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1555) | Acc: (94.00%) (15929/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1550) | Acc: (94.00%) (17144/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1535) | Acc: (95.00%) (18370/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1526) | Acc: (95.00%) (19580/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1530) | Acc: (94.00%) (20791/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1530) | Acc: (94.00%) (21999/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1523) | Acc: (94.00%) (23218/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1519) | Acc: (95.00%) (24444/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1533) | Acc: (94.00%) (25646/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1526) | Acc: (94.00%) (26864/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1528) | Acc: (94.00%) (28076/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1536) | Acc: (94.00%) (29272/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1539) | Acc: (94.00%) (30477/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1535) | Acc: (94.00%) (31702/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1537) | Acc: (94.00%) (32912/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1534) | Acc: (94.00%) (34133/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1537) | Acc: (94.00%) (35346/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1535) | Acc: (94.00%) (36552/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1541) | Acc: (94.00%) (37754/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1538) | Acc: (94.00%) (38964/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1542) | Acc: (94.00%) (40181/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1543) | Acc: (94.00%) (41396/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1544) | Acc: (94.00%) (42608/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1538) | Acc: (94.00%) (43829/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1536) | Acc: (94.00%) (45046/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1538) | Acc: (94.00%) (46257/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1540) | Acc: (94.00%) (47415/50000)
# TEST : Loss: (0.2758) | Acc: (90.00%) (9096/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3752e-01,  3.8586e-01, -1.6243e-01],
          [-3.7365e-02,  3.1416e-02, -9.2041e-02],
          [ 6.7593e-02, -2.2078e-01,  2.6459e-01]],

         [[-1.5321e-01,  5.2413e-01,  1.0096e-01],
          [-1.6083e-03, -2.9850e-02, -1.6920e-01],
          [ 7.2664e-02, -4.1884e-01, -1.2083e-02]],

         [[-1.6906e-01,  2.8980e-01, -1.2746e-01],
          [ 5.2421e-02, -1.4516e-01, -1.3085e-01],
          [ 1.6569e-01, -8.1033e-02,  1.9648e-01]]],


        [[[-2.0347e-01, -4.2850e-01, -2.4770e-01],
          [-8.7153e-02,  2.2417e-01,  1.8253e-01],
          [ 2.0316e-01,  1.8211e-01,  2.5885e-01]],

         [[-2.6693e-01, -3.3668e-01, -2.0987e-01],
          [-1.1701e-01,  1.6883e-01,  2.3025e-01],
          [ 2.8079e-01,  1.3562e-01,  1.7322e-01]],

         [[-1.5828e-01, -6.2988e-02, -2.4083e-01],
          [ 5.5667e-02,  2.1069e-01, -4.7754e-02],
          [-1.2952e-02,  7.5999e-02,  5.4349e-02]]],


        [[[-1.0647e-01,  2.7544e-01,  1.0238e-01],
          [ 1.8607e-01,  2.2547e-01, -4.4824e-02],
          [-2.5297e-01, -8.3869e-02, -3.2644e-01]],

         [[ 4.8058e-02,  1.5365e-01,  3.1325e-02],
          [ 1.0882e-01,  2.8715e-01,  6.1549e-02],
          [-1.7276e-01, -1.3782e-01, -4.2016e-01]],

         [[-5.7633e-02,  1.7261e-01,  2.1233e-01],
          [ 6.8848e-02,  2.9004e-01,  1.1763e-01],
          [-2.6180e-01, -2.0417e-01, -2.7177e-01]]],


        ...,


        [[[-9.8085e-02, -1.2567e-01,  1.7954e-02],
          [ 3.4028e-02, -3.8894e-01, -1.6862e-01],
          [ 1.5658e-01, -5.2655e-02,  1.0454e-01]],

         [[ 1.4636e-01, -3.7509e-02, -5.0541e-03],
          [-5.9939e-02, -4.0819e-01, -2.4393e-01],
          [ 1.4012e-01,  1.7535e-02,  2.6803e-02]],

         [[ 2.0199e-01,  3.8853e-02,  9.4950e-02],
          [ 4.0909e-03, -2.5798e-01, -2.1053e-01],
          [ 1.1245e-01, -9.7806e-02, -9.0114e-02]]],


        [[[ 2.4551e-03,  2.3928e-03,  2.0953e-03],
          [ 2.6999e-03,  2.4690e-03,  2.7831e-03],
          [ 4.6915e-03,  4.0734e-03,  5.2639e-03]],

         [[ 1.3347e-03,  4.9478e-04, -3.0717e-05],
          [ 1.6498e-03,  1.1127e-03,  1.0245e-03],
          [ 3.0741e-03,  2.2199e-03,  3.0680e-03]],

         [[-2.5978e-04, -3.2133e-04, -2.4837e-04],
          [ 1.5687e-04,  1.1862e-04,  1.4487e-04],
          [ 1.3193e-03,  1.0336e-03,  1.2661e-03]]],


        [[[ 2.7188e-29, -9.3069e-31, -1.8363e-32],
          [-2.1446e-34, -1.4755e-31, -1.1227e-30],
          [-8.5608e-36, -1.4884e-32, -4.2544e-29]],

         [[ 9.6606e-42,  6.0518e-41,  3.5635e-42],
          [-3.5170e-41,  7.3288e-42,  4.4004e-40],
          [-1.0658e-41, -8.3193e-40,  4.6852e-38]],

         [[-1.5742e-41,  5.0664e-40,  7.0979e-36],
          [-3.8170e-41,  9.8887e-41, -2.4519e-37],
          [-2.9052e-41, -6.5693e-41,  5.2600e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4896]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0435]], device='cuda:0')

Epoch: 137 | Batch_idx: 0 |  Loss: (0.1682) | Acc: (91.00%) (117/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1552) | Acc: (95.00%) (1340/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1603) | Acc: (94.00%) (2544/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1601) | Acc: (94.00%) (3757/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1582) | Acc: (94.00%) (4972/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1566) | Acc: (94.00%) (6187/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1568) | Acc: (94.00%) (7393/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1550) | Acc: (94.00%) (8616/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1554) | Acc: (94.00%) (9828/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1546) | Acc: (94.00%) (11050/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1541) | Acc: (94.00%) (12267/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1528) | Acc: (94.00%) (13485/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1525) | Acc: (94.00%) (14699/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1521) | Acc: (94.00%) (15921/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1527) | Acc: (94.00%) (17129/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1526) | Acc: (94.00%) (18353/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1526) | Acc: (94.00%) (19569/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1533) | Acc: (94.00%) (20780/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1538) | Acc: (94.00%) (21987/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1542) | Acc: (94.00%) (23194/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1541) | Acc: (94.00%) (24411/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1536) | Acc: (94.00%) (25633/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1540) | Acc: (94.00%) (26842/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1536) | Acc: (94.00%) (28064/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1536) | Acc: (94.00%) (29274/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1545) | Acc: (94.00%) (30482/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1542) | Acc: (94.00%) (31703/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1542) | Acc: (94.00%) (32919/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1537) | Acc: (94.00%) (34134/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1537) | Acc: (94.00%) (35345/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1542) | Acc: (94.00%) (36551/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1538) | Acc: (94.00%) (37778/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1536) | Acc: (94.00%) (38998/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1532) | Acc: (94.00%) (40215/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1528) | Acc: (94.00%) (41436/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1524) | Acc: (94.00%) (42665/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1520) | Acc: (94.00%) (43892/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1520) | Acc: (94.00%) (45102/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1520) | Acc: (94.00%) (46317/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1518) | Acc: (94.00%) (47494/50000)
# TEST : Loss: (0.2757) | Acc: (90.00%) (9092/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3696e-01,  3.8425e-01, -1.6177e-01],
          [-3.7218e-02,  3.1290e-02, -9.1682e-02],
          [ 6.7329e-02, -2.1986e-01,  2.6355e-01]],

         [[-1.5258e-01,  5.2186e-01,  1.0054e-01],
          [-1.6017e-03, -2.9725e-02, -1.6851e-01],
          [ 7.2369e-02, -4.1702e-01, -1.2033e-02]],

         [[-1.6832e-01,  2.8847e-01, -1.2690e-01],
          [ 5.2195e-02, -1.4452e-01, -1.3028e-01],
          [ 1.6498e-01, -8.0662e-02,  1.9564e-01]]],


        [[[-2.0293e-01, -4.2738e-01, -2.4705e-01],
          [-8.6920e-02,  2.2357e-01,  1.8204e-01],
          [ 2.0259e-01,  1.8160e-01,  2.5812e-01]],

         [[-2.6620e-01, -3.3576e-01, -2.0930e-01],
          [-1.1669e-01,  1.6836e-01,  2.2962e-01],
          [ 2.7999e-01,  1.3524e-01,  1.7273e-01]],

         [[-1.5781e-01, -6.2802e-02, -2.4012e-01],
          [ 5.5503e-02,  2.1008e-01, -4.7614e-02],
          [-1.2913e-02,  7.5772e-02,  5.4186e-02]]],


        [[[-1.0619e-01,  2.7473e-01,  1.0212e-01],
          [ 1.8561e-01,  2.2491e-01, -4.4712e-02],
          [-2.5235e-01, -8.3660e-02, -3.2561e-01]],

         [[ 4.7932e-02,  1.5325e-01,  3.1244e-02],
          [ 1.0854e-01,  2.8641e-01,  6.1391e-02],
          [-1.7232e-01, -1.3746e-01, -4.1907e-01]],

         [[-5.7474e-02,  1.7213e-01,  2.1175e-01],
          [ 6.8662e-02,  2.8925e-01,  1.1731e-01],
          [-2.6108e-01, -2.0360e-01, -2.7102e-01]]],


        ...,


        [[[-9.7562e-02, -1.2479e-01,  1.7836e-02],
          [ 3.3819e-02, -3.8486e-01, -1.6704e-01],
          [ 1.5578e-01, -5.2302e-02,  1.0387e-01]],

         [[ 1.4555e-01, -3.7229e-02, -5.0179e-03],
          [-5.9539e-02, -4.0283e-01, -2.4106e-01],
          [ 1.3936e-01,  1.7405e-02,  2.6613e-02]],

         [[ 2.0085e-01,  3.8574e-02,  9.4286e-02],
          [ 4.0640e-03, -2.5541e-01, -2.0855e-01],
          [ 1.1182e-01, -9.7094e-02, -8.9481e-02]]],


        [[[ 1.0424e-03,  9.9549e-04,  8.8790e-04],
          [ 1.0076e-03,  8.8384e-04,  1.0749e-03],
          [ 1.7312e-03,  1.3749e-03,  1.9137e-03]],

         [[ 5.1779e-04,  1.8416e-04, -1.1554e-05],
          [ 5.4833e-04,  3.3505e-04,  3.3756e-04],
          [ 1.0099e-03,  6.1819e-04,  9.6017e-04]],

         [[-8.3118e-05, -9.6960e-05, -7.6241e-05],
          [ 4.8171e-05,  3.2822e-05,  4.1736e-05],
          [ 4.3803e-04,  3.0086e-04,  3.7917e-04]]],


        [[[ 2.8653e-38, -5.7333e-40, -7.2489e-42],
          [ 6.5397e-41,  8.5289e-41,  1.7309e-40],
          [-3.6137e-41,  1.0018e-41, -4.5301e-38]],

         [[-4.2689e-41,  4.0925e-41,  6.5623e-42],
          [ 5.3185e-41,  1.1191e-41, -1.2193e-41],
          [-1.0688e-41, -6.7467e-41, -5.5982e-41]],

         [[ 3.5367e-41, -5.0180e-41, -1.6433e-41],
          [ 4.1923e-41,  6.7045e-41,  1.6786e-41],
          [-1.7767e-41, -6.3507e-41, -1.6855e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4826]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0116]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 138 | Batch_idx: 0 |  Loss: (0.2054) | Acc: (94.00%) (121/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1716) | Acc: (94.00%) (1325/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1912) | Acc: (93.00%) (2502/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.2178) | Acc: (92.00%) (3664/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.2315) | Acc: (92.00%) (4833/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.2434) | Acc: (91.00%) (5992/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.2546) | Acc: (91.00%) (7134/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.2562) | Acc: (91.00%) (8297/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.2606) | Acc: (91.00%) (9453/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.2609) | Acc: (91.00%) (10620/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.2622) | Acc: (91.00%) (11779/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.2673) | Acc: (90.00%) (12916/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.2689) | Acc: (90.00%) (14075/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.2666) | Acc: (90.00%) (15251/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.2692) | Acc: (90.00%) (16393/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.2693) | Acc: (90.00%) (17554/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.2704) | Acc: (90.00%) (18705/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.2689) | Acc: (90.00%) (19866/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.2698) | Acc: (90.00%) (21027/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.2706) | Acc: (90.00%) (22181/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.2711) | Acc: (90.00%) (23336/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.2704) | Acc: (90.00%) (24504/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.2698) | Acc: (90.00%) (25675/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.2699) | Acc: (90.00%) (26841/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.2676) | Acc: (90.00%) (28031/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.2660) | Acc: (90.00%) (29209/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.2651) | Acc: (90.00%) (30390/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.2647) | Acc: (90.00%) (31559/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.2638) | Acc: (91.00%) (32741/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.2623) | Acc: (91.00%) (33926/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.2614) | Acc: (91.00%) (35099/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.2600) | Acc: (91.00%) (36287/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.2591) | Acc: (91.00%) (37466/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.2582) | Acc: (91.00%) (38652/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.2572) | Acc: (91.00%) (39833/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.2582) | Acc: (91.00%) (40982/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.2579) | Acc: (91.00%) (42158/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.2568) | Acc: (91.00%) (43338/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.2569) | Acc: (91.00%) (44498/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.2575) | Acc: (91.00%) (45602/50000)
# TEST : Loss: (0.3647) | Acc: (88.00%) (8892/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4096e-01,  3.8222e-01, -1.7133e-01],
          [-4.2532e-02,  3.0836e-02, -8.9682e-02],
          [ 7.7352e-02, -2.1495e-01,  2.8799e-01]],

         [[-1.5440e-01,  5.2399e-01,  9.5917e-02],
          [-5.5908e-03, -2.4486e-02, -1.6546e-01],
          [ 8.3942e-02, -4.0532e-01,  1.1624e-02]],

         [[-1.7669e-01,  2.7804e-01, -1.4373e-01],
          [ 4.2036e-02, -1.4223e-01, -1.3732e-01],
          [ 1.6991e-01, -7.1846e-02,  2.0818e-01]]],


        [[[-2.0007e-01, -4.3180e-01, -2.4435e-01],
          [-7.8460e-02,  2.2665e-01,  1.8754e-01],
          [ 2.0549e-01,  1.8431e-01,  2.6215e-01]],

         [[-2.6322e-01, -3.3892e-01, -2.0445e-01],
          [-1.0554e-01,  1.7822e-01,  2.4113e-01],
          [ 2.8730e-01,  1.4477e-01,  1.8457e-01]],

         [[-1.5108e-01, -6.5508e-02, -2.3642e-01],
          [ 6.2859e-02,  2.1422e-01, -4.2480e-02],
          [-8.3339e-03,  7.8938e-02,  5.6481e-02]]],


        [[[-9.5578e-02,  2.8277e-01,  1.0184e-01],
          [ 1.8569e-01,  2.2835e-01, -4.5087e-02],
          [-2.5445e-01, -8.5088e-02, -3.3092e-01]],

         [[ 5.2062e-02,  1.5641e-01,  2.5369e-02],
          [ 1.0316e-01,  2.8360e-01,  5.3601e-02],
          [-1.8100e-01, -1.4562e-01, -4.3198e-01]],

         [[-5.7637e-02,  1.7371e-01,  2.0674e-01],
          [ 6.3505e-02,  2.8853e-01,  1.1422e-01],
          [-2.6653e-01, -2.0395e-01, -2.7520e-01]]],


        ...,


        [[[-1.0152e-01, -1.3509e-01,  7.8744e-03],
          [ 3.0153e-02, -3.9954e-01, -1.7175e-01],
          [ 1.5801e-01, -5.5501e-02,  1.0402e-01]],

         [[ 1.3464e-01, -5.5819e-02, -1.9956e-02],
          [-6.7613e-02, -4.2240e-01, -2.4456e-01],
          [ 1.3245e-01,  6.2164e-03,  2.5376e-02]],

         [[ 1.9550e-01,  2.4468e-02,  7.7780e-02],
          [ 3.8040e-03, -2.6276e-01, -2.0904e-01],
          [ 1.0966e-01, -1.0347e-01, -9.1742e-02]]],


        [[[ 3.6605e-04,  3.4093e-04,  3.1103e-04],
          [ 3.0196e-04,  2.5163e-04,  3.3599e-04],
          [ 5.1162e-04,  3.6411e-04,  5.5527e-04]],

         [[ 1.6273e-04,  5.5004e-05, -3.4958e-06],
          [ 1.4248e-04,  7.7086e-05,  8.6785e-05],
          [ 2.5869e-04,  1.2916e-04,  2.3167e-04]],

         [[-2.0609e-05, -2.2366e-05, -1.7962e-05],
          [ 1.1354e-05,  6.8036e-06,  9.0927e-06],
          [ 1.1367e-04,  6.6390e-05,  8.6650e-05]]],


        [[[-3.5960e-41, -3.1912e-41,  1.7240e-41],
          [ 6.5295e-41,  2.0103e-41, -2.6365e-41],
          [-1.6496e-41,  3.8262e-41,  2.6130e-41]],

         [[ 2.7296e-41, -4.0652e-42, -2.8983e-41],
          [ 4.0395e-41,  1.6387e-41,  4.5654e-41],
          [-2.3892e-42,  2.0435e-41, -8.3629e-42]],

         [[-3.6446e-41,  5.2208e-41, -5.2568e-41],
          [ 7.0033e-41, -5.9477e-41,  6.6466e-41],
          [-5.1938e-41,  6.5676e-41,  5.1344e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0144, -0.0410, -0.0609],
          [-0.0350, -0.0465, -0.0560],
          [-0.0549, -0.0540, -0.0366]],

         [[-0.0152, -0.0395, -0.0522],
          [-0.0289, -0.0436, -0.0462],
          [-0.0431, -0.0463, -0.0296]],

         [[-0.0110, -0.0266, -0.0373],
          [-0.0221, -0.0366, -0.0376],
          [-0.0371, -0.0437, -0.0276]]],


        [[[ 0.0136,  0.0151,  0.0235],
          [ 0.0188,  0.0102,  0.0156],
          [ 0.0325,  0.0177,  0.0048]],

         [[ 0.0101,  0.0105,  0.0152],
          [ 0.0115,  0.0053,  0.0132],
          [ 0.0207,  0.0082,  0.0020]],

         [[ 0.0017, -0.0006,  0.0035],
          [ 0.0034, -0.0021,  0.0066],
          [ 0.0141,  0.0042,  0.0028]]],


        [[[-0.0466, -0.0411, -0.0428],
          [-0.0607, -0.0413, -0.0384],
          [-0.0650, -0.0355, -0.0328]],

         [[-0.0083, -0.0106, -0.0153],
          [-0.0235, -0.0105, -0.0096],
          [-0.0283, -0.0049, -0.0030]],

         [[ 0.0057, -0.0011, -0.0056],
          [-0.0092, -0.0025,  0.0002],
          [-0.0171, -0.0016,  0.0022]]],


        ...,


        [[[ 0.0311,  0.0262,  0.0081],
          [ 0.0183,  0.0116,  0.0022],
          [ 0.0219,  0.0175,  0.0181]],

         [[ 0.0146,  0.0120, -0.0025],
          [ 0.0062,  0.0019, -0.0050],
          [ 0.0113,  0.0092,  0.0104]],

         [[ 0.0042,  0.0028, -0.0078],
          [-0.0009, -0.0042, -0.0101],
          [ 0.0037,  0.0020,  0.0021]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4796]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 139 | Batch_idx: 0 |  Loss: (0.1375) | Acc: (95.00%) (122/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.2197) | Acc: (93.00%) (1317/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.2198) | Acc: (92.00%) (2499/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.2130) | Acc: (93.00%) (3700/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.2123) | Acc: (92.00%) (4880/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.2110) | Acc: (93.00%) (6072/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.2083) | Acc: (93.00%) (7268/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.2034) | Acc: (93.00%) (8479/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.2039) | Acc: (93.00%) (9671/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.2079) | Acc: (93.00%) (10840/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.2079) | Acc: (93.00%) (12025/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.2075) | Acc: (93.00%) (13218/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.2075) | Acc: (93.00%) (14408/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.2077) | Acc: (92.00%) (15593/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.2101) | Acc: (92.00%) (16768/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.2097) | Acc: (92.00%) (17957/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.2121) | Acc: (92.00%) (19133/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.2109) | Acc: (92.00%) (20331/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.2119) | Acc: (92.00%) (21516/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.2119) | Acc: (92.00%) (22707/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.2106) | Acc: (92.00%) (23911/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.2102) | Acc: (92.00%) (25097/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.2101) | Acc: (92.00%) (26286/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.2101) | Acc: (92.00%) (27468/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.2102) | Acc: (92.00%) (28655/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.2097) | Acc: (92.00%) (29848/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.2101) | Acc: (92.00%) (31018/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.2095) | Acc: (92.00%) (32216/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.2091) | Acc: (92.00%) (33400/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.2095) | Acc: (92.00%) (34586/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.2100) | Acc: (92.00%) (35770/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.2100) | Acc: (92.00%) (36951/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.2093) | Acc: (92.00%) (38145/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.2096) | Acc: (92.00%) (39331/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.2102) | Acc: (92.00%) (40513/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.2103) | Acc: (92.00%) (41700/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.2112) | Acc: (92.00%) (42871/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.2120) | Acc: (92.00%) (44049/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.2128) | Acc: (92.00%) (45225/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.2127) | Acc: (92.00%) (46366/50000)
# TEST : Loss: (0.3441) | Acc: (88.00%) (8895/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4026e-01,  3.9243e-01, -1.6716e-01],
          [-4.8390e-02,  3.4973e-02, -8.2876e-02],
          [ 6.7781e-02, -2.1801e-01,  2.8023e-01]],

         [[-1.6260e-01,  5.2757e-01,  9.6969e-02],
          [-1.7115e-02, -2.6404e-02, -1.5736e-01],
          [ 6.9234e-02, -4.1874e-01,  7.8167e-04]],

         [[-1.7777e-01,  2.9216e-01, -1.3478e-01],
          [ 4.1515e-02, -1.3039e-01, -1.1816e-01],
          [ 1.6766e-01, -7.3768e-02,  2.0935e-01]]],


        [[[-2.0410e-01, -4.3467e-01, -2.4697e-01],
          [-7.8165e-02,  2.2607e-01,  1.8598e-01],
          [ 2.1173e-01,  1.8613e-01,  2.6133e-01]],

         [[-2.6971e-01, -3.4601e-01, -2.1169e-01],
          [-1.1002e-01,  1.7214e-01,  2.3230e-01],
          [ 2.8922e-01,  1.4076e-01,  1.7656e-01]],

         [[-1.5740e-01, -7.3119e-02, -2.4424e-01],
          [ 5.6259e-02,  2.0706e-01, -5.1773e-02],
          [-8.6895e-03,  7.4553e-02,  4.8084e-02]]],


        [[[-9.9921e-02,  2.8565e-01,  9.9517e-02],
          [ 1.8695e-01,  2.3002e-01, -4.5698e-02],
          [-2.5740e-01, -8.6397e-02, -3.3039e-01]],

         [[ 4.6802e-02,  1.5752e-01,  2.1612e-02],
          [ 1.0572e-01,  2.8550e-01,  5.3595e-02],
          [-1.8483e-01, -1.4596e-01, -4.2891e-01]],

         [[-5.3931e-02,  1.8161e-01,  2.0927e-01],
          [ 7.1714e-02,  2.9467e-01,  1.1795e-01],
          [-2.6597e-01, -1.9995e-01, -2.6922e-01]]],


        ...,


        [[[-9.2469e-02, -1.2682e-01,  1.6391e-02],
          [ 3.4508e-02, -3.9409e-01, -1.6013e-01],
          [ 1.5728e-01, -5.5560e-02,  1.0577e-01]],

         [[ 1.4143e-01, -5.5634e-02, -1.7674e-02],
          [-6.3504e-02, -4.2904e-01, -2.4496e-01],
          [ 1.3220e-01, -1.1016e-03,  1.4684e-02]],

         [[ 2.0829e-01,  3.5045e-02,  9.3743e-02],
          [ 1.2975e-02, -2.5953e-01, -1.9970e-01],
          [ 1.1292e-01, -1.0776e-01, -9.8251e-02]]],


        [[[ 1.0177e-04,  9.1917e-05,  8.6220e-05],
          [ 6.9064e-05,  5.4027e-05,  8.0949e-05],
          [ 1.1503e-04,  7.1496e-05,  1.2205e-04]],

         [[ 3.9470e-05,  1.2529e-05, -8.0907e-07],
          [ 2.7330e-05,  1.2721e-05,  1.6429e-05],
          [ 4.8747e-05,  1.8915e-05,  4.0548e-05]],

         [[-3.7305e-06, -3.7027e-06, -3.0523e-06],
          [ 1.9305e-06,  9.8671e-07,  1.4025e-06],
          [ 2.1768e-05,  1.0404e-05,  1.4180e-05]]],


        [[[-3.7410e-41, -2.6981e-41, -3.5167e-41],
          [ 2.8148e-41,  1.7743e-41,  6.7913e-41],
          [-2.1035e-41, -5.5217e-41,  5.2053e-41]],

         [[-5.0740e-41,  6.9838e-41, -5.6378e-41],
          [ 4.1291e-41,  8.0070e-42,  5.8906e-41],
          [-5.5931e-41, -5.2086e-42, -6.1318e-41]],

         [[ 6.2878e-41,  5.9907e-41,  4.4367e-41],
          [ 3.5831e-41, -6.7733e-41, -2.2850e-41],
          [ 2.5156e-41,  6.5719e-41,  6.5802e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0312,  0.0311,  0.0189],
          [ 0.0259,  0.0245,  0.0203],
          [ 0.0316,  0.0246,  0.0167]],

         [[ 0.0338,  0.0336,  0.0310],
          [ 0.0215,  0.0305,  0.0297],
          [ 0.0206,  0.0248,  0.0165]],

         [[ 0.0270,  0.0289,  0.0280],
          [ 0.0160,  0.0298,  0.0245],
          [ 0.0125,  0.0186,  0.0034]]],


        [[[ 0.0304,  0.0212,  0.0055],
          [ 0.0314,  0.0217,  0.0162],
          [ 0.0208,  0.0106,  0.0130]],

         [[ 0.0131,  0.0023, -0.0118],
          [ 0.0139,  0.0017, -0.0034],
          [ 0.0081,  0.0009,  0.0013]],

         [[ 0.0029, -0.0053, -0.0144],
          [ 0.0016, -0.0062, -0.0056],
          [ 0.0005,  0.0001,  0.0030]]],


        [[[-0.0649, -0.0688, -0.0834],
          [-0.0747, -0.0620, -0.0713],
          [-0.0781, -0.0593, -0.0627]],

         [[-0.0027, -0.0033, -0.0245],
          [-0.0049,  0.0064, -0.0103],
          [-0.0105,  0.0078, -0.0036]],

         [[ 0.0064,  0.0065, -0.0133],
          [ 0.0080,  0.0169, -0.0013],
          [ 0.0037,  0.0171,  0.0021]]],


        ...,


        [[[-0.0168, -0.0077, -0.0061],
          [-0.0061,  0.0042,  0.0000],
          [ 0.0034,  0.0090, -0.0025]],

         [[-0.0115, -0.0083, -0.0077],
          [-0.0014, -0.0001, -0.0036],
          [ 0.0082,  0.0047, -0.0041]],

         [[-0.0045, -0.0030, -0.0048],
          [ 0.0044,  0.0033, -0.0019],
          [ 0.0121,  0.0073,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4785]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 140 | Batch_idx: 0 |  Loss: (0.1778) | Acc: (92.00%) (119/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1736) | Acc: (93.00%) (1322/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1831) | Acc: (93.00%) (2522/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1742) | Acc: (93.00%) (3729/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1730) | Acc: (94.00%) (4937/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1787) | Acc: (93.00%) (6125/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1815) | Acc: (93.00%) (7318/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1843) | Acc: (93.00%) (8509/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1823) | Acc: (93.00%) (9718/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1831) | Acc: (93.00%) (10914/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1865) | Acc: (93.00%) (12092/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1890) | Acc: (93.00%) (13268/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1908) | Acc: (93.00%) (14464/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1927) | Acc: (93.00%) (15650/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1947) | Acc: (93.00%) (16827/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1960) | Acc: (93.00%) (18021/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1948) | Acc: (93.00%) (19215/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1952) | Acc: (93.00%) (20418/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1939) | Acc: (93.00%) (21621/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1935) | Acc: (93.00%) (22816/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1927) | Acc: (93.00%) (24008/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1921) | Acc: (93.00%) (25211/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1917) | Acc: (93.00%) (26401/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1918) | Acc: (93.00%) (27593/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1913) | Acc: (93.00%) (28793/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1911) | Acc: (93.00%) (30001/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1917) | Acc: (93.00%) (31190/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1911) | Acc: (93.00%) (32391/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1913) | Acc: (93.00%) (33587/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1896) | Acc: (93.00%) (34808/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1902) | Acc: (93.00%) (35991/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1917) | Acc: (93.00%) (37163/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1916) | Acc: (93.00%) (38361/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1915) | Acc: (93.00%) (39545/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1918) | Acc: (93.00%) (40737/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1927) | Acc: (93.00%) (41911/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1933) | Acc: (93.00%) (43094/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1931) | Acc: (93.00%) (44292/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1920) | Acc: (93.00%) (45500/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1923) | Acc: (93.00%) (46639/50000)
# TEST : Loss: (0.3337) | Acc: (89.00%) (8980/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3795e-01,  3.9387e-01, -1.6852e-01],
          [-4.9470e-02,  2.3837e-02, -8.7556e-02],
          [ 6.7602e-02, -2.2563e-01,  2.7022e-01]],

         [[-1.5736e-01,  5.3240e-01,  9.9251e-02],
          [-1.6314e-02, -3.4681e-02, -1.5808e-01],
          [ 7.3399e-02, -4.1806e-01, -7.6453e-04]],

         [[-1.7384e-01,  2.9618e-01, -1.2963e-01],
          [ 4.5928e-02, -1.3489e-01, -1.0962e-01],
          [ 1.8089e-01, -6.8609e-02,  2.1158e-01]]],


        [[[-2.1136e-01, -4.4136e-01, -2.4663e-01],
          [-8.1187e-02,  2.2060e-01,  1.8370e-01],
          [ 2.0985e-01,  1.8529e-01,  2.6033e-01]],

         [[-2.7486e-01, -3.4903e-01, -2.0634e-01],
          [-1.0987e-01,  1.6965e-01,  2.3297e-01],
          [ 2.9131e-01,  1.4247e-01,  1.7934e-01]],

         [[-1.5913e-01, -7.5092e-02, -2.3999e-01],
          [ 5.9216e-02,  2.0504e-01, -5.1551e-02],
          [-4.8406e-03,  7.7234e-02,  5.1674e-02]]],


        [[[-1.0655e-01,  2.8889e-01,  1.0393e-01],
          [ 1.8300e-01,  2.3195e-01, -4.6130e-02],
          [-2.5896e-01, -8.4602e-02, -3.2885e-01]],

         [[ 4.6228e-02,  1.6513e-01,  2.6384e-02],
          [ 1.0766e-01,  2.9176e-01,  5.4951e-02],
          [-1.8281e-01, -1.4054e-01, -4.2428e-01]],

         [[-6.0808e-02,  1.8269e-01,  2.1024e-01],
          [ 6.6978e-02,  2.9656e-01,  1.1891e-01],
          [-2.6980e-01, -1.9801e-01, -2.6577e-01]]],


        ...,


        [[[-9.7796e-02, -1.3616e-01,  1.0999e-02],
          [ 3.2894e-02, -4.0436e-01, -1.6792e-01],
          [ 1.5836e-01, -5.6134e-02,  1.0363e-01]],

         [[ 1.4166e-01, -5.4365e-02, -9.2608e-03],
          [-5.8353e-02, -4.2548e-01, -2.3654e-01],
          [ 1.3977e-01,  6.4654e-03,  1.9897e-02]],

         [[ 2.0469e-01,  3.2637e-02,  9.8127e-02],
          [ 1.6270e-02, -2.6127e-01, -1.9932e-01],
          [ 1.2142e-01, -1.0042e-01, -9.6143e-02]]],


        [[[ 2.1222e-05,  1.8452e-05,  1.7913e-05],
          [ 1.1314e-05,  8.1842e-06,  1.4142e-05],
          [ 1.8447e-05,  9.6956e-06,  1.9033e-05]],

         [[ 6.9527e-06,  2.0421e-06, -1.3450e-07],
          [ 3.6000e-06,  1.3901e-06,  2.1290e-06],
          [ 6.2817e-06,  1.7817e-06,  4.7672e-06]],

         [[-4.5732e-07, -4.0624e-07, -3.4594e-07],
          [ 2.1895e-07,  9.1824e-08,  1.4092e-07],
          [ 2.8616e-06,  1.0661e-06,  1.5336e-06]]],


        [[[-5.2627e-41, -6.2547e-41, -1.8710e-41],
          [-6.4577e-41,  2.4940e-41,  6.0972e-41],
          [-4.6920e-41, -4.3037e-41,  5.7257e-41]],

         [[ 8.3868e-42,  6.7949e-41, -6.9716e-41],
          [-6.2492e-41, -6.7430e-42,  6.2148e-42],
          [-2.0425e-41, -3.1347e-41,  3.2652e-41]],

         [[ 6.0606e-42, -5.3657e-41, -6.2447e-41],
          [-5.3630e-41,  4.4800e-42, -2.2906e-41],
          [-6.6937e-41,  6.6615e-41, -2.0739e-42]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0353, -0.0376, -0.0333],
          [-0.0573, -0.0560, -0.0591],
          [-0.0580, -0.0529, -0.0617]],

         [[-0.0226, -0.0271, -0.0234],
          [-0.0432, -0.0468, -0.0497],
          [-0.0401, -0.0427, -0.0516]],

         [[-0.0147, -0.0178, -0.0102],
          [-0.0307, -0.0318, -0.0309],
          [-0.0318, -0.0308, -0.0355]]],


        [[[ 0.0112,  0.0231,  0.0324],
          [ 0.0138,  0.0210,  0.0279],
          [ 0.0195,  0.0154,  0.0203]],

         [[-0.0017,  0.0101,  0.0183],
          [ 0.0017,  0.0088,  0.0161],
          [ 0.0067,  0.0028,  0.0091]],

         [[-0.0107, -0.0011,  0.0042],
          [-0.0105, -0.0059, -0.0024],
          [-0.0093, -0.0150, -0.0105]]],


        [[[-0.0399, -0.0321, -0.0151],
          [-0.0414, -0.0273, -0.0102],
          [-0.0353, -0.0236, -0.0202]],

         [[-0.0260, -0.0135,  0.0028],
          [-0.0255, -0.0083,  0.0089],
          [-0.0201, -0.0071, -0.0031]],

         [[-0.0082,  0.0029,  0.0170],
          [-0.0110,  0.0066,  0.0237],
          [-0.0067,  0.0086,  0.0166]]],


        ...,


        [[[-0.0229, -0.0191, -0.0133],
          [-0.0209, -0.0141, -0.0075],
          [-0.0326, -0.0274, -0.0176]],

         [[-0.0085, -0.0066, -0.0026],
          [-0.0074, -0.0033,  0.0016],
          [-0.0216, -0.0181, -0.0090]],

         [[ 0.0054,  0.0100,  0.0141],
          [ 0.0051,  0.0102,  0.0143],
          [-0.0116, -0.0094, -0.0024]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.4772]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1719) | Acc: (92.00%) (119/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1842) | Acc: (94.00%) (1329/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.2060) | Acc: (93.00%) (2507/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.2184) | Acc: (92.00%) (3674/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.2235) | Acc: (92.00%) (4843/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.2274) | Acc: (92.00%) (6021/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.2237) | Acc: (92.00%) (7215/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.2239) | Acc: (92.00%) (8396/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.2229) | Acc: (92.00%) (9582/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.2186) | Acc: (92.00%) (10784/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.2176) | Acc: (92.00%) (11974/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.2141) | Acc: (92.00%) (13173/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.2080) | Acc: (92.00%) (14398/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.2080) | Acc: (92.00%) (15591/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.2057) | Acc: (93.00%) (16798/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.2033) | Acc: (93.00%) (18000/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.2033) | Acc: (93.00%) (19192/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.2006) | Acc: (93.00%) (20400/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1991) | Acc: (93.00%) (21604/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1965) | Acc: (93.00%) (22827/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1958) | Acc: (93.00%) (24023/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1950) | Acc: (93.00%) (25219/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1934) | Acc: (93.00%) (26436/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1911) | Acc: (93.00%) (27658/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1907) | Acc: (93.00%) (28854/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1911) | Acc: (93.00%) (30049/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1889) | Acc: (93.00%) (31274/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1883) | Acc: (93.00%) (32472/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1870) | Acc: (93.00%) (33691/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1874) | Acc: (93.00%) (34890/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1861) | Acc: (93.00%) (36106/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1853) | Acc: (93.00%) (37312/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1846) | Acc: (93.00%) (38527/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1846) | Acc: (93.00%) (39723/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1843) | Acc: (93.00%) (40925/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1837) | Acc: (93.00%) (42132/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1840) | Acc: (93.00%) (43316/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1847) | Acc: (93.00%) (44503/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1843) | Acc: (93.00%) (45711/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1844) | Acc: (93.00%) (46871/50000)
# TEST : Loss: (0.3028) | Acc: (90.00%) (9043/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3302e-01,  3.9659e-01, -1.6490e-01],
          [-4.1613e-02,  2.9408e-02, -8.2632e-02],
          [ 7.4165e-02, -2.1983e-01,  2.7506e-01]],

         [[-1.5247e-01,  5.3466e-01,  1.0214e-01],
          [-8.5804e-03, -2.8935e-02, -1.5274e-01],
          [ 7.9601e-02, -4.1110e-01,  5.7383e-03]],

         [[-1.6808e-01,  2.9893e-01, -1.2670e-01],
          [ 5.3668e-02, -1.2929e-01, -1.0543e-01],
          [ 1.8726e-01, -6.2414e-02,  2.1688e-01]]],


        [[[-2.1232e-01, -4.4239e-01, -2.4826e-01],
          [-8.2922e-02,  2.1804e-01,  1.8085e-01],
          [ 2.0758e-01,  1.8332e-01,  2.5742e-01]],

         [[-2.7595e-01, -3.5017e-01, -2.0779e-01],
          [-1.1149e-01,  1.6766e-01,  2.3078e-01],
          [ 2.8936e-01,  1.4129e-01,  1.7751e-01]],

         [[-1.6000e-01, -7.6146e-02, -2.4072e-01],
          [ 5.8012e-02,  2.0367e-01, -5.2522e-02],
          [-5.1244e-03,  7.7205e-02,  5.1018e-02]]],


        [[[-1.0619e-01,  2.8825e-01,  1.0204e-01],
          [ 1.8321e-01,  2.3127e-01, -4.7720e-02],
          [-2.5789e-01, -8.4867e-02, -3.2963e-01]],

         [[ 4.5864e-02,  1.6406e-01,  2.3905e-02],
          [ 1.0748e-01,  2.9003e-01,  5.2115e-02],
          [-1.8242e-01, -1.4147e-01, -4.2560e-01]],

         [[-6.1638e-02,  1.8134e-01,  2.0752e-01],
          [ 6.6491e-02,  2.9474e-01,  1.1598e-01],
          [-2.6947e-01, -1.9892e-01, -2.6752e-01]]],


        ...,


        [[[-9.8168e-02, -1.3800e-01,  6.8144e-03],
          [ 3.3653e-02, -4.0002e-01, -1.6803e-01],
          [ 1.5736e-01, -5.7289e-02,  1.0123e-01]],

         [[ 1.3909e-01, -5.7923e-02, -1.4383e-02],
          [-5.9005e-02, -4.2316e-01, -2.3808e-01],
          [ 1.3686e-01,  2.7447e-03,  1.5774e-02]],

         [[ 2.0171e-01,  2.9204e-02,  9.3809e-02],
          [ 1.4677e-02, -2.6136e-01, -2.0020e-01],
          [ 1.1897e-01, -1.0271e-01, -9.8314e-02]]],


        [[[ 3.1004e-06,  2.5718e-06,  2.6051e-06],
          [ 1.2252e-06,  8.0405e-07,  1.6588e-06],
          [ 1.9456e-06,  8.2986e-07,  1.9386e-06]],

         [[ 8.2398e-07,  2.1975e-07, -1.4832e-08],
          [ 2.9716e-07,  9.0864e-08,  1.7219e-07],
          [ 5.0449e-07,  9.6701e-08,  3.4145e-07]],

         [[-3.4511e-08, -2.6688e-08, -2.3668e-08],
          [ 1.4992e-08,  4.9085e-09,  8.2931e-09],
          [ 2.3562e-07,  6.4305e-08,  9.8955e-08]]],


        [[[ 5.4513e-41,  3.5575e-41, -6.5265e-41],
          [-3.1419e-41,  7.4899e-42,  7.2573e-42],
          [-5.2636e-41, -3.6125e-41, -6.3756e-41]],

         [[ 1.5696e-41,  4.0730e-41, -1.4094e-41],
          [ 2.3462e-41,  5.2231e-41,  6.7459e-42],
          [ 7.1228e-41,  1.9114e-42,  7.2712e-41]],

         [[-9.5176e-42,  6.9502e-41, -6.6363e-41],
          [ 6.8240e-41,  6.3871e-42, -2.8926e-41],
          [ 8.3027e-42,  3.9685e-42,  1.6737e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5201]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0150]], device='cuda:0')

Epoch: 142 | Batch_idx: 0 |  Loss: (0.1326) | Acc: (94.00%) (121/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1592) | Acc: (94.00%) (1332/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1589) | Acc: (94.00%) (2548/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1618) | Acc: (94.00%) (3758/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1580) | Acc: (94.00%) (4971/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1545) | Acc: (94.00%) (6194/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1548) | Acc: (94.00%) (7404/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1583) | Acc: (94.00%) (8611/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1562) | Acc: (94.00%) (9831/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1581) | Acc: (94.00%) (11042/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1571) | Acc: (94.00%) (12266/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1579) | Acc: (94.00%) (13478/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1577) | Acc: (94.00%) (14705/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1596) | Acc: (94.00%) (15904/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1595) | Acc: (94.00%) (17121/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1592) | Acc: (94.00%) (18327/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1596) | Acc: (94.00%) (19531/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1588) | Acc: (94.00%) (20738/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1582) | Acc: (94.00%) (21951/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1577) | Acc: (94.00%) (23170/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1584) | Acc: (94.00%) (24382/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1577) | Acc: (94.00%) (25598/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1587) | Acc: (94.00%) (26801/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1594) | Acc: (94.00%) (28010/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1588) | Acc: (94.00%) (29228/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1587) | Acc: (94.00%) (30443/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1586) | Acc: (94.00%) (31658/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1595) | Acc: (94.00%) (32858/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1591) | Acc: (94.00%) (34080/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1590) | Acc: (94.00%) (35291/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1587) | Acc: (94.00%) (36518/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1585) | Acc: (94.00%) (37730/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1582) | Acc: (94.00%) (38944/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1580) | Acc: (94.00%) (40163/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1579) | Acc: (94.00%) (41379/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1580) | Acc: (94.00%) (42585/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1576) | Acc: (94.00%) (43802/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1576) | Acc: (94.00%) (45021/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1576) | Acc: (94.00%) (46227/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1578) | Acc: (94.00%) (47387/50000)
# TEST : Loss: (0.2936) | Acc: (90.00%) (9066/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3256e-01,  3.9514e-01, -1.6434e-01],
          [-4.1477e-02,  2.9308e-02, -8.2351e-02],
          [ 7.3927e-02, -2.1910e-01,  2.7418e-01]],

         [[-1.5193e-01,  5.3263e-01,  1.0178e-01],
          [-8.5512e-03, -2.8832e-02, -1.5220e-01],
          [ 7.9332e-02, -4.0965e-01,  5.7192e-03]],

         [[-1.6745e-01,  2.9777e-01, -1.2625e-01],
          [ 5.3475e-02, -1.2881e-01, -1.0505e-01],
          [ 1.8660e-01, -6.2185e-02,  2.1613e-01]]],


        [[[-2.1185e-01, -4.4140e-01, -2.4771e-01],
          [-8.2736e-02,  2.1755e-01,  1.8044e-01],
          [ 2.0709e-01,  1.8288e-01,  2.5680e-01]],

         [[-2.7530e-01, -3.4935e-01, -2.0731e-01],
          [-1.1123e-01,  1.6727e-01,  2.3025e-01],
          [ 2.8866e-01,  1.4095e-01,  1.7708e-01]],

         [[-1.5960e-01, -7.5958e-02, -2.4013e-01],
          [ 5.7871e-02,  2.0318e-01, -5.2394e-02],
          [-5.1119e-03,  7.7014e-02,  5.0892e-02]]],


        [[[-1.0596e-01,  2.8763e-01,  1.0182e-01],
          [ 1.8283e-01,  2.3078e-01, -4.7619e-02],
          [-2.5734e-01, -8.4685e-02, -3.2891e-01]],

         [[ 4.5764e-02,  1.6370e-01,  2.3853e-02],
          [ 1.0725e-01,  2.8940e-01,  5.2002e-02],
          [-1.8202e-01, -1.4116e-01, -4.2465e-01]],

         [[-6.1497e-02,  1.8092e-01,  2.0704e-01],
          [ 6.6340e-02,  2.9407e-01,  1.1572e-01],
          [-2.6884e-01, -1.9845e-01, -2.6689e-01]]],


        ...,


        [[[-9.7707e-02, -1.3711e-01,  6.7740e-03],
          [ 3.3468e-02, -3.9600e-01, -1.6656e-01],
          [ 1.5666e-01, -5.6953e-02,  1.0067e-01]],

         [[ 1.3841e-01, -5.7530e-02, -1.4291e-02],
          [-5.8661e-02, -4.1816e-01, -2.3559e-01],
          [ 1.3623e-01,  2.7274e-03,  1.5677e-02]],

         [[ 2.0072e-01,  2.9020e-02,  9.3235e-02],
          [ 1.4594e-02, -2.5913e-01, -1.9853e-01],
          [ 1.1840e-01, -1.0208e-01, -9.7706e-02]]],


        [[[ 2.9117e-07,  2.2777e-07,  2.4328e-07],
          [ 7.9185e-08,  4.6003e-08,  1.1847e-07],
          [ 1.2166e-07,  3.9941e-08,  1.1605e-07]],

         [[ 5.9609e-08,  1.4091e-08, -9.8069e-10],
          [ 1.3666e-08,  3.1152e-09,  7.7185e-09],
          [ 2.2415e-08,  2.6213e-09,  1.3136e-08]],

         [[-1.4179e-09, -9.2080e-10, -8.5946e-10],
          [ 5.4502e-10,  1.3052e-10,  2.4901e-10],
          [ 1.0801e-08,  1.9919e-09,  3.3376e-09]]],


        [[[ 1.7822e-41, -7.0600e-41,  7.1533e-41],
          [ 1.5212e-41, -1.4187e-41, -5.2114e-42],
          [-5.3535e-41,  5.8349e-41, -1.9901e-41]],

         [[-1.7404e-42, -6.2788e-41,  6.1423e-41],
          [ 1.2820e-41, -2.3482e-41, -6.4140e-41],
          [-6.1300e-41,  7.4780e-41,  7.1323e-41]],

         [[ 9.1715e-42, -2.5533e-41, -6.8388e-41],
          [-7.2957e-41,  3.1664e-41,  4.8317e-41],
          [ 7.2995e-41, -4.3559e-41, -7.1940e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5507]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0071]], device='cuda:0')

Epoch: 143 | Batch_idx: 0 |  Loss: (0.1355) | Acc: (96.00%) (123/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1553) | Acc: (94.00%) (1335/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1631) | Acc: (94.00%) (2535/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1606) | Acc: (94.00%) (3748/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1633) | Acc: (94.00%) (4957/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1644) | Acc: (94.00%) (6166/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1639) | Acc: (94.00%) (7382/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1610) | Acc: (94.00%) (8603/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1602) | Acc: (94.00%) (9817/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1616) | Acc: (94.00%) (11019/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1628) | Acc: (94.00%) (12223/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1641) | Acc: (94.00%) (13422/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1631) | Acc: (94.00%) (14641/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1634) | Acc: (94.00%) (15840/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1623) | Acc: (94.00%) (17055/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1620) | Acc: (94.00%) (18258/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1613) | Acc: (94.00%) (19476/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1621) | Acc: (94.00%) (20683/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1635) | Acc: (94.00%) (21873/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1632) | Acc: (94.00%) (23084/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1624) | Acc: (94.00%) (24304/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1626) | Acc: (94.00%) (25512/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1631) | Acc: (94.00%) (26713/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1627) | Acc: (94.00%) (27928/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1625) | Acc: (94.00%) (29135/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1612) | Acc: (94.00%) (30362/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1607) | Acc: (94.00%) (31574/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1604) | Acc: (94.00%) (32789/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1593) | Acc: (94.00%) (34016/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1594) | Acc: (94.00%) (35226/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1586) | Acc: (94.00%) (36448/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1581) | Acc: (94.00%) (37666/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1577) | Acc: (94.00%) (38884/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1578) | Acc: (94.00%) (40097/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1576) | Acc: (94.00%) (41315/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1580) | Acc: (94.00%) (42523/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1582) | Acc: (94.00%) (43735/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1577) | Acc: (94.00%) (44957/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1580) | Acc: (94.00%) (46167/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1572) | Acc: (94.00%) (47354/50000)
# TEST : Loss: (0.2923) | Acc: (90.00%) (9051/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3201e-01,  3.9339e-01, -1.6366e-01],
          [-4.1312e-02,  2.9187e-02, -8.2011e-02],
          [ 7.3639e-02, -2.1821e-01,  2.7311e-01]],

         [[-1.5128e-01,  5.3018e-01,  1.0135e-01],
          [-8.5158e-03, -2.8707e-02, -1.5154e-01],
          [ 7.9006e-02, -4.0789e-01,  5.6962e-03]],

         [[-1.6670e-01,  2.9636e-01, -1.2570e-01],
          [ 5.3241e-02, -1.2823e-01, -1.0458e-01],
          [ 1.8579e-01, -6.1907e-02,  2.1523e-01]]],


        [[[-2.1127e-01, -4.4020e-01, -2.4704e-01],
          [-8.2510e-02,  2.1695e-01,  1.7994e-01],
          [ 2.0650e-01,  1.8235e-01,  2.5605e-01]],

         [[-2.7451e-01, -3.4837e-01, -2.0673e-01],
          [-1.1091e-01,  1.6679e-01,  2.2960e-01],
          [ 2.8782e-01,  1.4053e-01,  1.7656e-01]],

         [[-1.5912e-01, -7.5731e-02, -2.3942e-01],
          [ 5.7700e-02,  2.0257e-01, -5.2238e-02],
          [-5.0967e-03,  7.6782e-02,  5.0738e-02]]],


        [[[-1.0569e-01,  2.8688e-01,  1.0156e-01],
          [ 1.8236e-01,  2.3019e-01, -4.7497e-02],
          [-2.5668e-01, -8.4464e-02, -3.2804e-01]],

         [[ 4.5641e-02,  1.6326e-01,  2.3789e-02],
          [ 1.0697e-01,  2.8863e-01,  5.1864e-02],
          [-1.8154e-01, -1.4078e-01, -4.2349e-01]],

         [[-6.1326e-02,  1.8041e-01,  2.0647e-01],
          [ 6.6157e-02,  2.9325e-01,  1.1540e-01],
          [-2.6808e-01, -1.9789e-01, -2.6612e-01]]],


        ...,


        [[[-9.7149e-02, -1.3605e-01,  6.7253e-03],
          [ 3.3244e-02, -3.9116e-01, -1.6480e-01],
          [ 1.5581e-01, -5.6548e-02,  9.9985e-02]],

         [[ 1.3758e-01, -5.7055e-02, -1.4181e-02],
          [-5.8244e-02, -4.1216e-01, -2.3260e-01],
          [ 1.3546e-01,  2.7065e-03,  1.5559e-02]],

         [[ 1.9952e-01,  2.8798e-02,  9.2541e-02],
          [ 1.4493e-02, -2.5645e-01, -1.9651e-01],
          [ 1.1772e-01, -1.0132e-01, -9.6973e-02]]],


        [[[ 1.5744e-08,  1.1443e-08,  1.3061e-08],
          [ 2.6763e-09,  1.3330e-09,  4.5409e-09],
          [ 3.9438e-09,  9.2982e-10,  3.5606e-09]],

         [[ 2.3222e-09,  4.7151e-10, -3.4111e-11],
          [ 3.0029e-10,  4.7108e-11,  1.6418e-10],
          [ 4.7147e-10,  2.9352e-11,  2.3006e-10]],

         [[-2.6998e-11, -1.4037e-11, -1.3985e-11],
          [ 8.8810e-12,  1.4259e-12,  3.1786e-12],
          [ 2.3639e-10,  2.6460e-11,  4.9429e-11]]],


        [[[-1.8890e-41, -2.3484e-41, -6.9873e-41],
          [ 4.6623e-41, -3.4668e-41,  6.9640e-41],
          [ 4.6824e-41, -4.0788e-41,  1.6128e-41]],

         [[-2.7178e-41, -1.2703e-41, -7.3467e-41],
          [-5.6694e-41, -1.7148e-41,  3.2716e-41],
          [ 6.4317e-41,  2.3739e-41,  5.0965e-41]],

         [[ 5.3147e-41, -5.9645e-41,  2.6056e-41],
          [ 5.1216e-41, -7.7444e-41, -6.6340e-41],
          [ 2.0166e-41,  5.1750e-41,  1.7991e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5590]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0126]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1481) | Acc: (95.00%) (122/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1578) | Acc: (94.00%) (1334/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1777) | Acc: (94.00%) (2531/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1942) | Acc: (93.00%) (3710/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.2082) | Acc: (92.00%) (4877/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.2127) | Acc: (92.00%) (6064/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.2270) | Acc: (92.00%) (7208/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.2392) | Acc: (91.00%) (8340/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.2474) | Acc: (91.00%) (9478/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.2529) | Acc: (91.00%) (10626/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.2616) | Acc: (91.00%) (11765/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.2609) | Acc: (91.00%) (12935/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.2612) | Acc: (91.00%) (14103/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.2608) | Acc: (91.00%) (15273/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.2622) | Acc: (91.00%) (16426/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.2631) | Acc: (91.00%) (17593/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.2635) | Acc: (90.00%) (18753/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.2631) | Acc: (90.00%) (19917/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.2624) | Acc: (91.00%) (21086/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.2641) | Acc: (90.00%) (22237/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.2655) | Acc: (90.00%) (23393/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.2647) | Acc: (90.00%) (24559/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.2652) | Acc: (90.00%) (25718/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.2647) | Acc: (90.00%) (26892/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.2634) | Acc: (90.00%) (28064/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.2635) | Acc: (90.00%) (29230/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.2609) | Acc: (91.00%) (30425/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.2596) | Acc: (91.00%) (31604/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.2587) | Acc: (91.00%) (32775/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.2588) | Acc: (91.00%) (33932/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.2582) | Acc: (91.00%) (35095/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.2571) | Acc: (91.00%) (36266/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.2579) | Acc: (91.00%) (37418/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.2574) | Acc: (91.00%) (38598/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.2566) | Acc: (91.00%) (39767/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.2572) | Acc: (91.00%) (40937/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.2566) | Acc: (91.00%) (42123/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.2556) | Acc: (91.00%) (43300/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.2545) | Acc: (91.00%) (44487/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.2541) | Acc: (91.00%) (45616/50000)
# TEST : Loss: (0.3466) | Acc: (88.00%) (8890/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3551e-01,  3.7807e-01, -1.8368e-01],
          [-4.1917e-02,  1.0658e-02, -1.0017e-01],
          [ 6.7174e-02, -2.3559e-01,  2.7177e-01]],

         [[-1.4998e-01,  5.2115e-01,  8.6220e-02],
          [-2.8780e-03, -4.2471e-02, -1.6034e-01],
          [ 6.6644e-02, -4.2751e-01,  1.3595e-02]],

         [[-1.6485e-01,  2.8652e-01, -1.3361e-01],
          [ 6.1550e-02, -1.3798e-01, -1.1086e-01],
          [ 1.7665e-01, -7.3446e-02,  2.2071e-01]]],


        [[[-2.0766e-01, -4.4485e-01, -2.5420e-01],
          [-7.4694e-02,  2.2139e-01,  1.7891e-01],
          [ 2.1384e-01,  1.9048e-01,  2.5793e-01]],

         [[-2.6645e-01, -3.5294e-01, -2.1531e-01],
          [-1.0245e-01,  1.6957e-01,  2.2737e-01],
          [ 2.9377e-01,  1.4528e-01,  1.7485e-01]],

         [[-1.3905e-01, -6.9105e-02, -2.3641e-01],
          [ 7.7093e-02,  2.1690e-01, -4.2775e-02],
          [ 9.4461e-03,  9.0779e-02,  5.8090e-02]]],


        [[[-1.0914e-01,  2.8953e-01,  9.9872e-02],
          [ 1.7374e-01,  2.2979e-01, -4.3668e-02],
          [-2.6948e-01, -9.0298e-02, -3.2753e-01]],

         [[ 4.0616e-02,  1.6968e-01,  2.9255e-02],
          [ 9.5446e-02,  2.8840e-01,  5.5637e-02],
          [-1.9675e-01, -1.4700e-01, -4.2329e-01]],

         [[-5.8567e-02,  1.9104e-01,  2.1277e-01],
          [ 6.1716e-02,  2.9715e-01,  1.2179e-01],
          [-2.7129e-01, -1.9291e-01, -2.5750e-01]]],


        ...,


        [[[-9.6791e-02, -1.3025e-01,  1.7554e-02],
          [ 2.2792e-02, -4.1173e-01, -1.7226e-01],
          [ 1.4332e-01, -6.9186e-02,  9.2240e-02]],

         [[ 1.3100e-01, -5.5412e-02, -5.3902e-03],
          [-6.9535e-02, -4.3333e-01, -2.3757e-01],
          [ 1.2095e-01, -1.2373e-02,  6.3621e-03]],

         [[ 1.8885e-01,  2.3164e-02,  9.0085e-02],
          [ 6.6261e-03, -2.7362e-01, -2.0925e-01],
          [ 1.0722e-01, -1.1490e-01, -1.1051e-01]]],


        [[[ 4.2477e-10,  2.8125e-10,  3.4923e-10],
          [ 3.9739e-11,  1.6259e-11,  7.9162e-11],
          [ 5.5522e-11,  8.5631e-12,  4.6722e-11]],

         [[ 4.1326e-11,  6.9127e-12, -5.2540e-13],
          [ 2.5674e-12,  2.4841e-13,  1.3462e-12],
          [ 3.8101e-12,  1.0463e-13,  1.4675e-12]],

         [[-1.9189e-13, -7.4799e-14, -8.1108e-14],
          [ 5.1598e-14,  4.9211e-15,  1.3445e-14],
          [ 2.0107e-12,  1.1788e-13,  2.5368e-13]]],


        [[[-2.9842e-41,  7.1270e-42,  3.4029e-41],
          [ 1.4157e-41,  6.2463e-41,  1.8765e-41],
          [ 2.5446e-41, -1.8990e-41,  2.6499e-41]],

         [[-2.2935e-41,  8.6728e-41,  2.2942e-41],
          [ 6.3211e-41,  7.2331e-41,  5.2900e-41],
          [-5.2622e-41, -3.2318e-41,  4.0315e-42]],

         [[ 3.4017e-41,  4.2691e-41,  7.2629e-41],
          [ 2.8491e-41,  3.8248e-41,  1.6893e-41],
          [-8.4058e-41, -7.0817e-41,  3.9210e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0217,  0.0107,  0.0113],
          [ 0.0010, -0.0097, -0.0150],
          [ 0.0038,  0.0023, -0.0150]],

         [[ 0.0208,  0.0136,  0.0129],
          [ 0.0041, -0.0035, -0.0100],
          [ 0.0063,  0.0039, -0.0102]],

         [[ 0.0299,  0.0222,  0.0252],
          [ 0.0114,  0.0065,  0.0025],
          [ 0.0130,  0.0145, -0.0012]]],


        [[[ 0.0328,  0.0347,  0.0375],
          [ 0.0345,  0.0364,  0.0431],
          [ 0.0255,  0.0272,  0.0320]],

         [[ 0.0342,  0.0361,  0.0413],
          [ 0.0374,  0.0382,  0.0467],
          [ 0.0296,  0.0297,  0.0340]],

         [[ 0.0272,  0.0292,  0.0324],
          [ 0.0303,  0.0316,  0.0391],
          [ 0.0206,  0.0232,  0.0285]]],


        [[[ 0.0401,  0.0490,  0.0480],
          [ 0.0385,  0.0460,  0.0497],
          [ 0.0355,  0.0448,  0.0475]],

         [[ 0.0265,  0.0308,  0.0311],
          [ 0.0294,  0.0334,  0.0368],
          [ 0.0277,  0.0349,  0.0368]],

         [[ 0.0344,  0.0386,  0.0387],
          [ 0.0372,  0.0418,  0.0453],
          [ 0.0362,  0.0451,  0.0465]]],


        ...,


        [[[-0.0023,  0.0003, -0.0025],
          [ 0.0053,  0.0038, -0.0013],
          [ 0.0098,  0.0068,  0.0027]],

         [[-0.0065, -0.0013, -0.0034],
          [ 0.0012,  0.0015, -0.0037],
          [ 0.0049,  0.0020, -0.0018]],

         [[-0.0062, -0.0020, -0.0048],
          [ 0.0009,  0.0005, -0.0048],
          [ 0.0042,  0.0006, -0.0034]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5606]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 145 | Batch_idx: 0 |  Loss: (0.2796) | Acc: (89.00%) (114/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.2151) | Acc: (92.00%) (1305/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.2099) | Acc: (92.00%) (2492/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.2029) | Acc: (93.00%) (3699/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.2087) | Acc: (92.00%) (4880/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.2066) | Acc: (93.00%) (6077/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.2025) | Acc: (93.00%) (7284/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1987) | Acc: (93.00%) (8484/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.2022) | Acc: (93.00%) (9670/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.2058) | Acc: (93.00%) (10850/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.2036) | Acc: (93.00%) (12055/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.2047) | Acc: (93.00%) (13238/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.2060) | Acc: (93.00%) (14420/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.2039) | Acc: (93.00%) (15621/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.2018) | Acc: (93.00%) (16829/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.2023) | Acc: (93.00%) (18008/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.2006) | Acc: (93.00%) (19216/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.2010) | Acc: (93.00%) (20405/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.2024) | Acc: (93.00%) (21591/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.2035) | Acc: (93.00%) (22775/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.2018) | Acc: (93.00%) (23978/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.2040) | Acc: (93.00%) (25157/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.2050) | Acc: (93.00%) (26341/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.2046) | Acc: (93.00%) (27539/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.2056) | Acc: (93.00%) (28720/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.2059) | Acc: (93.00%) (29911/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.2051) | Acc: (93.00%) (31109/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.2055) | Acc: (93.00%) (32296/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.2050) | Acc: (93.00%) (33487/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.2055) | Acc: (93.00%) (34666/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.2058) | Acc: (93.00%) (35854/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.2063) | Acc: (93.00%) (37025/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.2066) | Acc: (92.00%) (38202/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.2070) | Acc: (92.00%) (39383/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.2066) | Acc: (92.00%) (40580/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.2076) | Acc: (92.00%) (41759/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.2081) | Acc: (92.00%) (42940/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.2079) | Acc: (92.00%) (44136/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.2076) | Acc: (92.00%) (45323/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.2071) | Acc: (92.00%) (46473/50000)
# TEST : Loss: (0.3092) | Acc: (90.00%) (9020/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3716e-01,  3.8888e-01, -1.7838e-01],
          [-4.4137e-02,  1.5314e-02, -1.0079e-01],
          [ 5.2878e-02, -2.3951e-01,  2.6740e-01]],

         [[-1.5000e-01,  5.2685e-01,  8.2704e-02],
          [-7.8394e-03, -4.3011e-02, -1.6485e-01],
          [ 5.3216e-02, -4.3189e-01,  7.5014e-03]],

         [[-1.7262e-01,  2.8023e-01, -1.4045e-01],
          [ 5.3884e-02, -1.4497e-01, -1.2050e-01],
          [ 1.6562e-01, -8.1562e-02,  2.0928e-01]]],


        [[[-2.0804e-01, -4.4323e-01, -2.5278e-01],
          [-7.1289e-02,  2.2662e-01,  1.8104e-01],
          [ 2.1472e-01,  1.9454e-01,  2.6155e-01]],

         [[-2.6984e-01, -3.5394e-01, -2.1550e-01],
          [-1.0158e-01,  1.7140e-01,  2.2653e-01],
          [ 2.9391e-01,  1.4611e-01,  1.7683e-01]],

         [[-1.4435e-01, -7.3697e-02, -2.4163e-01],
          [ 7.5150e-02,  2.1545e-01, -4.6684e-02],
          [ 5.8356e-03,  8.8231e-02,  5.8202e-02]]],


        [[[-1.1580e-01,  2.8548e-01,  9.7640e-02],
          [ 1.7342e-01,  2.3051e-01, -4.6105e-02],
          [-2.7061e-01, -9.1512e-02, -3.3395e-01]],

         [[ 3.6017e-02,  1.6662e-01,  2.5336e-02],
          [ 9.3774e-02,  2.8775e-01,  5.2390e-02],
          [-1.9945e-01, -1.4930e-01, -4.2957e-01]],

         [[-6.1043e-02,  1.9197e-01,  2.1283e-01],
          [ 6.1746e-02,  2.9967e-01,  1.2336e-01],
          [-2.7219e-01, -1.9248e-01, -2.6115e-01]]],


        ...,


        [[[-1.0162e-01, -1.3635e-01,  2.3146e-02],
          [ 1.0906e-02, -4.2645e-01, -1.6579e-01],
          [ 1.3556e-01, -6.9495e-02,  1.0613e-01]],

         [[ 1.3245e-01, -5.5754e-02,  6.7338e-03],
          [-7.6180e-02, -4.4663e-01, -2.3023e-01],
          [ 1.2117e-01, -3.1889e-03,  2.4717e-02]],

         [[ 1.9869e-01,  4.0173e-02,  1.1818e-01],
          [ 8.4388e-03, -2.6325e-01, -1.8491e-01],
          [ 1.1080e-01, -9.7869e-02, -8.3469e-02]]],


        [[[ 4.7274e-12,  2.7775e-12,  3.8423e-12],
          [ 2.0464e-13,  6.4802e-14,  5.0197e-13],
          [ 2.6679e-13,  2.3621e-14,  2.0486e-13]],

         [[ 2.6914e-13,  3.5014e-14, -2.8375e-15],
          [ 6.4224e-15,  3.2733e-16,  3.1867e-15],
          [ 8.8487e-15,  8.1454e-17,  2.4919e-15]],

         [[-3.7608e-16, -9.9954e-17, -1.2134e-16],
          [ 7.7376e-17,  3.6673e-18,  1.3184e-17],
          [ 4.9957e-15,  1.2394e-16,  3.2240e-16]]],


        [[[-4.4672e-41,  6.9221e-41, -1.3918e-41],
          [-4.3953e-41, -4.9270e-42, -6.3032e-41],
          [-5.6408e-41,  6.4852e-42,  2.3469e-41]],

         [[ 3.3282e-41,  4.0562e-41,  8.8868e-41],
          [-2.9849e-41,  5.3098e-41, -4.9892e-41],
          [-1.8965e-41, -5.9865e-41, -5.2689e-42]],

         [[-1.9953e-41,  5.1174e-41,  6.1102e-41],
          [ 2.4175e-41, -2.0102e-41,  4.0460e-41],
          [ 4.3080e-41, -1.7955e-41, -7.9403e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0204, -0.0154, -0.0035],
          [-0.0085, -0.0113, -0.0026],
          [ 0.0024, -0.0129, -0.0024]],

         [[-0.0291, -0.0270, -0.0110],
          [-0.0211, -0.0239, -0.0106],
          [-0.0112, -0.0233, -0.0137]],

         [[-0.0206, -0.0198, -0.0074],
          [-0.0170, -0.0189, -0.0110],
          [-0.0147, -0.0221, -0.0173]]],


        [[[-0.0434, -0.0360, -0.0263],
          [-0.0449, -0.0367, -0.0244],
          [-0.0465, -0.0432, -0.0239]],

         [[-0.0184, -0.0124, -0.0093],
          [-0.0170, -0.0118, -0.0064],
          [-0.0199, -0.0196, -0.0060]],

         [[-0.0250, -0.0198, -0.0169],
          [-0.0207, -0.0161, -0.0120],
          [-0.0173, -0.0162, -0.0057]]],


        [[[ 0.0016, -0.0000,  0.0009],
          [-0.0105, -0.0089,  0.0018],
          [-0.0040, -0.0058,  0.0033]],

         [[ 0.0190,  0.0213,  0.0213],
          [ 0.0048,  0.0075,  0.0169],
          [ 0.0041,  0.0043,  0.0143]],

         [[ 0.0222,  0.0172,  0.0148],
          [ 0.0111,  0.0085,  0.0138],
          [ 0.0079,  0.0064,  0.0145]]],


        ...,


        [[[-0.0166, -0.0123, -0.0069],
          [-0.0108, -0.0063, -0.0060],
          [-0.0115, -0.0064, -0.0063]],

         [[-0.0125, -0.0057, -0.0024],
          [-0.0074,  0.0003, -0.0011],
          [-0.0084,  0.0002, -0.0009]],

         [[-0.0157, -0.0106, -0.0102],
          [-0.0112, -0.0039, -0.0065],
          [-0.0117, -0.0024, -0.0042]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5594]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 146 | Batch_idx: 0 |  Loss: (0.1216) | Acc: (95.00%) (122/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1459) | Acc: (95.00%) (1342/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1683) | Acc: (94.00%) (2544/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1722) | Acc: (94.00%) (3754/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1676) | Acc: (94.00%) (4973/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1682) | Acc: (94.00%) (6182/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1717) | Acc: (94.00%) (7379/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1733) | Acc: (94.00%) (8575/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1746) | Acc: (94.00%) (9771/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1848) | Acc: (93.00%) (10929/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1842) | Acc: (93.00%) (12128/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1840) | Acc: (93.00%) (13330/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1821) | Acc: (93.00%) (14536/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1835) | Acc: (93.00%) (15735/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1835) | Acc: (93.00%) (16927/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1837) | Acc: (93.00%) (18113/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1847) | Acc: (93.00%) (19314/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1853) | Acc: (93.00%) (20514/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1853) | Acc: (93.00%) (21710/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1867) | Acc: (93.00%) (22906/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1868) | Acc: (93.00%) (24103/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1863) | Acc: (93.00%) (25306/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1850) | Acc: (93.00%) (26517/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1854) | Acc: (93.00%) (27722/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1867) | Acc: (93.00%) (28913/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1867) | Acc: (93.00%) (30122/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1876) | Acc: (93.00%) (31308/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1874) | Acc: (93.00%) (32504/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1879) | Acc: (93.00%) (33703/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1882) | Acc: (93.00%) (34892/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1885) | Acc: (93.00%) (36080/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1889) | Acc: (93.00%) (37273/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1890) | Acc: (93.00%) (38463/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1890) | Acc: (93.00%) (39668/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1890) | Acc: (93.00%) (40866/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1889) | Acc: (93.00%) (42063/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1885) | Acc: (93.00%) (43262/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1894) | Acc: (93.00%) (44437/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1897) | Acc: (93.00%) (45629/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1896) | Acc: (93.00%) (46783/50000)
# TEST : Loss: (0.3469) | Acc: (89.00%) (8936/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4516e-01,  3.9616e-01, -1.7798e-01],
          [-4.7280e-02,  2.5230e-02, -9.9501e-02],
          [ 5.1865e-02, -2.2877e-01,  2.7010e-01]],

         [[-1.6239e-01,  5.2748e-01,  8.0879e-02],
          [-1.7249e-02, -4.0977e-02, -1.6709e-01],
          [ 4.5202e-02, -4.3253e-01,  1.6247e-03]],

         [[-1.8484e-01,  2.8041e-01, -1.4523e-01],
          [ 4.3196e-02, -1.4675e-01, -1.2937e-01],
          [ 1.5047e-01, -8.8903e-02,  1.9210e-01]]],


        [[[-2.0112e-01, -4.4041e-01, -2.4816e-01],
          [-6.3395e-02,  2.3363e-01,  1.8912e-01],
          [ 2.2119e-01,  2.0429e-01,  2.6771e-01]],

         [[-2.7229e-01, -3.5882e-01, -2.1763e-01],
          [-1.0468e-01,  1.6842e-01,  2.2530e-01],
          [ 2.9041e-01,  1.4628e-01,  1.7296e-01]],

         [[-1.4275e-01, -7.5685e-02, -2.4039e-01],
          [ 7.5958e-02,  2.1551e-01, -4.3446e-02],
          [ 8.4397e-03,  9.2070e-02,  5.8924e-02]]],


        [[[-1.1087e-01,  2.8712e-01,  9.6453e-02],
          [ 1.7832e-01,  2.2860e-01, -5.2734e-02],
          [-2.6805e-01, -9.3419e-02, -3.3701e-01]],

         [[ 4.5501e-02,  1.7002e-01,  2.2771e-02],
          [ 1.0015e-01,  2.8649e-01,  4.5716e-02],
          [-1.9886e-01, -1.5270e-01, -4.3358e-01]],

         [[-5.8926e-02,  1.8713e-01,  2.0243e-01],
          [ 6.1207e-02,  2.8923e-01,  1.0814e-01],
          [-2.8010e-01, -2.0641e-01, -2.7448e-01]]],


        ...,


        [[[-9.3776e-02, -1.3528e-01,  2.5486e-02],
          [ 2.7576e-02, -4.2532e-01, -1.5698e-01],
          [ 1.4410e-01, -6.7887e-02,  1.0943e-01]],

         [[ 1.4098e-01, -5.3632e-02,  1.4371e-02],
          [-5.7779e-02, -4.4422e-01, -2.1671e-01],
          [ 1.3009e-01, -4.0856e-03,  2.7835e-02]],

         [[ 1.9837e-01,  3.0171e-02,  1.1489e-01],
          [ 1.6107e-02, -2.7512e-01, -1.8609e-01],
          [ 1.0817e-01, -1.1272e-01, -9.3301e-02]]],


        [[[ 1.6718e-14,  8.3980e-15,  1.3384e-14],
          [ 2.6126e-16,  5.8659e-17,  8.4561e-16],
          [ 3.1047e-16,  1.2982e-17,  2.1083e-16]],

         [[ 4.6974e-16,  4.3724e-17, -3.8602e-18],
          [ 3.0880e-18,  6.4707e-20,  1.4207e-18],
          [ 3.8426e-18,  7.6147e-21,  7.0212e-19]],

         [[-1.2927e-19, -2.0151e-20, -2.8654e-20],
          [ 1.8334e-20,  3.2188e-22,  1.7156e-21],
          [ 2.3798e-18,  1.7810e-20,  6.0567e-20]]],


        [[[-7.7178e-41,  6.2540e-41,  5.7439e-42],
          [-6.7673e-41, -5.2983e-42,  3.6208e-41],
          [-8.3296e-41, -2.5637e-41,  5.9188e-41]],

         [[ 8.8112e-41,  3.4831e-41,  4.8179e-41],
          [-9.2784e-41,  7.1092e-41,  4.7781e-41],
          [ 7.3280e-41,  8.7690e-41,  2.9909e-41]],

         [[-9.0618e-41, -6.7342e-41,  7.0812e-41],
          [ 2.8870e-41,  7.9475e-41, -7.1524e-41],
          [-7.2764e-41,  1.6506e-41,  8.0779e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0099,  0.0197,  0.0132],
          [-0.0009,  0.0169,  0.0126],
          [-0.0009,  0.0054, -0.0034]],

         [[ 0.0221,  0.0316,  0.0226],
          [ 0.0050,  0.0288,  0.0227],
          [ 0.0028,  0.0134,  0.0040]],

         [[ 0.0211,  0.0256,  0.0208],
          [ 0.0084,  0.0243,  0.0220],
          [ 0.0069,  0.0101,  0.0018]]],


        [[[ 0.0069,  0.0171,  0.0275],
          [ 0.0008,  0.0115,  0.0280],
          [ 0.0005,  0.0112,  0.0254]],

         [[ 0.0091,  0.0187,  0.0277],
          [ 0.0063,  0.0156,  0.0301],
          [ 0.0053,  0.0159,  0.0282]],

         [[-0.0073, -0.0009,  0.0065],
          [-0.0118, -0.0064,  0.0044],
          [-0.0141, -0.0072,  0.0021]]],


        [[[-0.0114,  0.0027,  0.0093],
          [-0.0055,  0.0057,  0.0096],
          [-0.0007,  0.0104,  0.0103]],

         [[-0.0090,  0.0051,  0.0129],
          [-0.0102,  0.0014,  0.0061],
          [-0.0067,  0.0047,  0.0037]],

         [[ 0.0001,  0.0078,  0.0164],
          [-0.0014,  0.0039,  0.0112],
          [ 0.0030,  0.0070,  0.0099]]],


        ...,


        [[[ 0.0121,  0.0070,  0.0140],
          [ 0.0154,  0.0085,  0.0154],
          [ 0.0172,  0.0074,  0.0153]],

         [[ 0.0002, -0.0057,  0.0011],
          [ 0.0043, -0.0032,  0.0033],
          [ 0.0073, -0.0033,  0.0042]],

         [[-0.0086, -0.0124, -0.0047],
          [-0.0069, -0.0109, -0.0029],
          [-0.0057, -0.0122, -0.0028]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5579]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 147 | Batch_idx: 0 |  Loss: (0.2304) | Acc: (92.00%) (119/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1894) | Acc: (93.00%) (1319/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1967) | Acc: (93.00%) (2520/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.2045) | Acc: (93.00%) (3704/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.2028) | Acc: (93.00%) (4903/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.2004) | Acc: (93.00%) (6104/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1976) | Acc: (93.00%) (7308/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1958) | Acc: (93.00%) (8507/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1917) | Acc: (93.00%) (9717/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1900) | Acc: (93.00%) (10924/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1895) | Acc: (93.00%) (12117/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1876) | Acc: (93.00%) (13317/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1851) | Acc: (93.00%) (14527/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1845) | Acc: (93.00%) (15735/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1826) | Acc: (93.00%) (16941/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1815) | Acc: (93.00%) (18147/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1814) | Acc: (93.00%) (19352/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1810) | Acc: (93.00%) (20553/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1805) | Acc: (93.00%) (21759/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1798) | Acc: (93.00%) (22960/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1800) | Acc: (93.00%) (24158/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1807) | Acc: (93.00%) (25352/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1803) | Acc: (93.00%) (26556/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1796) | Acc: (93.00%) (27773/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1780) | Acc: (93.00%) (28991/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1779) | Acc: (93.00%) (30199/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1768) | Acc: (94.00%) (31411/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1765) | Acc: (94.00%) (32622/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1751) | Acc: (94.00%) (33847/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1749) | Acc: (94.00%) (35056/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1741) | Acc: (94.00%) (36269/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1747) | Acc: (94.00%) (37465/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1743) | Acc: (94.00%) (38681/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1733) | Acc: (94.00%) (39907/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1728) | Acc: (94.00%) (41125/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1722) | Acc: (94.00%) (42338/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1722) | Acc: (94.00%) (43546/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1717) | Acc: (94.00%) (44759/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1717) | Acc: (94.00%) (45970/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1711) | Acc: (94.00%) (47140/50000)
# TEST : Loss: (0.2851) | Acc: (90.00%) (9093/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4621e-01,  3.9273e-01, -1.7870e-01],
          [-4.8495e-02,  2.2516e-02, -1.0084e-01],
          [ 4.8869e-02, -2.3105e-01,  2.6742e-01]],

         [[-1.6296e-01,  5.2420e-01,  8.0252e-02],
          [-1.7884e-02, -4.3034e-02, -1.6757e-01],
          [ 4.2789e-02, -4.3357e-01,  8.7161e-04]],

         [[-1.8415e-01,  2.7851e-01, -1.4531e-01],
          [ 4.3479e-02, -1.4708e-01, -1.2995e-01],
          [ 1.4883e-01, -8.9359e-02,  1.9119e-01]]],


        [[[-1.9808e-01, -4.3729e-01, -2.4571e-01],
          [-6.0553e-02,  2.3555e-01,  1.9064e-01],
          [ 2.2361e-01,  2.0593e-01,  2.6883e-01]],

         [[-2.7025e-01, -3.5710e-01, -2.1646e-01],
          [-1.0275e-01,  1.6941e-01,  2.2571e-01],
          [ 2.9203e-01,  1.4726e-01,  1.7328e-01]],

         [[-1.4118e-01, -7.4779e-02, -2.3927e-01],
          [ 7.7438e-02,  2.1626e-01, -4.2667e-02],
          [ 1.0385e-02,  9.2977e-02,  5.9152e-02]]],


        [[[-1.1262e-01,  2.8386e-01,  9.3530e-02],
          [ 1.7561e-01,  2.2559e-01, -5.4854e-02],
          [-2.7053e-01, -9.6239e-02, -3.3901e-01]],

         [[ 4.3475e-02,  1.6680e-01,  1.9594e-02],
          [ 9.7558e-02,  2.8323e-01,  4.3227e-02],
          [-2.0154e-01, -1.5545e-01, -4.3530e-01]],

         [[-6.1442e-02,  1.8319e-01,  1.9804e-01],
          [ 5.7907e-02,  2.8515e-01,  1.0462e-01],
          [-2.8319e-01, -2.0963e-01, -2.7737e-01]]],


        ...,


        [[[-9.2031e-02, -1.3304e-01,  2.6914e-02],
          [ 2.8393e-02, -4.2074e-01, -1.5599e-01],
          [ 1.4529e-01, -6.4840e-02,  1.1057e-01]],

         [[ 1.4112e-01, -5.2854e-02,  1.4848e-02],
          [-5.6673e-02, -4.3904e-01, -2.1525e-01],
          [ 1.3155e-01, -9.2147e-04,  2.9619e-02]],

         [[ 1.9868e-01,  3.1055e-02,  1.1508e-01],
          [ 1.7489e-02, -2.7179e-01, -1.8412e-01],
          [ 1.1002e-01, -1.0881e-01, -9.0284e-02]]],


        [[[ 1.2876e-17,  5.2299e-18,  1.0100e-17],
          [ 4.9397e-20,  6.8092e-21,  2.3564e-19],
          [ 5.1511e-20,  7.3112e-22,  2.9389e-20]],

         [[ 1.3751e-19,  8.0134e-21, -7.9804e-22],
          [ 1.4276e-22,  7.6861e-25,  5.8700e-23],
          [ 1.5269e-22,  2.6426e-26,  1.4494e-23]],

         [[-3.6143e-24, -2.4692e-25, -4.5005e-25],
          [ 2.8946e-25,  1.0022e-27,  1.0376e-26],
          [ 1.0851e-22,  1.2674e-25,  6.6360e-25]]],


        [[[-2.7527e-41, -6.4140e-41, -7.3728e-41],
          [-3.7203e-41, -7.5537e-41, -5.3677e-41],
          [-9.0074e-41,  3.9008e-41,  7.1311e-41]],

         [[-9.9701e-41,  9.7868e-41,  1.0055e-40],
          [-6.3121e-41, -8.7115e-41,  4.5974e-41],
          [ 7.2083e-41, -8.4077e-41,  8.3600e-41]],

         [[ 6.1083e-41,  4.3921e-41, -7.3546e-41],
          [ 8.0056e-41, -4.5020e-41,  1.4389e-41],
          [ 1.0942e-40,  1.9617e-41,  6.7627e-42]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5280]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0379]], device='cuda:0')

Epoch: 148 | Batch_idx: 0 |  Loss: (0.1686) | Acc: (95.00%) (122/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1713) | Acc: (94.00%) (1330/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1523) | Acc: (95.00%) (2557/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1590) | Acc: (95.00%) (3775/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1660) | Acc: (94.00%) (4976/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1668) | Acc: (94.00%) (6184/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1657) | Acc: (94.00%) (7392/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1623) | Acc: (94.00%) (8610/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1598) | Acc: (94.00%) (9833/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1577) | Acc: (94.00%) (11054/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1569) | Acc: (94.00%) (12268/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1562) | Acc: (94.00%) (13489/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1550) | Acc: (94.00%) (14704/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1549) | Acc: (94.00%) (15918/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1543) | Acc: (95.00%) (17147/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1546) | Acc: (94.00%) (18357/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1542) | Acc: (94.00%) (19571/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1528) | Acc: (95.00%) (20800/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1527) | Acc: (95.00%) (22019/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1529) | Acc: (95.00%) (23232/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1531) | Acc: (95.00%) (24444/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1536) | Acc: (94.00%) (25653/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1534) | Acc: (94.00%) (26871/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1537) | Acc: (95.00%) (28091/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1529) | Acc: (95.00%) (29309/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1538) | Acc: (94.00%) (30514/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1540) | Acc: (94.00%) (31733/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1539) | Acc: (94.00%) (32949/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1548) | Acc: (94.00%) (34158/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1554) | Acc: (94.00%) (35363/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1550) | Acc: (94.00%) (36583/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1549) | Acc: (94.00%) (37793/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1547) | Acc: (94.00%) (39016/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1542) | Acc: (94.00%) (40236/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1545) | Acc: (94.00%) (41438/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1544) | Acc: (94.00%) (42649/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1542) | Acc: (94.00%) (43877/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1546) | Acc: (94.00%) (45089/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1546) | Acc: (94.00%) (46310/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1552) | Acc: (94.00%) (47462/50000)
# TEST : Loss: (0.2771) | Acc: (91.00%) (9107/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4569e-01,  3.9127e-01, -1.7808e-01],
          [-4.8328e-02,  2.2437e-02, -1.0049e-01],
          [ 4.8705e-02, -2.3024e-01,  2.6653e-01]],

         [[-1.6236e-01,  5.2217e-01,  7.9964e-02],
          [-1.7820e-02, -4.2876e-02, -1.6697e-01],
          [ 4.2638e-02, -4.3196e-01,  8.6855e-04]],

         [[-1.8344e-01,  2.7740e-01, -1.4477e-01],
          [ 4.3317e-02, -1.4652e-01, -1.2947e-01],
          [ 1.4829e-01, -8.9017e-02,  1.9049e-01]]],


        [[[-1.9768e-01, -4.3641e-01, -2.4522e-01],
          [-6.0429e-02,  2.3507e-01,  1.9025e-01],
          [ 2.2313e-01,  2.0550e-01,  2.6825e-01]],

         [[-2.6968e-01, -3.5636e-01, -2.1602e-01],
          [-1.0254e-01,  1.6905e-01,  2.2523e-01],
          [ 2.9140e-01,  1.4694e-01,  1.7291e-01]],

         [[-1.4086e-01, -7.4611e-02, -2.3874e-01],
          [ 7.7264e-02,  2.1578e-01, -4.2572e-02],
          [ 1.0362e-02,  9.2764e-02,  5.9017e-02]]],


        [[[-1.1238e-01,  2.8326e-01,  9.3333e-02],
          [ 1.7524e-01,  2.2512e-01, -5.4738e-02],
          [-2.6996e-01, -9.6036e-02, -3.3828e-01]],

         [[ 4.3382e-02,  1.6645e-01,  1.9552e-02],
          [ 9.7353e-02,  2.8263e-01,  4.3136e-02],
          [-2.0111e-01, -1.5512e-01, -4.3435e-01]],

         [[-6.1307e-02,  1.8278e-01,  1.9760e-01],
          [ 5.7782e-02,  2.8453e-01,  1.0439e-01],
          [-2.8256e-01, -2.0916e-01, -2.7674e-01]]],


        ...,


        [[[-9.1565e-02, -1.3216e-01,  2.6752e-02],
          [ 2.8216e-02, -4.1581e-01, -1.5452e-01],
          [ 1.4457e-01, -6.4419e-02,  1.0991e-01]],

         [[ 1.4040e-01, -5.2489e-02,  1.4753e-02],
          [-5.6312e-02, -4.3333e-01, -2.1299e-01],
          [ 1.3088e-01, -9.1519e-04,  2.9432e-02]],

         [[ 1.9764e-01,  3.0851e-02,  1.1436e-01],
          [ 1.7382e-02, -2.6939e-01, -1.8258e-01],
          [ 1.0945e-01, -1.0810e-01, -8.9705e-02]]],


        [[[ 1.1851e-21,  3.5369e-22,  9.0270e-22],
          [ 5.4676e-25,  3.4075e-26,  4.7824e-24],
          [ 4.6268e-25,  1.0318e-27,  1.9901e-25]],

         [[ 3.0100e-24,  8.4410e-26, -1.0174e-26],
          [ 1.3905e-28,  2.8497e-32,  4.5998e-29],
          [ 1.1079e-28, -1.3735e-34,  2.5547e-30]],

         [[-1.2704e-30, -1.0178e-32, -3.9312e-32],
          [ 2.5651e-32, -4.7253e-36, -3.2677e-35],
          [ 1.0293e-28,  7.9444e-35,  1.8346e-32]]],


        [[[ 8.3824e-41,  7.6729e-41,  2.3121e-43],
          [ 7.1002e-41, -7.5625e-41, -7.2610e-41],
          [-4.8523e-41, -3.7406e-41, -7.5561e-41]],

         [[ 9.5811e-41, -9.9751e-41, -7.3309e-41],
          [-8.8170e-41, -8.5112e-41, -3.0323e-41],
          [ 6.4404e-42,  4.3259e-41, -9.9646e-42]],

         [[-7.7893e-41,  1.0098e-40,  3.0128e-42],
          [ 4.2279e-41, -9.8842e-41, -9.8609e-42],
          [ 9.3127e-41,  1.3618e-41, -9.7914e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5369]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0186]], device='cuda:0')

Epoch: 149 | Batch_idx: 0 |  Loss: (0.1574) | Acc: (94.00%) (121/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1704) | Acc: (94.00%) (1327/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1616) | Acc: (94.00%) (2543/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1606) | Acc: (94.00%) (3762/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1582) | Acc: (94.00%) (4977/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1585) | Acc: (94.00%) (6191/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1577) | Acc: (94.00%) (7406/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1539) | Acc: (94.00%) (8633/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1544) | Acc: (94.00%) (9841/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1528) | Acc: (95.00%) (11067/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1522) | Acc: (95.00%) (12283/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1535) | Acc: (94.00%) (13490/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1524) | Acc: (94.00%) (14712/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1527) | Acc: (94.00%) (15922/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1526) | Acc: (94.00%) (17126/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1518) | Acc: (94.00%) (18348/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1531) | Acc: (94.00%) (19557/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1533) | Acc: (94.00%) (20771/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1542) | Acc: (94.00%) (21984/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1548) | Acc: (94.00%) (23193/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1556) | Acc: (94.00%) (24403/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1560) | Acc: (94.00%) (25615/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1552) | Acc: (94.00%) (26834/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1546) | Acc: (94.00%) (28056/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1545) | Acc: (94.00%) (29271/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1545) | Acc: (94.00%) (30490/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1545) | Acc: (94.00%) (31701/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1545) | Acc: (94.00%) (32915/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1545) | Acc: (94.00%) (34131/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1541) | Acc: (94.00%) (35349/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1542) | Acc: (94.00%) (36555/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1543) | Acc: (94.00%) (37772/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1547) | Acc: (94.00%) (38986/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1551) | Acc: (94.00%) (40202/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1558) | Acc: (94.00%) (41407/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1556) | Acc: (94.00%) (42619/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1550) | Acc: (94.00%) (43844/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1547) | Acc: (94.00%) (45061/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1547) | Acc: (94.00%) (46268/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1551) | Acc: (94.00%) (47424/50000)
# TEST : Loss: (0.2716) | Acc: (91.00%) (9139/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4506e-01,  3.8950e-01, -1.7733e-01],
          [-4.8126e-02,  2.2341e-02, -1.0008e-01],
          [ 4.8505e-02, -2.2926e-01,  2.6546e-01]],

         [[-1.6163e-01,  5.1971e-01,  7.9615e-02],
          [-1.7743e-02, -4.2685e-02, -1.6625e-01],
          [ 4.2456e-02, -4.3001e-01,  8.6485e-04]],

         [[-1.8258e-01,  2.7605e-01, -1.4411e-01],
          [ 4.3120e-02, -1.4584e-01, -1.2888e-01],
          [ 1.4763e-01, -8.8603e-02,  1.8965e-01]]],


        [[[-1.9718e-01, -4.3534e-01, -2.4462e-01],
          [-6.0280e-02,  2.3449e-01,  1.8977e-01],
          [ 2.2256e-01,  2.0497e-01,  2.6756e-01]],

         [[-2.6898e-01, -3.5546e-01, -2.1548e-01],
          [-1.0228e-01,  1.6862e-01,  2.2466e-01],
          [ 2.9064e-01,  1.4656e-01,  1.7245e-01]],

         [[-1.4047e-01, -7.4408e-02, -2.3810e-01],
          [ 7.7053e-02,  2.1519e-01, -4.2456e-02],
          [ 1.0333e-02,  9.2506e-02,  5.8854e-02]]],


        [[[-1.1209e-01,  2.8253e-01,  9.3093e-02],
          [ 1.7479e-01,  2.2455e-01, -5.4597e-02],
          [-2.6926e-01, -9.5790e-02, -3.3739e-01]],

         [[ 4.3270e-02,  1.6602e-01,  1.9502e-02],
          [ 9.7105e-02,  2.8191e-01,  4.3024e-02],
          [-2.0059e-01, -1.5472e-01, -4.3320e-01]],

         [[-6.1144e-02,  1.8229e-01,  1.9707e-01],
          [ 5.7629e-02,  2.8377e-01,  1.0410e-01],
          [-2.8181e-01, -2.0859e-01, -2.7597e-01]]],


        ...,


        [[[-9.1002e-02, -1.3109e-01,  2.6555e-02],
          [ 2.8003e-02, -4.0989e-01, -1.5274e-01],
          [ 1.4371e-01, -6.3911e-02,  1.0911e-01]],

         [[ 1.3953e-01, -5.2047e-02,  1.4639e-02],
          [-5.5877e-02, -4.2649e-01, -2.1027e-01],
          [ 1.3009e-01, -9.0761e-04,  2.9205e-02]],

         [[ 1.9639e-01,  3.0605e-02,  1.1348e-01],
          [ 1.7254e-02, -2.6650e-01, -1.8073e-01],
          [ 1.0877e-01, -1.0723e-01, -8.9007e-02]]],


        [[[ 4.0047e-27,  6.9623e-28,  2.8998e-27],
          [ 1.5711e-32, -1.7659e-34,  8.0909e-31],
          [ 5.1840e-33, -5.9136e-37, -1.5473e-34]],

         [[ 6.0990e-31,  1.9994e-33, -4.7788e-34],
          [ 7.4635e-38, -4.1492e-41,  4.0658e-38],
          [ 1.0641e-37, -5.2598e-41,  3.0650e-40]],

         [[-1.0904e-39,  2.2607e-41,  5.7620e-41],
          [-5.2923e-41, -5.2474e-41,  3.5889e-41],
          [ 6.0746e-38,  6.1936e-41, -3.9766e-41]]],


        [[[-4.0342e-41, -2.4102e-43,  1.4819e-41],
          [ 7.0847e-41,  9.0392e-41,  2.1406e-41],
          [ 4.4706e-41,  8.6547e-41,  8.1728e-41]],

         [[-8.5883e-41, -9.5134e-41, -6.3458e-41],
          [ 3.5615e-41,  5.7385e-41, -1.9428e-41],
          [-4.6722e-41,  1.0393e-40,  8.9928e-41]],

         [[ 1.2740e-40,  4.1232e-41, -9.1537e-41],
          [ 2.9339e-41, -6.5478e-41,  6.4825e-41],
          [ 1.6430e-41,  6.5079e-41, -1.1784e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5230]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0215]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 150 | Batch_idx: 0 |  Loss: (0.1921) | Acc: (92.00%) (118/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.1604) | Acc: (94.00%) (1332/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1831) | Acc: (93.00%) (2520/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1977) | Acc: (93.00%) (3699/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.2111) | Acc: (92.00%) (4867/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.2271) | Acc: (92.00%) (6020/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.2417) | Acc: (91.00%) (7155/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.2449) | Acc: (91.00%) (8316/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.2490) | Acc: (91.00%) (9480/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.2552) | Acc: (91.00%) (10636/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.2598) | Acc: (91.00%) (11791/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.2628) | Acc: (91.00%) (12936/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.2635) | Acc: (91.00%) (14095/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.2659) | Acc: (90.00%) (15245/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.2669) | Acc: (90.00%) (16399/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.2668) | Acc: (90.00%) (17567/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.2663) | Acc: (90.00%) (18734/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.2653) | Acc: (90.00%) (19905/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.2644) | Acc: (90.00%) (21070/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.2632) | Acc: (90.00%) (22239/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.2618) | Acc: (91.00%) (23422/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.2637) | Acc: (91.00%) (24579/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.2628) | Acc: (91.00%) (25749/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.2627) | Acc: (91.00%) (26918/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.2622) | Acc: (91.00%) (28088/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.2617) | Acc: (91.00%) (29259/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.2600) | Acc: (91.00%) (30437/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.2594) | Acc: (91.00%) (31618/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.2595) | Acc: (91.00%) (32780/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.2594) | Acc: (91.00%) (33951/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.2592) | Acc: (91.00%) (35122/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.2595) | Acc: (91.00%) (36288/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.2585) | Acc: (91.00%) (37467/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.2579) | Acc: (91.00%) (38645/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.2575) | Acc: (91.00%) (39818/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.2567) | Acc: (91.00%) (40994/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.2558) | Acc: (91.00%) (42172/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.2564) | Acc: (91.00%) (43337/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.2554) | Acc: (91.00%) (44523/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.2555) | Acc: (91.00%) (45649/50000)
# TEST : Loss: (0.3746) | Acc: (88.00%) (8861/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4047e-01,  3.9962e-01, -1.6992e-01],
          [-4.9431e-02,  2.5489e-02, -9.2663e-02],
          [ 6.5811e-02, -2.1952e-01,  2.7969e-01]],

         [[-1.4753e-01,  5.3431e-01,  9.1581e-02],
          [-9.1930e-03, -4.3347e-02, -1.5711e-01],
          [ 6.5102e-02, -4.1923e-01,  1.4208e-02]],

         [[-1.6756e-01,  2.8781e-01, -1.3713e-01],
          [ 5.7509e-02, -1.4170e-01, -1.1729e-01],
          [ 1.7843e-01, -7.1422e-02,  2.1336e-01]]],


        [[[-2.0488e-01, -4.3949e-01, -2.4152e-01],
          [-6.0911e-02,  2.3817e-01,  1.9740e-01],
          [ 2.2005e-01,  2.0491e-01,  2.6536e-01]],

         [[-2.8002e-01, -3.6256e-01, -2.1714e-01],
          [-1.0558e-01,  1.6882e-01,  2.2621e-01],
          [ 2.8938e-01,  1.4435e-01,  1.6518e-01]],

         [[-1.4686e-01, -7.5495e-02, -2.3337e-01],
          [ 7.4834e-02,  2.1984e-01, -3.6955e-02],
          [ 1.0900e-02,  9.3609e-02,  5.2773e-02]]],


        [[[-9.0836e-02,  3.0779e-01,  1.1793e-01],
          [ 1.8785e-01,  2.4249e-01, -3.2392e-02],
          [-2.6366e-01, -8.1149e-02, -3.2018e-01]],

         [[ 5.1294e-02,  1.8017e-01,  3.2924e-02],
          [ 1.0064e-01,  2.9152e-01,  5.8756e-02],
          [-2.0232e-01, -1.4680e-01, -4.2037e-01]],

         [[-4.9484e-02,  1.9723e-01,  2.1093e-01],
          [ 6.5665e-02,  2.9516e-01,  1.2043e-01],
          [-2.8194e-01, -1.9790e-01, -2.5939e-01]]],


        ...,


        [[[-7.9308e-02, -1.2773e-01,  1.8872e-02],
          [ 3.2276e-02, -4.0334e-01, -1.4672e-01],
          [ 1.4682e-01, -5.2265e-02,  1.2104e-01]],

         [[ 1.3879e-01, -6.8447e-02, -1.2771e-02],
          [-6.4010e-02, -4.4836e-01, -2.3385e-01],
          [ 1.3030e-01,  5.0299e-03,  3.2151e-02]],

         [[ 2.0317e-01,  2.1006e-02,  9.2564e-02],
          [ 1.7118e-02, -2.7680e-01, -1.9387e-01],
          [ 1.1034e-01, -1.0506e-01, -9.0667e-02]]],


        [[[-2.0387e-35, -1.4947e-36, -1.4110e-35],
          [-1.4125e-41,  5.9625e-42,  4.4154e-41],
          [-2.5364e-41,  6.5286e-41,  4.7885e-41]],

         [[ 1.6479e-40,  9.6690e-44,  1.7586e-41],
          [ 4.8961e-42, -6.7735e-41, -6.3765e-41],
          [-4.1909e-41, -6.5431e-41,  6.5116e-41]],

         [[ 5.1217e-42,  5.8311e-41,  1.7574e-41],
          [-1.1610e-41, -3.6309e-41,  4.1494e-41],
          [-2.3605e-41,  4.9107e-41, -6.5125e-41]]],


        [[[-5.3361e-42, -1.0168e-40, -6.0802e-42],
          [-2.9360e-41,  8.6445e-41,  8.7133e-42],
          [-1.0868e-40,  1.0124e-41, -8.8582e-41]],

         [[-1.1172e-40, -9.9651e-41, -4.7012e-41],
          [ 6.8701e-41,  6.9844e-41,  1.0197e-40],
          [-9.2428e-41, -7.2533e-41, -1.4836e-41]],

         [[ 4.3530e-41,  7.8263e-41,  4.2311e-41],
          [ 8.5493e-42, -5.1527e-41, -7.3530e-41],
          [ 5.3099e-41, -3.8541e-41, -7.2655e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0131, -0.0153, -0.0239],
          [ 0.0079, -0.0188, -0.0280],
          [-0.0268, -0.0410, -0.0322]],

         [[ 0.0210, -0.0071, -0.0122],
          [ 0.0103, -0.0183, -0.0259],
          [-0.0314, -0.0439, -0.0343]],

         [[ 0.0124, -0.0093, -0.0139],
          [ 0.0002, -0.0226, -0.0257],
          [-0.0444, -0.0528, -0.0384]]],


        [[[-0.0132, -0.0009,  0.0189],
          [-0.0126, -0.0018,  0.0188],
          [-0.0147, -0.0100,  0.0029]],

         [[-0.0070,  0.0037,  0.0188],
          [-0.0035,  0.0070,  0.0242],
          [-0.0052, -0.0007,  0.0111]],

         [[ 0.0158,  0.0222,  0.0306],
          [ 0.0185,  0.0270,  0.0372],
          [ 0.0149,  0.0187,  0.0252]]],


        [[[ 0.0395,  0.0273,  0.0106],
          [ 0.0534,  0.0498,  0.0301],
          [ 0.0386,  0.0399,  0.0331]],

         [[ 0.0334,  0.0165, -0.0020],
          [ 0.0458,  0.0364,  0.0133],
          [ 0.0320,  0.0300,  0.0184]],

         [[ 0.0242,  0.0069, -0.0096],
          [ 0.0395,  0.0299,  0.0082],
          [ 0.0268,  0.0238,  0.0136]]],


        ...,


        [[[ 0.0096,  0.0136,  0.0094],
          [ 0.0021,  0.0035,  0.0049],
          [ 0.0097,  0.0067,  0.0134]],

         [[ 0.0159,  0.0179,  0.0105],
          [ 0.0055,  0.0051,  0.0033],
          [ 0.0138,  0.0092,  0.0136]],

         [[ 0.0131,  0.0141,  0.0095],
          [ 0.0053,  0.0039,  0.0032],
          [ 0.0120,  0.0069,  0.0112]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5195]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 151 | Batch_idx: 0 |  Loss: (0.1732) | Acc: (93.00%) (120/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.2038) | Acc: (92.00%) (1305/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.2100) | Acc: (92.00%) (2489/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.2114) | Acc: (92.00%) (3666/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.2104) | Acc: (92.00%) (4854/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.2108) | Acc: (92.00%) (6036/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.2137) | Acc: (92.00%) (7216/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.2156) | Acc: (92.00%) (8390/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.2147) | Acc: (92.00%) (9579/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.2130) | Acc: (92.00%) (10770/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.2125) | Acc: (92.00%) (11960/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.2080) | Acc: (92.00%) (13171/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.2098) | Acc: (92.00%) (14353/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.2095) | Acc: (92.00%) (15549/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.2095) | Acc: (92.00%) (16735/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.2094) | Acc: (92.00%) (17931/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.2112) | Acc: (92.00%) (19100/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.2094) | Acc: (92.00%) (20308/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.2082) | Acc: (92.00%) (21504/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.2090) | Acc: (92.00%) (22681/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.2074) | Acc: (92.00%) (23883/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.2066) | Acc: (92.00%) (25072/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.2061) | Acc: (92.00%) (26271/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.2069) | Acc: (92.00%) (27459/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.2068) | Acc: (92.00%) (28644/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.2072) | Acc: (92.00%) (29829/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.2069) | Acc: (92.00%) (31027/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.2063) | Acc: (92.00%) (32219/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.2067) | Acc: (92.00%) (33404/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.2070) | Acc: (92.00%) (34592/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.2066) | Acc: (92.00%) (35786/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.2069) | Acc: (92.00%) (36966/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.2083) | Acc: (92.00%) (38143/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.2092) | Acc: (92.00%) (39323/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.2084) | Acc: (92.00%) (40525/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.2088) | Acc: (92.00%) (41708/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.2082) | Acc: (92.00%) (42906/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.2084) | Acc: (92.00%) (44096/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.2080) | Acc: (92.00%) (45286/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.2080) | Acc: (92.00%) (46426/50000)
# TEST : Loss: (0.3461) | Acc: (89.00%) (8928/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3880e-01,  3.9887e-01, -1.7584e-01],
          [-5.1142e-02,  2.3602e-02, -1.1310e-01],
          [ 7.5647e-02, -2.1645e-01,  2.7235e-01]],

         [[-1.4944e-01,  5.3163e-01,  9.3447e-02],
          [-1.9927e-02, -5.1605e-02, -1.7384e-01],
          [ 6.7998e-02, -4.2149e-01,  7.0061e-03]],

         [[-1.6646e-01,  2.8771e-01, -1.2498e-01],
          [ 4.7023e-02, -1.5047e-01, -1.2829e-01],
          [ 1.8344e-01, -6.8209e-02,  2.1460e-01]]],


        [[[-2.1368e-01, -4.5097e-01, -2.5027e-01],
          [-7.3058e-02,  2.2564e-01,  1.8598e-01],
          [ 2.1135e-01,  1.9805e-01,  2.6075e-01]],

         [[-2.8663e-01, -3.7148e-01, -2.2283e-01],
          [-1.1199e-01,  1.6222e-01,  2.1903e-01],
          [ 2.8856e-01,  1.4629e-01,  1.6793e-01]],

         [[-1.4735e-01, -7.8347e-02, -2.3378e-01],
          [ 7.2995e-02,  2.1901e-01, -3.7162e-02],
          [ 1.1749e-02,  9.9025e-02,  6.0928e-02]]],


        [[[-9.8514e-02,  3.0524e-01,  1.1721e-01],
          [ 1.8582e-01,  2.4606e-01, -2.9820e-02],
          [-2.6516e-01, -7.7123e-02, -3.2122e-01]],

         [[ 3.8579e-02,  1.7392e-01,  2.9302e-02],
          [ 9.2620e-02,  2.8872e-01,  5.6321e-02],
          [-2.1103e-01, -1.5121e-01, -4.2808e-01]],

         [[-5.7439e-02,  1.9866e-01,  2.1519e-01],
          [ 6.4721e-02,  3.0152e-01,  1.2654e-01],
          [-2.7983e-01, -1.9103e-01, -2.5668e-01]]],


        ...,


        [[[-7.1585e-02, -1.1871e-01,  2.8183e-02],
          [ 2.5000e-02, -4.1727e-01, -1.4727e-01],
          [ 1.3946e-01, -5.5761e-02,  1.2518e-01]],

         [[ 1.4557e-01, -5.7523e-02, -7.1136e-04],
          [-6.4178e-02, -4.5010e-01, -2.2478e-01],
          [ 1.3305e-01,  1.2142e-02,  4.4051e-02]],

         [[ 2.0260e-01,  2.3569e-02,  9.8889e-02],
          [ 1.0155e-02, -2.8782e-01, -1.9700e-01],
          [ 1.0852e-01, -1.0461e-01, -8.8287e-02]]],


        [[[-3.2624e-41,  5.8731e-41, -2.8166e-41],
          [-4.3210e-41,  5.1358e-42,  4.9375e-41],
          [-4.2840e-41,  2.5693e-41,  5.6021e-41]],

         [[ 4.7772e-41, -2.6080e-41, -5.9751e-41],
          [-4.8320e-41,  4.6058e-41, -1.3842e-41],
          [-3.9692e-41,  4.8898e-41, -2.8043e-41]],

         [[-6.7657e-41, -6.6696e-41,  1.4630e-41],
          [-2.4210e-41, -2.6919e-42, -3.6708e-41],
          [-6.4420e-41, -5.1457e-41,  6.0176e-41]]],


        [[[ 7.4344e-41, -1.2241e-40, -4.9946e-41],
          [ 5.1946e-41, -9.8031e-41, -9.3136e-41],
          [-1.0876e-40, -7.9847e-41, -6.0064e-41]],

         [[ 1.0056e-40,  1.1627e-40, -1.1831e-40],
          [ 1.1332e-40, -5.0276e-41, -5.3593e-41],
          [-9.4162e-41,  8.5499e-41, -1.1848e-40]],

         [[-1.5461e-40,  5.9841e-41, -1.7379e-41],
          [-1.1498e-40,  4.1897e-41, -1.6911e-41],
          [-7.5300e-41, -1.0686e-41,  1.2299e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0078, -0.0132, -0.0128],
          [-0.0054, -0.0112, -0.0068],
          [-0.0020, -0.0075, -0.0017]],

         [[ 0.0016, -0.0048, -0.0066],
          [ 0.0017, -0.0038,  0.0022],
          [ 0.0025, -0.0070,  0.0014]],

         [[ 0.0088,  0.0019, -0.0008],
          [ 0.0074,  0.0015,  0.0099],
          [ 0.0058, -0.0046,  0.0057]]],


        [[[ 0.0127,  0.0086,  0.0070],
          [ 0.0160,  0.0106,  0.0068],
          [ 0.0116,  0.0103,  0.0082]],

         [[-0.0032, -0.0055, -0.0044],
          [-0.0009, -0.0047, -0.0066],
          [-0.0020, -0.0047, -0.0060]],

         [[-0.0090, -0.0111, -0.0090],
          [-0.0075, -0.0114, -0.0118],
          [-0.0080, -0.0118, -0.0123]]],


        [[[-0.0163, -0.0214, -0.0186],
          [-0.0192, -0.0229, -0.0209],
          [-0.0194, -0.0224, -0.0225]],

         [[-0.0068, -0.0103, -0.0041],
          [-0.0055, -0.0099, -0.0057],
          [-0.0058, -0.0098, -0.0091]],

         [[-0.0020, -0.0031,  0.0051],
          [ 0.0009, -0.0027,  0.0025],
          [ 0.0013, -0.0029, -0.0016]]],


        ...,


        [[[ 0.0157,  0.0110,  0.0144],
          [ 0.0108,  0.0046,  0.0094],
          [ 0.0075,  0.0008,  0.0073]],

         [[ 0.0154,  0.0090,  0.0124],
          [ 0.0088,  0.0013,  0.0064],
          [ 0.0035, -0.0027,  0.0044]],

         [[ 0.0134,  0.0062,  0.0108],
          [ 0.0071, -0.0005,  0.0051],
          [ 0.0019, -0.0035,  0.0038]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5183]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 152 | Batch_idx: 0 |  Loss: (0.2615) | Acc: (89.00%) (115/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1793) | Acc: (93.00%) (1314/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1911) | Acc: (92.00%) (2499/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1814) | Acc: (93.00%) (3707/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1807) | Acc: (93.00%) (4906/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1842) | Acc: (93.00%) (6096/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1860) | Acc: (93.00%) (7289/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.1823) | Acc: (93.00%) (8496/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.1791) | Acc: (93.00%) (9708/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.1796) | Acc: (93.00%) (10909/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.1806) | Acc: (93.00%) (12108/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.1804) | Acc: (93.00%) (13307/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.1800) | Acc: (93.00%) (14505/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.1814) | Acc: (93.00%) (15694/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.1822) | Acc: (93.00%) (16888/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.1822) | Acc: (93.00%) (18092/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.1840) | Acc: (93.00%) (19273/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.1842) | Acc: (93.00%) (20471/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.1846) | Acc: (93.00%) (21660/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.1852) | Acc: (93.00%) (22856/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.1859) | Acc: (93.00%) (24050/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.1869) | Acc: (93.00%) (25240/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.1869) | Acc: (93.00%) (26443/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.1875) | Acc: (93.00%) (27647/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.1867) | Acc: (93.00%) (28848/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.1861) | Acc: (93.00%) (30055/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.1863) | Acc: (93.00%) (31251/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.1860) | Acc: (93.00%) (32454/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.1864) | Acc: (93.00%) (33660/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.1866) | Acc: (93.00%) (34860/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.1862) | Acc: (93.00%) (36058/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.1867) | Acc: (93.00%) (37254/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.1868) | Acc: (93.00%) (38452/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.1870) | Acc: (93.00%) (39644/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.1866) | Acc: (93.00%) (40853/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.1861) | Acc: (93.00%) (42060/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.1861) | Acc: (93.00%) (43258/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.1861) | Acc: (93.00%) (44455/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.1868) | Acc: (93.00%) (45643/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.1871) | Acc: (93.00%) (46788/50000)
# TEST : Loss: (0.3523) | Acc: (89.00%) (8952/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5402e-01,  3.9331e-01, -1.7740e-01],
          [-5.9504e-02,  2.0147e-02, -1.1582e-01],
          [ 6.5933e-02, -2.1573e-01,  2.8392e-01]],

         [[-1.5965e-01,  5.3196e-01,  9.8677e-02],
          [-2.3500e-02, -4.8901e-02, -1.6687e-01],
          [ 6.2083e-02, -4.1377e-01,  2.8017e-02]],

         [[-1.8594e-01,  2.7954e-01, -1.2706e-01],
          [ 3.5719e-02, -1.5211e-01, -1.2807e-01],
          [ 1.7555e-01, -6.0865e-02,  2.2835e-01]]],


        [[[-2.1387e-01, -4.5275e-01, -2.4628e-01],
          [-7.6583e-02,  2.2585e-01,  1.9318e-01],
          [ 2.0627e-01,  1.9440e-01,  2.5738e-01]],

         [[-2.9187e-01, -3.7811e-01, -2.2349e-01],
          [-1.1487e-01,  1.6144e-01,  2.2474e-01],
          [ 2.8535e-01,  1.4288e-01,  1.6507e-01]],

         [[-1.5000e-01, -8.3696e-02, -2.3500e-01],
          [ 7.3402e-02,  2.1950e-01, -3.0904e-02],
          [ 1.3287e-02,  9.8762e-02,  6.1852e-02]]],


        [[[-9.8679e-02,  3.0581e-01,  1.1834e-01],
          [ 1.8426e-01,  2.4412e-01, -3.0507e-02],
          [-2.7007e-01, -7.8883e-02, -3.2379e-01]],

         [[ 4.0624e-02,  1.7506e-01,  2.8275e-02],
          [ 9.2628e-02,  2.8666e-01,  5.5092e-02],
          [-2.1674e-01, -1.5370e-01, -4.2865e-01]],

         [[-5.0377e-02,  2.0283e-01,  2.1344e-01],
          [ 6.8322e-02,  3.0263e-01,  1.2612e-01],
          [-2.8323e-01, -1.9168e-01, -2.5636e-01]]],


        ...,


        [[[-8.9691e-02, -1.2909e-01,  1.0291e-02],
          [ 9.3451e-03, -4.2523e-01, -1.6511e-01],
          [ 1.3842e-01, -4.6639e-02,  1.2335e-01]],

         [[ 1.3253e-01, -6.5206e-02, -1.4845e-02],
          [-7.3464e-02, -4.5221e-01, -2.3956e-01],
          [ 1.3761e-01,  2.6696e-02,  4.5114e-02]],

         [[ 1.9447e-01,  2.4583e-02,  9.5776e-02],
          [ 6.9062e-03, -2.7850e-01, -1.9386e-01],
          [ 1.1862e-01, -8.3565e-02, -7.8124e-02]]],


        [[[-1.7424e-41,  5.5675e-41, -1.6970e-41],
          [ 6.0587e-41,  1.3252e-41, -4.6949e-41],
          [ 5.0647e-41,  4.4456e-41, -5.9716e-41]],

         [[-4.3051e-41,  4.1477e-41,  1.3681e-41],
          [ 2.0427e-41,  1.8985e-41, -6.9982e-41],
          [-4.8919e-41, -3.1919e-41, -4.0904e-42]],

         [[-3.7794e-41, -6.9701e-41,  2.1227e-41],
          [ 2.5383e-41, -6.7770e-41,  1.6048e-41],
          [-2.1824e-41, -4.7797e-41,  7.0180e-41]]],


        [[[ 1.2930e-40,  8.8936e-41, -2.5623e-41],
          [-6.0476e-41, -4.2710e-41,  1.2505e-41],
          [ 6.0620e-42, -7.0511e-41,  2.2973e-41]],

         [[-1.5993e-40, -3.5541e-41, -6.7893e-41],
          [-1.2290e-40,  6.8179e-41,  2.6723e-41],
          [ 1.0844e-40,  1.0241e-40,  9.2133e-41]],

         [[ 1.0725e-40,  1.2162e-40,  1.0731e-40],
          [ 1.2689e-40,  4.9092e-41, -5.8555e-41],
          [-6.5725e-41, -7.6288e-41, -6.3758e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0143,  0.0149,  0.0223],
          [ 0.0186,  0.0199,  0.0264],
          [ 0.0247,  0.0303,  0.0368]],

         [[ 0.0149,  0.0209,  0.0290],
          [ 0.0140,  0.0168,  0.0281],
          [ 0.0187,  0.0247,  0.0367]],

         [[ 0.0045,  0.0100,  0.0121],
          [ 0.0016,  0.0055,  0.0117],
          [-0.0003,  0.0090,  0.0143]]],


        [[[ 0.0057, -0.0025,  0.0025],
          [ 0.0013, -0.0023,  0.0081],
          [-0.0077, -0.0094, -0.0026]],

         [[-0.0012, -0.0101, -0.0035],
          [ 0.0022, -0.0015,  0.0088],
          [-0.0035, -0.0053,  0.0009]],

         [[-0.0140, -0.0174, -0.0061],
          [-0.0146, -0.0142, -0.0014],
          [-0.0145, -0.0133, -0.0055]]],


        [[[ 0.0116,  0.0209,  0.0254],
          [ 0.0169,  0.0286,  0.0310],
          [ 0.0219,  0.0294,  0.0288]],

         [[ 0.0102,  0.0201,  0.0235],
          [ 0.0110,  0.0229,  0.0242],
          [ 0.0138,  0.0208,  0.0207]],

         [[-0.0015,  0.0031,  0.0052],
          [ 0.0039,  0.0081,  0.0070],
          [ 0.0064,  0.0059,  0.0031]]],


        ...,


        [[[ 0.0305,  0.0146,  0.0148],
          [ 0.0264,  0.0096,  0.0093],
          [ 0.0294,  0.0144,  0.0127]],

         [[ 0.0311,  0.0155,  0.0157],
          [ 0.0281,  0.0108,  0.0099],
          [ 0.0326,  0.0175,  0.0143]],

         [[ 0.0155,  0.0027,  0.0032],
          [ 0.0135, -0.0005, -0.0019],
          [ 0.0157,  0.0027, -0.0006]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5169]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 153 | Batch_idx: 0 |  Loss: (0.1598) | Acc: (94.00%) (121/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1636) | Acc: (94.00%) (1324/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1791) | Acc: (93.00%) (2518/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1916) | Acc: (93.00%) (3703/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1937) | Acc: (93.00%) (4890/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1969) | Acc: (93.00%) (6078/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1963) | Acc: (92.00%) (7260/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1967) | Acc: (93.00%) (8460/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1929) | Acc: (93.00%) (9661/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1933) | Acc: (93.00%) (10859/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1909) | Acc: (93.00%) (12063/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1916) | Acc: (93.00%) (13257/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1905) | Acc: (93.00%) (14459/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1908) | Acc: (93.00%) (15655/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1899) | Acc: (93.00%) (16852/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1884) | Acc: (93.00%) (18058/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1856) | Acc: (93.00%) (19278/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1829) | Acc: (93.00%) (20493/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1825) | Acc: (93.00%) (21698/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1824) | Acc: (93.00%) (22899/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1812) | Acc: (93.00%) (24115/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1809) | Acc: (93.00%) (25318/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1802) | Acc: (93.00%) (26535/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1792) | Acc: (93.00%) (27750/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1793) | Acc: (93.00%) (28956/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1777) | Acc: (93.00%) (30172/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1781) | Acc: (93.00%) (31368/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1781) | Acc: (93.00%) (32562/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1778) | Acc: (93.00%) (33763/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1777) | Acc: (93.00%) (34960/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1769) | Acc: (93.00%) (36175/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1757) | Acc: (93.00%) (37392/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1754) | Acc: (93.00%) (38600/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1752) | Acc: (93.00%) (39808/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1739) | Acc: (93.00%) (41027/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1739) | Acc: (93.00%) (42227/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1734) | Acc: (94.00%) (43441/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1732) | Acc: (94.00%) (44646/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1726) | Acc: (94.00%) (45863/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1717) | Acc: (94.00%) (47040/50000)
# TEST : Loss: (0.3060) | Acc: (90.00%) (9068/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5320e-01,  3.9386e-01, -1.7471e-01],
          [-5.8937e-02,  2.1854e-02, -1.1403e-01],
          [ 6.7283e-02, -2.1323e-01,  2.8552e-01]],

         [[-1.5845e-01,  5.3119e-01,  9.9950e-02],
          [-2.3190e-02, -4.7484e-02, -1.6556e-01],
          [ 6.3783e-02, -4.1046e-01,  2.9753e-02]],

         [[-1.8548e-01,  2.7958e-01, -1.2489e-01],
          [ 3.5117e-02, -1.5055e-01, -1.2677e-01],
          [ 1.7607e-01, -5.9356e-02,  2.2922e-01]]],


        [[[-2.1007e-01, -4.4868e-01, -2.4392e-01],
          [-7.2627e-02,  2.2927e-01,  1.9556e-01],
          [ 2.0945e-01,  1.9749e-01,  2.5924e-01]],

         [[-2.8925e-01, -3.7546e-01, -2.2247e-01],
          [-1.1220e-01,  1.6342e-01,  2.2533e-01],
          [ 2.8653e-01,  1.4413e-01,  1.6530e-01]],

         [[-1.4552e-01, -7.9856e-02, -2.3220e-01],
          [ 7.7830e-02,  2.2333e-01, -2.7739e-02],
          [ 1.6580e-02,  1.0191e-01,  6.4277e-02]]],


        [[[-9.7654e-02,  3.0524e-01,  1.1793e-01],
          [ 1.8401e-01,  2.4274e-01, -3.1724e-02],
          [-2.6964e-01, -7.9447e-02, -3.2410e-01]],

         [[ 4.1418e-02,  1.7434e-01,  2.7141e-02],
          [ 9.2611e-02,  2.8492e-01,  5.3246e-02],
          [-2.1628e-01, -1.5424e-01, -4.2907e-01]],

         [[-4.8754e-02,  2.0319e-01,  2.1300e-01],
          [ 6.9055e-02,  3.0193e-01,  1.2507e-01],
          [-2.8220e-01, -1.9135e-01, -2.5632e-01]]],


        ...,


        [[[-9.0984e-02, -1.2865e-01,  1.0863e-02],
          [ 9.1164e-03, -4.2075e-01, -1.6293e-01],
          [ 1.3867e-01, -4.4806e-02,  1.2344e-01]],

         [[ 1.2892e-01, -6.7080e-02, -1.5756e-02],
          [-7.6116e-02, -4.5178e-01, -2.4005e-01],
          [ 1.3543e-01,  2.5160e-02,  4.3061e-02]],

         [[ 1.9209e-01,  2.4104e-02,  9.6101e-02],
          [ 5.5036e-03, -2.7704e-01, -1.9143e-01],
          [ 1.1742e-01, -8.2614e-02, -7.6673e-02]]],


        [[[-1.6170e-41,  4.7224e-43, -2.1663e-41],
          [ 4.9610e-41,  7.1255e-41, -2.7188e-41],
          [ 3.7111e-41, -7.4451e-42, -1.9073e-41]],

         [[-2.2180e-41,  2.6248e-41, -6.2446e-41],
          [-4.3516e-41,  5.1702e-41,  6.4255e-41],
          [ 4.2074e-41, -1.6524e-41,  4.4371e-41]],

         [[ 5.7920e-41,  8.6979e-42,  4.2891e-41],
          [ 6.2302e-41, -6.8952e-41, -2.8263e-41],
          [-2.5896e-42, -5.8578e-41,  4.8597e-42]]],


        [[[-8.9557e-42, -8.8189e-41, -3.1046e-41],
          [-5.1355e-41,  9.9425e-41,  1.0430e-40],
          [ 1.5814e-40, -7.4155e-41,  2.7285e-41]],

         [[ 1.1998e-40,  1.0115e-40, -1.5831e-40],
          [ 3.0767e-41,  1.0745e-40, -1.1379e-40],
          [-1.2158e-40, -1.2535e-40,  1.3130e-40]],

         [[ 1.1482e-40,  8.7832e-41, -2.5303e-41],
          [-1.0538e-40,  1.8001e-40,  6.6989e-41],
          [-2.3140e-41, -2.8219e-41, -7.7432e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5460]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0055]], device='cuda:0')

Epoch: 154 | Batch_idx: 0 |  Loss: (0.2093) | Acc: (93.00%) (120/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1538) | Acc: (94.00%) (1337/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1461) | Acc: (95.00%) (2563/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1523) | Acc: (95.00%) (3778/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1566) | Acc: (94.00%) (4983/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1584) | Acc: (94.00%) (6184/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1597) | Acc: (94.00%) (7392/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1605) | Acc: (94.00%) (8606/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1596) | Acc: (94.00%) (9824/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1611) | Acc: (94.00%) (11028/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1607) | Acc: (94.00%) (12241/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1624) | Acc: (94.00%) (13446/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1628) | Acc: (94.00%) (14650/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1610) | Acc: (94.00%) (15875/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1600) | Acc: (94.00%) (17090/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1603) | Acc: (94.00%) (18299/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1592) | Acc: (94.00%) (19513/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1580) | Acc: (94.00%) (20733/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1566) | Acc: (94.00%) (21954/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1568) | Acc: (94.00%) (23177/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1577) | Acc: (94.00%) (24378/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1575) | Acc: (94.00%) (25590/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1573) | Acc: (94.00%) (26804/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1571) | Acc: (94.00%) (28018/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1576) | Acc: (94.00%) (29228/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1572) | Acc: (94.00%) (30444/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1563) | Acc: (94.00%) (31676/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1562) | Acc: (94.00%) (32888/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1566) | Acc: (94.00%) (34097/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1567) | Acc: (94.00%) (35307/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1559) | Acc: (94.00%) (36534/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1563) | Acc: (94.00%) (37745/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1564) | Acc: (94.00%) (38950/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1564) | Acc: (94.00%) (40166/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1558) | Acc: (94.00%) (41394/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1560) | Acc: (94.00%) (42603/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1560) | Acc: (94.00%) (43817/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1555) | Acc: (94.00%) (45046/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1559) | Acc: (94.00%) (46243/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1562) | Acc: (94.00%) (47407/50000)
# TEST : Loss: (0.2967) | Acc: (90.00%) (9076/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5270e-01,  3.9252e-01, -1.7414e-01],
          [-5.8746e-02,  2.1783e-02, -1.1365e-01],
          [ 6.7068e-02, -2.1254e-01,  2.8464e-01]],

         [[-1.5791e-01,  5.2930e-01,  9.9611e-02],
          [-2.3112e-02, -4.7320e-02, -1.6499e-01],
          [ 6.3569e-02, -4.0904e-01,  2.9655e-02]],

         [[-1.8481e-01,  2.7853e-01, -1.2444e-01],
          [ 3.4994e-02, -1.5000e-01, -1.2630e-01],
          [ 1.7546e-01, -5.9139e-02,  2.2841e-01]]],


        [[[-2.0961e-01, -4.4770e-01, -2.4339e-01],
          [-7.2467e-02,  2.2876e-01,  1.9512e-01],
          [ 2.0897e-01,  1.9704e-01,  2.5864e-01]],

         [[-2.8859e-01, -3.7462e-01, -2.2197e-01],
          [-1.1195e-01,  1.6305e-01,  2.2482e-01],
          [ 2.8586e-01,  1.4379e-01,  1.6491e-01]],

         [[-1.4517e-01, -7.9664e-02, -2.3165e-01],
          [ 7.7643e-02,  2.2279e-01, -2.7673e-02],
          [ 1.6539e-02,  1.0166e-01,  6.4119e-02]]],


        [[[-9.7450e-02,  3.0460e-01,  1.1768e-01],
          [ 1.8364e-01,  2.4225e-01, -3.1658e-02],
          [-2.6908e-01, -7.9282e-02, -3.2342e-01]],

         [[ 4.1328e-02,  1.7396e-01,  2.7083e-02],
          [ 9.2414e-02,  2.8431e-01,  5.3135e-02],
          [-2.1581e-01, -1.5391e-01, -4.2815e-01]],

         [[-4.8643e-02,  2.0273e-01,  2.1251e-01],
          [ 6.8900e-02,  3.0126e-01,  1.2479e-01],
          [-2.8155e-01, -1.9092e-01, -2.5574e-01]]],


        ...,


        [[[-9.0558e-02, -1.2784e-01,  1.0802e-02],
          [ 9.0655e-03, -4.1648e-01, -1.6152e-01],
          [ 1.3805e-01, -4.4541e-02,  1.2276e-01]],

         [[ 1.2829e-01, -6.6625e-02, -1.5660e-02],
          [-7.5664e-02, -4.4632e-01, -2.3760e-01],
          [ 1.3478e-01,  2.4996e-02,  4.2800e-02]],

         [[ 1.9115e-01,  2.3955e-02,  9.5546e-02],
          [ 5.4724e-03, -2.7475e-01, -1.8990e-01],
          [ 1.1684e-01, -8.2097e-02, -7.6207e-02]]],


        [[[-5.5448e-41,  5.2198e-41, -4.7634e-41],
          [ 2.7247e-41,  5.3935e-41,  6.9724e-41],
          [ 6.2582e-41, -5.0279e-41, -6.9888e-41]],

         [[-1.8014e-41,  6.6029e-41, -3.5488e-41],
          [ 1.7194e-41, -2.0294e-41,  2.1126e-41],
          [ 5.0534e-41,  6.0956e-41,  4.1605e-42]],

         [[ 2.1846e-42, -8.8436e-42, -3.8312e-41],
          [-7.0380e-41, -3.1288e-41, -1.4052e-41],
          [ 6.6567e-41,  7.2238e-41, -2.5359e-41]]],


        [[[-1.7078e-40,  9.2553e-41,  6.1429e-41],
          [ 1.4073e-41, -1.3253e-40, -1.1333e-40],
          [ 5.8459e-41, -2.7890e-41, -1.6050e-40]],

         [[ 6.0406e-41, -9.5822e-41,  1.7941e-40],
          [-6.6926e-41,  5.1124e-41,  3.7716e-41],
          [-1.1671e-40, -9.3682e-41, -1.5078e-40]],

         [[-1.0328e-40,  1.9074e-40,  1.1558e-40],
          [-7.2779e-41, -1.9447e-40, -5.6220e-41],
          [-1.1013e-40, -3.2720e-42, -9.1697e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5513]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0376]], device='cuda:0')

Epoch: 155 | Batch_idx: 0 |  Loss: (0.1092) | Acc: (95.00%) (122/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.1177) | Acc: (95.00%) (1348/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1361) | Acc: (95.00%) (2558/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1280) | Acc: (95.00%) (3797/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1359) | Acc: (95.00%) (5004/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1422) | Acc: (95.00%) (6209/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1433) | Acc: (95.00%) (7425/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1411) | Acc: (95.00%) (8650/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1409) | Acc: (95.00%) (9879/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1430) | Acc: (95.00%) (11097/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1453) | Acc: (95.00%) (12302/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1471) | Acc: (95.00%) (13505/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1466) | Acc: (95.00%) (14722/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1455) | Acc: (95.00%) (15945/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1455) | Acc: (95.00%) (17164/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1469) | Acc: (95.00%) (18372/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1467) | Acc: (95.00%) (19595/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1473) | Acc: (95.00%) (20811/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1496) | Acc: (95.00%) (22015/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1517) | Acc: (94.00%) (23209/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1533) | Acc: (94.00%) (24404/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1533) | Acc: (94.00%) (25620/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1528) | Acc: (94.00%) (26835/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1531) | Acc: (94.00%) (28047/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1527) | Acc: (94.00%) (29269/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1528) | Acc: (94.00%) (30476/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1530) | Acc: (94.00%) (31693/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1532) | Acc: (94.00%) (32898/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1529) | Acc: (94.00%) (34118/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1530) | Acc: (94.00%) (35331/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1536) | Acc: (94.00%) (36544/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1538) | Acc: (94.00%) (37754/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1546) | Acc: (94.00%) (38966/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1545) | Acc: (94.00%) (40169/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1548) | Acc: (94.00%) (41371/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1552) | Acc: (94.00%) (42573/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1554) | Acc: (94.00%) (43777/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1560) | Acc: (94.00%) (44983/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1563) | Acc: (94.00%) (46189/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1563) | Acc: (94.00%) (47365/50000)
# TEST : Loss: (0.2887) | Acc: (90.00%) (9081/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5209e-01,  3.9089e-01, -1.7345e-01],
          [-5.8515e-02,  2.1696e-02, -1.1320e-01],
          [ 6.6807e-02, -2.1170e-01,  2.8356e-01]],

         [[-1.5726e-01,  5.2701e-01,  9.9199e-02],
          [-2.3017e-02, -4.7121e-02, -1.6430e-01],
          [ 6.3311e-02, -4.0732e-01,  2.9536e-02]],

         [[-1.8400e-01,  2.7725e-01, -1.2389e-01],
          [ 3.4844e-02, -1.4933e-01, -1.2574e-01],
          [ 1.7473e-01, -5.8877e-02,  2.2742e-01]]],


        [[[-2.0905e-01, -4.4651e-01, -2.4274e-01],
          [-7.2273e-02,  2.2815e-01,  1.9459e-01],
          [ 2.0839e-01,  1.9649e-01,  2.5791e-01]],

         [[-2.8780e-01, -3.7360e-01, -2.2136e-01],
          [-1.1164e-01,  1.6260e-01,  2.2421e-01],
          [ 2.8505e-01,  1.4338e-01,  1.6444e-01]],

         [[-1.4475e-01, -7.9432e-02, -2.3097e-01],
          [ 7.7416e-02,  2.2214e-01, -2.7592e-02],
          [ 1.6490e-02,  1.0136e-01,  6.3927e-02]]],


        [[[-9.7203e-02,  3.0382e-01,  1.1738e-01],
          [ 1.8318e-01,  2.4164e-01, -3.1579e-02],
          [-2.6840e-01, -7.9083e-02, -3.2260e-01]],

         [[ 4.1218e-02,  1.7350e-01,  2.7012e-02],
          [ 9.2175e-02,  2.8358e-01,  5.2999e-02],
          [-2.1524e-01, -1.5350e-01, -4.2703e-01]],

         [[-4.8507e-02,  2.0216e-01,  2.1193e-01],
          [ 6.8711e-02,  3.0044e-01,  1.2445e-01],
          [-2.8076e-01, -1.9039e-01, -2.5503e-01]]],


        ...,


        [[[-9.0043e-02, -1.2686e-01,  1.0727e-02],
          [ 9.0040e-03, -4.1135e-01, -1.5982e-01],
          [ 1.3729e-01, -4.4222e-02,  1.2193e-01]],

         [[ 1.2753e-01, -6.6075e-02, -1.5544e-02],
          [-7.5118e-02, -4.3977e-01, -2.3464e-01],
          [ 1.3401e-01,  2.4798e-02,  4.2485e-02]],

         [[ 1.9002e-01,  2.3776e-02,  9.4875e-02],
          [ 5.4347e-03, -2.7199e-01, -1.8806e-01],
          [ 1.1615e-01, -8.1472e-02, -7.5645e-02]]],


        [[[-7.0767e-41,  3.1503e-41, -5.3488e-41],
          [-3.8683e-41, -4.5804e-41, -2.9998e-41],
          [-6.9584e-41, -3.3159e-41,  1.7865e-41]],

         [[ 2.8756e-41, -7.4252e-41,  6.3389e-41],
          [ 3.7694e-41,  4.8551e-41, -2.8797e-42],
          [ 3.2600e-41, -4.0455e-42, -7.5062e-41]],

         [[-4.9822e-41,  4.9945e-41, -2.1738e-41],
          [ 1.9330e-41,  7.2303e-41,  3.4403e-41],
          [ 7.0847e-41, -7.5058e-41,  6.8832e-42]]],


        [[[-1.4770e-40,  4.0395e-41, -7.3603e-41],
          [ 4.6952e-41, -7.3271e-41, -9.2737e-41],
          [-1.1475e-40,  9.9026e-41,  1.7930e-40]],

         [[-1.3780e-40, -1.1358e-40, -2.0485e-40],
          [ 4.2563e-41, -1.5785e-40,  1.3175e-40],
          [ 1.1214e-40, -7.8271e-41,  1.4029e-40]],

         [[-1.2352e-40, -8.1102e-41, -8.4900e-41],
          [-1.0693e-40,  1.8811e-40, -2.6989e-42],
          [ 1.0854e-40,  6.7156e-41,  1.3191e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5296]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[-0.0412]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 156 | Batch_idx: 0 |  Loss: (0.1081) | Acc: (98.00%) (126/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1655) | Acc: (95.00%) (1344/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1700) | Acc: (94.00%) (2547/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1892) | Acc: (94.00%) (3736/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.2057) | Acc: (93.00%) (4899/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.2223) | Acc: (92.00%) (6052/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.2329) | Acc: (92.00%) (7209/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.2385) | Acc: (92.00%) (8371/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.2463) | Acc: (91.00%) (9530/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.2543) | Acc: (91.00%) (10679/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.2547) | Acc: (91.00%) (11845/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.2583) | Acc: (91.00%) (13001/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.2571) | Acc: (91.00%) (14176/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.2574) | Acc: (91.00%) (15345/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.2572) | Acc: (91.00%) (16515/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.2562) | Acc: (91.00%) (17689/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.2565) | Acc: (91.00%) (18861/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.2562) | Acc: (91.00%) (20023/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.2575) | Acc: (91.00%) (21179/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.2566) | Acc: (91.00%) (22345/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.2573) | Acc: (91.00%) (23515/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.2582) | Acc: (91.00%) (24678/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.2591) | Acc: (91.00%) (25835/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.2595) | Acc: (91.00%) (26989/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.2606) | Acc: (91.00%) (28144/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.2601) | Acc: (91.00%) (29318/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.2587) | Acc: (91.00%) (30496/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.2599) | Acc: (91.00%) (31656/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.2597) | Acc: (91.00%) (32830/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.2576) | Acc: (91.00%) (34032/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.2574) | Acc: (91.00%) (35202/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.2577) | Acc: (91.00%) (36364/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.2565) | Acc: (91.00%) (37551/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.2561) | Acc: (91.00%) (38721/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.2565) | Acc: (91.00%) (39882/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.2560) | Acc: (91.00%) (41056/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.2560) | Acc: (91.00%) (42212/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.2558) | Acc: (91.00%) (43392/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.2554) | Acc: (91.00%) (44574/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.2553) | Acc: (91.00%) (45696/50000)
# TEST : Loss: (0.4066) | Acc: (87.00%) (8701/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4198e-01,  3.9201e-01, -2.0085e-01],
          [-4.3398e-02,  1.6821e-02, -1.3673e-01],
          [ 6.9737e-02, -2.2938e-01,  2.5674e-01]],

         [[-1.3327e-01,  5.3253e-01,  7.4433e-02],
          [ 6.9488e-03, -4.7761e-02, -1.8154e-01],
          [ 7.7497e-02, -4.1500e-01,  5.9887e-03]],

         [[-1.5399e-01,  2.9305e-01, -1.4252e-01],
          [ 6.1852e-02, -1.4126e-01, -1.4216e-01],
          [ 1.8945e-01, -6.4635e-02,  1.9944e-01]]],


        [[[-2.0815e-01, -4.4941e-01, -2.4603e-01],
          [-7.0510e-02,  2.2910e-01,  1.9357e-01],
          [ 2.0959e-01,  2.0365e-01,  2.6117e-01]],

         [[-2.8684e-01, -3.7276e-01, -2.1792e-01],
          [-1.0946e-01,  1.6498e-01,  2.2515e-01],
          [ 2.8977e-01,  1.5119e-01,  1.6817e-01]],

         [[-1.5141e-01, -8.7348e-02, -2.3345e-01],
          [ 6.9894e-02,  2.1509e-01, -3.3096e-02],
          [ 1.3251e-02,  1.0120e-01,  6.0428e-02]]],


        [[[-8.5579e-02,  3.1151e-01,  1.1936e-01],
          [ 1.8852e-01,  2.4494e-01, -3.4606e-02],
          [-2.6782e-01, -8.1128e-02, -3.2887e-01]],

         [[ 5.3555e-02,  1.7742e-01,  2.2172e-02],
          [ 9.5169e-02,  2.8148e-01,  4.4658e-02],
          [-2.2034e-01, -1.6012e-01, -4.3538e-01]],

         [[-4.3739e-02,  1.9649e-01,  1.9843e-01],
          [ 6.1723e-02,  2.8904e-01,  1.0996e-01],
          [-2.9527e-01, -2.0488e-01, -2.6779e-01]]],


        ...,


        [[[-6.1723e-02, -9.1177e-02,  5.4246e-02],
          [ 2.6811e-02, -4.0496e-01, -1.4136e-01],
          [ 1.5121e-01, -4.4857e-02,  1.2526e-01]],

         [[ 1.4539e-01, -4.7622e-02,  1.4690e-02],
          [-7.2636e-02, -4.6273e-01, -2.3235e-01],
          [ 1.3784e-01,  1.1257e-02,  3.9811e-02]],

         [[ 2.0419e-01,  3.6852e-02,  1.2077e-01],
          [ 8.0126e-03, -2.8593e-01, -1.8684e-01],
          [ 1.2375e-01, -8.8696e-02, -7.2791e-02]]],


        [[[-1.2210e-41,  6.5968e-41, -4.3866e-41],
          [ 1.5511e-41,  8.0785e-42, -4.7829e-41],
          [ 7.1518e-41,  2.0864e-41, -2.8699e-42]],

         [[-4.9537e-41,  7.0816e-41, -3.3752e-41],
          [ 1.1289e-41, -5.8465e-41,  3.5551e-42],
          [ 4.6576e-41, -5.0714e-41, -1.4824e-41]],

         [[-7.7951e-41, -6.5889e-41,  6.9090e-41],
          [ 4.4919e-41, -5.4468e-42, -5.1465e-41],
          [ 5.6882e-41,  7.5565e-41,  5.2771e-41]]],


        [[[-1.6240e-40, -1.8480e-41,  1.0435e-40],
          [-8.7159e-41, -3.7737e-41,  9.4286e-41],
          [ 1.9521e-40, -9.2360e-41, -1.7540e-41]],

         [[ 8.8184e-41, -1.3626e-40, -1.9890e-40],
          [ 4.7734e-41,  1.3710e-40, -1.2854e-40],
          [-9.9226e-41,  2.7499e-41, -2.1277e-40]],

         [[ 1.2589e-40, -2.1652e-40,  1.0918e-41],
          [-1.2571e-40, -4.2039e-42,  9.3752e-41],
          [ 1.2651e-40,  7.9535e-41, -6.7454e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0097, -0.0246, -0.0153],
          [-0.0213, -0.0338, -0.0234],
          [-0.0157, -0.0222, -0.0050]],

         [[ 0.0038, -0.0152, -0.0072],
          [-0.0099, -0.0217, -0.0161],
          [-0.0142, -0.0129,  0.0005]],

         [[ 0.0105, -0.0007,  0.0021],
          [-0.0036, -0.0110, -0.0074],
          [-0.0068, -0.0093,  0.0019]]],


        [[[ 0.0110, -0.0053, -0.0185],
          [ 0.0057, -0.0050, -0.0151],
          [ 0.0035, -0.0012, -0.0092]],

         [[ 0.0064, -0.0035, -0.0118],
          [ 0.0032, -0.0029, -0.0078],
          [ 0.0062,  0.0016, -0.0034]],

         [[ 0.0097,  0.0056,  0.0035],
          [ 0.0084,  0.0069,  0.0072],
          [ 0.0125,  0.0104,  0.0095]]],


        [[[-0.0358, -0.0528, -0.0509],
          [-0.0371, -0.0560, -0.0599],
          [-0.0410, -0.0596, -0.0610]],

         [[-0.0284, -0.0479, -0.0437],
          [-0.0282, -0.0478, -0.0490],
          [-0.0343, -0.0495, -0.0466]],

         [[-0.0275, -0.0428, -0.0345],
          [-0.0278, -0.0419, -0.0386],
          [-0.0328, -0.0411, -0.0349]]],


        ...,


        [[[ 0.0014, -0.0017, -0.0079],
          [-0.0022, -0.0024, -0.0045],
          [-0.0015, -0.0017,  0.0002]],

         [[ 0.0039,  0.0001, -0.0103],
          [-0.0008,  0.0021, -0.0016],
          [-0.0004, -0.0005,  0.0015]],

         [[-0.0046, -0.0057, -0.0145],
          [-0.0067, -0.0032, -0.0064],
          [-0.0050, -0.0039, -0.0028]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5315]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 157 | Batch_idx: 0 |  Loss: (0.1298) | Acc: (97.00%) (125/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.2048) | Acc: (93.00%) (1312/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.2066) | Acc: (92.00%) (2498/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.2017) | Acc: (92.00%) (3690/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.2049) | Acc: (92.00%) (4874/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.2001) | Acc: (93.00%) (6073/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1978) | Acc: (93.00%) (7269/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.2013) | Acc: (93.00%) (8454/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.2018) | Acc: (92.00%) (9636/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.2049) | Acc: (92.00%) (10811/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.2068) | Acc: (92.00%) (11995/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.2089) | Acc: (92.00%) (13163/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.2089) | Acc: (92.00%) (14347/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.2098) | Acc: (92.00%) (15528/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.2074) | Acc: (92.00%) (16735/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.2057) | Acc: (92.00%) (17934/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.2073) | Acc: (92.00%) (19108/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.2058) | Acc: (92.00%) (20301/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.2061) | Acc: (92.00%) (21496/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.2062) | Acc: (92.00%) (22678/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.2053) | Acc: (92.00%) (23884/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.2071) | Acc: (92.00%) (25060/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.2080) | Acc: (92.00%) (26240/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.2072) | Acc: (92.00%) (27442/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.2066) | Acc: (92.00%) (28628/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.2062) | Acc: (92.00%) (29818/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.2055) | Acc: (92.00%) (31013/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.2049) | Acc: (92.00%) (32210/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.2049) | Acc: (92.00%) (33391/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.2049) | Acc: (92.00%) (34588/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.2045) | Acc: (92.00%) (35775/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.2039) | Acc: (92.00%) (36967/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.2048) | Acc: (92.00%) (38147/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.2044) | Acc: (92.00%) (39347/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.2036) | Acc: (92.00%) (40546/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.2027) | Acc: (92.00%) (41745/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.2033) | Acc: (92.00%) (42936/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.2039) | Acc: (92.00%) (44118/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.2033) | Acc: (92.00%) (45324/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.2037) | Acc: (92.00%) (46463/50000)
# TEST : Loss: (0.3459) | Acc: (89.00%) (8931/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3653e-01,  3.9666e-01, -2.0543e-01],
          [-3.8343e-02,  2.4796e-02, -1.3874e-01],
          [ 6.9853e-02, -2.2386e-01,  2.5951e-01]],

         [[-1.3738e-01,  5.3018e-01,  6.4302e-02],
          [ 3.1147e-03, -5.4035e-02, -1.8920e-01],
          [ 7.3129e-02, -4.2547e-01, -1.7858e-03]],

         [[-1.5298e-01,  2.9119e-01, -1.5246e-01],
          [ 5.6062e-02, -1.4587e-01, -1.5192e-01],
          [ 1.8168e-01, -7.4327e-02,  1.8968e-01]]],


        [[[-2.0921e-01, -4.5305e-01, -2.5432e-01],
          [-6.8513e-02,  2.2733e-01,  1.8565e-01],
          [ 2.0917e-01,  2.0288e-01,  2.6010e-01]],

         [[-2.8448e-01, -3.7277e-01, -2.2316e-01],
          [-1.0400e-01,  1.6669e-01,  2.1931e-01],
          [ 2.9302e-01,  1.5390e-01,  1.7035e-01]],

         [[-1.4414e-01, -8.5833e-02, -2.3817e-01],
          [ 7.5414e-02,  2.1643e-01, -3.7984e-02],
          [ 1.7946e-02,  1.0428e-01,  6.3868e-02]]],


        [[[-8.3602e-02,  3.0820e-01,  1.1507e-01],
          [ 1.8645e-01,  2.4005e-01, -4.1222e-02],
          [-2.7089e-01, -8.7727e-02, -3.3584e-01]],

         [[ 5.6205e-02,  1.7909e-01,  2.0952e-02],
          [ 9.5434e-02,  2.8105e-01,  4.2029e-02],
          [-2.2214e-01, -1.6447e-01, -4.3854e-01]],

         [[-3.5446e-02,  2.0592e-01,  2.0862e-01],
          [ 6.9949e-02,  2.9741e-01,  1.1854e-01],
          [-2.8593e-01, -1.9756e-01, -2.5783e-01]]],


        ...,


        [[[-7.9216e-02, -1.0480e-01,  4.5261e-02],
          [ 4.7688e-03, -4.2093e-01, -1.4083e-01],
          [ 1.3776e-01, -5.0237e-02,  1.2641e-01]],

         [[ 1.3736e-01, -5.6367e-02,  1.0305e-02],
          [-8.3468e-02, -4.7099e-01, -2.2334e-01],
          [ 1.3537e-01,  1.3784e-02,  4.6112e-02]],

         [[ 2.0062e-01,  2.8828e-02,  1.1608e-01],
          [-7.6850e-04, -2.9444e-01, -1.8144e-01],
          [ 1.1679e-01, -9.4586e-02, -7.1330e-02]]],


        [[[ 7.2367e-41,  4.0293e-41,  4.5195e-41],
          [ 3.3289e-41,  1.0419e-41,  3.6044e-41],
          [-7.9798e-41,  6.6747e-41, -4.1058e-42]],

         [[-4.8851e-41, -3.2767e-41, -1.8018e-41],
          [-2.8159e-41,  3.8027e-41,  1.2836e-41],
          [ 4.8154e-41, -1.8695e-41,  6.0907e-41]],

         [[-6.4334e-41,  1.0920e-41, -5.7551e-42],
          [-5.8965e-41, -7.7010e-41,  8.0810e-41],
          [ 2.7383e-41, -7.7764e-41, -8.3424e-41]]],


        [[[-9.5311e-41, -2.1335e-41, -1.2429e-40],
          [ 2.3996e-41,  7.8780e-41,  1.1153e-40],
          [ 2.0906e-40, -8.7831e-41, -1.5652e-40]],

         [[ 2.5836e-41, -1.3653e-40, -1.8381e-40],
          [ 5.5882e-41,  1.6490e-40,  1.7915e-40],
          [ 3.3515e-41,  3.2516e-41,  1.9711e-40]],

         [[-2.4925e-40, -1.8467e-40, -1.1647e-40],
          [-1.1794e-40, -1.5504e-40,  1.1126e-40],
          [-1.2872e-40,  4.3795e-41,  1.3144e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0186, -0.0011,  0.0024],
          [-0.0480, -0.0163, -0.0035],
          [-0.0344, -0.0103, -0.0057]],

         [[ 0.0164,  0.0274,  0.0250],
          [-0.0123,  0.0173,  0.0172],
          [-0.0076,  0.0202,  0.0194]],

         [[ 0.0512,  0.0543,  0.0514],
          [ 0.0297,  0.0496,  0.0527],
          [ 0.0240,  0.0514,  0.0543]]],


        [[[ 0.0348,  0.0247,  0.0300],
          [ 0.0384,  0.0175,  0.0183],
          [ 0.0186,  0.0107,  0.0226]],

         [[-0.0188, -0.0259, -0.0159],
          [-0.0050, -0.0213, -0.0176],
          [-0.0144, -0.0202, -0.0109]],

         [[-0.0766, -0.0822, -0.0747],
          [-0.0587, -0.0733, -0.0700],
          [-0.0592, -0.0657, -0.0592]]],


        [[[ 0.0418,  0.0350,  0.0363],
          [ 0.0253,  0.0336,  0.0416],
          [ 0.0280,  0.0431,  0.0451]],

         [[ 0.0471,  0.0389,  0.0419],
          [ 0.0281,  0.0345,  0.0451],
          [ 0.0204,  0.0385,  0.0474]],

         [[ 0.0587,  0.0525,  0.0509],
          [ 0.0403,  0.0455,  0.0548],
          [ 0.0286,  0.0438,  0.0569]]],


        ...,


        [[[-0.0152, -0.0106,  0.0070],
          [-0.0107, -0.0117, -0.0061],
          [-0.0076, -0.0140, -0.0158]],

         [[-0.0018,  0.0032,  0.0181],
          [ 0.0006,  0.0026,  0.0085],
          [ 0.0038, -0.0001,  0.0001]],

         [[-0.0017,  0.0058,  0.0190],
          [ 0.0015,  0.0084,  0.0135],
          [ 0.0038,  0.0046,  0.0043]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5302]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 158 | Batch_idx: 0 |  Loss: (0.1452) | Acc: (96.00%) (123/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.1719) | Acc: (93.00%) (1321/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.1839) | Acc: (93.00%) (2512/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.1798) | Acc: (93.00%) (3715/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.1722) | Acc: (93.00%) (4932/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.1787) | Acc: (93.00%) (6120/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.1812) | Acc: (93.00%) (7313/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.1818) | Acc: (93.00%) (8505/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.1859) | Acc: (93.00%) (9682/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1873) | Acc: (93.00%) (10875/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1861) | Acc: (93.00%) (12080/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1853) | Acc: (93.00%) (13281/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1848) | Acc: (93.00%) (14477/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1843) | Acc: (93.00%) (15677/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1816) | Acc: (93.00%) (16892/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1808) | Acc: (93.00%) (18091/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1828) | Acc: (93.00%) (19279/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1831) | Acc: (93.00%) (20478/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1839) | Acc: (93.00%) (21668/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1833) | Acc: (93.00%) (22869/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1851) | Acc: (93.00%) (24050/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1859) | Acc: (93.00%) (25254/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1868) | Acc: (93.00%) (26447/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1867) | Acc: (93.00%) (27648/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1878) | Acc: (93.00%) (28826/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1878) | Acc: (93.00%) (30026/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1871) | Acc: (93.00%) (31234/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1868) | Acc: (93.00%) (32425/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1866) | Acc: (93.00%) (33620/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1853) | Acc: (93.00%) (34832/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1849) | Acc: (93.00%) (36028/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1842) | Acc: (93.00%) (37235/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1841) | Acc: (93.00%) (38437/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1835) | Acc: (93.00%) (39648/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1834) | Acc: (93.00%) (40847/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1830) | Acc: (93.00%) (42052/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1836) | Acc: (93.00%) (43246/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1836) | Acc: (93.00%) (44437/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1838) | Acc: (93.00%) (45633/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1849) | Acc: (93.00%) (46776/50000)
# TEST : Loss: (0.3404) | Acc: (89.00%) (8981/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4060e-01,  3.9721e-01, -1.9729e-01],
          [-3.9628e-02,  2.6839e-02, -1.2809e-01],
          [ 6.2513e-02, -2.2588e-01,  2.7049e-01]],

         [[-1.4263e-01,  5.3318e-01,  7.2879e-02],
          [-3.1888e-06, -5.4786e-02, -1.8123e-01],
          [ 6.2869e-02, -4.2939e-01,  3.5372e-03]],

         [[-1.5753e-01,  2.9052e-01, -1.4906e-01],
          [ 5.4461e-02, -1.4357e-01, -1.4464e-01],
          [ 1.8099e-01, -7.0603e-02,  1.9536e-01]]],


        [[[-2.0738e-01, -4.5223e-01, -2.5398e-01],
          [-6.5685e-02,  2.3141e-01,  1.9011e-01],
          [ 2.1008e-01,  2.0601e-01,  2.6256e-01]],

         [[-2.8219e-01, -3.7230e-01, -2.2451e-01],
          [-1.0353e-01,  1.6983e-01,  2.2328e-01],
          [ 2.9219e-01,  1.5758e-01,  1.7487e-01]],

         [[-1.4253e-01, -8.5242e-02, -2.3814e-01],
          [ 7.1542e-02,  2.1602e-01, -3.7249e-02],
          [ 6.8682e-03,  9.9373e-02,  6.2849e-02]]],


        [[[-8.0950e-02,  3.0801e-01,  1.1818e-01],
          [ 1.8812e-01,  2.3850e-01, -3.8893e-02],
          [-2.6930e-01, -9.1868e-02, -3.3683e-01]],

         [[ 5.1139e-02,  1.7151e-01,  1.7465e-02],
          [ 9.0362e-02,  2.7382e-01,  3.9451e-02],
          [-2.2822e-01, -1.7580e-01, -4.4745e-01]],

         [[-4.4587e-02,  1.9390e-01,  1.9853e-01],
          [ 5.7788e-02,  2.8420e-01,  1.0952e-01],
          [-2.9972e-01, -2.1325e-01, -2.7347e-01]]],


        ...,


        [[[-7.9336e-02, -1.2052e-01,  1.3435e-02],
          [ 1.5742e-02, -4.3077e-01, -1.6886e-01],
          [ 1.4424e-01, -6.3857e-02,  9.6777e-02]],

         [[ 1.4115e-01, -5.4702e-02,  3.3235e-03],
          [-7.1775e-02, -4.6117e-01, -2.2058e-01],
          [ 1.4262e-01,  1.3445e-02,  4.0453e-02]],

         [[ 1.9139e-01,  2.0223e-02,  1.0339e-01],
          [-3.9656e-03, -3.0093e-01, -1.8912e-01],
          [ 1.1460e-01, -1.0342e-01, -8.3317e-02]]],


        [[[-4.1054e-41, -4.0492e-41,  2.3505e-41],
          [-6.8236e-41, -4.4550e-41,  7.6308e-41],
          [ 7.7846e-41,  8.5964e-41,  1.4192e-41]],

         [[ 2.5991e-41, -2.8054e-42,  5.8870e-41],
          [-2.3873e-41, -5.3055e-41, -1.4887e-41],
          [ 4.8425e-41, -1.3810e-41,  5.2124e-41]],

         [[ 3.6910e-41,  1.2836e-41, -4.9696e-41],
          [ 4.2265e-41, -2.0451e-41, -6.3706e-41],
          [ 2.2915e-41,  6.0409e-41,  8.3499e-41]]],


        [[[-1.7792e-40, -9.6584e-41,  7.2367e-41],
          [ 7.8652e-41, -1.6740e-40,  1.2961e-40],
          [-1.6364e-40, -5.4038e-41, -2.6485e-42]],

         [[-1.5607e-40, -1.8830e-40,  2.5903e-40],
          [ 6.5010e-41,  1.0252e-40,  1.5421e-40],
          [ 3.9346e-41,  2.0391e-40, -1.6291e-40]],

         [[ 1.1094e-40, -1.3141e-40, -1.8672e-40],
          [-7.2523e-41, -1.8018e-40,  1.0444e-40],
          [ 1.1057e-40, -6.2035e-42, -9.8047e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0259, -0.0119, -0.0081],
          [-0.0048,  0.0067,  0.0121],
          [-0.0050,  0.0136,  0.0230]],

         [[-0.0544, -0.0357, -0.0459],
          [-0.0369, -0.0206, -0.0265],
          [-0.0289, -0.0093, -0.0109]],

         [[-0.0419, -0.0226, -0.0424],
          [-0.0227, -0.0135, -0.0229],
          [-0.0225, -0.0074, -0.0131]]],


        [[[ 0.0432,  0.0303,  0.0056],
          [ 0.0368,  0.0245, -0.0032],
          [ 0.0580,  0.0403,  0.0069]],

         [[ 0.0917,  0.0806,  0.0636],
          [ 0.0869,  0.0785,  0.0571],
          [ 0.1034,  0.0859,  0.0533]],

         [[ 0.1504,  0.1316,  0.1124],
          [ 0.1483,  0.1340,  0.1095],
          [ 0.1634,  0.1424,  0.1052]]],


        [[[ 0.0636,  0.0602,  0.0377],
          [ 0.0895,  0.0770,  0.0539],
          [ 0.0832,  0.0657,  0.0589]],

         [[-0.0055, -0.0096, -0.0294],
          [ 0.0192,  0.0051, -0.0185],
          [ 0.0129, -0.0044, -0.0117]],

         [[-0.0740, -0.0691, -0.0844],
          [-0.0566, -0.0590, -0.0749],
          [-0.0570, -0.0642, -0.0672]]],


        ...,


        [[[ 0.0307,  0.0350,  0.0322],
          [ 0.0313,  0.0245,  0.0197],
          [ 0.0371,  0.0288,  0.0269]],

         [[-0.0225, -0.0105, -0.0075],
          [-0.0170, -0.0167, -0.0149],
          [-0.0172, -0.0199, -0.0168]],

         [[-0.0324, -0.0252, -0.0199],
          [-0.0262, -0.0285, -0.0247],
          [-0.0297, -0.0333, -0.0296]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5287]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 159 | Batch_idx: 0 |  Loss: (0.1717) | Acc: (96.00%) (123/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1942) | Acc: (93.00%) (1315/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.1899) | Acc: (93.00%) (2515/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.2078) | Acc: (92.00%) (3690/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.2093) | Acc: (93.00%) (4881/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.2100) | Acc: (93.00%) (6074/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.2147) | Acc: (92.00%) (7244/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.2157) | Acc: (92.00%) (8431/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.2146) | Acc: (92.00%) (9617/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.2128) | Acc: (92.00%) (10816/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.2118) | Acc: (92.00%) (12003/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.2081) | Acc: (92.00%) (13208/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.2070) | Acc: (92.00%) (14401/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.2077) | Acc: (92.00%) (15578/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.2045) | Acc: (93.00%) (16789/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.2046) | Acc: (93.00%) (17976/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.2033) | Acc: (93.00%) (19179/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.2017) | Acc: (93.00%) (20383/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.2001) | Acc: (93.00%) (21590/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1986) | Acc: (93.00%) (22800/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1974) | Acc: (93.00%) (24007/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1964) | Acc: (93.00%) (25211/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1946) | Acc: (93.00%) (26418/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1938) | Acc: (93.00%) (27627/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1922) | Acc: (93.00%) (28842/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1914) | Acc: (93.00%) (30053/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1915) | Acc: (93.00%) (31252/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1895) | Acc: (93.00%) (32471/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1885) | Acc: (93.00%) (33683/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1878) | Acc: (93.00%) (34890/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1865) | Acc: (93.00%) (36112/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1857) | Acc: (93.00%) (37325/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1854) | Acc: (93.00%) (38529/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1836) | Acc: (93.00%) (39757/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1843) | Acc: (93.00%) (40945/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1837) | Acc: (93.00%) (42147/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1838) | Acc: (93.00%) (43345/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1841) | Acc: (93.00%) (44539/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1836) | Acc: (93.00%) (45747/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1833) | Acc: (93.00%) (46902/50000)
# TEST : Loss: (0.3059) | Acc: (90.00%) (9067/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3691e-01,  3.9889e-01, -1.9432e-01],
          [-3.8372e-02,  2.7737e-02, -1.2640e-01],
          [ 6.2954e-02, -2.2481e-01,  2.6994e-01]],

         [[-1.3698e-01,  5.3561e-01,  7.6957e-02],
          [ 3.2748e-03, -5.2119e-02, -1.7726e-01],
          [ 6.4884e-02, -4.2668e-01,  5.1865e-03]],

         [[-1.5315e-01,  2.9198e-01, -1.4605e-01],
          [ 5.5824e-02, -1.4194e-01, -1.4240e-01],
          [ 1.8164e-01, -7.0108e-02,  1.9544e-01]]],


        [[[-2.1015e-01, -4.5357e-01, -2.5481e-01],
          [-6.8122e-02,  2.2890e-01,  1.8874e-01],
          [ 2.0636e-01,  2.0256e-01,  2.6002e-01]],

         [[-2.8651e-01, -3.7519e-01, -2.2696e-01],
          [-1.0738e-01,  1.6604e-01,  2.2039e-01],
          [ 2.8719e-01,  1.5342e-01,  1.7205e-01]],

         [[-1.4943e-01, -9.0620e-02, -2.4231e-01],
          [ 6.4741e-02,  2.0982e-01, -4.1733e-02],
          [-3.7913e-04,  9.2692e-02,  5.7928e-02]]],


        [[[-8.1320e-02,  3.0662e-01,  1.1784e-01],
          [ 1.8728e-01,  2.3666e-01, -3.9859e-02],
          [-2.6913e-01, -9.2535e-02, -3.3748e-01]],

         [[ 5.0989e-02,  1.7074e-01,  1.7698e-02],
          [ 9.0247e-02,  2.7247e-01,  3.9113e-02],
          [-2.2773e-01, -1.7601e-01, -4.4736e-01]],

         [[-4.1683e-02,  1.9535e-01,  2.0019e-01],
          [ 6.0529e-02,  2.8512e-01,  1.1078e-01],
          [-2.9665e-01, -2.1137e-01, -2.7199e-01]]],


        ...,


        [[[-8.0827e-02, -1.2282e-01,  1.0530e-02],
          [ 1.1905e-02, -4.3318e-01, -1.7243e-01],
          [ 1.3972e-01, -6.7521e-02,  9.2750e-02]],

         [[ 1.4389e-01, -5.0666e-02,  5.8508e-03],
          [-6.9393e-02, -4.5189e-01, -2.1587e-01],
          [ 1.4336e-01,  1.6180e-02,  4.2591e-02]],

         [[ 1.9508e-01,  2.5035e-02,  1.0720e-01],
          [-6.2421e-04, -2.9387e-01, -1.8316e-01],
          [ 1.1701e-01, -9.8639e-02, -7.8674e-02]]],


        [[[-5.0200e-41, -8.3779e-41, -5.8349e-41],
          [ 7.1113e-41,  7.1937e-41, -2.2117e-41],
          [-8.6712e-41,  9.2057e-41, -5.0985e-41]],

         [[ 3.0974e-41,  1.8049e-41, -4.3159e-41],
          [ 3.2137e-41, -2.4296e-41, -8.5570e-41],
          [-2.7845e-41, -7.6350e-41, -8.4737e-41]],

         [[ 4.4264e-41,  4.2557e-41, -1.7819e-41],
          [-5.6778e-41, -1.0475e-41, -4.9942e-41],
          [ 7.9686e-41,  4.6321e-41, -3.8732e-41]]],


        [[[ 6.1475e-42,  1.0623e-40, -2.9078e-41],
          [-1.1254e-40,  1.9655e-40,  9.6444e-41],
          [ 2.5680e-40, -5.5197e-42,  7.8014e-41]],

         [[-1.4695e-40, -2.1864e-40, -1.4601e-40],
          [-1.3228e-42, -1.2359e-40, -1.7821e-40],
          [ 1.4700e-40, -5.1594e-41,  2.0891e-40]],

         [[-1.2763e-41, -2.3619e-41, -6.6873e-41],
          [-5.0657e-42, -9.5583e-42,  1.5250e-40],
          [-1.3008e-40, -8.6881e-42, -1.4013e-41]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5449]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0376]], device='cuda:0')

Epoch: 160 | Batch_idx: 0 |  Loss: (0.2775) | Acc: (89.00%) (115/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.1559) | Acc: (95.00%) (1348/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.1709) | Acc: (94.00%) (2549/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1696) | Acc: (94.00%) (3748/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1705) | Acc: (94.00%) (4958/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.1633) | Acc: (94.00%) (6186/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.1626) | Acc: (94.00%) (7397/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.1668) | Acc: (94.00%) (8602/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.1637) | Acc: (94.00%) (9820/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.1631) | Acc: (94.00%) (11037/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.1618) | Acc: (94.00%) (12255/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.1596) | Acc: (94.00%) (13479/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.1596) | Acc: (94.00%) (14696/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.1583) | Acc: (94.00%) (15922/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.1583) | Acc: (94.00%) (17138/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.1599) | Acc: (94.00%) (18343/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.1589) | Acc: (94.00%) (19563/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.1582) | Acc: (94.00%) (20779/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.1572) | Acc: (94.00%) (22002/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.1574) | Acc: (94.00%) (23211/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.1577) | Acc: (94.00%) (24416/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.1568) | Acc: (94.00%) (25634/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.1580) | Acc: (94.00%) (26839/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.1588) | Acc: (94.00%) (28044/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.1597) | Acc: (94.00%) (29246/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.1589) | Acc: (94.00%) (30462/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.1580) | Acc: (94.00%) (31676/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.1587) | Acc: (94.00%) (32881/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.1595) | Acc: (94.00%) (34084/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.1607) | Acc: (94.00%) (35273/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.1609) | Acc: (94.00%) (36473/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.1608) | Acc: (94.00%) (37685/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.1607) | Acc: (94.00%) (38899/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.1604) | Acc: (94.00%) (40127/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.1601) | Acc: (94.00%) (41340/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.1602) | Acc: (94.00%) (42549/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.1600) | Acc: (94.00%) (43764/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.1600) | Acc: (94.00%) (44971/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.1600) | Acc: (94.00%) (46177/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.1601) | Acc: (94.00%) (47339/50000)
# TEST : Loss: (0.2955) | Acc: (90.00%) (9067/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3645e-01,  3.9748e-01, -1.9366e-01],
          [-3.8246e-02,  2.7644e-02, -1.2597e-01],
          [ 6.2746e-02, -2.2402e-01,  2.6903e-01]],

         [[-1.3650e-01,  5.3361e-01,  7.6685e-02],
          [ 3.2634e-03, -5.1931e-02, -1.7662e-01],
          [ 6.4656e-02, -4.2508e-01,  5.1681e-03]],

         [[-1.5259e-01,  2.9086e-01, -1.4551e-01],
          [ 5.5621e-02, -1.4141e-01, -1.4188e-01],
          [ 1.8098e-01, -6.9839e-02,  1.9473e-01]]],


        [[[-2.0967e-01, -4.5252e-01, -2.5422e-01],
          [-6.7965e-02,  2.2837e-01,  1.8830e-01],
          [ 2.0587e-01,  2.0207e-01,  2.5939e-01]],

         [[-2.8581e-01, -3.7428e-01, -2.2641e-01],
          [-1.0712e-01,  1.6564e-01,  2.1986e-01],
          [ 2.8647e-01,  1.5304e-01,  1.7161e-01]],

         [[-1.4905e-01, -9.0392e-02, -2.4170e-01],
          [ 6.4579e-02,  2.0929e-01, -4.1628e-02],
          [-3.7817e-04,  9.2455e-02,  5.7778e-02]]],


        [[[-8.1146e-02,  3.0596e-01,  1.1759e-01],
          [ 1.8690e-01,  2.3617e-01, -3.9776e-02],
          [-2.6857e-01, -9.2342e-02, -3.3676e-01]],

         [[ 5.0875e-02,  1.7036e-01,  1.7660e-02],
          [ 9.0050e-02,  2.7188e-01,  3.9029e-02],
          [-2.2723e-01, -1.7562e-01, -4.4636e-01]],

         [[-4.1585e-02,  1.9489e-01,  1.9973e-01],
          [ 6.0389e-02,  2.8446e-01,  1.1052e-01],
          [-2.9595e-01, -2.1087e-01, -2.7135e-01]]],


        ...,


        [[[-8.0456e-02, -1.2208e-01,  1.0475e-02],
          [ 1.1841e-02, -4.2908e-01, -1.7110e-01],
          [ 1.3910e-01, -6.7136e-02,  9.2258e-02]],

         [[ 1.4319e-01, -5.0332e-02,  5.8169e-03],
          [-6.8990e-02, -4.4662e-01, -2.1388e-01],
          [ 1.4270e-01,  1.6081e-02,  4.2348e-02]],

         [[ 1.9415e-01,  2.4885e-02,  1.0660e-01],
          [-6.2075e-04, -2.9149e-01, -1.8177e-01],
          [ 1.1645e-01, -9.8052e-02, -7.8218e-02]]],


        [[[ 2.0829e-41, -8.6588e-41, -8.5572e-41],
          [-2.0111e-41,  8.3910e-41, -2.6358e-41],
          [ 2.2803e-41,  4.5389e-41,  6.1277e-41]],

         [[ 1.8770e-41,  4.9096e-41, -7.2304e-41],
          [ 8.6739e-41, -6.1151e-41, -6.3030e-42],
          [-6.3157e-41,  3.1106e-41,  1.0023e-40]],

         [[-3.7768e-41, -8.9030e-41, -9.8371e-42],
          [-3.3158e-41, -6.3576e-41, -7.6996e-41],
          [ 4.7899e-41,  3.9419e-41, -4.7162e-41]]],


        [[[ 1.0073e-40, -9.9028e-41, -3.3951e-41],
          [ 1.3956e-40,  3.2265e-41, -1.4422e-40],
          [-2.2432e-40, -7.3886e-41,  1.5437e-40]],

         [[-8.6405e-41, -2.1173e-40,  2.7061e-40],
          [-8.9407e-41,  1.7250e-40, -1.3040e-40],
          [-6.4624e-41, -5.9562e-41, -8.0580e-41]],

         [[-3.0329e-40, -1.7428e-40,  2.6713e-41],
          [-9.4700e-41,  1.8086e-40, -8.0835e-41],
          [ 2.4580e-41,  2.9245e-41, -1.2973e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5694]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0005]], device='cuda:0')

Epoch: 161 | Batch_idx: 0 |  Loss: (0.1733) | Acc: (90.00%) (116/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.1641) | Acc: (94.00%) (1329/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.1729) | Acc: (94.00%) (2535/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.1699) | Acc: (94.00%) (3739/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.1696) | Acc: (94.00%) (4944/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1653) | Acc: (94.00%) (6158/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1638) | Acc: (94.00%) (7376/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1595) | Acc: (94.00%) (8606/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1554) | Acc: (94.00%) (9842/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1576) | Acc: (94.00%) (11049/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1590) | Acc: (94.00%) (12259/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1578) | Acc: (94.00%) (13475/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1571) | Acc: (94.00%) (14698/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1562) | Acc: (94.00%) (15914/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1566) | Acc: (94.00%) (17121/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1563) | Acc: (94.00%) (18340/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1569) | Acc: (94.00%) (19541/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1563) | Acc: (94.00%) (20758/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1565) | Acc: (94.00%) (21970/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1562) | Acc: (94.00%) (23188/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1563) | Acc: (94.00%) (24400/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1565) | Acc: (94.00%) (25610/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1569) | Acc: (94.00%) (26819/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1565) | Acc: (94.00%) (28035/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1566) | Acc: (94.00%) (29248/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1561) | Acc: (94.00%) (30461/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1559) | Acc: (94.00%) (31683/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1556) | Acc: (94.00%) (32901/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1557) | Acc: (94.00%) (34113/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1561) | Acc: (94.00%) (35312/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1553) | Acc: (94.00%) (36535/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1554) | Acc: (94.00%) (37744/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1558) | Acc: (94.00%) (38950/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1550) | Acc: (94.00%) (40176/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1555) | Acc: (94.00%) (41380/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1556) | Acc: (94.00%) (42597/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1556) | Acc: (94.00%) (43806/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1553) | Acc: (94.00%) (45015/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1562) | Acc: (94.00%) (46218/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1567) | Acc: (94.00%) (47376/50000)
# TEST : Loss: (0.2931) | Acc: (90.00%) (9081/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3590e-01,  3.9578e-01, -1.9287e-01],
          [-3.8094e-02,  2.7530e-02, -1.2545e-01],
          [ 6.2495e-02, -2.2307e-01,  2.6793e-01]],

         [[-1.3592e-01,  5.3118e-01,  7.6354e-02],
          [ 3.2496e-03, -5.1702e-02, -1.7585e-01],
          [ 6.4380e-02, -4.2314e-01,  5.1457e-03]],

         [[-1.5191e-01,  2.8951e-01, -1.4487e-01],
          [ 5.5374e-02, -1.4076e-01, -1.4124e-01],
          [ 1.8018e-01, -6.9512e-02,  1.9387e-01]]],


        [[[-2.0907e-01, -4.5124e-01, -2.5350e-01],
          [-6.7775e-02,  2.2773e-01,  1.8777e-01],
          [ 2.0527e-01,  2.0148e-01,  2.5862e-01]],

         [[-2.8497e-01, -3.7317e-01, -2.2575e-01],
          [-1.0681e-01,  1.6516e-01,  2.1922e-01],
          [ 2.8560e-01,  1.5257e-01,  1.7109e-01]],

         [[-1.4859e-01, -9.0114e-02, -2.4096e-01],
          [ 6.4383e-02,  2.0865e-01, -4.1501e-02],
          [-3.7700e-04,  9.2168e-02,  5.7596e-02]]],


        [[[-8.0935e-02,  3.0516e-01,  1.1729e-01],
          [ 1.8643e-01,  2.3558e-01, -3.9675e-02],
          [-2.6789e-01, -9.2107e-02, -3.3590e-01]],

         [[ 5.0738e-02,  1.6989e-01,  1.7612e-02],
          [ 8.9810e-02,  2.7116e-01,  3.8927e-02],
          [-2.2661e-01, -1.7515e-01, -4.4516e-01]],

         [[-4.1467e-02,  1.9434e-01,  1.9917e-01],
          [ 6.0219e-02,  2.8366e-01,  1.1022e-01],
          [-2.9510e-01, -2.1027e-01, -2.7058e-01]]],


        ...,


        [[[-8.0008e-02, -1.2118e-01,  1.0407e-02],
          [ 1.1763e-02, -4.2414e-01, -1.6950e-01],
          [ 1.3835e-01, -6.6671e-02,  9.1664e-02]],

         [[ 1.4236e-01, -4.9929e-02,  5.7760e-03],
          [-6.8503e-02, -4.4030e-01, -2.1149e-01],
          [ 1.4190e-01,  1.5962e-02,  4.2055e-02]],

         [[ 1.9302e-01,  2.4703e-02,  1.0588e-01],
          [-6.1656e-04, -2.8863e-01, -1.8009e-01],
          [ 1.1579e-01, -9.7342e-02, -7.7668e-02]]],


        [[[ 7.4758e-41, -5.7676e-41, -8.9436e-41],
          [ 7.2024e-41,  8.4888e-41,  3.0169e-41],
          [ 9.7146e-41,  1.9540e-41, -8.2639e-41]],

         [[-1.2238e-41, -2.1396e-41, -6.3248e-41],
          [-7.8890e-41,  3.4934e-42,  8.6799e-41],
          [ 6.7779e-41, -8.8394e-42, -8.1432e-41]],

         [[ 6.5055e-41, -9.8447e-41,  1.6450e-41],
          [ 4.5569e-41,  6.0032e-42, -8.8004e-41],
          [-8.0360e-41,  9.1987e-41, -7.6763e-41]]],


        [[[-1.7556e-40,  3.3655e-41,  1.1481e-40],
          [-1.1346e-40,  1.5017e-40,  9.7787e-41],
          [ 1.7930e-40, -9.0398e-42, -3.0885e-42]],

         [[ 4.0859e-41,  1.2578e-40, -2.3579e-40],
          [-1.5174e-40, -1.2246e-40,  1.9768e-40],
          [ 1.3772e-41, -1.1223e-40,  1.5455e-40]],

         [[ 3.1924e-40, -1.9731e-40, -1.7276e-40],
          [-1.5797e-40,  2.0674e-40, -1.3357e-40],
          [ 1.2445e-40, -9.9604e-42,  1.1122e-40]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5416]], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([[0.0018]], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1, out_features=1, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 162 | Batch_idx: 0 |  Loss: (0.0925) | Acc: (97.00%) (125/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.1644) | Acc: (93.00%) (1323/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.1856) | Acc: (93.00%) (2509/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.2030) | Acc: (92.00%) (3682/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.2140) | Acc: (92.00%) (4853/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.2246) | Acc: (92.00%) (6018/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.2376) | Acc: (91.00%) (7165/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.2423) | Acc: (91.00%) (8329/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.2401) | Acc: (91.00%) (9511/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.2457) | Acc: (91.00%) (10659/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.2477) | Acc: (91.00%) (11824/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.2488) | Acc: (91.00%) (12984/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.2489) | Acc: (91.00%) (14157/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.2539) | Acc: (91.00%) (15308/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.2562) | Acc: (91.00%) (16450/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.2589) | Acc: (91.00%) (17609/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.2584) | Acc: (91.00%) (18779/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.2587) | Acc: (91.00%) (19942/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.2568) | Acc: (91.00%) (21133/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.2568) | Acc: (91.00%) (22300/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.2561) | Acc: (91.00%) (23478/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.2572) | Acc: (91.00%) (24634/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.2561) | Acc: (91.00%) (25813/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.2569) | Acc: (91.00%) (26974/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.2577) | Acc: (91.00%) (28131/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.2572) | Acc: (91.00%) (29302/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.2579) | Acc: (91.00%) (30458/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.2575) | Acc: (91.00%) (31623/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.2577) | Acc: (91.00%) (32785/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.2571) | Acc: (91.00%) (33957/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.2571) | Acc: (91.00%) (35117/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.2567) | Acc: (91.00%) (36285/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.2562) | Acc: (91.00%) (37454/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.2568) | Acc: (91.00%) (38615/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.2554) | Acc: (91.00%) (39812/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.2553) | Acc: (91.00%) (40977/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.2554) | Acc: (91.00%) (42158/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.2550) | Acc: (91.00%) (43340/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.2550) | Acc: (91.00%) (44504/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.2537) | Acc: (91.00%) (45647/50000)
# TEST : Loss: (0.3697) | Acc: (88.00%) (8846/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.3432e-01,  4.1345e-01, -1.8835e-01],
          [-4.1528e-02,  3.4676e-02, -1.2315e-01],
          [ 7.1030e-02, -2.0994e-01,  2.6974e-01]],

         [[-1.4854e-01,  5.3795e-01,  7.7884e-02],
          [-1.1672e-02, -5.4358e-02, -1.7373e-01],
          [ 7.1660e-02, -4.1647e-01,  7.2383e-03]],

         [[-1.6999e-01,  2.8022e-01, -1.4994e-01],
          [ 3.7724e-02, -1.5537e-01, -1.4560e-01],
          [ 1.7727e-01, -7.0878e-02,  1.9045e-01]]],


        [[[-2.1501e-01, -4.5653e-01, -2.5795e-01],
          [-6.5487e-02,  2.2961e-01,  1.9069e-01],
          [ 2.0787e-01,  2.0499e-01,  2.6147e-01]],

         [[-2.9238e-01, -3.8096e-01, -2.3257e-01],
          [-1.1037e-01,  1.6141e-01,  2.1605e-01],
          [ 2.8266e-01,  1.4950e-01,  1.6511e-01]],

         [[-1.4951e-01, -8.9025e-02, -2.3669e-01],
          [ 6.8965e-02,  2.1572e-01, -3.2967e-02],
          [ 4.9251e-03,  9.9736e-02,  6.3089e-02]]],


        [[[-7.8604e-02,  3.1268e-01,  1.1124e-01],
          [ 1.9847e-01,  2.4732e-01, -3.7448e-02],
          [-2.6109e-01, -8.5974e-02, -3.3491e-01]],

         [[ 4.8352e-02,  1.7575e-01,  5.0346e-03],
          [ 9.5646e-02,  2.7865e-01,  3.5856e-02],
          [-2.2521e-01, -1.7206e-01, -4.4820e-01]],

         [[-5.0839e-02,  1.9434e-01,  1.7961e-01],
          [ 5.8524e-02,  2.8210e-01,  9.6777e-02],
          [-3.0076e-01, -2.1527e-01, -2.8374e-01]]],


        ...,


        [[[-6.7253e-02, -1.0714e-01,  1.2590e-02],
          [ 2.9303e-02, -4.1024e-01, -1.5803e-01],
          [ 1.4811e-01, -4.9662e-02,  1.0975e-01]],

         [[ 1.4091e-01, -6.0180e-02, -8.5932e-03],
          [-6.7410e-02, -4.6561e-01, -2.3228e-01],
          [ 1.3899e-01,  9.8813e-03,  3.3373e-02]],

         [[ 2.0587e-01,  3.0674e-02,  1.0409e-01],
          [ 1.2185e-02, -2.8775e-01, -1.8545e-01],
          [ 1.1861e-01, -9.2617e-02, -7.9676e-02]]],


        [[[-4.6030e-41,  8.2818e-41, -8.2431e-41],
          [-4.0918e-43,  6.6377e-41,  5.5403e-41],
          [ 1.0325e-40, -3.9971e-41, -7.5013e-41]],

         [[ 6.9332e-41, -7.9301e-41,  3.9368e-41],
          [ 5.6095e-41, -6.5907e-41,  1.0486e-40],
          [-5.4118e-42, -7.8819e-41,  4.0806e-42]],

         [[ 9.5242e-41, -9.4764e-41,  3.7361e-41],
          [ 7.2642e-41,  1.0063e-40, -8.1507e-41],
          [ 7.0534e-41,  9.9599e-41, -8.0484e-41]]],


        [[[-2.4366e-40,  3.9434e-41, -1.7720e-40],
          [ 4.8799e-41,  4.1015e-41, -5.7689e-41],
          [-2.1100e-40,  3.4979e-41,  1.2203e-40]],

         [[-1.1919e-40,  2.4894e-40, -3.1911e-40],
          [-1.7106e-40,  1.2068e-40, -2.0647e-41],
          [ 1.1598e-40, -1.3027e-40, -1.0681e-40]],

         [[-3.3739e-40,  2.6577e-40,  2.6752e-40],
          [-1.7741e-40,  2.3721e-40, -1.5139e-40],
          [ 2.6550e-41, -6.1069e-41, -1.6853e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0119,  0.0139, -0.0005],
          [ 0.0218,  0.0116,  0.0013],
          [ 0.0070,  0.0159, -0.0062]],

         [[ 0.0058,  0.0025, -0.0157],
          [ 0.0129, -0.0036, -0.0092],
          [ 0.0010,  0.0016, -0.0144]],

         [[ 0.0004, -0.0125, -0.0289],
          [ 0.0001, -0.0191, -0.0225],
          [-0.0105, -0.0138, -0.0282]]],


        [[[-0.0084,  0.0100,  0.0271],
          [-0.0160,  0.0095,  0.0244],
          [-0.0064,  0.0058,  0.0082]],

         [[ 0.0002,  0.0176,  0.0311],
          [-0.0060,  0.0168,  0.0271],
          [ 0.0055,  0.0167,  0.0113]],

         [[ 0.0094,  0.0199,  0.0260],
          [ 0.0088,  0.0231,  0.0243],
          [ 0.0171,  0.0234,  0.0098]]],


        [[[ 0.0151, -0.0039, -0.0193],
          [ 0.0121,  0.0034, -0.0123],
          [ 0.0085,  0.0036, -0.0089]],

         [[ 0.0167, -0.0022, -0.0191],
          [ 0.0111,  0.0046, -0.0126],
          [ 0.0063,  0.0058, -0.0044]],

         [[ 0.0312,  0.0190,  0.0061],
          [ 0.0263,  0.0258,  0.0131],
          [ 0.0171,  0.0222,  0.0169]]],


        ...,


        [[[-0.0080,  0.0006,  0.0018],
          [-0.0076, -0.0036, -0.0008],
          [-0.0056, -0.0022,  0.0072]],

         [[ 0.0042,  0.0096,  0.0102],
          [ 0.0044,  0.0052,  0.0057],
          [ 0.0011,  0.0025,  0.0086]],

         [[ 0.0140,  0.0133,  0.0107],
          [ 0.0120,  0.0071,  0.0047],
          [ 0.0032,  0.0009,  0.0035]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5446]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 163 | Batch_idx: 0 |  Loss: (0.2338) | Acc: (91.00%) (117/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.1926) | Acc: (93.00%) (1316/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.2034) | Acc: (93.00%) (2505/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.1955) | Acc: (93.00%) (3706/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.1935) | Acc: (93.00%) (4898/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.2020) | Acc: (93.00%) (6081/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.1941) | Acc: (93.00%) (7280/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.1955) | Acc: (93.00%) (8468/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.1940) | Acc: (93.00%) (9666/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1982) | Acc: (93.00%) (10856/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.1981) | Acc: (93.00%) (12051/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1967) | Acc: (93.00%) (13249/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.1962) | Acc: (93.00%) (14432/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.1971) | Acc: (93.00%) (15624/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.1957) | Acc: (93.00%) (16821/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.1949) | Acc: (93.00%) (18020/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.1942) | Acc: (93.00%) (19213/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1946) | Acc: (93.00%) (20401/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1950) | Acc: (93.00%) (21584/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1959) | Acc: (93.00%) (22769/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1959) | Acc: (93.00%) (23962/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1953) | Acc: (93.00%) (25154/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1947) | Acc: (93.00%) (26358/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1964) | Acc: (93.00%) (27543/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1962) | Acc: (93.00%) (28740/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1960) | Acc: (93.00%) (29931/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1981) | Acc: (93.00%) (31097/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1989) | Acc: (93.00%) (32284/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.2007) | Acc: (93.00%) (33457/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.2000) | Acc: (93.00%) (34651/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.2006) | Acc: (93.00%) (35834/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.2013) | Acc: (92.00%) (37021/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.2009) | Acc: (93.00%) (38227/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.2003) | Acc: (93.00%) (39428/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.2002) | Acc: (93.00%) (40624/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1998) | Acc: (93.00%) (41822/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1994) | Acc: (93.00%) (43030/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1994) | Acc: (93.00%) (44225/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1989) | Acc: (93.00%) (45429/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1997) | Acc: (93.00%) (46568/50000)
# TEST : Loss: (0.3247) | Acc: (89.00%) (8999/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.4476e-01,  4.0430e-01, -1.9484e-01],
          [-4.4457e-02,  2.6728e-02, -1.2455e-01],
          [ 7.5502e-02, -2.1062e-01,  2.7301e-01]],

         [[-1.4865e-01,  5.4650e-01,  8.1286e-02],
          [-4.8876e-03, -4.6815e-02, -1.6838e-01],
          [ 8.2093e-02, -4.1101e-01,  1.4564e-02]],

         [[-1.6491e-01,  2.9150e-01, -1.3853e-01],
          [ 4.9080e-02, -1.4022e-01, -1.2914e-01],
          [ 1.9324e-01, -5.5784e-02,  2.0909e-01]]],


        [[[-2.1124e-01, -4.5399e-01, -2.5386e-01],
          [-5.6943e-02,  2.3507e-01,  1.9374e-01],
          [ 2.1439e-01,  2.1347e-01,  2.6484e-01]],

         [[-2.8381e-01, -3.7352e-01, -2.2381e-01],
          [-9.8896e-02,  1.7145e-01,  2.2390e-01],
          [ 2.9230e-01,  1.6267e-01,  1.7382e-01]],

         [[-1.4291e-01, -8.3718e-02, -2.2807e-01],
          [ 7.8236e-02,  2.2352e-01, -2.3694e-02],
          [ 1.4006e-02,  1.1225e-01,  7.2806e-02]]],


        [[[-8.1426e-02,  3.1685e-01,  1.1663e-01],
          [ 1.9945e-01,  2.5462e-01, -2.7984e-02],
          [-2.5686e-01, -7.9176e-02, -3.2971e-01]],

         [[ 5.0536e-02,  1.8318e-01,  1.4404e-02],
          [ 1.0164e-01,  2.8915e-01,  4.9643e-02],
          [-2.2010e-01, -1.6411e-01, -4.4060e-01]],

         [[-4.9330e-02,  2.0326e-01,  1.8934e-01],
          [ 6.3939e-02,  2.9286e-01,  1.1043e-01],
          [-2.9587e-01, -2.0772e-01, -2.7631e-01]]],


        ...,


        [[[-6.2119e-02, -9.5673e-02,  1.9184e-02],
          [ 2.2106e-02, -4.2062e-01, -1.5283e-01],
          [ 1.4399e-01, -4.3467e-02,  1.2507e-01]],

         [[ 1.3709e-01, -4.8968e-02, -3.1893e-03],
          [-8.3065e-02, -4.7783e-01, -2.2951e-01],
          [ 1.3255e-01,  2.2119e-02,  5.4052e-02]],

         [[ 1.8798e-01,  2.5479e-02,  1.0089e-01],
          [-1.6510e-02, -3.1410e-01, -1.9604e-01],
          [ 9.9677e-02, -9.8425e-02, -7.4548e-02]]],


        [[[-9.2836e-42,  9.4625e-41, -4.2536e-41],
          [ 8.7433e-41, -4.1752e-41,  9.5458e-41],
          [ 9.4037e-41, -8.7037e-41,  8.4484e-41]],

         [[ 4.9883e-41, -1.0829e-40,  2.9657e-41],
          [-1.2068e-40, -8.6810e-42, -6.4023e-41],
          [-1.2480e-40,  5.5039e-41, -7.7388e-41]],

         [[ 6.8163e-41, -1.2218e-40,  9.9758e-42],
          [-9.3458e-41, -1.0445e-40,  1.0280e-41],
          [ 3.2827e-41, -1.2001e-40,  4.4914e-41]]],


        [[[-1.3517e-40, -1.4915e-40,  2.0037e-40],
          [-1.4892e-40,  4.4613e-41,  1.3150e-40],
          [-2.3911e-40,  9.1205e-41, -3.7961e-42]],

         [[ 4.6403e-41,  2.8160e-40, -1.2580e-40],
          [-1.2780e-40, -3.5044e-41, -1.8860e-40],
          [ 1.8655e-40, -9.4125e-41, -2.3236e-40]],

         [[-3.1860e-40, -3.6924e-40, -2.2968e-40],
          [-1.3335e-40,  1.5621e-40, -1.1629e-40],
          [-9.6400e-41,  1.0309e-40, -1.9694e-41]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0207,  0.0186,  0.0306],
          [ 0.0220,  0.0117,  0.0141],
          [ 0.0182,  0.0119,  0.0056]],

         [[ 0.0269,  0.0239,  0.0369],
          [ 0.0249,  0.0159,  0.0175],
          [ 0.0204,  0.0161,  0.0152]],

         [[ 0.0256,  0.0201,  0.0338],
          [ 0.0209,  0.0109,  0.0172],
          [ 0.0181,  0.0159,  0.0145]]],


        [[[ 0.0128,  0.0113,  0.0132],
          [ 0.0020,  0.0070,  0.0134],
          [ 0.0039,  0.0138,  0.0210]],

         [[ 0.0139,  0.0121,  0.0132],
          [ 0.0034,  0.0070,  0.0116],
          [ 0.0065,  0.0124,  0.0168]],

         [[ 0.0151,  0.0135,  0.0141],
          [ 0.0063,  0.0096,  0.0122],
          [ 0.0089,  0.0145,  0.0162]]],


        [[[-0.0139,  0.0048,  0.0101],
          [-0.0077,  0.0011,  0.0041],
          [-0.0047,  0.0023,  0.0084]],

         [[-0.0312, -0.0118, -0.0033],
          [-0.0272, -0.0138, -0.0075],
          [-0.0255, -0.0167, -0.0059]],

         [[-0.0369, -0.0220, -0.0136],
          [-0.0283, -0.0203, -0.0124],
          [-0.0257, -0.0188, -0.0072]]],


        ...,


        [[[ 0.0027, -0.0085, -0.0121],
          [ 0.0123,  0.0029, -0.0026],
          [ 0.0156,  0.0092,  0.0072]],

         [[ 0.0067, -0.0018, -0.0071],
          [ 0.0165,  0.0078,  0.0018],
          [ 0.0200,  0.0138,  0.0113]],

         [[-0.0003, -0.0077, -0.0139],
          [ 0.0101,  0.0035, -0.0054],
          [ 0.0132,  0.0091,  0.0043]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5434]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

Epoch: 164 | Batch_idx: 0 |  Loss: (0.2715) | Acc: (92.00%) (119/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1907) | Acc: (93.00%) (1320/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.1834) | Acc: (93.00%) (2525/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.1829) | Acc: (93.00%) (3711/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.1805) | Acc: (93.00%) (4915/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.1774) | Acc: (93.00%) (6124/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.1794) | Acc: (93.00%) (7324/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.1817) | Acc: (93.00%) (8516/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.1779) | Acc: (93.00%) (9723/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.1785) | Acc: (93.00%) (10919/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.1808) | Acc: (93.00%) (12099/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.1775) | Acc: (93.00%) (13314/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.1750) | Acc: (93.00%) (14525/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.1769) | Acc: (93.00%) (15717/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.1760) | Acc: (93.00%) (16927/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.1760) | Acc: (93.00%) (18132/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.1765) | Acc: (93.00%) (19328/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.1782) | Acc: (93.00%) (20515/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.1779) | Acc: (93.00%) (21721/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.1790) | Acc: (93.00%) (22907/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.1782) | Acc: (93.00%) (24120/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.1786) | Acc: (93.00%) (25316/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.1795) | Acc: (93.00%) (26508/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.1792) | Acc: (93.00%) (27708/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.1801) | Acc: (93.00%) (28891/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.1799) | Acc: (93.00%) (30097/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.1795) | Acc: (93.00%) (31309/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.1794) | Acc: (93.00%) (32503/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.1809) | Acc: (93.00%) (33686/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.1819) | Acc: (93.00%) (34874/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.1811) | Acc: (93.00%) (36083/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.1817) | Acc: (93.00%) (37278/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.1824) | Acc: (93.00%) (38474/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.1821) | Acc: (93.00%) (39676/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.1818) | Acc: (93.00%) (40874/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.1826) | Acc: (93.00%) (42058/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.1820) | Acc: (93.00%) (43272/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1816) | Acc: (93.00%) (44479/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.1812) | Acc: (93.00%) (45683/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1812) | Acc: (93.00%) (46848/50000)
# TEST : Loss: (0.3227) | Acc: (90.00%) (9027/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.5787e-01,  4.0385e-01, -1.9192e-01],
          [-5.1595e-02,  3.2215e-02, -1.1792e-01],
          [ 7.1521e-02, -2.0450e-01,  2.7534e-01]],

         [[-1.6315e-01,  5.4950e-01,  8.5328e-02],
          [-1.2366e-02, -4.3040e-02, -1.6555e-01],
          [ 7.5696e-02, -4.0949e-01,  1.2349e-02]],

         [[-1.7486e-01,  2.9417e-01, -1.3337e-01],
          [ 4.1185e-02, -1.4106e-01, -1.2833e-01],
          [ 1.8832e-01, -5.3579e-02,  2.0611e-01]]],


        [[[-2.1852e-01, -4.6468e-01, -2.6311e-01],
          [-6.6117e-02,  2.2624e-01,  1.8518e-01],
          [ 2.0739e-01,  2.0546e-01,  2.5676e-01]],

         [[-2.8717e-01, -3.8411e-01, -2.3451e-01],
          [-1.0364e-01,  1.6401e-01,  2.1556e-01],
          [ 2.9148e-01,  1.5798e-01,  1.6813e-01]],

         [[-1.4141e-01, -9.1915e-02, -2.3737e-01],
          [ 7.7236e-02,  2.1751e-01, -3.0103e-02],
          [ 1.5046e-02,  1.0656e-01,  6.6503e-02]]],


        [[[-8.3094e-02,  3.1500e-01,  1.1175e-01],
          [ 2.0044e-01,  2.5542e-01, -2.8288e-02],
          [-2.5791e-01, -7.8517e-02, -3.3099e-01]],

         [[ 5.3679e-02,  1.8811e-01,  1.4478e-02],
          [ 1.0746e-01,  2.9533e-01,  5.0459e-02],
          [-2.1633e-01, -1.6080e-01, -4.4243e-01]],

         [[-4.7938e-02,  2.0472e-01,  1.8700e-01],
          [ 6.8584e-02,  2.9576e-01,  1.0803e-01],
          [-2.9418e-01, -2.0818e-01, -2.8143e-01]]],


        ...,


        [[[-6.0151e-02, -9.9761e-02,  1.0782e-02],
          [ 2.4652e-02, -4.3129e-01, -1.6499e-01],
          [ 1.4342e-01, -5.5158e-02,  1.1265e-01]],

         [[ 1.4681e-01, -4.2778e-02,  2.0070e-03],
          [-6.9010e-02, -4.6943e-01, -2.1836e-01],
          [ 1.3849e-01,  1.8187e-02,  5.3693e-02]],

         [[ 1.9096e-01,  2.2905e-02,  9.8880e-02],
          [-1.0668e-02, -3.1661e-01, -1.9268e-01],
          [ 1.0380e-01, -1.0437e-01, -7.9692e-02]]],


        [[[ 9.4031e-41,  9.5072e-41, -9.5566e-41],
          [ 2.0074e-41,  8.4162e-42,  1.2213e-40],
          [-7.5110e-42,  3.4915e-41,  7.2069e-42]],

         [[ 8.0838e-41,  4.8129e-41,  3.6249e-41],
          [-1.2088e-41,  4.0661e-41, -7.7083e-41],
          [ 4.8276e-41,  1.1421e-41, -9.3027e-41]],

         [[ 8.1507e-41, -1.4554e-40,  6.2061e-41],
          [-9.5480e-41,  1.1074e-40, -1.4453e-40],
          [-1.3340e-40,  1.3584e-41, -9.1386e-41]]],


        [[[-2.6300e-40,  2.1603e-40, -1.7080e-40],
          [ 2.3511e-40,  2.1442e-40,  1.9986e-40],
          [ 2.0037e-40,  1.0275e-40, -1.6648e-40]],

         [[ 5.0717e-41, -2.1048e-40, -2.6933e-40],
          [ 2.0891e-40, -3.7132e-41, -2.0968e-40],
          [ 1.4128e-41,  1.6453e-41,  2.1694e-40]],

         [[-3.5289e-40,  1.4645e-40,  3.7262e-41],
          [ 1.3585e-40, -1.3657e-41, -8.1471e-42],
          [ 3.0002e-41,  1.1322e-40,  1.6742e-40]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0141, -0.0240, -0.0310],
          [-0.0254, -0.0402, -0.0392],
          [-0.0183, -0.0182, -0.0140]],

         [[-0.0360, -0.0472, -0.0592],
          [-0.0310, -0.0460, -0.0506],
          [-0.0217, -0.0326, -0.0359]],

         [[-0.0237, -0.0354, -0.0419],
          [-0.0186, -0.0302, -0.0382],
          [-0.0081, -0.0211, -0.0293]]],


        [[[ 0.0136,  0.0031,  0.0031],
          [ 0.0289,  0.0149,  0.0118],
          [ 0.0260,  0.0155,  0.0172]],

         [[ 0.0531,  0.0479,  0.0489],
          [ 0.0527,  0.0449,  0.0446],
          [ 0.0410,  0.0365,  0.0396]],

         [[ 0.0448,  0.0379,  0.0383],
          [ 0.0456,  0.0371,  0.0357],
          [ 0.0378,  0.0321,  0.0312]]],


        [[[ 0.0340,  0.0341,  0.0187],
          [ 0.0246,  0.0204,  0.0084],
          [ 0.0210,  0.0132,  0.0039]],

         [[-0.0106, -0.0163, -0.0349],
          [-0.0044, -0.0145, -0.0331],
          [ 0.0058, -0.0039, -0.0198]],

         [[-0.0038, -0.0062, -0.0251],
          [ 0.0006, -0.0055, -0.0242],
          [ 0.0108,  0.0030, -0.0143]]],


        ...,


        [[[ 0.0038,  0.0078,  0.0170],
          [-0.0090, -0.0069,  0.0042],
          [-0.0004,  0.0005,  0.0103]],

         [[ 0.0148,  0.0180,  0.0256],
          [ 0.0038,  0.0051,  0.0145],
          [ 0.0122,  0.0130,  0.0206]],

         [[ 0.0209,  0.0212,  0.0241],
          [ 0.0105,  0.0100,  0.0146],
          [ 0.0151,  0.0162,  0.0222]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight Parameter containing:
tensor([[0.5419]], device='cuda:0')

percentage_weight_grad tensor([[0.]], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1, out_features=1, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
3 hours 51 mins 30 secs for training