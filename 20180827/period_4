Files already downloaded and verified
USE 1 GPUs!
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3102) |  Loss2: (0.0000) | Acc: (5.00%) (7/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.3033) |  Loss2: (0.0000) | Acc: (10.00%) (146/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.2987) |  Loss2: (0.0000) | Acc: (9.00%) (268/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.2932) |  Loss2: (0.0000) | Acc: (10.00%) (408/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (2.2855) |  Loss2: (0.0000) | Acc: (11.00%) (626/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (2.2771) |  Loss2: (0.0000) | Acc: (13.00%) (860/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (2.2687) |  Loss2: (0.0000) | Acc: (14.00%) (1112/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (2.2601) |  Loss2: (0.0000) | Acc: (15.00%) (1381/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (2.2520) |  Loss2: (0.0000) | Acc: (16.00%) (1665/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (2.2432) |  Loss2: (0.0000) | Acc: (16.00%) (1945/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (2.2343) |  Loss2: (0.0000) | Acc: (17.00%) (2267/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (2.2273) |  Loss2: (0.0000) | Acc: (18.00%) (2570/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (2.2181) |  Loss2: (0.0000) | Acc: (18.00%) (2913/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (2.2108) |  Loss2: (0.0000) | Acc: (19.00%) (3215/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (2.2037) |  Loss2: (0.0000) | Acc: (19.00%) (3521/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (2.1945) |  Loss2: (0.0000) | Acc: (19.00%) (3860/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (2.1870) |  Loss2: (0.0000) | Acc: (20.00%) (4176/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (2.1800) |  Loss2: (0.0000) | Acc: (20.00%) (4492/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (2.1724) |  Loss2: (0.0000) | Acc: (20.00%) (4812/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (2.1654) |  Loss2: (0.0000) | Acc: (21.00%) (5155/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (2.1580) |  Loss2: (0.0000) | Acc: (21.00%) (5495/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (2.1512) |  Loss2: (0.0000) | Acc: (21.00%) (5843/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (2.1445) |  Loss2: (0.0000) | Acc: (21.00%) (6202/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (2.1366) |  Loss2: (0.0000) | Acc: (22.00%) (6563/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (2.1293) |  Loss2: (0.0000) | Acc: (22.00%) (6923/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (2.1226) |  Loss2: (0.0000) | Acc: (22.00%) (7296/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (2.1155) |  Loss2: (0.0000) | Acc: (22.00%) (7668/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (2.1081) |  Loss2: (0.0000) | Acc: (23.00%) (8034/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (2.1015) |  Loss2: (0.0000) | Acc: (23.00%) (8428/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (2.0963) |  Loss2: (0.0000) | Acc: (23.00%) (8800/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (2.0897) |  Loss2: (0.0000) | Acc: (23.00%) (9169/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (2.0836) |  Loss2: (0.0000) | Acc: (23.00%) (9553/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (2.0768) |  Loss2: (0.0000) | Acc: (24.00%) (9980/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (2.0706) |  Loss2: (0.0000) | Acc: (24.00%) (10408/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (2.0647) |  Loss2: (0.0000) | Acc: (24.00%) (10804/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (2.0586) |  Loss2: (0.0000) | Acc: (24.00%) (11222/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (2.0527) |  Loss2: (0.0000) | Acc: (25.00%) (11645/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (2.0472) |  Loss2: (0.0000) | Acc: (25.00%) (12059/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (2.0411) |  Loss2: (0.0000) | Acc: (25.00%) (12503/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (2.0363) |  Loss2: (0.0000) | Acc: (25.00%) (12882/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_000.pth.tar'
# TEST : Loss: (1.7804) | Acc: (33.00%) (3300/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(164.5010, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(768.8879, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(767.3822, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1535.0320, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(513.4285, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2171.2468, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4343.4224, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1450.8358, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6136.1587, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12285.1221, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4101.1802, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17365.6074, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.8030) |  Loss2: (0.0000) | Acc: (30.00%) (39/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.8240) |  Loss2: (0.0000) | Acc: (33.00%) (470/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.8177) |  Loss2: (0.0000) | Acc: (33.00%) (897/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8132) |  Loss2: (0.0000) | Acc: (32.00%) (1293/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8028) |  Loss2: (0.0000) | Acc: (33.00%) (1743/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.7969) |  Loss2: (0.0000) | Acc: (33.00%) (2185/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.7941) |  Loss2: (0.0000) | Acc: (33.00%) (2635/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.7908) |  Loss2: (0.0000) | Acc: (33.00%) (3063/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.7870) |  Loss2: (0.0000) | Acc: (33.00%) (3497/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.7842) |  Loss2: (0.0000) | Acc: (33.00%) (3950/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.7802) |  Loss2: (0.0000) | Acc: (34.00%) (4402/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.7795) |  Loss2: (0.0000) | Acc: (34.00%) (4846/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.7766) |  Loss2: (0.0000) | Acc: (34.00%) (5305/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.7746) |  Loss2: (0.0000) | Acc: (34.00%) (5747/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7716) |  Loss2: (0.0000) | Acc: (34.00%) (6193/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7703) |  Loss2: (0.0000) | Acc: (34.00%) (6652/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7667) |  Loss2: (0.0000) | Acc: (34.00%) (7143/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7631) |  Loss2: (0.0000) | Acc: (34.00%) (7622/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7596) |  Loss2: (0.0000) | Acc: (34.00%) (8087/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7573) |  Loss2: (0.0000) | Acc: (34.00%) (8537/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7537) |  Loss2: (0.0000) | Acc: (35.00%) (9019/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7511) |  Loss2: (0.0000) | Acc: (35.00%) (9499/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7486) |  Loss2: (0.0000) | Acc: (35.00%) (9978/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7457) |  Loss2: (0.0000) | Acc: (35.00%) (10470/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7419) |  Loss2: (0.0000) | Acc: (35.00%) (10959/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7390) |  Loss2: (0.0000) | Acc: (35.00%) (11478/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7361) |  Loss2: (0.0000) | Acc: (35.00%) (11969/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7335) |  Loss2: (0.0000) | Acc: (35.00%) (12458/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7316) |  Loss2: (0.0000) | Acc: (36.00%) (12954/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7285) |  Loss2: (0.0000) | Acc: (36.00%) (13433/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7263) |  Loss2: (0.0000) | Acc: (36.00%) (13910/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7231) |  Loss2: (0.0000) | Acc: (36.00%) (14440/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7205) |  Loss2: (0.0000) | Acc: (36.00%) (14947/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7179) |  Loss2: (0.0000) | Acc: (36.00%) (15454/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7155) |  Loss2: (0.0000) | Acc: (36.00%) (15963/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.7136) |  Loss2: (0.0000) | Acc: (36.00%) (16424/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.7113) |  Loss2: (0.0000) | Acc: (36.00%) (16937/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.7090) |  Loss2: (0.0000) | Acc: (36.00%) (17424/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.7070) |  Loss2: (0.0000) | Acc: (36.00%) (17933/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.7048) |  Loss2: (0.0000) | Acc: (36.00%) (18452/50000)
# TEST : Loss: (1.6098) | Acc: (39.00%) (3968/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 2 | Batch_idx: 0 |  Loss: (1.7238) |  Loss2: (0.0000) | Acc: (36.00%) (47/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.6075) |  Loss2: (0.0000) | Acc: (41.00%) (582/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.6104) |  Loss2: (0.0000) | Acc: (39.00%) (1071/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.6005) |  Loss2: (0.0000) | Acc: (40.00%) (1618/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.5904) |  Loss2: (0.0000) | Acc: (40.00%) (2147/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.5915) |  Loss2: (0.0000) | Acc: (40.00%) (2671/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.5874) |  Loss2: (0.0000) | Acc: (40.00%) (3196/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.5834) |  Loss2: (0.0000) | Acc: (40.00%) (3715/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.5840) |  Loss2: (0.0000) | Acc: (40.00%) (4228/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.5843) |  Loss2: (0.0000) | Acc: (40.00%) (4754/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.5836) |  Loss2: (0.0000) | Acc: (40.00%) (5285/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.5811) |  Loss2: (0.0000) | Acc: (40.00%) (5816/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5795) |  Loss2: (0.0000) | Acc: (40.00%) (6345/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5827) |  Loss2: (0.0000) | Acc: (41.00%) (6877/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5815) |  Loss2: (0.0000) | Acc: (41.00%) (7416/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5797) |  Loss2: (0.0000) | Acc: (41.00%) (7954/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5797) |  Loss2: (0.0000) | Acc: (41.00%) (8491/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5753) |  Loss2: (0.0000) | Acc: (41.00%) (9048/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5736) |  Loss2: (0.0000) | Acc: (41.00%) (9589/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5718) |  Loss2: (0.0000) | Acc: (41.00%) (10135/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5697) |  Loss2: (0.0000) | Acc: (41.00%) (10681/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5675) |  Loss2: (0.0000) | Acc: (41.00%) (11227/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5656) |  Loss2: (0.0000) | Acc: (41.00%) (11759/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5631) |  Loss2: (0.0000) | Acc: (41.00%) (12319/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5610) |  Loss2: (0.0000) | Acc: (41.00%) (12889/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5591) |  Loss2: (0.0000) | Acc: (41.00%) (13461/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5575) |  Loss2: (0.0000) | Acc: (41.00%) (14015/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5569) |  Loss2: (0.0000) | Acc: (41.00%) (14542/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5534) |  Loss2: (0.0000) | Acc: (42.00%) (15134/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5526) |  Loss2: (0.0000) | Acc: (42.00%) (15670/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5510) |  Loss2: (0.0000) | Acc: (42.00%) (16232/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5482) |  Loss2: (0.0000) | Acc: (42.00%) (16829/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5469) |  Loss2: (0.0000) | Acc: (42.00%) (17403/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5457) |  Loss2: (0.0000) | Acc: (42.00%) (17962/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.5423) |  Loss2: (0.0000) | Acc: (42.00%) (18544/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.5404) |  Loss2: (0.0000) | Acc: (42.00%) (19144/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.5381) |  Loss2: (0.0000) | Acc: (42.00%) (19747/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.5367) |  Loss2: (0.0000) | Acc: (42.00%) (20347/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.5347) |  Loss2: (0.0000) | Acc: (42.00%) (20949/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.5324) |  Loss2: (0.0000) | Acc: (43.00%) (21523/50000)
# TEST : Loss: (1.5095) | Acc: (44.00%) (4457/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 3 | Batch_idx: 0 |  Loss: (1.5040) |  Loss2: (0.0000) | Acc: (46.00%) (59/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4577) |  Loss2: (0.0000) | Acc: (46.00%) (651/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.4638) |  Loss2: (0.0000) | Acc: (45.00%) (1221/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.4510) |  Loss2: (0.0000) | Acc: (46.00%) (1838/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.4517) |  Loss2: (0.0000) | Acc: (45.00%) (2402/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.4515) |  Loss2: (0.0000) | Acc: (45.00%) (2992/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4455) |  Loss2: (0.0000) | Acc: (46.00%) (3611/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4435) |  Loss2: (0.0000) | Acc: (46.00%) (4230/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4404) |  Loss2: (0.0000) | Acc: (46.00%) (4841/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4365) |  Loss2: (0.0000) | Acc: (47.00%) (5478/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.4341) |  Loss2: (0.0000) | Acc: (47.00%) (6106/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.4322) |  Loss2: (0.0000) | Acc: (47.00%) (6717/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.4324) |  Loss2: (0.0000) | Acc: (47.00%) (7332/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.4329) |  Loss2: (0.0000) | Acc: (47.00%) (7924/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.4321) |  Loss2: (0.0000) | Acc: (47.00%) (8542/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.4318) |  Loss2: (0.0000) | Acc: (47.00%) (9137/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.4312) |  Loss2: (0.0000) | Acc: (47.00%) (9759/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.4329) |  Loss2: (0.0000) | Acc: (47.00%) (10354/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.4303) |  Loss2: (0.0000) | Acc: (47.00%) (11003/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.4286) |  Loss2: (0.0000) | Acc: (47.00%) (11627/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.4275) |  Loss2: (0.0000) | Acc: (47.00%) (12259/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.4237) |  Loss2: (0.0000) | Acc: (47.00%) (12909/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.4230) |  Loss2: (0.0000) | Acc: (47.00%) (13540/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.4212) |  Loss2: (0.0000) | Acc: (47.00%) (14171/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.4185) |  Loss2: (0.0000) | Acc: (48.00%) (14821/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.4168) |  Loss2: (0.0000) | Acc: (48.00%) (15436/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.4174) |  Loss2: (0.0000) | Acc: (48.00%) (16056/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.4152) |  Loss2: (0.0000) | Acc: (48.00%) (16712/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.4130) |  Loss2: (0.0000) | Acc: (48.00%) (17364/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.4101) |  Loss2: (0.0000) | Acc: (48.00%) (18034/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.4100) |  Loss2: (0.0000) | Acc: (48.00%) (18649/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.4085) |  Loss2: (0.0000) | Acc: (48.00%) (19294/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.4068) |  Loss2: (0.0000) | Acc: (48.00%) (19929/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.4044) |  Loss2: (0.0000) | Acc: (48.00%) (20575/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.4036) |  Loss2: (0.0000) | Acc: (48.00%) (21220/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.4009) |  Loss2: (0.0000) | Acc: (48.00%) (21912/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.4007) |  Loss2: (0.0000) | Acc: (48.00%) (22543/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.3985) |  Loss2: (0.0000) | Acc: (48.00%) (23229/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.3975) |  Loss2: (0.0000) | Acc: (48.00%) (23881/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.3951) |  Loss2: (0.0000) | Acc: (49.00%) (24553/50000)
# TEST : Loss: (1.5021) | Acc: (46.00%) (4620/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 4 | Batch_idx: 0 |  Loss: (1.4417) |  Loss2: (0.0000) | Acc: (41.00%) (53/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.5784) |  Loss2: (0.0000) | Acc: (44.00%) (632/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.7020) |  Loss2: (0.0000) | Acc: (41.00%) (1117/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.7302) |  Loss2: (0.0000) | Acc: (40.00%) (1603/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.7563) |  Loss2: (0.0000) | Acc: (39.00%) (2063/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.7717) |  Loss2: (0.0000) | Acc: (38.00%) (2545/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.7705) |  Loss2: (0.0000) | Acc: (38.00%) (3033/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.7652) |  Loss2: (0.0000) | Acc: (38.00%) (3516/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.7586) |  Loss2: (0.0000) | Acc: (38.00%) (4010/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.7531) |  Loss2: (0.0000) | Acc: (38.00%) (4520/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.7501) |  Loss2: (0.0000) | Acc: (39.00%) (5042/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.7454) |  Loss2: (0.0000) | Acc: (39.00%) (5554/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.7377) |  Loss2: (0.0000) | Acc: (39.00%) (6074/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.7281) |  Loss2: (0.0000) | Acc: (39.00%) (6596/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.7229) |  Loss2: (0.0000) | Acc: (39.00%) (7135/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.7168) |  Loss2: (0.0000) | Acc: (39.00%) (7653/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.7081) |  Loss2: (0.0000) | Acc: (39.00%) (8197/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.7008) |  Loss2: (0.0000) | Acc: (39.00%) (8730/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.6940) |  Loss2: (0.0000) | Acc: (39.00%) (9265/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.6862) |  Loss2: (0.0000) | Acc: (40.00%) (9841/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.6794) |  Loss2: (0.0000) | Acc: (40.00%) (10391/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.6716) |  Loss2: (0.0000) | Acc: (40.00%) (10964/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.6635) |  Loss2: (0.0000) | Acc: (40.00%) (11547/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.6562) |  Loss2: (0.0000) | Acc: (41.00%) (12137/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.6500) |  Loss2: (0.0000) | Acc: (41.00%) (12716/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.6431) |  Loss2: (0.0000) | Acc: (41.00%) (13315/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.6367) |  Loss2: (0.0000) | Acc: (41.00%) (13910/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.6338) |  Loss2: (0.0000) | Acc: (41.00%) (14454/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.6300) |  Loss2: (0.0000) | Acc: (41.00%) (15015/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.6257) |  Loss2: (0.0000) | Acc: (41.00%) (15598/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.6226) |  Loss2: (0.0000) | Acc: (41.00%) (16173/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.6200) |  Loss2: (0.0000) | Acc: (42.00%) (16768/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.6163) |  Loss2: (0.0000) | Acc: (42.00%) (17369/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.6111) |  Loss2: (0.0000) | Acc: (42.00%) (17971/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.6076) |  Loss2: (0.0000) | Acc: (42.00%) (18562/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.6050) |  Loss2: (0.0000) | Acc: (42.00%) (19120/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.6019) |  Loss2: (0.0000) | Acc: (42.00%) (19715/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.5986) |  Loss2: (0.0000) | Acc: (42.00%) (20296/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.5947) |  Loss2: (0.0000) | Acc: (42.00%) (20924/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.5911) |  Loss2: (0.0000) | Acc: (43.00%) (21509/50000)
# TEST : Loss: (1.4321) | Acc: (46.00%) (4676/10000)
percent tensor([0.4731, 0.4525, 0.4656, 0.4697, 0.4596, 0.4727, 0.4527, 0.4626, 0.4552,
        0.4602, 0.4602, 0.4614, 0.4679, 0.4442, 0.4635, 0.4711],
       device='cuda:0') torch.Size([16])
percent tensor([0.4847, 0.4725, 0.4836, 0.4840, 0.4818, 0.4910, 0.4742, 0.4794, 0.4744,
        0.4764, 0.4768, 0.4797, 0.4808, 0.4692, 0.4808, 0.4844],
       device='cuda:0') torch.Size([16])
percent tensor([0.4872, 0.4873, 0.4793, 0.4859, 0.4800, 0.4869, 0.4851, 0.4834, 0.4877,
        0.4859, 0.4882, 0.4802, 0.4877, 0.4925, 0.4878, 0.4871],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.4992, 0.4978, 0.4986, 0.4975, 0.4985, 0.4984, 0.4978, 0.4991,
        0.4981, 0.4987, 0.4972, 0.4987, 0.5002, 0.4984, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.5010, 0.4986, 0.5026, 0.5023, 0.5017, 0.5016, 0.4993, 0.5018, 0.4990,
        0.4999, 0.4987, 0.5013, 0.5002, 0.4975, 0.4991, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.4931, 0.4944, 0.4831, 0.4871, 0.4849, 0.4918, 0.4920, 0.4821, 0.4932,
        0.4914, 0.4944, 0.4843, 0.4940, 0.4952, 0.4918, 0.4919],
       device='cuda:0') torch.Size([16])
percent tensor([0.5013, 0.4981, 0.4767, 0.4815, 0.4775, 0.5028, 0.4916, 0.4636, 0.4962,
        0.4864, 0.4997, 0.4768, 0.5025, 0.5006, 0.4950, 0.4923],
       device='cuda:0') torch.Size([16])
percent tensor([0.5003, 0.4984, 0.4863, 0.4908, 0.4897, 0.5040, 0.4992, 0.4843, 0.4934,
        0.4998, 0.4971, 0.4885, 0.4945, 0.4959, 0.4984, 0.5111],
       device='cuda:0') torch.Size([16])
Epoch: 5 | Batch_idx: 0 |  Loss: (1.4682) |  Loss2: (0.0000) | Acc: (48.00%) (62/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.4740) |  Loss2: (0.0000) | Acc: (49.00%) (693/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.4815) |  Loss2: (0.0000) | Acc: (47.00%) (1282/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.4852) |  Loss2: (0.0000) | Acc: (46.00%) (1846/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.4714) |  Loss2: (0.0000) | Acc: (46.00%) (2438/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.4655) |  Loss2: (0.0000) | Acc: (46.00%) (3042/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.4623) |  Loss2: (0.0000) | Acc: (46.00%) (3635/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.4569) |  Loss2: (0.0000) | Acc: (46.00%) (4257/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.4555) |  Loss2: (0.0000) | Acc: (46.00%) (4851/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.4557) |  Loss2: (0.0000) | Acc: (46.00%) (5457/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.4563) |  Loss2: (0.0000) | Acc: (46.00%) (6045/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.4558) |  Loss2: (0.0000) | Acc: (46.00%) (6638/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.4523) |  Loss2: (0.0000) | Acc: (46.00%) (7267/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.4495) |  Loss2: (0.0000) | Acc: (47.00%) (7896/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.4464) |  Loss2: (0.0000) | Acc: (47.00%) (8510/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.4465) |  Loss2: (0.0000) | Acc: (47.00%) (9117/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.4458) |  Loss2: (0.0000) | Acc: (47.00%) (9740/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.4455) |  Loss2: (0.0000) | Acc: (47.00%) (10375/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.4424) |  Loss2: (0.0000) | Acc: (47.00%) (10998/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.4431) |  Loss2: (0.0000) | Acc: (47.00%) (11634/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.4413) |  Loss2: (0.0000) | Acc: (47.00%) (12265/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.4394) |  Loss2: (0.0000) | Acc: (47.00%) (12894/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.4373) |  Loss2: (0.0000) | Acc: (47.00%) (13524/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.4356) |  Loss2: (0.0000) | Acc: (47.00%) (14175/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.4344) |  Loss2: (0.0000) | Acc: (48.00%) (14811/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.4325) |  Loss2: (0.0000) | Acc: (48.00%) (15428/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.4313) |  Loss2: (0.0000) | Acc: (48.00%) (16048/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.4309) |  Loss2: (0.0000) | Acc: (48.00%) (16677/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.4300) |  Loss2: (0.0000) | Acc: (48.00%) (17301/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.4297) |  Loss2: (0.0000) | Acc: (48.00%) (17925/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.4297) |  Loss2: (0.0000) | Acc: (48.00%) (18527/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.4302) |  Loss2: (0.0000) | Acc: (48.00%) (19143/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.4295) |  Loss2: (0.0000) | Acc: (48.00%) (19789/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.4273) |  Loss2: (0.0000) | Acc: (48.00%) (20424/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.4250) |  Loss2: (0.0000) | Acc: (48.00%) (21086/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.4233) |  Loss2: (0.0000) | Acc: (48.00%) (21747/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.4237) |  Loss2: (0.0000) | Acc: (48.00%) (22336/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.4231) |  Loss2: (0.0000) | Acc: (48.00%) (22975/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.4234) |  Loss2: (0.0000) | Acc: (48.00%) (23604/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.4225) |  Loss2: (0.0000) | Acc: (48.00%) (24215/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_005.pth.tar'
# TEST : Loss: (1.3681) | Acc: (49.00%) (4939/10000)
percent tensor([0.4897, 0.4742, 0.4891, 0.4882, 0.4849, 0.4897, 0.4780, 0.4844, 0.4794,
        0.4822, 0.4813, 0.4861, 0.4859, 0.4667, 0.4835, 0.4873],
       device='cuda:0') torch.Size([16])
percent tensor([0.4890, 0.4799, 0.4902, 0.4891, 0.4885, 0.4932, 0.4822, 0.4864, 0.4821,
        0.4835, 0.4832, 0.4871, 0.4862, 0.4776, 0.4860, 0.4887],
       device='cuda:0') torch.Size([16])
percent tensor([0.4826, 0.4826, 0.4753, 0.4843, 0.4760, 0.4828, 0.4804, 0.4803, 0.4840,
        0.4813, 0.4832, 0.4762, 0.4829, 0.4898, 0.4835, 0.4828],
       device='cuda:0') torch.Size([16])
percent tensor([0.4977, 0.4980, 0.4957, 0.4981, 0.4955, 0.4982, 0.4963, 0.4957, 0.4975,
        0.4964, 0.4975, 0.4947, 0.4977, 0.4993, 0.4975, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.5021, 0.5003, 0.5067, 0.5048, 0.5050, 0.5031, 0.5013, 0.5063, 0.5002,
        0.5029, 0.5004, 0.5051, 0.5018, 0.4986, 0.4999, 0.5007],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.4983, 0.4846, 0.4891, 0.4874, 0.4952, 0.4950, 0.4848, 0.4965,
        0.4962, 0.4987, 0.4866, 0.4981, 0.4995, 0.4955, 0.4959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5170, 0.5103, 0.4849, 0.4907, 0.4850, 0.5243, 0.4980, 0.4732, 0.5062,
        0.5005, 0.5158, 0.4838, 0.5199, 0.5162, 0.5038, 0.5089],
       device='cuda:0') torch.Size([16])
percent tensor([0.5745, 0.5737, 0.5708, 0.5824, 0.5716, 0.6391, 0.5576, 0.6262, 0.5650,
        0.5892, 0.5764, 0.5633, 0.5885, 0.5825, 0.5837, 0.6576],
       device='cuda:0') torch.Size([16])
Epoch: 6 | Batch_idx: 0 |  Loss: (1.3261) |  Loss2: (0.0000) | Acc: (51.00%) (66/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.3482) |  Loss2: (0.0000) | Acc: (49.00%) (700/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.3686) |  Loss2: (0.0000) | Acc: (49.00%) (1341/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.3752) |  Loss2: (0.0000) | Acc: (49.00%) (1971/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.3836) |  Loss2: (0.0000) | Acc: (49.00%) (2593/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.3818) |  Loss2: (0.0000) | Acc: (49.00%) (3246/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.3814) |  Loss2: (0.0000) | Acc: (49.00%) (3882/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.3827) |  Loss2: (0.0000) | Acc: (49.00%) (4491/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.3861) |  Loss2: (0.0000) | Acc: (49.00%) (5115/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.3913) |  Loss2: (0.0000) | Acc: (49.00%) (5735/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.3910) |  Loss2: (0.0000) | Acc: (49.00%) (6356/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.3909) |  Loss2: (0.0000) | Acc: (49.00%) (6983/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.3893) |  Loss2: (0.0000) | Acc: (49.00%) (7613/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.3867) |  Loss2: (0.0000) | Acc: (49.00%) (8270/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.3848) |  Loss2: (0.0000) | Acc: (49.00%) (8930/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.3844) |  Loss2: (0.0000) | Acc: (49.00%) (9567/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.3828) |  Loss2: (0.0000) | Acc: (49.00%) (10199/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.3820) |  Loss2: (0.0000) | Acc: (49.00%) (10842/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.3817) |  Loss2: (0.0000) | Acc: (49.00%) (11483/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.3825) |  Loss2: (0.0000) | Acc: (49.00%) (12121/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.3841) |  Loss2: (0.0000) | Acc: (49.00%) (12705/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.3843) |  Loss2: (0.0000) | Acc: (49.00%) (13326/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.3841) |  Loss2: (0.0000) | Acc: (49.00%) (13955/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.3834) |  Loss2: (0.0000) | Acc: (49.00%) (14592/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.3843) |  Loss2: (0.0000) | Acc: (49.00%) (15223/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.3828) |  Loss2: (0.0000) | Acc: (49.00%) (15859/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.3821) |  Loss2: (0.0000) | Acc: (49.00%) (16519/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.3815) |  Loss2: (0.0000) | Acc: (49.00%) (17153/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.3811) |  Loss2: (0.0000) | Acc: (49.00%) (17818/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.3804) |  Loss2: (0.0000) | Acc: (49.00%) (18457/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.3798) |  Loss2: (0.0000) | Acc: (49.00%) (19097/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.3797) |  Loss2: (0.0000) | Acc: (49.00%) (19725/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.3804) |  Loss2: (0.0000) | Acc: (49.00%) (20368/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.3802) |  Loss2: (0.0000) | Acc: (49.00%) (21017/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.3800) |  Loss2: (0.0000) | Acc: (49.00%) (21637/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.3785) |  Loss2: (0.0000) | Acc: (49.00%) (22283/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.3784) |  Loss2: (0.0000) | Acc: (49.00%) (22917/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.3777) |  Loss2: (0.0000) | Acc: (49.00%) (23557/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.3788) |  Loss2: (0.0000) | Acc: (49.00%) (24187/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.3782) |  Loss2: (0.0000) | Acc: (49.00%) (24814/50000)
# TEST : Loss: (1.3407) | Acc: (50.00%) (5081/10000)
percent tensor([0.4985, 0.4847, 0.5011, 0.4987, 0.4978, 0.4992, 0.4903, 0.4958, 0.4915,
        0.4933, 0.4917, 0.4985, 0.4951, 0.4769, 0.4940, 0.4958],
       device='cuda:0') torch.Size([16])
percent tensor([0.4920, 0.4853, 0.4944, 0.4925, 0.4928, 0.4947, 0.4876, 0.4910, 0.4874,
        0.4884, 0.4876, 0.4918, 0.4900, 0.4836, 0.4897, 0.4917],
       device='cuda:0') torch.Size([16])
percent tensor([0.4792, 0.4787, 0.4723, 0.4838, 0.4734, 0.4800, 0.4767, 0.4778, 0.4808,
        0.4777, 0.4789, 0.4731, 0.4792, 0.4869, 0.4803, 0.4797],
       device='cuda:0') torch.Size([16])
percent tensor([0.4972, 0.4969, 0.4938, 0.4976, 0.4937, 0.4979, 0.4945, 0.4939, 0.4960,
        0.4950, 0.4964, 0.4925, 0.4969, 0.4985, 0.4967, 0.4969],
       device='cuda:0') torch.Size([16])
percent tensor([0.5040, 0.5025, 0.5120, 0.5089, 0.5091, 0.5064, 0.5037, 0.5119, 0.5020,
        0.5064, 0.5024, 0.5095, 0.5041, 0.5003, 0.5016, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.4998, 0.4838, 0.4892, 0.4873, 0.4967, 0.4960, 0.4842, 0.4978,
        0.4980, 0.5006, 0.4869, 0.5000, 0.5013, 0.4967, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.5270, 0.5166, 0.4874, 0.4944, 0.4867, 0.5372, 0.5007, 0.4742, 0.5125,
        0.5062, 0.5254, 0.4863, 0.5313, 0.5255, 0.5076, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.6781, 0.6773, 0.6783, 0.7031, 0.6802, 0.7925, 0.6433, 0.7788, 0.6646,
        0.7079, 0.6900, 0.6517, 0.7177, 0.6941, 0.6973, 0.8234],
       device='cuda:0') torch.Size([16])
Epoch: 7 | Batch_idx: 0 |  Loss: (1.3499) |  Loss2: (0.0000) | Acc: (51.00%) (66/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.3315) |  Loss2: (0.0000) | Acc: (52.00%) (737/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.3416) |  Loss2: (0.0000) | Acc: (52.00%) (1402/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.3515) |  Loss2: (0.0000) | Acc: (51.00%) (2052/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.3540) |  Loss2: (0.0000) | Acc: (51.00%) (2698/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.3674) |  Loss2: (0.0000) | Acc: (50.00%) (3307/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.3579) |  Loss2: (0.0000) | Acc: (50.00%) (3968/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.3660) |  Loss2: (0.0000) | Acc: (50.00%) (4583/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.3697) |  Loss2: (0.0000) | Acc: (50.00%) (5208/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.3659) |  Loss2: (0.0000) | Acc: (50.00%) (5862/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (1.3612) |  Loss2: (0.0000) | Acc: (50.00%) (6529/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (1.3578) |  Loss2: (0.0000) | Acc: (50.00%) (7164/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (1.3596) |  Loss2: (0.0000) | Acc: (50.00%) (7818/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (1.3599) |  Loss2: (0.0000) | Acc: (50.00%) (8455/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (1.3601) |  Loss2: (0.0000) | Acc: (50.00%) (9096/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (1.3618) |  Loss2: (0.0000) | Acc: (50.00%) (9724/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (1.3596) |  Loss2: (0.0000) | Acc: (50.00%) (10400/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (1.3582) |  Loss2: (0.0000) | Acc: (50.00%) (11051/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (1.3570) |  Loss2: (0.0000) | Acc: (50.00%) (11722/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (1.3567) |  Loss2: (0.0000) | Acc: (50.00%) (12363/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (1.3558) |  Loss2: (0.0000) | Acc: (50.00%) (13022/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (1.3556) |  Loss2: (0.0000) | Acc: (50.00%) (13668/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (1.3564) |  Loss2: (0.0000) | Acc: (50.00%) (14299/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (1.3571) |  Loss2: (0.0000) | Acc: (50.00%) (14949/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (1.3553) |  Loss2: (0.0000) | Acc: (50.00%) (15615/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (1.3542) |  Loss2: (0.0000) | Acc: (50.00%) (16273/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (1.3519) |  Loss2: (0.0000) | Acc: (50.00%) (16956/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (1.3513) |  Loss2: (0.0000) | Acc: (50.00%) (17614/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (1.3494) |  Loss2: (0.0000) | Acc: (50.00%) (18281/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (1.3474) |  Loss2: (0.0000) | Acc: (50.00%) (18970/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (1.3485) |  Loss2: (0.0000) | Acc: (50.00%) (19585/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (1.3508) |  Loss2: (0.0000) | Acc: (50.00%) (20185/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (1.3525) |  Loss2: (0.0000) | Acc: (50.00%) (20807/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (1.3547) |  Loss2: (0.0000) | Acc: (50.00%) (21434/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (1.3557) |  Loss2: (0.0000) | Acc: (50.00%) (22057/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (1.3548) |  Loss2: (0.0000) | Acc: (50.00%) (22723/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (1.3538) |  Loss2: (0.0000) | Acc: (50.00%) (23383/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (1.3526) |  Loss2: (0.0000) | Acc: (50.00%) (24062/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (1.3525) |  Loss2: (0.0000) | Acc: (50.00%) (24706/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (1.3518) |  Loss2: (0.0000) | Acc: (50.00%) (25341/50000)
# TEST : Loss: (1.3221) | Acc: (51.00%) (5145/10000)
percent tensor([0.5026, 0.4885, 0.5061, 0.5033, 0.5034, 0.5035, 0.4951, 0.5006, 0.4964,
        0.4977, 0.4959, 0.5036, 0.4992, 0.4801, 0.4985, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.4942, 0.4892, 0.4971, 0.4950, 0.4957, 0.4958, 0.4914, 0.4942, 0.4912,
        0.4920, 0.4909, 0.4951, 0.4928, 0.4879, 0.4925, 0.4940],
       device='cuda:0') torch.Size([16])
percent tensor([0.4766, 0.4757, 0.4703, 0.4836, 0.4718, 0.4777, 0.4740, 0.4762, 0.4780,
        0.4748, 0.4752, 0.4710, 0.4761, 0.4843, 0.4779, 0.4771],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.4961, 0.4920, 0.4970, 0.4920, 0.4977, 0.4928, 0.4922, 0.4949,
        0.4937, 0.4954, 0.4905, 0.4962, 0.4981, 0.4961, 0.4963],
       device='cuda:0') torch.Size([16])
percent tensor([0.5067, 0.5049, 0.5191, 0.5146, 0.5145, 0.5109, 0.5069, 0.5188, 0.5045,
        0.5104, 0.5047, 0.5154, 0.5070, 0.5022, 0.5040, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.4979, 0.4989, 0.4793, 0.4861, 0.4834, 0.4956, 0.4942, 0.4787, 0.4968,
        0.4965, 0.4999, 0.4838, 0.4994, 0.5007, 0.4949, 0.4957],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.5191, 0.4871, 0.4945, 0.4859, 0.5445, 0.5012, 0.4716, 0.5164,
        0.5083, 0.5303, 0.4874, 0.5372, 0.5295, 0.5095, 0.5207],
       device='cuda:0') torch.Size([16])
percent tensor([0.7450, 0.7433, 0.7487, 0.7839, 0.7518, 0.8693, 0.7021, 0.8505, 0.7332,
        0.7810, 0.7668, 0.7092, 0.7940, 0.7605, 0.7645, 0.8969],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 8 | Batch_idx: 0 |  Loss: (1.2315) |  Loss2: (0.0000) | Acc: (54.00%) (70/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (1.3191) |  Loss2: (0.0000) | Acc: (51.00%) (728/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (1.3217) |  Loss2: (0.0000) | Acc: (51.00%) (1387/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (1.3327) |  Loss2: (0.0000) | Acc: (51.00%) (2040/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (1.3211) |  Loss2: (0.0000) | Acc: (51.00%) (2716/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (1.3149) |  Loss2: (0.0000) | Acc: (52.00%) (3412/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (1.3144) |  Loss2: (0.0000) | Acc: (52.00%) (4075/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (1.3129) |  Loss2: (0.0000) | Acc: (52.00%) (4734/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (1.3063) |  Loss2: (0.0000) | Acc: (52.00%) (5409/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (1.3029) |  Loss2: (0.0000) | Acc: (52.00%) (6123/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (1.3004) |  Loss2: (0.0000) | Acc: (52.00%) (6795/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (1.2997) |  Loss2: (0.0000) | Acc: (52.00%) (7460/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (1.2985) |  Loss2: (0.0000) | Acc: (52.00%) (8132/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (1.2957) |  Loss2: (0.0000) | Acc: (52.00%) (8827/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (1.2904) |  Loss2: (0.0000) | Acc: (52.00%) (9529/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (1.2842) |  Loss2: (0.0000) | Acc: (53.00%) (10261/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (1.2819) |  Loss2: (0.0000) | Acc: (53.00%) (10973/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (1.2796) |  Loss2: (0.0000) | Acc: (53.00%) (11697/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (1.2801) |  Loss2: (0.0000) | Acc: (53.00%) (12371/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (1.2770) |  Loss2: (0.0000) | Acc: (53.00%) (13086/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (1.2741) |  Loss2: (0.0000) | Acc: (53.00%) (13791/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (1.2709) |  Loss2: (0.0000) | Acc: (53.00%) (14491/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (1.2693) |  Loss2: (0.0000) | Acc: (53.00%) (15213/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (1.2656) |  Loss2: (0.0000) | Acc: (53.00%) (15953/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (1.2638) |  Loss2: (0.0000) | Acc: (53.00%) (16655/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (1.2615) |  Loss2: (0.0000) | Acc: (54.00%) (17384/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (1.2580) |  Loss2: (0.0000) | Acc: (54.00%) (18119/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (1.2560) |  Loss2: (0.0000) | Acc: (54.00%) (18831/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (1.2540) |  Loss2: (0.0000) | Acc: (54.00%) (19564/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (1.2511) |  Loss2: (0.0000) | Acc: (54.00%) (20302/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (1.2502) |  Loss2: (0.0000) | Acc: (54.00%) (21018/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (1.2482) |  Loss2: (0.0000) | Acc: (54.00%) (21748/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (1.2448) |  Loss2: (0.0000) | Acc: (54.00%) (22511/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (1.2440) |  Loss2: (0.0000) | Acc: (54.00%) (23226/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (1.2426) |  Loss2: (0.0000) | Acc: (54.00%) (23963/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (1.2423) |  Loss2: (0.0000) | Acc: (54.00%) (24663/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (1.2411) |  Loss2: (0.0000) | Acc: (54.00%) (25354/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (1.2395) |  Loss2: (0.0000) | Acc: (54.00%) (26102/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (1.2388) |  Loss2: (0.0000) | Acc: (54.00%) (26819/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (1.2389) |  Loss2: (0.0000) | Acc: (55.00%) (27508/50000)
# TEST : Loss: (1.2249) | Acc: (56.00%) (5601/10000)
percent tensor([0.5028, 0.4890, 0.5061, 0.5041, 0.5039, 0.5046, 0.4951, 0.5009, 0.4957,
        0.4972, 0.4953, 0.5036, 0.4990, 0.4827, 0.4991, 0.4999],
       device='cuda:0') torch.Size([16])
percent tensor([0.4934, 0.4895, 0.4954, 0.4941, 0.4945, 0.4954, 0.4911, 0.4937, 0.4913,
        0.4912, 0.4908, 0.4938, 0.4921, 0.4888, 0.4921, 0.4937],
       device='cuda:0') torch.Size([16])
percent tensor([0.4770, 0.4722, 0.4750, 0.4855, 0.4763, 0.4811, 0.4725, 0.4764, 0.4795,
        0.4714, 0.4726, 0.4729, 0.4748, 0.4834, 0.4763, 0.4766],
       device='cuda:0') torch.Size([16])
percent tensor([0.4965, 0.4953, 0.4935, 0.4973, 0.4940, 0.4978, 0.4932, 0.4927, 0.4952,
        0.4936, 0.4951, 0.4920, 0.4954, 0.4968, 0.4950, 0.4961],
       device='cuda:0') torch.Size([16])
percent tensor([0.5065, 0.5041, 0.5191, 0.5160, 0.5133, 0.5126, 0.5069, 0.5155, 0.5060,
        0.5092, 0.5052, 0.5154, 0.5068, 0.5024, 0.5046, 0.5074],
       device='cuda:0') torch.Size([16])
percent tensor([0.4970, 0.4967, 0.4824, 0.4884, 0.4850, 0.4950, 0.4951, 0.4800, 0.4984,
        0.4951, 0.4983, 0.4868, 0.4992, 0.5012, 0.4916, 0.4944],
       device='cuda:0') torch.Size([16])
percent tensor([0.5264, 0.5131, 0.4883, 0.4970, 0.4853, 0.5409, 0.5032, 0.4720, 0.5224,
        0.5063, 0.5251, 0.4940, 0.5362, 0.5279, 0.5072, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.7713, 0.7507, 0.7549, 0.7784, 0.7590, 0.8735, 0.7813, 0.8386, 0.7512,
        0.7777, 0.7507, 0.7339, 0.7752, 0.7693, 0.8114, 0.9048],
       device='cuda:0') torch.Size([16])
Epoch: 9 | Batch_idx: 0 |  Loss: (1.2575) |  Loss2: (0.0000) | Acc: (53.00%) (69/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (1.1540) |  Loss2: (0.0000) | Acc: (58.00%) (819/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (1.1850) |  Loss2: (0.0000) | Acc: (56.00%) (1526/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (1.1950) |  Loss2: (0.0000) | Acc: (56.00%) (2245/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (1.1896) |  Loss2: (0.0000) | Acc: (56.00%) (2990/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (1.1857) |  Loss2: (0.0000) | Acc: (57.00%) (3740/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (1.1737) |  Loss2: (0.0000) | Acc: (57.00%) (4506/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (1.1676) |  Loss2: (0.0000) | Acc: (57.00%) (5270/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (1.1703) |  Loss2: (0.0000) | Acc: (58.00%) (6015/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (1.1747) |  Loss2: (0.0000) | Acc: (57.00%) (6724/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (1.1719) |  Loss2: (0.0000) | Acc: (57.00%) (7470/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (1.1630) |  Loss2: (0.0000) | Acc: (58.00%) (8275/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (1.1598) |  Loss2: (0.0000) | Acc: (58.00%) (9044/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (1.1606) |  Loss2: (0.0000) | Acc: (58.00%) (9765/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (1.1588) |  Loss2: (0.0000) | Acc: (58.00%) (10525/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (1.1574) |  Loss2: (0.0000) | Acc: (58.00%) (11256/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (1.1529) |  Loss2: (0.0000) | Acc: (58.00%) (12040/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (1.1543) |  Loss2: (0.0000) | Acc: (58.00%) (12809/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (1.1530) |  Loss2: (0.0000) | Acc: (58.00%) (13571/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (1.1523) |  Loss2: (0.0000) | Acc: (58.00%) (14331/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (1.1495) |  Loss2: (0.0000) | Acc: (58.00%) (15127/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (1.1485) |  Loss2: (0.0000) | Acc: (58.00%) (15904/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (1.1472) |  Loss2: (0.0000) | Acc: (58.00%) (16670/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (1.1463) |  Loss2: (0.0000) | Acc: (58.00%) (17441/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (1.1452) |  Loss2: (0.0000) | Acc: (59.00%) (18207/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (1.1424) |  Loss2: (0.0000) | Acc: (59.00%) (18992/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (1.1426) |  Loss2: (0.0000) | Acc: (59.00%) (19719/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (1.1404) |  Loss2: (0.0000) | Acc: (59.00%) (20519/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (1.1412) |  Loss2: (0.0000) | Acc: (59.00%) (21281/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (1.1399) |  Loss2: (0.0000) | Acc: (59.00%) (22048/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (1.1365) |  Loss2: (0.0000) | Acc: (59.00%) (22857/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (1.1346) |  Loss2: (0.0000) | Acc: (59.00%) (23628/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (1.1332) |  Loss2: (0.0000) | Acc: (59.00%) (24415/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (1.1311) |  Loss2: (0.0000) | Acc: (59.00%) (25217/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (1.1295) |  Loss2: (0.0000) | Acc: (59.00%) (26009/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (1.1282) |  Loss2: (0.0000) | Acc: (59.00%) (26805/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (1.1267) |  Loss2: (0.0000) | Acc: (59.00%) (27584/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (1.1251) |  Loss2: (0.0000) | Acc: (59.00%) (28373/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (1.1237) |  Loss2: (0.0000) | Acc: (59.00%) (29159/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (1.1231) |  Loss2: (0.0000) | Acc: (59.00%) (29895/50000)
# TEST : Loss: (1.2919) | Acc: (53.00%) (5330/10000)
percent tensor([0.5032, 0.4902, 0.5065, 0.5045, 0.5050, 0.5052, 0.4959, 0.5012, 0.4965,
        0.4975, 0.4956, 0.5041, 0.4993, 0.4846, 0.4997, 0.5007],
       device='cuda:0') torch.Size([16])
percent tensor([0.4939, 0.4902, 0.4960, 0.4945, 0.4952, 0.4967, 0.4922, 0.4943, 0.4922,
        0.4918, 0.4915, 0.4943, 0.4928, 0.4900, 0.4926, 0.4944],
       device='cuda:0') torch.Size([16])
percent tensor([0.4784, 0.4744, 0.4737, 0.4849, 0.4761, 0.4830, 0.4749, 0.4766, 0.4802,
        0.4712, 0.4739, 0.4710, 0.4751, 0.4850, 0.4773, 0.4783],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.4956, 0.4935, 0.4973, 0.4949, 0.4978, 0.4934, 0.4936, 0.4953,
        0.4937, 0.4953, 0.4920, 0.4952, 0.4969, 0.4952, 0.4963],
       device='cuda:0') torch.Size([16])
percent tensor([0.5073, 0.5055, 0.5197, 0.5194, 0.5149, 0.5131, 0.5078, 0.5172, 0.5050,
        0.5091, 0.5054, 0.5147, 0.5065, 0.5058, 0.5055, 0.5085],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.4975, 0.4855, 0.4903, 0.4877, 0.4950, 0.4950, 0.4835, 0.4983,
        0.4962, 0.4992, 0.4884, 0.4996, 0.5011, 0.4946, 0.4955],
       device='cuda:0') torch.Size([16])
percent tensor([0.5350, 0.5179, 0.4919, 0.5013, 0.4910, 0.5417, 0.5106, 0.4824, 0.5244,
        0.5157, 0.5332, 0.4984, 0.5424, 0.5299, 0.5158, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.8468, 0.7591, 0.7341, 0.7678, 0.7433, 0.8862, 0.8060, 0.8479, 0.7343,
        0.7825, 0.7648, 0.7161, 0.7756, 0.7704, 0.8364, 0.9126],
       device='cuda:0') torch.Size([16])
Epoch: 10 | Batch_idx: 0 |  Loss: (1.1566) |  Loss2: (0.0000) | Acc: (58.00%) (75/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (1.0967) |  Loss2: (0.0000) | Acc: (59.00%) (837/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (1.0744) |  Loss2: (0.0000) | Acc: (61.00%) (1659/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (1.0796) |  Loss2: (0.0000) | Acc: (62.00%) (2465/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (1.0835) |  Loss2: (0.0000) | Acc: (61.00%) (3232/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (1.0755) |  Loss2: (0.0000) | Acc: (61.00%) (4038/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (1.0714) |  Loss2: (0.0000) | Acc: (61.00%) (4833/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (1.0667) |  Loss2: (0.0000) | Acc: (62.00%) (5649/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (1.0631) |  Loss2: (0.0000) | Acc: (62.00%) (6447/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (1.0645) |  Loss2: (0.0000) | Acc: (62.00%) (7229/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (1.0606) |  Loss2: (0.0000) | Acc: (62.00%) (8042/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (1.0564) |  Loss2: (0.0000) | Acc: (62.00%) (8861/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (1.0615) |  Loss2: (0.0000) | Acc: (62.00%) (9623/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (1.0636) |  Loss2: (0.0000) | Acc: (61.00%) (10393/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (1.0609) |  Loss2: (0.0000) | Acc: (62.00%) (11215/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (1.0612) |  Loss2: (0.0000) | Acc: (62.00%) (12007/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (1.0600) |  Loss2: (0.0000) | Acc: (62.00%) (12809/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (1.0600) |  Loss2: (0.0000) | Acc: (62.00%) (13605/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (1.0583) |  Loss2: (0.0000) | Acc: (62.00%) (14415/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (1.0590) |  Loss2: (0.0000) | Acc: (62.00%) (15216/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (1.0582) |  Loss2: (0.0000) | Acc: (62.00%) (16005/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (1.0589) |  Loss2: (0.0000) | Acc: (62.00%) (16784/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (1.0563) |  Loss2: (0.0000) | Acc: (62.00%) (17611/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (1.0544) |  Loss2: (0.0000) | Acc: (62.00%) (18451/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (1.0525) |  Loss2: (0.0000) | Acc: (62.00%) (19265/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (1.0497) |  Loss2: (0.0000) | Acc: (62.00%) (20087/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (1.0480) |  Loss2: (0.0000) | Acc: (62.00%) (20911/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (1.0474) |  Loss2: (0.0000) | Acc: (62.00%) (21736/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (1.0448) |  Loss2: (0.0000) | Acc: (62.00%) (22563/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (1.0444) |  Loss2: (0.0000) | Acc: (62.00%) (23367/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (1.0446) |  Loss2: (0.0000) | Acc: (62.00%) (24184/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (1.0439) |  Loss2: (0.0000) | Acc: (62.00%) (25012/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (1.0431) |  Loss2: (0.0000) | Acc: (62.00%) (25825/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (1.0435) |  Loss2: (0.0000) | Acc: (62.00%) (26635/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (1.0427) |  Loss2: (0.0000) | Acc: (62.00%) (27473/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (1.0416) |  Loss2: (0.0000) | Acc: (62.00%) (28298/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (1.0404) |  Loss2: (0.0000) | Acc: (63.00%) (29117/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (1.0388) |  Loss2: (0.0000) | Acc: (63.00%) (29962/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (1.0374) |  Loss2: (0.0000) | Acc: (63.00%) (30785/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (1.0358) |  Loss2: (0.0000) | Acc: (63.00%) (31600/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_010.pth.tar'
# TEST : Loss: (1.1859) | Acc: (58.00%) (5807/10000)
percent tensor([0.5023, 0.4896, 0.5054, 0.5041, 0.5040, 0.5044, 0.4951, 0.5008, 0.4955,
        0.4971, 0.4946, 0.5029, 0.4986, 0.4842, 0.4994, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.4934, 0.4902, 0.4953, 0.4942, 0.4946, 0.4962, 0.4919, 0.4940, 0.4918,
        0.4913, 0.4912, 0.4937, 0.4924, 0.4902, 0.4925, 0.4941],
       device='cuda:0') torch.Size([16])
percent tensor([0.4779, 0.4739, 0.4737, 0.4853, 0.4765, 0.4832, 0.4745, 0.4771, 0.4790,
        0.4726, 0.4732, 0.4709, 0.4743, 0.4849, 0.4777, 0.4788],
       device='cuda:0') torch.Size([16])
percent tensor([0.4965, 0.4951, 0.4940, 0.4969, 0.4950, 0.4978, 0.4932, 0.4941, 0.4951,
        0.4936, 0.4951, 0.4924, 0.4952, 0.4965, 0.4949, 0.4965],
       device='cuda:0') torch.Size([16])
percent tensor([0.5083, 0.5055, 0.5185, 0.5176, 0.5139, 0.5139, 0.5071, 0.5159, 0.5050,
        0.5082, 0.5056, 0.5143, 0.5068, 0.5031, 0.5064, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4974, 0.4854, 0.4897, 0.4887, 0.4945, 0.4946, 0.4834, 0.4974,
        0.4967, 0.4982, 0.4875, 0.4986, 0.5005, 0.4937, 0.4966],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.5208, 0.4972, 0.5019, 0.4978, 0.5421, 0.5115, 0.4865, 0.5231,
        0.5190, 0.5284, 0.5054, 0.5423, 0.5263, 0.5153, 0.5282],
       device='cuda:0') torch.Size([16])
percent tensor([0.8378, 0.7125, 0.7531, 0.7616, 0.7614, 0.8647, 0.7410, 0.7923, 0.7539,
        0.7688, 0.7385, 0.7538, 0.7800, 0.7395, 0.7504, 0.8743],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(165.3138, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(776.4222, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(773.2694, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.7517, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(511.3250, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2167.1978, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4326.2534, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1445.4863, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6107.8169, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12229.8594, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4084.1306, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17274.7168, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 11 | Batch_idx: 0 |  Loss: (1.0163) |  Loss2: (0.0000) | Acc: (64.00%) (83/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (1.0026) |  Loss2: (0.0000) | Acc: (65.00%) (922/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (0.9883) |  Loss2: (0.0000) | Acc: (65.00%) (1752/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (0.9933) |  Loss2: (0.0000) | Acc: (65.00%) (2581/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (0.9970) |  Loss2: (0.0000) | Acc: (64.00%) (3387/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (0.9935) |  Loss2: (0.0000) | Acc: (64.00%) (4212/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (0.9961) |  Loss2: (0.0000) | Acc: (64.00%) (5022/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (0.9956) |  Loss2: (0.0000) | Acc: (64.00%) (5847/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (0.9949) |  Loss2: (0.0000) | Acc: (64.00%) (6671/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (0.9971) |  Loss2: (0.0000) | Acc: (64.00%) (7484/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (0.9924) |  Loss2: (0.0000) | Acc: (64.00%) (8347/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (0.9978) |  Loss2: (0.0000) | Acc: (64.00%) (9137/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (0.9949) |  Loss2: (0.0000) | Acc: (64.00%) (9974/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (0.9923) |  Loss2: (0.0000) | Acc: (64.00%) (10822/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (0.9886) |  Loss2: (0.0000) | Acc: (64.00%) (11672/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (0.9879) |  Loss2: (0.0000) | Acc: (64.00%) (12515/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (0.9875) |  Loss2: (0.0000) | Acc: (64.00%) (13353/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (0.9849) |  Loss2: (0.0000) | Acc: (64.00%) (14216/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (0.9826) |  Loss2: (0.0000) | Acc: (65.00%) (15062/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (0.9821) |  Loss2: (0.0000) | Acc: (64.00%) (15880/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (0.9831) |  Loss2: (0.0000) | Acc: (64.00%) (16705/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (0.9852) |  Loss2: (0.0000) | Acc: (64.00%) (17516/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (0.9860) |  Loss2: (0.0000) | Acc: (64.00%) (18332/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (0.9839) |  Loss2: (0.0000) | Acc: (64.00%) (19199/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (0.9824) |  Loss2: (0.0000) | Acc: (65.00%) (20057/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (0.9821) |  Loss2: (0.0000) | Acc: (65.00%) (20893/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (0.9821) |  Loss2: (0.0000) | Acc: (65.00%) (21730/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (0.9815) |  Loss2: (0.0000) | Acc: (65.00%) (22564/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (0.9801) |  Loss2: (0.0000) | Acc: (65.00%) (23423/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (0.9797) |  Loss2: (0.0000) | Acc: (65.00%) (24268/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (0.9788) |  Loss2: (0.0000) | Acc: (65.00%) (25098/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (0.9790) |  Loss2: (0.0000) | Acc: (65.00%) (25909/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (0.9767) |  Loss2: (0.0000) | Acc: (65.00%) (26767/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (0.9762) |  Loss2: (0.0000) | Acc: (65.00%) (27598/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (0.9765) |  Loss2: (0.0000) | Acc: (65.00%) (28424/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (0.9756) |  Loss2: (0.0000) | Acc: (65.00%) (29284/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (0.9727) |  Loss2: (0.0000) | Acc: (65.00%) (30189/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (0.9708) |  Loss2: (0.0000) | Acc: (65.00%) (31049/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (0.9697) |  Loss2: (0.0000) | Acc: (65.00%) (31918/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (0.9687) |  Loss2: (0.0000) | Acc: (65.00%) (32750/50000)
# TEST : Loss: (1.0694) | Acc: (62.00%) (6229/10000)
percent tensor([0.5030, 0.4894, 0.5059, 0.5042, 0.5045, 0.5050, 0.4951, 0.5007, 0.4954,
        0.4971, 0.4948, 0.5033, 0.4990, 0.4839, 0.4995, 0.5003],
       device='cuda:0') torch.Size([16])
percent tensor([0.4936, 0.4904, 0.4950, 0.4942, 0.4946, 0.4961, 0.4920, 0.4941, 0.4918,
        0.4916, 0.4915, 0.4937, 0.4926, 0.4904, 0.4924, 0.4941],
       device='cuda:0') torch.Size([16])
percent tensor([0.4770, 0.4734, 0.4743, 0.4835, 0.4760, 0.4821, 0.4733, 0.4762, 0.4789,
        0.4710, 0.4735, 0.4693, 0.4735, 0.4834, 0.4767, 0.4772],
       device='cuda:0') torch.Size([16])
percent tensor([0.4964, 0.4951, 0.4929, 0.4962, 0.4939, 0.4978, 0.4924, 0.4936, 0.4950,
        0.4935, 0.4950, 0.4916, 0.4954, 0.4967, 0.4946, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.5054, 0.5174, 0.5199, 0.5128, 0.5148, 0.5076, 0.5138, 0.5049,
        0.5084, 0.5056, 0.5131, 0.5063, 0.5044, 0.5062, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4964, 0.4831, 0.4878, 0.4856, 0.4940, 0.4932, 0.4808, 0.4970,
        0.4942, 0.4981, 0.4857, 0.4985, 0.5007, 0.4926, 0.4956],
       device='cuda:0') torch.Size([16])
percent tensor([0.5343, 0.5104, 0.4868, 0.4964, 0.4870, 0.5350, 0.4991, 0.4762, 0.5140,
        0.5049, 0.5186, 0.4922, 0.5374, 0.5199, 0.5033, 0.5185],
       device='cuda:0') torch.Size([16])
percent tensor([0.8488, 0.7454, 0.7807, 0.7795, 0.7824, 0.8264, 0.7701, 0.8296, 0.7377,
        0.7930, 0.7580, 0.7878, 0.7670, 0.7464, 0.7508, 0.8518],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 12 | Batch_idx: 0 |  Loss: (0.9479) |  Loss2: (0.0000) | Acc: (63.00%) (81/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (1.1251) |  Loss2: (0.0000) | Acc: (59.00%) (841/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (1.1945) |  Loss2: (0.0000) | Acc: (57.00%) (1538/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (1.2002) |  Loss2: (0.0000) | Acc: (57.00%) (2268/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (1.2265) |  Loss2: (0.0000) | Acc: (56.00%) (2982/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (1.2412) |  Loss2: (0.0000) | Acc: (56.00%) (3684/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (1.2436) |  Loss2: (0.0000) | Acc: (56.00%) (4400/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (1.2465) |  Loss2: (0.0000) | Acc: (56.00%) (5098/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (1.2441) |  Loss2: (0.0000) | Acc: (56.00%) (5815/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (1.2417) |  Loss2: (0.0000) | Acc: (55.00%) (6520/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (1.2388) |  Loss2: (0.0000) | Acc: (56.00%) (7241/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (1.2406) |  Loss2: (0.0000) | Acc: (55.00%) (7936/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (1.2329) |  Loss2: (0.0000) | Acc: (56.00%) (8695/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (1.2302) |  Loss2: (0.0000) | Acc: (56.00%) (9427/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (1.2266) |  Loss2: (0.0000) | Acc: (56.00%) (10183/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (1.2222) |  Loss2: (0.0000) | Acc: (56.00%) (10943/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (1.2135) |  Loss2: (0.0000) | Acc: (56.00%) (11732/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (1.2083) |  Loss2: (0.0000) | Acc: (57.00%) (12490/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (1.2023) |  Loss2: (0.0000) | Acc: (57.00%) (13254/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (1.1988) |  Loss2: (0.0000) | Acc: (57.00%) (14015/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (1.1948) |  Loss2: (0.0000) | Acc: (57.00%) (14797/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (1.1905) |  Loss2: (0.0000) | Acc: (57.00%) (15573/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (1.1869) |  Loss2: (0.0000) | Acc: (57.00%) (16343/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (1.1867) |  Loss2: (0.0000) | Acc: (57.00%) (17092/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (1.1832) |  Loss2: (0.0000) | Acc: (57.00%) (17881/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (1.1780) |  Loss2: (0.0000) | Acc: (58.00%) (18668/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (1.1753) |  Loss2: (0.0000) | Acc: (58.00%) (19437/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (1.1724) |  Loss2: (0.0000) | Acc: (58.00%) (20219/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (1.1704) |  Loss2: (0.0000) | Acc: (58.00%) (20979/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (1.1677) |  Loss2: (0.0000) | Acc: (58.00%) (21773/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (1.1642) |  Loss2: (0.0000) | Acc: (58.00%) (22570/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (1.1610) |  Loss2: (0.0000) | Acc: (58.00%) (23359/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (1.1581) |  Loss2: (0.0000) | Acc: (58.00%) (24152/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (1.1568) |  Loss2: (0.0000) | Acc: (58.00%) (24922/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (1.1542) |  Loss2: (0.0000) | Acc: (58.00%) (25704/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (1.1512) |  Loss2: (0.0000) | Acc: (58.00%) (26495/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (1.1483) |  Loss2: (0.0000) | Acc: (59.00%) (27297/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (1.1453) |  Loss2: (0.0000) | Acc: (59.00%) (28103/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (1.1436) |  Loss2: (0.0000) | Acc: (59.00%) (28906/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (1.1405) |  Loss2: (0.0000) | Acc: (59.00%) (29674/50000)
# TEST : Loss: (1.0378) | Acc: (62.00%) (6292/10000)
percent tensor([0.5069, 0.5012, 0.5111, 0.5084, 0.5107, 0.5084, 0.5052, 0.5073, 0.5051,
        0.5051, 0.5037, 0.5096, 0.5047, 0.4981, 0.5055, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.4881, 0.4866, 0.4862, 0.4879, 0.4871, 0.4913, 0.4867, 0.4879, 0.4877,
        0.4862, 0.4881, 0.4856, 0.4879, 0.4882, 0.4872, 0.4897],
       device='cuda:0') torch.Size([16])
percent tensor([0.4812, 0.4703, 0.4708, 0.4894, 0.4754, 0.4915, 0.4678, 0.4754, 0.4803,
        0.4681, 0.4748, 0.4617, 0.4758, 0.4843, 0.4758, 0.4807],
       device='cuda:0') torch.Size([16])
percent tensor([0.4948, 0.4949, 0.4934, 0.4971, 0.4950, 0.4967, 0.4931, 0.4949, 0.4943,
        0.4936, 0.4944, 0.4920, 0.4939, 0.4960, 0.4941, 0.4955],
       device='cuda:0') torch.Size([16])
percent tensor([0.5423, 0.5439, 0.5721, 0.5767, 0.5623, 0.5553, 0.5545, 0.5672, 0.5363,
        0.5569, 0.5402, 0.5752, 0.5401, 0.5277, 0.5469, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.5038, 0.5008, 0.4907, 0.4950, 0.4940, 0.5022, 0.4983, 0.4909, 0.5011,
        0.4997, 0.5011, 0.4896, 0.5030, 0.5045, 0.4984, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5473, 0.5162, 0.5064, 0.5178, 0.5042, 0.5485, 0.5163, 0.5080, 0.5169,
        0.5220, 0.5215, 0.5088, 0.5375, 0.5252, 0.5180, 0.5397],
       device='cuda:0') torch.Size([16])
percent tensor([0.8342, 0.7154, 0.7692, 0.7760, 0.7520, 0.8022, 0.7559, 0.8323, 0.6982,
        0.7595, 0.7107, 0.7898, 0.7241, 0.7029, 0.7710, 0.8417],
       device='cuda:0') torch.Size([16])
Epoch: 13 | Batch_idx: 0 |  Loss: (0.9385) |  Loss2: (0.0000) | Acc: (67.00%) (86/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (1.0159) |  Loss2: (0.0000) | Acc: (63.00%) (900/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (1.0229) |  Loss2: (0.0000) | Acc: (64.00%) (1725/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (1.0255) |  Loss2: (0.0000) | Acc: (63.00%) (2520/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (1.0171) |  Loss2: (0.0000) | Acc: (63.00%) (3354/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (1.0215) |  Loss2: (0.0000) | Acc: (63.00%) (4145/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (1.0227) |  Loss2: (0.0000) | Acc: (63.00%) (4937/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (1.0248) |  Loss2: (0.0000) | Acc: (63.00%) (5767/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (1.0208) |  Loss2: (0.0000) | Acc: (63.00%) (6616/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (1.0191) |  Loss2: (0.0000) | Acc: (63.00%) (7423/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (1.0172) |  Loss2: (0.0000) | Acc: (63.00%) (8247/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (1.0183) |  Loss2: (0.0000) | Acc: (63.00%) (9056/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (1.0147) |  Loss2: (0.0000) | Acc: (63.00%) (9892/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (1.0107) |  Loss2: (0.0000) | Acc: (64.00%) (10745/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (1.0115) |  Loss2: (0.0000) | Acc: (64.00%) (11571/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (1.0135) |  Loss2: (0.0000) | Acc: (63.00%) (12369/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (1.0115) |  Loss2: (0.0000) | Acc: (64.00%) (13193/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (1.0142) |  Loss2: (0.0000) | Acc: (63.00%) (13982/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (1.0147) |  Loss2: (0.0000) | Acc: (63.00%) (14810/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (1.0132) |  Loss2: (0.0000) | Acc: (64.00%) (15655/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (1.0139) |  Loss2: (0.0000) | Acc: (64.00%) (16466/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (1.0113) |  Loss2: (0.0000) | Acc: (64.00%) (17316/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (1.0088) |  Loss2: (0.0000) | Acc: (64.00%) (18161/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (1.0065) |  Loss2: (0.0000) | Acc: (64.00%) (18994/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (1.0055) |  Loss2: (0.0000) | Acc: (64.00%) (19827/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (1.0039) |  Loss2: (0.0000) | Acc: (64.00%) (20665/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (1.0039) |  Loss2: (0.0000) | Acc: (64.00%) (21493/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (1.0042) |  Loss2: (0.0000) | Acc: (64.00%) (22305/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (1.0041) |  Loss2: (0.0000) | Acc: (64.00%) (23139/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (1.0026) |  Loss2: (0.0000) | Acc: (64.00%) (23997/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (1.0031) |  Loss2: (0.0000) | Acc: (64.00%) (24798/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (1.0034) |  Loss2: (0.0000) | Acc: (64.00%) (25643/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (1.0033) |  Loss2: (0.0000) | Acc: (64.00%) (26463/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (1.0030) |  Loss2: (0.0000) | Acc: (64.00%) (27280/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (1.0022) |  Loss2: (0.0000) | Acc: (64.00%) (28116/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (1.0026) |  Loss2: (0.0000) | Acc: (64.00%) (28944/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (1.0031) |  Loss2: (0.0000) | Acc: (64.00%) (29742/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (1.0037) |  Loss2: (0.0000) | Acc: (64.00%) (30570/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (1.0038) |  Loss2: (0.0000) | Acc: (64.00%) (31372/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (1.0030) |  Loss2: (0.0000) | Acc: (64.00%) (32164/50000)
# TEST : Loss: (0.9846) | Acc: (64.00%) (6493/10000)
percent tensor([0.5090, 0.5072, 0.5134, 0.5101, 0.5137, 0.5097, 0.5103, 0.5108, 0.5107,
        0.5091, 0.5084, 0.5127, 0.5080, 0.5063, 0.5083, 0.5075],
       device='cuda:0') torch.Size([16])
percent tensor([0.4842, 0.4835, 0.4800, 0.4836, 0.4817, 0.4875, 0.4825, 0.4833, 0.4842,
        0.4818, 0.4852, 0.4796, 0.4842, 0.4867, 0.4831, 0.4862],
       device='cuda:0') torch.Size([16])
percent tensor([0.4796, 0.4640, 0.4555, 0.4868, 0.4641, 0.4943, 0.4578, 0.4653, 0.4778,
        0.4585, 0.4734, 0.4435, 0.4724, 0.4859, 0.4698, 0.4790],
       device='cuda:0') torch.Size([16])
percent tensor([0.4940, 0.4953, 0.4940, 0.4977, 0.4956, 0.4965, 0.4937, 0.4953, 0.4948,
        0.4935, 0.4946, 0.4921, 0.4934, 0.4965, 0.4941, 0.4951],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.5572, 0.5978, 0.6048, 0.5862, 0.5786, 0.5732, 0.5946, 0.5479,
        0.5739, 0.5523, 0.5977, 0.5512, 0.5380, 0.5656, 0.5639],
       device='cuda:0') torch.Size([16])
percent tensor([0.5031, 0.4977, 0.4871, 0.4954, 0.4919, 0.5053, 0.4951, 0.4859, 0.4989,
        0.4960, 0.4980, 0.4854, 0.5014, 0.5034, 0.4946, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.5559, 0.5177, 0.5049, 0.5210, 0.5029, 0.5666, 0.5195, 0.5056, 0.5170,
        0.5230, 0.5235, 0.5085, 0.5437, 0.5298, 0.5194, 0.5492],
       device='cuda:0') torch.Size([16])
percent tensor([0.9086, 0.8032, 0.8589, 0.8683, 0.8470, 0.8998, 0.8533, 0.9228, 0.7886,
        0.8450, 0.7987, 0.8707, 0.8161, 0.7953, 0.8563, 0.9242],
       device='cuda:0') torch.Size([16])
Epoch: 14 | Batch_idx: 0 |  Loss: (0.9932) |  Loss2: (0.0000) | Acc: (68.00%) (88/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.9732) |  Loss2: (0.0000) | Acc: (64.00%) (915/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.9700) |  Loss2: (0.0000) | Acc: (65.00%) (1748/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.9890) |  Loss2: (0.0000) | Acc: (64.00%) (2556/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.9903) |  Loss2: (0.0000) | Acc: (64.00%) (3392/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.9922) |  Loss2: (0.0000) | Acc: (64.00%) (4221/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.9826) |  Loss2: (0.0000) | Acc: (64.00%) (5071/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.9770) |  Loss2: (0.0000) | Acc: (64.00%) (5900/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.9797) |  Loss2: (0.0000) | Acc: (64.00%) (6720/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.9757) |  Loss2: (0.0000) | Acc: (64.00%) (7550/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.9756) |  Loss2: (0.0000) | Acc: (64.00%) (8392/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.9733) |  Loss2: (0.0000) | Acc: (64.00%) (9228/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.9692) |  Loss2: (0.0000) | Acc: (65.00%) (10088/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.9648) |  Loss2: (0.0000) | Acc: (65.00%) (10943/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.9658) |  Loss2: (0.0000) | Acc: (65.00%) (11775/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.9688) |  Loss2: (0.0000) | Acc: (65.00%) (12591/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.9654) |  Loss2: (0.0000) | Acc: (65.00%) (13441/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.9661) |  Loss2: (0.0000) | Acc: (65.00%) (14277/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.9666) |  Loss2: (0.0000) | Acc: (65.00%) (15108/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.9665) |  Loss2: (0.0000) | Acc: (65.00%) (15942/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.9659) |  Loss2: (0.0000) | Acc: (65.00%) (16761/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.9680) |  Loss2: (0.0000) | Acc: (65.00%) (17575/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.9667) |  Loss2: (0.0000) | Acc: (65.00%) (18434/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.9688) |  Loss2: (0.0000) | Acc: (65.00%) (19261/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.9685) |  Loss2: (0.0000) | Acc: (65.00%) (20119/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.9682) |  Loss2: (0.0000) | Acc: (65.00%) (20957/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.9689) |  Loss2: (0.0000) | Acc: (65.00%) (21800/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.9693) |  Loss2: (0.0000) | Acc: (65.00%) (22632/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.9692) |  Loss2: (0.0000) | Acc: (65.00%) (23485/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.9694) |  Loss2: (0.0000) | Acc: (65.00%) (24300/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.9704) |  Loss2: (0.0000) | Acc: (65.00%) (25126/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.9701) |  Loss2: (0.0000) | Acc: (65.00%) (25969/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.9708) |  Loss2: (0.0000) | Acc: (65.00%) (26801/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.9712) |  Loss2: (0.0000) | Acc: (65.00%) (27627/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.9717) |  Loss2: (0.0000) | Acc: (65.00%) (28450/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.9717) |  Loss2: (0.0000) | Acc: (65.00%) (29294/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.9712) |  Loss2: (0.0000) | Acc: (65.00%) (30151/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.9706) |  Loss2: (0.0000) | Acc: (65.00%) (30983/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.9700) |  Loss2: (0.0000) | Acc: (65.00%) (31833/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.9694) |  Loss2: (0.0000) | Acc: (65.00%) (32651/50000)
# TEST : Loss: (0.9692) | Acc: (65.00%) (6517/10000)
percent tensor([0.5077, 0.5052, 0.5122, 0.5084, 0.5123, 0.5076, 0.5083, 0.5092, 0.5092,
        0.5072, 0.5067, 0.5111, 0.5066, 0.5045, 0.5061, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.4837, 0.4836, 0.4783, 0.4829, 0.4803, 0.4865, 0.4820, 0.4826, 0.4841,
        0.4811, 0.4852, 0.4778, 0.4838, 0.4877, 0.4825, 0.4858],
       device='cuda:0') torch.Size([16])
percent tensor([0.4805, 0.4640, 0.4458, 0.4847, 0.4582, 0.4978, 0.4545, 0.4597, 0.4786,
        0.4552, 0.4753, 0.4323, 0.4723, 0.4899, 0.4691, 0.4804],
       device='cuda:0') torch.Size([16])
percent tensor([0.4934, 0.4955, 0.4940, 0.4978, 0.4957, 0.4962, 0.4938, 0.4952, 0.4949,
        0.4933, 0.4947, 0.4917, 0.4929, 0.4973, 0.4937, 0.4945],
       device='cuda:0') torch.Size([16])
percent tensor([0.5566, 0.5512, 0.6042, 0.6157, 0.5902, 0.5873, 0.5706, 0.5979, 0.5441,
        0.5692, 0.5463, 0.5986, 0.5440, 0.5342, 0.5641, 0.5616],
       device='cuda:0') torch.Size([16])
percent tensor([0.5009, 0.4936, 0.4806, 0.4934, 0.4869, 0.5068, 0.4905, 0.4776, 0.4957,
        0.4912, 0.4943, 0.4790, 0.4982, 0.5023, 0.4887, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5641, 0.5191, 0.4991, 0.5195, 0.4977, 0.5815, 0.5205, 0.4961, 0.5177,
        0.5243, 0.5268, 0.5062, 0.5511, 0.5359, 0.5182, 0.5553],
       device='cuda:0') torch.Size([16])
percent tensor([0.9392, 0.8425, 0.9025, 0.9117, 0.8940, 0.9392, 0.8944, 0.9529, 0.8294,
        0.8841, 0.8395, 0.9068, 0.8633, 0.8404, 0.8939, 0.9534],
       device='cuda:0') torch.Size([16])
Epoch: 15 | Batch_idx: 0 |  Loss: (1.0287) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.9448) |  Loss2: (0.0000) | Acc: (66.00%) (930/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.9672) |  Loss2: (0.0000) | Acc: (65.00%) (1750/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.9737) |  Loss2: (0.0000) | Acc: (64.00%) (2574/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.9693) |  Loss2: (0.0000) | Acc: (65.00%) (3417/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.9681) |  Loss2: (0.0000) | Acc: (65.00%) (4246/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.9714) |  Loss2: (0.0000) | Acc: (64.00%) (5075/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.9666) |  Loss2: (0.0000) | Acc: (64.00%) (5902/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.9648) |  Loss2: (0.0000) | Acc: (65.00%) (6763/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.9676) |  Loss2: (0.0000) | Acc: (65.00%) (7591/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.9718) |  Loss2: (0.0000) | Acc: (65.00%) (8417/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.9721) |  Loss2: (0.0000) | Acc: (65.00%) (9266/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.9711) |  Loss2: (0.0000) | Acc: (65.00%) (10122/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.9711) |  Loss2: (0.0000) | Acc: (65.00%) (10940/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.9680) |  Loss2: (0.0000) | Acc: (65.00%) (11785/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.9646) |  Loss2: (0.0000) | Acc: (65.00%) (12644/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.9648) |  Loss2: (0.0000) | Acc: (65.00%) (13505/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.9624) |  Loss2: (0.0000) | Acc: (65.00%) (14363/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.9593) |  Loss2: (0.0000) | Acc: (65.00%) (15213/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.9573) |  Loss2: (0.0000) | Acc: (65.00%) (16070/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.9594) |  Loss2: (0.0000) | Acc: (65.00%) (16902/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.9585) |  Loss2: (0.0000) | Acc: (65.00%) (17735/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.9591) |  Loss2: (0.0000) | Acc: (65.00%) (18556/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.9566) |  Loss2: (0.0000) | Acc: (65.00%) (19403/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.9581) |  Loss2: (0.0000) | Acc: (65.00%) (20242/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.9581) |  Loss2: (0.0000) | Acc: (65.00%) (21076/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.9587) |  Loss2: (0.0000) | Acc: (65.00%) (21907/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.9585) |  Loss2: (0.0000) | Acc: (65.00%) (22736/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.9579) |  Loss2: (0.0000) | Acc: (65.00%) (23596/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.9556) |  Loss2: (0.0000) | Acc: (65.00%) (24466/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.9544) |  Loss2: (0.0000) | Acc: (65.00%) (25322/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.9551) |  Loss2: (0.0000) | Acc: (65.00%) (26157/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.9550) |  Loss2: (0.0000) | Acc: (65.00%) (26994/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.9533) |  Loss2: (0.0000) | Acc: (65.00%) (27864/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.9554) |  Loss2: (0.0000) | Acc: (65.00%) (28686/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.9545) |  Loss2: (0.0000) | Acc: (65.00%) (29530/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.9550) |  Loss2: (0.0000) | Acc: (65.00%) (30380/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.9546) |  Loss2: (0.0000) | Acc: (65.00%) (31239/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.9537) |  Loss2: (0.0000) | Acc: (65.00%) (32089/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.9535) |  Loss2: (0.0000) | Acc: (65.00%) (32899/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_015.pth.tar'
# TEST : Loss: (0.9502) | Acc: (65.00%) (6574/10000)
percent tensor([0.5061, 0.5026, 0.5106, 0.5065, 0.5103, 0.5054, 0.5056, 0.5072, 0.5071,
        0.5050, 0.5045, 0.5092, 0.5049, 0.5019, 0.5036, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.4840, 0.4845, 0.4774, 0.4828, 0.4797, 0.4864, 0.4824, 0.4825, 0.4846,
        0.4813, 0.4860, 0.4770, 0.4841, 0.4893, 0.4828, 0.4860],
       device='cuda:0') torch.Size([16])
percent tensor([0.4832, 0.4703, 0.4450, 0.4856, 0.4599, 0.5009, 0.4591, 0.4616, 0.4825,
        0.4590, 0.4800, 0.4319, 0.4754, 0.4955, 0.4736, 0.4838],
       device='cuda:0') torch.Size([16])
percent tensor([0.4931, 0.4960, 0.4944, 0.4983, 0.4962, 0.4964, 0.4941, 0.4954, 0.4951,
        0.4933, 0.4950, 0.4916, 0.4928, 0.4982, 0.4937, 0.4943],
       device='cuda:0') torch.Size([16])
percent tensor([0.5524, 0.5442, 0.6062, 0.6204, 0.5905, 0.5892, 0.5659, 0.5967, 0.5399,
        0.5627, 0.5399, 0.5954, 0.5356, 0.5310, 0.5589, 0.5565],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4899, 0.4753, 0.4915, 0.4826, 0.5078, 0.4864, 0.4698, 0.4928,
        0.4872, 0.4909, 0.4736, 0.4952, 0.5013, 0.4830, 0.5004],
       device='cuda:0') torch.Size([16])
percent tensor([0.5707, 0.5208, 0.4937, 0.5172, 0.4916, 0.5926, 0.5214, 0.4863, 0.5195,
        0.5251, 0.5295, 0.5039, 0.5573, 0.5408, 0.5167, 0.5593],
       device='cuda:0') torch.Size([16])
percent tensor([0.9578, 0.8714, 0.9254, 0.9361, 0.9195, 0.9606, 0.9204, 0.9682, 0.8585,
        0.9049, 0.8673, 0.9233, 0.8935, 0.8698, 0.9190, 0.9691],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 16 | Batch_idx: 0 |  Loss: (0.8422) |  Loss2: (0.0000) | Acc: (71.00%) (91/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.9485) |  Loss2: (0.0000) | Acc: (66.00%) (940/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.9636) |  Loss2: (0.0000) | Acc: (65.00%) (1770/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.9434) |  Loss2: (0.0000) | Acc: (66.00%) (2640/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.9490) |  Loss2: (0.0000) | Acc: (66.00%) (3473/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.9406) |  Loss2: (0.0000) | Acc: (66.00%) (4350/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.9444) |  Loss2: (0.0000) | Acc: (66.00%) (5194/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.9422) |  Loss2: (0.0000) | Acc: (66.00%) (6063/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.9400) |  Loss2: (0.0000) | Acc: (66.00%) (6914/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.9389) |  Loss2: (0.0000) | Acc: (66.00%) (7750/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.9450) |  Loss2: (0.0000) | Acc: (66.00%) (8573/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.9421) |  Loss2: (0.0000) | Acc: (66.00%) (9442/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.9404) |  Loss2: (0.0000) | Acc: (66.00%) (10276/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.9387) |  Loss2: (0.0000) | Acc: (66.00%) (11139/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.9343) |  Loss2: (0.0000) | Acc: (66.00%) (12028/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.9341) |  Loss2: (0.0000) | Acc: (66.00%) (12891/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.9331) |  Loss2: (0.0000) | Acc: (66.00%) (13759/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.9328) |  Loss2: (0.0000) | Acc: (66.00%) (14597/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.9316) |  Loss2: (0.0000) | Acc: (66.00%) (15451/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.9309) |  Loss2: (0.0000) | Acc: (66.00%) (16308/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.9317) |  Loss2: (0.0000) | Acc: (66.00%) (17175/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.9310) |  Loss2: (0.0000) | Acc: (66.00%) (18031/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.9316) |  Loss2: (0.0000) | Acc: (66.00%) (18887/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.9321) |  Loss2: (0.0000) | Acc: (66.00%) (19739/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.9303) |  Loss2: (0.0000) | Acc: (66.00%) (20613/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.9292) |  Loss2: (0.0000) | Acc: (66.00%) (21467/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.9296) |  Loss2: (0.0000) | Acc: (66.00%) (22314/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.9270) |  Loss2: (0.0000) | Acc: (66.00%) (23194/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.9245) |  Loss2: (0.0000) | Acc: (66.00%) (24087/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.9242) |  Loss2: (0.0000) | Acc: (66.00%) (24921/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.9242) |  Loss2: (0.0000) | Acc: (66.00%) (25778/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.9229) |  Loss2: (0.0000) | Acc: (66.00%) (26646/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.9224) |  Loss2: (0.0000) | Acc: (66.00%) (27505/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.9225) |  Loss2: (0.0000) | Acc: (66.00%) (28346/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.9213) |  Loss2: (0.0000) | Acc: (66.00%) (29239/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.9205) |  Loss2: (0.0000) | Acc: (67.00%) (30128/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.9198) |  Loss2: (0.0000) | Acc: (67.00%) (31003/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.9178) |  Loss2: (0.0000) | Acc: (67.00%) (31906/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.9179) |  Loss2: (0.0000) | Acc: (67.00%) (32761/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.9171) |  Loss2: (0.0000) | Acc: (67.00%) (33617/50000)
# TEST : Loss: (0.9610) | Acc: (66.00%) (6612/10000)
percent tensor([0.5057, 0.5018, 0.5111, 0.5064, 0.5105, 0.5050, 0.5052, 0.5069, 0.5066,
        0.5047, 0.5037, 0.5098, 0.5044, 0.5007, 0.5032, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.4842, 0.4844, 0.4778, 0.4826, 0.4799, 0.4865, 0.4823, 0.4816, 0.4843,
        0.4809, 0.4858, 0.4770, 0.4841, 0.4881, 0.4829, 0.4857],
       device='cuda:0') torch.Size([16])
percent tensor([0.4783, 0.4715, 0.4513, 0.4792, 0.4631, 0.4954, 0.4657, 0.4615, 0.4840,
        0.4613, 0.4782, 0.4401, 0.4722, 0.4952, 0.4717, 0.4779],
       device='cuda:0') torch.Size([16])
percent tensor([0.4928, 0.4962, 0.4967, 0.4972, 0.4975, 0.4954, 0.4947, 0.4967, 0.4961,
        0.4941, 0.4951, 0.4937, 0.4931, 0.4991, 0.4931, 0.4934],
       device='cuda:0') torch.Size([16])
percent tensor([0.5516, 0.5506, 0.6136, 0.6031, 0.5947, 0.5759, 0.5657, 0.5980, 0.5423,
        0.5660, 0.5461, 0.5897, 0.5365, 0.5336, 0.5586, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.4948, 0.4892, 0.4835, 0.4913, 0.4884, 0.5068, 0.4889, 0.4754, 0.4949,
        0.4865, 0.4889, 0.4794, 0.4924, 0.4999, 0.4801, 0.4929],
       device='cuda:0') torch.Size([16])
percent tensor([0.5600, 0.5158, 0.4934, 0.5070, 0.4922, 0.5850, 0.5116, 0.4827, 0.5146,
        0.5098, 0.5205, 0.4957, 0.5494, 0.5300, 0.5089, 0.5452],
       device='cuda:0') torch.Size([16])
percent tensor([0.9565, 0.8764, 0.9166, 0.9166, 0.9283, 0.9584, 0.8929, 0.9457, 0.8615,
        0.9024, 0.8789, 0.8907, 0.8891, 0.8683, 0.9051, 0.9587],
       device='cuda:0') torch.Size([16])
Epoch: 17 | Batch_idx: 0 |  Loss: (0.8464) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.9141) |  Loss2: (0.0000) | Acc: (67.00%) (951/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.9015) |  Loss2: (0.0000) | Acc: (68.00%) (1837/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.8806) |  Loss2: (0.0000) | Acc: (69.00%) (2751/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.8827) |  Loss2: (0.0000) | Acc: (69.00%) (3633/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.8836) |  Loss2: (0.0000) | Acc: (68.00%) (4496/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.8842) |  Loss2: (0.0000) | Acc: (68.00%) (5369/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.8883) |  Loss2: (0.0000) | Acc: (68.00%) (6238/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.8811) |  Loss2: (0.0000) | Acc: (68.00%) (7129/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.8859) |  Loss2: (0.0000) | Acc: (68.00%) (7984/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.8865) |  Loss2: (0.0000) | Acc: (68.00%) (8867/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.8829) |  Loss2: (0.0000) | Acc: (68.00%) (9762/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.8808) |  Loss2: (0.0000) | Acc: (68.00%) (10662/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.8798) |  Loss2: (0.0000) | Acc: (68.00%) (11556/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.8774) |  Loss2: (0.0000) | Acc: (69.00%) (12472/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.8766) |  Loss2: (0.0000) | Acc: (69.00%) (13370/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.8772) |  Loss2: (0.0000) | Acc: (69.00%) (14249/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.8740) |  Loss2: (0.0000) | Acc: (69.00%) (15161/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.8708) |  Loss2: (0.0000) | Acc: (69.00%) (16076/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.8701) |  Loss2: (0.0000) | Acc: (69.00%) (16965/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.8704) |  Loss2: (0.0000) | Acc: (69.00%) (17847/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.8697) |  Loss2: (0.0000) | Acc: (69.00%) (18738/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.8686) |  Loss2: (0.0000) | Acc: (69.00%) (19628/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.8686) |  Loss2: (0.0000) | Acc: (69.00%) (20500/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.8676) |  Loss2: (0.0000) | Acc: (69.00%) (21388/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.8675) |  Loss2: (0.0000) | Acc: (69.00%) (22267/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.8664) |  Loss2: (0.0000) | Acc: (69.00%) (23197/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.8647) |  Loss2: (0.0000) | Acc: (69.00%) (24098/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.8633) |  Loss2: (0.0000) | Acc: (69.00%) (25000/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.8619) |  Loss2: (0.0000) | Acc: (69.00%) (25903/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.8614) |  Loss2: (0.0000) | Acc: (69.00%) (26786/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.8610) |  Loss2: (0.0000) | Acc: (69.00%) (27667/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.8606) |  Loss2: (0.0000) | Acc: (69.00%) (28570/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.8605) |  Loss2: (0.0000) | Acc: (69.00%) (29461/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.8600) |  Loss2: (0.0000) | Acc: (69.00%) (30352/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.8591) |  Loss2: (0.0000) | Acc: (69.00%) (31249/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.8588) |  Loss2: (0.0000) | Acc: (69.00%) (32153/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.8577) |  Loss2: (0.0000) | Acc: (69.00%) (33090/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.8578) |  Loss2: (0.0000) | Acc: (69.00%) (33983/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.8574) |  Loss2: (0.0000) | Acc: (69.00%) (34832/50000)
# TEST : Loss: (0.8761) | Acc: (69.00%) (6902/10000)
percent tensor([0.5054, 0.5022, 0.5093, 0.5062, 0.5091, 0.5048, 0.5049, 0.5068, 0.5062,
        0.5044, 0.5037, 0.5083, 0.5042, 0.5016, 0.5033, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.4844, 0.4847, 0.4767, 0.4830, 0.4799, 0.4868, 0.4825, 0.4816, 0.4841,
        0.4816, 0.4858, 0.4769, 0.4843, 0.4884, 0.4830, 0.4863],
       device='cuda:0') torch.Size([16])
percent tensor([0.4767, 0.4724, 0.4402, 0.4743, 0.4543, 0.4952, 0.4618, 0.4590, 0.4817,
        0.4582, 0.4783, 0.4296, 0.4701, 0.4972, 0.4701, 0.4802],
       device='cuda:0') torch.Size([16])
percent tensor([0.4932, 0.4960, 0.4954, 0.4978, 0.4962, 0.4959, 0.4942, 0.4969, 0.4950,
        0.4926, 0.4953, 0.4927, 0.4930, 0.4983, 0.4935, 0.4941],
       device='cuda:0') torch.Size([16])
percent tensor([0.5509, 0.5462, 0.6004, 0.6048, 0.5815, 0.5753, 0.5601, 0.5967, 0.5393,
        0.5634, 0.5440, 0.5823, 0.5389, 0.5349, 0.5592, 0.5608],
       device='cuda:0') torch.Size([16])
percent tensor([0.4949, 0.4906, 0.4776, 0.4849, 0.4848, 0.5050, 0.4872, 0.4730, 0.4928,
        0.4843, 0.4902, 0.4730, 0.4916, 0.5018, 0.4799, 0.4944],
       device='cuda:0') torch.Size([16])
percent tensor([0.5673, 0.5302, 0.4961, 0.5037, 0.4936, 0.5785, 0.5158, 0.4886, 0.5221,
        0.5190, 0.5351, 0.4974, 0.5574, 0.5395, 0.5145, 0.5530],
       device='cuda:0') torch.Size([16])
percent tensor([0.9669, 0.8864, 0.9349, 0.9297, 0.9244, 0.9512, 0.9221, 0.9611, 0.8719,
        0.9224, 0.8868, 0.9282, 0.8982, 0.8946, 0.9005, 0.9697],
       device='cuda:0') torch.Size([16])
Epoch: 18 | Batch_idx: 0 |  Loss: (0.7920) |  Loss2: (0.0000) | Acc: (71.00%) (92/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.8411) |  Loss2: (0.0000) | Acc: (69.00%) (974/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.8259) |  Loss2: (0.0000) | Acc: (70.00%) (1888/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.8291) |  Loss2: (0.0000) | Acc: (69.00%) (2776/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.8287) |  Loss2: (0.0000) | Acc: (70.00%) (3706/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.8269) |  Loss2: (0.0000) | Acc: (70.00%) (4602/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.8328) |  Loss2: (0.0000) | Acc: (70.00%) (5494/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.8319) |  Loss2: (0.0000) | Acc: (70.00%) (6389/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.8297) |  Loss2: (0.0000) | Acc: (70.00%) (7313/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.8319) |  Loss2: (0.0000) | Acc: (70.00%) (8214/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.8317) |  Loss2: (0.0000) | Acc: (70.00%) (9113/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.8277) |  Loss2: (0.0000) | Acc: (70.00%) (10031/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.8289) |  Loss2: (0.0000) | Acc: (70.00%) (10926/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.8318) |  Loss2: (0.0000) | Acc: (70.00%) (11804/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.8314) |  Loss2: (0.0000) | Acc: (70.00%) (12711/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.8302) |  Loss2: (0.0000) | Acc: (70.00%) (13623/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.8300) |  Loss2: (0.0000) | Acc: (70.00%) (14530/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.8316) |  Loss2: (0.0000) | Acc: (70.00%) (15422/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.8302) |  Loss2: (0.0000) | Acc: (70.00%) (16320/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.8298) |  Loss2: (0.0000) | Acc: (70.00%) (17223/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.8288) |  Loss2: (0.0000) | Acc: (70.00%) (18122/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.8286) |  Loss2: (0.0000) | Acc: (70.00%) (19034/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.8305) |  Loss2: (0.0000) | Acc: (70.00%) (19903/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.8289) |  Loss2: (0.0000) | Acc: (70.00%) (20802/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.8292) |  Loss2: (0.0000) | Acc: (70.00%) (21708/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.8287) |  Loss2: (0.0000) | Acc: (70.00%) (22638/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.8280) |  Loss2: (0.0000) | Acc: (70.00%) (23558/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.8264) |  Loss2: (0.0000) | Acc: (70.00%) (24490/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.8253) |  Loss2: (0.0000) | Acc: (70.00%) (25427/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.8239) |  Loss2: (0.0000) | Acc: (70.00%) (26358/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.8225) |  Loss2: (0.0000) | Acc: (70.00%) (27295/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.8224) |  Loss2: (0.0000) | Acc: (70.00%) (28211/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.8211) |  Loss2: (0.0000) | Acc: (70.00%) (29129/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.8208) |  Loss2: (0.0000) | Acc: (70.00%) (30041/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.8194) |  Loss2: (0.0000) | Acc: (70.00%) (30969/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.8179) |  Loss2: (0.0000) | Acc: (71.00%) (31907/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.8172) |  Loss2: (0.0000) | Acc: (71.00%) (32817/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.8169) |  Loss2: (0.0000) | Acc: (71.00%) (33733/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.8148) |  Loss2: (0.0000) | Acc: (71.00%) (34671/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.8144) |  Loss2: (0.0000) | Acc: (71.00%) (35536/50000)
# TEST : Loss: (0.9221) | Acc: (67.00%) (6775/10000)
percent tensor([0.5057, 0.5021, 0.5102, 0.5062, 0.5101, 0.5048, 0.5054, 0.5068, 0.5065,
        0.5049, 0.5039, 0.5093, 0.5045, 0.5012, 0.5034, 0.5037],
       device='cuda:0') torch.Size([16])
percent tensor([0.4838, 0.4849, 0.4772, 0.4826, 0.4792, 0.4860, 0.4827, 0.4823, 0.4838,
        0.4818, 0.4856, 0.4774, 0.4842, 0.4890, 0.4830, 0.4860],
       device='cuda:0') torch.Size([16])
percent tensor([0.4783, 0.4714, 0.4534, 0.4810, 0.4631, 0.4947, 0.4670, 0.4654, 0.4832,
        0.4632, 0.4776, 0.4430, 0.4710, 0.4970, 0.4724, 0.4808],
       device='cuda:0') torch.Size([16])
percent tensor([0.4934, 0.4963, 0.4979, 0.4985, 0.4993, 0.4965, 0.4951, 0.4970, 0.4968,
        0.4942, 0.4958, 0.4944, 0.4936, 0.4994, 0.4941, 0.4942],
       device='cuda:0') torch.Size([16])
percent tensor([0.5522, 0.5582, 0.6146, 0.6105, 0.5996, 0.5814, 0.5702, 0.6017, 0.5466,
        0.5724, 0.5482, 0.5920, 0.5393, 0.5445, 0.5639, 0.5619],
       device='cuda:0') torch.Size([16])
percent tensor([0.4957, 0.4930, 0.4855, 0.4912, 0.4912, 0.5092, 0.4891, 0.4799, 0.4943,
        0.4879, 0.4914, 0.4781, 0.4926, 0.5017, 0.4844, 0.5001],
       device='cuda:0') torch.Size([16])
percent tensor([0.5743, 0.5388, 0.5060, 0.5179, 0.5004, 0.5907, 0.5292, 0.4924, 0.5283,
        0.5366, 0.5456, 0.5078, 0.5579, 0.5429, 0.5345, 0.5727],
       device='cuda:0') torch.Size([16])
percent tensor([0.9692, 0.8816, 0.9211, 0.9354, 0.9090, 0.9645, 0.9244, 0.9447, 0.8718,
        0.9152, 0.8954, 0.9191, 0.9013, 0.8935, 0.9148, 0.9705],
       device='cuda:0') torch.Size([16])
Epoch: 19 | Batch_idx: 0 |  Loss: (0.7671) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.8016) |  Loss2: (0.0000) | Acc: (73.00%) (1028/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.7989) |  Loss2: (0.0000) | Acc: (72.00%) (1940/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.7895) |  Loss2: (0.0000) | Acc: (72.00%) (2872/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.7925) |  Loss2: (0.0000) | Acc: (72.00%) (3800/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.7959) |  Loss2: (0.0000) | Acc: (72.00%) (4726/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.7946) |  Loss2: (0.0000) | Acc: (72.00%) (5649/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.7978) |  Loss2: (0.0000) | Acc: (72.00%) (6564/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.7898) |  Loss2: (0.0000) | Acc: (72.00%) (7522/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.7910) |  Loss2: (0.0000) | Acc: (72.00%) (8432/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.7897) |  Loss2: (0.0000) | Acc: (72.00%) (9352/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.7903) |  Loss2: (0.0000) | Acc: (72.00%) (10286/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.7883) |  Loss2: (0.0000) | Acc: (72.00%) (11224/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.7902) |  Loss2: (0.0000) | Acc: (72.00%) (12122/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.7883) |  Loss2: (0.0000) | Acc: (72.00%) (13068/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.7875) |  Loss2: (0.0000) | Acc: (72.00%) (13998/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.7846) |  Loss2: (0.0000) | Acc: (72.00%) (14962/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.7839) |  Loss2: (0.0000) | Acc: (72.00%) (15899/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.7846) |  Loss2: (0.0000) | Acc: (72.00%) (16819/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.7835) |  Loss2: (0.0000) | Acc: (72.00%) (17734/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.7827) |  Loss2: (0.0000) | Acc: (72.00%) (18661/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.7799) |  Loss2: (0.0000) | Acc: (72.00%) (19619/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.7792) |  Loss2: (0.0000) | Acc: (72.00%) (20564/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.7794) |  Loss2: (0.0000) | Acc: (72.00%) (21492/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.7795) |  Loss2: (0.0000) | Acc: (72.00%) (22428/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.7786) |  Loss2: (0.0000) | Acc: (72.00%) (23372/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.7784) |  Loss2: (0.0000) | Acc: (72.00%) (24299/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.7785) |  Loss2: (0.0000) | Acc: (72.00%) (25248/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.7787) |  Loss2: (0.0000) | Acc: (72.00%) (26161/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.7782) |  Loss2: (0.0000) | Acc: (72.00%) (27101/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.7785) |  Loss2: (0.0000) | Acc: (72.00%) (28002/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.7779) |  Loss2: (0.0000) | Acc: (72.00%) (28924/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.7778) |  Loss2: (0.0000) | Acc: (72.00%) (29846/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.7797) |  Loss2: (0.0000) | Acc: (72.00%) (30749/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.7805) |  Loss2: (0.0000) | Acc: (72.00%) (31676/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.7787) |  Loss2: (0.0000) | Acc: (72.00%) (32620/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.7782) |  Loss2: (0.0000) | Acc: (72.00%) (33552/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.7765) |  Loss2: (0.0000) | Acc: (72.00%) (34510/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.7762) |  Loss2: (0.0000) | Acc: (72.00%) (35448/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.7750) |  Loss2: (0.0000) | Acc: (72.00%) (36361/50000)
# TEST : Loss: (0.8774) | Acc: (69.00%) (6942/10000)
percent tensor([0.5054, 0.5023, 0.5090, 0.5061, 0.5092, 0.5049, 0.5049, 0.5066, 0.5059,
        0.5045, 0.5037, 0.5084, 0.5041, 0.5015, 0.5036, 0.5037],
       device='cuda:0') torch.Size([16])
percent tensor([0.4844, 0.4855, 0.4781, 0.4834, 0.4802, 0.4860, 0.4833, 0.4826, 0.4840,
        0.4824, 0.4860, 0.4779, 0.4844, 0.4893, 0.4834, 0.4863],
       device='cuda:0') torch.Size([16])
percent tensor([0.4759, 0.4709, 0.4497, 0.4788, 0.4586, 0.4927, 0.4659, 0.4627, 0.4811,
        0.4613, 0.4774, 0.4400, 0.4679, 0.4983, 0.4700, 0.4797],
       device='cuda:0') torch.Size([16])
percent tensor([0.4930, 0.4952, 0.4961, 0.4976, 0.4973, 0.4957, 0.4943, 0.4962, 0.4957,
        0.4928, 0.4951, 0.4927, 0.4929, 0.4983, 0.4931, 0.4934],
       device='cuda:0') torch.Size([16])
percent tensor([0.5480, 0.5525, 0.6019, 0.6067, 0.5890, 0.5838, 0.5601, 0.5990, 0.5365,
        0.5655, 0.5415, 0.5790, 0.5341, 0.5424, 0.5589, 0.5602],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.4937, 0.4849, 0.4876, 0.4898, 0.5048, 0.4896, 0.4772, 0.4971,
        0.4919, 0.4927, 0.4801, 0.4954, 0.5054, 0.4832, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.5628, 0.5373, 0.5055, 0.5078, 0.4971, 0.5663, 0.5159, 0.4867, 0.5326,
        0.5446, 0.5417, 0.5085, 0.5547, 0.5485, 0.5186, 0.5559],
       device='cuda:0') torch.Size([16])
percent tensor([0.9533, 0.9019, 0.9462, 0.9398, 0.9308, 0.9408, 0.9213, 0.9629, 0.8640,
        0.9276, 0.9046, 0.9282, 0.8847, 0.9003, 0.8948, 0.9621],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 20 | Batch_idx: 0 |  Loss: (0.8025) |  Loss2: (0.0000) | Acc: (71.00%) (91/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7914) |  Loss2: (0.0000) | Acc: (72.00%) (1023/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.8542) |  Loss2: (0.0000) | Acc: (69.00%) (1881/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.8857) |  Loss2: (0.0000) | Acc: (68.00%) (2724/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.8951) |  Loss2: (0.0000) | Acc: (68.00%) (3584/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.9008) |  Loss2: (0.0000) | Acc: (67.00%) (4434/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.9126) |  Loss2: (0.0000) | Acc: (67.00%) (5272/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.9099) |  Loss2: (0.0000) | Acc: (67.00%) (6151/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.9069) |  Loss2: (0.0000) | Acc: (67.00%) (7032/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.9012) |  Loss2: (0.0000) | Acc: (68.00%) (7926/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.8999) |  Loss2: (0.0000) | Acc: (68.00%) (8805/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.8931) |  Loss2: (0.0000) | Acc: (68.00%) (9706/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.8838) |  Loss2: (0.0000) | Acc: (68.00%) (10652/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.8828) |  Loss2: (0.0000) | Acc: (68.00%) (11528/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.8789) |  Loss2: (0.0000) | Acc: (68.00%) (12427/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.8751) |  Loss2: (0.0000) | Acc: (68.00%) (13328/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.8715) |  Loss2: (0.0000) | Acc: (69.00%) (14224/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.8731) |  Loss2: (0.0000) | Acc: (68.00%) (15092/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.8699) |  Loss2: (0.0000) | Acc: (69.00%) (16008/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.8658) |  Loss2: (0.0000) | Acc: (69.00%) (16918/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.8655) |  Loss2: (0.0000) | Acc: (69.00%) (17794/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.8604) |  Loss2: (0.0000) | Acc: (69.00%) (18746/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.8603) |  Loss2: (0.0000) | Acc: (69.00%) (19628/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.8590) |  Loss2: (0.0000) | Acc: (69.00%) (20517/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.8556) |  Loss2: (0.0000) | Acc: (69.00%) (21451/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.8539) |  Loss2: (0.0000) | Acc: (69.00%) (22354/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.8512) |  Loss2: (0.0000) | Acc: (69.00%) (23275/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.8498) |  Loss2: (0.0000) | Acc: (69.00%) (24189/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.8488) |  Loss2: (0.0000) | Acc: (69.00%) (25107/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.8474) |  Loss2: (0.0000) | Acc: (69.00%) (26031/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.8445) |  Loss2: (0.0000) | Acc: (69.00%) (26968/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.8445) |  Loss2: (0.0000) | Acc: (70.00%) (27867/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.8433) |  Loss2: (0.0000) | Acc: (70.00%) (28795/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.8405) |  Loss2: (0.0000) | Acc: (70.00%) (29739/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.8396) |  Loss2: (0.0000) | Acc: (70.00%) (30664/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.8391) |  Loss2: (0.0000) | Acc: (70.00%) (31572/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.8371) |  Loss2: (0.0000) | Acc: (70.00%) (32512/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.8357) |  Loss2: (0.0000) | Acc: (70.00%) (33434/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.8341) |  Loss2: (0.0000) | Acc: (70.00%) (34354/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.8325) |  Loss2: (0.0000) | Acc: (70.00%) (35248/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_020.pth.tar'
# TEST : Loss: (0.7928) | Acc: (71.00%) (7180/10000)
percent tensor([0.5123, 0.5121, 0.5188, 0.5137, 0.5194, 0.5095, 0.5154, 0.5165, 0.5161,
        0.5145, 0.5125, 0.5190, 0.5121, 0.5115, 0.5108, 0.5103],
       device='cuda:0') torch.Size([16])
percent tensor([0.4868, 0.4878, 0.4810, 0.4839, 0.4832, 0.4876, 0.4864, 0.4843, 0.4874,
        0.4851, 0.4891, 0.4815, 0.4876, 0.4907, 0.4856, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.4852, 0.4789, 0.4629, 0.4829, 0.4711, 0.4973, 0.4744, 0.4722, 0.4910,
        0.4726, 0.4846, 0.4529, 0.4798, 0.5006, 0.4769, 0.4876],
       device='cuda:0') torch.Size([16])
percent tensor([0.4948, 0.4998, 0.4976, 0.4982, 0.4980, 0.4953, 0.4964, 0.4979, 0.4986,
        0.4979, 0.4985, 0.4942, 0.4963, 0.5013, 0.4950, 0.4959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5483, 0.5560, 0.6235, 0.6230, 0.6005, 0.5810, 0.5657, 0.6181, 0.5424,
        0.5712, 0.5437, 0.5880, 0.5338, 0.5428, 0.5649, 0.5558],
       device='cuda:0') torch.Size([16])
percent tensor([0.5003, 0.4985, 0.4906, 0.4928, 0.4959, 0.5113, 0.4939, 0.4846, 0.5001,
        0.4978, 0.4967, 0.4809, 0.4969, 0.5090, 0.4901, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5886, 0.5501, 0.5280, 0.5374, 0.5226, 0.5987, 0.5330, 0.5139, 0.5511,
        0.5659, 0.5537, 0.5237, 0.5618, 0.5702, 0.5377, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.9754, 0.9251, 0.9616, 0.9588, 0.9515, 0.9548, 0.9481, 0.9791, 0.9103,
        0.9521, 0.9250, 0.9557, 0.9231, 0.9285, 0.9275, 0.9775],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(167.4461, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(784.6041, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(780.9383, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.2949, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(509.7667, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2171.6646, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4315.4810, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1440.2029, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6092.9727, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12180.7812, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4067.9536, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17196.0605, device='cuda:0')
Epoch: 21 | Batch_idx: 0 |  Loss: (0.6940) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.7583) |  Loss2: (0.0000) | Acc: (73.00%) (1030/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.7913) |  Loss2: (0.0000) | Acc: (71.00%) (1934/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.7801) |  Loss2: (0.0000) | Acc: (72.00%) (2871/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.7909) |  Loss2: (0.0000) | Acc: (72.00%) (3779/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.7845) |  Loss2: (0.0000) | Acc: (72.00%) (4711/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.7873) |  Loss2: (0.0000) | Acc: (71.00%) (5616/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.7840) |  Loss2: (0.0000) | Acc: (72.00%) (6551/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.7791) |  Loss2: (0.0000) | Acc: (72.00%) (7506/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.7773) |  Loss2: (0.0000) | Acc: (72.00%) (8442/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.7767) |  Loss2: (0.0000) | Acc: (72.00%) (9353/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.7780) |  Loss2: (0.0000) | Acc: (72.00%) (10291/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.7742) |  Loss2: (0.0000) | Acc: (72.00%) (11247/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.7737) |  Loss2: (0.0000) | Acc: (72.00%) (12176/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.7712) |  Loss2: (0.0000) | Acc: (72.00%) (13134/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.7743) |  Loss2: (0.0000) | Acc: (72.00%) (14039/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.7758) |  Loss2: (0.0000) | Acc: (72.00%) (14946/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.7769) |  Loss2: (0.0000) | Acc: (72.00%) (15870/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.7785) |  Loss2: (0.0000) | Acc: (72.00%) (16799/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.7810) |  Loss2: (0.0000) | Acc: (72.00%) (17711/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.7815) |  Loss2: (0.0000) | Acc: (72.00%) (18643/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.7820) |  Loss2: (0.0000) | Acc: (72.00%) (19576/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.7792) |  Loss2: (0.0000) | Acc: (72.00%) (20519/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.7787) |  Loss2: (0.0000) | Acc: (72.00%) (21438/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.7787) |  Loss2: (0.0000) | Acc: (72.00%) (22367/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.7789) |  Loss2: (0.0000) | Acc: (72.00%) (23303/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.7786) |  Loss2: (0.0000) | Acc: (72.00%) (24239/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.7796) |  Loss2: (0.0000) | Acc: (72.00%) (25150/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.7793) |  Loss2: (0.0000) | Acc: (72.00%) (26074/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.7791) |  Loss2: (0.0000) | Acc: (72.00%) (27003/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.7797) |  Loss2: (0.0000) | Acc: (72.00%) (27923/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.7794) |  Loss2: (0.0000) | Acc: (72.00%) (28839/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.7788) |  Loss2: (0.0000) | Acc: (72.00%) (29781/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.7777) |  Loss2: (0.0000) | Acc: (72.00%) (30720/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.7785) |  Loss2: (0.0000) | Acc: (72.00%) (31614/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.7769) |  Loss2: (0.0000) | Acc: (72.00%) (32575/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.7764) |  Loss2: (0.0000) | Acc: (72.00%) (33501/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.7759) |  Loss2: (0.0000) | Acc: (72.00%) (34446/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.7743) |  Loss2: (0.0000) | Acc: (72.00%) (35394/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.7727) |  Loss2: (0.0000) | Acc: (72.00%) (36312/50000)
# TEST : Loss: (0.7801) | Acc: (72.00%) (7237/10000)
percent tensor([0.5125, 0.5118, 0.5196, 0.5131, 0.5200, 0.5077, 0.5160, 0.5171, 0.5174,
        0.5152, 0.5131, 0.5201, 0.5128, 0.5115, 0.5095, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.4858, 0.4866, 0.4793, 0.4821, 0.4816, 0.4866, 0.4851, 0.4827, 0.4864,
        0.4838, 0.4883, 0.4799, 0.4867, 0.4895, 0.4842, 0.4871],
       device='cuda:0') torch.Size([16])
percent tensor([0.4782, 0.4688, 0.4494, 0.4737, 0.4574, 0.4906, 0.4622, 0.4582, 0.4880,
        0.4621, 0.4806, 0.4371, 0.4739, 0.4994, 0.4647, 0.4802],
       device='cuda:0') torch.Size([16])
percent tensor([0.4939, 0.5001, 0.4961, 0.4964, 0.4965, 0.4932, 0.4956, 0.4961, 0.4983,
        0.4984, 0.4985, 0.4936, 0.4964, 0.5014, 0.4938, 0.4952],
       device='cuda:0') torch.Size([16])
percent tensor([0.5508, 0.5546, 0.6249, 0.6240, 0.6046, 0.5849, 0.5675, 0.6171, 0.5472,
        0.5675, 0.5436, 0.5884, 0.5334, 0.5469, 0.5646, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.5032, 0.5015, 0.4952, 0.4970, 0.5014, 0.5161, 0.4973, 0.4888, 0.5036,
        0.5014, 0.4993, 0.4841, 0.4990, 0.5129, 0.4938, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.6067, 0.5604, 0.5483, 0.5597, 0.5426, 0.6257, 0.5446, 0.5316, 0.5610,
        0.5808, 0.5620, 0.5377, 0.5702, 0.5859, 0.5519, 0.6001],
       device='cuda:0') torch.Size([16])
percent tensor([0.9877, 0.9529, 0.9781, 0.9748, 0.9724, 0.9738, 0.9683, 0.9890, 0.9420,
        0.9732, 0.9547, 0.9746, 0.9537, 0.9569, 0.9534, 0.9882],
       device='cuda:0') torch.Size([16])
Epoch: 22 | Batch_idx: 0 |  Loss: (0.7877) |  Loss2: (0.0000) | Acc: (70.00%) (90/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.7820) |  Loss2: (0.0000) | Acc: (72.00%) (1014/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.7847) |  Loss2: (0.0000) | Acc: (71.00%) (1933/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.7552) |  Loss2: (0.0000) | Acc: (72.00%) (2883/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.7412) |  Loss2: (0.0000) | Acc: (73.00%) (3851/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.7535) |  Loss2: (0.0000) | Acc: (72.00%) (4758/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.7498) |  Loss2: (0.0000) | Acc: (73.00%) (5722/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.7528) |  Loss2: (0.0000) | Acc: (73.00%) (6669/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.7591) |  Loss2: (0.0000) | Acc: (73.00%) (7579/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.7554) |  Loss2: (0.0000) | Acc: (73.00%) (8529/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.7586) |  Loss2: (0.0000) | Acc: (73.00%) (9441/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.7585) |  Loss2: (0.0000) | Acc: (73.00%) (10395/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.7626) |  Loss2: (0.0000) | Acc: (73.00%) (11313/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.7616) |  Loss2: (0.0000) | Acc: (73.00%) (12250/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.7650) |  Loss2: (0.0000) | Acc: (72.00%) (13156/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.7655) |  Loss2: (0.0000) | Acc: (72.00%) (14071/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.7631) |  Loss2: (0.0000) | Acc: (72.00%) (15013/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.7612) |  Loss2: (0.0000) | Acc: (72.00%) (15964/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.7613) |  Loss2: (0.0000) | Acc: (72.00%) (16907/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.7615) |  Loss2: (0.0000) | Acc: (72.00%) (17842/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.7628) |  Loss2: (0.0000) | Acc: (72.00%) (18753/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.7632) |  Loss2: (0.0000) | Acc: (72.00%) (19696/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.7636) |  Loss2: (0.0000) | Acc: (72.00%) (20626/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.7643) |  Loss2: (0.0000) | Acc: (72.00%) (21540/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.7627) |  Loss2: (0.0000) | Acc: (72.00%) (22505/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.7628) |  Loss2: (0.0000) | Acc: (72.00%) (23436/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.7651) |  Loss2: (0.0000) | Acc: (72.00%) (24360/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.7649) |  Loss2: (0.0000) | Acc: (72.00%) (25284/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.7662) |  Loss2: (0.0000) | Acc: (72.00%) (26210/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.7646) |  Loss2: (0.0000) | Acc: (72.00%) (27169/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.7645) |  Loss2: (0.0000) | Acc: (72.00%) (28113/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.7653) |  Loss2: (0.0000) | Acc: (72.00%) (29040/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.7639) |  Loss2: (0.0000) | Acc: (72.00%) (29981/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.7620) |  Loss2: (0.0000) | Acc: (73.00%) (30940/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.7607) |  Loss2: (0.0000) | Acc: (73.00%) (31889/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.7606) |  Loss2: (0.0000) | Acc: (73.00%) (32838/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.7605) |  Loss2: (0.0000) | Acc: (73.00%) (33768/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.7607) |  Loss2: (0.0000) | Acc: (73.00%) (34714/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.7602) |  Loss2: (0.0000) | Acc: (73.00%) (35660/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.7606) |  Loss2: (0.0000) | Acc: (73.00%) (36562/50000)
# TEST : Loss: (0.7716) | Acc: (72.00%) (7280/10000)
percent tensor([0.5130, 0.5116, 0.5203, 0.5129, 0.5207, 0.5066, 0.5165, 0.5176, 0.5187,
        0.5158, 0.5138, 0.5210, 0.5136, 0.5117, 0.5088, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.4866, 0.4872, 0.4799, 0.4824, 0.4822, 0.4872, 0.4859, 0.4831, 0.4870,
        0.4844, 0.4891, 0.4806, 0.4873, 0.4900, 0.4849, 0.4877],
       device='cuda:0') torch.Size([16])
percent tensor([0.4777, 0.4664, 0.4475, 0.4739, 0.4560, 0.4905, 0.4599, 0.4564, 0.4897,
        0.4607, 0.4811, 0.4342, 0.4734, 0.5012, 0.4616, 0.4794],
       device='cuda:0') torch.Size([16])
percent tensor([0.4938, 0.5007, 0.4957, 0.4957, 0.4962, 0.4923, 0.4955, 0.4956, 0.4984,
        0.4992, 0.4988, 0.4937, 0.4968, 0.5018, 0.4934, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.5493, 0.5502, 0.6205, 0.6215, 0.6026, 0.5854, 0.5644, 0.6105, 0.5458,
        0.5610, 0.5401, 0.5845, 0.5299, 0.5467, 0.5612, 0.5528],
       device='cuda:0') torch.Size([16])
percent tensor([0.5051, 0.5029, 0.4980, 0.5002, 0.5047, 0.5190, 0.4990, 0.4910, 0.5062,
        0.5035, 0.5007, 0.4861, 0.4999, 0.5157, 0.4957, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.6159, 0.5647, 0.5596, 0.5729, 0.5541, 0.6430, 0.5493, 0.5412, 0.5650,
        0.5872, 0.5640, 0.5439, 0.5738, 0.5946, 0.5576, 0.6097],
       device='cuda:0') torch.Size([16])
percent tensor([0.9924, 0.9668, 0.9863, 0.9837, 0.9826, 0.9824, 0.9787, 0.9938, 0.9580,
        0.9829, 0.9683, 0.9844, 0.9684, 0.9710, 0.9670, 0.9928],
       device='cuda:0') torch.Size([16])
Epoch: 23 | Batch_idx: 0 |  Loss: (0.7529) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.7577) |  Loss2: (0.0000) | Acc: (75.00%) (1069/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.7559) |  Loss2: (0.0000) | Acc: (74.00%) (2011/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.7546) |  Loss2: (0.0000) | Acc: (74.00%) (2944/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.7523) |  Loss2: (0.0000) | Acc: (74.00%) (3894/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.7511) |  Loss2: (0.0000) | Acc: (73.00%) (4819/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.7506) |  Loss2: (0.0000) | Acc: (73.00%) (5752/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.7507) |  Loss2: (0.0000) | Acc: (73.00%) (6683/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.7498) |  Loss2: (0.0000) | Acc: (73.00%) (7617/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.7542) |  Loss2: (0.0000) | Acc: (73.00%) (8539/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.7506) |  Loss2: (0.0000) | Acc: (73.00%) (9488/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.7515) |  Loss2: (0.0000) | Acc: (73.00%) (10416/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.7547) |  Loss2: (0.0000) | Acc: (73.00%) (11347/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.7555) |  Loss2: (0.0000) | Acc: (73.00%) (12286/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.7531) |  Loss2: (0.0000) | Acc: (73.00%) (13235/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.7537) |  Loss2: (0.0000) | Acc: (73.00%) (14157/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.7529) |  Loss2: (0.0000) | Acc: (73.00%) (15102/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.7532) |  Loss2: (0.0000) | Acc: (73.00%) (16038/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.7535) |  Loss2: (0.0000) | Acc: (73.00%) (16967/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.7516) |  Loss2: (0.0000) | Acc: (73.00%) (17922/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.7552) |  Loss2: (0.0000) | Acc: (73.00%) (18827/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.7550) |  Loss2: (0.0000) | Acc: (73.00%) (19769/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.7526) |  Loss2: (0.0000) | Acc: (73.00%) (20721/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.7541) |  Loss2: (0.0000) | Acc: (73.00%) (21638/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.7540) |  Loss2: (0.0000) | Acc: (73.00%) (22568/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.7544) |  Loss2: (0.0000) | Acc: (73.00%) (23511/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.7560) |  Loss2: (0.0000) | Acc: (73.00%) (24439/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.7571) |  Loss2: (0.0000) | Acc: (73.00%) (25367/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.7564) |  Loss2: (0.0000) | Acc: (73.00%) (26314/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.7569) |  Loss2: (0.0000) | Acc: (73.00%) (27245/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.7549) |  Loss2: (0.0000) | Acc: (73.00%) (28203/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.7544) |  Loss2: (0.0000) | Acc: (73.00%) (29138/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.7551) |  Loss2: (0.0000) | Acc: (73.00%) (30064/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.7544) |  Loss2: (0.0000) | Acc: (73.00%) (31014/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.7532) |  Loss2: (0.0000) | Acc: (73.00%) (31969/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.7531) |  Loss2: (0.0000) | Acc: (73.00%) (32909/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.7526) |  Loss2: (0.0000) | Acc: (73.00%) (33854/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.7517) |  Loss2: (0.0000) | Acc: (73.00%) (34815/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.7518) |  Loss2: (0.0000) | Acc: (73.00%) (35746/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.7509) |  Loss2: (0.0000) | Acc: (73.00%) (36678/50000)
# TEST : Loss: (0.7642) | Acc: (73.00%) (7319/10000)
percent tensor([0.5117, 0.5093, 0.5192, 0.5108, 0.5193, 0.5040, 0.5147, 0.5159, 0.5176,
        0.5141, 0.5123, 0.5199, 0.5125, 0.5095, 0.5062, 0.5079],
       device='cuda:0') torch.Size([16])
percent tensor([0.4860, 0.4862, 0.4789, 0.4811, 0.4811, 0.4867, 0.4849, 0.4819, 0.4861,
        0.4834, 0.4885, 0.4795, 0.4866, 0.4888, 0.4840, 0.4870],
       device='cuda:0') torch.Size([16])
percent tensor([0.4765, 0.4634, 0.4434, 0.4718, 0.4517, 0.4896, 0.4558, 0.4519, 0.4905,
        0.4579, 0.4812, 0.4289, 0.4723, 0.5028, 0.4574, 0.4776],
       device='cuda:0') torch.Size([16])
percent tensor([0.4935, 0.5011, 0.4952, 0.4953, 0.4957, 0.4915, 0.4954, 0.4949, 0.4984,
        0.4996, 0.4990, 0.4937, 0.4969, 0.5023, 0.4930, 0.4952],
       device='cuda:0') torch.Size([16])
percent tensor([0.5516, 0.5491, 0.6214, 0.6229, 0.6049, 0.5911, 0.5648, 0.6093, 0.5478,
        0.5585, 0.5392, 0.5838, 0.5299, 0.5493, 0.5615, 0.5547],
       device='cuda:0') torch.Size([16])
percent tensor([0.5071, 0.5052, 0.5014, 0.5031, 0.5083, 0.5221, 0.5020, 0.4932, 0.5093,
        0.5065, 0.5028, 0.4889, 0.5015, 0.5193, 0.4983, 0.5103],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.5701, 0.5689, 0.5834, 0.5624, 0.6581, 0.5547, 0.5464, 0.5704,
        0.5944, 0.5684, 0.5502, 0.5795, 0.6037, 0.5634, 0.6184],
       device='cuda:0') torch.Size([16])
percent tensor([0.9950, 0.9751, 0.9894, 0.9872, 0.9868, 0.9868, 0.9840, 0.9957, 0.9660,
        0.9876, 0.9762, 0.9875, 0.9759, 0.9784, 0.9745, 0.9950],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 24 | Batch_idx: 0 |  Loss: (0.7392) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.7630) |  Loss2: (0.0000) | Acc: (74.00%) (1044/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.7631) |  Loss2: (0.0000) | Acc: (73.00%) (1973/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.7713) |  Loss2: (0.0000) | Acc: (72.00%) (2896/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.7608) |  Loss2: (0.0000) | Acc: (73.00%) (3839/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.7603) |  Loss2: (0.0000) | Acc: (73.00%) (4780/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.7524) |  Loss2: (0.0000) | Acc: (73.00%) (5729/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.7531) |  Loss2: (0.0000) | Acc: (73.00%) (6665/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.7504) |  Loss2: (0.0000) | Acc: (73.00%) (7600/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.7518) |  Loss2: (0.0000) | Acc: (73.00%) (8536/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.7513) |  Loss2: (0.0000) | Acc: (73.00%) (9469/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.7514) |  Loss2: (0.0000) | Acc: (73.00%) (10413/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.7529) |  Loss2: (0.0000) | Acc: (73.00%) (11353/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.7534) |  Loss2: (0.0000) | Acc: (73.00%) (12285/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.7542) |  Loss2: (0.0000) | Acc: (73.00%) (13240/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.7560) |  Loss2: (0.0000) | Acc: (73.00%) (14174/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.7540) |  Loss2: (0.0000) | Acc: (73.00%) (15145/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.7540) |  Loss2: (0.0000) | Acc: (73.00%) (16076/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.7556) |  Loss2: (0.0000) | Acc: (73.00%) (17013/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.7546) |  Loss2: (0.0000) | Acc: (73.00%) (17950/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.7528) |  Loss2: (0.0000) | Acc: (73.00%) (18919/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.7524) |  Loss2: (0.0000) | Acc: (73.00%) (19860/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.7515) |  Loss2: (0.0000) | Acc: (73.00%) (20816/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.7506) |  Loss2: (0.0000) | Acc: (73.00%) (21770/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.7507) |  Loss2: (0.0000) | Acc: (73.00%) (22710/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.7504) |  Loss2: (0.0000) | Acc: (73.00%) (23647/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.7516) |  Loss2: (0.0000) | Acc: (73.00%) (24575/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.7504) |  Loss2: (0.0000) | Acc: (73.00%) (25542/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.7494) |  Loss2: (0.0000) | Acc: (73.00%) (26506/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.7482) |  Loss2: (0.0000) | Acc: (73.00%) (27463/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.7474) |  Loss2: (0.0000) | Acc: (73.00%) (28403/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.7494) |  Loss2: (0.0000) | Acc: (73.00%) (29311/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.7474) |  Loss2: (0.0000) | Acc: (73.00%) (30282/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.7477) |  Loss2: (0.0000) | Acc: (73.00%) (31230/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.7457) |  Loss2: (0.0000) | Acc: (73.00%) (32212/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.7451) |  Loss2: (0.0000) | Acc: (73.00%) (33166/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.7441) |  Loss2: (0.0000) | Acc: (73.00%) (34124/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.7439) |  Loss2: (0.0000) | Acc: (73.00%) (35073/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.7428) |  Loss2: (0.0000) | Acc: (73.00%) (36037/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.7423) |  Loss2: (0.0000) | Acc: (73.00%) (36954/50000)
# TEST : Loss: (0.8039) | Acc: (72.00%) (7235/10000)
percent tensor([0.5112, 0.5084, 0.5177, 0.5092, 0.5183, 0.5033, 0.5139, 0.5137, 0.5178,
        0.5134, 0.5125, 0.5186, 0.5121, 0.5088, 0.5054, 0.5075],
       device='cuda:0') torch.Size([16])
percent tensor([0.4856, 0.4853, 0.4797, 0.4827, 0.4815, 0.4859, 0.4842, 0.4830, 0.4856,
        0.4832, 0.4870, 0.4797, 0.4865, 0.4876, 0.4833, 0.4865],
       device='cuda:0') torch.Size([16])
percent tensor([0.4727, 0.4641, 0.4449, 0.4753, 0.4541, 0.4908, 0.4571, 0.4527, 0.4890,
        0.4590, 0.4826, 0.4320, 0.4658, 0.5063, 0.4587, 0.4761],
       device='cuda:0') torch.Size([16])
percent tensor([0.4924, 0.4998, 0.4947, 0.4954, 0.4957, 0.4919, 0.4948, 0.4947, 0.4971,
        0.4989, 0.4985, 0.4938, 0.4956, 0.5005, 0.4930, 0.4940],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.5561, 0.6130, 0.6227, 0.6049, 0.5912, 0.5730, 0.6048, 0.5589,
        0.5632, 0.5486, 0.5893, 0.5341, 0.5672, 0.5644, 0.5652],
       device='cuda:0') torch.Size([16])
percent tensor([0.5082, 0.5067, 0.5063, 0.5085, 0.5135, 0.5241, 0.5046, 0.4972, 0.5108,
        0.5053, 0.5039, 0.4937, 0.5022, 0.5192, 0.4963, 0.5116],
       device='cuda:0') torch.Size([16])
percent tensor([0.6156, 0.5708, 0.5740, 0.5906, 0.5698, 0.6656, 0.5731, 0.5521, 0.5774,
        0.5788, 0.5738, 0.5501, 0.5855, 0.6019, 0.5597, 0.6298],
       device='cuda:0') torch.Size([16])
percent tensor([0.9951, 0.9757, 0.9872, 0.9882, 0.9826, 0.9908, 0.9890, 0.9957, 0.9687,
        0.9894, 0.9800, 0.9839, 0.9764, 0.9846, 0.9813, 0.9960],
       device='cuda:0') torch.Size([16])
Epoch: 25 | Batch_idx: 0 |  Loss: (0.6541) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.6869) |  Loss2: (0.0000) | Acc: (75.00%) (1062/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.6908) |  Loss2: (0.0000) | Acc: (75.00%) (2036/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.7123) |  Loss2: (0.0000) | Acc: (74.00%) (2971/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.7098) |  Loss2: (0.0000) | Acc: (74.00%) (3915/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.7139) |  Loss2: (0.0000) | Acc: (74.00%) (4856/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.7028) |  Loss2: (0.0000) | Acc: (74.00%) (5835/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.7047) |  Loss2: (0.0000) | Acc: (74.00%) (6785/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.7051) |  Loss2: (0.0000) | Acc: (74.00%) (7752/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.7027) |  Loss2: (0.0000) | Acc: (74.00%) (8729/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.7079) |  Loss2: (0.0000) | Acc: (74.00%) (9665/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.7029) |  Loss2: (0.0000) | Acc: (75.00%) (10656/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.7000) |  Loss2: (0.0000) | Acc: (75.00%) (11641/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.7013) |  Loss2: (0.0000) | Acc: (75.00%) (12598/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.6998) |  Loss2: (0.0000) | Acc: (75.00%) (13585/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.7014) |  Loss2: (0.0000) | Acc: (75.00%) (14534/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.7008) |  Loss2: (0.0000) | Acc: (75.00%) (15514/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.7038) |  Loss2: (0.0000) | Acc: (75.00%) (16465/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.7039) |  Loss2: (0.0000) | Acc: (75.00%) (17428/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.7058) |  Loss2: (0.0000) | Acc: (75.00%) (18369/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.7032) |  Loss2: (0.0000) | Acc: (75.00%) (19350/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.7041) |  Loss2: (0.0000) | Acc: (75.00%) (20296/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.7044) |  Loss2: (0.0000) | Acc: (75.00%) (21262/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.7039) |  Loss2: (0.0000) | Acc: (75.00%) (22231/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.7035) |  Loss2: (0.0000) | Acc: (75.00%) (23189/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.7035) |  Loss2: (0.0000) | Acc: (75.00%) (24143/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.7043) |  Loss2: (0.0000) | Acc: (75.00%) (25097/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.7070) |  Loss2: (0.0000) | Acc: (74.00%) (26010/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.7062) |  Loss2: (0.0000) | Acc: (75.00%) (26988/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.7069) |  Loss2: (0.0000) | Acc: (75.00%) (27936/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.7077) |  Loss2: (0.0000) | Acc: (74.00%) (28887/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.7074) |  Loss2: (0.0000) | Acc: (75.00%) (29868/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.7064) |  Loss2: (0.0000) | Acc: (75.00%) (30859/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.7051) |  Loss2: (0.0000) | Acc: (75.00%) (31855/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.7044) |  Loss2: (0.0000) | Acc: (75.00%) (32811/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.7039) |  Loss2: (0.0000) | Acc: (75.00%) (33785/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.7050) |  Loss2: (0.0000) | Acc: (75.00%) (34720/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.7050) |  Loss2: (0.0000) | Acc: (75.00%) (35674/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.7053) |  Loss2: (0.0000) | Acc: (75.00%) (36631/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.7055) |  Loss2: (0.0000) | Acc: (75.00%) (37575/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_025.pth.tar'
# TEST : Loss: (0.7709) | Acc: (73.00%) (7327/10000)
percent tensor([0.5112, 0.5084, 0.5176, 0.5089, 0.5183, 0.5028, 0.5139, 0.5138, 0.5177,
        0.5136, 0.5125, 0.5184, 0.5121, 0.5090, 0.5052, 0.5075],
       device='cuda:0') torch.Size([16])
percent tensor([0.4856, 0.4855, 0.4811, 0.4828, 0.4825, 0.4857, 0.4848, 0.4835, 0.4853,
        0.4839, 0.4870, 0.4810, 0.4864, 0.4872, 0.4835, 0.4864],
       device='cuda:0') torch.Size([16])
percent tensor([0.4735, 0.4614, 0.4423, 0.4736, 0.4492, 0.4897, 0.4551, 0.4484, 0.4885,
        0.4576, 0.4823, 0.4295, 0.4667, 0.5054, 0.4564, 0.4773],
       device='cuda:0') torch.Size([16])
percent tensor([0.4927, 0.4998, 0.4941, 0.4948, 0.4951, 0.4921, 0.4948, 0.4943, 0.4979,
        0.4986, 0.4989, 0.4931, 0.4965, 0.5018, 0.4928, 0.4945],
       device='cuda:0') torch.Size([16])
percent tensor([0.5554, 0.5591, 0.6146, 0.6156, 0.6046, 0.5846, 0.5745, 0.6040, 0.5613,
        0.5656, 0.5551, 0.5866, 0.5373, 0.5612, 0.5639, 0.5613],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.5052, 0.5019, 0.5030, 0.5093, 0.5231, 0.5025, 0.4952, 0.5117,
        0.5037, 0.5049, 0.4880, 0.5042, 0.5200, 0.4964, 0.5106],
       device='cuda:0') torch.Size([16])
percent tensor([0.6193, 0.5671, 0.5669, 0.5769, 0.5547, 0.6598, 0.5574, 0.5458, 0.5761,
        0.5808, 0.5718, 0.5504, 0.5955, 0.5974, 0.5614, 0.6252],
       device='cuda:0') torch.Size([16])
percent tensor([0.9958, 0.9830, 0.9858, 0.9868, 0.9821, 0.9890, 0.9884, 0.9946, 0.9693,
        0.9907, 0.9821, 0.9852, 0.9791, 0.9839, 0.9834, 0.9968],
       device='cuda:0') torch.Size([16])
Epoch: 26 | Batch_idx: 0 |  Loss: (0.6995) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.6713) |  Loss2: (0.0000) | Acc: (76.00%) (1081/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.6785) |  Loss2: (0.0000) | Acc: (75.00%) (2035/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.6740) |  Loss2: (0.0000) | Acc: (76.00%) (3036/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.6760) |  Loss2: (0.0000) | Acc: (76.00%) (4016/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.6725) |  Loss2: (0.0000) | Acc: (76.00%) (5005/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.6737) |  Loss2: (0.0000) | Acc: (76.00%) (5973/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.6702) |  Loss2: (0.0000) | Acc: (76.00%) (6966/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.6720) |  Loss2: (0.0000) | Acc: (76.00%) (7938/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.6712) |  Loss2: (0.0000) | Acc: (76.00%) (8930/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.6675) |  Loss2: (0.0000) | Acc: (76.00%) (9927/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.6670) |  Loss2: (0.0000) | Acc: (76.00%) (10923/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.6676) |  Loss2: (0.0000) | Acc: (76.00%) (11905/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.6679) |  Loss2: (0.0000) | Acc: (76.00%) (12878/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.6673) |  Loss2: (0.0000) | Acc: (76.00%) (13855/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.6689) |  Loss2: (0.0000) | Acc: (76.00%) (14837/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.6702) |  Loss2: (0.0000) | Acc: (76.00%) (15805/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.6711) |  Loss2: (0.0000) | Acc: (76.00%) (16766/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.6704) |  Loss2: (0.0000) | Acc: (76.00%) (17762/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.6708) |  Loss2: (0.0000) | Acc: (76.00%) (18730/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.6685) |  Loss2: (0.0000) | Acc: (76.00%) (19720/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.6715) |  Loss2: (0.0000) | Acc: (76.00%) (20668/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.6726) |  Loss2: (0.0000) | Acc: (76.00%) (21644/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.6717) |  Loss2: (0.0000) | Acc: (76.00%) (22628/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.6733) |  Loss2: (0.0000) | Acc: (76.00%) (23599/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.6711) |  Loss2: (0.0000) | Acc: (76.00%) (24605/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.6718) |  Loss2: (0.0000) | Acc: (76.00%) (25580/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.6717) |  Loss2: (0.0000) | Acc: (76.00%) (26570/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.6714) |  Loss2: (0.0000) | Acc: (76.00%) (27582/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.6705) |  Loss2: (0.0000) | Acc: (76.00%) (28565/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.6697) |  Loss2: (0.0000) | Acc: (76.00%) (29558/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.6677) |  Loss2: (0.0000) | Acc: (76.00%) (30565/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.6660) |  Loss2: (0.0000) | Acc: (76.00%) (31575/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.6663) |  Loss2: (0.0000) | Acc: (76.00%) (32545/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.6657) |  Loss2: (0.0000) | Acc: (76.00%) (33533/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.6663) |  Loss2: (0.0000) | Acc: (76.00%) (34516/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.6667) |  Loss2: (0.0000) | Acc: (76.00%) (35497/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.6656) |  Loss2: (0.0000) | Acc: (76.00%) (36494/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.6662) |  Loss2: (0.0000) | Acc: (76.00%) (37457/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.6657) |  Loss2: (0.0000) | Acc: (76.00%) (38400/50000)
# TEST : Loss: (0.7126) | Acc: (74.00%) (7472/10000)
percent tensor([0.5106, 0.5093, 0.5166, 0.5104, 0.5174, 0.5031, 0.5138, 0.5143, 0.5162,
        0.5136, 0.5117, 0.5175, 0.5115, 0.5105, 0.5058, 0.5081],
       device='cuda:0') torch.Size([16])
percent tensor([0.4854, 0.4860, 0.4801, 0.4825, 0.4821, 0.4850, 0.4854, 0.4830, 0.4854,
        0.4842, 0.4873, 0.4809, 0.4863, 0.4882, 0.4836, 0.4863],
       device='cuda:0') torch.Size([16])
percent tensor([0.4750, 0.4626, 0.4463, 0.4742, 0.4526, 0.4875, 0.4565, 0.4530, 0.4866,
        0.4605, 0.4826, 0.4311, 0.4673, 0.5041, 0.4567, 0.4779],
       device='cuda:0') torch.Size([16])
percent tensor([0.4929, 0.4991, 0.4948, 0.4943, 0.4950, 0.4914, 0.4939, 0.4949, 0.4984,
        0.4992, 0.4994, 0.4932, 0.4965, 0.5012, 0.4922, 0.4941],
       device='cuda:0') torch.Size([16])
percent tensor([0.5529, 0.5434, 0.6219, 0.6178, 0.6087, 0.5862, 0.5653, 0.5989, 0.5480,
        0.5581, 0.5455, 0.5893, 0.5302, 0.5458, 0.5586, 0.5537],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.5011, 0.5036, 0.5073, 0.5117, 0.5204, 0.5000, 0.4965, 0.5078,
        0.5034, 0.5032, 0.4899, 0.5006, 0.5167, 0.4944, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.6142, 0.5586, 0.5789, 0.5924, 0.5727, 0.6591, 0.5620, 0.5487, 0.5722,
        0.5802, 0.5738, 0.5488, 0.5806, 0.6045, 0.5517, 0.6095],
       device='cuda:0') torch.Size([16])
percent tensor([0.9936, 0.9734, 0.9900, 0.9861, 0.9893, 0.9892, 0.9872, 0.9938, 0.9636,
        0.9883, 0.9765, 0.9840, 0.9753, 0.9818, 0.9778, 0.9930],
       device='cuda:0') torch.Size([16])
Epoch: 27 | Batch_idx: 0 |  Loss: (0.6128) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.6019) |  Loss2: (0.0000) | Acc: (79.00%) (1115/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.6193) |  Loss2: (0.0000) | Acc: (78.00%) (2113/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.6195) |  Loss2: (0.0000) | Acc: (78.00%) (3104/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.6207) |  Loss2: (0.0000) | Acc: (78.00%) (4128/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.6220) |  Loss2: (0.0000) | Acc: (78.00%) (5115/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.6287) |  Loss2: (0.0000) | Acc: (77.00%) (6088/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.6385) |  Loss2: (0.0000) | Acc: (77.00%) (7076/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.6400) |  Loss2: (0.0000) | Acc: (77.00%) (8062/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.6353) |  Loss2: (0.0000) | Acc: (77.00%) (9074/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.6357) |  Loss2: (0.0000) | Acc: (77.00%) (10068/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.6393) |  Loss2: (0.0000) | Acc: (77.00%) (11047/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.6406) |  Loss2: (0.0000) | Acc: (77.00%) (12042/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.6412) |  Loss2: (0.0000) | Acc: (77.00%) (13022/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.6401) |  Loss2: (0.0000) | Acc: (77.00%) (14024/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.6385) |  Loss2: (0.0000) | Acc: (77.00%) (15020/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.6399) |  Loss2: (0.0000) | Acc: (77.00%) (16004/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.6376) |  Loss2: (0.0000) | Acc: (77.00%) (17011/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.6368) |  Loss2: (0.0000) | Acc: (77.00%) (18019/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.6356) |  Loss2: (0.0000) | Acc: (77.00%) (19022/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.6362) |  Loss2: (0.0000) | Acc: (77.00%) (20008/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.6347) |  Loss2: (0.0000) | Acc: (77.00%) (21028/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.6339) |  Loss2: (0.0000) | Acc: (77.00%) (22027/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.6335) |  Loss2: (0.0000) | Acc: (77.00%) (23020/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.6343) |  Loss2: (0.0000) | Acc: (77.00%) (24009/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.6366) |  Loss2: (0.0000) | Acc: (77.00%) (24976/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.6370) |  Loss2: (0.0000) | Acc: (77.00%) (25963/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.6377) |  Loss2: (0.0000) | Acc: (77.00%) (26956/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.6387) |  Loss2: (0.0000) | Acc: (77.00%) (27941/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.6383) |  Loss2: (0.0000) | Acc: (77.00%) (28950/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.6363) |  Loss2: (0.0000) | Acc: (77.00%) (29974/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.6362) |  Loss2: (0.0000) | Acc: (77.00%) (30974/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.6360) |  Loss2: (0.0000) | Acc: (77.00%) (31978/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.6357) |  Loss2: (0.0000) | Acc: (77.00%) (32969/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.6358) |  Loss2: (0.0000) | Acc: (77.00%) (33955/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.6359) |  Loss2: (0.0000) | Acc: (77.00%) (34956/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.6356) |  Loss2: (0.0000) | Acc: (77.00%) (35955/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.6355) |  Loss2: (0.0000) | Acc: (77.00%) (36954/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.6366) |  Loss2: (0.0000) | Acc: (77.00%) (37943/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.6362) |  Loss2: (0.0000) | Acc: (77.00%) (38907/50000)
# TEST : Loss: (0.7248) | Acc: (74.00%) (7445/10000)
percent tensor([0.5108, 0.5088, 0.5168, 0.5094, 0.5178, 0.5027, 0.5136, 0.5136, 0.5167,
        0.5137, 0.5115, 0.5181, 0.5115, 0.5095, 0.5055, 0.5079],
       device='cuda:0') torch.Size([16])
percent tensor([0.4851, 0.4855, 0.4811, 0.4837, 0.4828, 0.4847, 0.4849, 0.4837, 0.4850,
        0.4840, 0.4864, 0.4813, 0.4857, 0.4869, 0.4832, 0.4860],
       device='cuda:0') torch.Size([16])
percent tensor([0.4706, 0.4640, 0.4489, 0.4755, 0.4552, 0.4883, 0.4575, 0.4526, 0.4856,
        0.4608, 0.4824, 0.4354, 0.4611, 0.5050, 0.4588, 0.4767],
       device='cuda:0') torch.Size([16])
percent tensor([0.4928, 0.4991, 0.4966, 0.4957, 0.4971, 0.4922, 0.4949, 0.4949, 0.4983,
        0.4995, 0.4992, 0.4946, 0.4964, 0.5016, 0.4928, 0.4945],
       device='cuda:0') torch.Size([16])
percent tensor([0.5528, 0.5499, 0.6099, 0.6121, 0.5998, 0.5873, 0.5654, 0.5939, 0.5525,
        0.5578, 0.5513, 0.5811, 0.5343, 0.5608, 0.5603, 0.5599],
       device='cuda:0') torch.Size([16])
percent tensor([0.5082, 0.5032, 0.5046, 0.5049, 0.5108, 0.5215, 0.5021, 0.4949, 0.5071,
        0.5058, 0.5050, 0.4923, 0.4993, 0.5181, 0.4960, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.6073, 0.5565, 0.5717, 0.5798, 0.5587, 0.6664, 0.5546, 0.5384, 0.5696,
        0.5783, 0.5765, 0.5490, 0.5666, 0.5966, 0.5578, 0.6102],
       device='cuda:0') torch.Size([16])
percent tensor([0.9945, 0.9742, 0.9858, 0.9842, 0.9813, 0.9902, 0.9867, 0.9913, 0.9719,
        0.9864, 0.9789, 0.9831, 0.9785, 0.9776, 0.9869, 0.9938],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 28 | Batch_idx: 0 |  Loss: (0.6074) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.6102) |  Loss2: (0.0000) | Acc: (78.00%) (1101/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.6519) |  Loss2: (0.0000) | Acc: (77.00%) (2082/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.6864) |  Loss2: (0.0000) | Acc: (76.00%) (3031/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.7053) |  Loss2: (0.0000) | Acc: (75.00%) (3968/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.7084) |  Loss2: (0.0000) | Acc: (74.00%) (4894/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.7079) |  Loss2: (0.0000) | Acc: (74.00%) (5851/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.7089) |  Loss2: (0.0000) | Acc: (74.00%) (6804/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.7125) |  Loss2: (0.0000) | Acc: (74.00%) (7743/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.7131) |  Loss2: (0.0000) | Acc: (74.00%) (8706/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.7098) |  Loss2: (0.0000) | Acc: (74.00%) (9684/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.7058) |  Loss2: (0.0000) | Acc: (74.00%) (10652/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.7057) |  Loss2: (0.0000) | Acc: (75.00%) (11617/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.7050) |  Loss2: (0.0000) | Acc: (75.00%) (12578/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.7036) |  Loss2: (0.0000) | Acc: (75.00%) (13554/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.7019) |  Loss2: (0.0000) | Acc: (75.00%) (14521/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.6996) |  Loss2: (0.0000) | Acc: (75.00%) (15498/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.6962) |  Loss2: (0.0000) | Acc: (75.00%) (16485/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.6948) |  Loss2: (0.0000) | Acc: (75.00%) (17455/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.6955) |  Loss2: (0.0000) | Acc: (75.00%) (18417/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.6941) |  Loss2: (0.0000) | Acc: (75.00%) (19418/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.6919) |  Loss2: (0.0000) | Acc: (75.00%) (20397/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.6909) |  Loss2: (0.0000) | Acc: (75.00%) (21364/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.6908) |  Loss2: (0.0000) | Acc: (75.00%) (22340/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.6912) |  Loss2: (0.0000) | Acc: (75.00%) (23317/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.6905) |  Loss2: (0.0000) | Acc: (75.00%) (24282/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.6915) |  Loss2: (0.0000) | Acc: (75.00%) (25230/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.6894) |  Loss2: (0.0000) | Acc: (75.00%) (26232/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.6887) |  Loss2: (0.0000) | Acc: (75.00%) (27211/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.6897) |  Loss2: (0.0000) | Acc: (75.00%) (28168/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.6881) |  Loss2: (0.0000) | Acc: (75.00%) (29156/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.6889) |  Loss2: (0.0000) | Acc: (75.00%) (30130/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.6887) |  Loss2: (0.0000) | Acc: (75.00%) (31103/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.6875) |  Loss2: (0.0000) | Acc: (75.00%) (32095/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.6879) |  Loss2: (0.0000) | Acc: (75.00%) (33064/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.6866) |  Loss2: (0.0000) | Acc: (75.00%) (34063/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.6854) |  Loss2: (0.0000) | Acc: (75.00%) (35064/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.6848) |  Loss2: (0.0000) | Acc: (75.00%) (36031/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.6842) |  Loss2: (0.0000) | Acc: (75.00%) (37010/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.6834) |  Loss2: (0.0000) | Acc: (75.00%) (37959/50000)
# TEST : Loss: (0.6812) | Acc: (75.00%) (7585/10000)
percent tensor([0.5140, 0.5129, 0.5185, 0.5120, 0.5204, 0.5059, 0.5174, 0.5168, 0.5203,
        0.5174, 0.5158, 0.5203, 0.5149, 0.5138, 0.5093, 0.5115],
       device='cuda:0') torch.Size([16])
percent tensor([0.4920, 0.4930, 0.4865, 0.4899, 0.4885, 0.4910, 0.4920, 0.4898, 0.4913,
        0.4908, 0.4935, 0.4874, 0.4922, 0.4938, 0.4909, 0.4927],
       device='cuda:0') torch.Size([16])
percent tensor([0.4522, 0.4370, 0.4227, 0.4569, 0.4285, 0.4782, 0.4288, 0.4245, 0.4621,
        0.4315, 0.4593, 0.4016, 0.4386, 0.4889, 0.4351, 0.4590],
       device='cuda:0') torch.Size([16])
percent tensor([0.4976, 0.5043, 0.4997, 0.4989, 0.5001, 0.4941, 0.5000, 0.4988, 0.5038,
        0.5049, 0.5055, 0.4984, 0.5012, 0.5072, 0.4978, 0.4983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5721, 0.5409, 0.6638, 0.6711, 0.6583, 0.6406, 0.5769, 0.6438, 0.5509,
        0.5353, 0.5289, 0.5984, 0.5266, 0.5531, 0.5772, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5087, 0.5246, 0.5244, 0.5344, 0.5396, 0.5120, 0.5129, 0.5145,
        0.5106, 0.5087, 0.5004, 0.5007, 0.5260, 0.4998, 0.5204],
       device='cuda:0') torch.Size([16])
percent tensor([0.6162, 0.5628, 0.6389, 0.6446, 0.6334, 0.7210, 0.5832, 0.5929, 0.5881,
        0.5839, 0.5736, 0.5865, 0.5618, 0.6161, 0.5676, 0.6364],
       device='cuda:0') torch.Size([16])
percent tensor([0.9962, 0.9767, 0.9893, 0.9880, 0.9834, 0.9943, 0.9887, 0.9926, 0.9780,
        0.9884, 0.9815, 0.9850, 0.9800, 0.9831, 0.9875, 0.9953],
       device='cuda:0') torch.Size([16])
Epoch: 29 | Batch_idx: 0 |  Loss: (0.8228) |  Loss2: (0.0000) | Acc: (71.00%) (91/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.6526) |  Loss2: (0.0000) | Acc: (77.00%) (1090/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.6619) |  Loss2: (0.0000) | Acc: (77.00%) (2076/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.6723) |  Loss2: (0.0000) | Acc: (76.00%) (3036/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.6738) |  Loss2: (0.0000) | Acc: (76.00%) (4020/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.6664) |  Loss2: (0.0000) | Acc: (76.00%) (5018/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.6699) |  Loss2: (0.0000) | Acc: (76.00%) (5991/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.6671) |  Loss2: (0.0000) | Acc: (76.00%) (6984/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.6645) |  Loss2: (0.0000) | Acc: (77.00%) (7987/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.6666) |  Loss2: (0.0000) | Acc: (76.00%) (8946/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.6660) |  Loss2: (0.0000) | Acc: (76.00%) (9928/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.6609) |  Loss2: (0.0000) | Acc: (76.00%) (10939/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.6565) |  Loss2: (0.0000) | Acc: (77.00%) (11956/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.6564) |  Loss2: (0.0000) | Acc: (77.00%) (12939/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.6519) |  Loss2: (0.0000) | Acc: (77.00%) (13975/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.6511) |  Loss2: (0.0000) | Acc: (77.00%) (14958/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.6494) |  Loss2: (0.0000) | Acc: (77.00%) (15964/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.6511) |  Loss2: (0.0000) | Acc: (77.00%) (16932/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.6494) |  Loss2: (0.0000) | Acc: (77.00%) (17929/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.6498) |  Loss2: (0.0000) | Acc: (77.00%) (18925/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.6495) |  Loss2: (0.0000) | Acc: (77.00%) (19908/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.6491) |  Loss2: (0.0000) | Acc: (77.00%) (20897/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.6482) |  Loss2: (0.0000) | Acc: (77.00%) (21895/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.6475) |  Loss2: (0.0000) | Acc: (77.00%) (22898/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.6453) |  Loss2: (0.0000) | Acc: (77.00%) (23914/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.6463) |  Loss2: (0.0000) | Acc: (77.00%) (24891/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.6458) |  Loss2: (0.0000) | Acc: (77.00%) (25889/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.6467) |  Loss2: (0.0000) | Acc: (77.00%) (26865/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.6456) |  Loss2: (0.0000) | Acc: (77.00%) (27859/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.6445) |  Loss2: (0.0000) | Acc: (77.00%) (28860/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.6465) |  Loss2: (0.0000) | Acc: (77.00%) (29820/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.6469) |  Loss2: (0.0000) | Acc: (77.00%) (30809/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.6453) |  Loss2: (0.0000) | Acc: (77.00%) (31807/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.6455) |  Loss2: (0.0000) | Acc: (77.00%) (32802/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.6443) |  Loss2: (0.0000) | Acc: (77.00%) (33830/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.6430) |  Loss2: (0.0000) | Acc: (77.00%) (34845/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.6425) |  Loss2: (0.0000) | Acc: (77.00%) (35849/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.6414) |  Loss2: (0.0000) | Acc: (77.00%) (36868/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.6412) |  Loss2: (0.0000) | Acc: (77.00%) (37866/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.6413) |  Loss2: (0.0000) | Acc: (77.00%) (38817/50000)
# TEST : Loss: (0.6546) | Acc: (76.00%) (7677/10000)
percent tensor([0.5147, 0.5150, 0.5179, 0.5118, 0.5203, 0.5061, 0.5188, 0.5173, 0.5219,
        0.5185, 0.5177, 0.5203, 0.5161, 0.5165, 0.5103, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.4951, 0.4962, 0.4887, 0.4926, 0.4908, 0.4938, 0.4950, 0.4924, 0.4939,
        0.4937, 0.4967, 0.4899, 0.4951, 0.4967, 0.4942, 0.4956],
       device='cuda:0') torch.Size([16])
percent tensor([0.4546, 0.4369, 0.4212, 0.4581, 0.4292, 0.4855, 0.4286, 0.4245, 0.4626,
        0.4293, 0.4594, 0.3992, 0.4388, 0.4905, 0.4379, 0.4607],
       device='cuda:0') torch.Size([16])
percent tensor([0.5008, 0.5082, 0.5018, 0.5006, 0.5023, 0.4950, 0.5036, 0.5012, 0.5077,
        0.5087, 0.5099, 0.5012, 0.5049, 0.5111, 0.5012, 0.5005],
       device='cuda:0') torch.Size([16])
percent tensor([0.5730, 0.5336, 0.6730, 0.6791, 0.6702, 0.6508, 0.5769, 0.6519, 0.5473,
        0.5214, 0.5192, 0.6006, 0.5226, 0.5437, 0.5814, 0.5778],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5184, 0.5470, 0.5456, 0.5586, 0.5604, 0.5247, 0.5319, 0.5267,
        0.5228, 0.5187, 0.5129, 0.5057, 0.5393, 0.5088, 0.5329],
       device='cuda:0') torch.Size([16])
percent tensor([0.6295, 0.5656, 0.6807, 0.6853, 0.6722, 0.7568, 0.5993, 0.6214, 0.5995,
        0.5942, 0.5779, 0.6114, 0.5628, 0.6343, 0.5742, 0.6497],
       device='cuda:0') torch.Size([16])
percent tensor([0.9974, 0.9813, 0.9926, 0.9911, 0.9879, 0.9953, 0.9914, 0.9946, 0.9823,
        0.9918, 0.9861, 0.9879, 0.9842, 0.9874, 0.9904, 0.9966],
       device='cuda:0') torch.Size([16])
Epoch: 30 | Batch_idx: 0 |  Loss: (0.6671) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.6446) |  Loss2: (0.0000) | Acc: (78.00%) (1101/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.6553) |  Loss2: (0.0000) | Acc: (77.00%) (2074/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.6494) |  Loss2: (0.0000) | Acc: (77.00%) (3067/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.6424) |  Loss2: (0.0000) | Acc: (77.00%) (4085/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.6371) |  Loss2: (0.0000) | Acc: (77.00%) (5091/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.6422) |  Loss2: (0.0000) | Acc: (77.00%) (6061/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.6415) |  Loss2: (0.0000) | Acc: (77.00%) (7054/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.6402) |  Loss2: (0.0000) | Acc: (77.00%) (8062/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.6402) |  Loss2: (0.0000) | Acc: (77.00%) (9061/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.6371) |  Loss2: (0.0000) | Acc: (77.00%) (10065/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.6371) |  Loss2: (0.0000) | Acc: (77.00%) (11074/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.6320) |  Loss2: (0.0000) | Acc: (78.00%) (12112/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.6314) |  Loss2: (0.0000) | Acc: (78.00%) (13127/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.6329) |  Loss2: (0.0000) | Acc: (78.00%) (14103/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.6328) |  Loss2: (0.0000) | Acc: (78.00%) (15095/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.6294) |  Loss2: (0.0000) | Acc: (78.00%) (16124/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.6277) |  Loss2: (0.0000) | Acc: (78.00%) (17145/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.6280) |  Loss2: (0.0000) | Acc: (78.00%) (18138/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.6275) |  Loss2: (0.0000) | Acc: (78.00%) (19140/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.6241) |  Loss2: (0.0000) | Acc: (78.00%) (20169/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.6212) |  Loss2: (0.0000) | Acc: (78.00%) (21192/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.6223) |  Loss2: (0.0000) | Acc: (78.00%) (22192/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.6228) |  Loss2: (0.0000) | Acc: (78.00%) (23195/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.6215) |  Loss2: (0.0000) | Acc: (78.00%) (24205/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.6214) |  Loss2: (0.0000) | Acc: (78.00%) (25231/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.6231) |  Loss2: (0.0000) | Acc: (78.00%) (26196/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.6238) |  Loss2: (0.0000) | Acc: (78.00%) (27191/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.6235) |  Loss2: (0.0000) | Acc: (78.00%) (28195/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.6223) |  Loss2: (0.0000) | Acc: (78.00%) (29224/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.6219) |  Loss2: (0.0000) | Acc: (78.00%) (30250/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.6220) |  Loss2: (0.0000) | Acc: (78.00%) (31255/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.6213) |  Loss2: (0.0000) | Acc: (78.00%) (32273/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.6214) |  Loss2: (0.0000) | Acc: (78.00%) (33274/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.6219) |  Loss2: (0.0000) | Acc: (78.00%) (34257/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.6217) |  Loss2: (0.0000) | Acc: (78.00%) (35251/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.6217) |  Loss2: (0.0000) | Acc: (78.00%) (36263/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.6216) |  Loss2: (0.0000) | Acc: (78.00%) (37259/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.6213) |  Loss2: (0.0000) | Acc: (78.00%) (38258/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.6214) |  Loss2: (0.0000) | Acc: (78.00%) (39208/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_030.pth.tar'
# TEST : Loss: (0.6399) | Acc: (77.00%) (7714/10000)
percent tensor([0.5149, 0.5158, 0.5171, 0.5112, 0.5198, 0.5059, 0.5192, 0.5172, 0.5225,
        0.5188, 0.5186, 0.5200, 0.5165, 0.5177, 0.5106, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.4945, 0.4956, 0.4873, 0.4917, 0.4895, 0.4938, 0.4941, 0.4912, 0.4929,
        0.4928, 0.4961, 0.4886, 0.4943, 0.4960, 0.4937, 0.4952],
       device='cuda:0') torch.Size([16])
percent tensor([0.4589, 0.4408, 0.4229, 0.4616, 0.4321, 0.4916, 0.4322, 0.4281, 0.4658,
        0.4321, 0.4630, 0.4020, 0.4428, 0.4936, 0.4437, 0.4649],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.5099, 0.5020, 0.5008, 0.5024, 0.4946, 0.5049, 0.5016, 0.5095,
        0.5100, 0.5121, 0.5020, 0.5066, 0.5133, 0.5025, 0.5009],
       device='cuda:0') torch.Size([16])
percent tensor([0.5708, 0.5319, 0.6741, 0.6794, 0.6710, 0.6522, 0.5740, 0.6515, 0.5426,
        0.5165, 0.5167, 0.6005, 0.5215, 0.5377, 0.5811, 0.5746],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5244, 0.5614, 0.5601, 0.5748, 0.5765, 0.5315, 0.5418, 0.5347,
        0.5301, 0.5253, 0.5199, 0.5079, 0.5491, 0.5121, 0.5405],
       device='cuda:0') torch.Size([16])
percent tensor([0.6378, 0.5679, 0.6990, 0.7027, 0.6861, 0.7757, 0.6048, 0.6294, 0.6066,
        0.5979, 0.5825, 0.6238, 0.5667, 0.6458, 0.5762, 0.6579],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9849, 0.9949, 0.9935, 0.9910, 0.9964, 0.9935, 0.9961, 0.9859,
        0.9939, 0.9892, 0.9906, 0.9871, 0.9904, 0.9925, 0.9977],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(168.8707, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(789.1555, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(785.6388, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.6169, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(508.2636, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2175.5500, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4305.9048, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1434.9670, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6084.6670, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12135.5693, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4052.1487, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17123.1738, device='cuda:0')
Epoch: 31 | Batch_idx: 0 |  Loss: (0.7535) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.6721) |  Loss2: (0.0000) | Acc: (77.00%) (1091/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.6523) |  Loss2: (0.0000) | Acc: (77.00%) (2083/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.6442) |  Loss2: (0.0000) | Acc: (77.00%) (3085/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.6354) |  Loss2: (0.0000) | Acc: (78.00%) (4103/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.6333) |  Loss2: (0.0000) | Acc: (78.00%) (5098/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.6359) |  Loss2: (0.0000) | Acc: (77.00%) (6082/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.6361) |  Loss2: (0.0000) | Acc: (77.00%) (7076/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.6339) |  Loss2: (0.0000) | Acc: (77.00%) (8082/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.6385) |  Loss2: (0.0000) | Acc: (77.00%) (9061/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.6342) |  Loss2: (0.0000) | Acc: (77.00%) (10065/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.6301) |  Loss2: (0.0000) | Acc: (78.00%) (11084/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.6289) |  Loss2: (0.0000) | Acc: (78.00%) (12090/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.6231) |  Loss2: (0.0000) | Acc: (78.00%) (13121/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.6238) |  Loss2: (0.0000) | Acc: (78.00%) (14117/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.6265) |  Loss2: (0.0000) | Acc: (78.00%) (15099/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.6256) |  Loss2: (0.0000) | Acc: (78.00%) (16107/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.6231) |  Loss2: (0.0000) | Acc: (78.00%) (17133/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.6239) |  Loss2: (0.0000) | Acc: (78.00%) (18136/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.6224) |  Loss2: (0.0000) | Acc: (78.00%) (19175/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.6228) |  Loss2: (0.0000) | Acc: (78.00%) (20172/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.6241) |  Loss2: (0.0000) | Acc: (78.00%) (21151/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.6232) |  Loss2: (0.0000) | Acc: (78.00%) (22160/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.6237) |  Loss2: (0.0000) | Acc: (78.00%) (23172/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.6222) |  Loss2: (0.0000) | Acc: (78.00%) (24188/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.6211) |  Loss2: (0.0000) | Acc: (78.00%) (25215/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.6199) |  Loss2: (0.0000) | Acc: (78.00%) (26212/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.6196) |  Loss2: (0.0000) | Acc: (78.00%) (27218/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.6187) |  Loss2: (0.0000) | Acc: (78.00%) (28250/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.6188) |  Loss2: (0.0000) | Acc: (78.00%) (29246/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.6172) |  Loss2: (0.0000) | Acc: (78.00%) (30271/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.6171) |  Loss2: (0.0000) | Acc: (78.00%) (31289/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.6173) |  Loss2: (0.0000) | Acc: (78.00%) (32276/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.6155) |  Loss2: (0.0000) | Acc: (78.00%) (33301/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.6151) |  Loss2: (0.0000) | Acc: (78.00%) (34317/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.6148) |  Loss2: (0.0000) | Acc: (78.00%) (35341/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.6152) |  Loss2: (0.0000) | Acc: (78.00%) (36343/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.6150) |  Loss2: (0.0000) | Acc: (78.00%) (37356/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.6147) |  Loss2: (0.0000) | Acc: (78.00%) (38362/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.6131) |  Loss2: (0.0000) | Acc: (78.00%) (39369/50000)
# TEST : Loss: (0.6286) | Acc: (77.00%) (7754/10000)
percent tensor([0.5144, 0.5162, 0.5153, 0.5099, 0.5184, 0.5053, 0.5189, 0.5163, 0.5225,
        0.5184, 0.5189, 0.5186, 0.5163, 0.5186, 0.5103, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.4948, 0.4960, 0.4870, 0.4917, 0.4893, 0.4943, 0.4942, 0.4912, 0.4928,
        0.4929, 0.4965, 0.4885, 0.4946, 0.4962, 0.4941, 0.4955],
       device='cuda:0') torch.Size([16])
percent tensor([0.4641, 0.4467, 0.4246, 0.4646, 0.4351, 0.4967, 0.4375, 0.4315, 0.4701,
        0.4369, 0.4679, 0.4059, 0.4487, 0.4970, 0.4501, 0.4700],
       device='cuda:0') torch.Size([16])
percent tensor([0.5036, 0.5124, 0.5031, 0.5017, 0.5035, 0.4950, 0.5071, 0.5028, 0.5121,
        0.5125, 0.5154, 0.5035, 0.5089, 0.5163, 0.5045, 0.5021],
       device='cuda:0') torch.Size([16])
percent tensor([0.5729, 0.5400, 0.6780, 0.6798, 0.6737, 0.6493, 0.5788, 0.6532, 0.5500,
        0.5216, 0.5246, 0.6076, 0.5304, 0.5429, 0.5831, 0.5760],
       device='cuda:0') torch.Size([16])
percent tensor([0.5407, 0.5379, 0.5802, 0.5792, 0.5944, 0.5939, 0.5456, 0.5593, 0.5494,
        0.5451, 0.5395, 0.5335, 0.5176, 0.5639, 0.5243, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.6448, 0.5724, 0.6965, 0.7028, 0.6804, 0.7828, 0.6056, 0.6181, 0.6144,
        0.6007, 0.5898, 0.6250, 0.5752, 0.6542, 0.5766, 0.6610],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9881, 0.9959, 0.9947, 0.9927, 0.9971, 0.9949, 0.9969, 0.9887,
        0.9954, 0.9916, 0.9925, 0.9898, 0.9928, 0.9941, 0.9982],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 32 | Batch_idx: 0 |  Loss: (0.6695) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.6294) |  Loss2: (0.0000) | Acc: (78.00%) (1103/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.6056) |  Loss2: (0.0000) | Acc: (79.00%) (2146/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5946) |  Loss2: (0.0000) | Acc: (80.00%) (3175/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5985) |  Loss2: (0.0000) | Acc: (79.00%) (4171/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.6004) |  Loss2: (0.0000) | Acc: (79.00%) (5186/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.6044) |  Loss2: (0.0000) | Acc: (79.00%) (6179/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.6023) |  Loss2: (0.0000) | Acc: (79.00%) (7201/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.6030) |  Loss2: (0.0000) | Acc: (79.00%) (8204/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.6058) |  Loss2: (0.0000) | Acc: (78.00%) (9197/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.6018) |  Loss2: (0.0000) | Acc: (79.00%) (10215/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.6041) |  Loss2: (0.0000) | Acc: (78.00%) (11202/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.6028) |  Loss2: (0.0000) | Acc: (78.00%) (12228/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.6049) |  Loss2: (0.0000) | Acc: (78.00%) (13225/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.6064) |  Loss2: (0.0000) | Acc: (78.00%) (14223/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.6084) |  Loss2: (0.0000) | Acc: (78.00%) (15220/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.6097) |  Loss2: (0.0000) | Acc: (78.00%) (16223/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.6112) |  Loss2: (0.0000) | Acc: (78.00%) (17196/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.6109) |  Loss2: (0.0000) | Acc: (78.00%) (18207/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.6129) |  Loss2: (0.0000) | Acc: (78.00%) (19200/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.6123) |  Loss2: (0.0000) | Acc: (78.00%) (20220/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.6126) |  Loss2: (0.0000) | Acc: (78.00%) (21203/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.6131) |  Loss2: (0.0000) | Acc: (78.00%) (22206/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.6135) |  Loss2: (0.0000) | Acc: (78.00%) (23196/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.6127) |  Loss2: (0.0000) | Acc: (78.00%) (24199/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.6123) |  Loss2: (0.0000) | Acc: (78.00%) (25201/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.6124) |  Loss2: (0.0000) | Acc: (78.00%) (26204/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.6106) |  Loss2: (0.0000) | Acc: (78.00%) (27226/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.6119) |  Loss2: (0.0000) | Acc: (78.00%) (28229/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.6111) |  Loss2: (0.0000) | Acc: (78.00%) (29238/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.6093) |  Loss2: (0.0000) | Acc: (78.00%) (30278/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.6091) |  Loss2: (0.0000) | Acc: (78.00%) (31298/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.6084) |  Loss2: (0.0000) | Acc: (78.00%) (32325/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.6100) |  Loss2: (0.0000) | Acc: (78.00%) (33308/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.6091) |  Loss2: (0.0000) | Acc: (78.00%) (34336/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.6111) |  Loss2: (0.0000) | Acc: (78.00%) (35320/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.6105) |  Loss2: (0.0000) | Acc: (78.00%) (36340/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.6091) |  Loss2: (0.0000) | Acc: (78.00%) (37369/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.6102) |  Loss2: (0.0000) | Acc: (78.00%) (38357/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.6107) |  Loss2: (0.0000) | Acc: (78.00%) (39324/50000)
# TEST : Loss: (0.7254) | Acc: (75.00%) (7513/10000)
percent tensor([0.5146, 0.5160, 0.5135, 0.5094, 0.5169, 0.5060, 0.5183, 0.5153, 0.5223,
        0.5174, 0.5195, 0.5177, 0.5166, 0.5184, 0.5103, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.4940, 0.4958, 0.4875, 0.4908, 0.4892, 0.4933, 0.4943, 0.4915, 0.4925,
        0.4930, 0.4960, 0.4884, 0.4942, 0.4964, 0.4935, 0.4949],
       device='cuda:0') torch.Size([16])
percent tensor([0.4664, 0.4478, 0.4271, 0.4661, 0.4360, 0.4958, 0.4399, 0.4320, 0.4738,
        0.4411, 0.4706, 0.4127, 0.4520, 0.4990, 0.4510, 0.4694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5030, 0.5108, 0.5019, 0.5017, 0.5022, 0.4957, 0.5054, 0.5022, 0.5116,
        0.5112, 0.5146, 0.5029, 0.5087, 0.5145, 0.5036, 0.5007],
       device='cuda:0') torch.Size([16])
percent tensor([0.5789, 0.5505, 0.6728, 0.6773, 0.6653, 0.6483, 0.5988, 0.6454, 0.5612,
        0.5310, 0.5401, 0.6256, 0.5342, 0.5538, 0.5929, 0.5858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5457, 0.5274, 0.5721, 0.5792, 0.5894, 0.5942, 0.5411, 0.5557, 0.5513,
        0.5349, 0.5320, 0.5302, 0.5194, 0.5605, 0.5287, 0.5542],
       device='cuda:0') torch.Size([16])
percent tensor([0.6597, 0.5545, 0.6739, 0.6813, 0.6670, 0.7671, 0.5939, 0.6110, 0.6223,
        0.6001, 0.5833, 0.6168, 0.5791, 0.6445, 0.5750, 0.6682],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9892, 0.9949, 0.9914, 0.9937, 0.9961, 0.9926, 0.9961, 0.9876,
        0.9957, 0.9920, 0.9930, 0.9913, 0.9946, 0.9935, 0.9978],
       device='cuda:0') torch.Size([16])
Epoch: 33 | Batch_idx: 0 |  Loss: (0.5535) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.5960) |  Loss2: (0.0000) | Acc: (77.00%) (1091/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.5921) |  Loss2: (0.0000) | Acc: (78.00%) (2116/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5811) |  Loss2: (0.0000) | Acc: (79.00%) (3139/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5734) |  Loss2: (0.0000) | Acc: (79.00%) (4171/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5687) |  Loss2: (0.0000) | Acc: (79.00%) (5190/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5775) |  Loss2: (0.0000) | Acc: (79.00%) (6184/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5815) |  Loss2: (0.0000) | Acc: (79.00%) (7184/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5818) |  Loss2: (0.0000) | Acc: (79.00%) (8205/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5797) |  Loss2: (0.0000) | Acc: (79.00%) (9234/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5760) |  Loss2: (0.0000) | Acc: (79.00%) (10276/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5776) |  Loss2: (0.0000) | Acc: (79.00%) (11290/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5771) |  Loss2: (0.0000) | Acc: (79.00%) (12321/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5761) |  Loss2: (0.0000) | Acc: (79.00%) (13345/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5761) |  Loss2: (0.0000) | Acc: (79.00%) (14381/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5753) |  Loss2: (0.0000) | Acc: (79.00%) (15421/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5751) |  Loss2: (0.0000) | Acc: (79.00%) (16441/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5775) |  Loss2: (0.0000) | Acc: (79.00%) (17430/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5780) |  Loss2: (0.0000) | Acc: (79.00%) (18453/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5805) |  Loss2: (0.0000) | Acc: (79.00%) (19453/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5782) |  Loss2: (0.0000) | Acc: (79.00%) (20500/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5761) |  Loss2: (0.0000) | Acc: (79.00%) (21544/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5761) |  Loss2: (0.0000) | Acc: (79.00%) (22577/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5776) |  Loss2: (0.0000) | Acc: (79.00%) (23592/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5780) |  Loss2: (0.0000) | Acc: (79.00%) (24613/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5782) |  Loss2: (0.0000) | Acc: (79.00%) (25627/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5787) |  Loss2: (0.0000) | Acc: (79.00%) (26644/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5794) |  Loss2: (0.0000) | Acc: (79.00%) (27655/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5808) |  Loss2: (0.0000) | Acc: (79.00%) (28681/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5822) |  Loss2: (0.0000) | Acc: (79.00%) (29682/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5827) |  Loss2: (0.0000) | Acc: (79.00%) (30690/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5843) |  Loss2: (0.0000) | Acc: (79.00%) (31678/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5838) |  Loss2: (0.0000) | Acc: (79.00%) (32709/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5850) |  Loss2: (0.0000) | Acc: (79.00%) (33722/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5844) |  Loss2: (0.0000) | Acc: (79.00%) (34739/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5837) |  Loss2: (0.0000) | Acc: (79.00%) (35775/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5826) |  Loss2: (0.0000) | Acc: (79.00%) (36827/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5825) |  Loss2: (0.0000) | Acc: (79.00%) (37858/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5833) |  Loss2: (0.0000) | Acc: (79.00%) (38866/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5831) |  Loss2: (0.0000) | Acc: (79.00%) (39861/50000)
# TEST : Loss: (0.6698) | Acc: (76.00%) (7660/10000)
percent tensor([0.5149, 0.5164, 0.5123, 0.5085, 0.5162, 0.5060, 0.5188, 0.5146, 0.5228,
        0.5174, 0.5203, 0.5169, 0.5169, 0.5191, 0.5103, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.4939, 0.4952, 0.4880, 0.4910, 0.4894, 0.4934, 0.4939, 0.4915, 0.4928,
        0.4930, 0.4956, 0.4888, 0.4941, 0.4962, 0.4932, 0.4947],
       device='cuda:0') torch.Size([16])
percent tensor([0.4689, 0.4439, 0.4253, 0.4673, 0.4357, 0.4961, 0.4382, 0.4313, 0.4698,
        0.4395, 0.4687, 0.4101, 0.4516, 0.4950, 0.4483, 0.4693],
       device='cuda:0') torch.Size([16])
percent tensor([0.5031, 0.5120, 0.5023, 0.5011, 0.5024, 0.4955, 0.5063, 0.5019, 0.5108,
        0.5125, 0.5157, 0.5037, 0.5087, 0.5149, 0.5034, 0.5017],
       device='cuda:0') torch.Size([16])
percent tensor([0.5746, 0.5439, 0.6555, 0.6648, 0.6537, 0.6402, 0.5940, 0.6425, 0.5604,
        0.5313, 0.5408, 0.6179, 0.5327, 0.5442, 0.5915, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.5535, 0.5295, 0.5670, 0.5749, 0.5869, 0.5947, 0.5384, 0.5477, 0.5588,
        0.5480, 0.5435, 0.5331, 0.5329, 0.5628, 0.5241, 0.5504],
       device='cuda:0') torch.Size([16])
percent tensor([0.6526, 0.5547, 0.6502, 0.6640, 0.6530, 0.7447, 0.5879, 0.5860, 0.6227,
        0.5982, 0.6004, 0.6235, 0.5940, 0.6336, 0.5714, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9923, 0.9938, 0.9902, 0.9934, 0.9962, 0.9963, 0.9966, 0.9890,
        0.9963, 0.9948, 0.9949, 0.9919, 0.9949, 0.9959, 0.9974],
       device='cuda:0') torch.Size([16])
Epoch: 34 | Batch_idx: 0 |  Loss: (0.5743) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.5375) |  Loss2: (0.0000) | Acc: (80.00%) (1140/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.5444) |  Loss2: (0.0000) | Acc: (81.00%) (2182/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.5504) |  Loss2: (0.0000) | Acc: (80.00%) (3200/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.5651) |  Loss2: (0.0000) | Acc: (79.00%) (4189/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.5635) |  Loss2: (0.0000) | Acc: (80.00%) (5225/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.5647) |  Loss2: (0.0000) | Acc: (80.00%) (6260/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.5632) |  Loss2: (0.0000) | Acc: (80.00%) (7289/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.5619) |  Loss2: (0.0000) | Acc: (80.00%) (8339/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.5610) |  Loss2: (0.0000) | Acc: (80.00%) (9380/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.5587) |  Loss2: (0.0000) | Acc: (80.00%) (10418/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.5591) |  Loss2: (0.0000) | Acc: (80.00%) (11447/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.5580) |  Loss2: (0.0000) | Acc: (80.00%) (12478/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.5593) |  Loss2: (0.0000) | Acc: (80.00%) (13496/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.5600) |  Loss2: (0.0000) | Acc: (80.00%) (14524/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.5589) |  Loss2: (0.0000) | Acc: (80.00%) (15569/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.5634) |  Loss2: (0.0000) | Acc: (80.00%) (16561/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.5602) |  Loss2: (0.0000) | Acc: (80.00%) (17620/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.5614) |  Loss2: (0.0000) | Acc: (80.00%) (18635/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.5592) |  Loss2: (0.0000) | Acc: (80.00%) (19682/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.5607) |  Loss2: (0.0000) | Acc: (80.00%) (20702/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.5617) |  Loss2: (0.0000) | Acc: (80.00%) (21727/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.5610) |  Loss2: (0.0000) | Acc: (80.00%) (22762/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.5610) |  Loss2: (0.0000) | Acc: (80.00%) (23800/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.5610) |  Loss2: (0.0000) | Acc: (80.00%) (24848/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.5603) |  Loss2: (0.0000) | Acc: (80.00%) (25891/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.5605) |  Loss2: (0.0000) | Acc: (80.00%) (26922/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.5619) |  Loss2: (0.0000) | Acc: (80.00%) (27930/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.5611) |  Loss2: (0.0000) | Acc: (80.00%) (28961/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.5604) |  Loss2: (0.0000) | Acc: (80.00%) (29999/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.5595) |  Loss2: (0.0000) | Acc: (80.00%) (31063/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.5589) |  Loss2: (0.0000) | Acc: (80.00%) (32105/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.5585) |  Loss2: (0.0000) | Acc: (80.00%) (33149/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.5582) |  Loss2: (0.0000) | Acc: (80.00%) (34186/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.5573) |  Loss2: (0.0000) | Acc: (80.00%) (35228/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.5574) |  Loss2: (0.0000) | Acc: (80.00%) (36264/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.5564) |  Loss2: (0.0000) | Acc: (80.00%) (37310/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.5573) |  Loss2: (0.0000) | Acc: (80.00%) (38341/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.5564) |  Loss2: (0.0000) | Acc: (80.00%) (39389/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.5563) |  Loss2: (0.0000) | Acc: (80.00%) (40372/50000)
# TEST : Loss: (0.6388) | Acc: (78.00%) (7808/10000)
percent tensor([0.5149, 0.5161, 0.5137, 0.5091, 0.5172, 0.5064, 0.5189, 0.5146, 0.5219,
        0.5177, 0.5192, 0.5183, 0.5166, 0.5189, 0.5106, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.4940, 0.4957, 0.4870, 0.4905, 0.4888, 0.4932, 0.4940, 0.4910, 0.4926,
        0.4927, 0.4961, 0.4877, 0.4943, 0.4964, 0.4932, 0.4946],
       device='cuda:0') torch.Size([16])
percent tensor([0.4650, 0.4452, 0.4308, 0.4701, 0.4435, 0.4962, 0.4422, 0.4337, 0.4679,
        0.4392, 0.4666, 0.4126, 0.4472, 0.4983, 0.4478, 0.4698],
       device='cuda:0') torch.Size([16])
percent tensor([0.5029, 0.5130, 0.5006, 0.5003, 0.5009, 0.4967, 0.5062, 0.5021, 0.5119,
        0.5123, 0.5157, 0.5024, 0.5088, 0.5173, 0.5040, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5738, 0.5478, 0.6644, 0.6641, 0.6570, 0.6324, 0.5957, 0.6370, 0.5514,
        0.5341, 0.5415, 0.6151, 0.5333, 0.5410, 0.5923, 0.5767],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.5297, 0.5694, 0.5747, 0.5851, 0.5913, 0.5442, 0.5492, 0.5528,
        0.5461, 0.5385, 0.5274, 0.5294, 0.5630, 0.5297, 0.5521],
       device='cuda:0') torch.Size([16])
percent tensor([0.6670, 0.5694, 0.6702, 0.6761, 0.6674, 0.7497, 0.6182, 0.6111, 0.6174,
        0.6073, 0.5808, 0.6250, 0.5997, 0.6207, 0.5811, 0.6605],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9891, 0.9941, 0.9939, 0.9931, 0.9974, 0.9968, 0.9974, 0.9893,
        0.9955, 0.9916, 0.9955, 0.9887, 0.9923, 0.9955, 0.9981],
       device='cuda:0') torch.Size([16])
Epoch: 35 | Batch_idx: 0 |  Loss: (0.6461) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.5040) |  Loss2: (0.0000) | Acc: (82.00%) (1155/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.5169) |  Loss2: (0.0000) | Acc: (82.00%) (2206/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.5205) |  Loss2: (0.0000) | Acc: (82.00%) (3256/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.5318) |  Loss2: (0.0000) | Acc: (81.00%) (4276/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.5320) |  Loss2: (0.0000) | Acc: (81.00%) (5312/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.5303) |  Loss2: (0.0000) | Acc: (81.00%) (6363/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.5306) |  Loss2: (0.0000) | Acc: (81.00%) (7396/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.5305) |  Loss2: (0.0000) | Acc: (81.00%) (8434/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.5340) |  Loss2: (0.0000) | Acc: (81.00%) (9483/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.5350) |  Loss2: (0.0000) | Acc: (81.00%) (10522/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.5397) |  Loss2: (0.0000) | Acc: (81.00%) (11555/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.5399) |  Loss2: (0.0000) | Acc: (81.00%) (12582/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.5426) |  Loss2: (0.0000) | Acc: (81.00%) (13622/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.5396) |  Loss2: (0.0000) | Acc: (81.00%) (14678/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.5369) |  Loss2: (0.0000) | Acc: (81.00%) (15727/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.5394) |  Loss2: (0.0000) | Acc: (81.00%) (16755/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.5375) |  Loss2: (0.0000) | Acc: (81.00%) (17811/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.5363) |  Loss2: (0.0000) | Acc: (81.00%) (18860/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.5357) |  Loss2: (0.0000) | Acc: (81.00%) (19902/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.5361) |  Loss2: (0.0000) | Acc: (81.00%) (20937/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.5351) |  Loss2: (0.0000) | Acc: (81.00%) (21990/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.5341) |  Loss2: (0.0000) | Acc: (81.00%) (23046/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.5338) |  Loss2: (0.0000) | Acc: (81.00%) (24084/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.5347) |  Loss2: (0.0000) | Acc: (81.00%) (25105/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.5341) |  Loss2: (0.0000) | Acc: (81.00%) (26167/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.5350) |  Loss2: (0.0000) | Acc: (81.00%) (27200/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.5344) |  Loss2: (0.0000) | Acc: (81.00%) (28250/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.5356) |  Loss2: (0.0000) | Acc: (81.00%) (29279/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.5352) |  Loss2: (0.0000) | Acc: (81.00%) (30336/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.5348) |  Loss2: (0.0000) | Acc: (81.00%) (31384/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.5359) |  Loss2: (0.0000) | Acc: (81.00%) (32404/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.5353) |  Loss2: (0.0000) | Acc: (81.00%) (33451/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.5354) |  Loss2: (0.0000) | Acc: (81.00%) (34493/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.5355) |  Loss2: (0.0000) | Acc: (81.00%) (35521/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.5353) |  Loss2: (0.0000) | Acc: (81.00%) (36565/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.5346) |  Loss2: (0.0000) | Acc: (81.00%) (37618/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.5332) |  Loss2: (0.0000) | Acc: (81.00%) (38687/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.5329) |  Loss2: (0.0000) | Acc: (81.00%) (39738/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.5329) |  Loss2: (0.0000) | Acc: (81.00%) (40751/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_035.pth.tar'
# TEST : Loss: (0.6045) | Acc: (79.00%) (7901/10000)
percent tensor([0.5145, 0.5178, 0.5114, 0.5088, 0.5153, 0.5062, 0.5192, 0.5148, 0.5224,
        0.5179, 0.5204, 0.5160, 0.5168, 0.5215, 0.5111, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.4945, 0.4955, 0.4891, 0.4916, 0.4905, 0.4935, 0.4942, 0.4919, 0.4928,
        0.4930, 0.4955, 0.4894, 0.4944, 0.4953, 0.4932, 0.4949],
       device='cuda:0') torch.Size([16])
percent tensor([0.4703, 0.4509, 0.4222, 0.4633, 0.4362, 0.4992, 0.4435, 0.4336, 0.4758,
        0.4412, 0.4725, 0.4041, 0.4516, 0.5005, 0.4524, 0.4736],
       device='cuda:0') torch.Size([16])
percent tensor([0.5029, 0.5120, 0.4990, 0.4988, 0.5000, 0.4963, 0.5056, 0.5014, 0.5117,
        0.5116, 0.5157, 0.5015, 0.5089, 0.5173, 0.5044, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.5796, 0.5492, 0.6550, 0.6693, 0.6585, 0.6474, 0.5997, 0.6404, 0.5671,
        0.5317, 0.5406, 0.6118, 0.5323, 0.5553, 0.5933, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.5602, 0.5510, 0.5704, 0.5777, 0.5908, 0.5974, 0.5600, 0.5617, 0.5710,
        0.5561, 0.5522, 0.5290, 0.5466, 0.5727, 0.5421, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.6798, 0.5955, 0.6642, 0.6810, 0.6724, 0.7684, 0.6214, 0.6073, 0.6553,
        0.6262, 0.6093, 0.6187, 0.6305, 0.6505, 0.5863, 0.6921],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9913, 0.9951, 0.9929, 0.9930, 0.9960, 0.9967, 0.9965, 0.9902,
        0.9973, 0.9939, 0.9959, 0.9922, 0.9951, 0.9924, 0.9983],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 36 | Batch_idx: 0 |  Loss: (0.4472) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.5373) |  Loss2: (0.0000) | Acc: (80.00%) (1140/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.5840) |  Loss2: (0.0000) | Acc: (79.00%) (2129/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.6041) |  Loss2: (0.0000) | Acc: (78.00%) (3107/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.6166) |  Loss2: (0.0000) | Acc: (77.00%) (4089/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.6221) |  Loss2: (0.0000) | Acc: (77.00%) (5091/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (6099/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.6224) |  Loss2: (0.0000) | Acc: (78.00%) (7100/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.6215) |  Loss2: (0.0000) | Acc: (78.00%) (8106/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.6211) |  Loss2: (0.0000) | Acc: (78.00%) (9124/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (10093/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.6220) |  Loss2: (0.0000) | Acc: (78.00%) (11102/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.6216) |  Loss2: (0.0000) | Acc: (78.00%) (12089/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.6169) |  Loss2: (0.0000) | Acc: (78.00%) (13121/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.6173) |  Loss2: (0.0000) | Acc: (78.00%) (14114/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.6148) |  Loss2: (0.0000) | Acc: (78.00%) (15129/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.6153) |  Loss2: (0.0000) | Acc: (78.00%) (16135/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.6146) |  Loss2: (0.0000) | Acc: (78.00%) (17155/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.6149) |  Loss2: (0.0000) | Acc: (78.00%) (18167/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.6141) |  Loss2: (0.0000) | Acc: (78.00%) (19181/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.6132) |  Loss2: (0.0000) | Acc: (78.00%) (20200/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.6109) |  Loss2: (0.0000) | Acc: (78.00%) (21242/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.6095) |  Loss2: (0.0000) | Acc: (78.00%) (22269/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.6107) |  Loss2: (0.0000) | Acc: (78.00%) (23272/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.6094) |  Loss2: (0.0000) | Acc: (78.00%) (24288/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.6111) |  Loss2: (0.0000) | Acc: (78.00%) (25275/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.6117) |  Loss2: (0.0000) | Acc: (78.00%) (26283/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.6110) |  Loss2: (0.0000) | Acc: (78.00%) (27300/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.6103) |  Loss2: (0.0000) | Acc: (78.00%) (28313/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.6090) |  Loss2: (0.0000) | Acc: (78.00%) (29346/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.6084) |  Loss2: (0.0000) | Acc: (78.00%) (30377/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.6079) |  Loss2: (0.0000) | Acc: (78.00%) (31389/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.6068) |  Loss2: (0.0000) | Acc: (78.00%) (32411/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.6046) |  Loss2: (0.0000) | Acc: (78.00%) (33456/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.6030) |  Loss2: (0.0000) | Acc: (79.00%) (34493/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.6015) |  Loss2: (0.0000) | Acc: (79.00%) (35538/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.6011) |  Loss2: (0.0000) | Acc: (79.00%) (36557/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.6000) |  Loss2: (0.0000) | Acc: (79.00%) (37591/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5987) |  Loss2: (0.0000) | Acc: (79.00%) (38632/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5987) |  Loss2: (0.0000) | Acc: (79.00%) (39597/50000)
# TEST : Loss: (0.6119) | Acc: (78.00%) (7890/10000)
percent tensor([0.5218, 0.5307, 0.5156, 0.5149, 0.5220, 0.5147, 0.5302, 0.5228, 0.5316,
        0.5269, 0.5306, 0.5222, 0.5245, 0.5351, 0.5213, 0.5214],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.4988, 0.4918, 0.4955, 0.4937, 0.4967, 0.4974, 0.4952, 0.4963,
        0.4965, 0.4994, 0.4922, 0.4978, 0.4980, 0.4970, 0.4984],
       device='cuda:0') torch.Size([16])
percent tensor([0.4775, 0.4493, 0.4509, 0.4908, 0.4666, 0.5107, 0.4538, 0.4639, 0.4844,
        0.4437, 0.4697, 0.4212, 0.4480, 0.5045, 0.4604, 0.4801],
       device='cuda:0') torch.Size([16])
percent tensor([0.5090, 0.5197, 0.5037, 0.5027, 0.5042, 0.4996, 0.5127, 0.5055, 0.5166,
        0.5198, 0.5227, 0.5089, 0.5157, 0.5233, 0.5113, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.5502, 0.5090, 0.6354, 0.6507, 0.6467, 0.6297, 0.5826, 0.6170, 0.5397,
        0.5077, 0.5146, 0.5856, 0.4956, 0.5266, 0.5676, 0.5518],
       device='cuda:0') torch.Size([16])
percent tensor([0.5253, 0.5246, 0.5315, 0.5454, 0.5639, 0.5801, 0.5326, 0.5270, 0.5366,
        0.5225, 0.5213, 0.4877, 0.5125, 0.5442, 0.5147, 0.5415],
       device='cuda:0') torch.Size([16])
percent tensor([0.6282, 0.5673, 0.6190, 0.6613, 0.6341, 0.7330, 0.5905, 0.5810, 0.6133,
        0.5808, 0.5874, 0.5715, 0.5727, 0.5994, 0.5586, 0.6414],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9921, 0.9961, 0.9962, 0.9943, 0.9965, 0.9968, 0.9973, 0.9925,
        0.9968, 0.9957, 0.9969, 0.9925, 0.9939, 0.9938, 0.9976],
       device='cuda:0') torch.Size([16])
Epoch: 37 | Batch_idx: 0 |  Loss: (0.5657) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.5561) |  Loss2: (0.0000) | Acc: (80.00%) (1127/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.5633) |  Loss2: (0.0000) | Acc: (80.00%) (2155/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.5704) |  Loss2: (0.0000) | Acc: (79.00%) (3167/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.5707) |  Loss2: (0.0000) | Acc: (79.00%) (4189/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.5663) |  Loss2: (0.0000) | Acc: (80.00%) (5225/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.5598) |  Loss2: (0.0000) | Acc: (80.00%) (6276/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.5581) |  Loss2: (0.0000) | Acc: (80.00%) (7310/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.5529) |  Loss2: (0.0000) | Acc: (80.00%) (8362/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.5521) |  Loss2: (0.0000) | Acc: (80.00%) (9408/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.5516) |  Loss2: (0.0000) | Acc: (80.00%) (10462/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.5477) |  Loss2: (0.0000) | Acc: (81.00%) (11530/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.5486) |  Loss2: (0.0000) | Acc: (81.00%) (12576/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.5478) |  Loss2: (0.0000) | Acc: (81.00%) (13614/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.5468) |  Loss2: (0.0000) | Acc: (81.00%) (14662/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.5469) |  Loss2: (0.0000) | Acc: (81.00%) (15706/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.5458) |  Loss2: (0.0000) | Acc: (81.00%) (16761/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.5456) |  Loss2: (0.0000) | Acc: (81.00%) (17807/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.5461) |  Loss2: (0.0000) | Acc: (81.00%) (18843/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.5446) |  Loss2: (0.0000) | Acc: (81.00%) (19895/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.5460) |  Loss2: (0.0000) | Acc: (81.00%) (20913/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.5472) |  Loss2: (0.0000) | Acc: (81.00%) (21946/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.5474) |  Loss2: (0.0000) | Acc: (81.00%) (22989/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.5490) |  Loss2: (0.0000) | Acc: (81.00%) (24012/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.5485) |  Loss2: (0.0000) | Acc: (81.00%) (25079/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.5492) |  Loss2: (0.0000) | Acc: (81.00%) (26110/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.5495) |  Loss2: (0.0000) | Acc: (81.00%) (27144/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.5481) |  Loss2: (0.0000) | Acc: (81.00%) (28188/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.5468) |  Loss2: (0.0000) | Acc: (81.00%) (29230/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.5462) |  Loss2: (0.0000) | Acc: (81.00%) (30273/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.5469) |  Loss2: (0.0000) | Acc: (81.00%) (31307/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.5473) |  Loss2: (0.0000) | Acc: (81.00%) (32345/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.5472) |  Loss2: (0.0000) | Acc: (81.00%) (33395/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.5470) |  Loss2: (0.0000) | Acc: (81.00%) (34430/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.5464) |  Loss2: (0.0000) | Acc: (81.00%) (35479/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.5455) |  Loss2: (0.0000) | Acc: (81.00%) (36527/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.5463) |  Loss2: (0.0000) | Acc: (81.00%) (37565/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.5471) |  Loss2: (0.0000) | Acc: (81.00%) (38591/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.5475) |  Loss2: (0.0000) | Acc: (81.00%) (39631/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.5485) |  Loss2: (0.0000) | Acc: (81.00%) (40598/50000)
# TEST : Loss: (0.5852) | Acc: (79.00%) (7995/10000)
percent tensor([0.5194, 0.5290, 0.5128, 0.5120, 0.5193, 0.5122, 0.5279, 0.5204, 0.5290,
        0.5246, 0.5283, 0.5195, 0.5224, 0.5330, 0.5191, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.4970, 0.4888, 0.4935, 0.4911, 0.4953, 0.4952, 0.4928, 0.4939,
        0.4943, 0.4977, 0.4892, 0.4957, 0.4963, 0.4951, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.4744, 0.4441, 0.4515, 0.4934, 0.4665, 0.5104, 0.4506, 0.4660, 0.4816,
        0.4397, 0.4649, 0.4183, 0.4409, 0.5059, 0.4573, 0.4779],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5244, 0.5064, 0.5058, 0.5067, 0.5025, 0.5174, 0.5089, 0.5200,
        0.5247, 0.5273, 0.5137, 0.5208, 0.5266, 0.5159, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5516, 0.5098, 0.6366, 0.6538, 0.6518, 0.6347, 0.5888, 0.6202, 0.5419,
        0.5093, 0.5170, 0.5847, 0.4915, 0.5311, 0.5706, 0.5535],
       device='cuda:0') torch.Size([16])
percent tensor([0.5350, 0.5333, 0.5419, 0.5532, 0.5746, 0.5895, 0.5417, 0.5385, 0.5440,
        0.5302, 0.5278, 0.4962, 0.5235, 0.5509, 0.5224, 0.5531],
       device='cuda:0') torch.Size([16])
percent tensor([0.6275, 0.5675, 0.6252, 0.6602, 0.6408, 0.7306, 0.5898, 0.5878, 0.6145,
        0.5855, 0.5881, 0.5764, 0.5763, 0.6001, 0.5571, 0.6393],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9933, 0.9969, 0.9966, 0.9958, 0.9971, 0.9976, 0.9980, 0.9938,
        0.9977, 0.9962, 0.9975, 0.9936, 0.9954, 0.9951, 0.9981],
       device='cuda:0') torch.Size([16])
Epoch: 38 | Batch_idx: 0 |  Loss: (0.4905) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.5149) |  Loss2: (0.0000) | Acc: (81.00%) (1152/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.5310) |  Loss2: (0.0000) | Acc: (81.00%) (2197/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.5382) |  Loss2: (0.0000) | Acc: (81.00%) (3222/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.5305) |  Loss2: (0.0000) | Acc: (81.00%) (4275/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.5273) |  Loss2: (0.0000) | Acc: (81.00%) (5323/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.5288) |  Loss2: (0.0000) | Acc: (81.00%) (6353/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.5314) |  Loss2: (0.0000) | Acc: (81.00%) (7388/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.5386) |  Loss2: (0.0000) | Acc: (81.00%) (8402/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.5393) |  Loss2: (0.0000) | Acc: (81.00%) (9450/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.5407) |  Loss2: (0.0000) | Acc: (81.00%) (10495/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.5425) |  Loss2: (0.0000) | Acc: (81.00%) (11529/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.5426) |  Loss2: (0.0000) | Acc: (81.00%) (12571/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.5417) |  Loss2: (0.0000) | Acc: (81.00%) (13622/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.5425) |  Loss2: (0.0000) | Acc: (81.00%) (14659/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.5398) |  Loss2: (0.0000) | Acc: (81.00%) (15717/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.5415) |  Loss2: (0.0000) | Acc: (81.00%) (16763/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.5401) |  Loss2: (0.0000) | Acc: (81.00%) (17811/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.5406) |  Loss2: (0.0000) | Acc: (81.00%) (18849/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.5400) |  Loss2: (0.0000) | Acc: (81.00%) (19898/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.5403) |  Loss2: (0.0000) | Acc: (81.00%) (20946/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.5410) |  Loss2: (0.0000) | Acc: (81.00%) (21967/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.5415) |  Loss2: (0.0000) | Acc: (81.00%) (23006/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.5409) |  Loss2: (0.0000) | Acc: (81.00%) (24071/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.5399) |  Loss2: (0.0000) | Acc: (81.00%) (25106/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.5401) |  Loss2: (0.0000) | Acc: (81.00%) (26138/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.5385) |  Loss2: (0.0000) | Acc: (81.00%) (27205/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.5386) |  Loss2: (0.0000) | Acc: (81.00%) (28249/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.5366) |  Loss2: (0.0000) | Acc: (81.00%) (29317/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.5376) |  Loss2: (0.0000) | Acc: (81.00%) (30349/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.5375) |  Loss2: (0.0000) | Acc: (81.00%) (31388/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.5370) |  Loss2: (0.0000) | Acc: (81.00%) (32450/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.5372) |  Loss2: (0.0000) | Acc: (81.00%) (33482/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.5375) |  Loss2: (0.0000) | Acc: (81.00%) (34516/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.5383) |  Loss2: (0.0000) | Acc: (81.00%) (35541/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.5388) |  Loss2: (0.0000) | Acc: (81.00%) (36570/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.5386) |  Loss2: (0.0000) | Acc: (81.00%) (37614/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.5383) |  Loss2: (0.0000) | Acc: (81.00%) (38660/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.5381) |  Loss2: (0.0000) | Acc: (81.00%) (39699/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.5378) |  Loss2: (0.0000) | Acc: (81.00%) (40714/50000)
# TEST : Loss: (0.5802) | Acc: (80.00%) (8008/10000)
percent tensor([0.5180, 0.5273, 0.5112, 0.5105, 0.5174, 0.5105, 0.5259, 0.5187, 0.5270,
        0.5228, 0.5265, 0.5177, 0.5209, 0.5310, 0.5176, 0.5176],
       device='cuda:0') torch.Size([16])
percent tensor([0.4960, 0.4967, 0.4877, 0.4932, 0.4903, 0.4952, 0.4947, 0.4921, 0.4932,
        0.4937, 0.4974, 0.4880, 0.4952, 0.4962, 0.4947, 0.4965],
       device='cuda:0') torch.Size([16])
percent tensor([0.4733, 0.4426, 0.4516, 0.4941, 0.4666, 0.5102, 0.4495, 0.4664, 0.4803,
        0.4383, 0.4630, 0.4168, 0.4385, 0.5066, 0.4563, 0.4774],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.5315, 0.5113, 0.5103, 0.5109, 0.5071, 0.5247, 0.5143, 0.5261,
        0.5322, 0.5344, 0.5208, 0.5285, 0.5332, 0.5232, 0.5190],
       device='cuda:0') torch.Size([16])
percent tensor([0.5484, 0.5073, 0.6345, 0.6527, 0.6502, 0.6288, 0.5891, 0.6191, 0.5439,
        0.5097, 0.5201, 0.5836, 0.4893, 0.5330, 0.5681, 0.5476],
       device='cuda:0') torch.Size([16])
percent tensor([0.5380, 0.5350, 0.5446, 0.5557, 0.5771, 0.5930, 0.5438, 0.5407, 0.5459,
        0.5304, 0.5286, 0.4975, 0.5274, 0.5524, 0.5232, 0.5564],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.5651, 0.6249, 0.6594, 0.6417, 0.7311, 0.5868, 0.5847, 0.6141,
        0.5871, 0.5879, 0.5757, 0.5772, 0.5981, 0.5523, 0.6367],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9943, 0.9969, 0.9964, 0.9961, 0.9976, 0.9979, 0.9980, 0.9946,
        0.9981, 0.9969, 0.9975, 0.9947, 0.9962, 0.9960, 0.9983],
       device='cuda:0') torch.Size([16])
Epoch: 39 | Batch_idx: 0 |  Loss: (0.5593) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.5458) |  Loss2: (0.0000) | Acc: (81.00%) (1150/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.5541) |  Loss2: (0.0000) | Acc: (81.00%) (2191/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.5494) |  Loss2: (0.0000) | Acc: (81.00%) (3250/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.5384) |  Loss2: (0.0000) | Acc: (82.00%) (4308/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.5332) |  Loss2: (0.0000) | Acc: (82.00%) (5375/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.5291) |  Loss2: (0.0000) | Acc: (82.00%) (6439/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.5317) |  Loss2: (0.0000) | Acc: (82.00%) (7466/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.5318) |  Loss2: (0.0000) | Acc: (82.00%) (8511/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.5339) |  Loss2: (0.0000) | Acc: (82.00%) (9554/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.5317) |  Loss2: (0.0000) | Acc: (82.00%) (10610/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.5281) |  Loss2: (0.0000) | Acc: (82.00%) (11656/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.5285) |  Loss2: (0.0000) | Acc: (81.00%) (12689/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.5282) |  Loss2: (0.0000) | Acc: (81.00%) (13743/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.5284) |  Loss2: (0.0000) | Acc: (81.00%) (14795/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.5302) |  Loss2: (0.0000) | Acc: (81.00%) (15829/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.5275) |  Loss2: (0.0000) | Acc: (82.00%) (16904/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.5253) |  Loss2: (0.0000) | Acc: (82.00%) (17973/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.5244) |  Loss2: (0.0000) | Acc: (82.00%) (19029/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.5243) |  Loss2: (0.0000) | Acc: (82.00%) (20070/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.5253) |  Loss2: (0.0000) | Acc: (82.00%) (21116/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.5252) |  Loss2: (0.0000) | Acc: (82.00%) (22172/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.5247) |  Loss2: (0.0000) | Acc: (82.00%) (23230/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.5247) |  Loss2: (0.0000) | Acc: (82.00%) (24277/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.5263) |  Loss2: (0.0000) | Acc: (82.00%) (25322/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.5256) |  Loss2: (0.0000) | Acc: (82.00%) (26366/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.5256) |  Loss2: (0.0000) | Acc: (82.00%) (27414/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.5269) |  Loss2: (0.0000) | Acc: (82.00%) (28449/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.5282) |  Loss2: (0.0000) | Acc: (81.00%) (29473/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.5275) |  Loss2: (0.0000) | Acc: (81.00%) (30530/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.5272) |  Loss2: (0.0000) | Acc: (81.00%) (31570/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.5268) |  Loss2: (0.0000) | Acc: (81.00%) (32612/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.5274) |  Loss2: (0.0000) | Acc: (81.00%) (33648/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.5277) |  Loss2: (0.0000) | Acc: (81.00%) (34684/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.5277) |  Loss2: (0.0000) | Acc: (81.00%) (35736/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.5285) |  Loss2: (0.0000) | Acc: (81.00%) (36778/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.5285) |  Loss2: (0.0000) | Acc: (81.00%) (37821/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.5279) |  Loss2: (0.0000) | Acc: (81.00%) (38890/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.5277) |  Loss2: (0.0000) | Acc: (81.00%) (39941/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.5287) |  Loss2: (0.0000) | Acc: (81.00%) (40938/50000)
# TEST : Loss: (0.5659) | Acc: (80.00%) (8046/10000)
percent tensor([0.5169, 0.5260, 0.5101, 0.5095, 0.5162, 0.5094, 0.5246, 0.5177, 0.5256,
        0.5217, 0.5251, 0.5165, 0.5198, 0.5296, 0.5166, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.4976, 0.4876, 0.4937, 0.4904, 0.4961, 0.4953, 0.4923, 0.4937,
        0.4943, 0.4983, 0.4880, 0.4958, 0.4971, 0.4956, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.4733, 0.4423, 0.4519, 0.4952, 0.4662, 0.5109, 0.4495, 0.4669, 0.4799,
        0.4379, 0.4628, 0.4163, 0.4378, 0.5083, 0.4566, 0.4778],
       device='cuda:0') torch.Size([16])
percent tensor([0.5221, 0.5338, 0.5130, 0.5120, 0.5124, 0.5088, 0.5272, 0.5165, 0.5278,
        0.5346, 0.5368, 0.5235, 0.5314, 0.5350, 0.5261, 0.5214],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5200, 0.6473, 0.6654, 0.6619, 0.6393, 0.6038, 0.6324, 0.5584,
        0.5195, 0.5336, 0.5971, 0.4945, 0.5475, 0.5808, 0.5591],
       device='cuda:0') torch.Size([16])
percent tensor([0.5403, 0.5375, 0.5473, 0.5580, 0.5797, 0.5971, 0.5457, 0.5420, 0.5472,
        0.5300, 0.5290, 0.4986, 0.5307, 0.5543, 0.5235, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.6262, 0.5628, 0.6302, 0.6633, 0.6454, 0.7352, 0.5843, 0.5834, 0.6150,
        0.5857, 0.5851, 0.5788, 0.5800, 0.5972, 0.5483, 0.6362],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9952, 0.9975, 0.9969, 0.9970, 0.9980, 0.9982, 0.9985, 0.9954,
        0.9984, 0.9972, 0.9980, 0.9954, 0.9968, 0.9967, 0.9987],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 40 | Batch_idx: 0 |  Loss: (0.5150) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.5273) |  Loss2: (0.0000) | Acc: (81.00%) (1154/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.5373) |  Loss2: (0.0000) | Acc: (80.00%) (2177/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.5182) |  Loss2: (0.0000) | Acc: (81.00%) (3243/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.5192) |  Loss2: (0.0000) | Acc: (81.00%) (4294/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.5277) |  Loss2: (0.0000) | Acc: (81.00%) (5309/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.5254) |  Loss2: (0.0000) | Acc: (81.00%) (6353/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.5336) |  Loss2: (0.0000) | Acc: (81.00%) (7379/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.5334) |  Loss2: (0.0000) | Acc: (81.00%) (8412/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.5280) |  Loss2: (0.0000) | Acc: (81.00%) (9466/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.5249) |  Loss2: (0.0000) | Acc: (81.00%) (10524/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.5310) |  Loss2: (0.0000) | Acc: (81.00%) (11546/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.5287) |  Loss2: (0.0000) | Acc: (81.00%) (12604/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.5288) |  Loss2: (0.0000) | Acc: (81.00%) (13665/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.5247) |  Loss2: (0.0000) | Acc: (81.00%) (14751/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.5255) |  Loss2: (0.0000) | Acc: (81.00%) (15792/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.5253) |  Loss2: (0.0000) | Acc: (81.00%) (16842/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.5244) |  Loss2: (0.0000) | Acc: (81.00%) (17900/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.5242) |  Loss2: (0.0000) | Acc: (81.00%) (18948/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.5252) |  Loss2: (0.0000) | Acc: (81.00%) (19973/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.5238) |  Loss2: (0.0000) | Acc: (81.00%) (21038/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.5241) |  Loss2: (0.0000) | Acc: (81.00%) (22075/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.5258) |  Loss2: (0.0000) | Acc: (81.00%) (23107/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.5276) |  Loss2: (0.0000) | Acc: (81.00%) (24137/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.5288) |  Loss2: (0.0000) | Acc: (81.00%) (25163/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.5269) |  Loss2: (0.0000) | Acc: (81.00%) (26230/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.5278) |  Loss2: (0.0000) | Acc: (81.00%) (27258/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.5271) |  Loss2: (0.0000) | Acc: (81.00%) (28313/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.5260) |  Loss2: (0.0000) | Acc: (81.00%) (29381/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.5256) |  Loss2: (0.0000) | Acc: (81.00%) (30439/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.5256) |  Loss2: (0.0000) | Acc: (81.00%) (31490/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.5250) |  Loss2: (0.0000) | Acc: (81.00%) (32546/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.5253) |  Loss2: (0.0000) | Acc: (81.00%) (33597/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.5250) |  Loss2: (0.0000) | Acc: (81.00%) (34649/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.5246) |  Loss2: (0.0000) | Acc: (81.00%) (35710/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.5249) |  Loss2: (0.0000) | Acc: (81.00%) (36740/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.5247) |  Loss2: (0.0000) | Acc: (81.00%) (37798/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.5251) |  Loss2: (0.0000) | Acc: (81.00%) (38857/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.5250) |  Loss2: (0.0000) | Acc: (81.00%) (39908/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.5248) |  Loss2: (0.0000) | Acc: (81.00%) (40915/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_040.pth.tar'
# TEST : Loss: (0.5679) | Acc: (80.00%) (8043/10000)
percent tensor([0.5183, 0.5250, 0.5128, 0.5118, 0.5180, 0.5091, 0.5245, 0.5191, 0.5263,
        0.5224, 0.5253, 0.5190, 0.5210, 0.5267, 0.5171, 0.5168],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.4972, 0.4880, 0.4936, 0.4895, 0.4960, 0.4954, 0.4921, 0.4944,
        0.4942, 0.4988, 0.4877, 0.4962, 0.4982, 0.4953, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.4745, 0.4448, 0.4655, 0.5002, 0.4761, 0.5087, 0.4567, 0.4691, 0.4829,
        0.4420, 0.4631, 0.4353, 0.4414, 0.5116, 0.4585, 0.4776],
       device='cuda:0') torch.Size([16])
percent tensor([0.5198, 0.5341, 0.5095, 0.5114, 0.5104, 0.5092, 0.5264, 0.5142, 0.5274,
        0.5321, 0.5362, 0.5200, 0.5299, 0.5341, 0.5252, 0.5205],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.5190, 0.6612, 0.6628, 0.6750, 0.6384, 0.5953, 0.6401, 0.5732,
        0.5212, 0.5419, 0.6046, 0.5053, 0.5536, 0.5789, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.5520, 0.5342, 0.5671, 0.5697, 0.5915, 0.5967, 0.5451, 0.5489, 0.5578,
        0.5406, 0.5351, 0.5169, 0.5350, 0.5594, 0.5209, 0.5608],
       device='cuda:0') torch.Size([16])
percent tensor([0.6294, 0.5716, 0.6550, 0.6766, 0.6718, 0.7227, 0.5961, 0.5797, 0.6336,
        0.6178, 0.5917, 0.6126, 0.5921, 0.6259, 0.5545, 0.6441],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9941, 0.9969, 0.9964, 0.9959, 0.9965, 0.9982, 0.9981, 0.9950,
        0.9981, 0.9969, 0.9978, 0.9949, 0.9968, 0.9963, 0.9991],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(170.7108, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(794.7382, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(791.5478, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.3037, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(506.7347, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2182.9885, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4299.8989, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1429.7589, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6085.5259, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12093.3271, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4036.5137, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17050.5488, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 41 | Batch_idx: 0 |  Loss: (0.4722) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.4515) |  Loss2: (0.0000) | Acc: (84.00%) (1190/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.4630) |  Loss2: (0.0000) | Acc: (83.00%) (2257/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.4748) |  Loss2: (0.0000) | Acc: (83.00%) (3313/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.4712) |  Loss2: (0.0000) | Acc: (83.00%) (4392/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.4761) |  Loss2: (0.0000) | Acc: (83.00%) (5448/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (6499/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.4824) |  Loss2: (0.0000) | Acc: (83.00%) (7548/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.4850) |  Loss2: (0.0000) | Acc: (82.00%) (8605/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.4857) |  Loss2: (0.0000) | Acc: (82.00%) (9663/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (83.00%) (10746/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.4841) |  Loss2: (0.0000) | Acc: (83.00%) (11813/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.4853) |  Loss2: (0.0000) | Acc: (83.00%) (12880/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.4861) |  Loss2: (0.0000) | Acc: (83.00%) (13941/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.4873) |  Loss2: (0.0000) | Acc: (83.00%) (15011/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.4891) |  Loss2: (0.0000) | Acc: (83.00%) (16056/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.4878) |  Loss2: (0.0000) | Acc: (83.00%) (17126/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.4899) |  Loss2: (0.0000) | Acc: (83.00%) (18177/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.4918) |  Loss2: (0.0000) | Acc: (82.00%) (19207/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.4915) |  Loss2: (0.0000) | Acc: (82.00%) (20270/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.4917) |  Loss2: (0.0000) | Acc: (82.00%) (21322/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.4920) |  Loss2: (0.0000) | Acc: (82.00%) (22364/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.4943) |  Loss2: (0.0000) | Acc: (82.00%) (23414/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.4955) |  Loss2: (0.0000) | Acc: (82.00%) (24450/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (82.00%) (25519/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (26564/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.4955) |  Loss2: (0.0000) | Acc: (82.00%) (27630/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.4965) |  Loss2: (0.0000) | Acc: (82.00%) (28681/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (29737/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.4959) |  Loss2: (0.0000) | Acc: (82.00%) (30798/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.4962) |  Loss2: (0.0000) | Acc: (82.00%) (31858/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.4968) |  Loss2: (0.0000) | Acc: (82.00%) (32915/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.4970) |  Loss2: (0.0000) | Acc: (82.00%) (33970/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.4981) |  Loss2: (0.0000) | Acc: (82.00%) (35011/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.4977) |  Loss2: (0.0000) | Acc: (82.00%) (36063/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (82.00%) (37136/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.4966) |  Loss2: (0.0000) | Acc: (82.00%) (38204/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.4965) |  Loss2: (0.0000) | Acc: (82.00%) (39253/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.4966) |  Loss2: (0.0000) | Acc: (82.00%) (40315/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.4974) |  Loss2: (0.0000) | Acc: (82.00%) (41334/50000)
# TEST : Loss: (0.5673) | Acc: (80.00%) (8050/10000)
percent tensor([0.5185, 0.5249, 0.5124, 0.5117, 0.5182, 0.5100, 0.5247, 0.5188, 0.5266,
        0.5222, 0.5252, 0.5191, 0.5215, 0.5270, 0.5169, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.4970, 0.4974, 0.4873, 0.4930, 0.4901, 0.4961, 0.4957, 0.4921, 0.4942,
        0.4943, 0.4984, 0.4877, 0.4960, 0.4987, 0.4955, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.4724, 0.4482, 0.4528, 0.4951, 0.4675, 0.5075, 0.4545, 0.4649, 0.4774,
        0.4391, 0.4638, 0.4233, 0.4383, 0.5115, 0.4593, 0.4777],
       device='cuda:0') torch.Size([16])
percent tensor([0.5205, 0.5358, 0.5102, 0.5127, 0.5104, 0.5112, 0.5278, 0.5137, 0.5280,
        0.5338, 0.5377, 0.5220, 0.5312, 0.5365, 0.5262, 0.5224],
       device='cuda:0') torch.Size([16])
percent tensor([0.5589, 0.5213, 0.6513, 0.6572, 0.6673, 0.6323, 0.6022, 0.6404, 0.5598,
        0.5156, 0.5350, 0.5979, 0.4977, 0.5542, 0.5786, 0.5553],
       device='cuda:0') torch.Size([16])
percent tensor([0.5487, 0.5350, 0.5566, 0.5676, 0.5843, 0.5943, 0.5433, 0.5474, 0.5532,
        0.5324, 0.5340, 0.5084, 0.5368, 0.5559, 0.5192, 0.5607],
       device='cuda:0') torch.Size([16])
percent tensor([0.6443, 0.5841, 0.6357, 0.6556, 0.6546, 0.7253, 0.5863, 0.5741, 0.6264,
        0.6153, 0.5985, 0.5943, 0.6033, 0.6186, 0.5589, 0.6521],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9938, 0.9969, 0.9966, 0.9974, 0.9978, 0.9981, 0.9982, 0.9937,
        0.9989, 0.9971, 0.9980, 0.9960, 0.9970, 0.9977, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 42 | Batch_idx: 0 |  Loss: (0.4173) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4688) |  Loss2: (0.0000) | Acc: (83.00%) (1176/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.4703) |  Loss2: (0.0000) | Acc: (83.00%) (2251/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.4770) |  Loss2: (0.0000) | Acc: (83.00%) (3314/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.4859) |  Loss2: (0.0000) | Acc: (83.00%) (4377/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (5445/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.4808) |  Loss2: (0.0000) | Acc: (83.00%) (6518/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.4775) |  Loss2: (0.0000) | Acc: (83.00%) (7593/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.4754) |  Loss2: (0.0000) | Acc: (83.00%) (8670/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.4712) |  Loss2: (0.0000) | Acc: (83.00%) (9761/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.4726) |  Loss2: (0.0000) | Acc: (83.00%) (10826/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4726) |  Loss2: (0.0000) | Acc: (83.00%) (11891/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4726) |  Loss2: (0.0000) | Acc: (83.00%) (12958/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4761) |  Loss2: (0.0000) | Acc: (83.00%) (14001/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4772) |  Loss2: (0.0000) | Acc: (83.00%) (15058/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4786) |  Loss2: (0.0000) | Acc: (83.00%) (16119/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4796) |  Loss2: (0.0000) | Acc: (83.00%) (17178/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4806) |  Loss2: (0.0000) | Acc: (83.00%) (18225/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4785) |  Loss2: (0.0000) | Acc: (83.00%) (19317/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.4789) |  Loss2: (0.0000) | Acc: (83.00%) (20396/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (83.00%) (21438/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.4809) |  Loss2: (0.0000) | Acc: (83.00%) (22514/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (23565/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.4814) |  Loss2: (0.0000) | Acc: (83.00%) (24645/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.4813) |  Loss2: (0.0000) | Acc: (83.00%) (25713/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.4821) |  Loss2: (0.0000) | Acc: (83.00%) (26755/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.4828) |  Loss2: (0.0000) | Acc: (83.00%) (27808/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (28883/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4823) |  Loss2: (0.0000) | Acc: (83.00%) (29950/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4817) |  Loss2: (0.0000) | Acc: (83.00%) (31024/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4817) |  Loss2: (0.0000) | Acc: (83.00%) (32090/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4831) |  Loss2: (0.0000) | Acc: (83.00%) (33153/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4838) |  Loss2: (0.0000) | Acc: (83.00%) (34205/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4841) |  Loss2: (0.0000) | Acc: (83.00%) (35263/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4848) |  Loss2: (0.0000) | Acc: (83.00%) (36320/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4856) |  Loss2: (0.0000) | Acc: (83.00%) (37368/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4851) |  Loss2: (0.0000) | Acc: (83.00%) (38442/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4851) |  Loss2: (0.0000) | Acc: (83.00%) (39496/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4862) |  Loss2: (0.0000) | Acc: (83.00%) (40538/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4862) |  Loss2: (0.0000) | Acc: (83.00%) (41568/50000)
# TEST : Loss: (0.6226) | Acc: (79.00%) (7910/10000)
percent tensor([0.5195, 0.5243, 0.5148, 0.5122, 0.5201, 0.5099, 0.5247, 0.5194, 0.5268,
        0.5227, 0.5256, 0.5210, 0.5220, 0.5248, 0.5168, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.4966, 0.4977, 0.4868, 0.4927, 0.4893, 0.4965, 0.4956, 0.4921, 0.4941,
        0.4942, 0.4983, 0.4870, 0.4958, 0.5001, 0.4955, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.4732, 0.4383, 0.4549, 0.4948, 0.4672, 0.5082, 0.4454, 0.4569, 0.4756,
        0.4369, 0.4596, 0.4251, 0.4384, 0.5038, 0.4524, 0.4750],
       device='cuda:0') torch.Size([16])
percent tensor([0.5217, 0.5363, 0.5121, 0.5123, 0.5131, 0.5106, 0.5302, 0.5157, 0.5280,
        0.5348, 0.5385, 0.5223, 0.5310, 0.5359, 0.5271, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.5636, 0.5189, 0.6490, 0.6630, 0.6594, 0.6391, 0.5834, 0.6230, 0.5669,
        0.5218, 0.5405, 0.5978, 0.5026, 0.5527, 0.5732, 0.5602],
       device='cuda:0') torch.Size([16])
percent tensor([0.5414, 0.5235, 0.5507, 0.5568, 0.5737, 0.5907, 0.5249, 0.5271, 0.5483,
        0.5262, 0.5262, 0.5093, 0.5265, 0.5492, 0.4993, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.6327, 0.5532, 0.6428, 0.6538, 0.6419, 0.7256, 0.5589, 0.5574, 0.6082,
        0.5810, 0.5776, 0.5998, 0.5641, 0.6080, 0.5411, 0.6270],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9957, 0.9971, 0.9964, 0.9972, 0.9979, 0.9985, 0.9984, 0.9969,
        0.9989, 0.9980, 0.9973, 0.9961, 0.9977, 0.9976, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 43 | Batch_idx: 0 |  Loss: (0.4652) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4719) |  Loss2: (0.0000) | Acc: (82.00%) (1166/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4632) |  Loss2: (0.0000) | Acc: (83.00%) (2250/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4598) |  Loss2: (0.0000) | Acc: (83.00%) (3330/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4697) |  Loss2: (0.0000) | Acc: (83.00%) (4384/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4749) |  Loss2: (0.0000) | Acc: (83.00%) (5447/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4709) |  Loss2: (0.0000) | Acc: (83.00%) (6522/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4744) |  Loss2: (0.0000) | Acc: (83.00%) (7596/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4740) |  Loss2: (0.0000) | Acc: (83.00%) (8679/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4745) |  Loss2: (0.0000) | Acc: (83.00%) (9749/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4735) |  Loss2: (0.0000) | Acc: (83.00%) (10816/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4722) |  Loss2: (0.0000) | Acc: (83.00%) (11893/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4724) |  Loss2: (0.0000) | Acc: (83.00%) (12965/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4743) |  Loss2: (0.0000) | Acc: (83.00%) (14028/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4720) |  Loss2: (0.0000) | Acc: (83.00%) (15118/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4712) |  Loss2: (0.0000) | Acc: (83.00%) (16199/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4703) |  Loss2: (0.0000) | Acc: (83.00%) (17282/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4681) |  Loss2: (0.0000) | Acc: (83.00%) (18380/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4674) |  Loss2: (0.0000) | Acc: (83.00%) (19447/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4677) |  Loss2: (0.0000) | Acc: (83.00%) (20517/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4669) |  Loss2: (0.0000) | Acc: (83.00%) (21602/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4668) |  Loss2: (0.0000) | Acc: (83.00%) (22675/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4662) |  Loss2: (0.0000) | Acc: (83.00%) (23758/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4657) |  Loss2: (0.0000) | Acc: (84.00%) (24844/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4666) |  Loss2: (0.0000) | Acc: (83.00%) (25895/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4654) |  Loss2: (0.0000) | Acc: (83.00%) (26978/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4662) |  Loss2: (0.0000) | Acc: (83.00%) (28032/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4673) |  Loss2: (0.0000) | Acc: (83.00%) (29101/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4668) |  Loss2: (0.0000) | Acc: (83.00%) (30166/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4662) |  Loss2: (0.0000) | Acc: (83.00%) (31248/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4662) |  Loss2: (0.0000) | Acc: (83.00%) (32316/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4663) |  Loss2: (0.0000) | Acc: (83.00%) (33367/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4655) |  Loss2: (0.0000) | Acc: (83.00%) (34454/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4652) |  Loss2: (0.0000) | Acc: (83.00%) (35522/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (83.00%) (36616/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (83.00%) (37700/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4635) |  Loss2: (0.0000) | Acc: (83.00%) (38790/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4625) |  Loss2: (0.0000) | Acc: (83.00%) (39883/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4627) |  Loss2: (0.0000) | Acc: (83.00%) (40954/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4632) |  Loss2: (0.0000) | Acc: (83.00%) (41982/50000)
# TEST : Loss: (0.5611) | Acc: (81.00%) (8126/10000)
percent tensor([0.5196, 0.5244, 0.5160, 0.5120, 0.5206, 0.5095, 0.5247, 0.5201, 0.5272,
        0.5228, 0.5257, 0.5214, 0.5222, 0.5248, 0.5169, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.4966, 0.4978, 0.4874, 0.4925, 0.4896, 0.4957, 0.4959, 0.4921, 0.4942,
        0.4942, 0.4983, 0.4874, 0.4959, 0.4996, 0.4953, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.4753, 0.4409, 0.4570, 0.4949, 0.4681, 0.5102, 0.4489, 0.4617, 0.4783,
        0.4387, 0.4635, 0.4284, 0.4388, 0.5065, 0.4564, 0.4773],
       device='cuda:0') torch.Size([16])
percent tensor([0.5217, 0.5345, 0.5099, 0.5104, 0.5110, 0.5102, 0.5281, 0.5150, 0.5289,
        0.5333, 0.5376, 0.5214, 0.5309, 0.5359, 0.5250, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5226, 0.6470, 0.6585, 0.6597, 0.6473, 0.5906, 0.6228, 0.5606,
        0.5233, 0.5481, 0.5995, 0.4969, 0.5552, 0.5805, 0.5588],
       device='cuda:0') torch.Size([16])
percent tensor([0.5476, 0.5286, 0.5618, 0.5588, 0.5850, 0.5957, 0.5358, 0.5363, 0.5487,
        0.5285, 0.5295, 0.5202, 0.5324, 0.5483, 0.5146, 0.5598],
       device='cuda:0') torch.Size([16])
percent tensor([0.6210, 0.5498, 0.6518, 0.6595, 0.6730, 0.7347, 0.5693, 0.5682, 0.6013,
        0.5745, 0.5719, 0.6141, 0.5723, 0.6020, 0.5464, 0.6360],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9950, 0.9973, 0.9967, 0.9982, 0.9973, 0.9980, 0.9982, 0.9942,
        0.9976, 0.9962, 0.9971, 0.9943, 0.9966, 0.9968, 0.9986],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 44 | Batch_idx: 0 |  Loss: (0.3949) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.4689) |  Loss2: (0.0000) | Acc: (84.00%) (1187/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.5118) |  Loss2: (0.0000) | Acc: (83.00%) (2246/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.5225) |  Loss2: (0.0000) | Acc: (82.00%) (3279/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.5336) |  Loss2: (0.0000) | Acc: (81.00%) (4293/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.5381) |  Loss2: (0.0000) | Acc: (81.00%) (5315/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.5404) |  Loss2: (0.0000) | Acc: (81.00%) (6373/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.5414) |  Loss2: (0.0000) | Acc: (81.00%) (7417/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.5455) |  Loss2: (0.0000) | Acc: (81.00%) (8451/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.5448) |  Loss2: (0.0000) | Acc: (81.00%) (9493/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.5411) |  Loss2: (0.0000) | Acc: (81.00%) (10554/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.5436) |  Loss2: (0.0000) | Acc: (81.00%) (11581/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.5411) |  Loss2: (0.0000) | Acc: (81.00%) (12630/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.5412) |  Loss2: (0.0000) | Acc: (81.00%) (13671/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.5400) |  Loss2: (0.0000) | Acc: (81.00%) (14724/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.5379) |  Loss2: (0.0000) | Acc: (81.00%) (15773/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.5366) |  Loss2: (0.0000) | Acc: (81.00%) (16826/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.5342) |  Loss2: (0.0000) | Acc: (81.00%) (17887/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.5329) |  Loss2: (0.0000) | Acc: (81.00%) (18942/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.5326) |  Loss2: (0.0000) | Acc: (81.00%) (19998/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.5297) |  Loss2: (0.0000) | Acc: (81.00%) (21057/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.5289) |  Loss2: (0.0000) | Acc: (81.00%) (22107/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.5294) |  Loss2: (0.0000) | Acc: (81.00%) (23149/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.5314) |  Loss2: (0.0000) | Acc: (81.00%) (24157/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.5312) |  Loss2: (0.0000) | Acc: (81.00%) (25192/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.5320) |  Loss2: (0.0000) | Acc: (81.00%) (26237/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.5308) |  Loss2: (0.0000) | Acc: (81.00%) (27284/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.5308) |  Loss2: (0.0000) | Acc: (81.00%) (28335/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.5314) |  Loss2: (0.0000) | Acc: (81.00%) (29360/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.5303) |  Loss2: (0.0000) | Acc: (81.00%) (30415/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.5300) |  Loss2: (0.0000) | Acc: (81.00%) (31469/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.5299) |  Loss2: (0.0000) | Acc: (81.00%) (32520/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.5282) |  Loss2: (0.0000) | Acc: (81.00%) (33581/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.5280) |  Loss2: (0.0000) | Acc: (81.00%) (34642/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.5260) |  Loss2: (0.0000) | Acc: (81.00%) (35717/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.5244) |  Loss2: (0.0000) | Acc: (81.00%) (36794/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.5226) |  Loss2: (0.0000) | Acc: (81.00%) (37879/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.5225) |  Loss2: (0.0000) | Acc: (81.00%) (38936/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.5221) |  Loss2: (0.0000) | Acc: (81.00%) (39979/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.5206) |  Loss2: (0.0000) | Acc: (82.00%) (41008/50000)
# TEST : Loss: (0.5519) | Acc: (81.00%) (8113/10000)
percent tensor([0.5070, 0.5091, 0.5046, 0.5002, 0.5072, 0.4981, 0.5094, 0.5065, 0.5118,
        0.5088, 0.5107, 0.5084, 0.5090, 0.5096, 0.5032, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.4876, 0.4886, 0.4795, 0.4854, 0.4813, 0.4892, 0.4860, 0.4843, 0.4848,
        0.4849, 0.4881, 0.4783, 0.4869, 0.4895, 0.4867, 0.4892],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.4723, 0.4918, 0.5169, 0.5050, 0.5303, 0.4845, 0.4971, 0.5078,
        0.4694, 0.4883, 0.4695, 0.4680, 0.5241, 0.4899, 0.5006],
       device='cuda:0') torch.Size([16])
percent tensor([0.5381, 0.5543, 0.5256, 0.5284, 0.5298, 0.5283, 0.5478, 0.5337, 0.5461,
        0.5533, 0.5577, 0.5372, 0.5464, 0.5576, 0.5442, 0.5430],
       device='cuda:0') torch.Size([16])
percent tensor([0.5543, 0.4939, 0.6490, 0.6563, 0.6593, 0.6518, 0.5770, 0.6119, 0.5370,
        0.5000, 0.5172, 0.5931, 0.4780, 0.5272, 0.5641, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.5621, 0.5453, 0.5846, 0.5756, 0.6052, 0.6105, 0.5572, 0.5555, 0.5650,
        0.5413, 0.5403, 0.5390, 0.5506, 0.5636, 0.5320, 0.5759],
       device='cuda:0') torch.Size([16])
percent tensor([0.6331, 0.5633, 0.6215, 0.6214, 0.6353, 0.7322, 0.5614, 0.5210, 0.6009,
        0.5697, 0.5707, 0.5905, 0.5930, 0.6038, 0.5328, 0.6352],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9951, 0.9959, 0.9952, 0.9974, 0.9978, 0.9981, 0.9979, 0.9972,
        0.9981, 0.9975, 0.9972, 0.9972, 0.9978, 0.9970, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 45 | Batch_idx: 0 |  Loss: (0.4421) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.4534) |  Loss2: (0.0000) | Acc: (84.00%) (1184/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4665) |  Loss2: (0.0000) | Acc: (83.00%) (2249/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4758) |  Loss2: (0.0000) | Acc: (83.00%) (3316/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.4779) |  Loss2: (0.0000) | Acc: (83.00%) (4377/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.4792) |  Loss2: (0.0000) | Acc: (83.00%) (5443/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.4793) |  Loss2: (0.0000) | Acc: (83.00%) (6508/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.4784) |  Loss2: (0.0000) | Acc: (83.00%) (7580/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (8622/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.4836) |  Loss2: (0.0000) | Acc: (83.00%) (9696/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.4795) |  Loss2: (0.0000) | Acc: (83.00%) (10777/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.4759) |  Loss2: (0.0000) | Acc: (83.00%) (11860/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.4746) |  Loss2: (0.0000) | Acc: (83.00%) (12940/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.4771) |  Loss2: (0.0000) | Acc: (83.00%) (13981/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.4761) |  Loss2: (0.0000) | Acc: (83.00%) (15057/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.4765) |  Loss2: (0.0000) | Acc: (83.00%) (16116/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.4741) |  Loss2: (0.0000) | Acc: (83.00%) (17200/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.4749) |  Loss2: (0.0000) | Acc: (83.00%) (18269/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.4762) |  Loss2: (0.0000) | Acc: (83.00%) (19320/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.4793) |  Loss2: (0.0000) | Acc: (83.00%) (20368/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.4785) |  Loss2: (0.0000) | Acc: (83.00%) (21452/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.4799) |  Loss2: (0.0000) | Acc: (83.00%) (22517/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.4769) |  Loss2: (0.0000) | Acc: (83.00%) (23611/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.4766) |  Loss2: (0.0000) | Acc: (83.00%) (24686/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.4770) |  Loss2: (0.0000) | Acc: (83.00%) (25749/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.4775) |  Loss2: (0.0000) | Acc: (83.00%) (26812/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.4770) |  Loss2: (0.0000) | Acc: (83.00%) (27888/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.4782) |  Loss2: (0.0000) | Acc: (83.00%) (28936/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.4794) |  Loss2: (0.0000) | Acc: (83.00%) (30000/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4799) |  Loss2: (0.0000) | Acc: (83.00%) (31047/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4794) |  Loss2: (0.0000) | Acc: (83.00%) (32129/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4792) |  Loss2: (0.0000) | Acc: (83.00%) (33199/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (34249/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4798) |  Loss2: (0.0000) | Acc: (83.00%) (35320/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4785) |  Loss2: (0.0000) | Acc: (83.00%) (36392/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4775) |  Loss2: (0.0000) | Acc: (83.00%) (37482/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4779) |  Loss2: (0.0000) | Acc: (83.00%) (38553/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4788) |  Loss2: (0.0000) | Acc: (83.00%) (39609/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4784) |  Loss2: (0.0000) | Acc: (83.00%) (40683/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4776) |  Loss2: (0.0000) | Acc: (83.00%) (41721/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_045.pth.tar'
# TEST : Loss: (0.5296) | Acc: (82.00%) (8202/10000)
percent tensor([0.5064, 0.5082, 0.5040, 0.5001, 0.5063, 0.4984, 0.5084, 0.5058, 0.5108,
        0.5078, 0.5097, 0.5074, 0.5082, 0.5090, 0.5028, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.4878, 0.4884, 0.4803, 0.4862, 0.4820, 0.4897, 0.4861, 0.4849, 0.4847,
        0.4850, 0.4878, 0.4790, 0.4867, 0.4891, 0.4871, 0.4894],
       device='cuda:0') torch.Size([16])
percent tensor([0.4993, 0.4722, 0.4853, 0.5151, 0.4979, 0.5295, 0.4810, 0.4914, 0.5078,
        0.4679, 0.4891, 0.4634, 0.4667, 0.5276, 0.4867, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5414, 0.5585, 0.5316, 0.5342, 0.5360, 0.5341, 0.5517, 0.5399, 0.5493,
        0.5579, 0.5613, 0.5410, 0.5485, 0.5610, 0.5487, 0.5476],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.4987, 0.6491, 0.6585, 0.6598, 0.6574, 0.5827, 0.6123, 0.5423,
        0.5033, 0.5230, 0.5955, 0.4793, 0.5319, 0.5709, 0.5543],
       device='cuda:0') torch.Size([16])
percent tensor([0.5668, 0.5516, 0.5947, 0.5864, 0.6148, 0.6210, 0.5643, 0.5616, 0.5732,
        0.5471, 0.5455, 0.5484, 0.5562, 0.5749, 0.5372, 0.5823],
       device='cuda:0') torch.Size([16])
percent tensor([0.6404, 0.5724, 0.6121, 0.6136, 0.6254, 0.7385, 0.5603, 0.5016, 0.6096,
        0.5791, 0.5816, 0.5899, 0.6066, 0.6209, 0.5296, 0.6414],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9955, 0.9966, 0.9960, 0.9978, 0.9981, 0.9984, 0.9983, 0.9974,
        0.9984, 0.9977, 0.9976, 0.9973, 0.9983, 0.9975, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 46 | Batch_idx: 0 |  Loss: (0.5749) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.4943) |  Loss2: (0.0000) | Acc: (83.00%) (1176/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.5115) |  Loss2: (0.0000) | Acc: (82.00%) (2227/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.5075) |  Loss2: (0.0000) | Acc: (82.00%) (3283/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4964) |  Loss2: (0.0000) | Acc: (83.00%) (4367/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4923) |  Loss2: (0.0000) | Acc: (83.00%) (5445/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4927) |  Loss2: (0.0000) | Acc: (83.00%) (6517/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4872) |  Loss2: (0.0000) | Acc: (83.00%) (7598/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4833) |  Loss2: (0.0000) | Acc: (83.00%) (8664/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4843) |  Loss2: (0.0000) | Acc: (83.00%) (9726/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4793) |  Loss2: (0.0000) | Acc: (83.00%) (10817/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4754) |  Loss2: (0.0000) | Acc: (83.00%) (11900/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4749) |  Loss2: (0.0000) | Acc: (83.00%) (12976/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4706) |  Loss2: (0.0000) | Acc: (83.00%) (14065/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4710) |  Loss2: (0.0000) | Acc: (83.00%) (15121/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4728) |  Loss2: (0.0000) | Acc: (83.00%) (16183/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4705) |  Loss2: (0.0000) | Acc: (83.00%) (17265/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4700) |  Loss2: (0.0000) | Acc: (83.00%) (18328/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4663) |  Loss2: (0.0000) | Acc: (83.00%) (19431/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4658) |  Loss2: (0.0000) | Acc: (83.00%) (20509/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (83.00%) (21592/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4642) |  Loss2: (0.0000) | Acc: (83.00%) (22664/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4639) |  Loss2: (0.0000) | Acc: (83.00%) (23756/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4636) |  Loss2: (0.0000) | Acc: (84.00%) (24847/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4647) |  Loss2: (0.0000) | Acc: (83.00%) (25908/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4646) |  Loss2: (0.0000) | Acc: (84.00%) (26991/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4653) |  Loss2: (0.0000) | Acc: (83.00%) (28061/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (84.00%) (29144/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4647) |  Loss2: (0.0000) | Acc: (84.00%) (30220/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4647) |  Loss2: (0.0000) | Acc: (83.00%) (31288/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4641) |  Loss2: (0.0000) | Acc: (84.00%) (32377/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4646) |  Loss2: (0.0000) | Acc: (84.00%) (33445/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4644) |  Loss2: (0.0000) | Acc: (84.00%) (34521/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4635) |  Loss2: (0.0000) | Acc: (84.00%) (35603/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4624) |  Loss2: (0.0000) | Acc: (84.00%) (36702/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4624) |  Loss2: (0.0000) | Acc: (84.00%) (37772/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4619) |  Loss2: (0.0000) | Acc: (84.00%) (38859/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4617) |  Loss2: (0.0000) | Acc: (84.00%) (39947/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4617) |  Loss2: (0.0000) | Acc: (84.00%) (41019/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4611) |  Loss2: (0.0000) | Acc: (84.00%) (42046/50000)
# TEST : Loss: (0.5200) | Acc: (82.00%) (8245/10000)
percent tensor([0.5075, 0.5094, 0.5050, 0.5018, 0.5074, 0.5001, 0.5096, 0.5071, 0.5119,
        0.5089, 0.5109, 0.5083, 0.5092, 0.5106, 0.5043, 0.5052],
       device='cuda:0') torch.Size([16])
percent tensor([0.4868, 0.4871, 0.4799, 0.4857, 0.4814, 0.4891, 0.4850, 0.4841, 0.4834,
        0.4840, 0.4863, 0.4783, 0.4855, 0.4875, 0.4861, 0.4885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.4780, 0.4829, 0.5145, 0.4951, 0.5310, 0.4832, 0.4887, 0.5123,
        0.4728, 0.4954, 0.4617, 0.4718, 0.5344, 0.4885, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5458, 0.5636, 0.5371, 0.5400, 0.5418, 0.5404, 0.5559, 0.5460, 0.5535,
        0.5632, 0.5658, 0.5450, 0.5522, 0.5656, 0.5538, 0.5532],
       device='cuda:0') torch.Size([16])
percent tensor([0.5639, 0.5013, 0.6534, 0.6639, 0.6641, 0.6660, 0.5886, 0.6136, 0.5515,
        0.5066, 0.5295, 0.6002, 0.4815, 0.5369, 0.5776, 0.5563],
       device='cuda:0') torch.Size([16])
percent tensor([0.5792, 0.5642, 0.6109, 0.6023, 0.6309, 0.6337, 0.5800, 0.5771, 0.5879,
        0.5612, 0.5587, 0.5655, 0.5689, 0.5917, 0.5511, 0.5949],
       device='cuda:0') torch.Size([16])
percent tensor([0.6509, 0.5835, 0.6157, 0.6137, 0.6290, 0.7487, 0.5662, 0.4958, 0.6212,
        0.5928, 0.5928, 0.5964, 0.6214, 0.6356, 0.5332, 0.6494],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9959, 0.9970, 0.9965, 0.9981, 0.9984, 0.9986, 0.9985, 0.9975,
        0.9986, 0.9980, 0.9978, 0.9975, 0.9986, 0.9977, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 47 | Batch_idx: 0 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.4576) |  Loss2: (0.0000) | Acc: (84.00%) (1188/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.4780) |  Loss2: (0.0000) | Acc: (83.00%) (2247/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.4583) |  Loss2: (0.0000) | Acc: (84.00%) (3349/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4645) |  Loss2: (0.0000) | Acc: (84.00%) (4418/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4688) |  Loss2: (0.0000) | Acc: (84.00%) (5491/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4639) |  Loss2: (0.0000) | Acc: (84.00%) (6578/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4624) |  Loss2: (0.0000) | Acc: (84.00%) (7653/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4600) |  Loss2: (0.0000) | Acc: (84.00%) (8732/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4638) |  Loss2: (0.0000) | Acc: (84.00%) (9794/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4655) |  Loss2: (0.0000) | Acc: (84.00%) (10864/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4645) |  Loss2: (0.0000) | Acc: (84.00%) (11938/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4630) |  Loss2: (0.0000) | Acc: (84.00%) (13013/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4609) |  Loss2: (0.0000) | Acc: (84.00%) (14108/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4644) |  Loss2: (0.0000) | Acc: (83.00%) (15154/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4644) |  Loss2: (0.0000) | Acc: (83.00%) (16235/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4636) |  Loss2: (0.0000) | Acc: (84.00%) (17319/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4638) |  Loss2: (0.0000) | Acc: (84.00%) (18389/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4621) |  Loss2: (0.0000) | Acc: (84.00%) (19475/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4614) |  Loss2: (0.0000) | Acc: (84.00%) (20543/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4615) |  Loss2: (0.0000) | Acc: (84.00%) (21612/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4606) |  Loss2: (0.0000) | Acc: (84.00%) (22694/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4603) |  Loss2: (0.0000) | Acc: (84.00%) (23777/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4596) |  Loss2: (0.0000) | Acc: (84.00%) (24865/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4577) |  Loss2: (0.0000) | Acc: (84.00%) (25966/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (84.00%) (27041/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4561) |  Loss2: (0.0000) | Acc: (84.00%) (28150/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4568) |  Loss2: (0.0000) | Acc: (84.00%) (29229/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4580) |  Loss2: (0.0000) | Acc: (84.00%) (30296/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4566) |  Loss2: (0.0000) | Acc: (84.00%) (31391/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4556) |  Loss2: (0.0000) | Acc: (84.00%) (32477/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4550) |  Loss2: (0.0000) | Acc: (84.00%) (33575/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4552) |  Loss2: (0.0000) | Acc: (84.00%) (34657/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4548) |  Loss2: (0.0000) | Acc: (84.00%) (35745/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4537) |  Loss2: (0.0000) | Acc: (84.00%) (36831/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4536) |  Loss2: (0.0000) | Acc: (84.00%) (37919/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4536) |  Loss2: (0.0000) | Acc: (84.00%) (39007/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4534) |  Loss2: (0.0000) | Acc: (84.00%) (40089/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4537) |  Loss2: (0.0000) | Acc: (84.00%) (41187/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4532) |  Loss2: (0.0000) | Acc: (84.00%) (42238/50000)
# TEST : Loss: (0.5123) | Acc: (82.00%) (8258/10000)
percent tensor([0.5080, 0.5096, 0.5056, 0.5025, 0.5079, 0.5006, 0.5098, 0.5076, 0.5122,
        0.5092, 0.5111, 0.5087, 0.5095, 0.5109, 0.5047, 0.5056],
       device='cuda:0') torch.Size([16])
percent tensor([0.4887, 0.4890, 0.4823, 0.4878, 0.4838, 0.4908, 0.4871, 0.4864, 0.4855,
        0.4860, 0.4881, 0.4809, 0.4873, 0.4894, 0.4882, 0.4902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.4806, 0.4812, 0.5134, 0.4925, 0.5299, 0.4827, 0.4872, 0.5135,
        0.4754, 0.4972, 0.4617, 0.4750, 0.5363, 0.4875, 0.5025],
       device='cuda:0') torch.Size([16])
percent tensor([0.5475, 0.5660, 0.5408, 0.5435, 0.5454, 0.5435, 0.5576, 0.5498, 0.5547,
        0.5658, 0.5674, 0.5474, 0.5534, 0.5669, 0.5563, 0.5558],
       device='cuda:0') torch.Size([16])
percent tensor([0.5641, 0.5042, 0.6521, 0.6610, 0.6613, 0.6628, 0.5917, 0.6121, 0.5541,
        0.5084, 0.5337, 0.6025, 0.4823, 0.5380, 0.5802, 0.5520],
       device='cuda:0') torch.Size([16])
percent tensor([0.5753, 0.5611, 0.6113, 0.6026, 0.6310, 0.6346, 0.5768, 0.5743, 0.5863,
        0.5578, 0.5551, 0.5650, 0.5652, 0.5897, 0.5475, 0.5922],
       device='cuda:0') torch.Size([16])
percent tensor([0.6619, 0.5937, 0.6217, 0.6199, 0.6358, 0.7572, 0.5721, 0.4967, 0.6315,
        0.6066, 0.6050, 0.6032, 0.6326, 0.6453, 0.5423, 0.6613],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9962, 0.9975, 0.9972, 0.9983, 0.9987, 0.9988, 0.9987, 0.9978,
        0.9988, 0.9982, 0.9981, 0.9979, 0.9987, 0.9980, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 48 | Batch_idx: 0 |  Loss: (0.4658) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.4219) |  Loss2: (0.0000) | Acc: (85.00%) (1200/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.4319) |  Loss2: (0.0000) | Acc: (84.00%) (2269/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.4354) |  Loss2: (0.0000) | Acc: (84.00%) (3363/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.4378) |  Loss2: (0.0000) | Acc: (84.00%) (4432/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.4429) |  Loss2: (0.0000) | Acc: (84.00%) (5512/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.4389) |  Loss2: (0.0000) | Acc: (84.00%) (6603/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.4426) |  Loss2: (0.0000) | Acc: (84.00%) (7682/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.4445) |  Loss2: (0.0000) | Acc: (84.00%) (8767/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.4419) |  Loss2: (0.0000) | Acc: (84.00%) (9865/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.4452) |  Loss2: (0.0000) | Acc: (84.00%) (10938/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.4476) |  Loss2: (0.0000) | Acc: (84.00%) (12005/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.4495) |  Loss2: (0.0000) | Acc: (84.00%) (13083/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.4522) |  Loss2: (0.0000) | Acc: (84.00%) (14161/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.4550) |  Loss2: (0.0000) | Acc: (84.00%) (15223/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (84.00%) (16305/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.4542) |  Loss2: (0.0000) | Acc: (84.00%) (17374/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.4525) |  Loss2: (0.0000) | Acc: (84.00%) (18466/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.4515) |  Loss2: (0.0000) | Acc: (84.00%) (19553/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.4552) |  Loss2: (0.0000) | Acc: (84.00%) (20603/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.4549) |  Loss2: (0.0000) | Acc: (84.00%) (21687/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.4551) |  Loss2: (0.0000) | Acc: (84.00%) (22779/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.4565) |  Loss2: (0.0000) | Acc: (84.00%) (23839/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.4560) |  Loss2: (0.0000) | Acc: (84.00%) (24919/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (26007/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.4540) |  Loss2: (0.0000) | Acc: (84.00%) (27104/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.4538) |  Loss2: (0.0000) | Acc: (84.00%) (28179/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.4535) |  Loss2: (0.0000) | Acc: (84.00%) (29264/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.4529) |  Loss2: (0.0000) | Acc: (84.00%) (30334/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.4524) |  Loss2: (0.0000) | Acc: (84.00%) (31408/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.4525) |  Loss2: (0.0000) | Acc: (84.00%) (32478/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.4525) |  Loss2: (0.0000) | Acc: (84.00%) (33551/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.4523) |  Loss2: (0.0000) | Acc: (84.00%) (34623/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.4518) |  Loss2: (0.0000) | Acc: (84.00%) (35714/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.4519) |  Loss2: (0.0000) | Acc: (84.00%) (36790/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.4511) |  Loss2: (0.0000) | Acc: (84.00%) (37903/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.4513) |  Loss2: (0.0000) | Acc: (84.00%) (38989/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.4520) |  Loss2: (0.0000) | Acc: (84.00%) (40061/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.4518) |  Loss2: (0.0000) | Acc: (84.00%) (41142/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.4522) |  Loss2: (0.0000) | Acc: (84.00%) (42171/50000)
# TEST : Loss: (0.5851) | Acc: (80.00%) (8007/10000)
percent tensor([0.5075, 0.5099, 0.5032, 0.5018, 0.5059, 0.5007, 0.5096, 0.5066, 0.5124,
        0.5090, 0.5115, 0.5067, 0.5094, 0.5120, 0.5046, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.4888, 0.4881, 0.4836, 0.4884, 0.4848, 0.4916, 0.4866, 0.4864, 0.4852,
        0.4854, 0.4876, 0.4816, 0.4871, 0.4885, 0.4881, 0.4903],
       device='cuda:0') torch.Size([16])
percent tensor([0.4969, 0.4831, 0.4783, 0.5172, 0.4903, 0.5246, 0.4832, 0.4922, 0.5136,
        0.4805, 0.4931, 0.4591, 0.4740, 0.5388, 0.4862, 0.5031],
       device='cuda:0') torch.Size([16])
percent tensor([0.5504, 0.5684, 0.5390, 0.5457, 0.5427, 0.5429, 0.5596, 0.5512, 0.5570,
        0.5689, 0.5706, 0.5473, 0.5565, 0.5745, 0.5572, 0.5558],
       device='cuda:0') torch.Size([16])
percent tensor([0.5520, 0.5146, 0.6379, 0.6518, 0.6511, 0.6498, 0.5868, 0.6125, 0.5494,
        0.5166, 0.5334, 0.5930, 0.4824, 0.5469, 0.5844, 0.5434],
       device='cuda:0') torch.Size([16])
percent tensor([0.5801, 0.5655, 0.6032, 0.6040, 0.6280, 0.6329, 0.5737, 0.5792, 0.5928,
        0.5596, 0.5604, 0.5559, 0.5669, 0.5957, 0.5503, 0.5899],
       device='cuda:0') torch.Size([16])
percent tensor([0.6770, 0.5951, 0.6378, 0.6372, 0.6505, 0.7583, 0.5919, 0.5226, 0.6595,
        0.6182, 0.6429, 0.5960, 0.6466, 0.6806, 0.5595, 0.6741],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9962, 0.9985, 0.9978, 0.9987, 0.9990, 0.9995, 0.9987, 0.9970,
        0.9990, 0.9989, 0.9983, 0.9968, 0.9984, 0.9986, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 49 | Batch_idx: 0 |  Loss: (0.6557) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.4587) |  Loss2: (0.0000) | Acc: (84.00%) (1194/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.4446) |  Loss2: (0.0000) | Acc: (84.00%) (2276/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.4401) |  Loss2: (0.0000) | Acc: (84.00%) (3357/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.4369) |  Loss2: (0.0000) | Acc: (84.00%) (4459/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.4418) |  Loss2: (0.0000) | Acc: (84.00%) (5538/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.4467) |  Loss2: (0.0000) | Acc: (84.00%) (6616/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.4465) |  Loss2: (0.0000) | Acc: (84.00%) (7697/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.4429) |  Loss2: (0.0000) | Acc: (84.00%) (8796/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.4415) |  Loss2: (0.0000) | Acc: (84.00%) (9882/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.4403) |  Loss2: (0.0000) | Acc: (84.00%) (10967/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.4371) |  Loss2: (0.0000) | Acc: (84.00%) (12066/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.4411) |  Loss2: (0.0000) | Acc: (84.00%) (13124/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.4425) |  Loss2: (0.0000) | Acc: (84.00%) (14188/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.4425) |  Loss2: (0.0000) | Acc: (84.00%) (15272/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.4447) |  Loss2: (0.0000) | Acc: (84.00%) (16328/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.4461) |  Loss2: (0.0000) | Acc: (84.00%) (17397/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.4468) |  Loss2: (0.0000) | Acc: (84.00%) (18479/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.4492) |  Loss2: (0.0000) | Acc: (84.00%) (19537/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.4513) |  Loss2: (0.0000) | Acc: (84.00%) (20593/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.4486) |  Loss2: (0.0000) | Acc: (84.00%) (21690/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.4503) |  Loss2: (0.0000) | Acc: (84.00%) (22768/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.4493) |  Loss2: (0.0000) | Acc: (84.00%) (23849/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.4489) |  Loss2: (0.0000) | Acc: (84.00%) (24929/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.4485) |  Loss2: (0.0000) | Acc: (84.00%) (26024/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.4481) |  Loss2: (0.0000) | Acc: (84.00%) (27108/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.4489) |  Loss2: (0.0000) | Acc: (84.00%) (28174/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (29265/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.4467) |  Loss2: (0.0000) | Acc: (84.00%) (30363/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.4473) |  Loss2: (0.0000) | Acc: (84.00%) (31434/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (32497/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.4482) |  Loss2: (0.0000) | Acc: (84.00%) (33571/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.4480) |  Loss2: (0.0000) | Acc: (84.00%) (34652/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.4462) |  Loss2: (0.0000) | Acc: (84.00%) (35764/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.4469) |  Loss2: (0.0000) | Acc: (84.00%) (36822/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.4477) |  Loss2: (0.0000) | Acc: (84.00%) (37897/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.4469) |  Loss2: (0.0000) | Acc: (84.00%) (39003/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.4459) |  Loss2: (0.0000) | Acc: (84.00%) (40088/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.4451) |  Loss2: (0.0000) | Acc: (84.00%) (41191/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.4442) |  Loss2: (0.0000) | Acc: (84.00%) (42252/50000)
# TEST : Loss: (0.5130) | Acc: (82.00%) (8247/10000)
percent tensor([0.5072, 0.5102, 0.5026, 0.5016, 0.5057, 0.5007, 0.5097, 0.5061, 0.5120,
        0.5089, 0.5112, 0.5061, 0.5090, 0.5128, 0.5046, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.4890, 0.4884, 0.4833, 0.4881, 0.4845, 0.4911, 0.4865, 0.4864, 0.4845,
        0.4856, 0.4878, 0.4819, 0.4873, 0.4887, 0.4884, 0.4904],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.4786, 0.4891, 0.5209, 0.5000, 0.5281, 0.4821, 0.4929, 0.5084,
        0.4791, 0.4898, 0.4669, 0.4715, 0.5351, 0.4853, 0.5024],
       device='cuda:0') torch.Size([16])
percent tensor([0.5482, 0.5672, 0.5443, 0.5456, 0.5451, 0.5432, 0.5590, 0.5512, 0.5556,
        0.5678, 0.5679, 0.5508, 0.5543, 0.5691, 0.5563, 0.5554],
       device='cuda:0') torch.Size([16])
percent tensor([0.5582, 0.5019, 0.6465, 0.6573, 0.6562, 0.6463, 0.5849, 0.6155, 0.5514,
        0.5099, 0.5405, 0.5950, 0.4897, 0.5289, 0.5840, 0.5417],
       device='cuda:0') torch.Size([16])
percent tensor([0.5778, 0.5580, 0.6062, 0.6040, 0.6264, 0.6272, 0.5732, 0.5751, 0.5934,
        0.5667, 0.5682, 0.5673, 0.5685, 0.5954, 0.5481, 0.5862],
       device='cuda:0') torch.Size([16])
percent tensor([0.6536, 0.5796, 0.6450, 0.6397, 0.6577, 0.7378, 0.5888, 0.5070, 0.6511,
        0.6269, 0.6408, 0.6232, 0.6411, 0.6595, 0.5371, 0.6539],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9961, 0.9983, 0.9970, 0.9977, 0.9987, 0.9987, 0.9988, 0.9965,
        0.9984, 0.9978, 0.9979, 0.9965, 0.9973, 0.9977, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 50 | Batch_idx: 0 |  Loss: (0.4054) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.4260) |  Loss2: (0.0000) | Acc: (84.00%) (1190/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.4009) |  Loss2: (0.0000) | Acc: (85.00%) (2311/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (85.00%) (3405/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.4165) |  Loss2: (0.0000) | Acc: (85.00%) (4491/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.4196) |  Loss2: (0.0000) | Acc: (85.00%) (5575/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.4175) |  Loss2: (0.0000) | Acc: (85.00%) (6674/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.4150) |  Loss2: (0.0000) | Acc: (85.00%) (7775/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.4159) |  Loss2: (0.0000) | Acc: (85.00%) (8858/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.4175) |  Loss2: (0.0000) | Acc: (85.00%) (9945/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.4157) |  Loss2: (0.0000) | Acc: (85.00%) (11045/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.4163) |  Loss2: (0.0000) | Acc: (85.00%) (12113/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.4188) |  Loss2: (0.0000) | Acc: (85.00%) (13196/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.4166) |  Loss2: (0.0000) | Acc: (85.00%) (14294/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.4144) |  Loss2: (0.0000) | Acc: (85.00%) (15400/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.4171) |  Loss2: (0.0000) | Acc: (85.00%) (16471/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.4155) |  Loss2: (0.0000) | Acc: (85.00%) (17590/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.4162) |  Loss2: (0.0000) | Acc: (85.00%) (18679/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.4176) |  Loss2: (0.0000) | Acc: (85.00%) (19766/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.4183) |  Loss2: (0.0000) | Acc: (85.00%) (20849/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (21924/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (23016/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (24105/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.4218) |  Loss2: (0.0000) | Acc: (85.00%) (25216/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (26333/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (27422/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (28499/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (29591/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4226) |  Loss2: (0.0000) | Acc: (85.00%) (30667/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4245) |  Loss2: (0.0000) | Acc: (85.00%) (31742/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4241) |  Loss2: (0.0000) | Acc: (85.00%) (32847/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4238) |  Loss2: (0.0000) | Acc: (85.00%) (33934/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4238) |  Loss2: (0.0000) | Acc: (85.00%) (35021/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4245) |  Loss2: (0.0000) | Acc: (85.00%) (36110/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4240) |  Loss2: (0.0000) | Acc: (85.00%) (37211/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.4246) |  Loss2: (0.0000) | Acc: (85.00%) (38298/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4241) |  Loss2: (0.0000) | Acc: (85.00%) (39407/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4246) |  Loss2: (0.0000) | Acc: (85.00%) (40483/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4264) |  Loss2: (0.0000) | Acc: (85.00%) (41542/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4259) |  Loss2: (0.0000) | Acc: (85.00%) (42602/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_050.pth.tar'
# TEST : Loss: (0.6075) | Acc: (79.00%) (7972/10000)
percent tensor([0.5075, 0.5092, 0.5038, 0.5017, 0.5063, 0.5007, 0.5092, 0.5064, 0.5120,
        0.5086, 0.5111, 0.5070, 0.5091, 0.5114, 0.5043, 0.5057],
       device='cuda:0') torch.Size([16])
percent tensor([0.4889, 0.4885, 0.4832, 0.4878, 0.4842, 0.4911, 0.4871, 0.4865, 0.4845,
        0.4857, 0.4874, 0.4817, 0.4870, 0.4889, 0.4884, 0.4902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5004, 0.4802, 0.4873, 0.5224, 0.4966, 0.5275, 0.4810, 0.4974, 0.5090,
        0.4792, 0.4892, 0.4636, 0.4741, 0.5346, 0.4883, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5492, 0.5664, 0.5443, 0.5462, 0.5461, 0.5422, 0.5574, 0.5507, 0.5555,
        0.5671, 0.5693, 0.5500, 0.5560, 0.5662, 0.5552, 0.5551],
       device='cuda:0') torch.Size([16])
percent tensor([0.5733, 0.5248, 0.6563, 0.6653, 0.6664, 0.6576, 0.6049, 0.6355, 0.5733,
        0.5247, 0.5520, 0.6057, 0.5011, 0.5509, 0.6036, 0.5623],
       device='cuda:0') torch.Size([16])
percent tensor([0.5846, 0.5695, 0.6052, 0.6085, 0.6274, 0.6291, 0.5789, 0.5842, 0.6004,
        0.5601, 0.5672, 0.5562, 0.5701, 0.5936, 0.5582, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.6517, 0.5855, 0.6276, 0.6297, 0.6368, 0.7543, 0.5616, 0.5076, 0.6508,
        0.5995, 0.6178, 0.5840, 0.6338, 0.6445, 0.5477, 0.6559],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9968, 0.9988, 0.9980, 0.9991, 0.9972, 0.9985, 0.9992, 0.9960,
        0.9990, 0.9976, 0.9988, 0.9960, 0.9975, 0.9984, 0.9986],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(173.0086, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(800.5626, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(797.8939, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.8756, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(505.2910, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2193.5872, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4297.7085, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1424.5785, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6096.2529, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12053.9043, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4020.9390, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16979.0254, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 51 | Batch_idx: 0 |  Loss: (0.4180) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.4213) |  Loss2: (0.0000) | Acc: (85.00%) (1198/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (2293/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (85.00%) (3391/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.4145) |  Loss2: (0.0000) | Acc: (85.00%) (4490/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.4052) |  Loss2: (0.0000) | Acc: (85.00%) (5602/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.4053) |  Loss2: (0.0000) | Acc: (85.00%) (6697/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (85.00%) (7811/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.4062) |  Loss2: (0.0000) | Acc: (85.00%) (8909/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (85.00%) (10005/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.4069) |  Loss2: (0.0000) | Acc: (85.00%) (11105/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.4027) |  Loss2: (0.0000) | Acc: (86.00%) (12228/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.4018) |  Loss2: (0.0000) | Acc: (86.00%) (13329/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (14396/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.4105) |  Loss2: (0.0000) | Acc: (85.00%) (15486/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (16579/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.4102) |  Loss2: (0.0000) | Acc: (85.00%) (17668/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.4106) |  Loss2: (0.0000) | Acc: (85.00%) (18754/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.4120) |  Loss2: (0.0000) | Acc: (85.00%) (19837/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.4127) |  Loss2: (0.0000) | Acc: (85.00%) (20936/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.4139) |  Loss2: (0.0000) | Acc: (85.00%) (22022/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.4144) |  Loss2: (0.0000) | Acc: (85.00%) (23110/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (24216/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (25328/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.4119) |  Loss2: (0.0000) | Acc: (85.00%) (26453/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.4118) |  Loss2: (0.0000) | Acc: (85.00%) (27562/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (85.00%) (28657/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.4115) |  Loss2: (0.0000) | Acc: (85.00%) (29756/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (30867/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.4106) |  Loss2: (0.0000) | Acc: (85.00%) (31976/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.4099) |  Loss2: (0.0000) | Acc: (85.00%) (33083/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (34193/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.4094) |  Loss2: (0.0000) | Acc: (85.00%) (35296/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (85.00%) (36395/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (85.00%) (37496/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.4087) |  Loss2: (0.0000) | Acc: (85.00%) (38591/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.4108) |  Loss2: (0.0000) | Acc: (85.00%) (39652/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.4102) |  Loss2: (0.0000) | Acc: (85.00%) (40768/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.4106) |  Loss2: (0.0000) | Acc: (85.00%) (41868/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.4110) |  Loss2: (0.0000) | Acc: (85.00%) (42912/50000)
# TEST : Loss: (0.5336) | Acc: (81.00%) (8187/10000)
percent tensor([0.5078, 0.5094, 0.5038, 0.5021, 0.5065, 0.5011, 0.5094, 0.5064, 0.5121,
        0.5086, 0.5112, 0.5071, 0.5094, 0.5111, 0.5047, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.4885, 0.4888, 0.4833, 0.4878, 0.4844, 0.4908, 0.4870, 0.4865, 0.4847,
        0.4857, 0.4874, 0.4821, 0.4869, 0.4893, 0.4882, 0.4898],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4769, 0.4907, 0.5178, 0.4987, 0.5255, 0.4801, 0.4929, 0.5110,
        0.4773, 0.4924, 0.4672, 0.4738, 0.5338, 0.4812, 0.5009],
       device='cuda:0') torch.Size([16])
percent tensor([0.5486, 0.5665, 0.5444, 0.5455, 0.5454, 0.5432, 0.5587, 0.5494, 0.5542,
        0.5670, 0.5665, 0.5512, 0.5553, 0.5679, 0.5544, 0.5556],
       device='cuda:0') torch.Size([16])
percent tensor([0.5552, 0.4970, 0.6370, 0.6561, 0.6405, 0.6385, 0.5679, 0.6047, 0.5538,
        0.5044, 0.5373, 0.5806, 0.4859, 0.5305, 0.5736, 0.5319],
       device='cuda:0') torch.Size([16])
percent tensor([0.5777, 0.5635, 0.6153, 0.6136, 0.6294, 0.6291, 0.5731, 0.5880, 0.5887,
        0.5602, 0.5605, 0.5721, 0.5659, 0.5844, 0.5535, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.6474, 0.5893, 0.6518, 0.6500, 0.6590, 0.7511, 0.5722, 0.5224, 0.6327,
        0.5995, 0.6174, 0.6159, 0.6288, 0.6379, 0.5499, 0.6513],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9973, 0.9988, 0.9978, 0.9990, 0.9992, 0.9988, 0.9987, 0.9979,
        0.9987, 0.9986, 0.9980, 0.9978, 0.9982, 0.9987, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 52 | Batch_idx: 0 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.3905) |  Loss2: (0.0000) | Acc: (86.00%) (1214/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.4133) |  Loss2: (0.0000) | Acc: (85.00%) (2294/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.4312) |  Loss2: (0.0000) | Acc: (84.00%) (3359/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.4561) |  Loss2: (0.0000) | Acc: (83.00%) (4397/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.4671) |  Loss2: (0.0000) | Acc: (83.00%) (5444/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.4676) |  Loss2: (0.0000) | Acc: (83.00%) (6512/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.4720) |  Loss2: (0.0000) | Acc: (83.00%) (7574/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.4750) |  Loss2: (0.0000) | Acc: (83.00%) (8635/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (82.00%) (9659/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (83.00%) (10743/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (11807/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.4811) |  Loss2: (0.0000) | Acc: (83.00%) (12869/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.4803) |  Loss2: (0.0000) | Acc: (83.00%) (13935/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.4803) |  Loss2: (0.0000) | Acc: (83.00%) (14995/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.4783) |  Loss2: (0.0000) | Acc: (83.00%) (16075/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.4732) |  Loss2: (0.0000) | Acc: (83.00%) (17194/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.4722) |  Loss2: (0.0000) | Acc: (83.00%) (18259/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.4701) |  Loss2: (0.0000) | Acc: (83.00%) (19345/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.4692) |  Loss2: (0.0000) | Acc: (83.00%) (20415/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.4683) |  Loss2: (0.0000) | Acc: (83.00%) (21480/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.4665) |  Loss2: (0.0000) | Acc: (83.00%) (22573/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.4663) |  Loss2: (0.0000) | Acc: (83.00%) (23648/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.4664) |  Loss2: (0.0000) | Acc: (83.00%) (24720/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.4656) |  Loss2: (0.0000) | Acc: (83.00%) (25803/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.4649) |  Loss2: (0.0000) | Acc: (83.00%) (26889/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (83.00%) (27970/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.4628) |  Loss2: (0.0000) | Acc: (83.00%) (29068/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.4625) |  Loss2: (0.0000) | Acc: (83.00%) (30146/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.4619) |  Loss2: (0.0000) | Acc: (83.00%) (31216/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.4609) |  Loss2: (0.0000) | Acc: (83.00%) (32302/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.4598) |  Loss2: (0.0000) | Acc: (83.00%) (33392/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.4607) |  Loss2: (0.0000) | Acc: (83.00%) (34463/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.4595) |  Loss2: (0.0000) | Acc: (83.00%) (35557/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.4592) |  Loss2: (0.0000) | Acc: (83.00%) (36638/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (84.00%) (37744/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.4565) |  Loss2: (0.0000) | Acc: (84.00%) (38855/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.4559) |  Loss2: (0.0000) | Acc: (84.00%) (39934/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.4542) |  Loss2: (0.0000) | Acc: (84.00%) (41040/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.4548) |  Loss2: (0.0000) | Acc: (84.00%) (42075/50000)
# TEST : Loss: (0.5293) | Acc: (82.00%) (8229/10000)
percent tensor([0.4865, 0.4850, 0.4833, 0.4801, 0.4829, 0.4794, 0.4847, 0.4840, 0.4879,
        0.4858, 0.4877, 0.4853, 0.4881, 0.4868, 0.4813, 0.4841],
       device='cuda:0') torch.Size([16])
percent tensor([0.4747, 0.4742, 0.4684, 0.4730, 0.4694, 0.4781, 0.4716, 0.4721, 0.4703,
        0.4706, 0.4729, 0.4668, 0.4738, 0.4746, 0.4735, 0.4764],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.4925, 0.4979, 0.5254, 0.5085, 0.5346, 0.4945, 0.5081, 0.5190,
        0.4872, 0.4981, 0.4800, 0.4883, 0.5382, 0.4995, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5817, 0.6067, 0.5653, 0.5706, 0.5708, 0.5709, 0.5961, 0.5801, 0.5855,
        0.6053, 0.6035, 0.5838, 0.5932, 0.6045, 0.5928, 0.5912],
       device='cuda:0') torch.Size([16])
percent tensor([0.5639, 0.5361, 0.6136, 0.6309, 0.6158, 0.6372, 0.5802, 0.5776, 0.5721,
        0.5347, 0.5601, 0.5827, 0.5187, 0.5669, 0.5761, 0.5543],
       device='cuda:0') torch.Size([16])
percent tensor([0.5333, 0.5175, 0.5730, 0.5733, 0.5828, 0.5941, 0.5261, 0.5316, 0.5550,
        0.5061, 0.5198, 0.5273, 0.5223, 0.5504, 0.5077, 0.5336],
       device='cuda:0') torch.Size([16])
percent tensor([0.6361, 0.5718, 0.5820, 0.5907, 0.5769, 0.7176, 0.5387, 0.4762, 0.6212,
        0.5646, 0.6049, 0.5621, 0.6283, 0.6292, 0.5222, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9973, 0.9983, 0.9980, 0.9983, 0.9989, 0.9989, 0.9990, 0.9977,
        0.9991, 0.9986, 0.9985, 0.9976, 0.9985, 0.9987, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 53 | Batch_idx: 0 |  Loss: (0.4919) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.4430) |  Loss2: (0.0000) | Acc: (84.00%) (1194/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.4190) |  Loss2: (0.0000) | Acc: (85.00%) (2293/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.4235) |  Loss2: (0.0000) | Acc: (85.00%) (3383/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.4225) |  Loss2: (0.0000) | Acc: (85.00%) (4490/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.4216) |  Loss2: (0.0000) | Acc: (85.00%) (5576/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.4217) |  Loss2: (0.0000) | Acc: (85.00%) (6665/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (7772/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.4200) |  Loss2: (0.0000) | Acc: (85.00%) (8858/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.4177) |  Loss2: (0.0000) | Acc: (85.00%) (9963/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.4198) |  Loss2: (0.0000) | Acc: (85.00%) (11061/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (12158/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.4210) |  Loss2: (0.0000) | Acc: (85.00%) (13250/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.4206) |  Loss2: (0.0000) | Acc: (85.00%) (14357/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.4203) |  Loss2: (0.0000) | Acc: (85.00%) (15466/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (16556/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (17650/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.4186) |  Loss2: (0.0000) | Acc: (85.00%) (18763/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.4172) |  Loss2: (0.0000) | Acc: (85.00%) (19879/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (20968/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (85.00%) (22051/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.4200) |  Loss2: (0.0000) | Acc: (85.00%) (23158/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.4191) |  Loss2: (0.0000) | Acc: (85.00%) (24259/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.4192) |  Loss2: (0.0000) | Acc: (85.00%) (25356/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.4197) |  Loss2: (0.0000) | Acc: (85.00%) (26454/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (27545/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.4210) |  Loss2: (0.0000) | Acc: (85.00%) (28643/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.4206) |  Loss2: (0.0000) | Acc: (85.00%) (29757/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (30853/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (85.00%) (31941/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (33017/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.4229) |  Loss2: (0.0000) | Acc: (85.00%) (34096/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (35206/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.4232) |  Loss2: (0.0000) | Acc: (85.00%) (36285/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (37381/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.4239) |  Loss2: (0.0000) | Acc: (85.00%) (38459/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.4236) |  Loss2: (0.0000) | Acc: (85.00%) (39572/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.4236) |  Loss2: (0.0000) | Acc: (85.00%) (40662/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (41744/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (42807/50000)
# TEST : Loss: (0.5083) | Acc: (82.00%) (8273/10000)
percent tensor([0.4893, 0.4889, 0.4860, 0.4833, 0.4859, 0.4827, 0.4883, 0.4873, 0.4912,
        0.4890, 0.4911, 0.4881, 0.4911, 0.4909, 0.4850, 0.4872],
       device='cuda:0') torch.Size([16])
percent tensor([0.4721, 0.4712, 0.4664, 0.4705, 0.4673, 0.4751, 0.4691, 0.4700, 0.4678,
        0.4678, 0.4700, 0.4646, 0.4713, 0.4716, 0.4705, 0.4736],
       device='cuda:0') torch.Size([16])
percent tensor([0.5126, 0.4932, 0.5007, 0.5282, 0.5100, 0.5379, 0.4956, 0.5111, 0.5197,
        0.4868, 0.4976, 0.4812, 0.4900, 0.5390, 0.5015, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5847, 0.6113, 0.5665, 0.5712, 0.5718, 0.5715, 0.5997, 0.5828, 0.5885,
        0.6094, 0.6073, 0.5874, 0.5980, 0.6075, 0.5967, 0.5941],
       device='cuda:0') torch.Size([16])
percent tensor([0.5578, 0.5354, 0.6044, 0.6235, 0.6069, 0.6400, 0.5721, 0.5597, 0.5738,
        0.5360, 0.5641, 0.5741, 0.5186, 0.5761, 0.5642, 0.5546],
       device='cuda:0') torch.Size([16])
percent tensor([0.5438, 0.5325, 0.5838, 0.5868, 0.5932, 0.6040, 0.5420, 0.5424, 0.5673,
        0.5193, 0.5346, 0.5403, 0.5310, 0.5670, 0.5235, 0.5424],
       device='cuda:0') torch.Size([16])
percent tensor([0.6561, 0.5956, 0.5821, 0.5925, 0.5789, 0.7310, 0.5525, 0.4726, 0.6427,
        0.5930, 0.6323, 0.5711, 0.6517, 0.6539, 0.5390, 0.6396],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9975, 0.9983, 0.9980, 0.9984, 0.9991, 0.9990, 0.9991, 0.9979,
        0.9991, 0.9988, 0.9986, 0.9979, 0.9989, 0.9988, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 54 | Batch_idx: 0 |  Loss: (0.4315) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (85.00%) (1208/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.4275) |  Loss2: (0.0000) | Acc: (85.00%) (2300/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.4265) |  Loss2: (0.0000) | Acc: (85.00%) (3394/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (4485/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (5580/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.4221) |  Loss2: (0.0000) | Acc: (85.00%) (6679/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.4251) |  Loss2: (0.0000) | Acc: (85.00%) (7762/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.4263) |  Loss2: (0.0000) | Acc: (85.00%) (8841/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.4228) |  Loss2: (0.0000) | Acc: (85.00%) (9942/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (11034/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.4220) |  Loss2: (0.0000) | Acc: (85.00%) (12118/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (13212/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.4206) |  Loss2: (0.0000) | Acc: (85.00%) (14301/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.4188) |  Loss2: (0.0000) | Acc: (85.00%) (15401/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.4179) |  Loss2: (0.0000) | Acc: (85.00%) (16499/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.4144) |  Loss2: (0.0000) | Acc: (85.00%) (17621/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.4150) |  Loss2: (0.0000) | Acc: (85.00%) (18710/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.4174) |  Loss2: (0.0000) | Acc: (85.00%) (19780/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.4184) |  Loss2: (0.0000) | Acc: (85.00%) (20852/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.4188) |  Loss2: (0.0000) | Acc: (85.00%) (21945/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.4167) |  Loss2: (0.0000) | Acc: (85.00%) (23049/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.4144) |  Loss2: (0.0000) | Acc: (85.00%) (24178/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (25282/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.4131) |  Loss2: (0.0000) | Acc: (85.00%) (26382/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.4136) |  Loss2: (0.0000) | Acc: (85.00%) (27488/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (28590/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.4124) |  Loss2: (0.0000) | Acc: (85.00%) (29695/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.4119) |  Loss2: (0.0000) | Acc: (85.00%) (30810/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.4107) |  Loss2: (0.0000) | Acc: (85.00%) (31918/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.4111) |  Loss2: (0.0000) | Acc: (85.00%) (33009/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.4116) |  Loss2: (0.0000) | Acc: (85.00%) (34109/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.4115) |  Loss2: (0.0000) | Acc: (85.00%) (35203/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.4116) |  Loss2: (0.0000) | Acc: (85.00%) (36294/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (37394/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.4120) |  Loss2: (0.0000) | Acc: (85.00%) (38494/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.4120) |  Loss2: (0.0000) | Acc: (85.00%) (39582/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (85.00%) (40670/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.4118) |  Loss2: (0.0000) | Acc: (85.00%) (41784/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (42843/50000)
# TEST : Loss: (0.4969) | Acc: (83.00%) (8311/10000)
percent tensor([0.4903, 0.4904, 0.4867, 0.4845, 0.4868, 0.4839, 0.4895, 0.4884, 0.4923,
        0.4902, 0.4924, 0.4889, 0.4922, 0.4926, 0.4865, 0.4884],
       device='cuda:0') torch.Size([16])
percent tensor([0.4708, 0.4698, 0.4651, 0.4694, 0.4661, 0.4735, 0.4678, 0.4690, 0.4667,
        0.4664, 0.4687, 0.4634, 0.4703, 0.4705, 0.4690, 0.4723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5133, 0.4905, 0.4994, 0.5292, 0.5074, 0.5399, 0.4926, 0.5106, 0.5190,
        0.4841, 0.4958, 0.4776, 0.4889, 0.5404, 0.5005, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.5863, 0.6146, 0.5671, 0.5712, 0.5725, 0.5714, 0.6023, 0.5843, 0.5901,
        0.6121, 0.6101, 0.5898, 0.6011, 0.6092, 0.5994, 0.5956],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5357, 0.6129, 0.6322, 0.6128, 0.6490, 0.5730, 0.5611, 0.5816,
        0.5394, 0.5690, 0.5794, 0.5221, 0.5837, 0.5615, 0.5586],
       device='cuda:0') torch.Size([16])
percent tensor([0.5392, 0.5293, 0.5818, 0.5861, 0.5918, 0.6019, 0.5399, 0.5381, 0.5666,
        0.5151, 0.5337, 0.5387, 0.5262, 0.5667, 0.5212, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.6704, 0.6123, 0.5855, 0.5957, 0.5833, 0.7424, 0.5613, 0.4715, 0.6607,
        0.6117, 0.6543, 0.5812, 0.6723, 0.6724, 0.5523, 0.6468],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9977, 0.9985, 0.9982, 0.9987, 0.9991, 0.9991, 0.9992, 0.9981,
        0.9993, 0.9990, 0.9988, 0.9980, 0.9991, 0.9989, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 55 | Batch_idx: 0 |  Loss: (0.5072) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.4404) |  Loss2: (0.0000) | Acc: (84.00%) (1193/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.4346) |  Loss2: (0.0000) | Acc: (84.00%) (2266/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (84.00%) (3370/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (4478/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (5570/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.4131) |  Loss2: (0.0000) | Acc: (85.00%) (6649/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.4189) |  Loss2: (0.0000) | Acc: (85.00%) (7731/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.4144) |  Loss2: (0.0000) | Acc: (85.00%) (8854/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.4144) |  Loss2: (0.0000) | Acc: (85.00%) (9959/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (11075/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (12173/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.4092) |  Loss2: (0.0000) | Acc: (85.00%) (13280/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.4112) |  Loss2: (0.0000) | Acc: (85.00%) (14365/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.4111) |  Loss2: (0.0000) | Acc: (85.00%) (15463/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.4098) |  Loss2: (0.0000) | Acc: (85.00%) (16575/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (85.00%) (17686/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (85.00%) (18787/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.4100) |  Loss2: (0.0000) | Acc: (85.00%) (19866/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (20985/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (22080/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (23198/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.4066) |  Loss2: (0.0000) | Acc: (85.00%) (24301/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.4060) |  Loss2: (0.0000) | Acc: (85.00%) (25399/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (85.00%) (26494/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.4052) |  Loss2: (0.0000) | Acc: (85.00%) (27601/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.4047) |  Loss2: (0.0000) | Acc: (85.00%) (28705/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.4041) |  Loss2: (0.0000) | Acc: (85.00%) (29810/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.4042) |  Loss2: (0.0000) | Acc: (85.00%) (30911/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (85.00%) (32008/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (33105/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.4055) |  Loss2: (0.0000) | Acc: (85.00%) (34228/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (86.00%) (35344/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (86.00%) (36458/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.4035) |  Loss2: (0.0000) | Acc: (86.00%) (37578/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.4034) |  Loss2: (0.0000) | Acc: (86.00%) (38690/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.4043) |  Loss2: (0.0000) | Acc: (86.00%) (39778/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.4042) |  Loss2: (0.0000) | Acc: (86.00%) (40881/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.4040) |  Loss2: (0.0000) | Acc: (86.00%) (41989/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (86.00%) (43050/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_055.pth.tar'
# TEST : Loss: (0.4909) | Acc: (83.00%) (8326/10000)
percent tensor([0.4915, 0.4919, 0.4877, 0.4859, 0.4879, 0.4852, 0.4908, 0.4896, 0.4936,
        0.4914, 0.4937, 0.4899, 0.4934, 0.4941, 0.4879, 0.4897],
       device='cuda:0') torch.Size([16])
percent tensor([0.4700, 0.4688, 0.4645, 0.4687, 0.4654, 0.4723, 0.4670, 0.4685, 0.4661,
        0.4655, 0.4679, 0.4627, 0.4697, 0.4696, 0.4680, 0.4714],
       device='cuda:0') torch.Size([16])
percent tensor([0.5161, 0.4900, 0.5000, 0.5321, 0.5075, 0.5447, 0.4919, 0.5121, 0.5202,
        0.4825, 0.4960, 0.4756, 0.4894, 0.5435, 0.5015, 0.5168],
       device='cuda:0') torch.Size([16])
percent tensor([0.5847, 0.6145, 0.5644, 0.5683, 0.5700, 0.5683, 0.6011, 0.5824, 0.5887,
        0.6115, 0.6098, 0.5885, 0.6011, 0.6079, 0.5981, 0.5941],
       device='cuda:0') torch.Size([16])
percent tensor([0.5604, 0.5370, 0.6153, 0.6348, 0.6151, 0.6532, 0.5739, 0.5602, 0.5865,
        0.5417, 0.5731, 0.5803, 0.5244, 0.5886, 0.5589, 0.5607],
       device='cuda:0') torch.Size([16])
percent tensor([0.5441, 0.5358, 0.5895, 0.5949, 0.5996, 0.6066, 0.5492, 0.5458, 0.5738,
        0.5213, 0.5414, 0.5476, 0.5292, 0.5748, 0.5297, 0.5384],
       device='cuda:0') torch.Size([16])
percent tensor([0.6728, 0.6163, 0.5883, 0.5981, 0.5871, 0.7447, 0.5637, 0.4689, 0.6670,
        0.6163, 0.6611, 0.5847, 0.6776, 0.6774, 0.5528, 0.6455],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9977, 0.9987, 0.9984, 0.9987, 0.9992, 0.9992, 0.9993, 0.9982,
        0.9993, 0.9990, 0.9989, 0.9981, 0.9991, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 56 | Batch_idx: 0 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.3832) |  Loss2: (0.0000) | Acc: (87.00%) (1225/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.3847) |  Loss2: (0.0000) | Acc: (86.00%) (2337/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.3926) |  Loss2: (0.0000) | Acc: (86.00%) (3449/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.3896) |  Loss2: (0.0000) | Acc: (86.00%) (4555/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.3930) |  Loss2: (0.0000) | Acc: (86.00%) (5661/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.3920) |  Loss2: (0.0000) | Acc: (86.00%) (6752/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (86.00%) (7824/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.3966) |  Loss2: (0.0000) | Acc: (86.00%) (8932/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.4003) |  Loss2: (0.0000) | Acc: (85.00%) (10016/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.4017) |  Loss2: (0.0000) | Acc: (85.00%) (11110/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.4041) |  Loss2: (0.0000) | Acc: (85.00%) (12191/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.4052) |  Loss2: (0.0000) | Acc: (85.00%) (13270/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (85.00%) (14380/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.4021) |  Loss2: (0.0000) | Acc: (85.00%) (15494/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (85.00%) (16587/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.4055) |  Loss2: (0.0000) | Acc: (85.00%) (17667/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.4041) |  Loss2: (0.0000) | Acc: (85.00%) (18781/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.4021) |  Loss2: (0.0000) | Acc: (85.00%) (19890/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (85.00%) (20991/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.4035) |  Loss2: (0.0000) | Acc: (85.00%) (22093/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.4046) |  Loss2: (0.0000) | Acc: (85.00%) (23188/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.4037) |  Loss2: (0.0000) | Acc: (85.00%) (24300/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.4042) |  Loss2: (0.0000) | Acc: (85.00%) (25402/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.4039) |  Loss2: (0.0000) | Acc: (85.00%) (26503/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (85.00%) (27580/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.4070) |  Loss2: (0.0000) | Acc: (85.00%) (28670/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (85.00%) (29772/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (30854/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.4069) |  Loss2: (0.0000) | Acc: (85.00%) (31961/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.4069) |  Loss2: (0.0000) | Acc: (85.00%) (33056/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.4062) |  Loss2: (0.0000) | Acc: (85.00%) (34162/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (85.00%) (35248/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (85.00%) (36363/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (37431/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (38534/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (39638/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (40727/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (41837/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.4080) |  Loss2: (0.0000) | Acc: (85.00%) (42902/50000)
# TEST : Loss: (0.5061) | Acc: (83.00%) (8303/10000)
percent tensor([0.4908, 0.4925, 0.4851, 0.4851, 0.4863, 0.4848, 0.4904, 0.4886, 0.4931,
        0.4912, 0.4937, 0.4877, 0.4930, 0.4959, 0.4879, 0.4898],
       device='cuda:0') torch.Size([16])
percent tensor([0.4697, 0.4692, 0.4648, 0.4699, 0.4661, 0.4731, 0.4675, 0.4690, 0.4659,
        0.4663, 0.4681, 0.4624, 0.4690, 0.4697, 0.4683, 0.4722],
       device='cuda:0') torch.Size([16])
percent tensor([0.5105, 0.4893, 0.4884, 0.5330, 0.4989, 0.5411, 0.4889, 0.5137, 0.5184,
        0.4813, 0.4975, 0.4615, 0.4834, 0.5478, 0.4983, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.6151, 0.5695, 0.5677, 0.5730, 0.5698, 0.6035, 0.5827, 0.5935,
        0.6150, 0.6117, 0.5932, 0.6046, 0.6096, 0.5989, 0.5954],
       device='cuda:0') torch.Size([16])
percent tensor([0.5524, 0.5233, 0.6139, 0.6329, 0.6307, 0.6590, 0.5701, 0.5716, 0.5848,
        0.5273, 0.5690, 0.5685, 0.5174, 0.5760, 0.5549, 0.5623],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5366, 0.5844, 0.5882, 0.6027, 0.6021, 0.5570, 0.5526, 0.5725,
        0.5149, 0.5438, 0.5345, 0.5260, 0.5668, 0.5244, 0.5419],
       device='cuda:0') torch.Size([16])
percent tensor([0.6532, 0.6180, 0.5926, 0.5947, 0.6123, 0.7353, 0.5760, 0.4823, 0.6473,
        0.6143, 0.6506, 0.5668, 0.6239, 0.6561, 0.5459, 0.6496],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9982, 0.9991, 0.9984, 0.9994, 0.9992, 0.9996, 0.9992, 0.9980,
        0.9995, 0.9991, 0.9990, 0.9974, 0.9993, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 57 | Batch_idx: 0 |  Loss: (0.5080) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.4008) |  Loss2: (0.0000) | Acc: (85.00%) (1209/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.3753) |  Loss2: (0.0000) | Acc: (87.00%) (2345/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.3960) |  Loss2: (0.0000) | Acc: (86.00%) (3427/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.3913) |  Loss2: (0.0000) | Acc: (86.00%) (4553/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.3905) |  Loss2: (0.0000) | Acc: (86.00%) (5663/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (6767/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.3922) |  Loss2: (0.0000) | Acc: (86.00%) (7871/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.3902) |  Loss2: (0.0000) | Acc: (86.00%) (8972/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (10070/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.3917) |  Loss2: (0.0000) | Acc: (86.00%) (11167/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.3966) |  Loss2: (0.0000) | Acc: (86.00%) (12241/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.3956) |  Loss2: (0.0000) | Acc: (86.00%) (13346/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (86.00%) (14450/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (86.00%) (15557/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.3963) |  Loss2: (0.0000) | Acc: (86.00%) (16642/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.3964) |  Loss2: (0.0000) | Acc: (86.00%) (17744/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.3965) |  Loss2: (0.0000) | Acc: (86.00%) (18843/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.3952) |  Loss2: (0.0000) | Acc: (86.00%) (19950/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.3948) |  Loss2: (0.0000) | Acc: (86.00%) (21054/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (22161/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.3952) |  Loss2: (0.0000) | Acc: (86.00%) (23256/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.3945) |  Loss2: (0.0000) | Acc: (86.00%) (24371/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (25485/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (26585/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (27667/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (28786/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (29892/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (30992/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (32105/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.3943) |  Loss2: (0.0000) | Acc: (86.00%) (33197/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.3945) |  Loss2: (0.0000) | Acc: (86.00%) (34304/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (35392/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.3946) |  Loss2: (0.0000) | Acc: (86.00%) (36514/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.3944) |  Loss2: (0.0000) | Acc: (86.00%) (37630/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (38740/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (39856/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (40937/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.3952) |  Loss2: (0.0000) | Acc: (86.00%) (42041/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.3953) |  Loss2: (0.0000) | Acc: (86.00%) (43121/50000)
# TEST : Loss: (0.5271) | Acc: (82.00%) (8228/10000)
percent tensor([0.4906, 0.4930, 0.4851, 0.4850, 0.4863, 0.4845, 0.4911, 0.4892, 0.4935,
        0.4915, 0.4938, 0.4880, 0.4928, 0.4972, 0.4880, 0.4898],
       device='cuda:0') torch.Size([16])
percent tensor([0.4694, 0.4682, 0.4644, 0.4690, 0.4657, 0.4726, 0.4666, 0.4685, 0.4657,
        0.4653, 0.4675, 0.4612, 0.4686, 0.4681, 0.4673, 0.4716],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.4927, 0.4960, 0.5382, 0.5029, 0.5434, 0.4909, 0.5147, 0.5197,
        0.4872, 0.4982, 0.4664, 0.4887, 0.5479, 0.4996, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5880, 0.6147, 0.5679, 0.5700, 0.5699, 0.5691, 0.6019, 0.5858, 0.5894,
        0.6137, 0.6135, 0.5905, 0.6034, 0.6082, 0.5988, 0.5967],
       device='cuda:0') torch.Size([16])
percent tensor([0.5599, 0.5251, 0.6268, 0.6439, 0.6480, 0.6629, 0.5751, 0.5783, 0.5826,
        0.5436, 0.5727, 0.5841, 0.5159, 0.5714, 0.5708, 0.5660],
       device='cuda:0') torch.Size([16])
percent tensor([0.5489, 0.5372, 0.5938, 0.5938, 0.6114, 0.6099, 0.5481, 0.5548, 0.5744,
        0.5327, 0.5472, 0.5550, 0.5325, 0.5648, 0.5356, 0.5474],
       device='cuda:0') torch.Size([16])
percent tensor([0.6738, 0.6210, 0.5911, 0.5995, 0.6415, 0.7559, 0.5914, 0.4830, 0.6634,
        0.6425, 0.6677, 0.5776, 0.6525, 0.6676, 0.5731, 0.6785],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9979, 0.9988, 0.9979, 0.9988, 0.9994, 0.9997, 0.9992, 0.9981,
        0.9995, 0.9993, 0.9994, 0.9985, 0.9993, 0.9988, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 58 | Batch_idx: 0 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3840) |  Loss2: (0.0000) | Acc: (86.00%) (1214/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (2342/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (3457/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3739) |  Loss2: (0.0000) | Acc: (86.00%) (4565/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (87.00%) (5694/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (6825/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3685) |  Loss2: (0.0000) | Acc: (87.00%) (7947/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3716) |  Loss2: (0.0000) | Acc: (87.00%) (9059/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3727) |  Loss2: (0.0000) | Acc: (87.00%) (10174/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (11293/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (12422/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (13554/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3720) |  Loss2: (0.0000) | Acc: (87.00%) (14651/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3700) |  Loss2: (0.0000) | Acc: (87.00%) (15776/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3700) |  Loss2: (0.0000) | Acc: (87.00%) (16892/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (87.00%) (18012/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (19104/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (20225/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (21338/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3742) |  Loss2: (0.0000) | Acc: (87.00%) (22456/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3753) |  Loss2: (0.0000) | Acc: (87.00%) (23574/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3742) |  Loss2: (0.0000) | Acc: (87.00%) (24701/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3762) |  Loss2: (0.0000) | Acc: (87.00%) (25786/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3779) |  Loss2: (0.0000) | Acc: (87.00%) (26878/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (87.00%) (28000/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (87.00%) (29086/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (87.00%) (30212/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (87.00%) (31324/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3781) |  Loss2: (0.0000) | Acc: (87.00%) (32453/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (87.00%) (33542/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (87.00%) (34644/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3816) |  Loss2: (0.0000) | Acc: (86.00%) (35740/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (86.00%) (36859/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (87.00%) (37976/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (39076/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (86.00%) (40186/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3805) |  Loss2: (0.0000) | Acc: (86.00%) (41306/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (42412/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3806) |  Loss2: (0.0000) | Acc: (86.00%) (43494/50000)
# TEST : Loss: (0.5005) | Acc: (83.00%) (8343/10000)
percent tensor([0.4909, 0.4926, 0.4866, 0.4860, 0.4872, 0.4851, 0.4910, 0.4899, 0.4930,
        0.4917, 0.4933, 0.4890, 0.4930, 0.4961, 0.4882, 0.4900],
       device='cuda:0') torch.Size([16])
percent tensor([0.4692, 0.4683, 0.4652, 0.4700, 0.4656, 0.4723, 0.4665, 0.4696, 0.4656,
        0.4655, 0.4670, 0.4623, 0.4689, 0.4690, 0.4676, 0.4718],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.4880, 0.4949, 0.5340, 0.5037, 0.5414, 0.4908, 0.5124, 0.5150,
        0.4836, 0.4940, 0.4698, 0.4822, 0.5510, 0.4979, 0.5177],
       device='cuda:0') torch.Size([16])
percent tensor([0.5883, 0.6143, 0.5671, 0.5692, 0.5713, 0.5707, 0.6017, 0.5830, 0.5924,
        0.6120, 0.6149, 0.5885, 0.6033, 0.6076, 0.5972, 0.5961],
       device='cuda:0') torch.Size([16])
percent tensor([0.5469, 0.5078, 0.6246, 0.6338, 0.6399, 0.6448, 0.5711, 0.5699, 0.5689,
        0.5253, 0.5560, 0.5753, 0.4986, 0.5623, 0.5520, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.5357, 0.5219, 0.5818, 0.5831, 0.6067, 0.6020, 0.5538, 0.5423, 0.5618,
        0.5097, 0.5318, 0.5351, 0.5075, 0.5588, 0.5135, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.6303, 0.5800, 0.6081, 0.5997, 0.6193, 0.7241, 0.5661, 0.4787, 0.6293,
        0.5766, 0.6249, 0.5620, 0.5902, 0.6198, 0.5158, 0.6406],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9981, 0.9992, 0.9984, 0.9993, 0.9986, 0.9994, 0.9993, 0.9981,
        0.9989, 0.9991, 0.9991, 0.9982, 0.9991, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 59 | Batch_idx: 0 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3928) |  Loss2: (0.0000) | Acc: (86.00%) (1222/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (87.00%) (2351/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3753) |  Loss2: (0.0000) | Acc: (87.00%) (3473/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3753) |  Loss2: (0.0000) | Acc: (87.00%) (4599/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (5738/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (88.00%) (6875/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (7982/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (9115/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (10241/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (11350/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (12456/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (13578/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (87.00%) (14706/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (15816/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (87.00%) (16909/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (87.00%) (18041/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (87.00%) (19149/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (87.00%) (20271/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3691) |  Loss2: (0.0000) | Acc: (87.00%) (21363/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3684) |  Loss2: (0.0000) | Acc: (87.00%) (22489/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3697) |  Loss2: (0.0000) | Acc: (87.00%) (23595/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3702) |  Loss2: (0.0000) | Acc: (87.00%) (24710/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (25825/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (87.00%) (26941/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3700) |  Loss2: (0.0000) | Acc: (87.00%) (28066/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3695) |  Loss2: (0.0000) | Acc: (87.00%) (29195/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (87.00%) (30299/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (87.00%) (31421/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (32543/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3687) |  Loss2: (0.0000) | Acc: (87.00%) (33674/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3695) |  Loss2: (0.0000) | Acc: (87.00%) (34775/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (87.00%) (35899/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3688) |  Loss2: (0.0000) | Acc: (87.00%) (37038/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3686) |  Loss2: (0.0000) | Acc: (87.00%) (38160/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3691) |  Loss2: (0.0000) | Acc: (87.00%) (39271/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (87.00%) (40390/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (87.00%) (41495/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3684) |  Loss2: (0.0000) | Acc: (87.00%) (42608/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3691) |  Loss2: (0.0000) | Acc: (87.00%) (43670/50000)
# TEST : Loss: (0.4538) | Acc: (84.00%) (8487/10000)
percent tensor([0.4913, 0.4925, 0.4870, 0.4857, 0.4878, 0.4851, 0.4911, 0.4897, 0.4939,
        0.4917, 0.4938, 0.4895, 0.4933, 0.4958, 0.4880, 0.4900],
       device='cuda:0') torch.Size([16])
percent tensor([0.4700, 0.4685, 0.4670, 0.4708, 0.4667, 0.4731, 0.4668, 0.4706, 0.4658,
        0.4660, 0.4674, 0.4638, 0.4692, 0.4681, 0.4681, 0.4725],
       device='cuda:0') torch.Size([16])
percent tensor([0.5144, 0.4980, 0.4998, 0.5377, 0.5051, 0.5439, 0.4950, 0.5154, 0.5199,
        0.4911, 0.5000, 0.4765, 0.4876, 0.5538, 0.5041, 0.5214],
       device='cuda:0') torch.Size([16])
percent tensor([0.5877, 0.6133, 0.5713, 0.5697, 0.5747, 0.5653, 0.6030, 0.5837, 0.5941,
        0.6128, 0.6156, 0.5923, 0.6051, 0.6081, 0.5959, 0.5943],
       device='cuda:0') torch.Size([16])
percent tensor([0.5503, 0.5224, 0.6260, 0.6388, 0.6440, 0.6548, 0.5817, 0.5840, 0.5683,
        0.5328, 0.5613, 0.5740, 0.4998, 0.5713, 0.5660, 0.5668],
       device='cuda:0') torch.Size([16])
percent tensor([0.5445, 0.5405, 0.5809, 0.5842, 0.6024, 0.6087, 0.5630, 0.5452, 0.5747,
        0.5331, 0.5461, 0.5397, 0.5283, 0.5763, 0.5303, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.6590, 0.6103, 0.6205, 0.5988, 0.6269, 0.7419, 0.5890, 0.4793, 0.6661,
        0.6326, 0.6515, 0.6010, 0.6347, 0.6455, 0.5530, 0.6620],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9973, 0.9990, 0.9982, 0.9994, 0.9990, 0.9994, 0.9992, 0.9978,
        0.9991, 0.9989, 0.9985, 0.9977, 0.9988, 0.9988, 0.9992],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.3622) |  Loss2: (0.0000) | Acc: (87.00%) (1231/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (86.00%) (2319/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (3395/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.4290) |  Loss2: (0.0000) | Acc: (85.00%) (4468/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.4281) |  Loss2: (0.0000) | Acc: (85.00%) (5564/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.4358) |  Loss2: (0.0000) | Acc: (85.00%) (6641/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.4394) |  Loss2: (0.0000) | Acc: (84.00%) (7713/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.4460) |  Loss2: (0.0000) | Acc: (84.00%) (8771/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.4481) |  Loss2: (0.0000) | Acc: (84.00%) (9845/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.4468) |  Loss2: (0.0000) | Acc: (84.00%) (10921/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.4444) |  Loss2: (0.0000) | Acc: (84.00%) (12007/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.4443) |  Loss2: (0.0000) | Acc: (84.00%) (13081/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.4432) |  Loss2: (0.0000) | Acc: (84.00%) (14161/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.4444) |  Loss2: (0.0000) | Acc: (84.00%) (15238/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.4425) |  Loss2: (0.0000) | Acc: (84.00%) (16321/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.4411) |  Loss2: (0.0000) | Acc: (84.00%) (17413/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.4408) |  Loss2: (0.0000) | Acc: (84.00%) (18505/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.4406) |  Loss2: (0.0000) | Acc: (84.00%) (19597/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.4398) |  Loss2: (0.0000) | Acc: (84.00%) (20685/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.4393) |  Loss2: (0.0000) | Acc: (84.00%) (21764/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.4387) |  Loss2: (0.0000) | Acc: (84.00%) (22843/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (84.00%) (23931/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.4376) |  Loss2: (0.0000) | Acc: (84.00%) (25025/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.4383) |  Loss2: (0.0000) | Acc: (84.00%) (26108/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.4380) |  Loss2: (0.0000) | Acc: (84.00%) (27204/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.4374) |  Loss2: (0.0000) | Acc: (84.00%) (28282/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.4368) |  Loss2: (0.0000) | Acc: (84.00%) (29372/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (84.00%) (30454/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.4358) |  Loss2: (0.0000) | Acc: (84.00%) (31546/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.4348) |  Loss2: (0.0000) | Acc: (84.00%) (32641/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.4337) |  Loss2: (0.0000) | Acc: (84.00%) (33746/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.4339) |  Loss2: (0.0000) | Acc: (84.00%) (34820/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.4329) |  Loss2: (0.0000) | Acc: (84.00%) (35919/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.4332) |  Loss2: (0.0000) | Acc: (84.00%) (37013/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.4327) |  Loss2: (0.0000) | Acc: (84.00%) (38099/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.4317) |  Loss2: (0.0000) | Acc: (84.00%) (39200/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.4309) |  Loss2: (0.0000) | Acc: (84.00%) (40315/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.4290) |  Loss2: (0.0000) | Acc: (84.00%) (41444/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.4286) |  Loss2: (0.0000) | Acc: (85.00%) (42504/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_060.pth.tar'
# TEST : Loss: (0.4930) | Acc: (83.00%) (8351/10000)
percent tensor([0.5005, 0.5027, 0.4964, 0.4950, 0.4983, 0.4936, 0.5018, 0.4997, 0.5047,
        0.5021, 0.5044, 0.4997, 0.5029, 0.5055, 0.4976, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.4726, 0.4720, 0.4705, 0.4733, 0.4702, 0.4745, 0.4710, 0.4744, 0.4698,
        0.4698, 0.4711, 0.4677, 0.4720, 0.4725, 0.4710, 0.4749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5104, 0.4918, 0.4906, 0.5366, 0.5040, 0.5510, 0.4882, 0.5158, 0.5171,
        0.4815, 0.4928, 0.4604, 0.4783, 0.5613, 0.5007, 0.5210],
       device='cuda:0') torch.Size([16])
percent tensor([0.6133, 0.6355, 0.6010, 0.5946, 0.6018, 0.5910, 0.6281, 0.6108, 0.6168,
        0.6393, 0.6425, 0.6201, 0.6290, 0.6295, 0.6226, 0.6192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5434, 0.5217, 0.6265, 0.6267, 0.6386, 0.6284, 0.5744, 0.5893, 0.5619,
        0.5377, 0.5567, 0.5786, 0.5082, 0.5574, 0.5592, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.5460, 0.5852, 0.5936, 0.6138, 0.6225, 0.5663, 0.5516, 0.5881,
        0.5507, 0.5612, 0.5451, 0.5436, 0.5856, 0.5376, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.6774, 0.6439, 0.6318, 0.6149, 0.6555, 0.7643, 0.5963, 0.4957, 0.6852,
        0.6656, 0.6850, 0.6108, 0.6487, 0.6732, 0.5850, 0.6859],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9977, 0.9991, 0.9979, 0.9995, 0.9991, 0.9992, 0.9995, 0.9977,
        0.9994, 0.9990, 0.9987, 0.9977, 0.9988, 0.9990, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(174.7141, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(803.9564, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(802.0015, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.2946, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(503.5626, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2200.9956, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4292.9302, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1419.4794, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6102.9102, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12014.7627, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4005.4751, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16909.6309, device='cuda:0')
Epoch: 61 | Batch_idx: 0 |  Loss: (0.3874) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3852) |  Loss2: (0.0000) | Acc: (86.00%) (1212/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3936) |  Loss2: (0.0000) | Acc: (85.00%) (2306/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3884) |  Loss2: (0.0000) | Acc: (86.00%) (3418/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3864) |  Loss2: (0.0000) | Acc: (86.00%) (4528/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (86.00%) (5652/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3891) |  Loss2: (0.0000) | Acc: (86.00%) (6745/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3899) |  Loss2: (0.0000) | Acc: (86.00%) (7859/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3890) |  Loss2: (0.0000) | Acc: (86.00%) (8975/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3867) |  Loss2: (0.0000) | Acc: (86.00%) (10098/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3884) |  Loss2: (0.0000) | Acc: (86.00%) (11198/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3880) |  Loss2: (0.0000) | Acc: (86.00%) (12308/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3887) |  Loss2: (0.0000) | Acc: (86.00%) (13416/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3919) |  Loss2: (0.0000) | Acc: (86.00%) (14502/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3925) |  Loss2: (0.0000) | Acc: (86.00%) (15605/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3926) |  Loss2: (0.0000) | Acc: (86.00%) (16710/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3949) |  Loss2: (0.0000) | Acc: (86.00%) (17789/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3945) |  Loss2: (0.0000) | Acc: (86.00%) (18892/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3932) |  Loss2: (0.0000) | Acc: (86.00%) (19995/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3924) |  Loss2: (0.0000) | Acc: (86.00%) (21107/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (22208/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3934) |  Loss2: (0.0000) | Acc: (86.00%) (23326/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3931) |  Loss2: (0.0000) | Acc: (86.00%) (24425/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (25571/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (26680/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (27818/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (86.00%) (28936/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (86.00%) (30040/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3890) |  Loss2: (0.0000) | Acc: (86.00%) (31134/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (86.00%) (32257/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3878) |  Loss2: (0.0000) | Acc: (86.00%) (33368/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3878) |  Loss2: (0.0000) | Acc: (86.00%) (34480/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3876) |  Loss2: (0.0000) | Acc: (86.00%) (35597/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3869) |  Loss2: (0.0000) | Acc: (86.00%) (36715/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3877) |  Loss2: (0.0000) | Acc: (86.00%) (37810/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3885) |  Loss2: (0.0000) | Acc: (86.00%) (38908/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (40032/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3880) |  Loss2: (0.0000) | Acc: (86.00%) (41128/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3877) |  Loss2: (0.0000) | Acc: (86.00%) (42237/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3865) |  Loss2: (0.0000) | Acc: (86.00%) (43318/50000)
# TEST : Loss: (0.4671) | Acc: (84.00%) (8439/10000)
percent tensor([0.5030, 0.5053, 0.4991, 0.4971, 0.5014, 0.4949, 0.5048, 0.5025, 0.5082,
        0.5053, 0.5075, 0.5029, 0.5057, 0.5081, 0.4997, 0.5013],
       device='cuda:0') torch.Size([16])
percent tensor([0.4771, 0.4766, 0.4754, 0.4775, 0.4752, 0.4780, 0.4760, 0.4792, 0.4751,
        0.4748, 0.4761, 0.4730, 0.4768, 0.4771, 0.4755, 0.4789],
       device='cuda:0') torch.Size([16])
percent tensor([0.5158, 0.4912, 0.4917, 0.5415, 0.5084, 0.5606, 0.4887, 0.5207, 0.5213,
        0.4798, 0.4933, 0.4574, 0.4779, 0.5677, 0.5027, 0.5269],
       device='cuda:0') torch.Size([16])
percent tensor([0.6150, 0.6356, 0.6010, 0.5947, 0.6023, 0.5930, 0.6292, 0.6112, 0.6187,
        0.6402, 0.6439, 0.6205, 0.6297, 0.6308, 0.6233, 0.6207],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5327, 0.6316, 0.6298, 0.6425, 0.6287, 0.5800, 0.5963, 0.5714,
        0.5467, 0.5652, 0.5875, 0.5209, 0.5627, 0.5660, 0.5522],
       device='cuda:0') torch.Size([16])
percent tensor([0.5626, 0.5512, 0.5859, 0.5930, 0.6149, 0.6292, 0.5698, 0.5469, 0.5939,
        0.5585, 0.5684, 0.5437, 0.5512, 0.5927, 0.5366, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.6690, 0.6395, 0.6289, 0.6143, 0.6559, 0.7671, 0.5929, 0.4889, 0.6864,
        0.6640, 0.6826, 0.6066, 0.6454, 0.6772, 0.5748, 0.6829],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9977, 0.9991, 0.9980, 0.9994, 0.9992, 0.9992, 0.9994, 0.9978,
        0.9994, 0.9990, 0.9988, 0.9977, 0.9989, 0.9990, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 62 | Batch_idx: 0 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3911) |  Loss2: (0.0000) | Acc: (86.00%) (2333/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (3442/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3843) |  Loss2: (0.0000) | Acc: (86.00%) (4558/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (5663/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3760) |  Loss2: (0.0000) | Acc: (86.00%) (6785/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3823) |  Loss2: (0.0000) | Acc: (86.00%) (7877/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (86.00%) (9006/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3773) |  Loss2: (0.0000) | Acc: (86.00%) (10122/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3775) |  Loss2: (0.0000) | Acc: (87.00%) (11249/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3758) |  Loss2: (0.0000) | Acc: (87.00%) (12382/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (87.00%) (13495/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3764) |  Loss2: (0.0000) | Acc: (87.00%) (14612/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3773) |  Loss2: (0.0000) | Acc: (87.00%) (15712/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3754) |  Loss2: (0.0000) | Acc: (87.00%) (16836/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3762) |  Loss2: (0.0000) | Acc: (87.00%) (17947/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3776) |  Loss2: (0.0000) | Acc: (87.00%) (19048/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3775) |  Loss2: (0.0000) | Acc: (86.00%) (20147/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3765) |  Loss2: (0.0000) | Acc: (87.00%) (21275/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3757) |  Loss2: (0.0000) | Acc: (87.00%) (22395/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3766) |  Loss2: (0.0000) | Acc: (86.00%) (23491/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3768) |  Loss2: (0.0000) | Acc: (86.00%) (24602/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3774) |  Loss2: (0.0000) | Acc: (86.00%) (25705/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3761) |  Loss2: (0.0000) | Acc: (86.00%) (26828/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3745) |  Loss2: (0.0000) | Acc: (87.00%) (27960/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3743) |  Loss2: (0.0000) | Acc: (86.00%) (29062/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3752) |  Loss2: (0.0000) | Acc: (86.00%) (30155/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3754) |  Loss2: (0.0000) | Acc: (86.00%) (31279/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3742) |  Loss2: (0.0000) | Acc: (87.00%) (32410/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3733) |  Loss2: (0.0000) | Acc: (87.00%) (33553/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (34688/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (87.00%) (35799/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (36920/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (38034/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (39154/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (40272/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3727) |  Loss2: (0.0000) | Acc: (87.00%) (41392/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3727) |  Loss2: (0.0000) | Acc: (87.00%) (42502/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3739) |  Loss2: (0.0000) | Acc: (87.00%) (43555/50000)
# TEST : Loss: (0.4572) | Acc: (84.00%) (8474/10000)
percent tensor([0.5024, 0.5046, 0.4988, 0.4964, 0.5010, 0.4935, 0.5043, 0.5021, 0.5081,
        0.5050, 0.5072, 0.5028, 0.5054, 0.5074, 0.4988, 0.5007],
       device='cuda:0') torch.Size([16])
percent tensor([0.4794, 0.4788, 0.4776, 0.4793, 0.4775, 0.4795, 0.4785, 0.4814, 0.4777,
        0.4773, 0.4787, 0.4755, 0.4793, 0.4795, 0.4776, 0.4807],
       device='cuda:0') torch.Size([16])
percent tensor([0.5153, 0.4860, 0.4871, 0.5402, 0.5050, 0.5635, 0.4836, 0.5185, 0.5195,
        0.4738, 0.4896, 0.4489, 0.4734, 0.5688, 0.4989, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.6123, 0.6313, 0.5973, 0.5916, 0.5986, 0.5906, 0.6258, 0.6076, 0.6166,
        0.6363, 0.6409, 0.6166, 0.6266, 0.6275, 0.6192, 0.6178],
       device='cuda:0') torch.Size([16])
percent tensor([0.5522, 0.5343, 0.6375, 0.6339, 0.6461, 0.6310, 0.5793, 0.6008, 0.5741,
        0.5478, 0.5652, 0.5918, 0.5229, 0.5639, 0.5670, 0.5504],
       device='cuda:0') torch.Size([16])
percent tensor([0.5702, 0.5600, 0.5906, 0.5954, 0.6212, 0.6379, 0.5767, 0.5493, 0.6010,
        0.5683, 0.5775, 0.5457, 0.5612, 0.6007, 0.5389, 0.5857],
       device='cuda:0') torch.Size([16])
percent tensor([0.6792, 0.6546, 0.6416, 0.6231, 0.6710, 0.7771, 0.6050, 0.4939, 0.6995,
        0.6789, 0.6974, 0.6158, 0.6583, 0.6920, 0.5825, 0.6946],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9977, 0.9992, 0.9982, 0.9995, 0.9992, 0.9992, 0.9994, 0.9979,
        0.9994, 0.9991, 0.9988, 0.9977, 0.9989, 0.9990, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 63 | Batch_idx: 0 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (86.00%) (1218/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3743) |  Loss2: (0.0000) | Acc: (87.00%) (2350/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3737) |  Loss2: (0.0000) | Acc: (87.00%) (3473/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (4586/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (5713/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (6843/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (87.00%) (7963/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.3618) |  Loss2: (0.0000) | Acc: (87.00%) (9082/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.3625) |  Loss2: (0.0000) | Acc: (87.00%) (10198/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.3618) |  Loss2: (0.0000) | Acc: (87.00%) (11312/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.3621) |  Loss2: (0.0000) | Acc: (87.00%) (12420/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (13543/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.3620) |  Loss2: (0.0000) | Acc: (87.00%) (14654/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (15771/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.3633) |  Loss2: (0.0000) | Acc: (87.00%) (16885/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (17999/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (87.00%) (19130/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.3621) |  Loss2: (0.0000) | Acc: (87.00%) (20255/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (87.00%) (21375/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.3625) |  Loss2: (0.0000) | Acc: (87.00%) (22501/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.3637) |  Loss2: (0.0000) | Acc: (87.00%) (23619/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (24719/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (25859/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (87.00%) (26993/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (28106/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (87.00%) (29227/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.3625) |  Loss2: (0.0000) | Acc: (87.00%) (30365/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.3633) |  Loss2: (0.0000) | Acc: (87.00%) (31481/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (32588/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (33707/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (34833/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (87.00%) (35950/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (37052/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (38173/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3640) |  Loss2: (0.0000) | Acc: (87.00%) (39304/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3621) |  Loss2: (0.0000) | Acc: (87.00%) (40441/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3613) |  Loss2: (0.0000) | Acc: (87.00%) (41577/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3618) |  Loss2: (0.0000) | Acc: (87.00%) (42685/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3618) |  Loss2: (0.0000) | Acc: (87.00%) (43758/50000)
# TEST : Loss: (0.4497) | Acc: (85.00%) (8500/10000)
percent tensor([0.5005, 0.5024, 0.4968, 0.4942, 0.4989, 0.4910, 0.5022, 0.5002, 0.5063,
        0.5033, 0.5054, 0.5010, 0.5037, 0.5053, 0.4964, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.4811, 0.4805, 0.4793, 0.4807, 0.4792, 0.4806, 0.4804, 0.4831, 0.4798,
        0.4792, 0.4808, 0.4774, 0.4811, 0.4811, 0.4792, 0.4821],
       device='cuda:0') torch.Size([16])
percent tensor([0.5157, 0.4849, 0.4841, 0.5386, 0.5041, 0.5655, 0.4828, 0.5183, 0.5191,
        0.4713, 0.4880, 0.4454, 0.4718, 0.5691, 0.4989, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.6088, 0.6268, 0.5931, 0.5876, 0.5946, 0.5870, 0.6217, 0.6034, 0.6137,
        0.6319, 0.6375, 0.6119, 0.6229, 0.6237, 0.6146, 0.6141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5520, 0.5352, 0.6390, 0.6332, 0.6449, 0.6292, 0.5770, 0.6014, 0.5748,
        0.5472, 0.5630, 0.5949, 0.5252, 0.5610, 0.5674, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.5705, 0.5613, 0.5895, 0.5930, 0.6209, 0.6412, 0.5766, 0.5446, 0.6016,
        0.5698, 0.5794, 0.5422, 0.5629, 0.6023, 0.5348, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.6740, 0.6515, 0.6331, 0.6156, 0.6628, 0.7774, 0.6008, 0.4877, 0.6979,
        0.6746, 0.6939, 0.6087, 0.6560, 0.6892, 0.5747, 0.6911],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9979, 0.9992, 0.9983, 0.9994, 0.9994, 0.9993, 0.9995, 0.9981,
        0.9995, 0.9992, 0.9988, 0.9980, 0.9990, 0.9991, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 64 | Batch_idx: 0 |  Loss: (0.3680) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.4055) |  Loss2: (0.0000) | Acc: (85.00%) (1203/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (86.00%) (2336/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (3446/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3708) |  Loss2: (0.0000) | Acc: (87.00%) (4574/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3685) |  Loss2: (0.0000) | Acc: (87.00%) (5690/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3692) |  Loss2: (0.0000) | Acc: (87.00%) (6803/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (87.00%) (7934/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (87.00%) (9047/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3678) |  Loss2: (0.0000) | Acc: (87.00%) (10162/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (11299/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (12408/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (13532/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (14651/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (15766/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3670) |  Loss2: (0.0000) | Acc: (87.00%) (16882/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3675) |  Loss2: (0.0000) | Acc: (87.00%) (18004/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (87.00%) (19121/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3660) |  Loss2: (0.0000) | Acc: (87.00%) (20255/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3668) |  Loss2: (0.0000) | Acc: (87.00%) (21361/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (22487/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (23616/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (24736/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (25849/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (26971/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (28105/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3628) |  Loss2: (0.0000) | Acc: (87.00%) (29224/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (87.00%) (30346/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (31452/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (32558/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (33679/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3667) |  Loss2: (0.0000) | Acc: (87.00%) (34773/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (35881/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3672) |  Loss2: (0.0000) | Acc: (87.00%) (37009/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3677) |  Loss2: (0.0000) | Acc: (87.00%) (38111/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3692) |  Loss2: (0.0000) | Acc: (87.00%) (39196/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (40308/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (41427/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (42537/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (43613/50000)
# TEST : Loss: (0.4861) | Acc: (84.00%) (8407/10000)
percent tensor([0.5004, 0.5033, 0.4956, 0.4945, 0.4979, 0.4910, 0.5023, 0.5000, 0.5058,
        0.5033, 0.5052, 0.5000, 0.5036, 0.5068, 0.4966, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.4816, 0.4805, 0.4793, 0.4811, 0.4803, 0.4814, 0.4807, 0.4826, 0.4796,
        0.4796, 0.4808, 0.4773, 0.4816, 0.4801, 0.4797, 0.4825],
       device='cuda:0') torch.Size([16])
percent tensor([0.5183, 0.4782, 0.4991, 0.5466, 0.5229, 0.5633, 0.4876, 0.5225, 0.5165,
        0.4723, 0.4843, 0.4567, 0.4719, 0.5590, 0.4951, 0.5263],
       device='cuda:0') torch.Size([16])
percent tensor([0.6083, 0.6287, 0.5876, 0.5869, 0.5889, 0.5877, 0.6215, 0.6002, 0.6113,
        0.6296, 0.6330, 0.6080, 0.6215, 0.6267, 0.6143, 0.6152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5362, 0.6277, 0.6327, 0.6385, 0.6370, 0.5717, 0.5908, 0.5745,
        0.5366, 0.5732, 0.5815, 0.5219, 0.5580, 0.5714, 0.5520],
       device='cuda:0') torch.Size([16])
percent tensor([0.5682, 0.5691, 0.5897, 0.5975, 0.6242, 0.6376, 0.5871, 0.5538, 0.5900,
        0.5573, 0.5693, 0.5398, 0.5576, 0.6043, 0.5310, 0.5882],
       device='cuda:0') torch.Size([16])
percent tensor([0.6560, 0.6395, 0.6349, 0.6149, 0.6685, 0.7624, 0.6097, 0.4960, 0.6671,
        0.6406, 0.6700, 0.5975, 0.6397, 0.6830, 0.5583, 0.6831],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9970, 0.9994, 0.9986, 0.9993, 0.9988, 0.9993, 0.9994, 0.9976,
        0.9990, 0.9988, 0.9991, 0.9970, 0.9989, 0.9989, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 65 | Batch_idx: 0 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (86.00%) (1224/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (2347/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3539) |  Loss2: (0.0000) | Acc: (87.00%) (3480/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3450) |  Loss2: (0.0000) | Acc: (88.00%) (4619/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3470) |  Loss2: (0.0000) | Acc: (87.00%) (5744/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (6863/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3503) |  Loss2: (0.0000) | Acc: (87.00%) (7983/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3473) |  Loss2: (0.0000) | Acc: (87.00%) (9117/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3483) |  Loss2: (0.0000) | Acc: (87.00%) (10242/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (11356/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3535) |  Loss2: (0.0000) | Acc: (87.00%) (12462/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (87.00%) (13604/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (14742/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3502) |  Loss2: (0.0000) | Acc: (87.00%) (15871/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (16992/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (18102/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3540) |  Loss2: (0.0000) | Acc: (87.00%) (19223/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (20342/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (87.00%) (21460/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (22563/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (23685/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (24813/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (25947/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (27062/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (28170/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (29301/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (30432/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (31543/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (32676/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (33797/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (34935/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (36064/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (37161/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (38293/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3536) |  Loss2: (0.0000) | Acc: (87.00%) (39446/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (40582/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3525) |  Loss2: (0.0000) | Acc: (87.00%) (41716/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3522) |  Loss2: (0.0000) | Acc: (87.00%) (42840/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3538) |  Loss2: (0.0000) | Acc: (87.00%) (43901/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_065.pth.tar'
# TEST : Loss: (0.4989) | Acc: (83.00%) (8323/10000)
percent tensor([0.5007, 0.5030, 0.4961, 0.4946, 0.4986, 0.4911, 0.5025, 0.5002, 0.5061,
        0.5032, 0.5053, 0.5004, 0.5036, 0.5061, 0.4967, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.4816, 0.4804, 0.4790, 0.4810, 0.4799, 0.4816, 0.4804, 0.4823, 0.4796,
        0.4791, 0.4806, 0.4772, 0.4817, 0.4813, 0.4795, 0.4823],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.4723, 0.5058, 0.5463, 0.5240, 0.5625, 0.4841, 0.5243, 0.5158,
        0.4717, 0.4806, 0.4631, 0.4732, 0.5545, 0.4945, 0.5256],
       device='cuda:0') torch.Size([16])
percent tensor([0.6062, 0.6273, 0.5849, 0.5874, 0.5883, 0.5872, 0.6207, 0.5971, 0.6085,
        0.6297, 0.6325, 0.6067, 0.6179, 0.6258, 0.6129, 0.6153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5631, 0.5329, 0.6450, 0.6417, 0.6497, 0.6413, 0.5728, 0.5968, 0.5794,
        0.5471, 0.5688, 0.6028, 0.5285, 0.5475, 0.5789, 0.5504],
       device='cuda:0') torch.Size([16])
percent tensor([0.5768, 0.5568, 0.6105, 0.6087, 0.6359, 0.6403, 0.5765, 0.5656, 0.5974,
        0.5711, 0.5669, 0.5672, 0.5670, 0.5887, 0.5414, 0.5850],
       device='cuda:0') torch.Size([16])
percent tensor([0.6792, 0.6302, 0.6626, 0.6401, 0.6955, 0.7637, 0.5998, 0.5218, 0.6869,
        0.6692, 0.6736, 0.6327, 0.6567, 0.6701, 0.5670, 0.6784],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9981, 0.9988, 0.9981, 0.9991, 0.9988, 0.9996, 0.9991, 0.9983,
        0.9992, 0.9989, 0.9989, 0.9982, 0.9989, 0.9988, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 66 | Batch_idx: 0 |  Loss: (0.3267) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.3433) |  Loss2: (0.0000) | Acc: (87.00%) (1231/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3408) |  Loss2: (0.0000) | Acc: (88.00%) (2378/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3377) |  Loss2: (0.0000) | Acc: (88.00%) (3518/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3377) |  Loss2: (0.0000) | Acc: (88.00%) (4652/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3333) |  Loss2: (0.0000) | Acc: (88.00%) (5792/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3372) |  Loss2: (0.0000) | Acc: (88.00%) (6911/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (88.00%) (8049/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3363) |  Loss2: (0.0000) | Acc: (88.00%) (9193/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3364) |  Loss2: (0.0000) | Acc: (88.00%) (10334/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (11469/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (88.00%) (12585/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3402) |  Loss2: (0.0000) | Acc: (88.00%) (13694/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (14830/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3363) |  Loss2: (0.0000) | Acc: (88.00%) (15976/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3374) |  Loss2: (0.0000) | Acc: (88.00%) (17103/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (18215/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3399) |  Loss2: (0.0000) | Acc: (88.00%) (19337/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3412) |  Loss2: (0.0000) | Acc: (88.00%) (20463/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3414) |  Loss2: (0.0000) | Acc: (88.00%) (21588/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3421) |  Loss2: (0.0000) | Acc: (88.00%) (22714/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3430) |  Loss2: (0.0000) | Acc: (88.00%) (23827/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3441) |  Loss2: (0.0000) | Acc: (88.00%) (24942/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3452) |  Loss2: (0.0000) | Acc: (88.00%) (26055/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (27191/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3439) |  Loss2: (0.0000) | Acc: (88.00%) (28312/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3436) |  Loss2: (0.0000) | Acc: (88.00%) (29449/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3441) |  Loss2: (0.0000) | Acc: (88.00%) (30571/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3424) |  Loss2: (0.0000) | Acc: (88.00%) (31713/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3442) |  Loss2: (0.0000) | Acc: (88.00%) (32820/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3439) |  Loss2: (0.0000) | Acc: (88.00%) (33956/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (35096/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3455) |  Loss2: (0.0000) | Acc: (88.00%) (36200/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3462) |  Loss2: (0.0000) | Acc: (88.00%) (37315/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3463) |  Loss2: (0.0000) | Acc: (88.00%) (38439/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3466) |  Loss2: (0.0000) | Acc: (88.00%) (39569/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (88.00%) (40684/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (88.00%) (41793/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (87.00%) (42913/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (87.00%) (43997/50000)
# TEST : Loss: (0.5047) | Acc: (83.00%) (8302/10000)
percent tensor([0.5006, 0.5032, 0.4958, 0.4945, 0.4982, 0.4905, 0.5025, 0.5000, 0.5062,
        0.5036, 0.5052, 0.5004, 0.5037, 0.5067, 0.4965, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.4814, 0.4804, 0.4790, 0.4812, 0.4799, 0.4814, 0.4802, 0.4829, 0.4791,
        0.4794, 0.4803, 0.4774, 0.4817, 0.4805, 0.4798, 0.4826],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.4722, 0.4994, 0.5394, 0.5187, 0.5635, 0.4783, 0.5169, 0.5127,
        0.4691, 0.4825, 0.4581, 0.4690, 0.5560, 0.4957, 0.5223],
       device='cuda:0') torch.Size([16])
percent tensor([0.6080, 0.6293, 0.5873, 0.5847, 0.5878, 0.5872, 0.6230, 0.5997, 0.6135,
        0.6315, 0.6377, 0.6067, 0.6212, 0.6260, 0.6130, 0.6148],
       device='cuda:0') torch.Size([16])
percent tensor([0.5560, 0.5224, 0.6381, 0.6337, 0.6414, 0.6365, 0.5708, 0.5838, 0.5859,
        0.5360, 0.5747, 0.5923, 0.5295, 0.5518, 0.5735, 0.5461],
       device='cuda:0') torch.Size([16])
percent tensor([0.5740, 0.5529, 0.6049, 0.6102, 0.6307, 0.6416, 0.5773, 0.5589, 0.5953,
        0.5601, 0.5635, 0.5553, 0.5623, 0.5946, 0.5386, 0.5855],
       device='cuda:0') torch.Size([16])
percent tensor([0.6670, 0.6263, 0.6638, 0.6561, 0.6924, 0.7756, 0.6086, 0.5131, 0.6809,
        0.6563, 0.6746, 0.6308, 0.6546, 0.6865, 0.5668, 0.6815],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9978, 0.9991, 0.9987, 0.9992, 0.9990, 0.9992, 0.9989, 0.9973,
        0.9991, 0.9989, 0.9988, 0.9978, 0.9983, 0.9988, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 67 | Batch_idx: 0 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (89.00%) (1254/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (2384/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3231) |  Loss2: (0.0000) | Acc: (88.00%) (3520/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3193) |  Loss2: (0.0000) | Acc: (88.00%) (4663/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (5793/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.3214) |  Loss2: (0.0000) | Acc: (88.00%) (6932/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (88.00%) (8083/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (88.00%) (9226/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3226) |  Loss2: (0.0000) | Acc: (88.00%) (10353/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3270) |  Loss2: (0.0000) | Acc: (88.00%) (11471/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3260) |  Loss2: (0.0000) | Acc: (88.00%) (12601/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (13742/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3252) |  Loss2: (0.0000) | Acc: (88.00%) (14887/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3254) |  Loss2: (0.0000) | Acc: (88.00%) (16024/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (17157/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3272) |  Loss2: (0.0000) | Acc: (88.00%) (18292/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3288) |  Loss2: (0.0000) | Acc: (88.00%) (19412/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3294) |  Loss2: (0.0000) | Acc: (88.00%) (20541/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3303) |  Loss2: (0.0000) | Acc: (88.00%) (21663/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (22785/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (23904/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (25017/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (26135/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3342) |  Loss2: (0.0000) | Acc: (88.00%) (27273/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3329) |  Loss2: (0.0000) | Acc: (88.00%) (28415/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (29540/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (30651/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (31781/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (32905/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (34034/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3348) |  Loss2: (0.0000) | Acc: (88.00%) (35175/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (88.00%) (36299/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (37444/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3343) |  Loss2: (0.0000) | Acc: (88.00%) (38585/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (39725/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (40855/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (41971/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3352) |  Loss2: (0.0000) | Acc: (88.00%) (43110/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (44196/50000)
# TEST : Loss: (0.4424) | Acc: (84.00%) (8498/10000)
percent tensor([0.5005, 0.5018, 0.4974, 0.4941, 0.4993, 0.4908, 0.5021, 0.5001, 0.5058,
        0.5031, 0.5049, 0.5014, 0.5035, 0.5044, 0.4960, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.4812, 0.4800, 0.4791, 0.4809, 0.4794, 0.4820, 0.4800, 0.4828, 0.4789,
        0.4786, 0.4799, 0.4765, 0.4812, 0.4800, 0.4798, 0.4825],
       device='cuda:0') torch.Size([16])
percent tensor([0.5183, 0.4784, 0.4852, 0.5422, 0.5064, 0.5614, 0.4819, 0.5179, 0.5144,
        0.4729, 0.4863, 0.4465, 0.4718, 0.5639, 0.4960, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.6304, 0.5904, 0.5875, 0.5916, 0.5893, 0.6254, 0.6004, 0.6177,
        0.6343, 0.6403, 0.6127, 0.6237, 0.6302, 0.6153, 0.6174],
       device='cuda:0') torch.Size([16])
percent tensor([0.5495, 0.5303, 0.6335, 0.6292, 0.6426, 0.6324, 0.5620, 0.5889, 0.5766,
        0.5419, 0.5566, 0.5935, 0.5146, 0.5495, 0.5730, 0.5490],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5675, 0.5931, 0.5958, 0.6225, 0.6399, 0.5835, 0.5544, 0.6002,
        0.5647, 0.5712, 0.5556, 0.5643, 0.6044, 0.5395, 0.5891],
       device='cuda:0') torch.Size([16])
percent tensor([0.6648, 0.6494, 0.6262, 0.6234, 0.6608, 0.7645, 0.6154, 0.5073, 0.6871,
        0.6562, 0.6839, 0.6291, 0.6578, 0.6986, 0.5773, 0.6946],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9983, 0.9988, 0.9985, 0.9990, 0.9991, 0.9996, 0.9992, 0.9986,
        0.9993, 0.9990, 0.9988, 0.9982, 0.9986, 0.9989, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 68 | Batch_idx: 0 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.3598) |  Loss2: (0.0000) | Acc: (87.00%) (1235/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (87.00%) (2339/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (3428/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.4050) |  Loss2: (0.0000) | Acc: (85.00%) (4499/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.4093) |  Loss2: (0.0000) | Acc: (85.00%) (5594/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (85.00%) (6686/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.4125) |  Loss2: (0.0000) | Acc: (85.00%) (7785/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.4098) |  Loss2: (0.0000) | Acc: (85.00%) (8895/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (85.00%) (9982/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.4101) |  Loss2: (0.0000) | Acc: (85.00%) (11082/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.4066) |  Loss2: (0.0000) | Acc: (85.00%) (12191/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (13266/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (85.00%) (14369/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.4067) |  Loss2: (0.0000) | Acc: (85.00%) (15493/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (85.00%) (16603/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.4026) |  Loss2: (0.0000) | Acc: (86.00%) (17732/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.3991) |  Loss2: (0.0000) | Acc: (86.00%) (18848/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.3965) |  Loss2: (0.0000) | Acc: (86.00%) (19977/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.3974) |  Loss2: (0.0000) | Acc: (86.00%) (21080/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.3964) |  Loss2: (0.0000) | Acc: (86.00%) (22192/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.3953) |  Loss2: (0.0000) | Acc: (86.00%) (23310/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.3940) |  Loss2: (0.0000) | Acc: (86.00%) (24425/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.3926) |  Loss2: (0.0000) | Acc: (86.00%) (25538/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.3928) |  Loss2: (0.0000) | Acc: (86.00%) (26636/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.3936) |  Loss2: (0.0000) | Acc: (86.00%) (27742/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3918) |  Loss2: (0.0000) | Acc: (86.00%) (28855/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3905) |  Loss2: (0.0000) | Acc: (86.00%) (29967/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3901) |  Loss2: (0.0000) | Acc: (86.00%) (31068/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3883) |  Loss2: (0.0000) | Acc: (86.00%) (32204/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3868) |  Loss2: (0.0000) | Acc: (86.00%) (33323/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3864) |  Loss2: (0.0000) | Acc: (86.00%) (34434/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3861) |  Loss2: (0.0000) | Acc: (86.00%) (35554/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3854) |  Loss2: (0.0000) | Acc: (86.00%) (36671/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3844) |  Loss2: (0.0000) | Acc: (86.00%) (37804/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3843) |  Loss2: (0.0000) | Acc: (86.00%) (38909/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3838) |  Loss2: (0.0000) | Acc: (86.00%) (40021/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3825) |  Loss2: (0.0000) | Acc: (86.00%) (41157/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3816) |  Loss2: (0.0000) | Acc: (86.00%) (42278/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (43364/50000)
# TEST : Loss: (0.4732) | Acc: (83.00%) (8391/10000)
percent tensor([0.5059, 0.5085, 0.5027, 0.4964, 0.5056, 0.4943, 0.5093, 0.5039, 0.5139,
        0.5094, 0.5123, 0.5082, 0.5099, 0.5108, 0.5006, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.4800, 0.4794, 0.4760, 0.4779, 0.4762, 0.4806, 0.4785, 0.4799, 0.4784,
        0.4776, 0.4804, 0.4739, 0.4810, 0.4797, 0.4782, 0.4813],
       device='cuda:0') torch.Size([16])
percent tensor([0.5240, 0.4813, 0.4792, 0.5480, 0.5026, 0.5628, 0.4816, 0.5233, 0.5165,
        0.4768, 0.4932, 0.4408, 0.4766, 0.5681, 0.4977, 0.5311],
       device='cuda:0') torch.Size([16])
percent tensor([0.6275, 0.6503, 0.6019, 0.5996, 0.6057, 0.6074, 0.6438, 0.6115, 0.6352,
        0.6522, 0.6554, 0.6287, 0.6413, 0.6516, 0.6341, 0.6367],
       device='cuda:0') torch.Size([16])
percent tensor([0.5543, 0.5268, 0.6493, 0.6452, 0.6493, 0.6427, 0.5588, 0.5941, 0.5858,
        0.5493, 0.5565, 0.6086, 0.5215, 0.5536, 0.5656, 0.5530],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.5231, 0.5581, 0.5605, 0.5832, 0.6088, 0.5364, 0.5090, 0.5628,
        0.5249, 0.5303, 0.5198, 0.5278, 0.5610, 0.4949, 0.5434],
       device='cuda:0') torch.Size([16])
percent tensor([0.6427, 0.6149, 0.6480, 0.6585, 0.6854, 0.7644, 0.6106, 0.5239, 0.6728,
        0.6459, 0.6654, 0.6545, 0.6351, 0.6800, 0.5627, 0.6723],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9982, 0.9990, 0.9988, 0.9990, 0.9988, 0.9995, 0.9993, 0.9984,
        0.9993, 0.9991, 0.9990, 0.9980, 0.9990, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 69 | Batch_idx: 0 |  Loss: (0.3536) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.3418) |  Loss2: (0.0000) | Acc: (88.00%) (1241/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.3623) |  Loss2: (0.0000) | Acc: (86.00%) (2328/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (86.00%) (3450/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.3625) |  Loss2: (0.0000) | Acc: (87.00%) (4581/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.3623) |  Loss2: (0.0000) | Acc: (87.00%) (5713/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.3669) |  Loss2: (0.0000) | Acc: (87.00%) (6818/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (7943/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (9052/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (10182/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (11301/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3616) |  Loss2: (0.0000) | Acc: (87.00%) (12421/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3600) |  Loss2: (0.0000) | Acc: (87.00%) (13548/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (14670/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (15808/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (16912/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3600) |  Loss2: (0.0000) | Acc: (87.00%) (18011/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.3609) |  Loss2: (0.0000) | Acc: (87.00%) (19128/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (20257/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (21380/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (22498/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (23628/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (24755/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (25883/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3571) |  Loss2: (0.0000) | Acc: (87.00%) (26997/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (28137/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3550) |  Loss2: (0.0000) | Acc: (87.00%) (29266/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (30379/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.3548) |  Loss2: (0.0000) | Acc: (87.00%) (31534/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.3545) |  Loss2: (0.0000) | Acc: (87.00%) (32660/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (87.00%) (33793/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3534) |  Loss2: (0.0000) | Acc: (87.00%) (34921/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (36045/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (37187/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (38305/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (39421/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3529) |  Loss2: (0.0000) | Acc: (87.00%) (40552/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3524) |  Loss2: (0.0000) | Acc: (87.00%) (41679/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (42830/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (43915/50000)
# TEST : Loss: (0.4507) | Acc: (84.00%) (8461/10000)
percent tensor([0.5066, 0.5108, 0.5017, 0.4946, 0.5054, 0.4932, 0.5112, 0.5034, 0.5164,
        0.5109, 0.5148, 0.5085, 0.5116, 0.5135, 0.5008, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.4753, 0.4751, 0.4703, 0.4721, 0.4706, 0.4757, 0.4738, 0.4742, 0.4742,
        0.4731, 0.4766, 0.4685, 0.4771, 0.4758, 0.4730, 0.4767],
       device='cuda:0') torch.Size([16])
percent tensor([0.5274, 0.4820, 0.4840, 0.5488, 0.5064, 0.5641, 0.4837, 0.5238, 0.5217,
        0.4783, 0.4966, 0.4416, 0.4789, 0.5730, 0.4976, 0.5337],
       device='cuda:0') torch.Size([16])
percent tensor([0.6251, 0.6477, 0.5946, 0.5944, 0.5990, 0.6069, 0.6398, 0.6054, 0.6316,
        0.6479, 0.6518, 0.6222, 0.6392, 0.6500, 0.6311, 0.6355],
       device='cuda:0') torch.Size([16])
percent tensor([0.5494, 0.5248, 0.6455, 0.6434, 0.6462, 0.6382, 0.5560, 0.5874, 0.5826,
        0.5496, 0.5567, 0.6005, 0.5185, 0.5540, 0.5566, 0.5531],
       device='cuda:0') torch.Size([16])
percent tensor([0.5337, 0.5312, 0.5636, 0.5685, 0.5899, 0.6144, 0.5454, 0.5166, 0.5683,
        0.5314, 0.5364, 0.5231, 0.5340, 0.5679, 0.5022, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.6241, 0.5962, 0.6505, 0.6660, 0.6873, 0.7641, 0.6000, 0.5224, 0.6552,
        0.6252, 0.6441, 0.6419, 0.6128, 0.6576, 0.5466, 0.6666],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9982, 0.9989, 0.9988, 0.9990, 0.9989, 0.9995, 0.9993, 0.9984,
        0.9993, 0.9991, 0.9988, 0.9980, 0.9990, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 70 | Batch_idx: 0 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.3416) |  Loss2: (0.0000) | Acc: (88.00%) (1241/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (2378/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (3497/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (87.00%) (4617/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.3369) |  Loss2: (0.0000) | Acc: (87.00%) (5737/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (87.00%) (6852/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (87.00%) (7984/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (9133/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (10252/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.3360) |  Loss2: (0.0000) | Acc: (88.00%) (11395/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (12510/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.3400) |  Loss2: (0.0000) | Acc: (88.00%) (13641/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (14758/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.3430) |  Loss2: (0.0000) | Acc: (87.00%) (15878/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.3426) |  Loss2: (0.0000) | Acc: (87.00%) (17008/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.3427) |  Loss2: (0.0000) | Acc: (87.00%) (18135/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.3413) |  Loss2: (0.0000) | Acc: (88.00%) (19271/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.3408) |  Loss2: (0.0000) | Acc: (88.00%) (20410/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (21563/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (88.00%) (22690/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.3393) |  Loss2: (0.0000) | Acc: (88.00%) (23816/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (88.00%) (24955/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (26080/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.3383) |  Loss2: (0.0000) | Acc: (88.00%) (27218/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (28346/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.3391) |  Loss2: (0.0000) | Acc: (88.00%) (29472/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (30615/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3377) |  Loss2: (0.0000) | Acc: (88.00%) (31757/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (88.00%) (32900/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (34019/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3376) |  Loss2: (0.0000) | Acc: (88.00%) (35147/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (36270/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (37400/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (38553/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (39716/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (40844/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (41972/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (43100/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (44219/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_070.pth.tar'
# TEST : Loss: (0.4411) | Acc: (85.00%) (8503/10000)
percent tensor([0.5072, 0.5124, 0.5012, 0.4935, 0.5057, 0.4925, 0.5127, 0.5031, 0.5184,
        0.5121, 0.5169, 0.5089, 0.5129, 0.5152, 0.5011, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.4733, 0.4733, 0.4674, 0.4692, 0.4678, 0.4733, 0.4718, 0.4714, 0.4727,
        0.4712, 0.4752, 0.4661, 0.4756, 0.4743, 0.4707, 0.4746],
       device='cuda:0') torch.Size([16])
percent tensor([0.5253, 0.4827, 0.4786, 0.5445, 0.5022, 0.5601, 0.4841, 0.5209, 0.5214,
        0.4783, 0.4970, 0.4398, 0.4782, 0.5747, 0.4964, 0.5326],
       device='cuda:0') torch.Size([16])
percent tensor([0.6243, 0.6467, 0.5921, 0.5921, 0.5964, 0.6068, 0.6381, 0.6024, 0.6307,
        0.6461, 0.6507, 0.6195, 0.6391, 0.6492, 0.6299, 0.6353],
       device='cuda:0') torch.Size([16])
percent tensor([0.5577, 0.5340, 0.6565, 0.6526, 0.6546, 0.6422, 0.5663, 0.5941, 0.5946,
        0.5636, 0.5711, 0.6115, 0.5283, 0.5681, 0.5612, 0.5621],
       device='cuda:0') torch.Size([16])
percent tensor([0.5456, 0.5418, 0.5735, 0.5800, 0.6006, 0.6215, 0.5570, 0.5295, 0.5784,
        0.5420, 0.5471, 0.5329, 0.5443, 0.5781, 0.5143, 0.5638],
       device='cuda:0') torch.Size([16])
percent tensor([0.6411, 0.6101, 0.6694, 0.6810, 0.7050, 0.7789, 0.6146, 0.5374, 0.6710,
        0.6402, 0.6551, 0.6563, 0.6287, 0.6705, 0.5625, 0.6919],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9982, 0.9991, 0.9988, 0.9990, 0.9989, 0.9995, 0.9993, 0.9985,
        0.9993, 0.9992, 0.9990, 0.9981, 0.9991, 0.9991, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.8305, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(805.8242, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(804.9030, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1525.4445, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.8005, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2206.1382, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4286.3501, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1414.4535, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6105.9092, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11975.7354, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3989.9119, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16841.7051, device='cuda:0')
Epoch: 71 | Batch_idx: 0 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (89.00%) (1254/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.3363) |  Loss2: (0.0000) | Acc: (89.00%) (2396/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (88.00%) (3507/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.3414) |  Loss2: (0.0000) | Acc: (88.00%) (4631/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.3449) |  Loss2: (0.0000) | Acc: (88.00%) (5757/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (88.00%) (6905/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.3342) |  Loss2: (0.0000) | Acc: (88.00%) (8052/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (9192/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (10327/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (11463/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.3315) |  Loss2: (0.0000) | Acc: (88.00%) (12595/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (13731/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.3288) |  Loss2: (0.0000) | Acc: (88.00%) (14884/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.3268) |  Loss2: (0.0000) | Acc: (88.00%) (16016/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.3259) |  Loss2: (0.0000) | Acc: (88.00%) (17157/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (18304/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.3268) |  Loss2: (0.0000) | Acc: (88.00%) (19437/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (20575/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.3267) |  Loss2: (0.0000) | Acc: (88.00%) (21706/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (22828/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.3266) |  Loss2: (0.0000) | Acc: (88.00%) (23970/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.3274) |  Loss2: (0.0000) | Acc: (88.00%) (25096/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.3271) |  Loss2: (0.0000) | Acc: (88.00%) (26224/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.3267) |  Loss2: (0.0000) | Acc: (88.00%) (27370/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.3273) |  Loss2: (0.0000) | Acc: (88.00%) (28499/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.3278) |  Loss2: (0.0000) | Acc: (88.00%) (29617/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (30747/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.3284) |  Loss2: (0.0000) | Acc: (88.00%) (31869/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (33005/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (34140/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (35269/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.3281) |  Loss2: (0.0000) | Acc: (88.00%) (36429/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (37554/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.3284) |  Loss2: (0.0000) | Acc: (88.00%) (38680/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (39829/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (40964/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (42101/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (43234/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.3279) |  Loss2: (0.0000) | Acc: (88.00%) (44332/50000)
# TEST : Loss: (0.4327) | Acc: (85.00%) (8538/10000)
percent tensor([0.5070, 0.5130, 0.4999, 0.4916, 0.5050, 0.4912, 0.5132, 0.5021, 0.5194,
        0.5123, 0.5179, 0.5085, 0.5134, 0.5159, 0.5006, 0.5032],
       device='cuda:0') torch.Size([16])
percent tensor([0.4732, 0.4735, 0.4669, 0.4685, 0.4674, 0.4728, 0.4719, 0.4708, 0.4730,
        0.4713, 0.4757, 0.4660, 0.4759, 0.4747, 0.4705, 0.4744],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.4776, 0.4752, 0.5380, 0.4991, 0.5533, 0.4803, 0.5160, 0.5163,
        0.4727, 0.4909, 0.4359, 0.4719, 0.5688, 0.4912, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.6241, 0.6460, 0.5903, 0.5912, 0.5950, 0.6080, 0.6370, 0.6015, 0.6299,
        0.6446, 0.6494, 0.6181, 0.6392, 0.6488, 0.6297, 0.6357],
       device='cuda:0') torch.Size([16])
percent tensor([0.5581, 0.5348, 0.6559, 0.6527, 0.6532, 0.6423, 0.5659, 0.5920, 0.5938,
        0.5649, 0.5722, 0.6095, 0.5300, 0.5685, 0.5590, 0.5642],
       device='cuda:0') torch.Size([16])
percent tensor([0.5488, 0.5449, 0.5767, 0.5840, 0.6039, 0.6240, 0.5602, 0.5326, 0.5816,
        0.5460, 0.5506, 0.5349, 0.5475, 0.5813, 0.5176, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.6342, 0.6034, 0.6698, 0.6783, 0.7033, 0.7818, 0.6092, 0.5300, 0.6674,
        0.6335, 0.6499, 0.6512, 0.6267, 0.6633, 0.5541, 0.6887],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9982, 0.9992, 0.9988, 0.9991, 0.9990, 0.9995, 0.9993, 0.9985,
        0.9993, 0.9993, 0.9989, 0.9981, 0.9990, 0.9992, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 72 | Batch_idx: 0 |  Loss: (0.3288) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.3296) |  Loss2: (0.0000) | Acc: (88.00%) (1252/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (89.00%) (2398/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (3522/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (4656/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (5771/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (6902/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.3339) |  Loss2: (0.0000) | Acc: (88.00%) (8034/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (9165/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (10315/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (11427/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (12557/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (13703/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (14871/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.3298) |  Loss2: (0.0000) | Acc: (88.00%) (15997/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (17135/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.3289) |  Loss2: (0.0000) | Acc: (88.00%) (18265/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (19401/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (20542/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (21678/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.3281) |  Loss2: (0.0000) | Acc: (88.00%) (22809/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.3286) |  Loss2: (0.0000) | Acc: (88.00%) (23935/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.3304) |  Loss2: (0.0000) | Acc: (88.00%) (25043/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.3303) |  Loss2: (0.0000) | Acc: (88.00%) (26166/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (27298/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (28434/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (29571/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (30694/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (31820/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.3310) |  Loss2: (0.0000) | Acc: (88.00%) (32967/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.3311) |  Loss2: (0.0000) | Acc: (88.00%) (34101/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (35232/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (36389/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (37504/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (38653/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (39771/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (40898/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.3331) |  Loss2: (0.0000) | Acc: (88.00%) (42006/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.3337) |  Loss2: (0.0000) | Acc: (88.00%) (43119/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (44215/50000)
# TEST : Loss: (0.4854) | Acc: (83.00%) (8390/10000)
percent tensor([0.5060, 0.5151, 0.4943, 0.4916, 0.5006, 0.4906, 0.5122, 0.5018, 0.5174,
        0.5119, 0.5180, 0.5035, 0.5129, 0.5196, 0.5017, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.4727, 0.4734, 0.4676, 0.4687, 0.4686, 0.4727, 0.4718, 0.4706, 0.4719,
        0.4709, 0.4743, 0.4666, 0.4751, 0.4734, 0.4703, 0.4738],
       device='cuda:0') torch.Size([16])
percent tensor([0.5185, 0.4723, 0.4823, 0.5355, 0.5046, 0.5515, 0.4792, 0.5175, 0.5177,
        0.4694, 0.4804, 0.4393, 0.4699, 0.5629, 0.4866, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.6273, 0.6468, 0.5942, 0.5955, 0.5998, 0.6099, 0.6376, 0.6060, 0.6244,
        0.6474, 0.6535, 0.6176, 0.6410, 0.6427, 0.6292, 0.6380],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.5441, 0.6429, 0.6461, 0.6436, 0.6508, 0.5803, 0.5987, 0.6074,
        0.5679, 0.6040, 0.5960, 0.5345, 0.5855, 0.5700, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.5459, 0.5463, 0.5685, 0.5689, 0.5951, 0.6197, 0.5678, 0.5252, 0.5872,
        0.5387, 0.5538, 0.5237, 0.5488, 0.5893, 0.5118, 0.5604],
       device='cuda:0') torch.Size([16])
percent tensor([0.6338, 0.6201, 0.6504, 0.6533, 0.6841, 0.7771, 0.6050, 0.5262, 0.6868,
        0.6391, 0.6448, 0.5972, 0.6441, 0.6728, 0.5361, 0.6942],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9989, 0.9991, 0.9992, 0.9995, 0.9991, 0.9996, 0.9994, 0.9984,
        0.9995, 0.9996, 0.9993, 0.9989, 0.9992, 0.9991, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 73 | Batch_idx: 0 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (87.00%) (1239/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.3267) |  Loss2: (0.0000) | Acc: (88.00%) (2371/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (88.00%) (3524/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (4655/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (5823/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (6943/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.3161) |  Loss2: (0.0000) | Acc: (88.00%) (8086/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.3167) |  Loss2: (0.0000) | Acc: (88.00%) (9227/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.3193) |  Loss2: (0.0000) | Acc: (88.00%) (10361/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.3165) |  Loss2: (0.0000) | Acc: (89.00%) (11514/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (12662/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.3101) |  Loss2: (0.0000) | Acc: (89.00%) (13815/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.3096) |  Loss2: (0.0000) | Acc: (89.00%) (14961/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (89.00%) (16117/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (17245/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (18363/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (19495/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (89.00%) (20623/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (88.00%) (21746/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.3166) |  Loss2: (0.0000) | Acc: (88.00%) (22883/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.3183) |  Loss2: (0.0000) | Acc: (88.00%) (24007/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (25140/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.3205) |  Loss2: (0.0000) | Acc: (88.00%) (26275/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.3213) |  Loss2: (0.0000) | Acc: (88.00%) (27407/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.3220) |  Loss2: (0.0000) | Acc: (88.00%) (28530/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.3220) |  Loss2: (0.0000) | Acc: (88.00%) (29660/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.3215) |  Loss2: (0.0000) | Acc: (88.00%) (30817/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.3213) |  Loss2: (0.0000) | Acc: (88.00%) (31955/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (88.00%) (33096/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.3212) |  Loss2: (0.0000) | Acc: (88.00%) (34234/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.3231) |  Loss2: (0.0000) | Acc: (88.00%) (35336/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (88.00%) (36484/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.3221) |  Loss2: (0.0000) | Acc: (88.00%) (37628/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (38760/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (39890/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (88.00%) (41019/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (42148/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (43281/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.3247) |  Loss2: (0.0000) | Acc: (88.00%) (44358/50000)
# TEST : Loss: (0.4725) | Acc: (84.00%) (8445/10000)
percent tensor([0.5071, 0.5153, 0.4981, 0.4934, 0.5039, 0.4914, 0.5137, 0.5030, 0.5185,
        0.5129, 0.5178, 0.5070, 0.5136, 0.5197, 0.5022, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.4723, 0.4731, 0.4668, 0.4681, 0.4676, 0.4726, 0.4710, 0.4704, 0.4722,
        0.4706, 0.4746, 0.4655, 0.4748, 0.4730, 0.4702, 0.4738],
       device='cuda:0') torch.Size([16])
percent tensor([0.5109, 0.4658, 0.4666, 0.5297, 0.4967, 0.5526, 0.4720, 0.5050, 0.5142,
        0.4598, 0.4805, 0.4274, 0.4657, 0.5636, 0.4804, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.6261, 0.6474, 0.5993, 0.5996, 0.6019, 0.6086, 0.6400, 0.6076, 0.6262,
        0.6479, 0.6548, 0.6223, 0.6427, 0.6436, 0.6319, 0.6384],
       device='cuda:0') torch.Size([16])
percent tensor([0.5618, 0.5506, 0.6406, 0.6387, 0.6465, 0.6459, 0.5885, 0.5966, 0.6057,
        0.5664, 0.6172, 0.5919, 0.5333, 0.5877, 0.5706, 0.5616],
       device='cuda:0') torch.Size([16])
percent tensor([0.5528, 0.5580, 0.5830, 0.5766, 0.6026, 0.6210, 0.5829, 0.5476, 0.5904,
        0.5547, 0.5649, 0.5266, 0.5568, 0.5905, 0.5215, 0.5682],
       device='cuda:0') torch.Size([16])
percent tensor([0.6606, 0.6461, 0.6955, 0.6564, 0.6993, 0.7921, 0.6465, 0.5724, 0.7018,
        0.6789, 0.6837, 0.6373, 0.6650, 0.6809, 0.5653, 0.7142],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9984, 0.9993, 0.9991, 0.9994, 0.9993, 0.9995, 0.9993, 0.9987,
        0.9994, 0.9997, 0.9994, 0.9991, 0.9991, 0.9990, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 74 | Batch_idx: 0 |  Loss: (0.3286) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (1241/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2954) |  Loss2: (0.0000) | Acc: (89.00%) (2407/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (3543/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (4690/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (5824/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (6965/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (8106/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (9235/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (89.00%) (10378/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (11542/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (12700/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.3103) |  Loss2: (0.0000) | Acc: (89.00%) (13834/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.3092) |  Loss2: (0.0000) | Acc: (89.00%) (14989/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.3101) |  Loss2: (0.0000) | Acc: (89.00%) (16125/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (17257/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (18401/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (19545/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.3092) |  Loss2: (0.0000) | Acc: (89.00%) (20700/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (21850/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (22991/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (24151/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (25285/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.3093) |  Loss2: (0.0000) | Acc: (89.00%) (26418/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (89.00%) (27532/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (28664/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (29804/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (30927/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (32072/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (89.00%) (33231/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (34382/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (35532/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (36664/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (37808/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.3123) |  Loss2: (0.0000) | Acc: (89.00%) (38948/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (89.00%) (40091/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (41263/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (42407/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (43563/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (44645/50000)
# TEST : Loss: (0.4997) | Acc: (83.00%) (8345/10000)
percent tensor([0.5060, 0.5149, 0.4935, 0.4927, 0.5000, 0.4913, 0.5118, 0.5012, 0.5167,
        0.5119, 0.5174, 0.5029, 0.5125, 0.5186, 0.5018, 0.5038],
       device='cuda:0') torch.Size([16])
percent tensor([0.4725, 0.4736, 0.4673, 0.4693, 0.4687, 0.4728, 0.4724, 0.4709, 0.4717,
        0.4712, 0.4743, 0.4671, 0.4747, 0.4746, 0.4706, 0.4736],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.4736, 0.4895, 0.5373, 0.5174, 0.5529, 0.4895, 0.5172, 0.5159,
        0.4728, 0.4825, 0.4484, 0.4651, 0.5706, 0.4914, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.6252, 0.6442, 0.5921, 0.5947, 0.5964, 0.6101, 0.6326, 0.6056, 0.6249,
        0.6409, 0.6490, 0.6158, 0.6400, 0.6418, 0.6283, 0.6348],
       device='cuda:0') torch.Size([16])
percent tensor([0.5641, 0.5381, 0.6588, 0.6469, 0.6630, 0.6397, 0.5830, 0.6040, 0.5959,
        0.5692, 0.6037, 0.6056, 0.5332, 0.5755, 0.5695, 0.5642],
       device='cuda:0') torch.Size([16])
percent tensor([0.5635, 0.5587, 0.5873, 0.5797, 0.6136, 0.6243, 0.5785, 0.5383, 0.5899,
        0.5605, 0.5678, 0.5499, 0.5621, 0.5967, 0.5286, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.6589, 0.6348, 0.7042, 0.6632, 0.7230, 0.7786, 0.6310, 0.5442, 0.6845,
        0.6466, 0.6737, 0.6648, 0.6461, 0.6778, 0.5576, 0.7029],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9995, 0.9993, 0.9995, 0.9992, 0.9993, 0.9991, 0.9990,
        0.9997, 0.9997, 0.9995, 0.9990, 0.9988, 0.9991, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 75 | Batch_idx: 0 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (89.00%) (1263/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (89.00%) (2417/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.2876) |  Loss2: (0.0000) | Acc: (89.00%) (3567/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.2877) |  Loss2: (0.0000) | Acc: (89.00%) (4715/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (5854/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (89.00%) (6991/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.2977) |  Loss2: (0.0000) | Acc: (89.00%) (8140/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (9281/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.2965) |  Loss2: (0.0000) | Acc: (89.00%) (10426/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (11564/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.2996) |  Loss2: (0.0000) | Acc: (89.00%) (12709/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (13856/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (14999/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (16127/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (17263/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (18398/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (19551/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (20689/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.3077) |  Loss2: (0.0000) | Acc: (89.00%) (21837/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (22972/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (24119/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (25255/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (26395/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (27547/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (28694/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (29853/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (31007/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (32143/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (33288/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (34422/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.3098) |  Loss2: (0.0000) | Acc: (89.00%) (35570/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (36705/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.3092) |  Loss2: (0.0000) | Acc: (89.00%) (37849/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (39014/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (40136/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (89.00%) (41292/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (42446/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.3073) |  Loss2: (0.0000) | Acc: (89.00%) (43605/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (44694/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_075.pth.tar'
# TEST : Loss: (0.4880) | Acc: (84.00%) (8402/10000)
percent tensor([0.5074, 0.5148, 0.4978, 0.4930, 0.5039, 0.4924, 0.5128, 0.5024, 0.5175,
        0.5126, 0.5179, 0.5067, 0.5132, 0.5173, 0.5028, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.4724, 0.4735, 0.4658, 0.4689, 0.4681, 0.4725, 0.4718, 0.4704, 0.4714,
        0.4709, 0.4741, 0.4663, 0.4745, 0.4742, 0.4704, 0.4736],
       device='cuda:0') torch.Size([16])
percent tensor([0.5139, 0.4750, 0.4917, 0.5355, 0.5144, 0.5511, 0.4837, 0.5182, 0.5206,
        0.4712, 0.4862, 0.4470, 0.4644, 0.5697, 0.4873, 0.5223],
       device='cuda:0') torch.Size([16])
percent tensor([0.6248, 0.6420, 0.5930, 0.5975, 0.5984, 0.6081, 0.6337, 0.6076, 0.6246,
        0.6419, 0.6483, 0.6169, 0.6399, 0.6409, 0.6260, 0.6339],
       device='cuda:0') torch.Size([16])
percent tensor([0.5590, 0.5465, 0.6584, 0.6494, 0.6583, 0.6395, 0.5859, 0.5982, 0.5946,
        0.5658, 0.6028, 0.6107, 0.5334, 0.5791, 0.5737, 0.5634],
       device='cuda:0') torch.Size([16])
percent tensor([0.5482, 0.5554, 0.5849, 0.5763, 0.6058, 0.6154, 0.5651, 0.5317, 0.5834,
        0.5512, 0.5570, 0.5367, 0.5517, 0.5840, 0.5148, 0.5613],
       device='cuda:0') torch.Size([16])
percent tensor([0.6294, 0.6301, 0.6672, 0.6442, 0.6933, 0.7613, 0.6162, 0.5188, 0.6624,
        0.6542, 0.6536, 0.6344, 0.6356, 0.6677, 0.5398, 0.6783],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9987, 0.9993, 0.9990, 0.9997, 0.9981, 0.9995, 0.9989, 0.9988,
        0.9996, 0.9995, 0.9995, 0.9985, 0.9993, 0.9989, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 76 | Batch_idx: 0 |  Loss: (0.4161) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.3518) |  Loss2: (0.0000) | Acc: (87.00%) (1237/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (2348/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (3462/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (87.00%) (4571/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (86.00%) (5671/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.3825) |  Loss2: (0.0000) | Acc: (86.00%) (6774/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.3857) |  Loss2: (0.0000) | Acc: (86.00%) (7880/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (8985/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.3828) |  Loss2: (0.0000) | Acc: (86.00%) (10100/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (11221/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (86.00%) (12335/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.3757) |  Loss2: (0.0000) | Acc: (86.00%) (13468/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.3719) |  Loss2: (0.0000) | Acc: (87.00%) (14602/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.3714) |  Loss2: (0.0000) | Acc: (87.00%) (15722/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.3692) |  Loss2: (0.0000) | Acc: (87.00%) (16861/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (18001/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (19121/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.3665) |  Loss2: (0.0000) | Acc: (87.00%) (20223/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (21357/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.3640) |  Loss2: (0.0000) | Acc: (87.00%) (22488/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.3652) |  Loss2: (0.0000) | Acc: (87.00%) (23601/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.3657) |  Loss2: (0.0000) | Acc: (87.00%) (24704/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (25848/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (26970/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.3623) |  Loss2: (0.0000) | Acc: (87.00%) (28093/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.3625) |  Loss2: (0.0000) | Acc: (87.00%) (29204/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.3614) |  Loss2: (0.0000) | Acc: (87.00%) (30340/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.3614) |  Loss2: (0.0000) | Acc: (87.00%) (31453/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.3614) |  Loss2: (0.0000) | Acc: (87.00%) (32577/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (33708/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.3604) |  Loss2: (0.0000) | Acc: (87.00%) (34827/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.3590) |  Loss2: (0.0000) | Acc: (87.00%) (35964/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (37090/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (38236/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (39345/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.3571) |  Loss2: (0.0000) | Acc: (87.00%) (40471/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (41611/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.3551) |  Loss2: (0.0000) | Acc: (87.00%) (42746/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.3542) |  Loss2: (0.0000) | Acc: (87.00%) (43847/50000)
# TEST : Loss: (0.4583) | Acc: (84.00%) (8478/10000)
percent tensor([0.5038, 0.5079, 0.4963, 0.4898, 0.5010, 0.4889, 0.5069, 0.4987, 0.5128,
        0.5074, 0.5120, 0.5034, 0.5087, 0.5097, 0.4971, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.4822, 0.4807, 0.4776, 0.4792, 0.4791, 0.4810, 0.4809, 0.4804, 0.4811,
        0.4796, 0.4825, 0.4772, 0.4827, 0.4819, 0.4792, 0.4817],
       device='cuda:0') torch.Size([16])
percent tensor([0.5274, 0.4828, 0.5095, 0.5562, 0.5327, 0.5620, 0.4930, 0.5383, 0.5333,
        0.4806, 0.4943, 0.4549, 0.4767, 0.5755, 0.4974, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.6259, 0.6429, 0.5951, 0.6009, 0.6006, 0.6093, 0.6350, 0.6108, 0.6259,
        0.6420, 0.6470, 0.6183, 0.6389, 0.6423, 0.6278, 0.6349],
       device='cuda:0') torch.Size([16])
percent tensor([0.5372, 0.5280, 0.6690, 0.6620, 0.6625, 0.6180, 0.5755, 0.6092, 0.5973,
        0.5544, 0.6004, 0.6120, 0.5045, 0.5869, 0.5512, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.5766, 0.5726, 0.6113, 0.6062, 0.6300, 0.6408, 0.5899, 0.5523, 0.6072,
        0.5656, 0.5744, 0.5637, 0.5712, 0.6077, 0.5450, 0.5891],
       device='cuda:0') torch.Size([16])
percent tensor([0.6549, 0.6344, 0.6908, 0.6725, 0.6932, 0.7829, 0.6292, 0.5009, 0.6931,
        0.6548, 0.6723, 0.6579, 0.6562, 0.7030, 0.5532, 0.6866],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9993, 0.9990, 0.9995, 0.9989, 0.9996, 0.9990, 0.9990,
        0.9996, 0.9996, 0.9995, 0.9985, 0.9994, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 77 | Batch_idx: 0 |  Loss: (0.4145) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.3417) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.3410) |  Loss2: (0.0000) | Acc: (88.00%) (2367/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (3495/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (4634/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (5776/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (6910/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.3309) |  Loss2: (0.0000) | Acc: (88.00%) (8045/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (9198/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (10361/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.3181) |  Loss2: (0.0000) | Acc: (89.00%) (11510/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.3184) |  Loss2: (0.0000) | Acc: (88.00%) (12644/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.3181) |  Loss2: (0.0000) | Acc: (89.00%) (13788/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.3182) |  Loss2: (0.0000) | Acc: (89.00%) (14928/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.3177) |  Loss2: (0.0000) | Acc: (89.00%) (16076/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (88.00%) (17188/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.3199) |  Loss2: (0.0000) | Acc: (88.00%) (18340/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.3176) |  Loss2: (0.0000) | Acc: (89.00%) (19492/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (89.00%) (20648/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (89.00%) (21782/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (89.00%) (22919/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (89.00%) (24052/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (89.00%) (25192/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (89.00%) (26329/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (89.00%) (27463/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (88.00%) (28586/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (88.00%) (29725/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (30866/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (88.00%) (32009/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (88.00%) (33145/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.3161) |  Loss2: (0.0000) | Acc: (88.00%) (34268/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (88.00%) (35416/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (88.00%) (36542/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (88.00%) (37667/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (88.00%) (38812/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.3165) |  Loss2: (0.0000) | Acc: (88.00%) (39935/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.3170) |  Loss2: (0.0000) | Acc: (88.00%) (41073/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (88.00%) (42223/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (88.00%) (43366/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (88.00%) (44471/50000)
# TEST : Loss: (0.4345) | Acc: (85.00%) (8555/10000)
percent tensor([0.5060, 0.5095, 0.4986, 0.4918, 0.5034, 0.4908, 0.5090, 0.5007, 0.5152,
        0.5095, 0.5142, 0.5058, 0.5108, 0.5115, 0.4988, 0.5017],
       device='cuda:0') torch.Size([16])
percent tensor([0.4844, 0.4816, 0.4798, 0.4814, 0.4812, 0.4828, 0.4824, 0.4824, 0.4828,
        0.4808, 0.4838, 0.4788, 0.4841, 0.4831, 0.4807, 0.4833],
       device='cuda:0') torch.Size([16])
percent tensor([0.5301, 0.4803, 0.5164, 0.5610, 0.5386, 0.5648, 0.4924, 0.5434, 0.5361,
        0.4803, 0.4935, 0.4587, 0.4777, 0.5745, 0.4973, 0.5360],
       device='cuda:0') torch.Size([16])
percent tensor([0.6313, 0.6476, 0.5997, 0.6065, 0.6059, 0.6127, 0.6402, 0.6167, 0.6318,
        0.6474, 0.6527, 0.6232, 0.6437, 0.6483, 0.6320, 0.6397],
       device='cuda:0') torch.Size([16])
percent tensor([0.5352, 0.5313, 0.6745, 0.6653, 0.6644, 0.6036, 0.5777, 0.6108, 0.6031,
        0.5590, 0.6086, 0.6207, 0.5080, 0.5934, 0.5481, 0.5458],
       device='cuda:0') torch.Size([16])
percent tensor([0.5637, 0.5603, 0.5998, 0.5953, 0.6216, 0.6346, 0.5760, 0.5374, 0.5962,
        0.5531, 0.5630, 0.5508, 0.5585, 0.5954, 0.5352, 0.5768],
       device='cuda:0') torch.Size([16])
percent tensor([0.6522, 0.6393, 0.6943, 0.6738, 0.7010, 0.7884, 0.6326, 0.4915, 0.7024,
        0.6618, 0.6867, 0.6692, 0.6620, 0.7110, 0.5537, 0.6845],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9993, 0.9990, 0.9996, 0.9988, 0.9996, 0.9991, 0.9989,
        0.9996, 0.9996, 0.9995, 0.9985, 0.9994, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 78 | Batch_idx: 0 |  Loss: (0.2931) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (90.00%) (1281/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (2408/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (3543/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (4686/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (5836/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (6961/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.3045) |  Loss2: (0.0000) | Acc: (89.00%) (8103/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.3077) |  Loss2: (0.0000) | Acc: (89.00%) (9243/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (10384/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.3067) |  Loss2: (0.0000) | Acc: (89.00%) (11539/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (12682/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.3073) |  Loss2: (0.0000) | Acc: (89.00%) (13820/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (14972/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.3072) |  Loss2: (0.0000) | Acc: (89.00%) (16112/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.3073) |  Loss2: (0.0000) | Acc: (89.00%) (17255/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (18413/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (19548/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (20679/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (21846/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (22989/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (24158/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (25290/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (26422/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (27547/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (89.00%) (28689/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (29848/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (31000/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (32137/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (33293/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (34425/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.3045) |  Loss2: (0.0000) | Acc: (89.00%) (35580/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (36710/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (37854/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (39001/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (40151/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (41292/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (42422/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (43576/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (44683/50000)
# TEST : Loss: (0.4244) | Acc: (85.00%) (8582/10000)
percent tensor([0.5062, 0.5092, 0.4987, 0.4917, 0.5035, 0.4906, 0.5089, 0.5007, 0.5154,
        0.5095, 0.5143, 0.5059, 0.5109, 0.5114, 0.4985, 0.5017],
       device='cuda:0') torch.Size([16])
percent tensor([0.4844, 0.4806, 0.4797, 0.4812, 0.4810, 0.4826, 0.4818, 0.4822, 0.4824,
        0.4801, 0.4831, 0.4782, 0.4836, 0.4823, 0.4800, 0.4830],
       device='cuda:0') torch.Size([16])
percent tensor([0.5278, 0.4767, 0.5151, 0.5583, 0.5339, 0.5622, 0.4870, 0.5396, 0.5339,
        0.4782, 0.4912, 0.4567, 0.4765, 0.5706, 0.4932, 0.5332],
       device='cuda:0') torch.Size([16])
percent tensor([0.6320, 0.6473, 0.6003, 0.6078, 0.6069, 0.6120, 0.6404, 0.6182, 0.6324,
        0.6476, 0.6529, 0.6237, 0.6439, 0.6484, 0.6319, 0.6396],
       device='cuda:0') torch.Size([16])
percent tensor([0.5338, 0.5321, 0.6760, 0.6652, 0.6632, 0.5935, 0.5768, 0.6091, 0.6038,
        0.5602, 0.6090, 0.6240, 0.5104, 0.5943, 0.5441, 0.5446],
       device='cuda:0') torch.Size([16])
percent tensor([0.5591, 0.5552, 0.5957, 0.5912, 0.6195, 0.6339, 0.5708, 0.5306, 0.5922,
        0.5476, 0.5586, 0.5465, 0.5540, 0.5892, 0.5325, 0.5734],
       device='cuda:0') torch.Size([16])
percent tensor([0.6590, 0.6503, 0.6998, 0.6766, 0.7103, 0.7978, 0.6404, 0.4871, 0.7133,
        0.6735, 0.7024, 0.6805, 0.6723, 0.7198, 0.5625, 0.6914],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9990, 0.9994, 0.9991, 0.9996, 0.9988, 0.9996, 0.9992, 0.9990,
        0.9997, 0.9996, 0.9995, 0.9987, 0.9994, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 79 | Batch_idx: 0 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2668) |  Loss2: (0.0000) | Acc: (90.00%) (1275/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (2429/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (89.00%) (3566/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (89.00%) (4700/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2902) |  Loss2: (0.0000) | Acc: (89.00%) (5852/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (89.00%) (7018/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (8164/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (89.00%) (9328/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (89.00%) (10467/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2895) |  Loss2: (0.0000) | Acc: (89.00%) (11630/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2902) |  Loss2: (0.0000) | Acc: (89.00%) (12781/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (89.00%) (13931/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2920) |  Loss2: (0.0000) | Acc: (89.00%) (15083/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2918) |  Loss2: (0.0000) | Acc: (89.00%) (16242/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (89.00%) (17390/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2922) |  Loss2: (0.0000) | Acc: (90.00%) (18552/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2918) |  Loss2: (0.0000) | Acc: (89.00%) (19698/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (20821/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (21974/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2953) |  Loss2: (0.0000) | Acc: (89.00%) (23115/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (24271/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (89.00%) (25410/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2951) |  Loss2: (0.0000) | Acc: (89.00%) (26556/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (27701/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2947) |  Loss2: (0.0000) | Acc: (89.00%) (28860/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2941) |  Loss2: (0.0000) | Acc: (89.00%) (30007/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (31134/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (32278/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (33414/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (34558/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2974) |  Loss2: (0.0000) | Acc: (89.00%) (35699/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2966) |  Loss2: (0.0000) | Acc: (89.00%) (36859/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2959) |  Loss2: (0.0000) | Acc: (89.00%) (38024/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (39162/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2966) |  Loss2: (0.0000) | Acc: (89.00%) (40305/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (41443/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (42587/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (43736/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (89.00%) (44853/50000)
# TEST : Loss: (0.4148) | Acc: (86.00%) (8607/10000)
percent tensor([0.5075, 0.5107, 0.4999, 0.4929, 0.5049, 0.4915, 0.5105, 0.5019, 0.5172,
        0.5111, 0.5161, 0.5074, 0.5125, 0.5130, 0.4997, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.4834, 0.4790, 0.4790, 0.4803, 0.4802, 0.4814, 0.4805, 0.4813, 0.4812,
        0.4787, 0.4817, 0.4770, 0.4823, 0.4809, 0.4785, 0.4818],
       device='cuda:0') torch.Size([16])
percent tensor([0.5249, 0.4754, 0.5106, 0.5529, 0.5294, 0.5585, 0.4847, 0.5340, 0.5317,
        0.4777, 0.4913, 0.4541, 0.4761, 0.5681, 0.4905, 0.5306],
       device='cuda:0') torch.Size([16])
percent tensor([0.6373, 0.6522, 0.6047, 0.6119, 0.6118, 0.6160, 0.6455, 0.6232, 0.6372,
        0.6530, 0.6578, 0.6284, 0.6490, 0.6534, 0.6366, 0.6445],
       device='cuda:0') torch.Size([16])
percent tensor([0.5316, 0.5304, 0.6710, 0.6597, 0.6586, 0.5850, 0.5746, 0.6045, 0.6015,
        0.5566, 0.6069, 0.6206, 0.5119, 0.5913, 0.5395, 0.5420],
       device='cuda:0') torch.Size([16])
percent tensor([0.5626, 0.5574, 0.6003, 0.5958, 0.6254, 0.6397, 0.5745, 0.5355, 0.5950,
        0.5511, 0.5614, 0.5492, 0.5561, 0.5927, 0.5371, 0.5788],
       device='cuda:0') torch.Size([16])
percent tensor([0.6623, 0.6557, 0.7022, 0.6752, 0.7157, 0.7983, 0.6446, 0.4894, 0.7128,
        0.6792, 0.7057, 0.6836, 0.6724, 0.7201, 0.5625, 0.6976],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9990, 0.9994, 0.9992, 0.9996, 0.9989, 0.9996, 0.9993, 0.9991,
        0.9997, 0.9996, 0.9995, 0.9988, 0.9994, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 80 | Batch_idx: 0 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (1268/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (2428/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (90.00%) (3576/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (4723/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2889) |  Loss2: (0.0000) | Acc: (89.00%) (5873/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (89.00%) (7012/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2909) |  Loss2: (0.0000) | Acc: (89.00%) (8171/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2911) |  Loss2: (0.0000) | Acc: (89.00%) (9319/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (89.00%) (10460/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2929) |  Loss2: (0.0000) | Acc: (89.00%) (11606/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (12750/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (13889/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (15042/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2959) |  Loss2: (0.0000) | Acc: (89.00%) (16194/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (89.00%) (17341/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2968) |  Loss2: (0.0000) | Acc: (89.00%) (18473/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (19645/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (89.00%) (20799/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (21925/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2959) |  Loss2: (0.0000) | Acc: (89.00%) (23070/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2959) |  Loss2: (0.0000) | Acc: (89.00%) (24222/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (25385/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (89.00%) (26540/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (27700/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2965) |  Loss2: (0.0000) | Acc: (89.00%) (28828/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2966) |  Loss2: (0.0000) | Acc: (89.00%) (29974/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2964) |  Loss2: (0.0000) | Acc: (89.00%) (31127/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (32276/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (33407/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (89.00%) (34537/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2985) |  Loss2: (0.0000) | Acc: (89.00%) (35671/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2988) |  Loss2: (0.0000) | Acc: (89.00%) (36818/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2995) |  Loss2: (0.0000) | Acc: (89.00%) (37956/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.3001) |  Loss2: (0.0000) | Acc: (89.00%) (39090/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (89.00%) (40228/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (41353/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (42486/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (43644/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (44757/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_080.pth.tar'
# TEST : Loss: (0.4786) | Acc: (84.00%) (8401/10000)
percent tensor([0.5062, 0.5123, 0.4956, 0.4920, 0.5003, 0.4899, 0.5105, 0.5014, 0.5168,
        0.5112, 0.5167, 0.5037, 0.5123, 0.5173, 0.4988, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.4833, 0.4789, 0.4785, 0.4794, 0.4789, 0.4812, 0.4803, 0.4813, 0.4811,
        0.4781, 0.4818, 0.4758, 0.4826, 0.4797, 0.4782, 0.4818],
       device='cuda:0') torch.Size([16])
percent tensor([0.5258, 0.4765, 0.5065, 0.5565, 0.5287, 0.5607, 0.4915, 0.5371, 0.5333,
        0.4852, 0.4897, 0.4632, 0.4810, 0.5730, 0.4937, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.6386, 0.6521, 0.6082, 0.6128, 0.6107, 0.6210, 0.6424, 0.6201, 0.6414,
        0.6532, 0.6644, 0.6255, 0.6490, 0.6561, 0.6370, 0.6468],
       device='cuda:0') torch.Size([16])
percent tensor([0.5377, 0.5339, 0.6752, 0.6526, 0.6620, 0.5826, 0.5915, 0.6030, 0.6211,
        0.5723, 0.6048, 0.6358, 0.5274, 0.6068, 0.5437, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5445, 0.5996, 0.5999, 0.6377, 0.6387, 0.5731, 0.5598, 0.5884,
        0.5432, 0.5530, 0.5462, 0.5461, 0.5851, 0.5328, 0.5759],
       device='cuda:0') torch.Size([16])
percent tensor([0.6626, 0.6405, 0.6994, 0.6907, 0.7684, 0.8107, 0.6473, 0.5299, 0.6986,
        0.6435, 0.6928, 0.6601, 0.6611, 0.6991, 0.5323, 0.7089],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9993, 0.9992, 0.9996, 0.9993, 0.9996, 0.9991, 0.9986,
        0.9992, 0.9994, 0.9993, 0.9990, 0.9989, 0.9989, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(177.2863, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(808.6268, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(808.7896, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.2943, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(500.1587, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2214.7729, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4282.4692, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1409.5400, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6115.2568, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11939.6719, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3974.4312, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16774.0039, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 81 | Batch_idx: 0 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (1259/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (2408/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2937) |  Loss2: (0.0000) | Acc: (89.00%) (3568/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (4716/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2885) |  Loss2: (0.0000) | Acc: (90.00%) (5876/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (7042/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (89.00%) (8178/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2880) |  Loss2: (0.0000) | Acc: (89.00%) (9322/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (90.00%) (10485/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (11649/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (12811/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (13970/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (15123/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (16291/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (17424/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (90.00%) (18574/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (19722/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (20869/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (22019/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (23169/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (24335/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (25502/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (26651/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (27792/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2857) |  Loss2: (0.0000) | Acc: (90.00%) (28949/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (30104/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (90.00%) (31259/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (32410/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (90.00%) (33565/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (90.00%) (34714/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2868) |  Loss2: (0.0000) | Acc: (90.00%) (35871/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (90.00%) (37025/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2868) |  Loss2: (0.0000) | Acc: (90.00%) (38186/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (90.00%) (39330/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (40475/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2877) |  Loss2: (0.0000) | Acc: (90.00%) (41627/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2879) |  Loss2: (0.0000) | Acc: (90.00%) (42776/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (90.00%) (43930/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2881) |  Loss2: (0.0000) | Acc: (90.00%) (45040/50000)
# TEST : Loss: (0.4507) | Acc: (85.00%) (8529/10000)
percent tensor([0.5060, 0.5109, 0.4941, 0.4910, 0.5000, 0.4897, 0.5097, 0.4998, 0.5163,
        0.5099, 0.5161, 0.5031, 0.5116, 0.5163, 0.4986, 0.5025],
       device='cuda:0') torch.Size([16])
percent tensor([0.4834, 0.4795, 0.4782, 0.4800, 0.4791, 0.4817, 0.4803, 0.4812, 0.4809,
        0.4787, 0.4820, 0.4755, 0.4828, 0.4807, 0.4788, 0.4824],
       device='cuda:0') torch.Size([16])
percent tensor([0.5325, 0.4779, 0.5099, 0.5601, 0.5328, 0.5707, 0.4912, 0.5403, 0.5289,
        0.4807, 0.4890, 0.4628, 0.4791, 0.5712, 0.5001, 0.5357],
       device='cuda:0') torch.Size([16])
percent tensor([0.6381, 0.6512, 0.6091, 0.6117, 0.6113, 0.6188, 0.6447, 0.6217, 0.6364,
        0.6526, 0.6610, 0.6278, 0.6482, 0.6565, 0.6385, 0.6444],
       device='cuda:0') torch.Size([16])
percent tensor([0.5344, 0.5363, 0.6605, 0.6610, 0.6580, 0.5946, 0.5894, 0.5925, 0.6070,
        0.5676, 0.6086, 0.6204, 0.5210, 0.6042, 0.5431, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.5548, 0.5568, 0.6016, 0.6058, 0.6345, 0.6376, 0.5813, 0.5541, 0.5929,
        0.5533, 0.5517, 0.5524, 0.5477, 0.5855, 0.5375, 0.5870],
       device='cuda:0') torch.Size([16])
percent tensor([0.6682, 0.6661, 0.7353, 0.6959, 0.7787, 0.8021, 0.6620, 0.5350, 0.7062,
        0.7067, 0.7028, 0.7013, 0.6720, 0.7077, 0.5748, 0.7283],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9983, 0.9997, 0.9995, 0.9997, 0.9985, 0.9993, 0.9995, 0.9987,
        0.9994, 0.9995, 0.9995, 0.9988, 0.9991, 0.9990, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 82 | Batch_idx: 0 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2912) |  Loss2: (0.0000) | Acc: (90.00%) (1274/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2899) |  Loss2: (0.0000) | Acc: (90.00%) (2423/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2924) |  Loss2: (0.0000) | Acc: (89.00%) (3564/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (90.00%) (4724/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (5890/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (7053/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (8203/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (9372/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (90.00%) (10535/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (11704/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (12874/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (14021/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (15198/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (16366/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2773) |  Loss2: (0.0000) | Acc: (90.00%) (17512/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (18646/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (19805/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (20964/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (22121/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (23270/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (24432/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (25575/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (26730/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (27872/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (29020/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (30162/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (90.00%) (31323/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (32467/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (33638/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (34798/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (35939/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (90.00%) (37095/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (38248/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (90.00%) (39398/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (40548/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (41697/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (42848/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (44005/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (45113/50000)
# TEST : Loss: (0.4549) | Acc: (84.00%) (8488/10000)
percent tensor([0.5057, 0.5098, 0.4984, 0.4921, 0.5030, 0.4900, 0.5101, 0.5014, 0.5166,
        0.5104, 0.5153, 0.5063, 0.5113, 0.5134, 0.4984, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.4827, 0.4795, 0.4774, 0.4790, 0.4777, 0.4803, 0.4798, 0.4813, 0.4811,
        0.4785, 0.4825, 0.4746, 0.4827, 0.4818, 0.4783, 0.4818],
       device='cuda:0') torch.Size([16])
percent tensor([0.5233, 0.4745, 0.4993, 0.5488, 0.5230, 0.5616, 0.4849, 0.5284, 0.5249,
        0.4758, 0.4854, 0.4590, 0.4759, 0.5712, 0.4951, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.6360, 0.6539, 0.6082, 0.6105, 0.6112, 0.6181, 0.6475, 0.6232, 0.6390,
        0.6556, 0.6637, 0.6285, 0.6482, 0.6595, 0.6403, 0.6456],
       device='cuda:0') torch.Size([16])
percent tensor([0.5460, 0.5318, 0.6564, 0.6560, 0.6587, 0.6090, 0.5817, 0.5904, 0.6021,
        0.5649, 0.6077, 0.6173, 0.5245, 0.6019, 0.5468, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.5638, 0.5555, 0.5859, 0.5807, 0.6195, 0.6347, 0.5730, 0.5461, 0.5849,
        0.5582, 0.5600, 0.5351, 0.5535, 0.5865, 0.5332, 0.5814],
       device='cuda:0') torch.Size([16])
percent tensor([0.7043, 0.6884, 0.6971, 0.6488, 0.7460, 0.8096, 0.6506, 0.5095, 0.7207,
        0.7102, 0.7283, 0.6895, 0.6875, 0.7331, 0.5687, 0.7212],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9996, 0.9995, 0.9998, 0.9996, 0.9995, 0.9995, 0.9992,
        0.9995, 0.9997, 0.9994, 0.9990, 0.9995, 0.9991, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 83 | Batch_idx: 0 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (2420/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (90.00%) (3581/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (4734/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (5885/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (7044/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2808) |  Loss2: (0.0000) | Acc: (90.00%) (8221/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2794) |  Loss2: (0.0000) | Acc: (90.00%) (9391/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (10554/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (11706/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (12881/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (14042/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (15203/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (16371/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (17537/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (18713/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (19886/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (21039/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (22184/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (23339/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (24501/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (25652/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2737) |  Loss2: (0.0000) | Acc: (90.00%) (26802/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (27968/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (29123/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (30279/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (31452/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (32598/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (33764/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2737) |  Loss2: (0.0000) | Acc: (90.00%) (34911/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (36072/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (37210/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (38323/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (39477/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (40619/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (41769/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (42924/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (44076/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (45186/50000)
# TEST : Loss: (0.4436) | Acc: (85.00%) (8569/10000)
percent tensor([0.5056, 0.5110, 0.4958, 0.4923, 0.5013, 0.4899, 0.5098, 0.5012, 0.5163,
        0.5105, 0.5155, 0.5044, 0.5116, 0.5154, 0.4988, 0.5026],
       device='cuda:0') torch.Size([16])
percent tensor([0.4829, 0.4798, 0.4773, 0.4794, 0.4784, 0.4821, 0.4802, 0.4809, 0.4813,
        0.4785, 0.4825, 0.4741, 0.4825, 0.4816, 0.4790, 0.4823],
       device='cuda:0') torch.Size([16])
percent tensor([0.5318, 0.4811, 0.5002, 0.5515, 0.5225, 0.5674, 0.4934, 0.5368, 0.5329,
        0.4797, 0.4958, 0.4576, 0.4842, 0.5780, 0.5005, 0.5347],
       device='cuda:0') torch.Size([16])
percent tensor([0.6361, 0.6513, 0.6127, 0.6100, 0.6127, 0.6170, 0.6428, 0.6238, 0.6370,
        0.6547, 0.6622, 0.6313, 0.6480, 0.6510, 0.6376, 0.6426],
       device='cuda:0') torch.Size([16])
percent tensor([0.5407, 0.5246, 0.6600, 0.6603, 0.6665, 0.6017, 0.5797, 0.6058, 0.6111,
        0.5624, 0.5996, 0.6189, 0.5248, 0.5793, 0.5382, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5589, 0.5798, 0.5859, 0.6243, 0.6322, 0.5803, 0.5493, 0.5999,
        0.5526, 0.5643, 0.5291, 0.5560, 0.5897, 0.5310, 0.5745],
       device='cuda:0') torch.Size([16])
percent tensor([0.6827, 0.6738, 0.6999, 0.6755, 0.7578, 0.8046, 0.6433, 0.5332, 0.7363,
        0.6838, 0.7202, 0.6616, 0.6732, 0.7108, 0.5504, 0.7031],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9980, 0.9997, 0.9995, 0.9997, 0.9989, 0.9994, 0.9996, 0.9988,
        0.9995, 0.9996, 0.9998, 0.9986, 0.9982, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 84 | Batch_idx: 0 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (88.00%) (1252/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.3220) |  Loss2: (0.0000) | Acc: (88.00%) (2388/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.3397) |  Loss2: (0.0000) | Acc: (88.00%) (3504/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (87.00%) (4612/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (5722/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (6843/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (7969/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (9079/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (10200/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (11337/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (12469/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (87.00%) (13605/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (14740/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (87.00%) (15876/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.3494) |  Loss2: (0.0000) | Acc: (87.00%) (17002/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.3487) |  Loss2: (0.0000) | Acc: (88.00%) (18138/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.3472) |  Loss2: (0.0000) | Acc: (88.00%) (19271/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (88.00%) (20423/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.3446) |  Loss2: (0.0000) | Acc: (88.00%) (21543/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.3433) |  Loss2: (0.0000) | Acc: (88.00%) (22681/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.3424) |  Loss2: (0.0000) | Acc: (88.00%) (23812/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.3405) |  Loss2: (0.0000) | Acc: (88.00%) (24964/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (88.00%) (26120/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (27249/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (88.00%) (28382/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.3367) |  Loss2: (0.0000) | Acc: (88.00%) (29518/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.3366) |  Loss2: (0.0000) | Acc: (88.00%) (30658/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (31801/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (32952/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.3339) |  Loss2: (0.0000) | Acc: (88.00%) (34095/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.3333) |  Loss2: (0.0000) | Acc: (88.00%) (35235/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (36386/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (37541/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (38678/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.3293) |  Loss2: (0.0000) | Acc: (88.00%) (39826/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.3288) |  Loss2: (0.0000) | Acc: (88.00%) (40968/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (42121/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (43252/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.3265) |  Loss2: (0.0000) | Acc: (88.00%) (44368/50000)
# TEST : Loss: (0.4418) | Acc: (85.00%) (8571/10000)
percent tensor([0.5350, 0.5458, 0.5223, 0.5210, 0.5319, 0.5190, 0.5444, 0.5320, 0.5491,
        0.5429, 0.5485, 0.5352, 0.5420, 0.5495, 0.5316, 0.5327],
       device='cuda:0') torch.Size([16])
percent tensor([0.4858, 0.4846, 0.4782, 0.4812, 0.4799, 0.4840, 0.4839, 0.4834, 0.4849,
        0.4822, 0.4870, 0.4761, 0.4865, 0.4872, 0.4818, 0.4854],
       device='cuda:0') torch.Size([16])
percent tensor([0.5492, 0.5061, 0.4989, 0.5576, 0.5241, 0.5851, 0.5089, 0.5374, 0.5478,
        0.5022, 0.5236, 0.4602, 0.5102, 0.5995, 0.5132, 0.5517],
       device='cuda:0') torch.Size([16])
percent tensor([0.6343, 0.6549, 0.6046, 0.6005, 0.6041, 0.6115, 0.6414, 0.6153, 0.6349,
        0.6582, 0.6629, 0.6272, 0.6502, 0.6529, 0.6328, 0.6419],
       device='cuda:0') torch.Size([16])
percent tensor([0.5581, 0.5375, 0.6554, 0.6668, 0.6796, 0.6462, 0.5914, 0.6135, 0.6205,
        0.5708, 0.6108, 0.6044, 0.5407, 0.5797, 0.5582, 0.5844],
       device='cuda:0') torch.Size([16])
percent tensor([0.6411, 0.6374, 0.6507, 0.6585, 0.6845, 0.6879, 0.6636, 0.6265, 0.6691,
        0.6401, 0.6460, 0.6159, 0.6366, 0.6661, 0.6142, 0.6552],
       device='cuda:0') torch.Size([16])
percent tensor([0.6480, 0.6255, 0.6875, 0.6662, 0.7223, 0.7803, 0.6044, 0.4778, 0.7314,
        0.6745, 0.7168, 0.6638, 0.6368, 0.6922, 0.5044, 0.6489],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9980, 0.9996, 0.9994, 0.9995, 0.9991, 0.9994, 0.9994, 0.9992,
        0.9994, 0.9997, 0.9997, 0.9985, 0.9979, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 85 | Batch_idx: 0 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (1279/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (2442/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (90.00%) (3577/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2890) |  Loss2: (0.0000) | Acc: (90.00%) (4739/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (5851/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (6993/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (8144/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (9295/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (10446/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.3100) |  Loss2: (0.0000) | Acc: (89.00%) (11574/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (12726/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.3082) |  Loss2: (0.0000) | Acc: (89.00%) (13868/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.3072) |  Loss2: (0.0000) | Acc: (89.00%) (15026/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.3036) |  Loss2: (0.0000) | Acc: (89.00%) (16199/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (17340/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (18496/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (19637/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (20798/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (21937/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (23102/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (24243/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.3008) |  Loss2: (0.0000) | Acc: (89.00%) (25397/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (26548/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (27693/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2999) |  Loss2: (0.0000) | Acc: (89.00%) (28847/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2999) |  Loss2: (0.0000) | Acc: (89.00%) (29993/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (31164/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2972) |  Loss2: (0.0000) | Acc: (89.00%) (32323/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2964) |  Loss2: (0.0000) | Acc: (89.00%) (33481/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2970) |  Loss2: (0.0000) | Acc: (89.00%) (34627/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (35788/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2951) |  Loss2: (0.0000) | Acc: (89.00%) (36953/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (38126/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2947) |  Loss2: (0.0000) | Acc: (89.00%) (39264/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (40430/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (41587/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2932) |  Loss2: (0.0000) | Acc: (90.00%) (42742/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2927) |  Loss2: (0.0000) | Acc: (90.00%) (43903/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (90.00%) (45020/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_085.pth.tar'
# TEST : Loss: (0.4240) | Acc: (86.00%) (8613/10000)
percent tensor([0.5300, 0.5392, 0.5176, 0.5158, 0.5266, 0.5135, 0.5382, 0.5266, 0.5436,
        0.5371, 0.5426, 0.5301, 0.5367, 0.5440, 0.5252, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.4855, 0.4846, 0.4772, 0.4804, 0.4790, 0.4835, 0.4835, 0.4827, 0.4846,
        0.4819, 0.4872, 0.4754, 0.4866, 0.4870, 0.4814, 0.4853],
       device='cuda:0') torch.Size([16])
percent tensor([0.5443, 0.5051, 0.4865, 0.5524, 0.5095, 0.5818, 0.5017, 0.5278, 0.5430,
        0.4995, 0.5228, 0.4500, 0.5069, 0.6016, 0.5080, 0.5501],
       device='cuda:0') torch.Size([16])
percent tensor([0.6384, 0.6646, 0.6031, 0.6009, 0.6033, 0.6114, 0.6478, 0.6167, 0.6404,
        0.6668, 0.6726, 0.6302, 0.6586, 0.6634, 0.6364, 0.6479],
       device='cuda:0') torch.Size([16])
percent tensor([0.5626, 0.5429, 0.6598, 0.6727, 0.6843, 0.6595, 0.5918, 0.6141, 0.6260,
        0.5771, 0.6170, 0.6059, 0.5482, 0.5886, 0.5619, 0.5952],
       device='cuda:0') torch.Size([16])
percent tensor([0.6349, 0.6357, 0.6504, 0.6572, 0.6809, 0.6856, 0.6603, 0.6152, 0.6713,
        0.6387, 0.6460, 0.6210, 0.6365, 0.6677, 0.6087, 0.6482],
       device='cuda:0') torch.Size([16])
percent tensor([0.6581, 0.6375, 0.7011, 0.6799, 0.7340, 0.7886, 0.6148, 0.4714, 0.7547,
        0.6895, 0.7298, 0.6798, 0.6485, 0.7104, 0.5027, 0.6551],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9983, 0.9996, 0.9993, 0.9996, 0.9991, 0.9994, 0.9994, 0.9993,
        0.9994, 0.9997, 0.9997, 0.9987, 0.9982, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 86 | Batch_idx: 0 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (91.00%) (2457/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (3591/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (4742/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (5899/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (7055/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (8197/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (9382/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (10534/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (90.00%) (11686/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (12828/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (13977/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (15151/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (16306/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (17447/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (18597/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (19753/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (20917/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2789) |  Loss2: (0.0000) | Acc: (90.00%) (22086/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (23249/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2776) |  Loss2: (0.0000) | Acc: (90.00%) (24402/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (25552/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (26705/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2773) |  Loss2: (0.0000) | Acc: (90.00%) (27873/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (29039/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (30201/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (31352/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (32496/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (33653/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (34813/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (35973/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (37125/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (38281/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (39452/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2770) |  Loss2: (0.0000) | Acc: (90.00%) (40627/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (41780/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2773) |  Loss2: (0.0000) | Acc: (90.00%) (42942/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (44103/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (45218/50000)
# TEST : Loss: (0.4146) | Acc: (86.00%) (8645/10000)
percent tensor([0.5293, 0.5378, 0.5175, 0.5155, 0.5260, 0.5129, 0.5371, 0.5260, 0.5428,
        0.5362, 0.5413, 0.5297, 0.5358, 0.5429, 0.5241, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.4858, 0.4852, 0.4774, 0.4807, 0.4793, 0.4837, 0.4840, 0.4830, 0.4850,
        0.4825, 0.4878, 0.4759, 0.4871, 0.4876, 0.4818, 0.4857],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.5040, 0.4842, 0.5528, 0.5060, 0.5805, 0.4990, 0.5260, 0.5415,
        0.4989, 0.5217, 0.4481, 0.5048, 0.6015, 0.5061, 0.5490],
       device='cuda:0') torch.Size([16])
percent tensor([0.6298, 0.6601, 0.5932, 0.5923, 0.5937, 0.6023, 0.6407, 0.6074, 0.6330,
        0.6610, 0.6667, 0.6214, 0.6526, 0.6593, 0.6275, 0.6409],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.5343, 0.6593, 0.6730, 0.6852, 0.6616, 0.5830, 0.6112, 0.6231,
        0.5684, 0.6083, 0.6012, 0.5422, 0.5811, 0.5579, 0.5907],
       device='cuda:0') torch.Size([16])
percent tensor([0.6188, 0.6217, 0.6401, 0.6455, 0.6680, 0.6749, 0.6449, 0.5933, 0.6627,
        0.6243, 0.6346, 0.6146, 0.6249, 0.6567, 0.5920, 0.6305],
       device='cuda:0') torch.Size([16])
percent tensor([0.6622, 0.6339, 0.7039, 0.6852, 0.7397, 0.7900, 0.6134, 0.4705, 0.7592,
        0.6937, 0.7272, 0.6869, 0.6504, 0.7091, 0.4982, 0.6561],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9984, 0.9996, 0.9993, 0.9996, 0.9991, 0.9995, 0.9994, 0.9992,
        0.9994, 0.9997, 0.9997, 0.9987, 0.9983, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 87 | Batch_idx: 0 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (1294/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (91.00%) (2463/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (3629/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (4789/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (91.00%) (5964/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (7138/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (91.00%) (8290/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2622) |  Loss2: (0.0000) | Acc: (91.00%) (9454/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (91.00%) (10618/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (91.00%) (11783/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (91.00%) (12938/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (91.00%) (14108/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (15253/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (16415/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (90.00%) (17584/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (18744/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2668) |  Loss2: (0.0000) | Acc: (90.00%) (19902/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (21046/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (22210/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (23375/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (24544/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (25709/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (26868/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (28028/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (90.00%) (29196/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (30368/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (31530/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (32687/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (33852/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (34998/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (36152/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (37300/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (38453/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (39606/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (40771/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (41933/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (43098/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (44260/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2690) |  Loss2: (0.0000) | Acc: (90.00%) (45379/50000)
# TEST : Loss: (0.4099) | Acc: (86.00%) (8630/10000)
percent tensor([0.5245, 0.5322, 0.5128, 0.5107, 0.5206, 0.5079, 0.5316, 0.5208, 0.5376,
        0.5309, 0.5359, 0.5246, 0.5308, 0.5381, 0.5186, 0.5218],
       device='cuda:0') torch.Size([16])
percent tensor([0.4866, 0.4862, 0.4782, 0.4814, 0.4800, 0.4844, 0.4850, 0.4839, 0.4859,
        0.4835, 0.4889, 0.4767, 0.4881, 0.4886, 0.4826, 0.4866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5413, 0.5061, 0.4820, 0.5534, 0.5034, 0.5805, 0.4990, 0.5261, 0.5412,
        0.4997, 0.5237, 0.4472, 0.5052, 0.6035, 0.5072, 0.5496],
       device='cuda:0') torch.Size([16])
percent tensor([0.6353, 0.6680, 0.5972, 0.5959, 0.5967, 0.6047, 0.6473, 0.6112, 0.6393,
        0.6688, 0.6744, 0.6270, 0.6602, 0.6670, 0.6320, 0.6467],
       device='cuda:0') torch.Size([16])
percent tensor([0.5479, 0.5229, 0.6481, 0.6641, 0.6759, 0.6528, 0.5703, 0.5997, 0.6109,
        0.5548, 0.5957, 0.5901, 0.5283, 0.5721, 0.5472, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.6248, 0.6309, 0.6449, 0.6500, 0.6709, 0.6791, 0.6518, 0.5955, 0.6679,
        0.6320, 0.6417, 0.6231, 0.6329, 0.6662, 0.5989, 0.6373],
       device='cuda:0') torch.Size([16])
percent tensor([0.6848, 0.6579, 0.7078, 0.6965, 0.7421, 0.7977, 0.6309, 0.4762, 0.7708,
        0.7116, 0.7447, 0.6957, 0.6663, 0.7248, 0.5132, 0.6772],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9985, 0.9996, 0.9994, 0.9996, 0.9992, 0.9996, 0.9993, 0.9994,
        0.9995, 0.9998, 0.9997, 0.9989, 0.9985, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (2441/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (3602/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2596) |  Loss2: (0.0000) | Acc: (91.00%) (4777/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (91.00%) (5949/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2617) |  Loss2: (0.0000) | Acc: (91.00%) (7119/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (91.00%) (8293/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (9465/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (91.00%) (10632/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (91.00%) (11786/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (91.00%) (12935/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2656) |  Loss2: (0.0000) | Acc: (91.00%) (14095/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2646) |  Loss2: (0.0000) | Acc: (90.00%) (15254/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (16411/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (17557/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (18718/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (19876/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (21032/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (22189/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2682) |  Loss2: (0.0000) | Acc: (90.00%) (23360/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (24503/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (25658/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (26810/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (27969/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2706) |  Loss2: (0.0000) | Acc: (90.00%) (29125/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (30281/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2706) |  Loss2: (0.0000) | Acc: (90.00%) (31441/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (32603/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (33764/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2706) |  Loss2: (0.0000) | Acc: (90.00%) (34932/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (36093/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (37246/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (38393/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (39551/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (40718/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (41876/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (43044/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (44210/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (45326/50000)
# TEST : Loss: (0.4569) | Acc: (84.00%) (8493/10000)
percent tensor([0.5249, 0.5297, 0.5164, 0.5105, 0.5238, 0.5083, 0.5311, 0.5204, 0.5379,
        0.5307, 0.5358, 0.5270, 0.5306, 0.5338, 0.5177, 0.5212],
       device='cuda:0') torch.Size([16])
percent tensor([0.4874, 0.4864, 0.4811, 0.4830, 0.4818, 0.4844, 0.4854, 0.4855, 0.4860,
        0.4844, 0.4881, 0.4792, 0.4886, 0.4876, 0.4830, 0.4868],
       device='cuda:0') torch.Size([16])
percent tensor([0.5428, 0.4973, 0.5109, 0.5668, 0.5259, 0.5863, 0.4968, 0.5343, 0.5451,
        0.4999, 0.5153, 0.4674, 0.5010, 0.5965, 0.5050, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.6292, 0.6636, 0.5903, 0.5949, 0.5935, 0.6009, 0.6454, 0.6071, 0.6356,
        0.6648, 0.6759, 0.6220, 0.6546, 0.6639, 0.6284, 0.6417],
       device='cuda:0') torch.Size([16])
percent tensor([0.5594, 0.5398, 0.6844, 0.6678, 0.6884, 0.6392, 0.5978, 0.6066, 0.6189,
        0.5693, 0.6237, 0.6201, 0.5381, 0.5988, 0.5625, 0.5895],
       device='cuda:0') torch.Size([16])
percent tensor([0.6394, 0.6389, 0.6655, 0.6621, 0.6825, 0.6845, 0.6692, 0.6151, 0.6655,
        0.6422, 0.6499, 0.6486, 0.6383, 0.6639, 0.6287, 0.6510],
       device='cuda:0') torch.Size([16])
percent tensor([0.7173, 0.7068, 0.7589, 0.7070, 0.7765, 0.8179, 0.6854, 0.5288, 0.7515,
        0.7425, 0.7473, 0.7172, 0.6945, 0.7157, 0.5818, 0.7284],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9996, 0.9990, 0.9996, 0.9991, 0.9996, 0.9992, 0.9991,
        0.9994, 0.9998, 0.9991, 0.9993, 0.9991, 0.9992, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 89 | Batch_idx: 0 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (90.00%) (2445/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (91.00%) (3615/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (4773/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (91.00%) (5942/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2629) |  Loss2: (0.0000) | Acc: (91.00%) (7112/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (8269/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (91.00%) (9444/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (91.00%) (10618/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (90.00%) (11760/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (12916/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (90.00%) (14082/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (91.00%) (15260/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (16412/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (17579/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (18740/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (19892/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (21074/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (22229/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (23401/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (24576/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (25729/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (26864/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (28034/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (29193/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (30373/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (31522/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (32665/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (33820/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (34981/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (36133/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (90.00%) (37315/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (90.00%) (38486/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (39655/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (40830/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (41985/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (43158/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (44326/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (45428/50000)
# TEST : Loss: (0.4777) | Acc: (84.00%) (8423/10000)
percent tensor([0.5254, 0.5317, 0.5161, 0.5129, 0.5234, 0.5094, 0.5323, 0.5216, 0.5384,
        0.5321, 0.5364, 0.5271, 0.5314, 0.5375, 0.5187, 0.5225],
       device='cuda:0') torch.Size([16])
percent tensor([0.4870, 0.4852, 0.4810, 0.4822, 0.4818, 0.4834, 0.4850, 0.4856, 0.4860,
        0.4837, 0.4880, 0.4787, 0.4884, 0.4861, 0.4819, 0.4860],
       device='cuda:0') torch.Size([16])
percent tensor([0.5416, 0.4870, 0.5146, 0.5619, 0.5271, 0.5838, 0.4919, 0.5345, 0.5453,
        0.4925, 0.5101, 0.4614, 0.4982, 0.5924, 0.4958, 0.5488],
       device='cuda:0') torch.Size([16])
percent tensor([0.6299, 0.6595, 0.5904, 0.5934, 0.5955, 0.6017, 0.6391, 0.6071, 0.6341,
        0.6615, 0.6681, 0.6193, 0.6528, 0.6599, 0.6279, 0.6413],
       device='cuda:0') torch.Size([16])
percent tensor([0.5453, 0.5268, 0.6787, 0.6716, 0.6906, 0.6350, 0.5843, 0.6096, 0.6169,
        0.5490, 0.6041, 0.6149, 0.5301, 0.5899, 0.5515, 0.5741],
       device='cuda:0') torch.Size([16])
percent tensor([0.6195, 0.6109, 0.6577, 0.6606, 0.6767, 0.6853, 0.6394, 0.5987, 0.6556,
        0.6118, 0.6270, 0.6284, 0.6194, 0.6525, 0.6022, 0.6324],
       device='cuda:0') torch.Size([16])
percent tensor([0.6666, 0.6274, 0.7425, 0.7009, 0.7636, 0.8021, 0.6282, 0.4862, 0.7183,
        0.6833, 0.6942, 0.6901, 0.6778, 0.6893, 0.5220, 0.6881],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9997, 0.9995, 0.9997, 0.9992, 0.9995, 0.9994, 0.9988,
        0.9995, 0.9994, 0.9995, 0.9993, 0.9989, 0.9992, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 90 | Batch_idx: 0 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (92.00%) (2489/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (3645/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (4827/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (5985/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (7160/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (8325/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (9487/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (10648/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (11815/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (12987/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (14140/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (15306/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (16480/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (17643/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (18808/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (19941/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (21120/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (91.00%) (22277/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (23441/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (24616/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (25781/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (26955/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (28109/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (29279/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (30451/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (31617/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (91.00%) (32772/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (33938/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (91.00%) (35104/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (36270/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (37431/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (91.00%) (38593/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2565) |  Loss2: (0.0000) | Acc: (91.00%) (39768/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2572) |  Loss2: (0.0000) | Acc: (91.00%) (40927/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (42083/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2578) |  Loss2: (0.0000) | Acc: (91.00%) (43259/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (44424/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (91.00%) (45538/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_090.pth.tar'
# TEST : Loss: (0.4631) | Acc: (84.00%) (8494/10000)
percent tensor([0.5257, 0.5315, 0.5180, 0.5127, 0.5247, 0.5098, 0.5324, 0.5225, 0.5387,
        0.5318, 0.5365, 0.5278, 0.5311, 0.5367, 0.5189, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.4870, 0.4855, 0.4823, 0.4833, 0.4829, 0.4842, 0.4859, 0.4859, 0.4862,
        0.4844, 0.4878, 0.4801, 0.4881, 0.4875, 0.4827, 0.4864],
       device='cuda:0') torch.Size([16])
percent tensor([0.5317, 0.4876, 0.5107, 0.5649, 0.5230, 0.5833, 0.4909, 0.5329, 0.5405,
        0.4889, 0.5084, 0.4638, 0.4858, 0.5875, 0.5000, 0.5438],
       device='cuda:0') torch.Size([16])
percent tensor([0.6309, 0.6602, 0.5928, 0.5952, 0.5933, 0.6018, 0.6412, 0.6096, 0.6374,
        0.6639, 0.6715, 0.6212, 0.6549, 0.6613, 0.6281, 0.6416],
       device='cuda:0') torch.Size([16])
percent tensor([0.5482, 0.5389, 0.6672, 0.6710, 0.6858, 0.6432, 0.5863, 0.6138, 0.6091,
        0.5570, 0.6164, 0.6035, 0.5315, 0.5991, 0.5574, 0.5785],
       device='cuda:0') torch.Size([16])
percent tensor([0.6287, 0.6269, 0.6534, 0.6548, 0.6691, 0.6863, 0.6433, 0.5882, 0.6601,
        0.6300, 0.6377, 0.6346, 0.6298, 0.6657, 0.6108, 0.6366],
       device='cuda:0') torch.Size([16])
percent tensor([0.6843, 0.6724, 0.6950, 0.6599, 0.7380, 0.8138, 0.6363, 0.4598, 0.7148,
        0.6919, 0.7301, 0.6794, 0.6737, 0.7470, 0.5508, 0.6972],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9985, 0.9996, 0.9994, 0.9997, 0.9986, 0.9998, 0.9995, 0.9989,
        0.9995, 0.9996, 0.9997, 0.9991, 0.9985, 0.9992, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.8029, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(812.7704, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(813.4594, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.4078, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(498.5024, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2225.2266, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4281.7627, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1404.5803, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6133.7368, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11906.5566, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3959.0229, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16705.9414, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 91 | Batch_idx: 0 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (2485/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (3641/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (4814/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (5977/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (7144/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (8315/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (9484/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (10625/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (11801/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (12951/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (14118/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (15288/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (16457/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (17621/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (18789/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (19958/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (21107/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (22272/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (23431/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (24604/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (25755/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (26942/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (28099/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (29254/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (30420/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (31577/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (32749/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (33910/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (35062/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (90.00%) (36215/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (90.00%) (37386/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (38562/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (39737/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (40911/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (42096/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (43257/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (44420/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (45554/50000)
# TEST : Loss: (0.4308) | Acc: (85.00%) (8583/10000)
percent tensor([0.5264, 0.5316, 0.5154, 0.5119, 0.5229, 0.5100, 0.5320, 0.5208, 0.5387,
        0.5315, 0.5374, 0.5265, 0.5321, 0.5363, 0.5192, 0.5227],
       device='cuda:0') torch.Size([16])
percent tensor([0.4871, 0.4864, 0.4794, 0.4819, 0.4805, 0.4846, 0.4853, 0.4855, 0.4858,
        0.4837, 0.4884, 0.4773, 0.4881, 0.4873, 0.4831, 0.4869],
       device='cuda:0') torch.Size([16])
percent tensor([0.5405, 0.4960, 0.4963, 0.5573, 0.5162, 0.5816, 0.4967, 0.5352, 0.5490,
        0.4954, 0.5170, 0.4638, 0.4978, 0.5972, 0.5065, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6335, 0.6614, 0.5982, 0.6035, 0.5981, 0.6039, 0.6425, 0.6148, 0.6411,
        0.6655, 0.6720, 0.6250, 0.6572, 0.6612, 0.6310, 0.6456],
       device='cuda:0') torch.Size([16])
percent tensor([0.5582, 0.5401, 0.6754, 0.6740, 0.6846, 0.6494, 0.5914, 0.6027, 0.6241,
        0.5688, 0.6251, 0.6256, 0.5343, 0.6056, 0.5573, 0.5787],
       device='cuda:0') torch.Size([16])
percent tensor([0.6293, 0.6307, 0.6583, 0.6575, 0.6740, 0.6852, 0.6510, 0.5978, 0.6697,
        0.6378, 0.6439, 0.6384, 0.6351, 0.6706, 0.6119, 0.6382],
       device='cuda:0') torch.Size([16])
percent tensor([0.6933, 0.6854, 0.7413, 0.7010, 0.7753, 0.8060, 0.6522, 0.5003, 0.7687,
        0.7174, 0.7389, 0.7044, 0.6946, 0.7370, 0.5645, 0.6983],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9986, 0.9996, 0.9995, 0.9997, 0.9991, 0.9995, 0.9996, 0.9988,
        0.9992, 0.9998, 0.9994, 0.9991, 0.9986, 0.9992, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 92 | Batch_idx: 0 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (90.00%) (2434/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (89.00%) (3558/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (4694/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (5839/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2917) |  Loss2: (0.0000) | Acc: (89.00%) (6997/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2883) |  Loss2: (0.0000) | Acc: (89.00%) (8158/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (89.00%) (9326/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (89.00%) (10468/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (89.00%) (11621/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (89.00%) (12768/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (89.00%) (13927/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (89.00%) (15078/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (89.00%) (16239/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (89.00%) (17394/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (18558/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (19711/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (20874/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (22034/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (23183/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (24350/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (25491/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2789) |  Loss2: (0.0000) | Acc: (90.00%) (26647/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2776) |  Loss2: (0.0000) | Acc: (90.00%) (27802/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (28971/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (30136/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (31313/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (32479/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (33653/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (34807/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (35953/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (37129/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (38271/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (39431/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (40600/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (41762/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2698) |  Loss2: (0.0000) | Acc: (90.00%) (42918/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (44095/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (45219/50000)
# TEST : Loss: (0.4205) | Acc: (86.00%) (8616/10000)
percent tensor([0.5496, 0.5588, 0.5349, 0.5320, 0.5456, 0.5303, 0.5586, 0.5430, 0.5656,
        0.5571, 0.5646, 0.5502, 0.5569, 0.5637, 0.5430, 0.5452],
       device='cuda:0') torch.Size([16])
percent tensor([0.4846, 0.4862, 0.4756, 0.4792, 0.4769, 0.4818, 0.4842, 0.4830, 0.4836,
        0.4826, 0.4872, 0.4746, 0.4865, 0.4870, 0.4810, 0.4851],
       device='cuda:0') torch.Size([16])
percent tensor([0.5383, 0.4989, 0.4951, 0.5545, 0.5135, 0.5760, 0.5000, 0.5303, 0.5521,
        0.5037, 0.5247, 0.4657, 0.5006, 0.6027, 0.5050, 0.5454],
       device='cuda:0') torch.Size([16])
percent tensor([0.6372, 0.6705, 0.5941, 0.5977, 0.5929, 0.6009, 0.6457, 0.6113, 0.6453,
        0.6725, 0.6787, 0.6260, 0.6660, 0.6683, 0.6323, 0.6476],
       device='cuda:0') torch.Size([16])
percent tensor([0.5959, 0.5667, 0.7224, 0.7227, 0.7419, 0.7071, 0.6366, 0.6634, 0.6553,
        0.5837, 0.6448, 0.6617, 0.5573, 0.6293, 0.6064, 0.6205],
       device='cuda:0') torch.Size([16])
percent tensor([0.6403, 0.6391, 0.6675, 0.6656, 0.6856, 0.6937, 0.6572, 0.6095, 0.6793,
        0.6468, 0.6556, 0.6483, 0.6449, 0.6797, 0.6201, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.6565, 0.6525, 0.7431, 0.7018, 0.7858, 0.7866, 0.6205, 0.5063, 0.7402,
        0.6903, 0.7103, 0.7039, 0.6427, 0.7109, 0.5418, 0.6468],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9986, 0.9995, 0.9995, 0.9995, 0.9991, 0.9996, 0.9996, 0.9990,
        0.9992, 0.9997, 0.9994, 0.9991, 0.9987, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 93 | Batch_idx: 0 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (1288/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (2456/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (3640/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (4805/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (5965/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (7130/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (8287/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (9463/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (10639/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (11807/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (12956/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (14114/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (15293/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (16453/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (91.00%) (17625/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (18777/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (19946/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (21127/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (22303/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (23463/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (24641/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (25819/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (26970/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (28144/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (29315/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (30472/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (31635/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (32818/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (33985/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (35166/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (36339/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (37512/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (38686/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (39864/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (41043/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (42216/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (43377/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (44564/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (45706/50000)
# TEST : Loss: (0.4064) | Acc: (86.00%) (8642/10000)
percent tensor([0.5476, 0.5565, 0.5318, 0.5293, 0.5426, 0.5272, 0.5562, 0.5402, 0.5641,
        0.5549, 0.5628, 0.5475, 0.5550, 0.5630, 0.5399, 0.5428],
       device='cuda:0') torch.Size([16])
percent tensor([0.4854, 0.4878, 0.4751, 0.4795, 0.4764, 0.4823, 0.4853, 0.4832, 0.4845,
        0.4837, 0.4888, 0.4747, 0.4877, 0.4887, 0.4820, 0.4862],
       device='cuda:0') torch.Size([16])
percent tensor([0.5348, 0.4993, 0.4906, 0.5512, 0.5080, 0.5687, 0.4999, 0.5283, 0.5526,
        0.5050, 0.5263, 0.4648, 0.4990, 0.6058, 0.5015, 0.5422],
       device='cuda:0') torch.Size([16])
percent tensor([0.6385, 0.6749, 0.5929, 0.5967, 0.5914, 0.5983, 0.6481, 0.6110, 0.6467,
        0.6761, 0.6831, 0.6269, 0.6697, 0.6718, 0.6328, 0.6488],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.5482, 0.7203, 0.7267, 0.7431, 0.7093, 0.6279, 0.6629, 0.6433,
        0.5595, 0.6214, 0.6507, 0.5359, 0.6170, 0.5999, 0.6090],
       device='cuda:0') torch.Size([16])
percent tensor([0.6453, 0.6448, 0.6736, 0.6711, 0.6916, 0.6989, 0.6636, 0.6159, 0.6833,
        0.6509, 0.6582, 0.6523, 0.6506, 0.6837, 0.6257, 0.6541],
       device='cuda:0') torch.Size([16])
percent tensor([0.6523, 0.6565, 0.7463, 0.6991, 0.7878, 0.7864, 0.6200, 0.5027, 0.7406,
        0.6855, 0.7099, 0.7018, 0.6450, 0.7088, 0.5335, 0.6406],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9987, 0.9996, 0.9995, 0.9996, 0.9991, 0.9996, 0.9996, 0.9990,
        0.9992, 0.9997, 0.9994, 0.9991, 0.9988, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 94 | Batch_idx: 0 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (1287/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (2455/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (3619/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (4789/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (5952/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (7123/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (8288/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (9460/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (10604/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (11766/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (12942/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (14127/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (15291/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (16468/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (17641/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (18812/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (19980/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (21162/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (22339/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (23493/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (24660/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (25847/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (27016/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (91.00%) (28196/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (29388/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (30556/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (31724/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (32904/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (34079/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (35264/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2428) |  Loss2: (0.0000) | Acc: (91.00%) (36445/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (37620/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (38794/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2428) |  Loss2: (0.0000) | Acc: (91.00%) (39970/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (41166/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (42357/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (91.00%) (43545/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (44712/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (45830/50000)
# TEST : Loss: (0.3973) | Acc: (86.00%) (8679/10000)
percent tensor([0.5443, 0.5526, 0.5278, 0.5255, 0.5384, 0.5234, 0.5523, 0.5364, 0.5608,
        0.5512, 0.5593, 0.5435, 0.5515, 0.5602, 0.5358, 0.5393],
       device='cuda:0') torch.Size([16])
percent tensor([0.4873, 0.4903, 0.4762, 0.4808, 0.4775, 0.4837, 0.4874, 0.4848, 0.4867,
        0.4859, 0.4915, 0.4761, 0.4898, 0.4916, 0.4839, 0.4882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5352, 0.5014, 0.4920, 0.5526, 0.5075, 0.5680, 0.5014, 0.5304, 0.5561,
        0.5079, 0.5304, 0.4670, 0.5004, 0.6122, 0.5013, 0.5430],
       device='cuda:0') torch.Size([16])
percent tensor([0.6403, 0.6777, 0.5946, 0.5978, 0.5924, 0.5978, 0.6506, 0.6129, 0.6487,
        0.6795, 0.6863, 0.6292, 0.6728, 0.6744, 0.6336, 0.6506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5691, 0.5377, 0.7087, 0.7203, 0.7367, 0.7036, 0.6187, 0.6539, 0.6304,
        0.5435, 0.6067, 0.6361, 0.5196, 0.6088, 0.5917, 0.5969],
       device='cuda:0') torch.Size([16])
percent tensor([0.6413, 0.6422, 0.6707, 0.6677, 0.6883, 0.6966, 0.6599, 0.6117, 0.6795,
        0.6460, 0.6533, 0.6467, 0.6478, 0.6801, 0.6216, 0.6515],
       device='cuda:0') torch.Size([16])
percent tensor([0.6588, 0.6669, 0.7566, 0.7039, 0.7926, 0.7926, 0.6246, 0.5021, 0.7507,
        0.6888, 0.7230, 0.7090, 0.6543, 0.7154, 0.5363, 0.6420],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9987, 0.9996, 0.9995, 0.9996, 0.9990, 0.9996, 0.9996, 0.9991,
        0.9993, 0.9997, 0.9995, 0.9991, 0.9989, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 95 | Batch_idx: 0 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (93.00%) (1310/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (2495/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (3690/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (4862/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (6023/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (92.00%) (7193/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (8380/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (92.00%) (9545/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (92.00%) (10726/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (11901/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (13075/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (14256/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (92.00%) (15436/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (92.00%) (16617/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (92.00%) (17796/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (92.00%) (18968/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (92.00%) (20141/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (92.00%) (21327/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (92.00%) (22516/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2314) |  Loss2: (0.0000) | Acc: (92.00%) (23695/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (92.00%) (24862/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (92.00%) (26034/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (92.00%) (27206/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (91.00%) (28378/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (92.00%) (29563/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2314) |  Loss2: (0.0000) | Acc: (92.00%) (30754/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (31933/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (92.00%) (33108/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (92.00%) (34278/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2314) |  Loss2: (0.0000) | Acc: (92.00%) (35450/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (92.00%) (36634/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (91.00%) (37795/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (92.00%) (38981/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (40150/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (91.00%) (41321/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (42481/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (91.00%) (43669/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (44841/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (91.00%) (45989/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_095.pth.tar'
# TEST : Loss: (0.3934) | Acc: (86.00%) (8678/10000)
percent tensor([0.5435, 0.5517, 0.5260, 0.5241, 0.5366, 0.5217, 0.5511, 0.5351, 0.5604,
        0.5502, 0.5588, 0.5419, 0.5509, 0.5604, 0.5344, 0.5384],
       device='cuda:0') torch.Size([16])
percent tensor([0.4883, 0.4917, 0.4763, 0.4814, 0.4777, 0.4846, 0.4885, 0.4853, 0.4877,
        0.4870, 0.4931, 0.4765, 0.4908, 0.4932, 0.4849, 0.4893],
       device='cuda:0') torch.Size([16])
percent tensor([0.5295, 0.4954, 0.4892, 0.5501, 0.5028, 0.5626, 0.4965, 0.5263, 0.5527,
        0.5037, 0.5264, 0.4635, 0.4928, 0.6117, 0.4950, 0.5377],
       device='cuda:0') torch.Size([16])
percent tensor([0.6378, 0.6762, 0.5924, 0.5954, 0.5895, 0.5939, 0.6479, 0.6101, 0.6470,
        0.6779, 0.6852, 0.6268, 0.6711, 0.6734, 0.6298, 0.6480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.5376, 0.7103, 0.7230, 0.7403, 0.7042, 0.6219, 0.6582, 0.6312,
        0.5383, 0.6034, 0.6375, 0.5181, 0.6085, 0.5966, 0.5931],
       device='cuda:0') torch.Size([16])
percent tensor([0.6442, 0.6453, 0.6732, 0.6697, 0.6908, 0.6989, 0.6625, 0.6141, 0.6811,
        0.6480, 0.6537, 0.6494, 0.6503, 0.6808, 0.6249, 0.6551],
       device='cuda:0') torch.Size([16])
percent tensor([0.6513, 0.6613, 0.7474, 0.6905, 0.7846, 0.7897, 0.6157, 0.4885, 0.7433,
        0.6811, 0.7126, 0.6989, 0.6480, 0.7031, 0.5224, 0.6324],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9987, 0.9997, 0.9995, 0.9997, 0.9990, 0.9997, 0.9996, 0.9990,
        0.9993, 0.9997, 0.9995, 0.9991, 0.9989, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 96 | Batch_idx: 0 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (2469/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (3655/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (4825/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (92.00%) (6009/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (7176/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (8342/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (9514/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2336) |  Loss2: (0.0000) | Acc: (91.00%) (10700/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2354) |  Loss2: (0.0000) | Acc: (91.00%) (11867/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (13057/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (14216/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (15385/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (16547/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (17703/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (18873/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (20041/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (21204/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (22364/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (23536/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (24711/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (25875/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (27045/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (28225/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (29399/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (30563/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (31713/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (32899/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (34092/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (35266/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (36443/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (37615/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (38782/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (39956/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (41118/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (42279/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (43440/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (44598/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (91.00%) (45723/50000)
# TEST : Loss: (0.4057) | Acc: (86.00%) (8683/10000)
percent tensor([0.5435, 0.5510, 0.5309, 0.5255, 0.5391, 0.5216, 0.5517, 0.5372, 0.5614,
        0.5507, 0.5585, 0.5450, 0.5505, 0.5596, 0.5346, 0.5388],
       device='cuda:0') torch.Size([16])
percent tensor([0.4895, 0.4914, 0.4779, 0.4817, 0.4790, 0.4850, 0.4890, 0.4856, 0.4881,
        0.4879, 0.4936, 0.4784, 0.4922, 0.4934, 0.4847, 0.4895],
       device='cuda:0') torch.Size([16])
percent tensor([0.5341, 0.5031, 0.5085, 0.5614, 0.5147, 0.5645, 0.5047, 0.5356, 0.5523,
        0.5076, 0.5229, 0.4776, 0.4967, 0.6137, 0.4945, 0.5442],
       device='cuda:0') torch.Size([16])
percent tensor([0.6362, 0.6726, 0.5929, 0.5945, 0.5920, 0.5963, 0.6462, 0.6070, 0.6431,
        0.6739, 0.6827, 0.6256, 0.6680, 0.6679, 0.6275, 0.6465],
       device='cuda:0') torch.Size([16])
percent tensor([0.5768, 0.5604, 0.7238, 0.7382, 0.7471, 0.6956, 0.6404, 0.6696, 0.6353,
        0.5657, 0.6142, 0.6570, 0.5408, 0.6423, 0.6092, 0.6109],
       device='cuda:0') torch.Size([16])
percent tensor([0.6483, 0.6442, 0.6709, 0.6718, 0.6893, 0.7037, 0.6642, 0.6140, 0.6793,
        0.6438, 0.6511, 0.6482, 0.6525, 0.6762, 0.6321, 0.6582],
       device='cuda:0') torch.Size([16])
percent tensor([0.6857, 0.6525, 0.7279, 0.6754, 0.7710, 0.8070, 0.6311, 0.4850, 0.7214,
        0.6859, 0.7143, 0.6898, 0.6513, 0.6973, 0.5403, 0.6621],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9989, 0.9995, 0.9995, 0.9998, 0.9995, 0.9997, 0.9996, 0.9988,
        0.9996, 0.9997, 0.9994, 0.9993, 0.9993, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 97 | Batch_idx: 0 |  Loss: (0.2968) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (92.00%) (2474/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (3641/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (4805/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (5976/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (7148/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2432) |  Loss2: (0.0000) | Acc: (91.00%) (8308/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (9483/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (10657/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (11840/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (13013/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (14195/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (15375/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (16544/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (17694/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (18867/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (20042/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (21217/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (22366/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (23532/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (24702/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (25867/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (27042/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (28213/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (29380/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (30555/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (31733/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (32917/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (34092/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (35272/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (36460/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (37618/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (38784/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (39963/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (41126/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (42313/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2432) |  Loss2: (0.0000) | Acc: (91.00%) (43494/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (44664/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (45794/50000)
# TEST : Loss: (0.4704) | Acc: (85.00%) (8501/10000)
percent tensor([0.5452, 0.5479, 0.5375, 0.5256, 0.5452, 0.5226, 0.5514, 0.5380, 0.5624,
        0.5509, 0.5579, 0.5496, 0.5512, 0.5518, 0.5337, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.4894, 0.4900, 0.4800, 0.4810, 0.4805, 0.4847, 0.4882, 0.4862, 0.4890,
        0.4876, 0.4941, 0.4790, 0.4921, 0.4914, 0.4842, 0.4894],
       device='cuda:0') torch.Size([16])
percent tensor([0.5369, 0.4996, 0.4959, 0.5565, 0.5157, 0.5713, 0.5004, 0.5274, 0.5549,
        0.5025, 0.5219, 0.4696, 0.4960, 0.6075, 0.4961, 0.5450],
       device='cuda:0') torch.Size([16])
percent tensor([0.6348, 0.6793, 0.5941, 0.5959, 0.5935, 0.5959, 0.6517, 0.6098, 0.6477,
        0.6790, 0.6880, 0.6271, 0.6682, 0.6799, 0.6319, 0.6455],
       device='cuda:0') torch.Size([16])
percent tensor([0.5944, 0.5526, 0.6988, 0.7223, 0.7332, 0.7043, 0.6322, 0.6553, 0.6457,
        0.5544, 0.6278, 0.6325, 0.5403, 0.6322, 0.6084, 0.6161],
       device='cuda:0') torch.Size([16])
percent tensor([0.6650, 0.6536, 0.6699, 0.6725, 0.6937, 0.7063, 0.6783, 0.6189, 0.6795,
        0.6507, 0.6639, 0.6484, 0.6593, 0.6812, 0.6430, 0.6725],
       device='cuda:0') torch.Size([16])
percent tensor([0.7110, 0.6833, 0.6825, 0.6652, 0.7506, 0.8225, 0.6520, 0.4746, 0.7365,
        0.6952, 0.7339, 0.6622, 0.6808, 0.7102, 0.5713, 0.7133],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9989, 0.9993, 0.9993, 0.9996, 0.9993, 0.9997, 0.9994, 0.9991,
        0.9996, 0.9997, 0.9995, 0.9994, 0.9989, 0.9993, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 98 | Batch_idx: 0 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (92.00%) (2480/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (3643/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (92.00%) (4832/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (6012/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (7192/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (8368/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (9555/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (10729/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (92.00%) (11901/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (13069/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (14247/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (15413/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (91.00%) (16597/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (17776/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (91.00%) (18952/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (91.00%) (20132/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (91.00%) (21308/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2324) |  Loss2: (0.0000) | Acc: (91.00%) (22476/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (91.00%) (23657/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (24823/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (25996/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (91.00%) (27190/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2324) |  Loss2: (0.0000) | Acc: (91.00%) (28369/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (91.00%) (29534/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (30709/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (31880/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (91.00%) (33047/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (34218/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (91.00%) (35402/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (36581/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (37744/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2354) |  Loss2: (0.0000) | Acc: (91.00%) (38927/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (40102/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (41273/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (42449/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (43617/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (44799/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (45907/50000)
# TEST : Loss: (0.4159) | Acc: (86.00%) (8673/10000)
percent tensor([0.5417, 0.5515, 0.5301, 0.5252, 0.5385, 0.5205, 0.5514, 0.5374, 0.5592,
        0.5509, 0.5566, 0.5440, 0.5494, 0.5599, 0.5340, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.4892, 0.4899, 0.4783, 0.4820, 0.4794, 0.4835, 0.4885, 0.4862, 0.4877,
        0.4875, 0.4925, 0.4788, 0.4916, 0.4921, 0.4835, 0.4888],
       device='cuda:0') torch.Size([16])
percent tensor([0.5354, 0.5026, 0.5044, 0.5639, 0.5136, 0.5715, 0.5031, 0.5376, 0.5514,
        0.5072, 0.5249, 0.4707, 0.4978, 0.6146, 0.4978, 0.5433],
       device='cuda:0') torch.Size([16])
percent tensor([0.6376, 0.6792, 0.5980, 0.5959, 0.5963, 0.5987, 0.6528, 0.6100, 0.6428,
        0.6781, 0.6830, 0.6305, 0.6671, 0.6752, 0.6327, 0.6478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5661, 0.5310, 0.7133, 0.7096, 0.7387, 0.6851, 0.6083, 0.6423, 0.6277,
        0.5506, 0.6037, 0.6365, 0.5361, 0.5945, 0.5841, 0.5918],
       device='cuda:0') torch.Size([16])
percent tensor([0.6466, 0.6390, 0.6673, 0.6691, 0.6897, 0.7021, 0.6639, 0.6050, 0.6801,
        0.6440, 0.6522, 0.6501, 0.6545, 0.6729, 0.6277, 0.6502],
       device='cuda:0') torch.Size([16])
percent tensor([0.6921, 0.6517, 0.7179, 0.6776, 0.7633, 0.8261, 0.6082, 0.4610, 0.7297,
        0.6842, 0.7179, 0.6845, 0.6744, 0.7015, 0.5349, 0.6592],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9989, 0.9995, 0.9995, 0.9998, 0.9996, 0.9997, 0.9997, 0.9994,
        0.9995, 0.9997, 0.9993, 0.9994, 0.9983, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 99 | Batch_idx: 0 |  Loss: (0.2244) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2578) |  Loss2: (0.0000) | Acc: (91.00%) (1284/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (92.00%) (2484/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (3667/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (92.00%) (4847/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (92.00%) (6016/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (7195/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (8370/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (9546/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (10730/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (11925/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (13116/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (14287/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (15470/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (16634/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (17815/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (18996/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (20170/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2281) |  Loss2: (0.0000) | Acc: (92.00%) (21351/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (22543/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (23711/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (24901/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (26085/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (27263/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (28430/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (29621/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (30800/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (31983/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (33170/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (34338/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (35515/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (36700/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (37877/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (39047/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (40203/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2306) |  Loss2: (0.0000) | Acc: (92.00%) (41349/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (42512/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (43681/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (91.00%) (44840/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (45966/50000)
# TEST : Loss: (0.4214) | Acc: (85.00%) (8598/10000)
percent tensor([0.5424, 0.5513, 0.5289, 0.5249, 0.5385, 0.5205, 0.5512, 0.5370, 0.5600,
        0.5507, 0.5574, 0.5434, 0.5498, 0.5602, 0.5336, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.4897, 0.4904, 0.4776, 0.4811, 0.4792, 0.4844, 0.4884, 0.4850, 0.4885,
        0.4873, 0.4941, 0.4781, 0.4923, 0.4913, 0.4841, 0.4893],
       device='cuda:0') torch.Size([16])
percent tensor([0.5373, 0.5048, 0.4916, 0.5585, 0.5086, 0.5738, 0.5019, 0.5353, 0.5562,
        0.5042, 0.5279, 0.4627, 0.4965, 0.6156, 0.5007, 0.5476],
       device='cuda:0') torch.Size([16])
percent tensor([0.6350, 0.6760, 0.5907, 0.5931, 0.5900, 0.5940, 0.6489, 0.6078, 0.6439,
        0.6757, 0.6843, 0.6250, 0.6695, 0.6717, 0.6296, 0.6456],
       device='cuda:0') torch.Size([16])
percent tensor([0.5797, 0.5491, 0.7033, 0.7087, 0.7375, 0.6958, 0.6336, 0.6464, 0.6421,
        0.5571, 0.6364, 0.6291, 0.5422, 0.6157, 0.5994, 0.6015],
       device='cuda:0') torch.Size([16])
percent tensor([0.6501, 0.6482, 0.6676, 0.6711, 0.6883, 0.6953, 0.6693, 0.6167, 0.6762,
        0.6421, 0.6519, 0.6317, 0.6483, 0.6733, 0.6247, 0.6541],
       device='cuda:0') torch.Size([16])
percent tensor([0.6790, 0.6668, 0.7073, 0.6599, 0.7353, 0.8000, 0.6101, 0.4853, 0.7334,
        0.6797, 0.7107, 0.6379, 0.6630, 0.6984, 0.5170, 0.6679],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9995, 0.9993, 0.9997, 0.9992, 0.9996, 0.9996, 0.9992,
        0.9993, 0.9997, 0.9995, 0.9994, 0.9987, 0.9992, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 100 | Batch_idx: 0 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (2463/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (3608/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (4732/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (5866/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2920) |  Loss2: (0.0000) | Acc: (89.00%) (7026/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (90.00%) (8180/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2954) |  Loss2: (0.0000) | Acc: (89.00%) (9318/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (89.00%) (10465/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (89.00%) (11598/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (12742/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (13876/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (89.00%) (15039/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2973) |  Loss2: (0.0000) | Acc: (89.00%) (16203/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2980) |  Loss2: (0.0000) | Acc: (89.00%) (17344/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (18480/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2974) |  Loss2: (0.0000) | Acc: (89.00%) (19620/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (20800/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2937) |  Loss2: (0.0000) | Acc: (89.00%) (21950/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (89.00%) (23101/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2927) |  Loss2: (0.0000) | Acc: (89.00%) (24258/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (89.00%) (25417/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2909) |  Loss2: (0.0000) | Acc: (89.00%) (26550/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (27702/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2885) |  Loss2: (0.0000) | Acc: (89.00%) (28861/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (89.00%) (30019/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (89.00%) (31181/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (89.00%) (32361/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (89.00%) (33518/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (34682/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (35857/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (36995/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (38153/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (90.00%) (39320/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (40485/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (41661/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (42813/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (43972/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (45105/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_100.pth.tar'
# TEST : Loss: (0.4386) | Acc: (85.00%) (8574/10000)
percent tensor([0.5535, 0.5588, 0.5457, 0.5345, 0.5550, 0.5283, 0.5630, 0.5486, 0.5727,
        0.5625, 0.5675, 0.5605, 0.5608, 0.5656, 0.5415, 0.5473],
       device='cuda:0') torch.Size([16])
percent tensor([0.4884, 0.4875, 0.4799, 0.4808, 0.4804, 0.4830, 0.4867, 0.4853, 0.4876,
        0.4860, 0.4914, 0.4789, 0.4904, 0.4876, 0.4823, 0.4877],
       device='cuda:0') torch.Size([16])
percent tensor([0.5271, 0.4988, 0.4715, 0.5428, 0.4898, 0.5604, 0.4900, 0.5258, 0.5434,
        0.4969, 0.5159, 0.4396, 0.4922, 0.5961, 0.4929, 0.5426],
       device='cuda:0') torch.Size([16])
percent tensor([0.6197, 0.6600, 0.5797, 0.5755, 0.5766, 0.5744, 0.6332, 0.5858, 0.6307,
        0.6607, 0.6714, 0.6145, 0.6541, 0.6578, 0.6132, 0.6268],
       device='cuda:0') torch.Size([16])
percent tensor([0.5716, 0.5426, 0.6675, 0.6801, 0.7042, 0.6882, 0.6029, 0.6155, 0.6283,
        0.5434, 0.6130, 0.5883, 0.5431, 0.6053, 0.5808, 0.5981],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.6066, 0.6419, 0.6276, 0.6572, 0.6621, 0.6267, 0.5903, 0.6433,
        0.5997, 0.6120, 0.5945, 0.6085, 0.6384, 0.5873, 0.6202],
       device='cuda:0') torch.Size([16])
percent tensor([0.7034, 0.6873, 0.7071, 0.6207, 0.7066, 0.7968, 0.6212, 0.5028, 0.7520,
        0.7037, 0.7184, 0.6358, 0.6884, 0.7089, 0.5597, 0.6878],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9997, 0.9993, 0.9997, 0.9993, 0.9997, 0.9994, 0.9993,
        0.9995, 0.9997, 0.9996, 0.9995, 0.9991, 0.9993, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.8752, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(815.7247, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(816.8485, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1523.1130, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(496.8825, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2232.2400, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4279.3901, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1399.5613, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6146.0488, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11871.3398, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3943.6680, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16639.1348, device='cuda:0')
Epoch: 101 | Batch_idx: 0 |  Loss: (0.3343) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (1285/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (2454/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2445) |  Loss2: (0.0000) | Acc: (91.00%) (3636/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (4795/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (5953/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (7116/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (8298/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (9459/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (10634/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (11801/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (12981/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (14157/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (15329/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (16492/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (17672/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (18831/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (20000/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (21168/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (22321/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (23487/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (24663/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (25834/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (27004/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (28183/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (29346/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (30528/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (31703/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (32884/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (34054/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (35237/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (36418/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (37590/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (38770/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (39952/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (41111/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (42297/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (43474/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (44648/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (45780/50000)
# TEST : Loss: (0.4153) | Acc: (86.00%) (8636/10000)
percent tensor([0.5532, 0.5573, 0.5455, 0.5330, 0.5550, 0.5263, 0.5625, 0.5479, 0.5730,
        0.5623, 0.5671, 0.5608, 0.5606, 0.5644, 0.5398, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.4856, 0.4840, 0.4774, 0.4786, 0.4780, 0.4803, 0.4835, 0.4826, 0.4846,
        0.4828, 0.4880, 0.4761, 0.4873, 0.4847, 0.4789, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5299, 0.4963, 0.4778, 0.5464, 0.4944, 0.5635, 0.4906, 0.5284, 0.5459,
        0.4972, 0.5150, 0.4423, 0.4928, 0.5962, 0.4926, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.6255, 0.6641, 0.5822, 0.5779, 0.5793, 0.5782, 0.6387, 0.5898, 0.6359,
        0.6650, 0.6770, 0.6183, 0.6596, 0.6616, 0.6179, 0.6317],
       device='cuda:0') torch.Size([16])
percent tensor([0.5743, 0.5461, 0.6772, 0.6922, 0.7119, 0.7042, 0.6071, 0.6119, 0.6390,
        0.5490, 0.6222, 0.5950, 0.5484, 0.6171, 0.5839, 0.6046],
       device='cuda:0') torch.Size([16])
percent tensor([0.6170, 0.6084, 0.6437, 0.6287, 0.6597, 0.6648, 0.6292, 0.5957, 0.6440,
        0.6028, 0.6132, 0.5978, 0.6108, 0.6369, 0.5916, 0.6246],
       device='cuda:0') torch.Size([16])
percent tensor([0.7109, 0.7047, 0.7044, 0.6106, 0.7112, 0.7949, 0.6278, 0.5106, 0.7517,
        0.7170, 0.7254, 0.6441, 0.6944, 0.7091, 0.5769, 0.6920],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9992, 0.9997, 0.9993, 0.9997, 0.9993, 0.9997, 0.9994, 0.9992,
        0.9996, 0.9998, 0.9996, 0.9995, 0.9991, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 102 | Batch_idx: 0 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (1291/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (92.00%) (2475/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (3633/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (4801/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (5965/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (7134/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (8302/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (9474/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (10645/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (11811/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (12976/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (14148/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (15326/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2445) |  Loss2: (0.0000) | Acc: (91.00%) (16499/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (17690/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (18865/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (20050/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (21228/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (22414/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (23605/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (24787/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (25981/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (27164/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (28348/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (29514/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (30680/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (31850/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (33031/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (34206/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (35363/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (36542/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (37717/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (38887/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (40067/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (41244/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (42421/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (43607/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (44782/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (45909/50000)
# TEST : Loss: (0.4051) | Acc: (86.00%) (8676/10000)
percent tensor([0.5537, 0.5566, 0.5461, 0.5325, 0.5556, 0.5257, 0.5626, 0.5478, 0.5739,
        0.5625, 0.5674, 0.5616, 0.5609, 0.5640, 0.5390, 0.5463],
       device='cuda:0') torch.Size([16])
percent tensor([0.4820, 0.4799, 0.4743, 0.4756, 0.4747, 0.4770, 0.4795, 0.4793, 0.4809,
        0.4790, 0.4839, 0.4725, 0.4836, 0.4809, 0.4749, 0.4815],
       device='cuda:0') torch.Size([16])
percent tensor([0.5321, 0.4972, 0.4829, 0.5492, 0.4986, 0.5638, 0.4939, 0.5319, 0.5496,
        0.5000, 0.5170, 0.4474, 0.4954, 0.5987, 0.4937, 0.5454],
       device='cuda:0') torch.Size([16])
percent tensor([0.6271, 0.6646, 0.5817, 0.5783, 0.5798, 0.5790, 0.6404, 0.5908, 0.6369,
        0.6654, 0.6790, 0.6184, 0.6606, 0.6620, 0.6192, 0.6323],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5408, 0.6744, 0.6915, 0.7048, 0.6988, 0.6004, 0.6001, 0.6379,
        0.5444, 0.6209, 0.5954, 0.5431, 0.6150, 0.5814, 0.5918],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.6168, 0.6516, 0.6361, 0.6682, 0.6737, 0.6386, 0.6070, 0.6509,
        0.6116, 0.6206, 0.6073, 0.6192, 0.6417, 0.6030, 0.6365],
       device='cuda:0') torch.Size([16])
percent tensor([0.7202, 0.7182, 0.7064, 0.6112, 0.7190, 0.8047, 0.6369, 0.5152, 0.7588,
        0.7269, 0.7391, 0.6536, 0.7031, 0.7152, 0.5935, 0.7025],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9992, 0.9996, 0.9993, 0.9997, 0.9993, 0.9997, 0.9994, 0.9992,
        0.9996, 0.9998, 0.9996, 0.9995, 0.9990, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 103 | Batch_idx: 0 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (92.00%) (2477/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (92.00%) (3654/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (4827/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2337) |  Loss2: (0.0000) | Acc: (91.00%) (5997/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (91.00%) (7160/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (8347/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (9545/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (10726/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (91.00%) (11892/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (13074/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (14241/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (15414/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (91.00%) (16602/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (17787/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (18968/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (20155/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (21350/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (22534/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (23716/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (24900/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (26081/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (27253/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (28425/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (29608/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (30788/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (31969/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (33159/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (34327/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (35502/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (36677/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (37864/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (39043/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (40234/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (41403/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (42585/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (43769/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (44943/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (46088/50000)
# TEST : Loss: (0.3997) | Acc: (86.00%) (8692/10000)
percent tensor([0.5552, 0.5569, 0.5483, 0.5332, 0.5576, 0.5257, 0.5638, 0.5489, 0.5758,
        0.5640, 0.5687, 0.5639, 0.5624, 0.5642, 0.5391, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.4793, 0.4769, 0.4720, 0.4731, 0.4723, 0.4743, 0.4768, 0.4769, 0.4783,
        0.4763, 0.4810, 0.4699, 0.4810, 0.4782, 0.4719, 0.4789],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.4925, 0.4821, 0.5454, 0.4967, 0.5575, 0.4908, 0.5288, 0.5482,
        0.4974, 0.5147, 0.4463, 0.4924, 0.5958, 0.4882, 0.5408],
       device='cuda:0') torch.Size([16])
percent tensor([0.6314, 0.6682, 0.5835, 0.5802, 0.5819, 0.5812, 0.6446, 0.5932, 0.6410,
        0.6694, 0.6838, 0.6211, 0.6651, 0.6658, 0.6225, 0.6358],
       device='cuda:0') torch.Size([16])
percent tensor([0.5611, 0.5408, 0.6767, 0.6935, 0.7069, 0.6964, 0.6035, 0.5991, 0.6418,
        0.5460, 0.6260, 0.6026, 0.5439, 0.6176, 0.5826, 0.5834],
       device='cuda:0') torch.Size([16])
percent tensor([0.6299, 0.6186, 0.6562, 0.6408, 0.6741, 0.6775, 0.6425, 0.6142, 0.6528,
        0.6136, 0.6223, 0.6100, 0.6204, 0.6416, 0.6067, 0.6411],
       device='cuda:0') torch.Size([16])
percent tensor([0.7097, 0.7120, 0.7070, 0.6070, 0.7201, 0.8041, 0.6279, 0.5129, 0.7533,
        0.7190, 0.7315, 0.6465, 0.6964, 0.7029, 0.5837, 0.6936],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9996, 0.9993, 0.9997, 0.9993, 0.9997, 0.9994, 0.9993,
        0.9996, 0.9998, 0.9996, 0.9995, 0.9990, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 104 | Batch_idx: 0 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.2573) |  Loss2: (0.0000) | Acc: (91.00%) (1291/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (92.00%) (2476/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (92.00%) (3666/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (92.00%) (4841/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (92.00%) (6006/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (92.00%) (7189/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (91.00%) (8353/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (92.00%) (9542/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (92.00%) (10728/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (11914/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (13076/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (14250/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (91.00%) (15422/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (91.00%) (16596/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (92.00%) (17787/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (18958/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (92.00%) (20142/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (92.00%) (21335/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (92.00%) (22516/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (92.00%) (23707/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (92.00%) (24901/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (92.00%) (26088/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (27294/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (28466/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (29644/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (30837/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (32005/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (33179/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (92.00%) (34352/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (92.00%) (35517/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (36702/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (92.00%) (37872/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (39041/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (92.00%) (40214/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (92.00%) (41392/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (92.00%) (42579/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (92.00%) (43757/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (92.00%) (44931/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (92.00%) (46068/50000)
# TEST : Loss: (0.4547) | Acc: (85.00%) (8535/10000)
percent tensor([0.5522, 0.5548, 0.5413, 0.5299, 0.5520, 0.5251, 0.5601, 0.5443, 0.5728,
        0.5599, 0.5671, 0.5578, 0.5596, 0.5625, 0.5376, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.4785, 0.4762, 0.4685, 0.4713, 0.4696, 0.4747, 0.4759, 0.4758, 0.4775,
        0.4750, 0.4806, 0.4671, 0.4808, 0.4797, 0.4712, 0.4784],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.4890, 0.4978, 0.5544, 0.5081, 0.5647, 0.4948, 0.5269, 0.5443,
        0.4967, 0.5131, 0.4682, 0.4942, 0.5986, 0.4874, 0.5404],
       device='cuda:0') torch.Size([16])
percent tensor([0.6308, 0.6657, 0.5829, 0.5832, 0.5798, 0.5826, 0.6433, 0.5987, 0.6397,
        0.6674, 0.6798, 0.6184, 0.6638, 0.6628, 0.6218, 0.6358],
       device='cuda:0') torch.Size([16])
percent tensor([0.5690, 0.5497, 0.7031, 0.7100, 0.7303, 0.6992, 0.6191, 0.6169, 0.6449,
        0.5455, 0.6275, 0.6369, 0.5451, 0.6181, 0.5905, 0.5875],
       device='cuda:0') torch.Size([16])
percent tensor([0.6313, 0.6244, 0.6529, 0.6482, 0.6806, 0.6872, 0.6482, 0.6155, 0.6512,
        0.6182, 0.6222, 0.6185, 0.6236, 0.6381, 0.6149, 0.6532],
       device='cuda:0') torch.Size([16])
percent tensor([0.7048, 0.7221, 0.7163, 0.6562, 0.7579, 0.8225, 0.6581, 0.5309, 0.7351,
        0.7117, 0.7200, 0.6833, 0.6951, 0.6974, 0.5870, 0.7289],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9993, 0.9997, 0.9994, 0.9997, 0.9994, 0.9995, 0.9996, 0.9994,
        0.9997, 0.9998, 0.9995, 0.9995, 0.9993, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 105 | Batch_idx: 0 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (1301/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (93.00%) (2505/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (93.00%) (3694/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (93.00%) (4883/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (93.00%) (6081/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (93.00%) (7272/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (93.00%) (8452/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (9640/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (10824/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (12014/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (13202/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (14377/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (15551/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (16727/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (17909/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (19081/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (20272/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (21453/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (22645/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (23822/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (24995/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (26171/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (27348/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (28525/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (29692/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (30870/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (32076/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (33260/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (34435/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (35607/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (36788/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (37962/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (39145/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (40313/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (41482/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (42666/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (43832/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (45025/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (46177/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_105.pth.tar'
# TEST : Loss: (0.4200) | Acc: (86.00%) (8633/10000)
percent tensor([0.5510, 0.5561, 0.5399, 0.5312, 0.5495, 0.5234, 0.5601, 0.5452, 0.5716,
        0.5607, 0.5662, 0.5566, 0.5594, 0.5655, 0.5378, 0.5452],
       device='cuda:0') torch.Size([16])
percent tensor([0.4777, 0.4773, 0.4685, 0.4712, 0.4692, 0.4732, 0.4762, 0.4765, 0.4767,
        0.4751, 0.4799, 0.4668, 0.4806, 0.4803, 0.4711, 0.4781],
       device='cuda:0') torch.Size([16])
percent tensor([0.5306, 0.4907, 0.4997, 0.5557, 0.5102, 0.5611, 0.4959, 0.5294, 0.5457,
        0.4987, 0.5161, 0.4655, 0.4975, 0.6023, 0.4874, 0.5416],
       device='cuda:0') torch.Size([16])
percent tensor([0.6317, 0.6636, 0.5862, 0.5850, 0.5831, 0.5861, 0.6446, 0.5986, 0.6364,
        0.6671, 0.6762, 0.6199, 0.6635, 0.6578, 0.6225, 0.6400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5573, 0.5471, 0.6858, 0.7013, 0.7182, 0.6943, 0.6066, 0.6116, 0.6463,
        0.5436, 0.6201, 0.6276, 0.5445, 0.6161, 0.5843, 0.5809],
       device='cuda:0') torch.Size([16])
percent tensor([0.6286, 0.6230, 0.6460, 0.6421, 0.6764, 0.6797, 0.6470, 0.6053, 0.6522,
        0.6132, 0.6232, 0.6140, 0.6280, 0.6470, 0.6055, 0.6431],
       device='cuda:0') torch.Size([16])
percent tensor([0.6918, 0.7002, 0.7123, 0.6261, 0.7579, 0.7840, 0.6576, 0.5019, 0.7363,
        0.7091, 0.7241, 0.6843, 0.7008, 0.7153, 0.5447, 0.6897],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9990, 0.9997, 0.9996, 0.9998, 0.9986, 0.9997, 0.9996, 0.9990,
        0.9998, 0.9997, 0.9995, 0.9995, 0.9992, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 106 | Batch_idx: 0 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (92.00%) (1307/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (2483/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (3678/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (4868/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (6053/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (92.00%) (7250/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (8433/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (92.00%) (9632/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (92.00%) (10816/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (92.00%) (12009/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (92.00%) (13196/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (14381/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (15552/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (16718/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (17899/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (19067/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (20245/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (21417/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (22589/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (23784/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (24971/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2145) |  Loss2: (0.0000) | Acc: (92.00%) (26150/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (27329/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (28513/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (29695/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (30868/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (32039/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (33233/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (34407/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (35569/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (36741/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (37929/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (39110/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (40305/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (41494/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (42665/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (43842/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (45028/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (46173/50000)
# TEST : Loss: (0.4418) | Acc: (86.00%) (8630/10000)
percent tensor([0.5506, 0.5540, 0.5406, 0.5300, 0.5497, 0.5244, 0.5587, 0.5440, 0.5709,
        0.5593, 0.5659, 0.5560, 0.5580, 0.5627, 0.5370, 0.5442],
       device='cuda:0') torch.Size([16])
percent tensor([0.4789, 0.4776, 0.4690, 0.4716, 0.4697, 0.4746, 0.4767, 0.4766, 0.4775,
        0.4751, 0.4806, 0.4673, 0.4815, 0.4810, 0.4722, 0.4786],
       device='cuda:0') torch.Size([16])
percent tensor([0.5366, 0.4891, 0.5010, 0.5556, 0.5117, 0.5703, 0.4947, 0.5255, 0.5450,
        0.4959, 0.5167, 0.4688, 0.5019, 0.5931, 0.4888, 0.5421],
       device='cuda:0') torch.Size([16])
percent tensor([0.6341, 0.6702, 0.5796, 0.5826, 0.5795, 0.5887, 0.6496, 0.6009, 0.6444,
        0.6683, 0.6866, 0.6169, 0.6691, 0.6612, 0.6270, 0.6400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.5394, 0.6993, 0.7115, 0.7254, 0.6894, 0.5967, 0.6074, 0.6421,
        0.5473, 0.6185, 0.6379, 0.5350, 0.6148, 0.5733, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.6336, 0.6245, 0.6465, 0.6461, 0.6762, 0.6827, 0.6472, 0.6055, 0.6512,
        0.6197, 0.6228, 0.6175, 0.6254, 0.6436, 0.6066, 0.6476],
       device='cuda:0') torch.Size([16])
percent tensor([0.6984, 0.6948, 0.7133, 0.6519, 0.7604, 0.8038, 0.6629, 0.4985, 0.7385,
        0.7067, 0.7229, 0.6986, 0.6896, 0.6966, 0.5619, 0.7078],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9992, 0.9997, 0.9997, 0.9998, 0.9993, 0.9997, 0.9996, 0.9993,
        0.9998, 0.9998, 0.9996, 0.9996, 0.9992, 0.9993, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 107 | Batch_idx: 0 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (1299/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (2490/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (3677/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.2128) |  Loss2: (0.0000) | Acc: (92.00%) (4870/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (6056/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (7256/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (8450/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (93.00%) (9650/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (93.00%) (10838/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (12033/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (13224/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (14423/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (93.00%) (15612/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (93.00%) (16800/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (93.00%) (17993/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (93.00%) (19188/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (93.00%) (20384/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (93.00%) (21558/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (93.00%) (22749/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (93.00%) (23936/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (25112/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (26287/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (27467/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (28639/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (29835/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (31020/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (32213/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (33380/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (34559/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (35746/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (36937/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (38112/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (39306/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (40489/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (41666/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (42845/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (44010/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (45198/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (46333/50000)
# TEST : Loss: (0.4169) | Acc: (86.00%) (8635/10000)
percent tensor([0.5516, 0.5589, 0.5374, 0.5305, 0.5479, 0.5251, 0.5608, 0.5455, 0.5728,
        0.5611, 0.5683, 0.5534, 0.5600, 0.5700, 0.5396, 0.5466],
       device='cuda:0') torch.Size([16])
percent tensor([0.4792, 0.4777, 0.4713, 0.4710, 0.4712, 0.4746, 0.4773, 0.4767, 0.4787,
        0.4764, 0.4816, 0.4694, 0.4820, 0.4801, 0.4719, 0.4783],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.4941, 0.4894, 0.5420, 0.4978, 0.5584, 0.4948, 0.5266, 0.5462,
        0.4978, 0.5183, 0.4575, 0.4957, 0.5997, 0.4869, 0.5420],
       device='cuda:0') torch.Size([16])
percent tensor([0.6297, 0.6696, 0.5860, 0.5896, 0.5828, 0.5858, 0.6489, 0.6032, 0.6401,
        0.6694, 0.6800, 0.6191, 0.6649, 0.6608, 0.6216, 0.6403],
       device='cuda:0') torch.Size([16])
percent tensor([0.5513, 0.5282, 0.6712, 0.6930, 0.7081, 0.6827, 0.5952, 0.6016, 0.6406,
        0.5404, 0.6055, 0.6213, 0.5520, 0.6127, 0.5739, 0.5721],
       device='cuda:0') torch.Size([16])
percent tensor([0.6303, 0.6097, 0.6438, 0.6406, 0.6727, 0.6834, 0.6406, 0.6089, 0.6493,
        0.6104, 0.6198, 0.6156, 0.6313, 0.6344, 0.6069, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.6806, 0.6889, 0.7154, 0.6329, 0.7520, 0.8137, 0.6295, 0.5105, 0.7338,
        0.6987, 0.7124, 0.6723, 0.7046, 0.6917, 0.5539, 0.7200],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9998, 0.9997, 0.9997, 0.9996, 0.9997, 0.9994, 0.9994,
        0.9998, 0.9998, 0.9996, 0.9995, 0.9994, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 108 | Batch_idx: 0 |  Loss: (0.3072) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (3612/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (4767/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.2606) |  Loss2: (0.0000) | Acc: (90.00%) (5929/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.2596) |  Loss2: (0.0000) | Acc: (90.00%) (7088/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.2583) |  Loss2: (0.0000) | Acc: (90.00%) (8265/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (90.00%) (9427/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (90.00%) (10598/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (11767/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (12932/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (90.00%) (14078/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.2591) |  Loss2: (0.0000) | Acc: (90.00%) (15234/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (90.00%) (16405/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (90.00%) (17574/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (90.00%) (18714/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.2610) |  Loss2: (0.0000) | Acc: (90.00%) (19873/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.2614) |  Loss2: (0.0000) | Acc: (90.00%) (21032/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (90.00%) (22200/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (90.00%) (23368/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (90.00%) (24553/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.2575) |  Loss2: (0.0000) | Acc: (90.00%) (25712/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.2572) |  Loss2: (0.0000) | Acc: (90.00%) (26879/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (90.00%) (28036/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (90.00%) (29220/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (90.00%) (30390/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (90.00%) (31557/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (90.00%) (32715/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (90.00%) (33882/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (90.00%) (35049/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (90.00%) (36209/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (90.00%) (37384/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (90.00%) (38554/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (39721/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (40893/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (42063/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (43242/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (44420/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (45566/50000)
# TEST : Loss: (0.4265) | Acc: (86.00%) (8623/10000)
percent tensor([0.5500, 0.5607, 0.5297, 0.5272, 0.5427, 0.5245, 0.5603, 0.5427, 0.5700,
        0.5597, 0.5677, 0.5473, 0.5585, 0.5725, 0.5394, 0.5463],
       device='cuda:0') torch.Size([16])
percent tensor([0.4766, 0.4749, 0.4657, 0.4651, 0.4669, 0.4716, 0.4745, 0.4712, 0.4756,
        0.4730, 0.4796, 0.4653, 0.4798, 0.4771, 0.4677, 0.4751],
       device='cuda:0') torch.Size([16])
percent tensor([0.5529, 0.5017, 0.5045, 0.5588, 0.5125, 0.5898, 0.5017, 0.5396, 0.5654,
        0.5072, 0.5334, 0.4610, 0.5142, 0.6100, 0.4989, 0.5653],
       device='cuda:0') torch.Size([16])
percent tensor([0.6446, 0.6882, 0.5852, 0.5938, 0.5873, 0.5981, 0.6656, 0.6150, 0.6567,
        0.6849, 0.6971, 0.6252, 0.6840, 0.6766, 0.6381, 0.6568],
       device='cuda:0') torch.Size([16])
percent tensor([0.5736, 0.5617, 0.6834, 0.7013, 0.7143, 0.6833, 0.6276, 0.6187, 0.6585,
        0.5694, 0.6326, 0.6628, 0.5840, 0.6304, 0.6024, 0.5871],
       device='cuda:0') torch.Size([16])
percent tensor([0.6478, 0.6194, 0.6628, 0.6610, 0.6927, 0.7031, 0.6584, 0.6205, 0.6659,
        0.6322, 0.6395, 0.6418, 0.6462, 0.6599, 0.6214, 0.6656],
       device='cuda:0') torch.Size([16])
percent tensor([0.6948, 0.6698, 0.7552, 0.6942, 0.7980, 0.8302, 0.6443, 0.5365, 0.7446,
        0.7148, 0.7312, 0.7260, 0.6901, 0.7362, 0.5825, 0.7114],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9993, 0.9997, 0.9995, 0.9997, 0.9994, 0.9997, 0.9993, 0.9991,
        0.9997, 0.9998, 0.9996, 0.9995, 0.9994, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 109 | Batch_idx: 0 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (90.00%) (1278/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (2448/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (3623/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (4795/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (5963/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (7137/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (8300/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (9483/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (10654/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (11821/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (12996/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (14171/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (15359/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (16537/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (17720/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (18902/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (20074/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (21240/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (22415/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (23603/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (24787/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (91.00%) (25965/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (27153/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (28325/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (91.00%) (29474/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (30650/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (91.00%) (31833/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (32992/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (34173/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (35365/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (91.00%) (36543/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (91.00%) (37740/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (38916/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (91.00%) (40103/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (91.00%) (41280/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (91.00%) (42453/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.2324) |  Loss2: (0.0000) | Acc: (91.00%) (43639/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (44827/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (91.00%) (45965/50000)
# TEST : Loss: (0.4081) | Acc: (86.00%) (8687/10000)
percent tensor([0.5505, 0.5614, 0.5288, 0.5261, 0.5425, 0.5246, 0.5610, 0.5419, 0.5703,
        0.5600, 0.5684, 0.5471, 0.5589, 0.5733, 0.5395, 0.5468],
       device='cuda:0') torch.Size([16])
percent tensor([0.4780, 0.4762, 0.4651, 0.4649, 0.4667, 0.4729, 0.4756, 0.4714, 0.4764,
        0.4738, 0.4814, 0.4650, 0.4813, 0.4780, 0.4686, 0.4765],
       device='cuda:0') torch.Size([16])
percent tensor([0.5592, 0.5011, 0.5043, 0.5598, 0.5140, 0.5994, 0.5033, 0.5414, 0.5673,
        0.5069, 0.5352, 0.4596, 0.5161, 0.6144, 0.5015, 0.5722],
       device='cuda:0') torch.Size([16])
percent tensor([0.6487, 0.6920, 0.5872, 0.5949, 0.5902, 0.6016, 0.6697, 0.6164, 0.6610,
        0.6887, 0.7022, 0.6287, 0.6886, 0.6803, 0.6416, 0.6602],
       device='cuda:0') torch.Size([16])
percent tensor([0.5747, 0.5593, 0.6951, 0.7085, 0.7226, 0.6817, 0.6326, 0.6298, 0.6690,
        0.5705, 0.6389, 0.6709, 0.5807, 0.6317, 0.6051, 0.5840],
       device='cuda:0') torch.Size([16])
percent tensor([0.6460, 0.6201, 0.6654, 0.6626, 0.6955, 0.7073, 0.6591, 0.6199, 0.6675,
        0.6335, 0.6399, 0.6431, 0.6467, 0.6611, 0.6203, 0.6668],
       device='cuda:0') torch.Size([16])
percent tensor([0.6857, 0.6614, 0.7644, 0.7035, 0.8022, 0.8304, 0.6410, 0.5384, 0.7413,
        0.7104, 0.7251, 0.7328, 0.6776, 0.7320, 0.5775, 0.7038],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9992, 0.9997, 0.9995, 0.9997, 0.9995, 0.9998, 0.9993, 0.9990,
        0.9997, 0.9998, 0.9996, 0.9995, 0.9994, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 110 | Batch_idx: 0 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (93.00%) (1310/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (2499/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (3674/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (4853/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (6029/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (7210/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (8380/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (9579/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (10750/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (11925/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (13112/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (14295/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (15470/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (16655/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (17839/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (19022/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (20200/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (21400/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (22580/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (23743/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (24942/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (26105/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (27296/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (28487/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (29672/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (30848/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (32031/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (33193/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (34393/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (35585/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (36770/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (37955/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (39135/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (40327/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (41515/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (42709/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (43886/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (45054/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (46202/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_110.pth.tar'
# TEST : Loss: (0.4016) | Acc: (87.00%) (8702/10000)
percent tensor([0.5497, 0.5603, 0.5277, 0.5250, 0.5413, 0.5237, 0.5600, 0.5406, 0.5687,
        0.5587, 0.5671, 0.5460, 0.5577, 0.5719, 0.5386, 0.5460],
       device='cuda:0') torch.Size([16])
percent tensor([0.4802, 0.4781, 0.4659, 0.4661, 0.4679, 0.4748, 0.4775, 0.4729, 0.4781,
        0.4755, 0.4837, 0.4662, 0.4834, 0.4798, 0.4705, 0.4786],
       device='cuda:0') torch.Size([16])
percent tensor([0.5586, 0.4935, 0.5052, 0.5586, 0.5179, 0.6009, 0.5008, 0.5446, 0.5641,
        0.5001, 0.5281, 0.4565, 0.5103, 0.6101, 0.4982, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.6485, 0.6911, 0.5866, 0.5932, 0.5896, 0.6007, 0.6694, 0.6151, 0.6614,
        0.6879, 0.7026, 0.6281, 0.6883, 0.6806, 0.6405, 0.6591],
       device='cuda:0') torch.Size([16])
percent tensor([0.5669, 0.5477, 0.6946, 0.7055, 0.7205, 0.6767, 0.6231, 0.6250, 0.6631,
        0.5596, 0.6313, 0.6636, 0.5668, 0.6204, 0.5990, 0.5747],
       device='cuda:0') torch.Size([16])
percent tensor([0.6338, 0.6122, 0.6569, 0.6541, 0.6871, 0.7015, 0.6490, 0.6071, 0.6579,
        0.6245, 0.6298, 0.6343, 0.6377, 0.6521, 0.6094, 0.6569],
       device='cuda:0') torch.Size([16])
percent tensor([0.6827, 0.6637, 0.7579, 0.6981, 0.7914, 0.8327, 0.6353, 0.5205, 0.7355,
        0.7083, 0.7225, 0.7294, 0.6785, 0.7301, 0.5696, 0.6971],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9992, 0.9997, 0.9996, 0.9997, 0.9996, 0.9998, 0.9994, 0.9991,
        0.9997, 0.9998, 0.9996, 0.9995, 0.9994, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.5012, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(817.3493, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(818.3600, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.2885, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(495.1549, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2235.6768, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4273.8945, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1394.2853, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6150.7441, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11834.6045, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3928.3413, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16572.7949, device='cuda:0')
Epoch: 111 | Batch_idx: 0 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (92.00%) (1308/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (2490/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (3677/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (4875/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (6063/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (7238/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (8426/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (9614/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (10809/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (12003/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (13174/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (14355/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (15544/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (16729/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (17909/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (19098/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (20285/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (21467/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (22656/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (23847/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (25034/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (26223/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (27401/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (28590/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (29777/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (30965/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (32154/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (33336/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (34521/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (35710/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (36888/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (38065/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (39258/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (40429/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (41608/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (42793/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (43972/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (45155/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (46296/50000)
# TEST : Loss: (0.3949) | Acc: (87.00%) (8709/10000)
percent tensor([0.5508, 0.5613, 0.5285, 0.5260, 0.5422, 0.5250, 0.5611, 0.5414, 0.5694,
        0.5596, 0.5681, 0.5469, 0.5588, 0.5728, 0.5397, 0.5473],
       device='cuda:0') torch.Size([16])
percent tensor([0.4827, 0.4808, 0.4675, 0.4678, 0.4698, 0.4772, 0.4801, 0.4749, 0.4805,
        0.4779, 0.4866, 0.4681, 0.4860, 0.4822, 0.4731, 0.4810],
       device='cuda:0') torch.Size([16])
percent tensor([0.5522, 0.4883, 0.4973, 0.5497, 0.5131, 0.5945, 0.4970, 0.5392, 0.5581,
        0.4938, 0.5222, 0.4495, 0.5034, 0.6055, 0.4931, 0.5648],
       device='cuda:0') torch.Size([16])
percent tensor([0.6478, 0.6902, 0.5864, 0.5925, 0.5892, 0.5999, 0.6680, 0.6139, 0.6613,
        0.6868, 0.7024, 0.6275, 0.6875, 0.6801, 0.6392, 0.6581],
       device='cuda:0') torch.Size([16])
percent tensor([0.5684, 0.5460, 0.6985, 0.7068, 0.7223, 0.6805, 0.6217, 0.6244, 0.6684,
        0.5599, 0.6343, 0.6661, 0.5662, 0.6216, 0.6013, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.6284, 0.6101, 0.6551, 0.6509, 0.6860, 0.6997, 0.6457, 0.6032, 0.6546,
        0.6219, 0.6247, 0.6313, 0.6341, 0.6490, 0.6054, 0.6534],
       device='cuda:0') torch.Size([16])
percent tensor([0.6861, 0.6695, 0.7635, 0.7049, 0.7932, 0.8334, 0.6450, 0.5274, 0.7394,
        0.7160, 0.7241, 0.7339, 0.6813, 0.7362, 0.5769, 0.6993],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9992, 0.9997, 0.9996, 0.9997, 0.9996, 0.9998, 0.9994, 0.9991,
        0.9997, 0.9998, 0.9996, 0.9995, 0.9994, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 112 | Batch_idx: 0 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (1315/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (3691/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (4891/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (6084/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (7284/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (8489/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (9672/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (10847/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (12054/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (93.00%) (13222/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.2066) |  Loss2: (0.0000) | Acc: (92.00%) (14399/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (93.00%) (15595/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (93.00%) (16790/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (93.00%) (17989/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (93.00%) (19169/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (93.00%) (20364/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (21542/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (22714/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (23895/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (25067/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (26258/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (27449/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (28644/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (29833/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (31016/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (32212/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (33397/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (34580/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (35772/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (36941/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (38110/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (39293/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (40480/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (41661/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (42856/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (44051/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (45238/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (46386/50000)
# TEST : Loss: (0.3977) | Acc: (87.00%) (8758/10000)
percent tensor([0.5540, 0.5559, 0.5415, 0.5300, 0.5515, 0.5257, 0.5609, 0.5448, 0.5719,
        0.5598, 0.5673, 0.5566, 0.5603, 0.5622, 0.5394, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.4823, 0.4812, 0.4692, 0.4707, 0.4695, 0.4761, 0.4787, 0.4779, 0.4805,
        0.4781, 0.4864, 0.4675, 0.4859, 0.4827, 0.4737, 0.4820],
       device='cuda:0') torch.Size([16])
percent tensor([0.5508, 0.4903, 0.5217, 0.5668, 0.5315, 0.5940, 0.5029, 0.5498, 0.5528,
        0.5003, 0.5218, 0.4661, 0.5026, 0.6104, 0.4973, 0.5644],
       device='cuda:0') torch.Size([16])
percent tensor([0.6509, 0.6880, 0.6014, 0.5953, 0.5968, 0.6027, 0.6671, 0.6125, 0.6660,
        0.6861, 0.7032, 0.6362, 0.6866, 0.6865, 0.6406, 0.6564],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5358, 0.7025, 0.6993, 0.7248, 0.6737, 0.6190, 0.6214, 0.6502,
        0.5600, 0.6268, 0.6479, 0.5517, 0.5997, 0.5934, 0.5792],
       device='cuda:0') torch.Size([16])
percent tensor([0.6224, 0.6255, 0.6580, 0.6519, 0.6846, 0.6973, 0.6578, 0.6000, 0.6534,
        0.6276, 0.6195, 0.6275, 0.6289, 0.6562, 0.6117, 0.6510],
       device='cuda:0') torch.Size([16])
percent tensor([0.6620, 0.6883, 0.7462, 0.6842, 0.7833, 0.8239, 0.6684, 0.5170, 0.7520,
        0.7186, 0.7328, 0.7331, 0.6632, 0.7369, 0.5865, 0.6868],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9992, 0.9996, 0.9994, 0.9999, 0.9997, 0.9997, 0.9994, 0.9996,
        0.9997, 0.9998, 0.9995, 0.9997, 0.9989, 0.9993, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 113 | Batch_idx: 0 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (2495/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (3721/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (4914/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (6102/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (7299/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (8500/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (9698/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1946) |  Loss2: (0.0000) | Acc: (93.00%) (10885/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (12058/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (13242/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (14434/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (15621/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (93.00%) (16811/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (18024/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (19209/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (20398/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (21580/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (93.00%) (22762/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (23955/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (93.00%) (25130/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (93.00%) (26316/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (27494/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (92.00%) (28680/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (29878/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (92.00%) (31052/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (92.00%) (32247/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (92.00%) (33419/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (92.00%) (34609/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (35792/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (36980/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (38171/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (39370/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (40553/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (41745/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (42918/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.2048) |  Loss2: (0.0000) | Acc: (92.00%) (44119/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (45305/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (46451/50000)
# TEST : Loss: (0.4244) | Acc: (86.00%) (8643/10000)
percent tensor([0.5545, 0.5556, 0.5428, 0.5301, 0.5528, 0.5253, 0.5612, 0.5461, 0.5725,
        0.5610, 0.5676, 0.5586, 0.5609, 0.5621, 0.5389, 0.5465],
       device='cuda:0') torch.Size([16])
percent tensor([0.4829, 0.4798, 0.4723, 0.4718, 0.4722, 0.4773, 0.4793, 0.4778, 0.4800,
        0.4779, 0.4853, 0.4706, 0.4853, 0.4797, 0.4743, 0.4817],
       device='cuda:0') torch.Size([16])
percent tensor([0.5507, 0.4891, 0.5133, 0.5671, 0.5320, 0.5936, 0.5004, 0.5518, 0.5605,
        0.4989, 0.5191, 0.4636, 0.5020, 0.6092, 0.4978, 0.5648],
       device='cuda:0') torch.Size([16])
percent tensor([0.6474, 0.6858, 0.6071, 0.6050, 0.5990, 0.6004, 0.6665, 0.6178, 0.6623,
        0.6869, 0.7001, 0.6417, 0.6838, 0.6833, 0.6374, 0.6533],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5312, 0.6843, 0.6860, 0.7108, 0.6703, 0.6264, 0.6140, 0.6667,
        0.5572, 0.6420, 0.6385, 0.5490, 0.6339, 0.5852, 0.5737],
       device='cuda:0') torch.Size([16])
percent tensor([0.6184, 0.6128, 0.6523, 0.6436, 0.6774, 0.6913, 0.6473, 0.5981, 0.6553,
        0.6130, 0.6200, 0.6198, 0.6223, 0.6410, 0.5997, 0.6467],
       device='cuda:0') torch.Size([16])
percent tensor([0.6613, 0.6879, 0.7579, 0.6760, 0.7759, 0.8222, 0.6318, 0.5168, 0.7480,
        0.7006, 0.7159, 0.6943, 0.6641, 0.7005, 0.5814, 0.6944],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9996, 0.9997, 0.9999, 0.9996, 0.9996, 0.9994, 0.9995,
        0.9997, 0.9998, 0.9994, 0.9995, 0.9993, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 114 | Batch_idx: 0 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (2523/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (3702/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (4891/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (6087/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (7269/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (8475/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (9669/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (10854/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (12040/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (13231/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (14428/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (15628/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (16808/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (18006/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (19216/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (20414/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (21618/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (22801/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (23990/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (25176/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (26367/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (27554/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (28728/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (29927/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (31118/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (32319/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (33527/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (34716/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (35924/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (37114/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (38304/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (39487/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (40683/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (41876/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (43056/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (44251/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (45444/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (46568/50000)
# TEST : Loss: (0.5466) | Acc: (83.00%) (8358/10000)
percent tensor([0.5534, 0.5569, 0.5382, 0.5277, 0.5469, 0.5245, 0.5601, 0.5443, 0.5736,
        0.5601, 0.5697, 0.5531, 0.5609, 0.5647, 0.5386, 0.5466],
       device='cuda:0') torch.Size([16])
percent tensor([0.4840, 0.4813, 0.4713, 0.4713, 0.4712, 0.4777, 0.4805, 0.4771, 0.4812,
        0.4785, 0.4868, 0.4689, 0.4870, 0.4821, 0.4748, 0.4829],
       device='cuda:0') torch.Size([16])
percent tensor([0.5569, 0.4966, 0.5209, 0.5737, 0.5346, 0.5941, 0.5132, 0.5514, 0.5595,
        0.5103, 0.5250, 0.4733, 0.5072, 0.6177, 0.4990, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.6507, 0.6870, 0.6018, 0.6000, 0.5972, 0.6049, 0.6664, 0.6117, 0.6615,
        0.6865, 0.7034, 0.6358, 0.6823, 0.6824, 0.6406, 0.6582],
       device='cuda:0') torch.Size([16])
percent tensor([0.5682, 0.5391, 0.6949, 0.7032, 0.7292, 0.6857, 0.6286, 0.6269, 0.6685,
        0.5628, 0.6544, 0.6423, 0.5641, 0.6177, 0.5934, 0.5863],
       device='cuda:0') torch.Size([16])
percent tensor([0.6369, 0.6383, 0.6610, 0.6595, 0.6895, 0.7027, 0.6642, 0.6084, 0.6675,
        0.6383, 0.6397, 0.6360, 0.6440, 0.6584, 0.6165, 0.6602],
       device='cuda:0') torch.Size([16])
percent tensor([0.6983, 0.7535, 0.7529, 0.6941, 0.7945, 0.8457, 0.6868, 0.5298, 0.7708,
        0.7614, 0.7542, 0.7309, 0.7147, 0.7476, 0.6080, 0.7324],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9994, 0.9996, 0.9995, 0.9999, 0.9998, 0.9997, 0.9991, 0.9993,
        0.9997, 0.9999, 0.9994, 0.9996, 0.9993, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 115 | Batch_idx: 0 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (91.00%) (1294/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (3713/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (4917/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (6107/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (7313/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (8513/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (9713/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (10931/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (12140/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (13346/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (14550/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (15747/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (16944/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (18139/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (19334/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (20531/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (21722/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (22902/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (24089/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (25294/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (26496/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (27693/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (28878/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (30070/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (31242/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (32444/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (33634/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (34827/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (36034/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (37207/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (38409/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (39602/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (40783/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (41974/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (43172/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (44378/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (45573/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (46718/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_115.pth.tar'
# TEST : Loss: (0.4467) | Acc: (86.00%) (8612/10000)
percent tensor([0.5532, 0.5577, 0.5391, 0.5290, 0.5492, 0.5238, 0.5614, 0.5453, 0.5725,
        0.5608, 0.5679, 0.5559, 0.5610, 0.5666, 0.5382, 0.5466],
       device='cuda:0') torch.Size([16])
percent tensor([0.4831, 0.4824, 0.4683, 0.4710, 0.4698, 0.4784, 0.4810, 0.4757, 0.4801,
        0.4782, 0.4871, 0.4672, 0.4860, 0.4848, 0.4753, 0.4828],
       device='cuda:0') torch.Size([16])
percent tensor([0.5531, 0.4805, 0.5130, 0.5648, 0.5258, 0.5928, 0.4944, 0.5433, 0.5576,
        0.4958, 0.5184, 0.4665, 0.5090, 0.6015, 0.4894, 0.5605],
       device='cuda:0') torch.Size([16])
percent tensor([0.6521, 0.6860, 0.5965, 0.6001, 0.5928, 0.6061, 0.6644, 0.6121, 0.6632,
        0.6849, 0.7028, 0.6321, 0.6861, 0.6903, 0.6396, 0.6603],
       device='cuda:0') torch.Size([16])
percent tensor([0.5587, 0.5293, 0.6820, 0.6982, 0.7181, 0.6664, 0.6037, 0.6118, 0.6685,
        0.5558, 0.6231, 0.6438, 0.5565, 0.5831, 0.5802, 0.5621],
       device='cuda:0') torch.Size([16])
percent tensor([0.6223, 0.6160, 0.6501, 0.6525, 0.6805, 0.6905, 0.6391, 0.6002, 0.6613,
        0.6177, 0.6197, 0.6218, 0.6318, 0.6436, 0.5976, 0.6382],
       device='cuda:0') torch.Size([16])
percent tensor([0.6726, 0.6821, 0.7389, 0.6873, 0.7775, 0.8345, 0.6477, 0.5253, 0.7364,
        0.6937, 0.7095, 0.7140, 0.6891, 0.7002, 0.5657, 0.6993],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9990, 0.9997, 0.9997, 0.9998, 0.9997, 0.9998, 0.9996, 0.9991,
        0.9995, 0.9998, 0.9996, 0.9996, 0.9987, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 116 | Batch_idx: 0 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (92.00%) (1308/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (2483/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (3675/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (4863/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (6037/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (7203/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (8386/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (9557/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (10747/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (11923/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (13097/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (14268/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (15446/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (16618/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (17787/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (18976/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (20145/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (91.00%) (21313/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (91.00%) (22491/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (23688/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (24880/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (26058/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (27235/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (28415/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (29606/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (30791/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (31973/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (33177/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (34360/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (35531/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (36731/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (37917/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (39093/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (40266/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (41466/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (42660/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (43861/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (45064/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (46205/50000)
# TEST : Loss: (0.3968) | Acc: (87.00%) (8736/10000)
percent tensor([0.5501, 0.5576, 0.5330, 0.5244, 0.5450, 0.5206, 0.5600, 0.5413, 0.5691,
        0.5582, 0.5663, 0.5515, 0.5586, 0.5644, 0.5366, 0.5435],
       device='cuda:0') torch.Size([16])
percent tensor([0.4848, 0.4865, 0.4692, 0.4721, 0.4716, 0.4802, 0.4844, 0.4778, 0.4814,
        0.4803, 0.4891, 0.4692, 0.4880, 0.4884, 0.4781, 0.4849],
       device='cuda:0') torch.Size([16])
percent tensor([0.5726, 0.4889, 0.5308, 0.5955, 0.5458, 0.6218, 0.5097, 0.5693, 0.5763,
        0.5083, 0.5342, 0.4797, 0.5217, 0.6255, 0.5062, 0.5848],
       device='cuda:0') torch.Size([16])
percent tensor([0.6616, 0.6932, 0.6078, 0.6091, 0.6037, 0.6148, 0.6722, 0.6229, 0.6730,
        0.6923, 0.7081, 0.6419, 0.6928, 0.6950, 0.6509, 0.6682],
       device='cuda:0') torch.Size([16])
percent tensor([0.5621, 0.5510, 0.6670, 0.6830, 0.7041, 0.6647, 0.6099, 0.6073, 0.6639,
        0.5585, 0.6370, 0.6379, 0.5661, 0.6029, 0.5838, 0.5715],
       device='cuda:0') torch.Size([16])
percent tensor([0.6298, 0.6210, 0.6517, 0.6539, 0.6843, 0.6959, 0.6419, 0.6026, 0.6604,
        0.6196, 0.6233, 0.6168, 0.6339, 0.6467, 0.5969, 0.6469],
       device='cuda:0') torch.Size([16])
percent tensor([0.7051, 0.7091, 0.7618, 0.7094, 0.8027, 0.8502, 0.6731, 0.5397, 0.7740,
        0.7179, 0.7525, 0.7172, 0.7127, 0.7343, 0.5884, 0.7290],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9990, 0.9995, 0.9995, 0.9998, 0.9997, 0.9998, 0.9995, 0.9995,
        0.9995, 0.9998, 0.9995, 0.9996, 0.9990, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 117 | Batch_idx: 0 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (3697/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (4873/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (6052/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (7250/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (8434/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (93.00%) (9644/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (10819/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (12004/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (13215/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (14421/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (15616/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (16811/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (17993/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (19188/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (20374/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (21562/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (22747/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (23940/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (25136/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (26327/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (27519/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (28722/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (29916/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (31121/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (32317/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (33496/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (34683/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (35875/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (37088/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (38275/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (39458/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (40654/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (41837/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (43046/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (44227/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (45411/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (46566/50000)
# TEST : Loss: (0.3844) | Acc: (87.00%) (8766/10000)
percent tensor([0.5517, 0.5599, 0.5342, 0.5250, 0.5468, 0.5222, 0.5624, 0.5422, 0.5706,
        0.5599, 0.5685, 0.5530, 0.5603, 0.5653, 0.5386, 0.5450],
       device='cuda:0') torch.Size([16])
percent tensor([0.4863, 0.4887, 0.4698, 0.4729, 0.4728, 0.4820, 0.4862, 0.4791, 0.4823,
        0.4818, 0.4909, 0.4701, 0.4896, 0.4897, 0.4800, 0.4866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5727, 0.4921, 0.5340, 0.6010, 0.5496, 0.6229, 0.5127, 0.5750, 0.5770,
        0.5114, 0.5333, 0.4840, 0.5226, 0.6291, 0.5080, 0.5868],
       device='cuda:0') torch.Size([16])
percent tensor([0.6623, 0.6960, 0.6066, 0.6077, 0.6032, 0.6150, 0.6735, 0.6236, 0.6712,
        0.6928, 0.7082, 0.6419, 0.6934, 0.6948, 0.6530, 0.6694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5533, 0.5371, 0.6660, 0.6817, 0.7053, 0.6666, 0.6040, 0.6051, 0.6562,
        0.5427, 0.6268, 0.6344, 0.5501, 0.5945, 0.5769, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.6355, 0.6275, 0.6565, 0.6578, 0.6881, 0.7005, 0.6475, 0.6081, 0.6638,
        0.6254, 0.6270, 0.6199, 0.6406, 0.6493, 0.6015, 0.6546],
       device='cuda:0') torch.Size([16])
percent tensor([0.6952, 0.7085, 0.7545, 0.6920, 0.7897, 0.8408, 0.6612, 0.5222, 0.7746,
        0.7220, 0.7511, 0.7081, 0.7141, 0.7331, 0.5788, 0.7165],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9990, 0.9996, 0.9994, 0.9998, 0.9998, 0.9998, 0.9995, 0.9995,
        0.9995, 0.9998, 0.9995, 0.9996, 0.9990, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 118 | Batch_idx: 0 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (2515/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (4941/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (6145/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (94.00%) (7346/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (94.00%) (8552/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (94.00%) (9752/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (94.00%) (10955/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (12143/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (13346/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (14535/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (15731/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (16938/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (18130/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (19340/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (20539/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (21739/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (22945/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (24149/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (25344/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (26542/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (27734/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (28928/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (30115/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (31316/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (32513/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (33714/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (34930/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (36117/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (37331/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (38528/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (39737/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (40944/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (42138/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (43331/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (44533/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (45709/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (46857/50000)
# TEST : Loss: (0.3775) | Acc: (87.00%) (8776/10000)
percent tensor([0.5470, 0.5553, 0.5294, 0.5199, 0.5419, 0.5169, 0.5576, 0.5373, 0.5660,
        0.5553, 0.5638, 0.5484, 0.5557, 0.5608, 0.5337, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.4876, 0.4905, 0.4704, 0.4735, 0.4735, 0.4833, 0.4877, 0.4802, 0.4834,
        0.4831, 0.4925, 0.4708, 0.4911, 0.4914, 0.4814, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5635, 0.4861, 0.5263, 0.5960, 0.5415, 0.6157, 0.5052, 0.5705, 0.5692,
        0.5044, 0.5263, 0.4760, 0.5131, 0.6241, 0.5014, 0.5796],
       device='cuda:0') torch.Size([16])
percent tensor([0.6629, 0.6976, 0.6067, 0.6072, 0.6037, 0.6153, 0.6741, 0.6249, 0.6707,
        0.6930, 0.7082, 0.6423, 0.6947, 0.6956, 0.6541, 0.6700],
       device='cuda:0') torch.Size([16])
percent tensor([0.5502, 0.5355, 0.6650, 0.6826, 0.7093, 0.6737, 0.6059, 0.6047, 0.6542,
        0.5367, 0.6251, 0.6329, 0.5454, 0.5944, 0.5764, 0.5695],
       device='cuda:0') torch.Size([16])
percent tensor([0.6396, 0.6355, 0.6599, 0.6612, 0.6914, 0.7040, 0.6531, 0.6123, 0.6663,
        0.6295, 0.6286, 0.6219, 0.6460, 0.6531, 0.6063, 0.6601],
       device='cuda:0') torch.Size([16])
percent tensor([0.6964, 0.7209, 0.7561, 0.6882, 0.7896, 0.8390, 0.6674, 0.5234, 0.7778,
        0.7306, 0.7523, 0.7102, 0.7192, 0.7379, 0.5840, 0.7163],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9990, 0.9997, 0.9995, 0.9999, 0.9998, 0.9998, 0.9996, 0.9995,
        0.9995, 0.9998, 0.9995, 0.9996, 0.9989, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (94.00%) (1325/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (3715/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (94.00%) (4934/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (6135/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (94.00%) (7340/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (8534/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (9740/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (10944/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (12146/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (13347/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (14544/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (93.00%) (15761/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (94.00%) (16968/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (18185/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (94.00%) (19401/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (20614/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (21812/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (94.00%) (23012/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (94.00%) (24201/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (94.00%) (25407/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (94.00%) (26596/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (94.00%) (27800/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (29014/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (30218/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (94.00%) (31431/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (94.00%) (32617/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (94.00%) (33821/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (35006/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (36215/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (94.00%) (37421/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (94.00%) (38625/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (93.00%) (39819/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (41027/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (42222/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (43425/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (44615/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (45814/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (46976/50000)
# TEST : Loss: (0.3729) | Acc: (87.00%) (8795/10000)
percent tensor([0.5517, 0.5608, 0.5347, 0.5246, 0.5476, 0.5213, 0.5633, 0.5427, 0.5710,
        0.5608, 0.5690, 0.5539, 0.5607, 0.5654, 0.5388, 0.5449],
       device='cuda:0') torch.Size([16])
percent tensor([0.4871, 0.4910, 0.4702, 0.4729, 0.4733, 0.4829, 0.4878, 0.4801, 0.4828,
        0.4833, 0.4922, 0.4707, 0.4909, 0.4913, 0.4812, 0.4879],
       device='cuda:0') torch.Size([16])
percent tensor([0.5641, 0.4947, 0.5297, 0.5965, 0.5447, 0.6126, 0.5121, 0.5740, 0.5724,
        0.5127, 0.5308, 0.4841, 0.5190, 0.6291, 0.5047, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.6589, 0.6958, 0.6028, 0.6026, 0.5999, 0.6112, 0.6706, 0.6207, 0.6670,
        0.6906, 0.7049, 0.6386, 0.6919, 0.6922, 0.6501, 0.6663],
       device='cuda:0') torch.Size([16])
percent tensor([0.5431, 0.5261, 0.6578, 0.6770, 0.7057, 0.6721, 0.5980, 0.6004, 0.6427,
        0.5263, 0.6153, 0.6219, 0.5343, 0.5855, 0.5690, 0.5668],
       device='cuda:0') torch.Size([16])
percent tensor([0.6315, 0.6282, 0.6540, 0.6542, 0.6846, 0.6990, 0.6447, 0.6034, 0.6584,
        0.6213, 0.6202, 0.6141, 0.6409, 0.6444, 0.5975, 0.6532],
       device='cuda:0') torch.Size([16])
percent tensor([0.7074, 0.7330, 0.7635, 0.6914, 0.7903, 0.8466, 0.6764, 0.5198, 0.7914,
        0.7421, 0.7682, 0.7212, 0.7390, 0.7501, 0.5954, 0.7248],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9997, 0.9994, 0.9998, 0.9998, 0.9997, 0.9996, 0.9996,
        0.9996, 0.9998, 0.9994, 0.9997, 0.9990, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (94.00%) (2527/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (94.00%) (3735/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (94.00%) (4936/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (6130/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (7333/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (8541/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (94.00%) (9748/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.1800) |  Loss2: (0.0000) | Acc: (93.00%) (10939/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (12143/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (13331/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (14524/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (15721/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (16928/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (18132/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (19335/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (20541/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (21721/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (22904/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (24098/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (25282/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (26459/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (27646/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (28830/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (30032/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (31238/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (32437/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (33626/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (34811/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (36018/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (37217/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (38416/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (39618/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (40819/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (41994/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (43185/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (44370/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.1903) |  Loss2: (0.0000) | Acc: (93.00%) (45554/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (46693/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_120.pth.tar'
# TEST : Loss: (0.4372) | Acc: (86.00%) (8654/10000)
percent tensor([0.5536, 0.5610, 0.5364, 0.5243, 0.5483, 0.5245, 0.5638, 0.5437, 0.5735,
        0.5615, 0.5714, 0.5544, 0.5624, 0.5653, 0.5402, 0.5467],
       device='cuda:0') torch.Size([16])
percent tensor([0.4883, 0.4916, 0.4719, 0.4726, 0.4745, 0.4831, 0.4883, 0.4811, 0.4849,
        0.4847, 0.4933, 0.4716, 0.4919, 0.4912, 0.4818, 0.4886],
       device='cuda:0') torch.Size([16])
percent tensor([0.5639, 0.4963, 0.5216, 0.5878, 0.5419, 0.6159, 0.5150, 0.5555, 0.5688,
        0.5042, 0.5313, 0.4775, 0.5093, 0.6337, 0.5055, 0.5763],
       device='cuda:0') torch.Size([16])
percent tensor([0.6594, 0.7012, 0.6051, 0.5978, 0.6005, 0.6114, 0.6763, 0.6266, 0.6700,
        0.6953, 0.7139, 0.6438, 0.6966, 0.6906, 0.6549, 0.6680],
       device='cuda:0') torch.Size([16])
percent tensor([0.5389, 0.4969, 0.6792, 0.6907, 0.7174, 0.6757, 0.5922, 0.5975, 0.6165,
        0.5129, 0.5859, 0.6189, 0.5126, 0.5644, 0.5583, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.6392, 0.6224, 0.6509, 0.6443, 0.6802, 0.7073, 0.6461, 0.5978, 0.6518,
        0.6202, 0.6136, 0.6159, 0.6416, 0.6469, 0.5953, 0.6554],
       device='cuda:0') torch.Size([16])
percent tensor([0.7171, 0.7211, 0.7471, 0.6550, 0.7629, 0.8557, 0.6726, 0.5013, 0.7603,
        0.7427, 0.7515, 0.7275, 0.7283, 0.7496, 0.5870, 0.7164],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9997, 0.9996, 0.9998, 0.9997, 0.9998, 0.9997, 0.9997,
        0.9998, 0.9999, 0.9996, 0.9997, 0.9994, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(181.3763, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(819.6234, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.0258, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1520.1195, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(493.4349, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2241.5286, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4270.6641, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1389.2518, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6162.8467, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11800.4932, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3913.0605, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16506.3965, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 121 | Batch_idx: 0 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (92.00%) (1308/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (2514/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (3718/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (4916/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (6123/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (7326/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (8526/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (9716/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (10911/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (12121/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (13322/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (14524/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (15730/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (16932/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (18142/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (19342/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (20539/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (21740/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (22940/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (24133/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (25339/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (26539/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (27743/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (28950/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (30144/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (31337/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (32535/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (33732/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (34918/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (36123/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (37323/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (38516/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (39712/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (40906/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (42100/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (43295/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (44488/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (45677/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (46811/50000)
# TEST : Loss: (0.4081) | Acc: (87.00%) (8728/10000)
percent tensor([0.5538, 0.5598, 0.5414, 0.5269, 0.5531, 0.5247, 0.5649, 0.5449, 0.5717,
        0.5620, 0.5696, 0.5591, 0.5615, 0.5624, 0.5407, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.4887, 0.4897, 0.4735, 0.4733, 0.4767, 0.4839, 0.4880, 0.4812, 0.4849,
        0.4842, 0.4926, 0.4730, 0.4917, 0.4885, 0.4816, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5554, 0.4951, 0.5215, 0.5876, 0.5441, 0.6079, 0.5091, 0.5622, 0.5721,
        0.5060, 0.5322, 0.4714, 0.5058, 0.6314, 0.5046, 0.5758],
       device='cuda:0') torch.Size([16])
percent tensor([0.6642, 0.7038, 0.6034, 0.6027, 0.6051, 0.6182, 0.6811, 0.6272, 0.6740,
        0.6966, 0.7140, 0.6431, 0.6968, 0.6969, 0.6577, 0.6716],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.5084, 0.6744, 0.6733, 0.7011, 0.6495, 0.6026, 0.5989, 0.6254,
        0.5191, 0.6055, 0.6283, 0.5296, 0.5980, 0.5608, 0.5430],
       device='cuda:0') torch.Size([16])
percent tensor([0.6350, 0.6250, 0.6639, 0.6483, 0.6878, 0.7023, 0.6464, 0.6135, 0.6459,
        0.6219, 0.6143, 0.6254, 0.6398, 0.6437, 0.6030, 0.6563],
       device='cuda:0') torch.Size([16])
percent tensor([0.7110, 0.7255, 0.7643, 0.6700, 0.7811, 0.8465, 0.6490, 0.5393, 0.7468,
        0.7359, 0.7559, 0.7231, 0.7127, 0.7475, 0.5951, 0.7187],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9997, 0.9995, 0.9999, 0.9998, 0.9997, 0.9997, 0.9995,
        0.9997, 0.9998, 0.9995, 0.9996, 0.9992, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 122 | Batch_idx: 0 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (2536/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (3746/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (4944/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (6139/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (93.00%) (7339/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (8526/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (93.00%) (9740/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (93.00%) (10942/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (12150/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (13348/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (94.00%) (14560/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (15768/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (93.00%) (16954/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (18143/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (19336/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (20520/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (21706/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (22908/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (24121/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (25333/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (26537/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (27744/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (28949/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (30144/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (31356/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (32571/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (33759/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (34965/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1786) |  Loss2: (0.0000) | Acc: (93.00%) (36145/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (37332/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (38547/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (39737/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (40922/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1786) |  Loss2: (0.0000) | Acc: (93.00%) (42132/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (43331/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (44530/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (45728/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (46873/50000)
# TEST : Loss: (0.4263) | Acc: (86.00%) (8681/10000)
percent tensor([0.5550, 0.5623, 0.5401, 0.5261, 0.5520, 0.5258, 0.5666, 0.5451, 0.5749,
        0.5631, 0.5726, 0.5578, 0.5635, 0.5665, 0.5423, 0.5477],
       device='cuda:0') torch.Size([16])
percent tensor([0.4878, 0.4909, 0.4721, 0.4721, 0.4750, 0.4822, 0.4881, 0.4811, 0.4844,
        0.4848, 0.4929, 0.4731, 0.4913, 0.4903, 0.4812, 0.4877],
       device='cuda:0') torch.Size([16])
percent tensor([0.5622, 0.5057, 0.5261, 0.5878, 0.5472, 0.6112, 0.5163, 0.5633, 0.5698,
        0.5109, 0.5359, 0.4818, 0.5111, 0.6306, 0.5129, 0.5802],
       device='cuda:0') torch.Size([16])
percent tensor([0.6568, 0.6986, 0.6060, 0.6022, 0.5996, 0.6042, 0.6736, 0.6233, 0.6679,
        0.6932, 0.7060, 0.6430, 0.6958, 0.6885, 0.6500, 0.6613],
       device='cuda:0') torch.Size([16])
percent tensor([0.5449, 0.5252, 0.6703, 0.6832, 0.7181, 0.6789, 0.5972, 0.6019, 0.6261,
        0.5346, 0.6165, 0.6185, 0.5282, 0.5902, 0.5744, 0.5713],
       device='cuda:0') torch.Size([16])
percent tensor([0.6323, 0.6321, 0.6581, 0.6453, 0.6841, 0.6995, 0.6466, 0.6047, 0.6572,
        0.6295, 0.6277, 0.6195, 0.6482, 0.6508, 0.6090, 0.6558],
       device='cuda:0') torch.Size([16])
percent tensor([0.6958, 0.7168, 0.7476, 0.6400, 0.7639, 0.8464, 0.6424, 0.5151, 0.7636,
        0.7329, 0.7644, 0.7249, 0.7263, 0.7498, 0.6043, 0.6921],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9997, 0.9996, 0.9999, 0.9995, 0.9997, 0.9996, 0.9994,
        0.9997, 0.9998, 0.9997, 0.9995, 0.9992, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 123 | Batch_idx: 0 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (93.00%) (1319/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (2527/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (3730/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (93.00%) (4930/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (6127/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (7334/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (93.00%) (8537/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (93.00%) (9740/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (10930/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (12131/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (93.00%) (13350/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (93.00%) (14553/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (93.00%) (15760/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (93.00%) (16959/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (18170/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (19377/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (20572/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (93.00%) (21773/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (22970/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (24167/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (25370/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (26578/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (93.00%) (27786/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (28980/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (30168/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (31362/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (32577/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (33780/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (34965/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (36181/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (37381/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (38584/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (39759/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (40964/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (42158/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (43339/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (44542/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (45744/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (46903/50000)
# TEST : Loss: (0.3910) | Acc: (87.00%) (8786/10000)
percent tensor([0.5543, 0.5634, 0.5372, 0.5271, 0.5500, 0.5249, 0.5660, 0.5458, 0.5739,
        0.5629, 0.5720, 0.5558, 0.5634, 0.5676, 0.5419, 0.5479],
       device='cuda:0') torch.Size([16])
percent tensor([0.4882, 0.4907, 0.4711, 0.4730, 0.4738, 0.4818, 0.4876, 0.4814, 0.4854,
        0.4849, 0.4934, 0.4720, 0.4922, 0.4892, 0.4807, 0.4884],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5073, 0.5294, 0.5978, 0.5484, 0.6125, 0.5193, 0.5653, 0.5690,
        0.5180, 0.5352, 0.4827, 0.5121, 0.6347, 0.5144, 0.5824],
       device='cuda:0') torch.Size([16])
percent tensor([0.6602, 0.6996, 0.6077, 0.6016, 0.6038, 0.6140, 0.6734, 0.6250, 0.6663,
        0.6925, 0.7085, 0.6431, 0.6931, 0.6911, 0.6525, 0.6674],
       device='cuda:0') torch.Size([16])
percent tensor([0.5434, 0.5163, 0.6682, 0.6694, 0.7121, 0.6698, 0.6022, 0.6054, 0.6265,
        0.5390, 0.6038, 0.6209, 0.5387, 0.5884, 0.5753, 0.5598],
       device='cuda:0') torch.Size([16])
percent tensor([0.6335, 0.6205, 0.6620, 0.6539, 0.6865, 0.7004, 0.6548, 0.6141, 0.6496,
        0.6176, 0.6170, 0.6203, 0.6410, 0.6469, 0.6053, 0.6597],
       device='cuda:0') torch.Size([16])
percent tensor([0.7118, 0.7336, 0.7651, 0.6965, 0.7904, 0.8531, 0.6844, 0.5410, 0.7388,
        0.7167, 0.7375, 0.7272, 0.7306, 0.7291, 0.6121, 0.7207],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9992, 0.9997, 0.9995, 0.9998, 0.9995, 0.9998, 0.9995, 0.9993,
        0.9997, 0.9998, 0.9995, 0.9996, 0.9991, 0.9992, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (1317/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (2491/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (3682/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (4856/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (6020/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (7215/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (8410/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (9602/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (10771/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (11944/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (13125/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (14306/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (15500/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (16667/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (17849/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (19030/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (20183/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (21375/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (22556/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (23744/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (24942/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (26127/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (27318/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (28494/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (29687/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (30867/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (32063/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (33257/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (34456/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (35646/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (36836/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (38029/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (39223/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (40412/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (41597/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (42794/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (43988/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (45172/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (46333/50000)
# TEST : Loss: (0.4157) | Acc: (87.00%) (8706/10000)
percent tensor([0.5639, 0.5767, 0.5430, 0.5373, 0.5581, 0.5355, 0.5773, 0.5565, 0.5854,
        0.5742, 0.5837, 0.5636, 0.5746, 0.5821, 0.5536, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.4846, 0.4870, 0.4651, 0.4686, 0.4684, 0.4788, 0.4831, 0.4759, 0.4814,
        0.4808, 0.4902, 0.4659, 0.4886, 0.4862, 0.4761, 0.4847],
       device='cuda:0') torch.Size([16])
percent tensor([0.5747, 0.5236, 0.5247, 0.6006, 0.5446, 0.6162, 0.5289, 0.5645, 0.5813,
        0.5312, 0.5536, 0.4871, 0.5322, 0.6437, 0.5262, 0.5887],
       device='cuda:0') torch.Size([16])
percent tensor([0.6482, 0.6842, 0.6036, 0.5971, 0.5977, 0.6016, 0.6618, 0.6184, 0.6554,
        0.6794, 0.6945, 0.6393, 0.6794, 0.6767, 0.6417, 0.6529],
       device='cuda:0') torch.Size([16])
percent tensor([0.5583, 0.5179, 0.6907, 0.6960, 0.7357, 0.6979, 0.6076, 0.6273, 0.6353,
        0.5488, 0.6076, 0.6314, 0.5342, 0.5789, 0.5882, 0.5821],
       device='cuda:0') torch.Size([16])
percent tensor([0.6693, 0.6525, 0.6774, 0.6777, 0.7066, 0.7277, 0.6815, 0.6351, 0.6854,
        0.6551, 0.6521, 0.6390, 0.6807, 0.6852, 0.6310, 0.6955],
       device='cuda:0') torch.Size([16])
percent tensor([0.6801, 0.6924, 0.7143, 0.6713, 0.7615, 0.8405, 0.6432, 0.5015, 0.7373,
        0.7030, 0.7236, 0.6964, 0.7153, 0.7350, 0.5804, 0.6892],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9991, 0.9994, 0.9996, 0.9997, 0.9997, 0.9999, 0.9995, 0.9993,
        0.9997, 0.9998, 0.9996, 0.9996, 0.9992, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 125 | Batch_idx: 0 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (1305/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (2511/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (3703/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (4904/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (6111/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (7300/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (8507/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (9690/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (10904/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (12104/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (13298/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (14497/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (15702/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (16916/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (18099/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (19293/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (20480/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (21672/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (22874/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (24065/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (25247/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (26451/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (27637/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (28855/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (30059/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (31266/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (32477/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (33672/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (34874/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (36066/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (37263/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (38467/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (39666/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (40850/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (42060/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (43253/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (44459/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (45653/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (46815/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_125.pth.tar'
# TEST : Loss: (0.4029) | Acc: (87.00%) (8747/10000)
percent tensor([0.5593, 0.5714, 0.5409, 0.5354, 0.5547, 0.5318, 0.5721, 0.5539, 0.5806,
        0.5699, 0.5783, 0.5603, 0.5700, 0.5770, 0.5494, 0.5543],
       device='cuda:0') torch.Size([16])
percent tensor([0.4839, 0.4855, 0.4639, 0.4674, 0.4673, 0.4784, 0.4816, 0.4746, 0.4806,
        0.4795, 0.4897, 0.4644, 0.4881, 0.4843, 0.4750, 0.4838],
       device='cuda:0') torch.Size([16])
percent tensor([0.5708, 0.5252, 0.5146, 0.5956, 0.5309, 0.6082, 0.5231, 0.5565, 0.5820,
        0.5334, 0.5591, 0.4817, 0.5351, 0.6467, 0.5211, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.6439, 0.6793, 0.5997, 0.5952, 0.5943, 0.5966, 0.6577, 0.6154, 0.6525,
        0.6747, 0.6915, 0.6359, 0.6747, 0.6732, 0.6374, 0.6481],
       device='cuda:0') torch.Size([16])
percent tensor([0.5665, 0.5233, 0.7025, 0.7047, 0.7457, 0.7092, 0.6177, 0.6388, 0.6367,
        0.5541, 0.6061, 0.6377, 0.5360, 0.5836, 0.5974, 0.5895],
       device='cuda:0') torch.Size([16])
percent tensor([0.6568, 0.6426, 0.6654, 0.6656, 0.6969, 0.7216, 0.6679, 0.6175, 0.6763,
        0.6419, 0.6382, 0.6251, 0.6712, 0.6761, 0.6156, 0.6841],
       device='cuda:0') torch.Size([16])
percent tensor([0.6803, 0.6961, 0.7295, 0.6838, 0.7772, 0.8440, 0.6494, 0.5075, 0.7485,
        0.7029, 0.7273, 0.7117, 0.7134, 0.7374, 0.5876, 0.6846],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9992, 0.9995, 0.9996, 0.9997, 0.9997, 0.9999, 0.9996, 0.9994,
        0.9997, 0.9998, 0.9996, 0.9996, 0.9992, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (92.00%) (1307/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (2517/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (94.00%) (3730/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (4932/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (6136/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (7336/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (8538/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (9732/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (10931/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (12132/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (13329/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (14524/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (15720/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (16928/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (18114/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (19322/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (20523/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (21716/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (22911/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (24112/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (25313/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (26520/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (27730/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (28942/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (30134/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (31343/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (32547/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (33753/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (34946/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (36142/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (37327/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (38545/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (39740/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (40938/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (42139/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (43354/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (44559/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (45751/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (46899/50000)
# TEST : Loss: (0.3977) | Acc: (87.00%) (8777/10000)
percent tensor([0.5569, 0.5690, 0.5395, 0.5347, 0.5525, 0.5300, 0.5693, 0.5528, 0.5778,
        0.5677, 0.5753, 0.5583, 0.5676, 0.5746, 0.5474, 0.5522],
       device='cuda:0') torch.Size([16])
percent tensor([0.4831, 0.4845, 0.4633, 0.4663, 0.4667, 0.4776, 0.4807, 0.4735, 0.4802,
        0.4788, 0.4892, 0.4636, 0.4877, 0.4835, 0.4739, 0.4829],
       device='cuda:0') torch.Size([16])
percent tensor([0.5613, 0.5175, 0.5077, 0.5885, 0.5231, 0.5991, 0.5149, 0.5494, 0.5766,
        0.5258, 0.5532, 0.4749, 0.5272, 0.6422, 0.5121, 0.5775],
       device='cuda:0') torch.Size([16])
percent tensor([0.6469, 0.6812, 0.6039, 0.6002, 0.5980, 0.5987, 0.6612, 0.6201, 0.6566,
        0.6779, 0.6952, 0.6404, 0.6771, 0.6769, 0.6402, 0.6507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5649, 0.5156, 0.7054, 0.7094, 0.7488, 0.7121, 0.6137, 0.6409, 0.6295,
        0.5465, 0.5968, 0.6331, 0.5268, 0.5760, 0.5951, 0.5861],
       device='cuda:0') torch.Size([16])
percent tensor([0.6574, 0.6452, 0.6651, 0.6645, 0.6982, 0.7233, 0.6681, 0.6161, 0.6771,
        0.6426, 0.6358, 0.6226, 0.6733, 0.6763, 0.6134, 0.6863],
       device='cuda:0') torch.Size([16])
percent tensor([0.6632, 0.6847, 0.7258, 0.6748, 0.7739, 0.8380, 0.6380, 0.5009, 0.7413,
        0.6882, 0.7144, 0.7037, 0.6979, 0.7241, 0.5762, 0.6686],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9992, 0.9995, 0.9996, 0.9997, 0.9998, 0.9999, 0.9995, 0.9994,
        0.9997, 0.9998, 0.9996, 0.9997, 0.9991, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 127 | Batch_idx: 0 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (2520/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (3718/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (4913/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (6133/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (94.00%) (7343/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (94.00%) (8549/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (94.00%) (9749/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (10957/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (94.00%) (12164/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (94.00%) (13374/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (14588/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (15799/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (16993/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (94.00%) (18181/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (94.00%) (19376/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (94.00%) (20580/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (94.00%) (21786/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (94.00%) (22982/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (94.00%) (24194/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (94.00%) (25407/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (26618/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (27819/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (94.00%) (29019/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (30230/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (94.00%) (31427/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (32625/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (33847/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (35055/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (94.00%) (36242/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (94.00%) (37428/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (38619/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (94.00%) (39829/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (41042/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (94.00%) (42255/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (43468/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (94.00%) (44678/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (94.00%) (45885/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (47037/50000)
# TEST : Loss: (0.3940) | Acc: (87.00%) (8758/10000)
percent tensor([0.5597, 0.5724, 0.5436, 0.5392, 0.5563, 0.5334, 0.5728, 0.5570, 0.5806,
        0.5711, 0.5780, 0.5621, 0.5704, 0.5779, 0.5512, 0.5555],
       device='cuda:0') torch.Size([16])
percent tensor([0.4831, 0.4843, 0.4635, 0.4660, 0.4669, 0.4776, 0.4806, 0.4733, 0.4806,
        0.4788, 0.4895, 0.4637, 0.4880, 0.4828, 0.4736, 0.4826],
       device='cuda:0') torch.Size([16])
percent tensor([0.5645, 0.5256, 0.5108, 0.5909, 0.5254, 0.6003, 0.5205, 0.5524, 0.5832,
        0.5338, 0.5607, 0.4818, 0.5347, 0.6480, 0.5174, 0.5806],
       device='cuda:0') torch.Size([16])
percent tensor([0.6465, 0.6806, 0.6036, 0.6003, 0.5968, 0.5970, 0.6606, 0.6195, 0.6576,
        0.6776, 0.6954, 0.6403, 0.6774, 0.6766, 0.6391, 0.6495],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.5197, 0.7050, 0.7079, 0.7487, 0.7125, 0.6169, 0.6411, 0.6295,
        0.5487, 0.5987, 0.6335, 0.5286, 0.5779, 0.5985, 0.5867],
       device='cuda:0') torch.Size([16])
percent tensor([0.6486, 0.6379, 0.6579, 0.6561, 0.6914, 0.7193, 0.6583, 0.6060, 0.6701,
        0.6340, 0.6265, 0.6132, 0.6664, 0.6683, 0.6027, 0.6798],
       device='cuda:0') torch.Size([16])
percent tensor([0.6718, 0.6885, 0.7438, 0.6957, 0.7889, 0.8440, 0.6499, 0.5176, 0.7499,
        0.6965, 0.7213, 0.7203, 0.7000, 0.7305, 0.5915, 0.6780],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9992, 0.9994, 0.9996, 0.9997, 0.9997, 0.9999, 0.9995, 0.9995,
        0.9997, 0.9998, 0.9997, 0.9997, 0.9991, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 128 | Batch_idx: 0 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (1331/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (3749/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (4955/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (6156/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (7367/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (8584/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (9802/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (11009/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (12217/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (13414/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (14599/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (15798/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (16995/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (18197/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (19384/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (20585/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (94.00%) (21780/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (94.00%) (22983/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (93.00%) (24174/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (25375/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (26571/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (27770/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (28964/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (30170/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (31386/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (32591/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (33783/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (34971/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (36173/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (37376/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (38574/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (39786/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (40980/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (42168/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (43354/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (44562/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1786) |  Loss2: (0.0000) | Acc: (93.00%) (45756/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (46919/50000)
# TEST : Loss: (0.4373) | Acc: (86.00%) (8660/10000)
percent tensor([0.5627, 0.5697, 0.5541, 0.5420, 0.5657, 0.5340, 0.5743, 0.5597, 0.5806,
        0.5732, 0.5769, 0.5720, 0.5706, 0.5715, 0.5519, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.4831, 0.4843, 0.4631, 0.4649, 0.4668, 0.4784, 0.4801, 0.4723, 0.4793,
        0.4788, 0.4899, 0.4629, 0.4884, 0.4822, 0.4744, 0.4834],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5062, 0.5298, 0.5785, 0.5389, 0.5912, 0.5141, 0.5500, 0.5744,
        0.5238, 0.5471, 0.5011, 0.5248, 0.6330, 0.4989, 0.5684],
       device='cuda:0') torch.Size([16])
percent tensor([0.6473, 0.6821, 0.5989, 0.5995, 0.5974, 0.5923, 0.6633, 0.6193, 0.6611,
        0.6844, 0.7007, 0.6375, 0.6787, 0.6807, 0.6388, 0.6505],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.5142, 0.7043, 0.7016, 0.7344, 0.7099, 0.6193, 0.6292, 0.6110,
        0.5232, 0.6057, 0.6329, 0.5296, 0.5786, 0.5958, 0.5719],
       device='cuda:0') torch.Size([16])
percent tensor([0.6486, 0.6495, 0.6714, 0.6495, 0.6933, 0.7104, 0.6627, 0.6134, 0.6593,
        0.6384, 0.6250, 0.6198, 0.6677, 0.6584, 0.6010, 0.6756],
       device='cuda:0') torch.Size([16])
percent tensor([0.6767, 0.6968, 0.7844, 0.6943, 0.7791, 0.8301, 0.6575, 0.5506, 0.7394,
        0.6953, 0.7111, 0.7391, 0.7068, 0.7032, 0.5901, 0.6748],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9994, 0.9996, 0.9997, 0.9998, 0.9998, 0.9998, 0.9995, 0.9998,
        0.9998, 0.9999, 0.9996, 0.9998, 0.9992, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 129 | Batch_idx: 0 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (93.00%) (2524/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (3735/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (4951/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (6147/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (7366/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (8573/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (9778/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (10994/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (12189/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (13394/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (14586/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (15800/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (17000/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (18214/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (19425/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (20635/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (21837/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (23050/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (24246/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (25457/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (26662/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (27856/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (29066/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (30282/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (31479/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (32675/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (33861/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (35061/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (36275/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (37454/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (38645/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (39843/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (41050/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (42261/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (43447/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (44642/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (45847/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (93.00%) (46996/50000)
# TEST : Loss: (0.3963) | Acc: (87.00%) (8749/10000)
percent tensor([0.5607, 0.5726, 0.5469, 0.5403, 0.5596, 0.5337, 0.5741, 0.5576, 0.5800,
        0.5726, 0.5779, 0.5657, 0.5703, 0.5759, 0.5521, 0.5556],
       device='cuda:0') torch.Size([16])
percent tensor([0.4828, 0.4855, 0.4640, 0.4661, 0.4679, 0.4788, 0.4821, 0.4724, 0.4785,
        0.4795, 0.4885, 0.4649, 0.4868, 0.4846, 0.4751, 0.4835],
       device='cuda:0') torch.Size([16])
percent tensor([0.5589, 0.5231, 0.5191, 0.5824, 0.5316, 0.5938, 0.5244, 0.5544, 0.5832,
        0.5336, 0.5551, 0.4927, 0.5274, 0.6511, 0.5106, 0.5764],
       device='cuda:0') torch.Size([16])
percent tensor([0.6452, 0.6818, 0.6071, 0.6024, 0.6025, 0.5946, 0.6637, 0.6190, 0.6579,
        0.6794, 0.6935, 0.6396, 0.6768, 0.6789, 0.6377, 0.6474],
       device='cuda:0') torch.Size([16])
percent tensor([0.5662, 0.5146, 0.6940, 0.7012, 0.7313, 0.7092, 0.6088, 0.6210, 0.6363,
        0.5475, 0.6274, 0.6283, 0.5304, 0.6133, 0.5936, 0.5830],
       device='cuda:0') torch.Size([16])
percent tensor([0.6523, 0.6524, 0.6636, 0.6518, 0.6941, 0.7216, 0.6636, 0.6081, 0.6680,
        0.6387, 0.6385, 0.6193, 0.6657, 0.6759, 0.6092, 0.6779],
       device='cuda:0') torch.Size([16])
percent tensor([0.6867, 0.7153, 0.7564, 0.6698, 0.7755, 0.8293, 0.6470, 0.5267, 0.7474,
        0.7011, 0.7330, 0.7281, 0.6958, 0.7311, 0.6044, 0.6797],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9997, 0.9996, 0.9999, 0.9997, 0.9998, 0.9997, 0.9996,
        0.9998, 0.9998, 0.9997, 0.9996, 0.9992, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 130 | Batch_idx: 0 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (2552/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (3766/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (4968/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (6170/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (7366/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (8572/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (9775/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (10993/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (12202/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (13410/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (14621/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (15828/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (17030/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (18234/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (19459/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (20653/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (21859/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (23069/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (24283/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (25489/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (26684/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (27893/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (29102/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (30302/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (31497/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (32703/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (33886/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (35082/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (36279/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (37468/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (38673/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (39875/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (41074/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (42264/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (43473/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (44682/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (45877/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (47029/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_130.pth.tar'
# TEST : Loss: (0.4332) | Acc: (86.00%) (8639/10000)
percent tensor([0.5611, 0.5706, 0.5488, 0.5394, 0.5612, 0.5324, 0.5737, 0.5578, 0.5815,
        0.5717, 0.5779, 0.5667, 0.5708, 0.5736, 0.5508, 0.5553],
       device='cuda:0') torch.Size([16])
percent tensor([0.4827, 0.4851, 0.4638, 0.4646, 0.4675, 0.4772, 0.4817, 0.4735, 0.4796,
        0.4783, 0.4886, 0.4643, 0.4876, 0.4843, 0.4743, 0.4822],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5139, 0.5183, 0.5787, 0.5294, 0.5990, 0.5178, 0.5479, 0.5847,
        0.5230, 0.5549, 0.4862, 0.5283, 0.6426, 0.5102, 0.5732],
       device='cuda:0') torch.Size([16])
percent tensor([0.6426, 0.6775, 0.5945, 0.5991, 0.5935, 0.5924, 0.6592, 0.6200, 0.6593,
        0.6753, 0.6975, 0.6295, 0.6762, 0.6792, 0.6354, 0.6480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5692, 0.5263, 0.7100, 0.7076, 0.7391, 0.7091, 0.6102, 0.6258, 0.6335,
        0.5409, 0.6055, 0.6413, 0.5350, 0.5906, 0.5917, 0.5804],
       device='cuda:0') torch.Size([16])
percent tensor([0.6535, 0.6464, 0.6685, 0.6486, 0.6947, 0.7127, 0.6573, 0.6121, 0.6648,
        0.6408, 0.6215, 0.6286, 0.6683, 0.6674, 0.6113, 0.6703],
       device='cuda:0') torch.Size([16])
percent tensor([0.6985, 0.7038, 0.7687, 0.6824, 0.7847, 0.8280, 0.6390, 0.5279, 0.7585,
        0.7120, 0.7002, 0.7347, 0.6905, 0.7210, 0.6279, 0.6586],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9997, 0.9996, 0.9998, 0.9997, 0.9999, 0.9995, 0.9997,
        0.9998, 0.9998, 0.9996, 0.9998, 0.9992, 0.9995, 0.9999],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.4978, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.0278, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(824.9977, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1520.4794, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(492.0012, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2250.2898, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4270.8936, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1384.4241, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6183.7485, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11769.8350, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3897.9075, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16440.2578, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (95.00%) (3772/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (95.00%) (4993/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (95.00%) (6216/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (95.00%) (7427/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (8632/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (9848/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (11054/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (12267/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (13469/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (14685/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (15886/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (17106/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (18308/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (19519/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (20732/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (21954/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (23172/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (24390/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (25604/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (26813/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (28020/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (29221/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (30445/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (31648/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (32867/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (34091/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (35297/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (36505/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (37722/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (38927/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (40123/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (41331/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (42533/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (43743/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (44955/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (46153/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (47306/50000)
# TEST : Loss: (0.4318) | Acc: (86.00%) (8668/10000)
percent tensor([0.5617, 0.5714, 0.5520, 0.5421, 0.5625, 0.5338, 0.5745, 0.5603, 0.5817,
        0.5733, 0.5776, 0.5687, 0.5711, 0.5748, 0.5522, 0.5570],
       device='cuda:0') torch.Size([16])
percent tensor([0.4834, 0.4857, 0.4682, 0.4659, 0.4696, 0.4791, 0.4832, 0.4756, 0.4802,
        0.4795, 0.4895, 0.4668, 0.4877, 0.4853, 0.4756, 0.4840],
       device='cuda:0') torch.Size([16])
percent tensor([0.5597, 0.5194, 0.5176, 0.5854, 0.5286, 0.6021, 0.5231, 0.5578, 0.5862,
        0.5253, 0.5576, 0.4857, 0.5252, 0.6457, 0.5145, 0.5781],
       device='cuda:0') torch.Size([16])
percent tensor([0.6476, 0.6796, 0.6048, 0.6049, 0.5966, 0.5983, 0.6599, 0.6225, 0.6624,
        0.6773, 0.6971, 0.6341, 0.6803, 0.6842, 0.6384, 0.6498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5581, 0.5273, 0.6918, 0.6973, 0.7348, 0.7060, 0.6197, 0.6260, 0.6196,
        0.5391, 0.6186, 0.6284, 0.5155, 0.5974, 0.5934, 0.5816],
       device='cuda:0') torch.Size([16])
percent tensor([0.6554, 0.6460, 0.6659, 0.6498, 0.6935, 0.7209, 0.6651, 0.6014, 0.6550,
        0.6320, 0.6282, 0.6252, 0.6718, 0.6636, 0.6130, 0.6802],
       device='cuda:0') torch.Size([16])
percent tensor([0.6896, 0.7015, 0.7713, 0.6796, 0.7804, 0.8283, 0.6560, 0.5430, 0.7441,
        0.7036, 0.7131, 0.7285, 0.7101, 0.7124, 0.6151, 0.6754],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9998, 0.9997, 0.9998, 0.9997, 0.9999, 0.9996, 0.9997,
        0.9998, 0.9999, 0.9997, 0.9998, 0.9994, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 132 | Batch_idx: 0 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (2512/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (3698/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (93.00%) (4885/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (92.00%) (6071/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (7254/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (92.00%) (8445/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (9646/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (10839/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (12034/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (13226/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (14410/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (15610/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (16796/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (17980/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (92.00%) (19160/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (92.00%) (20345/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (92.00%) (21544/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (92.00%) (22731/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (23928/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (25126/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (26321/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1946) |  Loss2: (0.0000) | Acc: (93.00%) (27523/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (28695/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (29889/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (31092/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (32275/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (33480/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (34681/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (35874/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (37077/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (38267/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (39480/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (40677/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (41890/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (43099/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (44299/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (45493/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (46633/50000)
# TEST : Loss: (0.4146) | Acc: (86.00%) (8688/10000)
percent tensor([0.5474, 0.5591, 0.5337, 0.5283, 0.5438, 0.5200, 0.5594, 0.5455, 0.5665,
        0.5590, 0.5636, 0.5507, 0.5578, 0.5637, 0.5387, 0.5436],
       device='cuda:0') torch.Size([16])
percent tensor([0.4834, 0.4858, 0.4694, 0.4654, 0.4703, 0.4784, 0.4838, 0.4763, 0.4808,
        0.4799, 0.4895, 0.4679, 0.4878, 0.4842, 0.4754, 0.4834],
       device='cuda:0') torch.Size([16])
percent tensor([0.5662, 0.5174, 0.5281, 0.5917, 0.5468, 0.6112, 0.5304, 0.5691, 0.5894,
        0.5217, 0.5500, 0.4882, 0.5260, 0.6394, 0.5228, 0.5804],
       device='cuda:0') torch.Size([16])
percent tensor([0.6912, 0.7257, 0.6363, 0.6446, 0.6300, 0.6356, 0.7037, 0.6626, 0.7024,
        0.7231, 0.7406, 0.6743, 0.7246, 0.7276, 0.6843, 0.6957],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.5208, 0.6957, 0.6947, 0.7322, 0.7027, 0.6194, 0.6197, 0.6454,
        0.5403, 0.6287, 0.6303, 0.5227, 0.6070, 0.5835, 0.5823],
       device='cuda:0') torch.Size([16])
percent tensor([0.6370, 0.6284, 0.6435, 0.6401, 0.6759, 0.7030, 0.6449, 0.5828, 0.6379,
        0.6100, 0.6092, 0.5997, 0.6515, 0.6450, 0.5941, 0.6654],
       device='cuda:0') torch.Size([16])
percent tensor([0.6920, 0.7105, 0.7378, 0.6843, 0.7687, 0.8288, 0.6597, 0.5219, 0.7444,
        0.6939, 0.7142, 0.6897, 0.7138, 0.7097, 0.5984, 0.6881],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9997, 0.9997, 0.9996, 0.9998, 0.9996, 0.9996,
        0.9998, 0.9999, 0.9997, 0.9997, 0.9993, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 133 | Batch_idx: 0 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (92.00%) (1305/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (93.00%) (3721/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (4917/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (93.00%) (6117/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (93.00%) (7317/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (93.00%) (8525/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (93.00%) (9732/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (93.00%) (10939/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (12153/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (93.00%) (13351/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (93.00%) (14551/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (15773/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (16987/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (18183/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (19403/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (20597/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (21809/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (23019/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (24204/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (25410/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (26613/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (27819/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (29028/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (30239/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (31441/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (32657/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (33863/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (35066/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (36267/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (37473/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (38658/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (39871/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (41080/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (42281/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (43491/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (44677/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (45894/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (47046/50000)
# TEST : Loss: (0.3998) | Acc: (87.00%) (8722/10000)
percent tensor([0.5489, 0.5611, 0.5360, 0.5307, 0.5458, 0.5212, 0.5614, 0.5481, 0.5677,
        0.5612, 0.5648, 0.5533, 0.5596, 0.5652, 0.5406, 0.5454],
       device='cuda:0') torch.Size([16])
percent tensor([0.4834, 0.4863, 0.4692, 0.4651, 0.4703, 0.4778, 0.4841, 0.4766, 0.4811,
        0.4803, 0.4897, 0.4682, 0.4882, 0.4840, 0.4755, 0.4832],
       device='cuda:0') torch.Size([16])
percent tensor([0.5598, 0.5107, 0.5209, 0.5854, 0.5425, 0.6052, 0.5252, 0.5628, 0.5826,
        0.5140, 0.5419, 0.4815, 0.5184, 0.6343, 0.5158, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.6826, 0.7205, 0.6259, 0.6345, 0.6196, 0.6235, 0.6964, 0.6510, 0.6944,
        0.7179, 0.7351, 0.6667, 0.7174, 0.7206, 0.6759, 0.6871],
       device='cuda:0') torch.Size([16])
percent tensor([0.5801, 0.5256, 0.7036, 0.7009, 0.7360, 0.7099, 0.6274, 0.6268, 0.6672,
        0.5507, 0.6498, 0.6404, 0.5400, 0.6195, 0.5903, 0.5913],
       device='cuda:0') torch.Size([16])
percent tensor([0.6427, 0.6357, 0.6503, 0.6467, 0.6836, 0.7062, 0.6521, 0.5963, 0.6435,
        0.6155, 0.6148, 0.6031, 0.6548, 0.6466, 0.6018, 0.6740],
       device='cuda:0') torch.Size([16])
percent tensor([0.7055, 0.7252, 0.7396, 0.6925, 0.7722, 0.8363, 0.6680, 0.5209, 0.7559,
        0.7076, 0.7237, 0.6896, 0.7268, 0.7206, 0.5994, 0.7049],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9997, 0.9997, 0.9995, 0.9998, 0.9996, 0.9996,
        0.9998, 0.9999, 0.9997, 0.9997, 0.9994, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (2539/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (3751/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (4965/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (6169/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (7371/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (8581/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (9801/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (11000/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (12194/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (13401/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (14605/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (15814/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (17031/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (18240/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (19440/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (20645/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (21850/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (23061/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (24283/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (25499/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (26707/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (27907/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (29117/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (30331/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (31539/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (32747/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (33964/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (35179/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (36391/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (37599/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (38802/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (40014/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (41220/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (42443/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (43656/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (44863/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (46077/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (47253/50000)
# TEST : Loss: (0.3909) | Acc: (87.00%) (8741/10000)
percent tensor([0.5486, 0.5606, 0.5365, 0.5313, 0.5459, 0.5209, 0.5611, 0.5486, 0.5669,
        0.5609, 0.5639, 0.5536, 0.5591, 0.5648, 0.5403, 0.5453],
       device='cuda:0') torch.Size([16])
percent tensor([0.4862, 0.4891, 0.4726, 0.4684, 0.4736, 0.4800, 0.4873, 0.4801, 0.4842,
        0.4833, 0.4924, 0.4715, 0.4910, 0.4871, 0.4783, 0.4859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5592, 0.5097, 0.5214, 0.5873, 0.5454, 0.6039, 0.5264, 0.5652, 0.5814,
        0.5130, 0.5402, 0.4821, 0.5162, 0.6340, 0.5163, 0.5740],
       device='cuda:0') torch.Size([16])
percent tensor([0.6850, 0.7240, 0.6271, 0.6350, 0.6202, 0.6230, 0.6995, 0.6514, 0.6970,
        0.7215, 0.7385, 0.6692, 0.7209, 0.7240, 0.6778, 0.6891],
       device='cuda:0') torch.Size([16])
percent tensor([0.5842, 0.5220, 0.7052, 0.7036, 0.7379, 0.7155, 0.6255, 0.6249, 0.6758,
        0.5497, 0.6580, 0.6400, 0.5434, 0.6211, 0.5898, 0.5915],
       device='cuda:0') torch.Size([16])
percent tensor([0.6480, 0.6430, 0.6606, 0.6582, 0.6941, 0.7130, 0.6603, 0.6096, 0.6507,
        0.6213, 0.6200, 0.6112, 0.6574, 0.6539, 0.6100, 0.6811],
       device='cuda:0') torch.Size([16])
percent tensor([0.6964, 0.7225, 0.7267, 0.6814, 0.7606, 0.8338, 0.6584, 0.5081, 0.7444,
        0.6967, 0.7101, 0.6760, 0.7196, 0.7162, 0.5791, 0.7008],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9997, 0.9997, 0.9995, 0.9999, 0.9996, 0.9996,
        0.9998, 0.9999, 0.9997, 0.9997, 0.9994, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (1330/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (2553/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (3771/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (4973/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (6193/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (7411/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (8620/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (9840/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (95.00%) (11073/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (12279/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (13474/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (14697/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (15921/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (17137/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (18339/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (19567/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (20785/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (21994/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (23202/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (24412/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (25628/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (26845/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (28060/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (29260/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (30480/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (31686/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (32901/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (34113/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (35320/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (36530/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (37731/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (38946/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (40178/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (41378/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (42584/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (43796/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (44998/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (46219/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (47382/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_135.pth.tar'
# TEST : Loss: (0.3837) | Acc: (87.00%) (8759/10000)
percent tensor([0.5487, 0.5607, 0.5370, 0.5320, 0.5461, 0.5213, 0.5610, 0.5490, 0.5665,
        0.5609, 0.5636, 0.5540, 0.5592, 0.5647, 0.5406, 0.5456],
       device='cuda:0') torch.Size([16])
percent tensor([0.4855, 0.4882, 0.4717, 0.4674, 0.4725, 0.4791, 0.4864, 0.4793, 0.4831,
        0.4824, 0.4915, 0.4706, 0.4901, 0.4861, 0.4773, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5541, 0.5054, 0.5149, 0.5836, 0.5409, 0.5997, 0.5218, 0.5610, 0.5757,
        0.5074, 0.5342, 0.4760, 0.5098, 0.6313, 0.5122, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.6763, 0.7166, 0.6182, 0.6256, 0.6112, 0.6127, 0.6912, 0.6420, 0.6890,
        0.7141, 0.7316, 0.6599, 0.7132, 0.7165, 0.6681, 0.6801],
       device='cuda:0') torch.Size([16])
percent tensor([0.5978, 0.5337, 0.7149, 0.7095, 0.7443, 0.7230, 0.6356, 0.6335, 0.6902,
        0.5652, 0.6739, 0.6525, 0.5593, 0.6321, 0.6012, 0.6027],
       device='cuda:0') torch.Size([16])
percent tensor([0.6477, 0.6445, 0.6626, 0.6603, 0.6968, 0.7138, 0.6612, 0.6121, 0.6518,
        0.6211, 0.6201, 0.6123, 0.6576, 0.6541, 0.6102, 0.6815],
       device='cuda:0') torch.Size([16])
percent tensor([0.7091, 0.7378, 0.7361, 0.6940, 0.7680, 0.8430, 0.6689, 0.5063, 0.7620,
        0.7113, 0.7239, 0.6884, 0.7354, 0.7342, 0.5880, 0.7103],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9997, 0.9997, 0.9995, 0.9999, 0.9996, 0.9996,
        0.9998, 0.9999, 0.9997, 0.9997, 0.9994, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 136 | Batch_idx: 0 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (94.00%) (2551/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (3745/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (4946/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (6157/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (7369/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (8585/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (9811/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (11002/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (12197/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (13419/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (14623/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (15822/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (17029/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (18231/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (19443/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (20656/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (21846/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (23052/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (24262/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (25465/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (26678/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (27889/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (29097/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (30311/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (31518/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (32727/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (33951/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (35149/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (36346/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (37560/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (38770/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (39971/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (41169/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (42353/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (43556/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (44760/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (45973/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (47141/50000)
# TEST : Loss: (0.4111) | Acc: (87.00%) (8755/10000)
percent tensor([0.5493, 0.5609, 0.5397, 0.5331, 0.5491, 0.5233, 0.5622, 0.5496, 0.5670,
        0.5612, 0.5641, 0.5565, 0.5592, 0.5651, 0.5412, 0.5459],
       device='cuda:0') torch.Size([16])
percent tensor([0.4861, 0.4883, 0.4719, 0.4688, 0.4727, 0.4796, 0.4861, 0.4791, 0.4822,
        0.4829, 0.4915, 0.4711, 0.4909, 0.4853, 0.4779, 0.4859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5607, 0.5099, 0.5220, 0.5909, 0.5406, 0.6031, 0.5193, 0.5639, 0.5685,
        0.5156, 0.5353, 0.4882, 0.5147, 0.6302, 0.5156, 0.5733],
       device='cuda:0') torch.Size([16])
percent tensor([0.6763, 0.7156, 0.6308, 0.6204, 0.6223, 0.6167, 0.6946, 0.6381, 0.6883,
        0.7174, 0.7346, 0.6719, 0.7098, 0.7133, 0.6685, 0.6772],
       device='cuda:0') torch.Size([16])
percent tensor([0.5997, 0.5281, 0.7207, 0.7124, 0.7476, 0.7155, 0.6268, 0.6452, 0.6869,
        0.5718, 0.6762, 0.6601, 0.5792, 0.6187, 0.6063, 0.6018],
       device='cuda:0') torch.Size([16])
percent tensor([0.6475, 0.6461, 0.6766, 0.6610, 0.7064, 0.7149, 0.6617, 0.6183, 0.6602,
        0.6340, 0.6215, 0.6291, 0.6561, 0.6535, 0.6110, 0.6825],
       device='cuda:0') torch.Size([16])
percent tensor([0.7008, 0.7401, 0.7540, 0.6557, 0.7671, 0.8350, 0.6501, 0.4988, 0.7573,
        0.7308, 0.7341, 0.7248, 0.7202, 0.7474, 0.6212, 0.7072],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9998, 0.9996, 0.9998, 0.9997, 0.9999, 0.9996, 0.9996,
        0.9998, 0.9999, 0.9994, 0.9997, 0.9995, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 137 | Batch_idx: 0 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (3767/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (4993/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (6190/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (7388/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (8603/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (9803/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (10993/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (12213/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (13426/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (14630/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (15836/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (17059/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (18267/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (19469/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (20678/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (21893/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (23111/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (24323/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (25527/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (26737/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (27963/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (29163/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (30372/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (31583/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (32782/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (34000/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (35215/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (36426/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (37637/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (38850/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (40057/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (41247/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (42456/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (43662/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (44877/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (46067/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (47216/50000)
# TEST : Loss: (0.4486) | Acc: (86.00%) (8650/10000)
percent tensor([0.5509, 0.5586, 0.5446, 0.5335, 0.5522, 0.5221, 0.5623, 0.5507, 0.5673,
        0.5617, 0.5634, 0.5602, 0.5602, 0.5607, 0.5402, 0.5460],
       device='cuda:0') torch.Size([16])
percent tensor([0.4877, 0.4892, 0.4723, 0.4704, 0.4722, 0.4807, 0.4855, 0.4803, 0.4833,
        0.4834, 0.4922, 0.4709, 0.4919, 0.4858, 0.4793, 0.4872],
       device='cuda:0') torch.Size([16])
percent tensor([0.5606, 0.5032, 0.5298, 0.5941, 0.5468, 0.6010, 0.5163, 0.5690, 0.5693,
        0.5139, 0.5273, 0.4913, 0.5137, 0.6265, 0.5092, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.6755, 0.7176, 0.6214, 0.6252, 0.6163, 0.6117, 0.6939, 0.6424, 0.6849,
        0.7151, 0.7348, 0.6654, 0.7107, 0.7167, 0.6703, 0.6813],
       device='cuda:0') torch.Size([16])
percent tensor([0.5939, 0.5160, 0.7259, 0.6988, 0.7451, 0.7219, 0.6268, 0.6445, 0.6718,
        0.5697, 0.6416, 0.6532, 0.5649, 0.6059, 0.5919, 0.5932],
       device='cuda:0') torch.Size([16])
percent tensor([0.6424, 0.6407, 0.6622, 0.6574, 0.6948, 0.7063, 0.6559, 0.6119, 0.6645,
        0.6300, 0.6174, 0.6154, 0.6545, 0.6518, 0.5961, 0.6650],
       device='cuda:0') torch.Size([16])
percent tensor([0.7067, 0.7438, 0.7386, 0.6663, 0.7445, 0.8460, 0.6761, 0.5044, 0.7657,
        0.7162, 0.7409, 0.6952, 0.7106, 0.7290, 0.5802, 0.7034],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9996, 0.9996, 0.9998, 0.9994, 0.9999, 0.9996, 0.9998,
        0.9998, 1.0000, 0.9996, 0.9998, 0.9991, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (2539/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (3763/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (4975/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (6198/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (7403/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (8617/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (95.00%) (9854/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (95.00%) (11069/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (95.00%) (12289/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (13497/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (14713/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (15914/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (17123/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (18333/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (19537/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (20733/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (21953/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (23176/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (24372/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (25575/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (26786/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (27991/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (29197/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (30396/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (31613/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (32837/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (34050/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (35270/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (36479/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (37663/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (38868/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (40080/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (41288/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (42503/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (43718/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (44929/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (46142/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (47310/50000)
# TEST : Loss: (0.4126) | Acc: (87.00%) (8774/10000)
percent tensor([0.5502, 0.5604, 0.5421, 0.5328, 0.5513, 0.5219, 0.5631, 0.5513, 0.5679,
        0.5622, 0.5641, 0.5595, 0.5601, 0.5642, 0.5409, 0.5462],
       device='cuda:0') torch.Size([16])
percent tensor([0.4866, 0.4898, 0.4698, 0.4701, 0.4712, 0.4797, 0.4859, 0.4793, 0.4818,
        0.4833, 0.4918, 0.4692, 0.4910, 0.4885, 0.4787, 0.4869],
       device='cuda:0') torch.Size([16])
percent tensor([0.5524, 0.5096, 0.5229, 0.5922, 0.5438, 0.5875, 0.5203, 0.5712, 0.5635,
        0.5173, 0.5277, 0.4913, 0.5098, 0.6319, 0.5088, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.6744, 0.7172, 0.6184, 0.6227, 0.6171, 0.6145, 0.6928, 0.6413, 0.6876,
        0.7144, 0.7320, 0.6629, 0.7109, 0.7133, 0.6670, 0.6792],
       device='cuda:0') torch.Size([16])
percent tensor([0.5926, 0.5289, 0.7239, 0.7114, 0.7460, 0.7284, 0.6304, 0.6413, 0.6726,
        0.5697, 0.6720, 0.6545, 0.5601, 0.6286, 0.6182, 0.5983],
       device='cuda:0') torch.Size([16])
percent tensor([0.6399, 0.6468, 0.6570, 0.6558, 0.6953, 0.7031, 0.6597, 0.6142, 0.6603,
        0.6313, 0.6221, 0.6114, 0.6491, 0.6612, 0.6085, 0.6733],
       device='cuda:0') torch.Size([16])
percent tensor([0.7016, 0.7648, 0.7378, 0.6502, 0.7481, 0.8273, 0.6797, 0.5083, 0.7578,
        0.7481, 0.7591, 0.7310, 0.7127, 0.7437, 0.5756, 0.7024],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9998, 0.9998, 0.9998, 0.9996, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9995, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 139 | Batch_idx: 0 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (2558/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (3782/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (5001/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (6219/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (7442/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (8660/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (9868/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (11081/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (12297/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (13506/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (94.00%) (14712/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (94.00%) (15921/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (94.00%) (17142/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (18342/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (19552/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (20766/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (21973/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (23200/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (24414/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (25632/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (26852/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (28070/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (29286/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (30508/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (31729/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (32934/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (34140/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (35343/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (36545/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (37765/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (38983/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (40193/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (41415/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (42625/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (43837/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (45053/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (46262/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (47442/50000)
# TEST : Loss: (0.4830) | Acc: (85.00%) (8573/10000)
percent tensor([0.5500, 0.5607, 0.5406, 0.5328, 0.5488, 0.5219, 0.5621, 0.5506, 0.5671,
        0.5617, 0.5642, 0.5573, 0.5601, 0.5643, 0.5413, 0.5466],
       device='cuda:0') torch.Size([16])
percent tensor([0.4859, 0.4899, 0.4699, 0.4695, 0.4711, 0.4793, 0.4854, 0.4798, 0.4811,
        0.4822, 0.4914, 0.4677, 0.4902, 0.4862, 0.4786, 0.4870],
       device='cuda:0') torch.Size([16])
percent tensor([0.5568, 0.5125, 0.5158, 0.5913, 0.5413, 0.6025, 0.5201, 0.5646, 0.5688,
        0.5157, 0.5345, 0.4836, 0.5100, 0.6410, 0.5136, 0.5758],
       device='cuda:0') torch.Size([16])
percent tensor([0.6761, 0.7122, 0.6215, 0.6212, 0.6170, 0.6114, 0.6905, 0.6373, 0.6945,
        0.7144, 0.7326, 0.6643, 0.7138, 0.7140, 0.6626, 0.6770],
       device='cuda:0') torch.Size([16])
percent tensor([0.5832, 0.5342, 0.7245, 0.7080, 0.7425, 0.7152, 0.6379, 0.6601, 0.6545,
        0.5680, 0.6512, 0.6580, 0.5548, 0.6077, 0.6177, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.6333, 0.6448, 0.6597, 0.6603, 0.6941, 0.7058, 0.6636, 0.6181, 0.6574,
        0.6198, 0.6105, 0.6038, 0.6407, 0.6510, 0.6101, 0.6611],
       device='cuda:0') torch.Size([16])
percent tensor([0.6796, 0.7569, 0.7568, 0.7077, 0.7721, 0.8508, 0.6715, 0.5215, 0.7511,
        0.7071, 0.7303, 0.7043, 0.7009, 0.7188, 0.6164, 0.6739],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9995, 0.9998, 0.9995, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9998, 0.9996, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 140 | Batch_idx: 0 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (2534/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (3740/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (4939/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (93.00%) (6132/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (7307/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (8504/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (9684/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (10880/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (12068/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (13266/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (14462/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (15653/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (16840/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (18027/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (19226/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (20423/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (21611/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (22821/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (24018/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (25227/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (26433/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (27642/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (28842/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (30042/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (31261/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (32483/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (33689/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (34893/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (36097/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (37307/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (38524/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (39732/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (40944/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (93.00%) (42152/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (93.00%) (43368/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (44575/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (93.00%) (45774/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (93.00%) (46946/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_140.pth.tar'
# TEST : Loss: (0.4180) | Acc: (87.00%) (8731/10000)
percent tensor([0.5360, 0.5433, 0.5260, 0.5172, 0.5321, 0.5086, 0.5448, 0.5341, 0.5508,
        0.5449, 0.5478, 0.5412, 0.5445, 0.5485, 0.5250, 0.5318],
       device='cuda:0') torch.Size([16])
percent tensor([0.4862, 0.4893, 0.4662, 0.4678, 0.4669, 0.4797, 0.4832, 0.4780, 0.4800,
        0.4804, 0.4919, 0.4637, 0.4902, 0.4870, 0.4775, 0.4877],
       device='cuda:0') torch.Size([16])
percent tensor([0.5790, 0.5128, 0.5400, 0.6142, 0.5597, 0.6288, 0.5229, 0.5882, 0.5812,
        0.5174, 0.5391, 0.4961, 0.5234, 0.6435, 0.5273, 0.5939],
       device='cuda:0') torch.Size([16])
percent tensor([0.6979, 0.7349, 0.6373, 0.6350, 0.6331, 0.6315, 0.7145, 0.6570, 0.7106,
        0.7351, 0.7510, 0.6813, 0.7373, 0.7327, 0.6862, 0.7017],
       device='cuda:0') torch.Size([16])
percent tensor([0.6041, 0.5591, 0.7231, 0.7036, 0.7377, 0.7271, 0.6502, 0.6425, 0.6711,
        0.5829, 0.6650, 0.6626, 0.5831, 0.6260, 0.6272, 0.6112],
       device='cuda:0') torch.Size([16])
percent tensor([0.6179, 0.6266, 0.6442, 0.6474, 0.6768, 0.6971, 0.6436, 0.5983, 0.6457,
        0.6061, 0.5970, 0.5926, 0.6211, 0.6328, 0.5937, 0.6464],
       device='cuda:0') torch.Size([16])
percent tensor([0.6388, 0.6842, 0.7121, 0.6765, 0.7323, 0.8164, 0.6129, 0.5064, 0.6820,
        0.6616, 0.6621, 0.6302, 0.5991, 0.6402, 0.5365, 0.6372],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9996, 0.9997, 0.9998, 0.9995, 0.9998, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9995, 0.9998, 0.9995, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(183.2151, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(825.2084, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(827.1558, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1519.3381, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(490.2775, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2256.5376, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4268.6836, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1379.3906, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6196.8960, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11736.7402, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3882.7041, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16374.8301, device='cuda:0')
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (2562/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (95.00%) (3777/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (4984/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (6177/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (7399/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (8605/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (9817/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (11031/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (12230/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (13432/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (14650/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (15855/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (17074/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (18291/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (19501/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (20703/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (21923/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (23134/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (24350/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (25564/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (26776/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (27988/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (29192/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (30399/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (31613/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (32830/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (34018/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (35230/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (36443/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (37665/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (38877/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (40089/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (41314/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (42532/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (43755/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (44983/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (46194/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (47358/50000)
# TEST : Loss: (0.4037) | Acc: (87.00%) (8779/10000)
percent tensor([0.5387, 0.5454, 0.5282, 0.5194, 0.5344, 0.5115, 0.5471, 0.5360, 0.5532,
        0.5470, 0.5503, 0.5434, 0.5468, 0.5509, 0.5273, 0.5345],
       device='cuda:0') torch.Size([16])
percent tensor([0.4892, 0.4915, 0.4679, 0.4698, 0.4686, 0.4826, 0.4854, 0.4800, 0.4827,
        0.4823, 0.4946, 0.4651, 0.4926, 0.4898, 0.4797, 0.4906],
       device='cuda:0') torch.Size([16])
percent tensor([0.5828, 0.5091, 0.5440, 0.6182, 0.5647, 0.6349, 0.5224, 0.5939, 0.5825,
        0.5141, 0.5354, 0.4964, 0.5239, 0.6409, 0.5276, 0.5988],
       device='cuda:0') torch.Size([16])
percent tensor([0.6908, 0.7282, 0.6274, 0.6262, 0.6252, 0.6273, 0.7069, 0.6484, 0.7015,
        0.7258, 0.7419, 0.6706, 0.7298, 0.7241, 0.6800, 0.6959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5994, 0.5579, 0.7131, 0.6968, 0.7281, 0.7251, 0.6455, 0.6279, 0.6702,
        0.5817, 0.6648, 0.6559, 0.5792, 0.6349, 0.6213, 0.6070],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.6376, 0.6508, 0.6518, 0.6813, 0.7013, 0.6544, 0.6066, 0.6526,
        0.6170, 0.6064, 0.6041, 0.6315, 0.6398, 0.6039, 0.6562],
       device='cuda:0') torch.Size([16])
percent tensor([0.6628, 0.7040, 0.7258, 0.6864, 0.7403, 0.8164, 0.6394, 0.5284, 0.6978,
        0.6877, 0.6778, 0.6488, 0.6254, 0.6526, 0.5547, 0.6669],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9997, 0.9998, 0.9998, 0.9995, 0.9998, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9995, 0.9998, 0.9996, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 142 | Batch_idx: 0 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (2562/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (94.00%) (3768/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (94.00%) (4978/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (94.00%) (6195/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (7396/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (94.00%) (8629/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (9835/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (11056/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (95.00%) (12283/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (94.00%) (13494/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (14720/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (15950/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (17175/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (18406/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (19624/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (20819/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (22031/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (23244/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (24456/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (95.00%) (25660/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (95.00%) (26877/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (95.00%) (28095/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (95.00%) (29316/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (95.00%) (30534/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (95.00%) (31755/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (32975/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (95.00%) (34179/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (95.00%) (35405/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (95.00%) (36619/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (37846/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (95.00%) (39065/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (40285/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (41503/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (42726/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (43947/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (45179/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (46399/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (47578/50000)
# TEST : Loss: (0.3999) | Acc: (87.00%) (8794/10000)
percent tensor([0.5389, 0.5455, 0.5284, 0.5199, 0.5344, 0.5120, 0.5471, 0.5362, 0.5532,
        0.5471, 0.5504, 0.5433, 0.5469, 0.5512, 0.5276, 0.5349],
       device='cuda:0') torch.Size([16])
percent tensor([0.4918, 0.4938, 0.4700, 0.4717, 0.4708, 0.4851, 0.4879, 0.4820, 0.4855,
        0.4846, 0.4974, 0.4671, 0.4951, 0.4926, 0.4818, 0.4932],
       device='cuda:0') torch.Size([16])
percent tensor([0.5912, 0.5148, 0.5537, 0.6259, 0.5753, 0.6442, 0.5303, 0.6027, 0.5915,
        0.5209, 0.5424, 0.5044, 0.5315, 0.6470, 0.5351, 0.6075],
       device='cuda:0') torch.Size([16])
percent tensor([0.6883, 0.7252, 0.6233, 0.6222, 0.6221, 0.6261, 0.7030, 0.6445, 0.6973,
        0.7220, 0.7371, 0.6652, 0.7273, 0.7184, 0.6777, 0.6940],
       device='cuda:0') torch.Size([16])
percent tensor([0.5971, 0.5578, 0.7107, 0.6989, 0.7273, 0.7261, 0.6445, 0.6255, 0.6693,
        0.5810, 0.6654, 0.6542, 0.5748, 0.6411, 0.6203, 0.6053],
       device='cuda:0') torch.Size([16])
percent tensor([0.6336, 0.6445, 0.6564, 0.6568, 0.6852, 0.7071, 0.6609, 0.6116, 0.6578,
        0.6223, 0.6133, 0.6106, 0.6378, 0.6467, 0.6113, 0.6631],
       device='cuda:0') torch.Size([16])
percent tensor([0.6842, 0.7206, 0.7387, 0.7007, 0.7492, 0.8267, 0.6578, 0.5395, 0.7152,
        0.7041, 0.7006, 0.6668, 0.6464, 0.6721, 0.5718, 0.6886],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9997, 0.9998, 0.9998, 0.9996, 0.9999, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9996, 0.9998, 0.9997, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 143 | Batch_idx: 0 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (2575/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (3789/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (5010/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (6225/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (7442/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (8654/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (9869/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (11079/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (12294/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (13503/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (14720/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (15949/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (17173/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (18400/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (19607/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (20833/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (22055/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (23284/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (24501/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (25710/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (26932/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (28149/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (29378/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (30596/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (31812/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (33032/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (34247/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (35466/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (36698/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (37915/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (39145/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (40367/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (41587/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (42797/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (44027/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (45251/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (46470/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (47646/50000)
# TEST : Loss: (0.3897) | Acc: (88.00%) (8807/10000)
percent tensor([0.5391, 0.5451, 0.5285, 0.5199, 0.5344, 0.5123, 0.5469, 0.5360, 0.5531,
        0.5469, 0.5501, 0.5433, 0.5468, 0.5509, 0.5274, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.4903, 0.4917, 0.4677, 0.4697, 0.4683, 0.4836, 0.4857, 0.4801, 0.4836,
        0.4823, 0.4954, 0.4644, 0.4934, 0.4906, 0.4796, 0.4918],
       device='cuda:0') torch.Size([16])
percent tensor([0.5869, 0.5105, 0.5471, 0.6206, 0.5691, 0.6406, 0.5242, 0.5967, 0.5866,
        0.5161, 0.5385, 0.4978, 0.5279, 0.6411, 0.5305, 0.6046],
       device='cuda:0') torch.Size([16])
percent tensor([0.6884, 0.7260, 0.6217, 0.6210, 0.6216, 0.6286, 0.7035, 0.6434, 0.6959,
        0.7213, 0.7367, 0.6636, 0.7271, 0.7185, 0.6790, 0.6953],
       device='cuda:0') torch.Size([16])
percent tensor([0.5938, 0.5540, 0.7072, 0.6978, 0.7221, 0.7207, 0.6402, 0.6223, 0.6651,
        0.5790, 0.6589, 0.6506, 0.5706, 0.6376, 0.6158, 0.6000],
       device='cuda:0') torch.Size([16])
percent tensor([0.6349, 0.6492, 0.6579, 0.6566, 0.6855, 0.7081, 0.6637, 0.6111, 0.6601,
        0.6256, 0.6154, 0.6143, 0.6416, 0.6503, 0.6142, 0.6634],
       device='cuda:0') torch.Size([16])
percent tensor([0.6844, 0.7249, 0.7367, 0.6937, 0.7413, 0.8292, 0.6591, 0.5312, 0.7185,
        0.7034, 0.7026, 0.6675, 0.6547, 0.6716, 0.5727, 0.6845],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9997, 0.9998, 0.9998, 0.9996, 0.9999, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9995, 0.9998, 0.9996, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (3778/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (4999/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (6214/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (7430/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (95.00%) (8645/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (95.00%) (9854/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (95.00%) (11067/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (12276/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (95.00%) (13508/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (14729/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (15952/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (17165/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (95.00%) (18365/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (95.00%) (19580/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (20792/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (22002/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (23213/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (24436/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (25639/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (26854/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (28066/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (29278/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (30484/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (31682/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (32895/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (34099/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (35315/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (36518/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (37742/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (38951/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (40157/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (41376/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (42579/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (43794/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (44996/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (46209/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (47386/50000)
# TEST : Loss: (0.4529) | Acc: (86.00%) (8640/10000)
percent tensor([0.5405, 0.5476, 0.5263, 0.5196, 0.5351, 0.5148, 0.5485, 0.5352, 0.5554,
        0.5480, 0.5529, 0.5423, 0.5483, 0.5538, 0.5290, 0.5362],
       device='cuda:0') torch.Size([16])
percent tensor([0.4919, 0.4933, 0.4728, 0.4712, 0.4745, 0.4850, 0.4898, 0.4801, 0.4859,
        0.4858, 0.4965, 0.4705, 0.4959, 0.4899, 0.4810, 0.4919],
       device='cuda:0') torch.Size([16])
percent tensor([0.5861, 0.5082, 0.5602, 0.6160, 0.5836, 0.6400, 0.5298, 0.5942, 0.5918,
        0.5159, 0.5368, 0.5004, 0.5270, 0.6310, 0.5269, 0.6003],
       device='cuda:0') torch.Size([16])
percent tensor([0.6883, 0.7297, 0.6159, 0.6237, 0.6169, 0.6323, 0.6992, 0.6467, 0.6955,
        0.7221, 0.7379, 0.6588, 0.7248, 0.7214, 0.6801, 0.6930],
       device='cuda:0') torch.Size([16])
percent tensor([0.5898, 0.5343, 0.6956, 0.7110, 0.7245, 0.7262, 0.6341, 0.6161, 0.6784,
        0.5578, 0.6530, 0.6339, 0.5671, 0.6388, 0.6037, 0.5973],
       device='cuda:0') torch.Size([16])
percent tensor([0.6351, 0.6416, 0.6635, 0.6502, 0.6870, 0.7090, 0.6548, 0.6012, 0.6513,
        0.6172, 0.6058, 0.6173, 0.6424, 0.6452, 0.5973, 0.6601],
       device='cuda:0') torch.Size([16])
percent tensor([0.6724, 0.7123, 0.7303, 0.6524, 0.7279, 0.8191, 0.6391, 0.4901, 0.7178,
        0.7080, 0.6915, 0.6793, 0.6921, 0.6699, 0.5293, 0.6690],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9998, 0.9997, 0.9998, 0.9992, 0.9998, 0.9997, 0.9997,
        0.9998, 0.9999, 0.9997, 0.9998, 0.9995, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (2573/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (3794/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (5014/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (6246/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (7466/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (8682/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (9909/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (11115/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (12333/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (13554/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (14767/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (15988/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (17207/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (18413/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (19638/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (20844/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (22066/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (23297/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (24513/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (25721/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (26925/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (28142/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (29357/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (30571/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (31782/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (32997/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (34213/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (35428/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (36642/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (37850/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (39062/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (40270/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (95.00%) (41473/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (42676/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (43878/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (45089/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (46296/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (47470/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_145.pth.tar'
# TEST : Loss: (0.4297) | Acc: (86.00%) (8690/10000)
percent tensor([0.5403, 0.5454, 0.5292, 0.5200, 0.5364, 0.5132, 0.5476, 0.5360, 0.5545,
        0.5478, 0.5512, 0.5445, 0.5476, 0.5506, 0.5275, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.4912, 0.4917, 0.4693, 0.4704, 0.4714, 0.4853, 0.4884, 0.4793, 0.4861,
        0.4839, 0.4959, 0.4677, 0.4942, 0.4934, 0.4812, 0.4919],
       device='cuda:0') torch.Size([16])
percent tensor([0.5810, 0.5017, 0.5339, 0.6148, 0.5522, 0.6379, 0.5150, 0.5934, 0.5799,
        0.5054, 0.5364, 0.4854, 0.5237, 0.6287, 0.5272, 0.5978],
       device='cuda:0') torch.Size([16])
percent tensor([0.6925, 0.7279, 0.6399, 0.6275, 0.6413, 0.6313, 0.7092, 0.6507, 0.6999,
        0.7257, 0.7356, 0.6791, 0.7284, 0.7181, 0.6835, 0.6945],
       device='cuda:0') torch.Size([16])
percent tensor([0.5799, 0.5351, 0.6863, 0.7049, 0.7179, 0.7179, 0.6176, 0.6082, 0.6611,
        0.5652, 0.6416, 0.6167, 0.5543, 0.6291, 0.5907, 0.5933],
       device='cuda:0') torch.Size([16])
percent tensor([0.6436, 0.6416, 0.6717, 0.6564, 0.6935, 0.7108, 0.6592, 0.6110, 0.6714,
        0.6241, 0.6214, 0.6193, 0.6469, 0.6636, 0.6017, 0.6671],
       device='cuda:0') torch.Size([16])
percent tensor([0.6911, 0.7318, 0.7317, 0.6537, 0.7275, 0.8173, 0.6442, 0.4896, 0.7597,
        0.6926, 0.7280, 0.7054, 0.7008, 0.7133, 0.5529, 0.6792],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9997, 0.9997, 0.9999, 0.9996, 0.9998, 0.9992, 0.9998,
        0.9999, 0.9999, 0.9995, 0.9998, 0.9995, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 146 | Batch_idx: 0 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (2555/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (3773/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (4998/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (6236/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (7465/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (8694/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (9910/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (11116/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (12346/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (13581/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (14800/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (16014/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (17243/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (18464/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (19690/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (20913/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (22136/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (23351/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (24584/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (25806/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (27031/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (28259/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (29476/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (30694/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (31908/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (33118/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (34336/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (35561/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (36775/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (37986/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (39210/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (40426/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (41638/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (42857/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (44079/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (45294/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (46511/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (47678/50000)
# TEST : Loss: (0.4279) | Acc: (87.00%) (8729/10000)
percent tensor([0.5410, 0.5460, 0.5298, 0.5217, 0.5366, 0.5154, 0.5479, 0.5369, 0.5558,
        0.5486, 0.5525, 0.5436, 0.5484, 0.5508, 0.5289, 0.5365],
       device='cuda:0') torch.Size([16])
percent tensor([0.4908, 0.4908, 0.4718, 0.4702, 0.4720, 0.4859, 0.4878, 0.4795, 0.4862,
        0.4843, 0.4966, 0.4680, 0.4941, 0.4898, 0.4804, 0.4914],
       device='cuda:0') torch.Size([16])
percent tensor([0.5818, 0.5113, 0.5510, 0.6170, 0.5646, 0.6283, 0.5254, 0.5941, 0.5824,
        0.5232, 0.5362, 0.4997, 0.5250, 0.6408, 0.5236, 0.5977],
       device='cuda:0') torch.Size([16])
percent tensor([0.6895, 0.7273, 0.6284, 0.6257, 0.6247, 0.6370, 0.7003, 0.6408, 0.6915,
        0.7214, 0.7345, 0.6688, 0.7247, 0.7152, 0.6834, 0.6912],
       device='cuda:0') torch.Size([16])
percent tensor([0.5884, 0.5321, 0.7113, 0.7128, 0.7447, 0.7127, 0.6274, 0.6273, 0.6682,
        0.5583, 0.6341, 0.6360, 0.5691, 0.6076, 0.5989, 0.6061],
       device='cuda:0') torch.Size([16])
percent tensor([0.6367, 0.6448, 0.6592, 0.6445, 0.6900, 0.7064, 0.6636, 0.6198, 0.6596,
        0.6194, 0.6168, 0.6182, 0.6456, 0.6489, 0.6091, 0.6622],
       device='cuda:0') torch.Size([16])
percent tensor([0.6702, 0.7288, 0.7132, 0.6387, 0.7226, 0.8008, 0.6751, 0.5157, 0.7266,
        0.6991, 0.7135, 0.6909, 0.6726, 0.6817, 0.5656, 0.6664],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9997, 0.9997, 0.9998, 0.9996, 0.9999, 0.9996, 0.9997,
        0.9998, 0.9999, 0.9996, 0.9998, 0.9994, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 147 | Batch_idx: 0 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (2558/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (3781/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (4996/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (6210/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (7427/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (8650/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (9871/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (11083/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (12311/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (13522/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (14741/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (15947/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (17181/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (18400/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (19621/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (20832/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (22041/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (23241/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (24449/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (25670/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (26885/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (28108/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (29336/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (30549/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (31766/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (32975/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (34185/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (35406/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (36636/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (37849/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (39064/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (40281/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (41501/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (42722/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (43938/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (45154/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (46374/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (47556/50000)
# TEST : Loss: (0.4233) | Acc: (87.00%) (8761/10000)
percent tensor([0.5406, 0.5463, 0.5296, 0.5208, 0.5367, 0.5147, 0.5485, 0.5368, 0.5553,
        0.5484, 0.5522, 0.5443, 0.5480, 0.5520, 0.5289, 0.5367],
       device='cuda:0') torch.Size([16])
percent tensor([0.4921, 0.4906, 0.4686, 0.4674, 0.4716, 0.4864, 0.4876, 0.4771, 0.4856,
        0.4841, 0.4963, 0.4673, 0.4950, 0.4886, 0.4802, 0.4911],
       device='cuda:0') torch.Size([16])
percent tensor([0.5840, 0.5114, 0.5493, 0.6052, 0.5677, 0.6308, 0.5293, 0.5893, 0.5832,
        0.5169, 0.5351, 0.5011, 0.5266, 0.6385, 0.5208, 0.5963],
       device='cuda:0') torch.Size([16])
percent tensor([0.6851, 0.7255, 0.6227, 0.6256, 0.6237, 0.6335, 0.6995, 0.6449, 0.6917,
        0.7217, 0.7348, 0.6637, 0.7182, 0.7156, 0.6800, 0.6942],
       device='cuda:0') torch.Size([16])
percent tensor([0.5980, 0.5574, 0.7113, 0.7242, 0.7401, 0.7184, 0.6592, 0.6309, 0.6840,
        0.5810, 0.6756, 0.6604, 0.5834, 0.6517, 0.6217, 0.6136],
       device='cuda:0') torch.Size([16])
percent tensor([0.6514, 0.6484, 0.6820, 0.6729, 0.7062, 0.7153, 0.6680, 0.6282, 0.6658,
        0.6275, 0.6232, 0.6373, 0.6448, 0.6463, 0.6274, 0.6689],
       device='cuda:0') torch.Size([16])
percent tensor([0.6989, 0.7476, 0.7629, 0.6848, 0.7659, 0.8115, 0.6774, 0.5549, 0.7447,
        0.7259, 0.7316, 0.7147, 0.6910, 0.6823, 0.6173, 0.6797],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9994, 0.9998, 0.9998, 0.9999, 0.9996, 0.9999, 0.9995, 0.9997,
        0.9999, 0.9999, 0.9996, 0.9997, 0.9995, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 148 | Batch_idx: 0 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (2572/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (3792/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (4992/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (95.00%) (6204/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (7417/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (8627/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (9845/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (11065/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (12276/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (13489/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (14691/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (15890/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (17100/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (18299/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (19511/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (20711/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (21922/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (23139/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (24354/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (25571/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (26774/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (27997/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (29217/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (30429/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (31650/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (32864/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (34079/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (35282/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (36501/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (37723/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (38945/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (40150/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (41377/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (42594/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (43820/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (45038/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (46248/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (47431/50000)
# TEST : Loss: (0.3902) | Acc: (88.00%) (8800/10000)
percent tensor([0.5129, 0.5160, 0.5020, 0.4929, 0.5065, 0.4863, 0.5176, 0.5089, 0.5260,
        0.5189, 0.5224, 0.5145, 0.5203, 0.5228, 0.4992, 0.5085],
       device='cuda:0') torch.Size([16])
percent tensor([0.4912, 0.4896, 0.4673, 0.4660, 0.4697, 0.4842, 0.4863, 0.4770, 0.4859,
        0.4833, 0.4970, 0.4657, 0.4952, 0.4887, 0.4794, 0.4902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.5376, 0.5551, 0.6093, 0.5695, 0.6367, 0.5454, 0.5940, 0.6005,
        0.5423, 0.5617, 0.5144, 0.5552, 0.6545, 0.5404, 0.6120],
       device='cuda:0') torch.Size([16])
percent tensor([0.6827, 0.7269, 0.6154, 0.6168, 0.6180, 0.6297, 0.6989, 0.6429, 0.6876,
        0.7195, 0.7328, 0.6586, 0.7215, 0.7101, 0.6816, 0.6921],
       device='cuda:0') torch.Size([16])
percent tensor([0.5822, 0.5355, 0.7106, 0.7115, 0.7319, 0.7081, 0.6394, 0.6249, 0.6728,
        0.5563, 0.6444, 0.6543, 0.5679, 0.6172, 0.6058, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.6549, 0.6447, 0.6827, 0.6792, 0.7166, 0.7252, 0.6663, 0.6341, 0.6691,
        0.6239, 0.6149, 0.6287, 0.6394, 0.6452, 0.6240, 0.6744],
       device='cuda:0') torch.Size([16])
percent tensor([0.6990, 0.7434, 0.7680, 0.6902, 0.7862, 0.8215, 0.6759, 0.5775, 0.7397,
        0.7181, 0.7243, 0.6995, 0.6675, 0.6788, 0.6058, 0.6908],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9997, 0.9997, 0.9999, 0.9997, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9995, 0.9997, 0.9995, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 149 | Batch_idx: 0 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (3775/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (4987/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (6198/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (7422/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (8650/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (9863/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (11074/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (12301/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (13517/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (14742/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (15960/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (17192/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (18414/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (19625/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (20846/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (22072/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (23275/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (24487/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (25718/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (26926/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (28131/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (29361/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (30585/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (31808/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (33020/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (34260/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (35493/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (36728/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (37962/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (39187/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (40422/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (41650/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (42881/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (44105/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (45334/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (46555/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (47741/50000)
# TEST : Loss: (0.3762) | Acc: (88.00%) (8844/10000)
percent tensor([0.5126, 0.5162, 0.5015, 0.4917, 0.5064, 0.4848, 0.5179, 0.5086, 0.5266,
        0.5191, 0.5227, 0.5146, 0.5205, 0.5229, 0.4986, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.4907, 0.4893, 0.4671, 0.4653, 0.4696, 0.4832, 0.4861, 0.4768, 0.4860,
        0.4832, 0.4968, 0.4656, 0.4952, 0.4885, 0.4788, 0.4896],
       device='cuda:0') torch.Size([16])
percent tensor([0.5914, 0.5367, 0.5446, 0.6001, 0.5585, 0.6307, 0.5407, 0.5825, 0.5970,
        0.5407, 0.5636, 0.5077, 0.5509, 0.6560, 0.5350, 0.6079],
       device='cuda:0') torch.Size([16])
percent tensor([0.6790, 0.7244, 0.6109, 0.6102, 0.6140, 0.6245, 0.6958, 0.6390, 0.6852,
        0.7154, 0.7293, 0.6545, 0.7212, 0.7044, 0.6777, 0.6869],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.5326, 0.7252, 0.7251, 0.7435, 0.7158, 0.6449, 0.6416, 0.6789,
        0.5506, 0.6419, 0.6664, 0.5694, 0.6130, 0.6096, 0.5821],
       device='cuda:0') torch.Size([16])
percent tensor([0.6557, 0.6457, 0.6819, 0.6782, 0.7199, 0.7276, 0.6633, 0.6330, 0.6662,
        0.6226, 0.6096, 0.6194, 0.6369, 0.6422, 0.6206, 0.6783],
       device='cuda:0') torch.Size([16])
percent tensor([0.6961, 0.7436, 0.7638, 0.6841, 0.7834, 0.8157, 0.6715, 0.5703, 0.7344,
        0.7229, 0.7225, 0.6910, 0.6599, 0.6822, 0.5925, 0.6944],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9997, 0.9997, 0.9999, 0.9997, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9995, 0.9997, 0.9995, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 150 | Batch_idx: 0 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (3784/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (6240/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (7463/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (8681/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (9920/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (11143/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (12369/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (13588/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (14804/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (16026/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (17240/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (18476/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (19701/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (20924/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (22152/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (23379/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (24613/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (25839/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (27063/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (28285/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (29505/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (30733/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (31957/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (33179/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (34409/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (35645/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (36882/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (38102/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (39339/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (40567/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (41797/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (43019/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (44244/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (45456/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (46684/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (47875/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_150.pth.tar'
# TEST : Loss: (0.3731) | Acc: (88.00%) (8851/10000)
percent tensor([0.5158, 0.5199, 0.5048, 0.4948, 0.5103, 0.4877, 0.5217, 0.5122, 0.5304,
        0.5227, 0.5264, 0.5182, 0.5240, 0.5264, 0.5020, 0.5109],
       device='cuda:0') torch.Size([16])
percent tensor([0.4893, 0.4880, 0.4670, 0.4647, 0.4693, 0.4821, 0.4852, 0.4760, 0.4850,
        0.4823, 0.4954, 0.4654, 0.4939, 0.4873, 0.4776, 0.4882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5946, 0.5397, 0.5540, 0.6089, 0.5671, 0.6343, 0.5464, 0.5890, 0.6028,
        0.5456, 0.5672, 0.5169, 0.5528, 0.6612, 0.5394, 0.6102],
       device='cuda:0') torch.Size([16])
percent tensor([0.6778, 0.7241, 0.6075, 0.6060, 0.6108, 0.6229, 0.6942, 0.6364, 0.6840,
        0.7137, 0.7277, 0.6517, 0.7220, 0.7024, 0.6763, 0.6854],
       device='cuda:0') torch.Size([16])
percent tensor([0.5755, 0.5248, 0.7218, 0.7209, 0.7389, 0.7082, 0.6371, 0.6381, 0.6768,
        0.5403, 0.6358, 0.6630, 0.5646, 0.6041, 0.6020, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.6567, 0.6496, 0.6818, 0.6783, 0.7223, 0.7324, 0.6644, 0.6321, 0.6655,
        0.6259, 0.6080, 0.6142, 0.6379, 0.6442, 0.6206, 0.6813],
       device='cuda:0') torch.Size([16])
percent tensor([0.7036, 0.7566, 0.7629, 0.6851, 0.7801, 0.8184, 0.6788, 0.5623, 0.7430,
        0.7386, 0.7390, 0.6940, 0.6738, 0.6988, 0.6030, 0.7012],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9997, 0.9997, 0.9999, 0.9997, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9995, 0.9997, 0.9995, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(183.5366, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(825.9638, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.1678, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1517.1880, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(488.4952, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2258.8860, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4262.8960, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1374.2318, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6202.1743, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11701.0068, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3867.6714, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16309.5400, device='cuda:0')
Epoch: 151 | Batch_idx: 0 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (2578/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (96.00%) (3812/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (5029/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (6240/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (7461/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (8694/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (9916/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (11151/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (12387/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (13619/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (14855/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (16097/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (96.00%) (17327/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (96.00%) (18556/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (19778/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (21007/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (22233/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (23465/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (96.00%) (24703/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (96.00%) (25928/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (27149/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (28370/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (29597/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (30825/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (32056/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (33275/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (34502/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (35725/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (36939/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (38178/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (39396/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (40626/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (41852/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (43079/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (44306/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (45537/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (46763/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (47954/50000)
# TEST : Loss: (0.3690) | Acc: (88.00%) (8851/10000)
percent tensor([0.5202, 0.5249, 0.5098, 0.4990, 0.5160, 0.4911, 0.5273, 0.5174, 0.5358,
        0.5280, 0.5314, 0.5239, 0.5287, 0.5311, 0.5065, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.4880, 0.4869, 0.4661, 0.4637, 0.4686, 0.4807, 0.4842, 0.4751, 0.4838,
        0.4811, 0.4939, 0.4645, 0.4924, 0.4864, 0.4764, 0.4868],
       device='cuda:0') torch.Size([16])
percent tensor([0.5862, 0.5306, 0.5489, 0.6042, 0.5624, 0.6275, 0.5388, 0.5831, 0.5954,
        0.5373, 0.5589, 0.5120, 0.5425, 0.6538, 0.5319, 0.6022],
       device='cuda:0') torch.Size([16])
percent tensor([0.6840, 0.7292, 0.6140, 0.6123, 0.6177, 0.6298, 0.7003, 0.6430, 0.6904,
        0.7182, 0.7326, 0.6573, 0.7283, 0.7078, 0.6819, 0.6913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5767, 0.5298, 0.7278, 0.7237, 0.7441, 0.7109, 0.6411, 0.6436, 0.6824,
        0.5464, 0.6422, 0.6708, 0.5714, 0.6054, 0.6054, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.6638, 0.6561, 0.6876, 0.6829, 0.7302, 0.7397, 0.6696, 0.6379, 0.6717,
        0.6319, 0.6127, 0.6170, 0.6445, 0.6505, 0.6254, 0.6881],
       device='cuda:0') torch.Size([16])
percent tensor([0.7012, 0.7573, 0.7612, 0.6812, 0.7782, 0.8145, 0.6756, 0.5539, 0.7441,
        0.7393, 0.7421, 0.6948, 0.6721, 0.6995, 0.6002, 0.6936],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9997, 0.9998, 0.9999, 0.9997, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9997, 0.9995, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 152 | Batch_idx: 0 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (2587/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (96.00%) (3814/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (96.00%) (5048/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (96.00%) (6267/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (7485/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (8706/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (9933/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (11141/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (12370/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (13591/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (14816/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (16034/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (17269/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (18491/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (19708/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (20928/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (22142/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (23363/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (24569/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (25802/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (27031/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (28245/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (29464/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (30687/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (31898/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (33118/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (34351/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (35568/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (36797/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (38010/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (39232/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (40455/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (41674/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (42887/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (44093/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (45301/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (46529/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (47702/50000)
# TEST : Loss: (0.4086) | Acc: (87.00%) (8751/10000)
percent tensor([0.5230, 0.5259, 0.5108, 0.5001, 0.5187, 0.4937, 0.5289, 0.5174, 0.5391,
        0.5292, 0.5339, 0.5254, 0.5314, 0.5319, 0.5076, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.4892, 0.4874, 0.4727, 0.4666, 0.4742, 0.4823, 0.4868, 0.4778, 0.4857,
        0.4829, 0.4941, 0.4698, 0.4934, 0.4858, 0.4772, 0.4880],
       device='cuda:0') torch.Size([16])
percent tensor([0.5842, 0.5321, 0.5495, 0.6090, 0.5655, 0.6314, 0.5422, 0.5847, 0.6032,
        0.5337, 0.5635, 0.5059, 0.5401, 0.6557, 0.5362, 0.6021],
       device='cuda:0') torch.Size([16])
percent tensor([0.6880, 0.7286, 0.6253, 0.6179, 0.6234, 0.6264, 0.6999, 0.6488, 0.6924,
        0.7176, 0.7314, 0.6638, 0.7328, 0.7040, 0.6815, 0.6883],
       device='cuda:0') torch.Size([16])
percent tensor([0.5827, 0.5254, 0.7232, 0.7238, 0.7426, 0.7261, 0.6309, 0.6222, 0.6930,
        0.5665, 0.6658, 0.6666, 0.5661, 0.6346, 0.5954, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.6592, 0.6494, 0.6895, 0.6740, 0.7263, 0.7319, 0.6660, 0.6254, 0.6750,
        0.6262, 0.6130, 0.6153, 0.6563, 0.6579, 0.6019, 0.6909],
       device='cuda:0') torch.Size([16])
percent tensor([0.7000, 0.7461, 0.7540, 0.6844, 0.7614, 0.8132, 0.6769, 0.5319, 0.7662,
        0.7128, 0.7311, 0.6813, 0.7010, 0.7202, 0.5987, 0.7141],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9999, 0.9999, 0.9998, 0.9999, 0.9995, 0.9997,
        0.9998, 0.9999, 0.9996, 0.9998, 0.9994, 0.9996, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 153 | Batch_idx: 0 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (2569/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (3799/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (5015/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (6247/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (7472/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (8700/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (9921/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (11148/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (12366/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (13595/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (14820/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (16049/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (17283/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (18510/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (19745/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (20970/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (22185/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (23416/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (24633/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (25856/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (27074/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (28291/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (29511/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (30732/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (31954/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (33181/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (34418/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (35634/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (36849/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (38083/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (39312/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (40534/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (41768/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (42989/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (44221/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (45448/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (46673/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (47852/50000)
# TEST : Loss: (0.4392) | Acc: (86.00%) (8695/10000)
percent tensor([0.5217, 0.5266, 0.5087, 0.4990, 0.5167, 0.4934, 0.5291, 0.5168, 0.5383,
        0.5287, 0.5335, 0.5242, 0.5303, 0.5345, 0.5075, 0.5162],
       device='cuda:0') torch.Size([16])
percent tensor([0.4882, 0.4892, 0.4673, 0.4655, 0.4685, 0.4807, 0.4860, 0.4758, 0.4841,
        0.4823, 0.4943, 0.4657, 0.4928, 0.4905, 0.4771, 0.4879],
       device='cuda:0') torch.Size([16])
percent tensor([0.5780, 0.5234, 0.5268, 0.6099, 0.5497, 0.6209, 0.5325, 0.5882, 0.5869,
        0.5271, 0.5527, 0.4933, 0.5340, 0.6559, 0.5261, 0.5999],
       device='cuda:0') torch.Size([16])
percent tensor([0.6855, 0.7248, 0.6311, 0.6107, 0.6276, 0.6304, 0.6979, 0.6408, 0.6857,
        0.7129, 0.7254, 0.6647, 0.7226, 0.7042, 0.6774, 0.6882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5900, 0.5338, 0.7254, 0.7398, 0.7441, 0.7206, 0.6387, 0.6411, 0.7052,
        0.5584, 0.6622, 0.6702, 0.5889, 0.6256, 0.6080, 0.5860],
       device='cuda:0') torch.Size([16])
percent tensor([0.6594, 0.6537, 0.6706, 0.6642, 0.7209, 0.7346, 0.6644, 0.6252, 0.6758,
        0.6317, 0.6151, 0.5905, 0.6537, 0.6582, 0.6100, 0.6895],
       device='cuda:0') torch.Size([16])
percent tensor([0.7027, 0.7486, 0.7379, 0.6717, 0.7473, 0.8189, 0.6598, 0.5283, 0.7818,
        0.7489, 0.7437, 0.7003, 0.7070, 0.7042, 0.6036, 0.7024],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9996, 0.9998, 0.9996, 0.9998, 0.9995, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9997, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 154 | Batch_idx: 0 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (2583/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (3800/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (5035/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (96.00%) (6267/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (7486/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (8714/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (9926/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (11143/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (12367/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (13593/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (14817/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (16046/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (17273/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (18498/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (19715/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (20938/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (22172/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (23392/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (24614/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (25832/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (27064/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (28269/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (29489/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (30714/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (31930/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (33157/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (34374/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (35593/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (36813/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (38035/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (39260/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (40466/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (41685/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (42903/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (44115/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (45333/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (46555/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (47739/50000)
# TEST : Loss: (0.4088) | Acc: (87.00%) (8795/10000)
percent tensor([0.5212, 0.5262, 0.5097, 0.5003, 0.5172, 0.4924, 0.5284, 0.5177, 0.5365,
        0.5291, 0.5319, 0.5254, 0.5297, 0.5325, 0.5071, 0.5156],
       device='cuda:0') torch.Size([16])
percent tensor([0.4873, 0.4871, 0.4681, 0.4671, 0.4690, 0.4796, 0.4851, 0.4773, 0.4848,
        0.4819, 0.4932, 0.4653, 0.4915, 0.4892, 0.4756, 0.4876],
       device='cuda:0') torch.Size([16])
percent tensor([0.5859, 0.5276, 0.5476, 0.6218, 0.5646, 0.6314, 0.5398, 0.5867, 0.5948,
        0.5380, 0.5576, 0.5136, 0.5415, 0.6565, 0.5302, 0.6039],
       device='cuda:0') torch.Size([16])
percent tensor([0.6837, 0.7240, 0.6182, 0.6045, 0.6162, 0.6260, 0.6986, 0.6377, 0.6909,
        0.7114, 0.7314, 0.6572, 0.7212, 0.7069, 0.6764, 0.6878],
       device='cuda:0') torch.Size([16])
percent tensor([0.5784, 0.5166, 0.7257, 0.7297, 0.7486, 0.7198, 0.6173, 0.6410, 0.6917,
        0.5504, 0.6528, 0.6719, 0.5680, 0.6199, 0.6026, 0.5737],
       device='cuda:0') torch.Size([16])
percent tensor([0.6637, 0.6653, 0.6819, 0.6712, 0.7267, 0.7299, 0.6720, 0.6249, 0.6713,
        0.6411, 0.6211, 0.6132, 0.6581, 0.6633, 0.6142, 0.6933],
       device='cuda:0') torch.Size([16])
percent tensor([0.7103, 0.7774, 0.7275, 0.6689, 0.7581, 0.8101, 0.6964, 0.4937, 0.7789,
        0.7542, 0.7623, 0.7137, 0.7458, 0.7379, 0.5892, 0.6929],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9997, 0.9999, 0.9997, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9997, 0.9999, 0.9995, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 155 | Batch_idx: 0 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (2568/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (3799/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (5032/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (6263/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (7481/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (8724/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (9942/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (11169/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (12388/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (13611/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (14839/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (16064/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (17281/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (18503/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (19739/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (20966/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (22187/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (23418/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (24642/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (25870/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (27087/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (28311/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (29515/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (30727/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (31947/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (33162/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (34372/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (35600/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (36812/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (38040/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (39249/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (40464/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (41680/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (42899/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (44120/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (45348/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (46572/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (47754/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_155.pth.tar'
# TEST : Loss: (0.4271) | Acc: (87.00%) (8727/10000)
percent tensor([0.5219, 0.5245, 0.5112, 0.5005, 0.5189, 0.4925, 0.5276, 0.5168, 0.5358,
        0.5282, 0.5315, 0.5259, 0.5296, 0.5284, 0.5070, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.4871, 0.4881, 0.4683, 0.4665, 0.4701, 0.4800, 0.4848, 0.4772, 0.4851,
        0.4812, 0.4937, 0.4658, 0.4917, 0.4871, 0.4768, 0.4868],
       device='cuda:0') torch.Size([16])
percent tensor([0.5888, 0.5159, 0.5579, 0.6136, 0.5728, 0.6407, 0.5355, 0.5795, 0.6042,
        0.5337, 0.5578, 0.5139, 0.5412, 0.6478, 0.5292, 0.6011],
       device='cuda:0') torch.Size([16])
percent tensor([0.6866, 0.7278, 0.6172, 0.6142, 0.6187, 0.6205, 0.7019, 0.6513, 0.6929,
        0.7138, 0.7316, 0.6584, 0.7265, 0.7114, 0.6787, 0.6885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5736, 0.5283, 0.7228, 0.7225, 0.7419, 0.7096, 0.6237, 0.6281, 0.6754,
        0.5435, 0.6393, 0.6614, 0.5654, 0.6007, 0.5866, 0.5740],
       device='cuda:0') torch.Size([16])
percent tensor([0.6584, 0.6667, 0.6786, 0.6662, 0.7223, 0.7332, 0.6686, 0.6306, 0.6729,
        0.6263, 0.6171, 0.6054, 0.6662, 0.6656, 0.6089, 0.6914],
       device='cuda:0') torch.Size([16])
percent tensor([0.7016, 0.7700, 0.7310, 0.6474, 0.7569, 0.8240, 0.6714, 0.5276, 0.7685,
        0.7187, 0.7458, 0.6818, 0.7230, 0.7092, 0.5660, 0.6862],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9997, 0.9999, 0.9997, 0.9998, 0.9997, 0.9997,
        0.9998, 0.9999, 0.9997, 0.9998, 0.9994, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 156 | Batch_idx: 0 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (3763/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (4975/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (6191/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (7395/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (8617/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (9827/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (11037/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (12264/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (13467/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (14684/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (15910/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (17127/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (18353/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (19569/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (94.00%) (20789/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (94.00%) (22006/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (94.00%) (23224/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (94.00%) (24439/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (25667/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (26899/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (28121/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (29347/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (30575/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (31794/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (33018/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (34239/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (35459/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (36676/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (37897/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (39116/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (40345/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (41565/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (42785/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (44014/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (45244/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (46458/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (47647/50000)
# TEST : Loss: (0.3963) | Acc: (88.00%) (8810/10000)
percent tensor([0.5143, 0.5164, 0.5030, 0.4932, 0.5099, 0.4865, 0.5189, 0.5083, 0.5272,
        0.5196, 0.5229, 0.5169, 0.5213, 0.5212, 0.4994, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.4869, 0.4859, 0.4699, 0.4690, 0.4719, 0.4820, 0.4841, 0.4776, 0.4844,
        0.4802, 0.4915, 0.4665, 0.4901, 0.4863, 0.4776, 0.4866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5907, 0.5108, 0.5756, 0.6262, 0.5900, 0.6496, 0.5406, 0.5958, 0.6043,
        0.5287, 0.5485, 0.5225, 0.5356, 0.6474, 0.5304, 0.6048],
       device='cuda:0') torch.Size([16])
percent tensor([0.6675, 0.7075, 0.6017, 0.5949, 0.6036, 0.6082, 0.6812, 0.6352, 0.6746,
        0.6929, 0.7106, 0.6384, 0.7060, 0.6862, 0.6619, 0.6688],
       device='cuda:0') torch.Size([16])
percent tensor([0.5639, 0.5206, 0.7107, 0.7122, 0.7316, 0.6942, 0.6057, 0.6008, 0.6733,
        0.5472, 0.6467, 0.6490, 0.5600, 0.6016, 0.5698, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.6457, 0.6572, 0.6648, 0.6459, 0.7101, 0.7249, 0.6603, 0.6118, 0.6556,
        0.6148, 0.6050, 0.5959, 0.6525, 0.6467, 0.5962, 0.6811],
       device='cuda:0') torch.Size([16])
percent tensor([0.7059, 0.7832, 0.6913, 0.5956, 0.7215, 0.8202, 0.6878, 0.5051, 0.7740,
        0.7287, 0.7551, 0.6890, 0.7490, 0.7243, 0.5635, 0.7013],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9997, 0.9996, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9997, 0.9999, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 157 | Batch_idx: 0 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (2582/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (95.00%) (3802/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (5025/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (6242/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (7465/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (8678/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (9912/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (11130/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (12340/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (13570/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (14805/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (16032/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (17264/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (18490/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (19700/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (20935/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (22167/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (23399/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (24642/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (25875/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (27100/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (28324/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (29556/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (30787/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (32018/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (33250/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (34468/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (35683/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (36905/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (38133/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (39355/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (40594/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (41821/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (43053/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (44271/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (45499/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (46729/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (47911/50000)
# TEST : Loss: (0.3871) | Acc: (88.00%) (8823/10000)
percent tensor([0.5147, 0.5175, 0.5030, 0.4935, 0.5099, 0.4877, 0.5196, 0.5085, 0.5274,
        0.5200, 0.5235, 0.5168, 0.5217, 0.5222, 0.5006, 0.5085],
       device='cuda:0') torch.Size([16])
percent tensor([0.4850, 0.4832, 0.4698, 0.4690, 0.4714, 0.4813, 0.4818, 0.4770, 0.4824,
        0.4780, 0.4888, 0.4655, 0.4879, 0.4840, 0.4762, 0.4851],
       device='cuda:0') torch.Size([16])
percent tensor([0.5859, 0.5060, 0.5724, 0.6236, 0.5899, 0.6489, 0.5363, 0.5948, 0.5974,
        0.5226, 0.5397, 0.5167, 0.5298, 0.6410, 0.5268, 0.6015],
       device='cuda:0') torch.Size([16])
percent tensor([0.6786, 0.7185, 0.6103, 0.6018, 0.6133, 0.6189, 0.6921, 0.6444, 0.6850,
        0.7036, 0.7213, 0.6482, 0.7175, 0.6957, 0.6728, 0.6793],
       device='cuda:0') torch.Size([16])
percent tensor([0.5628, 0.5254, 0.7053, 0.7089, 0.7284, 0.6942, 0.6072, 0.5925, 0.6760,
        0.5555, 0.6573, 0.6480, 0.5594, 0.6133, 0.5716, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.6475, 0.6585, 0.6629, 0.6443, 0.7091, 0.7254, 0.6613, 0.6110, 0.6563,
        0.6141, 0.6076, 0.5964, 0.6557, 0.6495, 0.5956, 0.6836],
       device='cuda:0') torch.Size([16])
percent tensor([0.7184, 0.7929, 0.6895, 0.5924, 0.7131, 0.8210, 0.6957, 0.5120, 0.7783,
        0.7405, 0.7659, 0.6975, 0.7627, 0.7350, 0.5758, 0.7117],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9997, 0.9996, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9999, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 158 | Batch_idx: 0 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (95.00%) (3804/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (5022/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (6260/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (7488/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (8703/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (9935/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (11170/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (12399/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (13630/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (14851/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (16073/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (17303/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (18534/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (19759/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (20985/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (22210/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (23450/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (24673/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (25903/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (27120/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (28351/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (29577/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (30800/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (32039/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (33284/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (34525/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (35748/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (36973/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (38207/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (39435/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (40668/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (96.00%) (41908/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (43130/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (44363/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (96.00%) (45592/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (96.00%) (46819/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (95.00%) (47995/50000)
# TEST : Loss: (0.3805) | Acc: (88.00%) (8825/10000)
percent tensor([0.5174, 0.5210, 0.5054, 0.4960, 0.5126, 0.4906, 0.5228, 0.5112, 0.5304,
        0.5230, 0.5267, 0.5194, 0.5245, 0.5256, 0.5038, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.4856, 0.4838, 0.4709, 0.4700, 0.4724, 0.4819, 0.4825, 0.4779, 0.4832,
        0.4787, 0.4893, 0.4666, 0.4884, 0.4848, 0.4770, 0.4857],
       device='cuda:0') torch.Size([16])
percent tensor([0.5883, 0.5116, 0.5731, 0.6232, 0.5923, 0.6522, 0.5406, 0.5964, 0.5974,
        0.5258, 0.5417, 0.5185, 0.5337, 0.6419, 0.5312, 0.6052],
       device='cuda:0') torch.Size([16])
percent tensor([0.6797, 0.7208, 0.6088, 0.5994, 0.6130, 0.6198, 0.6935, 0.6434, 0.6859,
        0.7053, 0.7232, 0.6478, 0.7201, 0.6969, 0.6740, 0.6802],
       device='cuda:0') torch.Size([16])
percent tensor([0.5694, 0.5314, 0.7131, 0.7188, 0.7365, 0.7028, 0.6140, 0.5985, 0.6863,
        0.5625, 0.6682, 0.6569, 0.5640, 0.6245, 0.5803, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.6519, 0.6628, 0.6660, 0.6473, 0.7113, 0.7274, 0.6653, 0.6152, 0.6607,
        0.6192, 0.6135, 0.6011, 0.6598, 0.6546, 0.5992, 0.6874],
       device='cuda:0') torch.Size([16])
percent tensor([0.7162, 0.7880, 0.6830, 0.5858, 0.6984, 0.8154, 0.6906, 0.5036, 0.7761,
        0.7360, 0.7635, 0.6974, 0.7589, 0.7332, 0.5690, 0.7047],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9997, 0.9996, 0.9998, 0.9999, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9999, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 159 | Batch_idx: 0 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (2591/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (3799/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (5030/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (6252/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (7491/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (8724/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (95.00%) (9948/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (11169/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (12406/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (13626/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (14863/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (16085/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (17314/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (18548/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (19785/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1165) |  Loss2: (0.0000) | Acc: (96.00%) (21017/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (22246/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (23487/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (24716/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (25952/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (27184/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (28412/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (29644/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (30870/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (32102/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (33333/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (34570/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (35796/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (37016/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1165) |  Loss2: (0.0000) | Acc: (96.00%) (38251/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (39485/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (96.00%) (40705/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (41936/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (43172/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (44402/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (45636/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (46864/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (48050/50000)
# TEST : Loss: (0.3774) | Acc: (88.00%) (8838/10000)
percent tensor([0.5181, 0.5220, 0.5059, 0.4968, 0.5131, 0.4914, 0.5236, 0.5121, 0.5310,
        0.5237, 0.5274, 0.5200, 0.5252, 0.5266, 0.5048, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.4857, 0.4840, 0.4713, 0.4704, 0.4727, 0.4822, 0.4827, 0.4782, 0.4834,
        0.4789, 0.4894, 0.4672, 0.4886, 0.4848, 0.4772, 0.4858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5918, 0.5170, 0.5768, 0.6249, 0.5969, 0.6561, 0.5457, 0.6001, 0.5995,
        0.5314, 0.5448, 0.5239, 0.5392, 0.6430, 0.5360, 0.6088],
       device='cuda:0') torch.Size([16])
percent tensor([0.6769, 0.7183, 0.6050, 0.5949, 0.6096, 0.6175, 0.6904, 0.6396, 0.6826,
        0.7022, 0.7208, 0.6438, 0.7178, 0.6927, 0.6716, 0.6770],
       device='cuda:0') torch.Size([16])
percent tensor([0.5659, 0.5289, 0.7077, 0.7135, 0.7307, 0.6972, 0.6074, 0.5927, 0.6813,
        0.5593, 0.6639, 0.6527, 0.5601, 0.6212, 0.5781, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.6374, 0.6484, 0.6517, 0.6342, 0.6978, 0.7162, 0.6513, 0.5989, 0.6485,
        0.6051, 0.6012, 0.5893, 0.6452, 0.6438, 0.5833, 0.6716],
       device='cuda:0') torch.Size([16])
percent tensor([0.7241, 0.7948, 0.6924, 0.5999, 0.7076, 0.8196, 0.6988, 0.5079, 0.7898,
        0.7477, 0.7809, 0.7184, 0.7676, 0.7491, 0.5830, 0.7082],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9996, 0.9999, 0.9998, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9997, 0.9999, 0.9996, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 160 | Batch_idx: 0 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (1358/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (2591/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (3831/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (5051/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (6277/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (7504/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (8733/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (9964/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (95.00%) (11181/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (12399/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (13628/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (14858/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (16087/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (17317/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (18546/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (19773/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (20996/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (22215/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (23440/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (24670/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (25892/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (27125/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (28348/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (29580/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (30803/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (32015/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (33226/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (34444/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (35638/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (36869/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (38085/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (39314/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (40542/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (41760/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (42989/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (44215/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (45443/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (46669/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (47861/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_160.pth.tar'
# TEST : Loss: (0.4751) | Acc: (86.00%) (8618/10000)
percent tensor([0.5181, 0.5218, 0.5097, 0.4977, 0.5154, 0.4919, 0.5249, 0.5150, 0.5324,
        0.5247, 0.5278, 0.5230, 0.5256, 0.5275, 0.5049, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.4849, 0.4841, 0.4699, 0.4712, 0.4720, 0.4817, 0.4826, 0.4776, 0.4827,
        0.4785, 0.4886, 0.4671, 0.4882, 0.4876, 0.4768, 0.4854],
       device='cuda:0') torch.Size([16])
percent tensor([0.5872, 0.5158, 0.5677, 0.6208, 0.5856, 0.6453, 0.5363, 0.5937, 0.5909,
        0.5269, 0.5425, 0.5162, 0.5345, 0.6369, 0.5312, 0.6026],
       device='cuda:0') torch.Size([16])
percent tensor([0.6760, 0.7167, 0.5924, 0.5938, 0.6005, 0.6196, 0.6911, 0.6301, 0.6817,
        0.7038, 0.7196, 0.6399, 0.7189, 0.6992, 0.6703, 0.6806],
       device='cuda:0') torch.Size([16])
percent tensor([0.5660, 0.5333, 0.7178, 0.7177, 0.7367, 0.7028, 0.6144, 0.6104, 0.6667,
        0.5606, 0.6505, 0.6700, 0.5469, 0.6217, 0.5823, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.6341, 0.6559, 0.6564, 0.6564, 0.6954, 0.7108, 0.6562, 0.6077, 0.6501,
        0.6259, 0.6019, 0.6137, 0.6438, 0.6638, 0.5885, 0.6734],
       device='cuda:0') torch.Size([16])
percent tensor([0.7169, 0.7817, 0.7151, 0.6572, 0.7346, 0.8101, 0.6908, 0.5286, 0.7862,
        0.7659, 0.7718, 0.7512, 0.7705, 0.7475, 0.5917, 0.7204],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9996, 0.9997, 0.9998, 0.9998, 0.9996, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9998, 0.9994, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.0997, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(827.1617, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.3958, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1516.0532, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(486.9183, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2263.9192, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4260.0659, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1369.3579, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6212.8599, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11668.3369, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3852.6968, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16244.5977, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 161 | Batch_idx: 0 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (2575/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (3805/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (5036/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (95.00%) (6263/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (95.00%) (7494/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (95.00%) (8724/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (9939/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (11152/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (12388/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (13606/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (14830/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (16058/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (17289/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (18513/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (19729/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (20956/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (22178/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (23405/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (24636/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (25861/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (27095/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (28316/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (29548/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (30781/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (32012/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (33240/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (34459/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (35680/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (36899/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (38112/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (39338/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (40558/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (41781/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (42998/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (44231/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (45443/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (46670/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (47845/50000)
# TEST : Loss: (0.4425) | Acc: (87.00%) (8709/10000)
percent tensor([0.5169, 0.5241, 0.5032, 0.4954, 0.5103, 0.4907, 0.5241, 0.5122, 0.5314,
        0.5235, 0.5282, 0.5180, 0.5253, 0.5311, 0.5052, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.4849, 0.4850, 0.4692, 0.4705, 0.4712, 0.4811, 0.4827, 0.4782, 0.4816,
        0.4784, 0.4884, 0.4667, 0.4881, 0.4871, 0.4763, 0.4858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5835, 0.5138, 0.5358, 0.6208, 0.5619, 0.6488, 0.5280, 0.5885, 0.5826,
        0.5181, 0.5401, 0.4850, 0.5273, 0.6443, 0.5334, 0.6081],
       device='cuda:0') torch.Size([16])
percent tensor([0.6787, 0.7117, 0.6259, 0.6001, 0.6235, 0.6220, 0.6923, 0.6350, 0.6817,
        0.7023, 0.7175, 0.6568, 0.7186, 0.6889, 0.6682, 0.6774],
       device='cuda:0') torch.Size([16])
percent tensor([0.5723, 0.5398, 0.6970, 0.7030, 0.7100, 0.7065, 0.6224, 0.6079, 0.6809,
        0.5720, 0.6722, 0.6536, 0.5606, 0.6357, 0.6031, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.6245, 0.6283, 0.6477, 0.6403, 0.6800, 0.7105, 0.6416, 0.5869, 0.6407,
        0.6001, 0.5967, 0.5731, 0.6238, 0.6399, 0.5662, 0.6555],
       device='cuda:0') torch.Size([16])
percent tensor([0.6970, 0.7579, 0.7204, 0.6224, 0.6920, 0.7947, 0.6727, 0.5011, 0.7689,
        0.7280, 0.7582, 0.7074, 0.7302, 0.7276, 0.5524, 0.6830],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9998, 0.9998, 0.9998, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 162 | Batch_idx: 0 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (2589/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (3826/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (5052/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (6274/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (7511/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (8755/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (9975/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (11202/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (12435/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (13672/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (14892/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (16115/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (17345/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (18572/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (19797/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (21037/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (22265/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (23503/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (24743/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (25969/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (27183/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (28409/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (29636/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (30855/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (32080/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (33303/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (34530/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (95.00%) (35752/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (95.00%) (36967/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (38190/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (95.00%) (39406/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (40629/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (41849/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (43077/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (95.00%) (44316/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (45533/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (95.00%) (46757/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (47939/50000)
# TEST : Loss: (0.3954) | Acc: (88.00%) (8842/10000)
percent tensor([0.5172, 0.5233, 0.5056, 0.4963, 0.5117, 0.4912, 0.5244, 0.5131, 0.5325,
        0.5240, 0.5282, 0.5194, 0.5253, 0.5309, 0.5051, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.4849, 0.4850, 0.4684, 0.4696, 0.4709, 0.4815, 0.4825, 0.4781, 0.4820,
        0.4782, 0.4890, 0.4657, 0.4884, 0.4872, 0.4767, 0.4860],
       device='cuda:0') torch.Size([16])
percent tensor([0.5821, 0.5158, 0.5686, 0.6231, 0.5818, 0.6362, 0.5340, 0.6026, 0.5887,
        0.5281, 0.5410, 0.5173, 0.5296, 0.6431, 0.5324, 0.6038],
       device='cuda:0') torch.Size([16])
percent tensor([0.6794, 0.7173, 0.6056, 0.6001, 0.6095, 0.6280, 0.6922, 0.6318, 0.6772,
        0.7046, 0.7184, 0.6420, 0.7189, 0.6944, 0.6699, 0.6804],
       device='cuda:0') torch.Size([16])
percent tensor([0.5638, 0.5309, 0.7165, 0.7134, 0.7349, 0.7086, 0.6290, 0.6185, 0.6762,
        0.5668, 0.6474, 0.6678, 0.5526, 0.6267, 0.5930, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.6224, 0.6359, 0.6547, 0.6438, 0.6978, 0.7087, 0.6457, 0.5953, 0.6460,
        0.6073, 0.5869, 0.5992, 0.6213, 0.6381, 0.5822, 0.6569],
       device='cuda:0') torch.Size([16])
percent tensor([0.7022, 0.7586, 0.7448, 0.6404, 0.7424, 0.7949, 0.6669, 0.5403, 0.7542,
        0.7292, 0.7525, 0.7470, 0.7141, 0.7116, 0.5919, 0.6732],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9997, 0.9998, 0.9996, 0.9997, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9994, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 163 | Batch_idx: 0 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (5040/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (6276/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (7513/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (8751/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (9979/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (11210/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (12437/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (13674/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (14898/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (16127/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (17345/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (18576/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (19808/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (21052/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (22280/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (23514/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (24741/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (25963/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (27196/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (28431/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (29669/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (30895/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (32108/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (33347/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (34569/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (35801/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (37032/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (38264/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (39491/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (40722/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (41943/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (43167/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (44390/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (45620/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (46855/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (48040/50000)
# TEST : Loss: (0.4048) | Acc: (87.00%) (8775/10000)
percent tensor([0.5171, 0.5242, 0.5035, 0.4961, 0.5107, 0.4911, 0.5246, 0.5125, 0.5317,
        0.5238, 0.5278, 0.5186, 0.5252, 0.5314, 0.5055, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.4847, 0.4831, 0.4687, 0.4693, 0.4712, 0.4812, 0.4822, 0.4770, 0.4826,
        0.4779, 0.4885, 0.4661, 0.4882, 0.4847, 0.4756, 0.4849],
       device='cuda:0') torch.Size([16])
percent tensor([0.5833, 0.5176, 0.5567, 0.6191, 0.5726, 0.6447, 0.5358, 0.5954, 0.5954,
        0.5262, 0.5479, 0.5038, 0.5289, 0.6502, 0.5333, 0.6040],
       device='cuda:0') torch.Size([16])
percent tensor([0.6770, 0.7199, 0.6007, 0.5917, 0.6069, 0.6171, 0.6930, 0.6326, 0.6828,
        0.7045, 0.7222, 0.6443, 0.7195, 0.7001, 0.6706, 0.6794],
       device='cuda:0') torch.Size([16])
percent tensor([0.5718, 0.5243, 0.7173, 0.7310, 0.7436, 0.7096, 0.6188, 0.6035, 0.6716,
        0.5656, 0.6587, 0.6723, 0.5570, 0.6403, 0.5984, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.6251, 0.6263, 0.6562, 0.6452, 0.7050, 0.7101, 0.6381, 0.5825, 0.6363,
        0.6031, 0.5888, 0.5896, 0.6228, 0.6292, 0.5748, 0.6640],
       device='cuda:0') torch.Size([16])
percent tensor([0.6817, 0.7520, 0.7011, 0.6313, 0.7207, 0.7983, 0.6619, 0.4860, 0.7408,
        0.7027, 0.7396, 0.7055, 0.7229, 0.7158, 0.5540, 0.6897],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9995, 0.9998, 0.9998, 0.9997, 0.9995, 0.9997,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 164 | Batch_idx: 0 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (2565/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (3780/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (94.00%) (4981/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (94.00%) (6194/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (94.00%) (7396/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (94.00%) (8608/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (9810/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (11027/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (12244/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (13459/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (14674/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (15876/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (17088/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (18303/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (19521/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (20740/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (21959/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (23180/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (24388/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (25607/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (26832/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (28040/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (29256/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (30482/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (94.00%) (31702/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (32907/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (94.00%) (34125/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (94.00%) (35342/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (94.00%) (36567/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (94.00%) (37781/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (94.00%) (39012/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (94.00%) (40240/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (41474/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (42693/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (43931/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (45160/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (46382/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (47556/50000)
# TEST : Loss: (0.4037) | Acc: (87.00%) (8774/10000)
percent tensor([0.5310, 0.5400, 0.5181, 0.5105, 0.5268, 0.5046, 0.5406, 0.5277, 0.5467,
        0.5394, 0.5426, 0.5348, 0.5392, 0.5472, 0.5206, 0.5266],
       device='cuda:0') torch.Size([16])
percent tensor([0.4818, 0.4793, 0.4685, 0.4672, 0.4710, 0.4789, 0.4794, 0.4743, 0.4800,
        0.4748, 0.4836, 0.4650, 0.4844, 0.4808, 0.4720, 0.4815],
       device='cuda:0') torch.Size([16])
percent tensor([0.5868, 0.5135, 0.5671, 0.6263, 0.5910, 0.6523, 0.5389, 0.6075, 0.5962,
        0.5207, 0.5368, 0.4964, 0.5197, 0.6436, 0.5383, 0.6102],
       device='cuda:0') torch.Size([16])
percent tensor([0.6815, 0.7200, 0.6036, 0.5931, 0.6115, 0.6193, 0.6939, 0.6339, 0.6850,
        0.7083, 0.7233, 0.6480, 0.7203, 0.7025, 0.6711, 0.6819],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5351, 0.7056, 0.7162, 0.7313, 0.6919, 0.6375, 0.5982, 0.6683,
        0.5789, 0.6751, 0.6743, 0.5645, 0.6442, 0.5918, 0.5702],
       device='cuda:0') torch.Size([16])
percent tensor([0.6367, 0.6338, 0.6706, 0.6569, 0.7149, 0.7184, 0.6454, 0.5961, 0.6386,
        0.6091, 0.5887, 0.5914, 0.6291, 0.6363, 0.5854, 0.6830],
       device='cuda:0') torch.Size([16])
percent tensor([0.6776, 0.7443, 0.7212, 0.6507, 0.7141, 0.7925, 0.6650, 0.5171, 0.7174,
        0.6981, 0.7120, 0.7022, 0.7076, 0.7177, 0.5663, 0.7083],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9995, 0.9998, 0.9998, 0.9998, 0.9996, 0.9996,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9996, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 165 | Batch_idx: 0 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 165 | Batch_idx: 10 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 165 | Batch_idx: 20 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (2566/2688)
Epoch: 165 | Batch_idx: 30 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (3781/3968)
Epoch: 165 | Batch_idx: 40 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (4996/5248)
Epoch: 165 | Batch_idx: 50 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (6205/6528)
Epoch: 165 | Batch_idx: 60 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (7423/7808)
Epoch: 165 | Batch_idx: 70 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (8651/9088)
Epoch: 165 | Batch_idx: 80 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (9875/10368)
Epoch: 165 | Batch_idx: 90 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (11108/11648)
Epoch: 165 | Batch_idx: 100 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (12346/12928)
Epoch: 165 | Batch_idx: 110 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (13558/14208)
Epoch: 165 | Batch_idx: 120 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (14779/15488)
Epoch: 165 | Batch_idx: 130 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (15999/16768)
Epoch: 165 | Batch_idx: 140 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (17226/18048)
Epoch: 165 | Batch_idx: 150 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (18453/19328)
Epoch: 165 | Batch_idx: 160 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (19679/20608)
Epoch: 165 | Batch_idx: 170 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (20900/21888)
Epoch: 165 | Batch_idx: 180 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (22114/23168)
Epoch: 165 | Batch_idx: 190 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (23348/24448)
Epoch: 165 | Batch_idx: 200 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (24567/25728)
Epoch: 165 | Batch_idx: 210 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (25801/27008)
Epoch: 165 | Batch_idx: 220 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (27025/28288)
Epoch: 165 | Batch_idx: 230 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (28253/29568)
Epoch: 165 | Batch_idx: 240 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (29476/30848)
Epoch: 165 | Batch_idx: 250 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (30708/32128)
Epoch: 165 | Batch_idx: 260 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (31925/33408)
Epoch: 165 | Batch_idx: 270 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (33151/34688)
Epoch: 165 | Batch_idx: 280 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (34382/35968)
Epoch: 165 | Batch_idx: 290 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (35609/37248)
Epoch: 165 | Batch_idx: 300 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (36833/38528)
Epoch: 165 | Batch_idx: 310 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (38068/39808)
Epoch: 165 | Batch_idx: 320 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (39294/41088)
Epoch: 165 | Batch_idx: 330 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (40526/42368)
Epoch: 165 | Batch_idx: 340 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (41754/43648)
Epoch: 165 | Batch_idx: 350 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (42974/44928)
Epoch: 165 | Batch_idx: 360 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (44205/46208)
Epoch: 165 | Batch_idx: 370 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (45437/47488)
Epoch: 165 | Batch_idx: 380 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (46661/48768)
Epoch: 165 | Batch_idx: 390 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (47835/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_165.pth.tar'
# TEST : Loss: (0.3898) | Acc: (88.00%) (8806/10000)
percent tensor([0.5295, 0.5384, 0.5166, 0.5094, 0.5252, 0.5028, 0.5389, 0.5265, 0.5452,
        0.5379, 0.5407, 0.5332, 0.5376, 0.5460, 0.5189, 0.5251],
       device='cuda:0') torch.Size([16])
percent tensor([0.4805, 0.4786, 0.4662, 0.4659, 0.4691, 0.4773, 0.4782, 0.4729, 0.4788,
        0.4736, 0.4826, 0.4635, 0.4832, 0.4808, 0.4709, 0.4803],
       device='cuda:0') torch.Size([16])
percent tensor([0.5904, 0.5092, 0.5731, 0.6321, 0.5991, 0.6573, 0.5395, 0.6155, 0.5970,
        0.5156, 0.5308, 0.4971, 0.5173, 0.6402, 0.5417, 0.6114],
       device='cuda:0') torch.Size([16])
percent tensor([0.6797, 0.7170, 0.6014, 0.5921, 0.6102, 0.6181, 0.6921, 0.6322, 0.6813,
        0.7058, 0.7203, 0.6451, 0.7162, 0.6998, 0.6702, 0.6809],
       device='cuda:0') torch.Size([16])
percent tensor([0.5618, 0.5385, 0.7140, 0.7210, 0.7348, 0.6912, 0.6401, 0.6037, 0.6785,
        0.5896, 0.6855, 0.6846, 0.5692, 0.6532, 0.5916, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.6334, 0.6311, 0.6677, 0.6525, 0.7144, 0.7189, 0.6444, 0.5931, 0.6334,
        0.6041, 0.5837, 0.5874, 0.6250, 0.6308, 0.5820, 0.6810],
       device='cuda:0') torch.Size([16])
percent tensor([0.6839, 0.7495, 0.7311, 0.6586, 0.7274, 0.7991, 0.6767, 0.5281, 0.7220,
        0.7014, 0.7165, 0.7155, 0.7103, 0.7168, 0.5780, 0.7071],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9996, 0.9998, 0.9998, 0.9998, 0.9996, 0.9996,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9996, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 166 | Batch_idx: 0 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 166 | Batch_idx: 10 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 166 | Batch_idx: 20 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 166 | Batch_idx: 30 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (95.00%) (3806/3968)
Epoch: 166 | Batch_idx: 40 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (5050/5248)
Epoch: 166 | Batch_idx: 50 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (6295/6528)
Epoch: 166 | Batch_idx: 60 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (7525/7808)
Epoch: 166 | Batch_idx: 70 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (8768/9088)
Epoch: 166 | Batch_idx: 80 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (96.00%) (9988/10368)
Epoch: 166 | Batch_idx: 90 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (11217/11648)
Epoch: 166 | Batch_idx: 100 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (12436/12928)
Epoch: 166 | Batch_idx: 110 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (96.00%) (13656/14208)
Epoch: 166 | Batch_idx: 120 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (14895/15488)
Epoch: 166 | Batch_idx: 130 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (16113/16768)
Epoch: 166 | Batch_idx: 140 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (17342/18048)
Epoch: 166 | Batch_idx: 150 |  Loss: (0.1165) |  Loss2: (0.0000) | Acc: (96.00%) (18569/19328)
Epoch: 166 | Batch_idx: 160 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (19795/20608)
Epoch: 166 | Batch_idx: 170 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (21032/21888)
Epoch: 166 | Batch_idx: 180 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (22272/23168)
Epoch: 166 | Batch_idx: 190 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (23504/24448)
Epoch: 166 | Batch_idx: 200 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (24746/25728)
Epoch: 166 | Batch_idx: 210 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (25967/27008)
Epoch: 166 | Batch_idx: 220 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (27197/28288)
Epoch: 166 | Batch_idx: 230 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (28431/29568)
Epoch: 166 | Batch_idx: 240 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (29660/30848)
Epoch: 166 | Batch_idx: 250 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (30876/32128)
Epoch: 166 | Batch_idx: 260 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (32108/33408)
Epoch: 166 | Batch_idx: 270 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (33329/34688)
Epoch: 166 | Batch_idx: 280 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (34550/35968)
Epoch: 166 | Batch_idx: 290 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (35780/37248)
Epoch: 166 | Batch_idx: 300 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (37000/38528)
Epoch: 166 | Batch_idx: 310 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (38232/39808)
Epoch: 166 | Batch_idx: 320 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (39455/41088)
Epoch: 166 | Batch_idx: 330 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (40685/42368)
Epoch: 166 | Batch_idx: 340 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (41910/43648)
Epoch: 166 | Batch_idx: 350 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (95.00%) (43130/44928)
Epoch: 166 | Batch_idx: 360 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (44366/46208)
Epoch: 166 | Batch_idx: 370 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (45606/47488)
Epoch: 166 | Batch_idx: 380 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (96.00%) (46836/48768)
Epoch: 166 | Batch_idx: 390 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (48019/50000)
# TEST : Loss: (0.3824) | Acc: (88.00%) (8831/10000)
percent tensor([0.5302, 0.5395, 0.5170, 0.5100, 0.5258, 0.5037, 0.5398, 0.5271, 0.5458,
        0.5386, 0.5416, 0.5337, 0.5384, 0.5469, 0.5199, 0.5259],
       device='cuda:0') torch.Size([16])
percent tensor([0.4813, 0.4798, 0.4668, 0.4671, 0.4698, 0.4779, 0.4792, 0.4739, 0.4798,
        0.4747, 0.4837, 0.4645, 0.4842, 0.4822, 0.4719, 0.4813],
       device='cuda:0') torch.Size([16])
percent tensor([0.5942, 0.5091, 0.5757, 0.6367, 0.6050, 0.6615, 0.5428, 0.6206, 0.6000,
        0.5155, 0.5314, 0.4997, 0.5179, 0.6419, 0.5463, 0.6144],
       device='cuda:0') torch.Size([16])
percent tensor([0.6770, 0.7130, 0.6004, 0.5910, 0.6089, 0.6165, 0.6884, 0.6290, 0.6776,
        0.7028, 0.7162, 0.6421, 0.7121, 0.6958, 0.6672, 0.6786],
       device='cuda:0') torch.Size([16])
percent tensor([0.5641, 0.5453, 0.7184, 0.7208, 0.7372, 0.6926, 0.6414, 0.6073, 0.6818,
        0.5981, 0.6905, 0.6888, 0.5736, 0.6564, 0.5935, 0.5737],
       device='cuda:0') torch.Size([16])
percent tensor([0.6416, 0.6378, 0.6753, 0.6601, 0.7232, 0.7263, 0.6531, 0.6026, 0.6381,
        0.6085, 0.5901, 0.5937, 0.6306, 0.6370, 0.5889, 0.6902],
       device='cuda:0') torch.Size([16])
percent tensor([0.6806, 0.7458, 0.7343, 0.6592, 0.7269, 0.7989, 0.6758, 0.5268, 0.7164,
        0.6914, 0.7148, 0.7182, 0.7040, 0.7131, 0.5764, 0.6997],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9996, 0.9998, 0.9998, 0.9998, 0.9996, 0.9996,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9996, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 167 | Batch_idx: 0 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 167 | Batch_idx: 10 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (1351/1408)
Epoch: 167 | Batch_idx: 20 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (2574/2688)
Epoch: 167 | Batch_idx: 30 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (95.00%) (3809/3968)
Epoch: 167 | Batch_idx: 40 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (5047/5248)
Epoch: 167 | Batch_idx: 50 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (6272/6528)
Epoch: 167 | Batch_idx: 60 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (7503/7808)
Epoch: 167 | Batch_idx: 70 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (8730/9088)
Epoch: 167 | Batch_idx: 80 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (9956/10368)
Epoch: 167 | Batch_idx: 90 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (11189/11648)
Epoch: 167 | Batch_idx: 100 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (96.00%) (12417/12928)
Epoch: 167 | Batch_idx: 110 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (13646/14208)
Epoch: 167 | Batch_idx: 120 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (14874/15488)
Epoch: 167 | Batch_idx: 130 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (16105/16768)
Epoch: 167 | Batch_idx: 140 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (17318/18048)
Epoch: 167 | Batch_idx: 150 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (95.00%) (18551/19328)
Epoch: 167 | Batch_idx: 160 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (95.00%) (19779/20608)
Epoch: 167 | Batch_idx: 170 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (95.00%) (21010/21888)
Epoch: 167 | Batch_idx: 180 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (95.00%) (22237/23168)
Epoch: 167 | Batch_idx: 190 |  Loss: (0.1165) |  Loss2: (0.0000) | Acc: (95.00%) (23465/24448)
Epoch: 167 | Batch_idx: 200 |  Loss: (0.1165) |  Loss2: (0.0000) | Acc: (96.00%) (24701/25728)
Epoch: 167 | Batch_idx: 210 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (25949/27008)
Epoch: 167 | Batch_idx: 220 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (27170/28288)
Epoch: 167 | Batch_idx: 230 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (28405/29568)
Epoch: 167 | Batch_idx: 240 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (29633/30848)
Epoch: 167 | Batch_idx: 250 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (30853/32128)
Epoch: 167 | Batch_idx: 260 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (32093/33408)
Epoch: 167 | Batch_idx: 270 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (33321/34688)
Epoch: 167 | Batch_idx: 280 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (34566/35968)
Epoch: 167 | Batch_idx: 290 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (35809/37248)
Epoch: 167 | Batch_idx: 300 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (37034/38528)
Epoch: 167 | Batch_idx: 310 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (38265/39808)
Epoch: 167 | Batch_idx: 320 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (39487/41088)
Epoch: 167 | Batch_idx: 330 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (40729/42368)
Epoch: 167 | Batch_idx: 340 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (41954/43648)
Epoch: 167 | Batch_idx: 350 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (43180/44928)
Epoch: 167 | Batch_idx: 360 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (44419/46208)
Epoch: 167 | Batch_idx: 370 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (45655/47488)
Epoch: 167 | Batch_idx: 380 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (46889/48768)
Epoch: 167 | Batch_idx: 390 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (48075/50000)
# TEST : Loss: (0.3778) | Acc: (88.00%) (8850/10000)
percent tensor([0.5301, 0.5396, 0.5163, 0.5103, 0.5250, 0.5043, 0.5394, 0.5268, 0.5452,
        0.5382, 0.5414, 0.5327, 0.5381, 0.5471, 0.5203, 0.5261],
       device='cuda:0') torch.Size([16])
percent tensor([0.4816, 0.4805, 0.4671, 0.4677, 0.4701, 0.4784, 0.4797, 0.4744, 0.4803,
        0.4754, 0.4843, 0.4650, 0.4846, 0.4832, 0.4725, 0.4818],
       device='cuda:0') torch.Size([16])
percent tensor([0.5925, 0.5087, 0.5709, 0.6294, 0.5991, 0.6583, 0.5406, 0.6130, 0.5970,
        0.5149, 0.5325, 0.4968, 0.5189, 0.6377, 0.5443, 0.6117],
       device='cuda:0') torch.Size([16])
percent tensor([0.6810, 0.7164, 0.6054, 0.5965, 0.6138, 0.6210, 0.6922, 0.6332, 0.6807,
        0.7070, 0.7189, 0.6464, 0.7143, 0.7004, 0.6718, 0.6832],
       device='cuda:0') torch.Size([16])
percent tensor([0.5677, 0.5425, 0.7247, 0.7258, 0.7421, 0.6955, 0.6398, 0.6142, 0.6817,
        0.5958, 0.6869, 0.6894, 0.5707, 0.6517, 0.5933, 0.5744],
       device='cuda:0') torch.Size([16])
percent tensor([0.6337, 0.6331, 0.6690, 0.6536, 0.7182, 0.7220, 0.6484, 0.5960, 0.6320,
        0.6001, 0.5828, 0.5876, 0.6223, 0.6329, 0.5810, 0.6810],
       device='cuda:0') torch.Size([16])
percent tensor([0.6829, 0.7535, 0.7300, 0.6525, 0.7237, 0.7994, 0.6810, 0.5259, 0.7196,
        0.6936, 0.7191, 0.7202, 0.7088, 0.7141, 0.5781, 0.6918],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9996, 0.9998, 0.9998, 0.9998, 0.9996, 0.9996,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9996, 0.9998],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 168 | Batch_idx: 0 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 168 | Batch_idx: 10 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 168 | Batch_idx: 20 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (2593/2688)
Epoch: 168 | Batch_idx: 30 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (3838/3968)
Epoch: 168 | Batch_idx: 40 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (5060/5248)
Epoch: 168 | Batch_idx: 50 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (6299/6528)
Epoch: 168 | Batch_idx: 60 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (7532/7808)
Epoch: 168 | Batch_idx: 70 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (8766/9088)
Epoch: 168 | Batch_idx: 80 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (9995/10368)
Epoch: 168 | Batch_idx: 90 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (11208/11648)
Epoch: 168 | Batch_idx: 100 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (12435/12928)
Epoch: 168 | Batch_idx: 110 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (13656/14208)
Epoch: 168 | Batch_idx: 120 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (14895/15488)
Epoch: 168 | Batch_idx: 130 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (16127/16768)
Epoch: 168 | Batch_idx: 140 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (17362/18048)
Epoch: 168 | Batch_idx: 150 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (18594/19328)
Epoch: 168 | Batch_idx: 160 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (19820/20608)
Epoch: 168 | Batch_idx: 170 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (21040/21888)
Epoch: 168 | Batch_idx: 180 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (22262/23168)
Epoch: 168 | Batch_idx: 190 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (23498/24448)
Epoch: 168 | Batch_idx: 200 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (24741/25728)
Epoch: 168 | Batch_idx: 210 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (25974/27008)
Epoch: 168 | Batch_idx: 220 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (27202/28288)
Epoch: 168 | Batch_idx: 230 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (28432/29568)
Epoch: 168 | Batch_idx: 240 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (29667/30848)
Epoch: 168 | Batch_idx: 250 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (30909/32128)
Epoch: 168 | Batch_idx: 260 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (32123/33408)
Epoch: 168 | Batch_idx: 270 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (33340/34688)
Epoch: 168 | Batch_idx: 280 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (34572/35968)
Epoch: 168 | Batch_idx: 290 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (35794/37248)
Epoch: 168 | Batch_idx: 300 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (37014/38528)
Epoch: 168 | Batch_idx: 310 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (38242/39808)
Epoch: 168 | Batch_idx: 320 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (39467/41088)
Epoch: 168 | Batch_idx: 330 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (40681/42368)
Epoch: 168 | Batch_idx: 340 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (41927/43648)
Epoch: 168 | Batch_idx: 350 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (43158/44928)
Epoch: 168 | Batch_idx: 360 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (44380/46208)
Epoch: 168 | Batch_idx: 370 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (45609/47488)
Epoch: 168 | Batch_idx: 380 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (46835/48768)
Epoch: 168 | Batch_idx: 390 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (48019/50000)
# TEST : Loss: (0.4265) | Acc: (87.00%) (8761/10000)
percent tensor([0.5293, 0.5391, 0.5149, 0.5095, 0.5234, 0.5028, 0.5383, 0.5264, 0.5450,
        0.5377, 0.5415, 0.5308, 0.5381, 0.5462, 0.5193, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.4804, 0.4804, 0.4649, 0.4655, 0.4676, 0.4781, 0.4781, 0.4733, 0.4780,
        0.4744, 0.4840, 0.4626, 0.4838, 0.4818, 0.4719, 0.4806],
       device='cuda:0') torch.Size([16])
percent tensor([0.5941, 0.5157, 0.5665, 0.6271, 0.5904, 0.6464, 0.5483, 0.6203, 0.5993,
        0.5279, 0.5368, 0.5061, 0.5302, 0.6459, 0.5398, 0.6091],
       device='cuda:0') torch.Size([16])
percent tensor([0.6782, 0.7136, 0.6085, 0.5958, 0.6119, 0.6208, 0.6898, 0.6285, 0.6778,
        0.7040, 0.7213, 0.6424, 0.7127, 0.6882, 0.6690, 0.6789],
       device='cuda:0') torch.Size([16])
percent tensor([0.5793, 0.5539, 0.7219, 0.7183, 0.7361, 0.6954, 0.6475, 0.6244, 0.6893,
        0.6044, 0.6768, 0.6915, 0.5629, 0.6748, 0.6014, 0.5936],
       device='cuda:0') torch.Size([16])
percent tensor([0.6291, 0.6389, 0.6711, 0.6555, 0.7027, 0.7154, 0.6509, 0.5959, 0.6303,
        0.5979, 0.5823, 0.5993, 0.6169, 0.6312, 0.5954, 0.6782],
       device='cuda:0') torch.Size([16])
percent tensor([0.6700, 0.7505, 0.7385, 0.6402, 0.6958, 0.7693, 0.6820, 0.5106, 0.7317,
        0.6974, 0.7414, 0.7424, 0.7065, 0.7315, 0.5953, 0.6681],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9999, 0.9997, 0.9998, 0.9996, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 169 | Batch_idx: 0 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 169 | Batch_idx: 10 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 169 | Batch_idx: 20 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (2589/2688)
Epoch: 169 | Batch_idx: 30 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (3826/3968)
Epoch: 169 | Batch_idx: 40 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (5060/5248)
Epoch: 169 | Batch_idx: 50 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (6293/6528)
Epoch: 169 | Batch_idx: 60 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (7524/7808)
Epoch: 169 | Batch_idx: 70 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (8763/9088)
Epoch: 169 | Batch_idx: 80 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (9990/10368)
Epoch: 169 | Batch_idx: 90 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (11223/11648)
Epoch: 169 | Batch_idx: 100 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (12458/12928)
Epoch: 169 | Batch_idx: 110 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (13691/14208)
Epoch: 169 | Batch_idx: 120 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (14924/15488)
Epoch: 169 | Batch_idx: 130 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (16145/16768)
Epoch: 169 | Batch_idx: 140 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (17376/18048)
Epoch: 169 | Batch_idx: 150 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (18602/19328)
Epoch: 169 | Batch_idx: 160 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (19827/20608)
Epoch: 169 | Batch_idx: 170 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (21061/21888)
Epoch: 169 | Batch_idx: 180 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (22296/23168)
Epoch: 169 | Batch_idx: 190 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (23534/24448)
Epoch: 169 | Batch_idx: 200 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (24770/25728)
Epoch: 169 | Batch_idx: 210 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (26000/27008)
Epoch: 169 | Batch_idx: 220 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (27238/28288)
Epoch: 169 | Batch_idx: 230 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (28466/29568)
Epoch: 169 | Batch_idx: 240 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (29701/30848)
Epoch: 169 | Batch_idx: 250 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (30931/32128)
Epoch: 169 | Batch_idx: 260 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (32159/33408)
Epoch: 169 | Batch_idx: 270 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (33394/34688)
Epoch: 169 | Batch_idx: 280 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (34616/35968)
Epoch: 169 | Batch_idx: 290 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (35836/37248)
Epoch: 169 | Batch_idx: 300 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (37071/38528)
Epoch: 169 | Batch_idx: 310 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (38291/39808)
Epoch: 169 | Batch_idx: 320 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (39522/41088)
Epoch: 169 | Batch_idx: 330 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (40750/42368)
Epoch: 169 | Batch_idx: 340 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (41982/43648)
Epoch: 169 | Batch_idx: 350 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (43222/44928)
Epoch: 169 | Batch_idx: 360 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (44447/46208)
Epoch: 169 | Batch_idx: 370 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (45681/47488)
Epoch: 169 | Batch_idx: 380 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (46910/48768)
Epoch: 169 | Batch_idx: 390 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (48090/50000)
# TEST : Loss: (0.4571) | Acc: (86.00%) (8683/10000)
percent tensor([0.5304, 0.5389, 0.5171, 0.5108, 0.5258, 0.5031, 0.5393, 0.5268, 0.5456,
        0.5384, 0.5415, 0.5331, 0.5386, 0.5450, 0.5197, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.4816, 0.4803, 0.4669, 0.4682, 0.4692, 0.4781, 0.4790, 0.4742, 0.4782,
        0.4761, 0.4845, 0.4652, 0.4849, 0.4830, 0.4723, 0.4815],
       device='cuda:0') torch.Size([16])
percent tensor([0.5946, 0.5026, 0.5712, 0.6270, 0.5955, 0.6478, 0.5402, 0.6091, 0.5958,
        0.5192, 0.5341, 0.5120, 0.5300, 0.6336, 0.5314, 0.6020],
       device='cuda:0') torch.Size([16])
percent tensor([0.6816, 0.7175, 0.6074, 0.6021, 0.6108, 0.6253, 0.6956, 0.6343, 0.6853,
        0.7093, 0.7267, 0.6429, 0.7129, 0.7057, 0.6730, 0.6861],
       device='cuda:0') torch.Size([16])
percent tensor([0.5737, 0.5486, 0.7201, 0.7084, 0.7410, 0.7001, 0.6248, 0.6155, 0.6869,
        0.5853, 0.6714, 0.6775, 0.5796, 0.6404, 0.5886, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.6314, 0.6292, 0.6678, 0.6433, 0.7075, 0.7134, 0.6490, 0.6007, 0.6378,
        0.5906, 0.5839, 0.5914, 0.6267, 0.6186, 0.5775, 0.6656],
       device='cuda:0') torch.Size([16])
percent tensor([0.6810, 0.7462, 0.7137, 0.6377, 0.7162, 0.7917, 0.6682, 0.5076, 0.7357,
        0.6792, 0.7213, 0.7042, 0.7076, 0.6981, 0.5815, 0.6743],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9993, 0.9997,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9996, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 170 | Batch_idx: 0 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 170 | Batch_idx: 10 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 170 | Batch_idx: 20 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (2588/2688)
Epoch: 170 | Batch_idx: 30 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (3818/3968)
Epoch: 170 | Batch_idx: 40 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (5061/5248)
Epoch: 170 | Batch_idx: 50 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (6294/6528)
Epoch: 170 | Batch_idx: 60 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (7538/7808)
Epoch: 170 | Batch_idx: 70 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (8765/9088)
Epoch: 170 | Batch_idx: 80 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (9998/10368)
Epoch: 170 | Batch_idx: 90 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (11233/11648)
Epoch: 170 | Batch_idx: 100 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (12473/12928)
Epoch: 170 | Batch_idx: 110 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (13705/14208)
Epoch: 170 | Batch_idx: 120 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (14931/15488)
Epoch: 170 | Batch_idx: 130 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (16163/16768)
Epoch: 170 | Batch_idx: 140 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (17403/18048)
Epoch: 170 | Batch_idx: 150 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (18624/19328)
Epoch: 170 | Batch_idx: 160 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (19866/20608)
Epoch: 170 | Batch_idx: 170 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (21092/21888)
Epoch: 170 | Batch_idx: 180 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (22334/23168)
Epoch: 170 | Batch_idx: 190 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (23557/24448)
Epoch: 170 | Batch_idx: 200 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (24782/25728)
Epoch: 170 | Batch_idx: 210 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (26021/27008)
Epoch: 170 | Batch_idx: 220 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (27250/28288)
Epoch: 170 | Batch_idx: 230 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (28480/29568)
Epoch: 170 | Batch_idx: 240 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (29713/30848)
Epoch: 170 | Batch_idx: 250 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (30944/32128)
Epoch: 170 | Batch_idx: 260 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (32185/33408)
Epoch: 170 | Batch_idx: 270 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (33418/34688)
Epoch: 170 | Batch_idx: 280 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (34657/35968)
Epoch: 170 | Batch_idx: 290 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (35892/37248)
Epoch: 170 | Batch_idx: 300 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (37128/38528)
Epoch: 170 | Batch_idx: 310 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (38352/39808)
Epoch: 170 | Batch_idx: 320 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (39579/41088)
Epoch: 170 | Batch_idx: 330 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (40807/42368)
Epoch: 170 | Batch_idx: 340 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (42042/43648)
Epoch: 170 | Batch_idx: 350 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (43265/44928)
Epoch: 170 | Batch_idx: 360 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (44506/46208)
Epoch: 170 | Batch_idx: 370 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (45747/47488)
Epoch: 170 | Batch_idx: 380 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (46970/48768)
Epoch: 170 | Batch_idx: 390 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (48152/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_170.pth.tar'
# TEST : Loss: (0.4009) | Acc: (88.00%) (8848/10000)
percent tensor([0.5300, 0.5397, 0.5165, 0.5093, 0.5243, 0.5031, 0.5396, 0.5271, 0.5458,
        0.5386, 0.5423, 0.5320, 0.5389, 0.5465, 0.5199, 0.5256],
       device='cuda:0') torch.Size([16])
percent tensor([0.4805, 0.4805, 0.4680, 0.4677, 0.4694, 0.4758, 0.4791, 0.4756, 0.4787,
        0.4761, 0.4840, 0.4651, 0.4843, 0.4827, 0.4711, 0.4809],
       device='cuda:0') torch.Size([16])
percent tensor([0.5915, 0.5110, 0.5675, 0.6298, 0.5949, 0.6406, 0.5446, 0.6109, 0.5941,
        0.5225, 0.5385, 0.5098, 0.5268, 0.6409, 0.5329, 0.6010],
       device='cuda:0') torch.Size([16])
percent tensor([0.6809, 0.7178, 0.6164, 0.6010, 0.6168, 0.6230, 0.6956, 0.6379, 0.6855,
        0.7118, 0.7213, 0.6505, 0.7179, 0.6993, 0.6738, 0.6839],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5352, 0.7281, 0.7265, 0.7402, 0.7002, 0.6292, 0.6096, 0.6740,
        0.5813, 0.6739, 0.6786, 0.5526, 0.6357, 0.5918, 0.5756],
       device='cuda:0') torch.Size([16])
percent tensor([0.6253, 0.6224, 0.6608, 0.6547, 0.7054, 0.7095, 0.6447, 0.5878, 0.6274,
        0.5942, 0.5823, 0.6019, 0.6205, 0.6186, 0.5879, 0.6602],
       device='cuda:0') torch.Size([16])
percent tensor([0.6764, 0.7380, 0.7033, 0.6341, 0.6941, 0.7949, 0.6567, 0.4815, 0.7272,
        0.7032, 0.7360, 0.7182, 0.7137, 0.7053, 0.5732, 0.6533],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9999, 0.9997, 0.9999, 0.9996, 0.9998, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9997, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.8747, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(829.3023, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(833.1635, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1515.6976, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(485.2559, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2270.6121, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4259.7222, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1364.4598, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6230.7949, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11637.8389, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3837.9082, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16179.5928, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 171 | Batch_idx: 0 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 171 | Batch_idx: 10 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 171 | Batch_idx: 20 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (2601/2688)
Epoch: 171 | Batch_idx: 30 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (3835/3968)
Epoch: 171 | Batch_idx: 40 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (5068/5248)
Epoch: 171 | Batch_idx: 50 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (6311/6528)
Epoch: 171 | Batch_idx: 60 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (7560/7808)
Epoch: 171 | Batch_idx: 70 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (8785/9088)
Epoch: 171 | Batch_idx: 80 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (10020/10368)
Epoch: 171 | Batch_idx: 90 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (11258/11648)
Epoch: 171 | Batch_idx: 100 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (12482/12928)
Epoch: 171 | Batch_idx: 110 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (13704/14208)
Epoch: 171 | Batch_idx: 120 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (14940/15488)
Epoch: 171 | Batch_idx: 130 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (16173/16768)
Epoch: 171 | Batch_idx: 140 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (17404/18048)
Epoch: 171 | Batch_idx: 150 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (18637/19328)
Epoch: 171 | Batch_idx: 160 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (19868/20608)
Epoch: 171 | Batch_idx: 170 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (21104/21888)
Epoch: 171 | Batch_idx: 180 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (22332/23168)
Epoch: 171 | Batch_idx: 190 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (23562/24448)
Epoch: 171 | Batch_idx: 200 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (24796/25728)
Epoch: 171 | Batch_idx: 210 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (26031/27008)
Epoch: 171 | Batch_idx: 220 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (27261/28288)
Epoch: 171 | Batch_idx: 230 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (28502/29568)
Epoch: 171 | Batch_idx: 240 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (29725/30848)
Epoch: 171 | Batch_idx: 250 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (30960/32128)
Epoch: 171 | Batch_idx: 260 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (32187/33408)
Epoch: 171 | Batch_idx: 270 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (33415/34688)
Epoch: 171 | Batch_idx: 280 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (34638/35968)
Epoch: 171 | Batch_idx: 290 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (35868/37248)
Epoch: 171 | Batch_idx: 300 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (37109/38528)
Epoch: 171 | Batch_idx: 310 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (38348/39808)
Epoch: 171 | Batch_idx: 320 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (39581/41088)
Epoch: 171 | Batch_idx: 330 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (40810/42368)
Epoch: 171 | Batch_idx: 340 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (42038/43648)
Epoch: 171 | Batch_idx: 350 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (43268/44928)
Epoch: 171 | Batch_idx: 360 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (44505/46208)
Epoch: 171 | Batch_idx: 370 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (45732/47488)
Epoch: 171 | Batch_idx: 380 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (46965/48768)
Epoch: 171 | Batch_idx: 390 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (48151/50000)
# TEST : Loss: (0.4217) | Acc: (87.00%) (8757/10000)
percent tensor([0.5299, 0.5361, 0.5201, 0.5095, 0.5273, 0.5023, 0.5377, 0.5273, 0.5450,
        0.5379, 0.5401, 0.5347, 0.5380, 0.5403, 0.5181, 0.5243],
       device='cuda:0') torch.Size([16])
percent tensor([0.4819, 0.4786, 0.4686, 0.4684, 0.4697, 0.4777, 0.4784, 0.4760, 0.4797,
        0.4759, 0.4844, 0.4658, 0.4849, 0.4816, 0.4714, 0.4823],
       device='cuda:0') torch.Size([16])
percent tensor([0.5919, 0.5107, 0.5759, 0.6282, 0.5937, 0.6430, 0.5428, 0.6122, 0.6023,
        0.5275, 0.5443, 0.5209, 0.5263, 0.6400, 0.5316, 0.6048],
       device='cuda:0') torch.Size([16])
percent tensor([0.6785, 0.7157, 0.6091, 0.5985, 0.6148, 0.6231, 0.6934, 0.6331, 0.6802,
        0.7091, 0.7217, 0.6461, 0.7159, 0.6991, 0.6731, 0.6826],
       device='cuda:0') torch.Size([16])
percent tensor([0.5815, 0.5421, 0.7280, 0.7311, 0.7432, 0.7163, 0.6235, 0.6278, 0.6853,
        0.5817, 0.6660, 0.6709, 0.5587, 0.6420, 0.5963, 0.5795],
       device='cuda:0') torch.Size([16])
percent tensor([0.6238, 0.6244, 0.6604, 0.6548, 0.7051, 0.7178, 0.6451, 0.5813, 0.6337,
        0.5999, 0.5784, 0.5993, 0.6215, 0.6208, 0.5781, 0.6719],
       device='cuda:0') torch.Size([16])
percent tensor([0.6657, 0.7417, 0.6998, 0.6485, 0.7173, 0.8051, 0.6494, 0.4827, 0.7057,
        0.6989, 0.7267, 0.7010, 0.6812, 0.6915, 0.5591, 0.6713],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9998, 0.9999, 0.9998, 0.9998, 0.9995, 0.9996,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9996, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 172 | Batch_idx: 0 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 172 | Batch_idx: 10 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 172 | Batch_idx: 20 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (95.00%) (2575/2688)
Epoch: 172 | Batch_idx: 30 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (3780/3968)
Epoch: 172 | Batch_idx: 40 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (4997/5248)
Epoch: 172 | Batch_idx: 50 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (6224/6528)
Epoch: 172 | Batch_idx: 60 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (7440/7808)
Epoch: 172 | Batch_idx: 70 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (8645/9088)
Epoch: 172 | Batch_idx: 80 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (9862/10368)
Epoch: 172 | Batch_idx: 90 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (11084/11648)
Epoch: 172 | Batch_idx: 100 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (12298/12928)
Epoch: 172 | Batch_idx: 110 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (13521/14208)
Epoch: 172 | Batch_idx: 120 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (14744/15488)
Epoch: 172 | Batch_idx: 130 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (15967/16768)
Epoch: 172 | Batch_idx: 140 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (17189/18048)
Epoch: 172 | Batch_idx: 150 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (18411/19328)
Epoch: 172 | Batch_idx: 160 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (19627/20608)
Epoch: 172 | Batch_idx: 170 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (20844/21888)
Epoch: 172 | Batch_idx: 180 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (22063/23168)
Epoch: 172 | Batch_idx: 190 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (23288/24448)
Epoch: 172 | Batch_idx: 200 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (24506/25728)
Epoch: 172 | Batch_idx: 210 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (25727/27008)
Epoch: 172 | Batch_idx: 220 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (26944/28288)
Epoch: 172 | Batch_idx: 230 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (28168/29568)
Epoch: 172 | Batch_idx: 240 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (29389/30848)
Epoch: 172 | Batch_idx: 250 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (30612/32128)
Epoch: 172 | Batch_idx: 260 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (31827/33408)
Epoch: 172 | Batch_idx: 270 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (33047/34688)
Epoch: 172 | Batch_idx: 280 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (34273/35968)
Epoch: 172 | Batch_idx: 290 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (35494/37248)
Epoch: 172 | Batch_idx: 300 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (36715/38528)
Epoch: 172 | Batch_idx: 310 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (37935/39808)
Epoch: 172 | Batch_idx: 320 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (39158/41088)
Epoch: 172 | Batch_idx: 330 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (40404/42368)
Epoch: 172 | Batch_idx: 340 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (41631/43648)
Epoch: 172 | Batch_idx: 350 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (42853/44928)
Epoch: 172 | Batch_idx: 360 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (44074/46208)
Epoch: 172 | Batch_idx: 370 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (45304/47488)
Epoch: 172 | Batch_idx: 380 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (46529/48768)
Epoch: 172 | Batch_idx: 390 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (47702/50000)
# TEST : Loss: (0.4217) | Acc: (87.00%) (8777/10000)
percent tensor([0.5471, 0.5528, 0.5407, 0.5272, 0.5486, 0.5203, 0.5566, 0.5455, 0.5625,
        0.5551, 0.5576, 0.5540, 0.5541, 0.5550, 0.5358, 0.5415],
       device='cuda:0') torch.Size([16])
percent tensor([0.4867, 0.4837, 0.4764, 0.4745, 0.4772, 0.4838, 0.4840, 0.4825, 0.4848,
        0.4811, 0.4884, 0.4730, 0.4888, 0.4852, 0.4775, 0.4872],
       device='cuda:0') torch.Size([16])
percent tensor([0.5785, 0.5082, 0.5547, 0.6158, 0.5702, 0.6351, 0.5299, 0.6035, 0.5920,
        0.5213, 0.5385, 0.5004, 0.5162, 0.6357, 0.5237, 0.5994],
       device='cuda:0') torch.Size([16])
percent tensor([0.6608, 0.7003, 0.6050, 0.5829, 0.6051, 0.6076, 0.6757, 0.6132, 0.6655,
        0.6957, 0.7048, 0.6411, 0.7002, 0.6816, 0.6531, 0.6638],
       device='cuda:0') torch.Size([16])
percent tensor([0.6029, 0.5483, 0.7486, 0.7560, 0.7736, 0.7455, 0.6385, 0.6562, 0.7019,
        0.5866, 0.6760, 0.6693, 0.5675, 0.6480, 0.6158, 0.6144],
       device='cuda:0') torch.Size([16])
percent tensor([0.6578, 0.6669, 0.6861, 0.6724, 0.7285, 0.7304, 0.6810, 0.6178, 0.6748,
        0.6458, 0.6282, 0.6307, 0.6672, 0.6710, 0.6188, 0.7053],
       device='cuda:0') torch.Size([16])
percent tensor([0.6542, 0.7526, 0.6876, 0.5972, 0.6922, 0.7869, 0.6314, 0.4651, 0.7233,
        0.7052, 0.7368, 0.6776, 0.7061, 0.7027, 0.5720, 0.6490],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9999, 0.9998, 0.9997, 0.9996, 0.9995,
        0.9999, 0.9999, 0.9997, 0.9997, 0.9994, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 173 | Batch_idx: 0 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 173 | Batch_idx: 10 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 173 | Batch_idx: 20 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (2593/2688)
Epoch: 173 | Batch_idx: 30 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (3816/3968)
Epoch: 173 | Batch_idx: 40 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (95.00%) (5037/5248)
Epoch: 173 | Batch_idx: 50 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (95.00%) (6263/6528)
Epoch: 173 | Batch_idx: 60 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (95.00%) (7489/7808)
Epoch: 173 | Batch_idx: 70 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (8726/9088)
Epoch: 173 | Batch_idx: 80 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (9958/10368)
Epoch: 173 | Batch_idx: 90 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (11187/11648)
Epoch: 173 | Batch_idx: 100 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (12414/12928)
Epoch: 173 | Batch_idx: 110 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (13649/14208)
Epoch: 173 | Batch_idx: 120 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (14880/15488)
Epoch: 173 | Batch_idx: 130 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (16106/16768)
Epoch: 173 | Batch_idx: 140 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (17330/18048)
Epoch: 173 | Batch_idx: 150 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (18568/19328)
Epoch: 173 | Batch_idx: 160 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (19791/20608)
Epoch: 173 | Batch_idx: 170 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (21027/21888)
Epoch: 173 | Batch_idx: 180 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (22258/23168)
Epoch: 173 | Batch_idx: 190 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (23492/24448)
Epoch: 173 | Batch_idx: 200 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (24721/25728)
Epoch: 173 | Batch_idx: 210 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (25932/27008)
Epoch: 173 | Batch_idx: 220 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (27175/28288)
Epoch: 173 | Batch_idx: 230 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (28401/29568)
Epoch: 173 | Batch_idx: 240 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (29630/30848)
Epoch: 173 | Batch_idx: 250 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (30858/32128)
Epoch: 173 | Batch_idx: 260 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (95.00%) (32069/33408)
Epoch: 173 | Batch_idx: 270 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (33302/34688)
Epoch: 173 | Batch_idx: 280 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (34537/35968)
Epoch: 173 | Batch_idx: 290 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (35767/37248)
Epoch: 173 | Batch_idx: 300 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (37004/38528)
Epoch: 173 | Batch_idx: 310 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (38228/39808)
Epoch: 173 | Batch_idx: 320 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (39462/41088)
Epoch: 173 | Batch_idx: 330 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (40690/42368)
Epoch: 173 | Batch_idx: 340 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (41926/43648)
Epoch: 173 | Batch_idx: 350 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (43166/44928)
Epoch: 173 | Batch_idx: 360 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (44409/46208)
Epoch: 173 | Batch_idx: 370 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (45643/47488)
Epoch: 173 | Batch_idx: 380 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (46873/48768)
Epoch: 173 | Batch_idx: 390 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (48049/50000)
# TEST : Loss: (0.4101) | Acc: (88.00%) (8806/10000)
percent tensor([0.5428, 0.5480, 0.5361, 0.5231, 0.5435, 0.5174, 0.5515, 0.5403, 0.5567,
        0.5497, 0.5522, 0.5486, 0.5488, 0.5504, 0.5317, 0.5375],
       device='cuda:0') torch.Size([16])
percent tensor([0.4873, 0.4842, 0.4776, 0.4756, 0.4787, 0.4853, 0.4846, 0.4835, 0.4853,
        0.4815, 0.4886, 0.4736, 0.4892, 0.4855, 0.4787, 0.4882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5718, 0.5017, 0.5497, 0.6107, 0.5622, 0.6326, 0.5221, 0.5962, 0.5856,
        0.5152, 0.5318, 0.4920, 0.5074, 0.6330, 0.5173, 0.5949],
       device='cuda:0') torch.Size([16])
percent tensor([0.6606, 0.7024, 0.6054, 0.5836, 0.6054, 0.6053, 0.6768, 0.6148, 0.6675,
        0.6987, 0.7077, 0.6429, 0.7022, 0.6853, 0.6522, 0.6643],
       device='cuda:0') torch.Size([16])
percent tensor([0.5950, 0.5372, 0.7459, 0.7531, 0.7703, 0.7463, 0.6266, 0.6467, 0.6921,
        0.5717, 0.6590, 0.6617, 0.5622, 0.6286, 0.6081, 0.6079],
       device='cuda:0') torch.Size([16])
percent tensor([0.6527, 0.6637, 0.6784, 0.6621, 0.7189, 0.7217, 0.6756, 0.6086, 0.6698,
        0.6446, 0.6243, 0.6278, 0.6652, 0.6656, 0.6133, 0.6989],
       device='cuda:0') torch.Size([16])
percent tensor([0.6672, 0.7690, 0.6959, 0.5997, 0.7008, 0.7912, 0.6453, 0.4698, 0.7354,
        0.7259, 0.7500, 0.6898, 0.7234, 0.7106, 0.5870, 0.6568],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9996, 0.9996,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9995, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 174 | Batch_idx: 0 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 174 | Batch_idx: 10 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 174 | Batch_idx: 20 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (2594/2688)
Epoch: 174 | Batch_idx: 30 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (3834/3968)
Epoch: 174 | Batch_idx: 40 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (5062/5248)
Epoch: 174 | Batch_idx: 50 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (6292/6528)
Epoch: 174 | Batch_idx: 60 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (7524/7808)
Epoch: 174 | Batch_idx: 70 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (8752/9088)
Epoch: 174 | Batch_idx: 80 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (9983/10368)
Epoch: 174 | Batch_idx: 90 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (11224/11648)
Epoch: 174 | Batch_idx: 100 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (12471/12928)
Epoch: 174 | Batch_idx: 110 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (13713/14208)
Epoch: 174 | Batch_idx: 120 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (14931/15488)
Epoch: 174 | Batch_idx: 130 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (16155/16768)
Epoch: 174 | Batch_idx: 140 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (17376/18048)
Epoch: 174 | Batch_idx: 150 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (18606/19328)
Epoch: 174 | Batch_idx: 160 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (19839/20608)
Epoch: 174 | Batch_idx: 170 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (21074/21888)
Epoch: 174 | Batch_idx: 180 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (22306/23168)
Epoch: 174 | Batch_idx: 190 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (23544/24448)
Epoch: 174 | Batch_idx: 200 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (24791/25728)
Epoch: 174 | Batch_idx: 210 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (26018/27008)
Epoch: 174 | Batch_idx: 220 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (27244/28288)
Epoch: 174 | Batch_idx: 230 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (28476/29568)
Epoch: 174 | Batch_idx: 240 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (29709/30848)
Epoch: 174 | Batch_idx: 250 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (30945/32128)
Epoch: 174 | Batch_idx: 260 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (32184/33408)
Epoch: 174 | Batch_idx: 270 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (33416/34688)
Epoch: 174 | Batch_idx: 280 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (34649/35968)
Epoch: 174 | Batch_idx: 290 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (35888/37248)
Epoch: 174 | Batch_idx: 300 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (37109/38528)
Epoch: 174 | Batch_idx: 310 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (38343/39808)
Epoch: 174 | Batch_idx: 320 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (39562/41088)
Epoch: 174 | Batch_idx: 330 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (40789/42368)
Epoch: 174 | Batch_idx: 340 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (42030/43648)
Epoch: 174 | Batch_idx: 350 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (43266/44928)
Epoch: 174 | Batch_idx: 360 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (44506/46208)
Epoch: 174 | Batch_idx: 370 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (45746/47488)
Epoch: 174 | Batch_idx: 380 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (46977/48768)
Epoch: 174 | Batch_idx: 390 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (48158/50000)
# TEST : Loss: (0.3984) | Acc: (88.00%) (8844/10000)
percent tensor([0.5383, 0.5429, 0.5321, 0.5192, 0.5388, 0.5134, 0.5464, 0.5361, 0.5516,
        0.5451, 0.5473, 0.5441, 0.5441, 0.5455, 0.5272, 0.5332],
       device='cuda:0') torch.Size([16])
percent tensor([0.4872, 0.4840, 0.4778, 0.4757, 0.4791, 0.4855, 0.4845, 0.4838, 0.4854,
        0.4814, 0.4883, 0.4737, 0.4890, 0.4855, 0.4787, 0.4882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5718, 0.5022, 0.5516, 0.6123, 0.5632, 0.6350, 0.5225, 0.5978, 0.5849,
        0.5148, 0.5302, 0.4923, 0.5063, 0.6331, 0.5201, 0.5958],
       device='cuda:0') torch.Size([16])
percent tensor([0.6687, 0.7114, 0.6142, 0.5931, 0.6138, 0.6111, 0.6857, 0.6247, 0.6780,
        0.7095, 0.7186, 0.6531, 0.7120, 0.6959, 0.6595, 0.6729],
       device='cuda:0') torch.Size([16])
percent tensor([0.5952, 0.5462, 0.7425, 0.7490, 0.7674, 0.7477, 0.6283, 0.6414, 0.6939,
        0.5758, 0.6635, 0.6634, 0.5736, 0.6303, 0.6115, 0.6098],
       device='cuda:0') torch.Size([16])
percent tensor([0.6493, 0.6584, 0.6719, 0.6565, 0.7121, 0.7167, 0.6708, 0.6020, 0.6648,
        0.6403, 0.6208, 0.6215, 0.6596, 0.6609, 0.6088, 0.6949],
       device='cuda:0') torch.Size([16])
percent tensor([0.6735, 0.7761, 0.7080, 0.6103, 0.7134, 0.7990, 0.6523, 0.4739, 0.7469,
        0.7353, 0.7612, 0.7000, 0.7269, 0.7170, 0.5948, 0.6543],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9999, 0.9998, 0.9998, 0.9996, 0.9996,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9995, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 175 | Batch_idx: 0 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 175 | Batch_idx: 10 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 175 | Batch_idx: 20 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (95.00%) (2580/2688)
Epoch: 175 | Batch_idx: 30 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (3812/3968)
Epoch: 175 | Batch_idx: 40 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (5051/5248)
Epoch: 175 | Batch_idx: 50 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (6286/6528)
Epoch: 175 | Batch_idx: 60 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (7508/7808)
Epoch: 175 | Batch_idx: 70 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (8755/9088)
Epoch: 175 | Batch_idx: 80 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (9993/10368)
Epoch: 175 | Batch_idx: 90 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (11223/11648)
Epoch: 175 | Batch_idx: 100 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (12461/12928)
Epoch: 175 | Batch_idx: 110 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (13700/14208)
Epoch: 175 | Batch_idx: 120 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (14928/15488)
Epoch: 175 | Batch_idx: 130 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (16163/16768)
Epoch: 175 | Batch_idx: 140 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (17403/18048)
Epoch: 175 | Batch_idx: 150 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (18637/19328)
Epoch: 175 | Batch_idx: 160 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (19875/20608)
Epoch: 175 | Batch_idx: 170 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (21097/21888)
Epoch: 175 | Batch_idx: 180 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (22335/23168)
Epoch: 175 | Batch_idx: 190 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (23576/24448)
Epoch: 175 | Batch_idx: 200 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (24796/25728)
Epoch: 175 | Batch_idx: 210 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (26024/27008)
Epoch: 175 | Batch_idx: 220 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (27263/28288)
Epoch: 175 | Batch_idx: 230 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (28488/29568)
Epoch: 175 | Batch_idx: 240 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (29725/30848)
Epoch: 175 | Batch_idx: 250 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (30968/32128)
Epoch: 175 | Batch_idx: 260 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (32200/33408)
Epoch: 175 | Batch_idx: 270 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (33430/34688)
Epoch: 175 | Batch_idx: 280 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (34668/35968)
Epoch: 175 | Batch_idx: 290 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (35911/37248)
Epoch: 175 | Batch_idx: 300 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (37147/38528)
Epoch: 175 | Batch_idx: 310 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (38384/39808)
Epoch: 175 | Batch_idx: 320 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (39621/41088)
Epoch: 175 | Batch_idx: 330 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (40853/42368)
Epoch: 175 | Batch_idx: 340 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (42095/43648)
Epoch: 175 | Batch_idx: 350 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (43326/44928)
Epoch: 175 | Batch_idx: 360 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (44558/46208)
Epoch: 175 | Batch_idx: 370 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (45799/47488)
Epoch: 175 | Batch_idx: 380 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (47046/48768)
Epoch: 175 | Batch_idx: 390 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (48244/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_175.pth.tar'
# TEST : Loss: (0.3944) | Acc: (88.00%) (8848/10000)
percent tensor([0.5395, 0.5434, 0.5330, 0.5207, 0.5396, 0.5155, 0.5473, 0.5364, 0.5516,
        0.5454, 0.5475, 0.5443, 0.5443, 0.5462, 0.5286, 0.5347],
       device='cuda:0') torch.Size([16])
percent tensor([0.4867, 0.4837, 0.4776, 0.4754, 0.4790, 0.4856, 0.4840, 0.4834, 0.4847,
        0.4809, 0.4875, 0.4733, 0.4884, 0.4847, 0.4785, 0.4880],
       device='cuda:0') torch.Size([16])
percent tensor([0.5694, 0.5008, 0.5525, 0.6101, 0.5652, 0.6315, 0.5224, 0.5981, 0.5826,
        0.5142, 0.5262, 0.4941, 0.5055, 0.6287, 0.5193, 0.5929],
       device='cuda:0') torch.Size([16])
percent tensor([0.6649, 0.7101, 0.6095, 0.5884, 0.6098, 0.6062, 0.6830, 0.6214, 0.6752,
        0.7079, 0.7172, 0.6500, 0.7103, 0.6934, 0.6556, 0.6698],
       device='cuda:0') torch.Size([16])
percent tensor([0.5962, 0.5462, 0.7474, 0.7518, 0.7696, 0.7480, 0.6294, 0.6414, 0.6995,
        0.5759, 0.6666, 0.6702, 0.5786, 0.6315, 0.6121, 0.6084],
       device='cuda:0') torch.Size([16])
percent tensor([0.6565, 0.6640, 0.6757, 0.6609, 0.7146, 0.7185, 0.6770, 0.6083, 0.6702,
        0.6497, 0.6278, 0.6281, 0.6659, 0.6654, 0.6157, 0.6999],
       device='cuda:0') torch.Size([16])
percent tensor([0.6705, 0.7712, 0.7094, 0.6187, 0.7154, 0.7978, 0.6471, 0.4742, 0.7426,
        0.7331, 0.7517, 0.6969, 0.7161, 0.7101, 0.5919, 0.6506],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9999, 0.9998, 0.9998, 0.9996, 0.9996,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9995, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 176 | Batch_idx: 0 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 176 | Batch_idx: 10 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 176 | Batch_idx: 20 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 176 | Batch_idx: 30 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (97.00%) (3853/3968)
Epoch: 176 | Batch_idx: 40 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (5087/5248)
Epoch: 176 | Batch_idx: 50 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (6309/6528)
Epoch: 176 | Batch_idx: 60 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (7550/7808)
Epoch: 176 | Batch_idx: 70 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (8783/9088)
Epoch: 176 | Batch_idx: 80 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (10023/10368)
Epoch: 176 | Batch_idx: 90 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (11257/11648)
Epoch: 176 | Batch_idx: 100 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (12491/12928)
Epoch: 176 | Batch_idx: 110 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (13711/14208)
Epoch: 176 | Batch_idx: 120 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (14947/15488)
Epoch: 176 | Batch_idx: 130 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (16184/16768)
Epoch: 176 | Batch_idx: 140 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (17419/18048)
Epoch: 176 | Batch_idx: 150 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (18650/19328)
Epoch: 176 | Batch_idx: 160 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (19876/20608)
Epoch: 176 | Batch_idx: 170 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (21100/21888)
Epoch: 176 | Batch_idx: 180 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (22331/23168)
Epoch: 176 | Batch_idx: 190 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (23563/24448)
Epoch: 176 | Batch_idx: 200 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (24790/25728)
Epoch: 176 | Batch_idx: 210 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (26021/27008)
Epoch: 176 | Batch_idx: 220 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (27254/28288)
Epoch: 176 | Batch_idx: 230 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (28487/29568)
Epoch: 176 | Batch_idx: 240 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (29715/30848)
Epoch: 176 | Batch_idx: 250 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (30947/32128)
Epoch: 176 | Batch_idx: 260 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (32180/33408)
Epoch: 176 | Batch_idx: 270 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (33411/34688)
Epoch: 176 | Batch_idx: 280 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (34640/35968)
Epoch: 176 | Batch_idx: 290 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (35871/37248)
Epoch: 176 | Batch_idx: 300 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (37101/38528)
Epoch: 176 | Batch_idx: 310 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (38328/39808)
Epoch: 176 | Batch_idx: 320 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (39567/41088)
Epoch: 176 | Batch_idx: 330 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (40801/42368)
Epoch: 176 | Batch_idx: 340 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (42027/43648)
Epoch: 176 | Batch_idx: 350 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (43251/44928)
Epoch: 176 | Batch_idx: 360 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (44467/46208)
Epoch: 176 | Batch_idx: 370 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (45703/47488)
Epoch: 176 | Batch_idx: 380 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (46925/48768)
Epoch: 176 | Batch_idx: 390 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (48118/50000)
# TEST : Loss: (0.4417) | Acc: (87.00%) (8735/10000)
percent tensor([0.5380, 0.5462, 0.5237, 0.5197, 0.5321, 0.5154, 0.5463, 0.5340, 0.5497,
        0.5441, 0.5477, 0.5383, 0.5435, 0.5513, 0.5298, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.4857, 0.4857, 0.4733, 0.4750, 0.4758, 0.4850, 0.4838, 0.4822, 0.4839,
        0.4802, 0.4872, 0.4696, 0.4879, 0.4890, 0.4783, 0.4873],
       device='cuda:0') torch.Size([16])
percent tensor([0.5782, 0.5044, 0.5527, 0.6199, 0.5733, 0.6399, 0.5288, 0.5920, 0.5809,
        0.5204, 0.5343, 0.5008, 0.5164, 0.6403, 0.5256, 0.5968],
       device='cuda:0') torch.Size([16])
percent tensor([0.6689, 0.7063, 0.6089, 0.5905, 0.6093, 0.6126, 0.6794, 0.6241, 0.6752,
        0.7028, 0.7147, 0.6429, 0.7086, 0.6839, 0.6575, 0.6698],
       device='cuda:0') torch.Size([16])
percent tensor([0.6039, 0.5645, 0.7461, 0.7448, 0.7662, 0.7404, 0.6466, 0.6390, 0.7014,
        0.5923, 0.6781, 0.6926, 0.5866, 0.6390, 0.6228, 0.6018],
       device='cuda:0') torch.Size([16])
percent tensor([0.6608, 0.6620, 0.6707, 0.6703, 0.7175, 0.7231, 0.6861, 0.6324, 0.6610,
        0.6421, 0.6258, 0.6138, 0.6525, 0.6727, 0.6153, 0.6917],
       device='cuda:0') torch.Size([16])
percent tensor([0.6764, 0.7710, 0.7299, 0.6362, 0.7331, 0.7814, 0.6920, 0.5374, 0.7467,
        0.7308, 0.7705, 0.7136, 0.7020, 0.7255, 0.5873, 0.6421],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9996, 0.9999, 0.9997, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 177 | Batch_idx: 0 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 177 | Batch_idx: 10 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 177 | Batch_idx: 20 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (2587/2688)
Epoch: 177 | Batch_idx: 30 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (3820/3968)
Epoch: 177 | Batch_idx: 40 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (5069/5248)
Epoch: 177 | Batch_idx: 50 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (6318/6528)
Epoch: 177 | Batch_idx: 60 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (7564/7808)
Epoch: 177 | Batch_idx: 70 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (8808/9088)
Epoch: 177 | Batch_idx: 80 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (10055/10368)
Epoch: 177 | Batch_idx: 90 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (11291/11648)
Epoch: 177 | Batch_idx: 100 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (97.00%) (12542/12928)
Epoch: 177 | Batch_idx: 110 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (97.00%) (13783/14208)
Epoch: 177 | Batch_idx: 120 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (15015/15488)
Epoch: 177 | Batch_idx: 130 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (16239/16768)
Epoch: 177 | Batch_idx: 140 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (17464/18048)
Epoch: 177 | Batch_idx: 150 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (18703/19328)
Epoch: 177 | Batch_idx: 160 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (19932/20608)
Epoch: 177 | Batch_idx: 170 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (21166/21888)
Epoch: 177 | Batch_idx: 180 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (22392/23168)
Epoch: 177 | Batch_idx: 190 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (23624/24448)
Epoch: 177 | Batch_idx: 200 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (24860/25728)
Epoch: 177 | Batch_idx: 210 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (26098/27008)
Epoch: 177 | Batch_idx: 220 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (27336/28288)
Epoch: 177 | Batch_idx: 230 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (28560/29568)
Epoch: 177 | Batch_idx: 240 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (29796/30848)
Epoch: 177 | Batch_idx: 250 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (31034/32128)
Epoch: 177 | Batch_idx: 260 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (32274/33408)
Epoch: 177 | Batch_idx: 270 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (33494/34688)
Epoch: 177 | Batch_idx: 280 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (34728/35968)
Epoch: 177 | Batch_idx: 290 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (35964/37248)
Epoch: 177 | Batch_idx: 300 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (37191/38528)
Epoch: 177 | Batch_idx: 310 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (38420/39808)
Epoch: 177 | Batch_idx: 320 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (39645/41088)
Epoch: 177 | Batch_idx: 330 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (40877/42368)
Epoch: 177 | Batch_idx: 340 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (42105/43648)
Epoch: 177 | Batch_idx: 350 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (43332/44928)
Epoch: 177 | Batch_idx: 360 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (44569/46208)
Epoch: 177 | Batch_idx: 370 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (45798/47488)
Epoch: 177 | Batch_idx: 380 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (47024/48768)
Epoch: 177 | Batch_idx: 390 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (48199/50000)
# TEST : Loss: (0.4134) | Acc: (88.00%) (8824/10000)
percent tensor([0.5385, 0.5446, 0.5261, 0.5195, 0.5334, 0.5155, 0.5462, 0.5342, 0.5501,
        0.5440, 0.5477, 0.5401, 0.5434, 0.5494, 0.5292, 0.5347],
       device='cuda:0') torch.Size([16])
percent tensor([0.4858, 0.4849, 0.4744, 0.4753, 0.4772, 0.4847, 0.4836, 0.4833, 0.4831,
        0.4799, 0.4872, 0.4701, 0.4886, 0.4857, 0.4786, 0.4870],
       device='cuda:0') torch.Size([16])
percent tensor([0.5809, 0.5043, 0.5666, 0.6245, 0.5811, 0.6395, 0.5297, 0.6034, 0.5782,
        0.5186, 0.5298, 0.5046, 0.5225, 0.6314, 0.5274, 0.5962],
       device='cuda:0') torch.Size([16])
percent tensor([0.6659, 0.7104, 0.5987, 0.5891, 0.6041, 0.6076, 0.6828, 0.6245, 0.6775,
        0.7076, 0.7194, 0.6407, 0.7100, 0.6988, 0.6580, 0.6717],
       device='cuda:0') torch.Size([16])
percent tensor([0.5923, 0.5605, 0.7486, 0.7343, 0.7665, 0.7357, 0.6346, 0.6328, 0.6932,
        0.5824, 0.6657, 0.6864, 0.5744, 0.6360, 0.6100, 0.6054],
       device='cuda:0') torch.Size([16])
percent tensor([0.6565, 0.6690, 0.6709, 0.6629, 0.7129, 0.7184, 0.6736, 0.6243, 0.6655,
        0.6346, 0.6237, 0.6176, 0.6652, 0.6544, 0.6049, 0.6967],
       device='cuda:0') torch.Size([16])
percent tensor([0.6427, 0.7609, 0.7117, 0.6248, 0.7238, 0.7769, 0.6451, 0.5026, 0.7651,
        0.6809, 0.7293, 0.7100, 0.7075, 0.6866, 0.5456, 0.6190],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9998, 0.9999, 0.9997, 0.9998, 0.9996, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9998, 0.9996, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 178 | Batch_idx: 0 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 178 | Batch_idx: 10 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 178 | Batch_idx: 20 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (2598/2688)
Epoch: 178 | Batch_idx: 30 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (3838/3968)
Epoch: 178 | Batch_idx: 40 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (5082/5248)
Epoch: 178 | Batch_idx: 50 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (6323/6528)
Epoch: 178 | Batch_idx: 60 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (7557/7808)
Epoch: 178 | Batch_idx: 70 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (8792/9088)
Epoch: 178 | Batch_idx: 80 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (10025/10368)
Epoch: 178 | Batch_idx: 90 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (11260/11648)
Epoch: 178 | Batch_idx: 100 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (12500/12928)
Epoch: 178 | Batch_idx: 110 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (13747/14208)
Epoch: 178 | Batch_idx: 120 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (14987/15488)
Epoch: 178 | Batch_idx: 130 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (16220/16768)
Epoch: 178 | Batch_idx: 140 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (17466/18048)
Epoch: 178 | Batch_idx: 150 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (18704/19328)
Epoch: 178 | Batch_idx: 160 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (19940/20608)
Epoch: 178 | Batch_idx: 170 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (21182/21888)
Epoch: 178 | Batch_idx: 180 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (22402/23168)
Epoch: 178 | Batch_idx: 190 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (23644/24448)
Epoch: 178 | Batch_idx: 200 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (24872/25728)
Epoch: 178 | Batch_idx: 210 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (26123/27008)
Epoch: 178 | Batch_idx: 220 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (27366/28288)
Epoch: 178 | Batch_idx: 230 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (28614/29568)
Epoch: 178 | Batch_idx: 240 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (29845/30848)
Epoch: 178 | Batch_idx: 250 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (31074/32128)
Epoch: 178 | Batch_idx: 260 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (32297/33408)
Epoch: 178 | Batch_idx: 270 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (33535/34688)
Epoch: 178 | Batch_idx: 280 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (34772/35968)
Epoch: 178 | Batch_idx: 290 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (35991/37248)
Epoch: 178 | Batch_idx: 300 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (37209/38528)
Epoch: 178 | Batch_idx: 310 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (38444/39808)
Epoch: 178 | Batch_idx: 320 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (39677/41088)
Epoch: 178 | Batch_idx: 330 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (40913/42368)
Epoch: 178 | Batch_idx: 340 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (42134/43648)
Epoch: 178 | Batch_idx: 350 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (43381/44928)
Epoch: 178 | Batch_idx: 360 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (44620/46208)
Epoch: 178 | Batch_idx: 370 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (45851/47488)
Epoch: 178 | Batch_idx: 380 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (47079/48768)
Epoch: 178 | Batch_idx: 390 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (48274/50000)
# TEST : Loss: (0.4026) | Acc: (88.00%) (8841/10000)
percent tensor([0.5370, 0.5450, 0.5279, 0.5198, 0.5345, 0.5135, 0.5464, 0.5351, 0.5500,
        0.5446, 0.5467, 0.5412, 0.5427, 0.5503, 0.5284, 0.5340],
       device='cuda:0') torch.Size([16])
percent tensor([0.4859, 0.4856, 0.4733, 0.4756, 0.4763, 0.4846, 0.4835, 0.4820, 0.4833,
        0.4805, 0.4878, 0.4694, 0.4891, 0.4867, 0.4792, 0.4876],
       device='cuda:0') torch.Size([16])
percent tensor([0.5768, 0.5078, 0.5540, 0.6190, 0.5730, 0.6320, 0.5294, 0.5969, 0.5842,
        0.5214, 0.5344, 0.4990, 0.5206, 0.6461, 0.5263, 0.5955],
       device='cuda:0') torch.Size([16])
percent tensor([0.6697, 0.7106, 0.6071, 0.5917, 0.6096, 0.6091, 0.6829, 0.6240, 0.6783,
        0.7066, 0.7215, 0.6440, 0.7108, 0.6886, 0.6574, 0.6716],
       device='cuda:0') torch.Size([16])
percent tensor([0.5907, 0.5434, 0.7442, 0.7323, 0.7710, 0.7312, 0.6258, 0.6442, 0.6959,
        0.5709, 0.6411, 0.6751, 0.5672, 0.6118, 0.6146, 0.5950],
       device='cuda:0') torch.Size([16])
percent tensor([0.6613, 0.6732, 0.6659, 0.6609, 0.7234, 0.7200, 0.6733, 0.6211, 0.6657,
        0.6353, 0.6228, 0.6057, 0.6668, 0.6721, 0.6145, 0.7024],
       device='cuda:0') torch.Size([16])
percent tensor([0.6655, 0.7645, 0.6910, 0.6438, 0.7365, 0.7882, 0.6578, 0.5031, 0.7534,
        0.6996, 0.7331, 0.6933, 0.7233, 0.7230, 0.5735, 0.6323],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9999, 0.9998, 0.9999, 0.9998, 0.9998, 0.9997, 0.9997,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9993, 0.9997, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 179 | Batch_idx: 0 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 179 | Batch_idx: 10 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 179 | Batch_idx: 20 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 179 | Batch_idx: 30 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (3862/3968)
Epoch: 179 | Batch_idx: 40 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (5103/5248)
Epoch: 179 | Batch_idx: 50 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (6349/6528)
Epoch: 179 | Batch_idx: 60 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (7584/7808)
Epoch: 179 | Batch_idx: 70 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (97.00%) (8818/9088)
Epoch: 179 | Batch_idx: 80 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (10054/10368)
Epoch: 179 | Batch_idx: 90 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (11292/11648)
Epoch: 179 | Batch_idx: 100 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (12540/12928)
Epoch: 179 | Batch_idx: 110 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (97.00%) (13786/14208)
Epoch: 179 | Batch_idx: 120 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (15023/15488)
Epoch: 179 | Batch_idx: 130 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (97.00%) (16266/16768)
Epoch: 179 | Batch_idx: 140 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (17494/18048)
Epoch: 179 | Batch_idx: 150 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (18728/19328)
Epoch: 179 | Batch_idx: 160 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (19948/20608)
Epoch: 179 | Batch_idx: 170 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (21184/21888)
Epoch: 179 | Batch_idx: 180 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (22412/23168)
Epoch: 179 | Batch_idx: 190 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (23642/24448)
Epoch: 179 | Batch_idx: 200 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (24880/25728)
Epoch: 179 | Batch_idx: 210 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (26117/27008)
Epoch: 179 | Batch_idx: 220 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (27360/28288)
Epoch: 179 | Batch_idx: 230 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (28598/29568)
Epoch: 179 | Batch_idx: 240 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (29835/30848)
Epoch: 179 | Batch_idx: 250 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (31075/32128)
Epoch: 179 | Batch_idx: 260 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (32316/33408)
Epoch: 179 | Batch_idx: 270 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (33547/34688)
Epoch: 179 | Batch_idx: 280 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (34771/35968)
Epoch: 179 | Batch_idx: 290 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (36012/37248)
Epoch: 179 | Batch_idx: 300 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (37250/38528)
Epoch: 179 | Batch_idx: 310 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (38490/39808)
Epoch: 179 | Batch_idx: 320 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (39719/41088)
Epoch: 179 | Batch_idx: 330 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (40949/42368)
Epoch: 179 | Batch_idx: 340 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (42179/43648)
Epoch: 179 | Batch_idx: 350 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (43408/44928)
Epoch: 179 | Batch_idx: 360 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (44646/46208)
Epoch: 179 | Batch_idx: 370 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (45886/47488)
Epoch: 179 | Batch_idx: 380 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (47130/48768)
Epoch: 179 | Batch_idx: 390 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (48316/50000)
# TEST : Loss: (0.4231) | Acc: (87.00%) (8786/10000)
percent tensor([0.5379, 0.5443, 0.5290, 0.5203, 0.5357, 0.5141, 0.5465, 0.5353, 0.5497,
        0.5444, 0.5467, 0.5414, 0.5431, 0.5488, 0.5284, 0.5341],
       device='cuda:0') torch.Size([16])
percent tensor([0.4869, 0.4852, 0.4756, 0.4761, 0.4794, 0.4866, 0.4847, 0.4830, 0.4844,
        0.4809, 0.4880, 0.4727, 0.4890, 0.4864, 0.4792, 0.4876],
       device='cuda:0') torch.Size([16])
percent tensor([0.5801, 0.5041, 0.5441, 0.6184, 0.5659, 0.6462, 0.5237, 0.5948, 0.5822,
        0.5149, 0.5351, 0.4848, 0.5194, 0.6360, 0.5291, 0.5971],
       device='cuda:0') torch.Size([16])
percent tensor([0.6679, 0.7103, 0.6067, 0.5905, 0.6102, 0.6056, 0.6865, 0.6242, 0.6758,
        0.7033, 0.7165, 0.6450, 0.7103, 0.6956, 0.6561, 0.6722],
       device='cuda:0') torch.Size([16])
percent tensor([0.5871, 0.5592, 0.7550, 0.7438, 0.7714, 0.7299, 0.6423, 0.6396, 0.7100,
        0.5899, 0.6658, 0.6963, 0.5806, 0.6483, 0.6208, 0.6062],
       device='cuda:0') torch.Size([16])
percent tensor([0.6588, 0.6711, 0.6721, 0.6683, 0.7171, 0.7175, 0.6813, 0.6161, 0.6617,
        0.6382, 0.6259, 0.6300, 0.6624, 0.6700, 0.6162, 0.6990],
       device='cuda:0') torch.Size([16])
percent tensor([0.6579, 0.7666, 0.7028, 0.6366, 0.7124, 0.7699, 0.6727, 0.4910, 0.7462,
        0.6850, 0.7336, 0.7095, 0.7101, 0.7276, 0.5591, 0.6414],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9998, 0.9994, 0.9998, 0.9997, 0.9998, 0.9996, 0.9996,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9996, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 180 | Batch_idx: 0 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 180 | Batch_idx: 10 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 180 | Batch_idx: 20 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (2604/2688)
Epoch: 180 | Batch_idx: 30 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (3841/3968)
Epoch: 180 | Batch_idx: 40 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (5064/5248)
Epoch: 180 | Batch_idx: 50 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (6285/6528)
Epoch: 180 | Batch_idx: 60 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (7500/7808)
Epoch: 180 | Batch_idx: 70 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (95.00%) (8722/9088)
Epoch: 180 | Batch_idx: 80 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (9954/10368)
Epoch: 180 | Batch_idx: 90 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (95.00%) (11182/11648)
Epoch: 180 | Batch_idx: 100 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (12413/12928)
Epoch: 180 | Batch_idx: 110 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (95.00%) (13637/14208)
Epoch: 180 | Batch_idx: 120 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (14870/15488)
Epoch: 180 | Batch_idx: 130 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (95.00%) (16095/16768)
Epoch: 180 | Batch_idx: 140 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (95.00%) (17324/18048)
Epoch: 180 | Batch_idx: 150 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (18563/19328)
Epoch: 180 | Batch_idx: 160 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (19796/20608)
Epoch: 180 | Batch_idx: 170 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (21026/21888)
Epoch: 180 | Batch_idx: 180 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (22264/23168)
Epoch: 180 | Batch_idx: 190 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (23493/24448)
Epoch: 180 | Batch_idx: 200 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (24728/25728)
Epoch: 180 | Batch_idx: 210 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (25969/27008)
Epoch: 180 | Batch_idx: 220 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (27211/28288)
Epoch: 180 | Batch_idx: 230 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (28444/29568)
Epoch: 180 | Batch_idx: 240 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (29684/30848)
Epoch: 180 | Batch_idx: 250 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (30925/32128)
Epoch: 180 | Batch_idx: 260 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (32158/33408)
Epoch: 180 | Batch_idx: 270 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (33380/34688)
Epoch: 180 | Batch_idx: 280 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (34621/35968)
Epoch: 180 | Batch_idx: 290 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (35845/37248)
Epoch: 180 | Batch_idx: 300 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (37075/38528)
Epoch: 180 | Batch_idx: 310 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (38307/39808)
Epoch: 180 | Batch_idx: 320 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (39543/41088)
Epoch: 180 | Batch_idx: 330 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (40782/42368)
Epoch: 180 | Batch_idx: 340 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (42013/43648)
Epoch: 180 | Batch_idx: 350 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (43261/44928)
Epoch: 180 | Batch_idx: 360 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (44503/46208)
Epoch: 180 | Batch_idx: 370 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (45744/47488)
Epoch: 180 | Batch_idx: 380 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (46973/48768)
Epoch: 180 | Batch_idx: 390 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (48159/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_180.pth.tar'
# TEST : Loss: (0.4115) | Acc: (88.00%) (8833/10000)
percent tensor([0.5366, 0.5445, 0.5265, 0.5184, 0.5332, 0.5129, 0.5452, 0.5335, 0.5488,
        0.5438, 0.5463, 0.5400, 0.5429, 0.5488, 0.5276, 0.5329],
       device='cuda:0') torch.Size([16])
percent tensor([0.4806, 0.4809, 0.4684, 0.4699, 0.4724, 0.4809, 0.4790, 0.4766, 0.4779,
        0.4759, 0.4826, 0.4660, 0.4839, 0.4808, 0.4738, 0.4823],
       device='cuda:0') torch.Size([16])
percent tensor([0.5862, 0.5140, 0.5365, 0.6136, 0.5571, 0.6505, 0.5273, 0.5855, 0.5841,
        0.5241, 0.5501, 0.4816, 0.5310, 0.6465, 0.5322, 0.6058],
       device='cuda:0') torch.Size([16])
percent tensor([0.6742, 0.7163, 0.6105, 0.5928, 0.6138, 0.6166, 0.6911, 0.6285, 0.6766,
        0.7089, 0.7187, 0.6485, 0.7151, 0.6995, 0.6628, 0.6802],
       device='cuda:0') torch.Size([16])
percent tensor([0.5881, 0.5439, 0.7586, 0.7521, 0.7786, 0.7536, 0.6278, 0.6389, 0.7120,
        0.5742, 0.6492, 0.6851, 0.5680, 0.6294, 0.6184, 0.6036],
       device='cuda:0') torch.Size([16])
percent tensor([0.6896, 0.6924, 0.6963, 0.6922, 0.7423, 0.7407, 0.7084, 0.6467, 0.6915,
        0.6624, 0.6514, 0.6522, 0.6909, 0.6928, 0.6407, 0.7203],
       device='cuda:0') torch.Size([16])
percent tensor([0.6845, 0.7815, 0.7078, 0.6407, 0.7265, 0.7928, 0.6870, 0.4986, 0.7685,
        0.6912, 0.7537, 0.7081, 0.7361, 0.7461, 0.5626, 0.6493],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9998, 0.9996, 0.9998, 0.9998, 0.9998, 0.9997, 0.9995,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9996, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(185.3943, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.2273, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(834.9939, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1514.2303, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(483.6860, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2274.4675, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4256.2881, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1359.5066, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6241.2632, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11604.6436, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3823.0242, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16115.0254, device='cuda:0')
Epoch: 181 | Batch_idx: 0 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 181 | Batch_idx: 10 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 181 | Batch_idx: 20 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (2593/2688)
Epoch: 181 | Batch_idx: 30 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (3830/3968)
Epoch: 181 | Batch_idx: 40 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (5068/5248)
Epoch: 181 | Batch_idx: 50 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (6312/6528)
Epoch: 181 | Batch_idx: 60 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (7561/7808)
Epoch: 181 | Batch_idx: 70 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (8790/9088)
Epoch: 181 | Batch_idx: 80 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (10021/10368)
Epoch: 181 | Batch_idx: 90 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (11263/11648)
Epoch: 181 | Batch_idx: 100 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (12501/12928)
Epoch: 181 | Batch_idx: 110 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (13739/14208)
Epoch: 181 | Batch_idx: 120 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (14984/15488)
Epoch: 181 | Batch_idx: 130 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (16227/16768)
Epoch: 181 | Batch_idx: 140 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (17458/18048)
Epoch: 181 | Batch_idx: 150 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (18698/19328)
Epoch: 181 | Batch_idx: 160 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (19942/20608)
Epoch: 181 | Batch_idx: 170 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (21177/21888)
Epoch: 181 | Batch_idx: 180 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (22426/23168)
Epoch: 181 | Batch_idx: 190 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (23665/24448)
Epoch: 181 | Batch_idx: 200 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (24897/25728)
Epoch: 181 | Batch_idx: 210 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (26137/27008)
Epoch: 181 | Batch_idx: 220 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (27377/28288)
Epoch: 181 | Batch_idx: 230 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (28629/29568)
Epoch: 181 | Batch_idx: 240 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (29862/30848)
Epoch: 181 | Batch_idx: 250 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (31110/32128)
Epoch: 181 | Batch_idx: 260 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (32349/33408)
Epoch: 181 | Batch_idx: 270 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (33585/34688)
Epoch: 181 | Batch_idx: 280 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (34829/35968)
Epoch: 181 | Batch_idx: 290 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (36067/37248)
Epoch: 181 | Batch_idx: 300 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (37304/38528)
Epoch: 181 | Batch_idx: 310 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (38539/39808)
Epoch: 181 | Batch_idx: 320 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (39778/41088)
Epoch: 181 | Batch_idx: 330 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (41016/42368)
Epoch: 181 | Batch_idx: 340 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (42265/43648)
Epoch: 181 | Batch_idx: 350 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (43519/44928)
Epoch: 181 | Batch_idx: 360 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (44758/46208)
Epoch: 181 | Batch_idx: 370 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (45996/47488)
Epoch: 181 | Batch_idx: 380 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (47232/48768)
Epoch: 181 | Batch_idx: 390 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (48437/50000)
# TEST : Loss: (0.4011) | Acc: (88.00%) (8874/10000)
percent tensor([0.5359, 0.5440, 0.5255, 0.5173, 0.5321, 0.5121, 0.5444, 0.5323, 0.5480,
        0.5434, 0.5458, 0.5393, 0.5426, 0.5479, 0.5269, 0.5321],
       device='cuda:0') torch.Size([16])
percent tensor([0.4812, 0.4823, 0.4686, 0.4700, 0.4728, 0.4814, 0.4800, 0.4770, 0.4786,
        0.4771, 0.4837, 0.4667, 0.4852, 0.4817, 0.4748, 0.4833],
       device='cuda:0') torch.Size([16])
percent tensor([0.5855, 0.5166, 0.5335, 0.6098, 0.5546, 0.6499, 0.5282, 0.5813, 0.5829,
        0.5263, 0.5531, 0.4805, 0.5319, 0.6487, 0.5320, 0.6062],
       device='cuda:0') torch.Size([16])
percent tensor([0.6776, 0.7181, 0.6154, 0.5964, 0.6171, 0.6213, 0.6923, 0.6309, 0.6775,
        0.7115, 0.7194, 0.6509, 0.7176, 0.7001, 0.6648, 0.6844],
       device='cuda:0') torch.Size([16])
percent tensor([0.5959, 0.5442, 0.7635, 0.7643, 0.7886, 0.7724, 0.6321, 0.6504, 0.7171,
        0.5703, 0.6474, 0.6829, 0.5662, 0.6323, 0.6273, 0.6139],
       device='cuda:0') torch.Size([16])
percent tensor([0.7087, 0.7088, 0.7133, 0.7088, 0.7587, 0.7539, 0.7258, 0.6665, 0.7098,
        0.6793, 0.6679, 0.6682, 0.7085, 0.7090, 0.6581, 0.7385],
       device='cuda:0') torch.Size([16])
percent tensor([0.6864, 0.7847, 0.7096, 0.6427, 0.7307, 0.7963, 0.6850, 0.4956, 0.7692,
        0.6881, 0.7560, 0.7102, 0.7393, 0.7464, 0.5582, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9996, 0.9998, 0.9998, 0.9998, 0.9997, 0.9995,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9996, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 182 | Batch_idx: 0 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 182 | Batch_idx: 10 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 182 | Batch_idx: 20 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 182 | Batch_idx: 30 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (3851/3968)
Epoch: 182 | Batch_idx: 40 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (5085/5248)
Epoch: 182 | Batch_idx: 50 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (6322/6528)
Epoch: 182 | Batch_idx: 60 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (96.00%) (7570/7808)
Epoch: 182 | Batch_idx: 70 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (8805/9088)
Epoch: 182 | Batch_idx: 80 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (96.00%) (10056/10368)
Epoch: 182 | Batch_idx: 90 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (11297/11648)
Epoch: 182 | Batch_idx: 100 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (12546/12928)
Epoch: 182 | Batch_idx: 110 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (13795/14208)
Epoch: 182 | Batch_idx: 120 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (15041/15488)
Epoch: 182 | Batch_idx: 130 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (16287/16768)
Epoch: 182 | Batch_idx: 140 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (17529/18048)
Epoch: 182 | Batch_idx: 150 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (18772/19328)
Epoch: 182 | Batch_idx: 160 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (20003/20608)
Epoch: 182 | Batch_idx: 170 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (21243/21888)
Epoch: 182 | Batch_idx: 180 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (22483/23168)
Epoch: 182 | Batch_idx: 190 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (23729/24448)
Epoch: 182 | Batch_idx: 200 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (24973/25728)
Epoch: 182 | Batch_idx: 210 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (26214/27008)
Epoch: 182 | Batch_idx: 220 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (27455/28288)
Epoch: 182 | Batch_idx: 230 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (28685/29568)
Epoch: 182 | Batch_idx: 240 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (29937/30848)
Epoch: 182 | Batch_idx: 250 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (31183/32128)
Epoch: 182 | Batch_idx: 260 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (32422/33408)
Epoch: 182 | Batch_idx: 270 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (33659/34688)
Epoch: 182 | Batch_idx: 280 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (34918/35968)
Epoch: 182 | Batch_idx: 290 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (36160/37248)
Epoch: 182 | Batch_idx: 300 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (37401/38528)
Epoch: 182 | Batch_idx: 310 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (97.00%) (38644/39808)
Epoch: 182 | Batch_idx: 320 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (39897/41088)
Epoch: 182 | Batch_idx: 330 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (41139/42368)
Epoch: 182 | Batch_idx: 340 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (42382/43648)
Epoch: 182 | Batch_idx: 350 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (43631/44928)
Epoch: 182 | Batch_idx: 360 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (44870/46208)
Epoch: 182 | Batch_idx: 370 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (46115/47488)
Epoch: 182 | Batch_idx: 380 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (47349/48768)
Epoch: 182 | Batch_idx: 390 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (48547/50000)
# TEST : Loss: (0.3986) | Acc: (88.00%) (8871/10000)
percent tensor([0.5339, 0.5415, 0.5238, 0.5153, 0.5300, 0.5104, 0.5419, 0.5302, 0.5456,
        0.5414, 0.5435, 0.5375, 0.5407, 0.5454, 0.5247, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.4812, 0.4827, 0.4690, 0.4704, 0.4731, 0.4815, 0.4802, 0.4772, 0.4788,
        0.4776, 0.4838, 0.4672, 0.4856, 0.4819, 0.4752, 0.4836],
       device='cuda:0') torch.Size([16])
percent tensor([0.5887, 0.5199, 0.5360, 0.6120, 0.5578, 0.6534, 0.5319, 0.5822, 0.5872,
        0.5302, 0.5575, 0.4834, 0.5359, 0.6533, 0.5342, 0.6100],
       device='cuda:0') torch.Size([16])
percent tensor([0.6803, 0.7201, 0.6187, 0.5996, 0.6202, 0.6259, 0.6940, 0.6336, 0.6789,
        0.7140, 0.7205, 0.6532, 0.7194, 0.7012, 0.6679, 0.6878],
       device='cuda:0') torch.Size([16])
percent tensor([0.5940, 0.5434, 0.7594, 0.7628, 0.7860, 0.7736, 0.6295, 0.6479, 0.7149,
        0.5671, 0.6453, 0.6764, 0.5652, 0.6306, 0.6248, 0.6118],
       device='cuda:0') torch.Size([16])
percent tensor([0.7022, 0.7019, 0.7063, 0.7016, 0.7519, 0.7497, 0.7173, 0.6570, 0.7017,
        0.6690, 0.6582, 0.6586, 0.7019, 0.7024, 0.6480, 0.7323],
       device='cuda:0') torch.Size([16])
percent tensor([0.6943, 0.7863, 0.7169, 0.6541, 0.7386, 0.8040, 0.6909, 0.5007, 0.7695,
        0.6875, 0.7554, 0.7153, 0.7404, 0.7476, 0.5616, 0.6543],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9996, 0.9998, 0.9998, 0.9998, 0.9997, 0.9995,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9996, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 183 | Batch_idx: 0 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 183 | Batch_idx: 10 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 183 | Batch_idx: 20 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (2603/2688)
Epoch: 183 | Batch_idx: 30 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (3852/3968)
Epoch: 183 | Batch_idx: 40 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (5100/5248)
Epoch: 183 | Batch_idx: 50 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (6337/6528)
Epoch: 183 | Batch_idx: 60 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (7580/7808)
Epoch: 183 | Batch_idx: 70 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (8820/9088)
Epoch: 183 | Batch_idx: 80 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (97.00%) (10068/10368)
Epoch: 183 | Batch_idx: 90 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (11304/11648)
Epoch: 183 | Batch_idx: 100 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (12550/12928)
Epoch: 183 | Batch_idx: 110 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (13790/14208)
Epoch: 183 | Batch_idx: 120 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (15024/15488)
Epoch: 183 | Batch_idx: 130 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (16271/16768)
Epoch: 183 | Batch_idx: 140 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (17515/18048)
Epoch: 183 | Batch_idx: 150 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (18764/19328)
Epoch: 183 | Batch_idx: 160 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (20005/20608)
Epoch: 183 | Batch_idx: 170 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (21253/21888)
Epoch: 183 | Batch_idx: 180 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (97.00%) (22502/23168)
Epoch: 183 | Batch_idx: 190 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (23758/24448)
Epoch: 183 | Batch_idx: 200 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (25008/25728)
Epoch: 183 | Batch_idx: 210 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (26257/27008)
Epoch: 183 | Batch_idx: 220 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (27496/28288)
Epoch: 183 | Batch_idx: 230 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (28733/29568)
Epoch: 183 | Batch_idx: 240 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (29972/30848)
Epoch: 183 | Batch_idx: 250 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (31219/32128)
Epoch: 183 | Batch_idx: 260 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (32465/33408)
Epoch: 183 | Batch_idx: 270 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (33709/34688)
Epoch: 183 | Batch_idx: 280 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (34956/35968)
Epoch: 183 | Batch_idx: 290 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (36199/37248)
Epoch: 183 | Batch_idx: 300 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (37436/38528)
Epoch: 183 | Batch_idx: 310 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (38682/39808)
Epoch: 183 | Batch_idx: 320 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (39924/41088)
Epoch: 183 | Batch_idx: 330 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (41164/42368)
Epoch: 183 | Batch_idx: 340 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (42407/43648)
Epoch: 183 | Batch_idx: 350 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (43650/44928)
Epoch: 183 | Batch_idx: 360 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (44896/46208)
Epoch: 183 | Batch_idx: 370 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (46151/47488)
Epoch: 183 | Batch_idx: 380 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (47385/48768)
Epoch: 183 | Batch_idx: 390 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (48577/50000)
# TEST : Loss: (0.3908) | Acc: (88.00%) (8877/10000)
percent tensor([0.5367, 0.5443, 0.5269, 0.5180, 0.5331, 0.5130, 0.5450, 0.5331, 0.5484,
        0.5440, 0.5463, 0.5403, 0.5431, 0.5478, 0.5274, 0.5328],
       device='cuda:0') torch.Size([16])
percent tensor([0.4806, 0.4824, 0.4684, 0.4697, 0.4726, 0.4809, 0.4797, 0.4766, 0.4780,
        0.4772, 0.4831, 0.4668, 0.4852, 0.4811, 0.4747, 0.4832],
       device='cuda:0') torch.Size([16])
percent tensor([0.5866, 0.5163, 0.5328, 0.6099, 0.5558, 0.6538, 0.5287, 0.5796, 0.5823,
        0.5260, 0.5521, 0.4795, 0.5314, 0.6497, 0.5319, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.6775, 0.7166, 0.6167, 0.5971, 0.6184, 0.6258, 0.6902, 0.6304, 0.6756,
        0.7113, 0.7172, 0.6502, 0.7159, 0.6978, 0.6646, 0.6859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5889, 0.5415, 0.7519, 0.7563, 0.7783, 0.7688, 0.6214, 0.6400, 0.7082,
        0.5622, 0.6404, 0.6672, 0.5602, 0.6251, 0.6194, 0.6079],
       device='cuda:0') torch.Size([16])
percent tensor([0.6979, 0.6967, 0.7014, 0.6956, 0.7466, 0.7467, 0.7127, 0.6506, 0.6970,
        0.6634, 0.6528, 0.6533, 0.6985, 0.6973, 0.6433, 0.7275],
       device='cuda:0') torch.Size([16])
percent tensor([0.6911, 0.7837, 0.7141, 0.6534, 0.7353, 0.8044, 0.6916, 0.4964, 0.7737,
        0.6832, 0.7563, 0.7176, 0.7461, 0.7457, 0.5643, 0.6500],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9996, 0.9998, 0.9998, 0.9998, 0.9997, 0.9996,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9996, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 184 | Batch_idx: 0 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 184 | Batch_idx: 10 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 184 | Batch_idx: 20 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 184 | Batch_idx: 30 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (3844/3968)
Epoch: 184 | Batch_idx: 40 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (5086/5248)
Epoch: 184 | Batch_idx: 50 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (6327/6528)
Epoch: 184 | Batch_idx: 60 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (7573/7808)
Epoch: 184 | Batch_idx: 70 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (8813/9088)
Epoch: 184 | Batch_idx: 80 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (10059/10368)
Epoch: 184 | Batch_idx: 90 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (11284/11648)
Epoch: 184 | Batch_idx: 100 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (12521/12928)
Epoch: 184 | Batch_idx: 110 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (13759/14208)
Epoch: 184 | Batch_idx: 120 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (14995/15488)
Epoch: 184 | Batch_idx: 130 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (16236/16768)
Epoch: 184 | Batch_idx: 140 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (17472/18048)
Epoch: 184 | Batch_idx: 150 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (18715/19328)
Epoch: 184 | Batch_idx: 160 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (19954/20608)
Epoch: 184 | Batch_idx: 170 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (21191/21888)
Epoch: 184 | Batch_idx: 180 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (22419/23168)
Epoch: 184 | Batch_idx: 190 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (23657/24448)
Epoch: 184 | Batch_idx: 200 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (24888/25728)
Epoch: 184 | Batch_idx: 210 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (26122/27008)
Epoch: 184 | Batch_idx: 220 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (27368/28288)
Epoch: 184 | Batch_idx: 230 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (28601/29568)
Epoch: 184 | Batch_idx: 240 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (29842/30848)
Epoch: 184 | Batch_idx: 250 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (31075/32128)
Epoch: 184 | Batch_idx: 260 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (32305/33408)
Epoch: 184 | Batch_idx: 270 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (33552/34688)
Epoch: 184 | Batch_idx: 280 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (34794/35968)
Epoch: 184 | Batch_idx: 290 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (36030/37248)
Epoch: 184 | Batch_idx: 300 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (37268/38528)
Epoch: 184 | Batch_idx: 310 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (38505/39808)
Epoch: 184 | Batch_idx: 320 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (39748/41088)
Epoch: 184 | Batch_idx: 330 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (40977/42368)
Epoch: 184 | Batch_idx: 340 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (42220/43648)
Epoch: 184 | Batch_idx: 350 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (43458/44928)
Epoch: 184 | Batch_idx: 360 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (44702/46208)
Epoch: 184 | Batch_idx: 370 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (45940/47488)
Epoch: 184 | Batch_idx: 380 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (47174/48768)
Epoch: 184 | Batch_idx: 390 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (48361/50000)
# TEST : Loss: (0.4143) | Acc: (88.00%) (8804/10000)
percent tensor([0.5388, 0.5454, 0.5279, 0.5205, 0.5340, 0.5163, 0.5463, 0.5337, 0.5496,
        0.5451, 0.5479, 0.5412, 0.5445, 0.5483, 0.5299, 0.5354],
       device='cuda:0') torch.Size([16])
percent tensor([0.4795, 0.4826, 0.4677, 0.4683, 0.4714, 0.4795, 0.4792, 0.4757, 0.4778,
        0.4764, 0.4831, 0.4653, 0.4849, 0.4811, 0.4747, 0.4828],
       device='cuda:0') torch.Size([16])
percent tensor([0.5848, 0.5080, 0.5530, 0.6062, 0.5723, 0.6463, 0.5300, 0.5799, 0.5867,
        0.5208, 0.5433, 0.4986, 0.5311, 0.6412, 0.5262, 0.6012],
       device='cuda:0') torch.Size([16])
percent tensor([0.6752, 0.7166, 0.6090, 0.5989, 0.6100, 0.6263, 0.6837, 0.6285, 0.6758,
        0.7128, 0.7175, 0.6424, 0.7178, 0.6987, 0.6644, 0.6871],
       device='cuda:0') torch.Size([16])
percent tensor([0.5827, 0.5333, 0.7557, 0.7538, 0.7801, 0.7558, 0.6191, 0.6372, 0.6790,
        0.5542, 0.6197, 0.6772, 0.5400, 0.6180, 0.6058, 0.5904],
       device='cuda:0') torch.Size([16])
percent tensor([0.7082, 0.6967, 0.7108, 0.6979, 0.7506, 0.7565, 0.7123, 0.6639, 0.6902,
        0.6679, 0.6505, 0.6538, 0.7039, 0.6835, 0.6444, 0.7369],
       device='cuda:0') torch.Size([16])
percent tensor([0.7042, 0.7696, 0.7367, 0.6813, 0.7288, 0.8121, 0.6842, 0.5245, 0.7653,
        0.7056, 0.7550, 0.7336, 0.7525, 0.7239, 0.5789, 0.6561],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9999, 0.9998, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9997, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 185 | Batch_idx: 0 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 185 | Batch_idx: 10 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 185 | Batch_idx: 20 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 185 | Batch_idx: 30 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (3848/3968)
Epoch: 185 | Batch_idx: 40 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (5089/5248)
Epoch: 185 | Batch_idx: 50 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (6335/6528)
Epoch: 185 | Batch_idx: 60 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (7576/7808)
Epoch: 185 | Batch_idx: 70 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (8825/9088)
Epoch: 185 | Batch_idx: 80 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (10059/10368)
Epoch: 185 | Batch_idx: 90 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (11303/11648)
Epoch: 185 | Batch_idx: 100 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (12550/12928)
Epoch: 185 | Batch_idx: 110 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (13783/14208)
Epoch: 185 | Batch_idx: 120 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (15022/15488)
Epoch: 185 | Batch_idx: 130 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (16269/16768)
Epoch: 185 | Batch_idx: 140 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (17501/18048)
Epoch: 185 | Batch_idx: 150 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (18734/19328)
Epoch: 185 | Batch_idx: 160 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (19973/20608)
Epoch: 185 | Batch_idx: 170 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (21215/21888)
Epoch: 185 | Batch_idx: 180 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (22455/23168)
Epoch: 185 | Batch_idx: 190 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (23686/24448)
Epoch: 185 | Batch_idx: 200 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (24921/25728)
Epoch: 185 | Batch_idx: 210 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (26157/27008)
Epoch: 185 | Batch_idx: 220 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (27397/28288)
Epoch: 185 | Batch_idx: 230 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (28639/29568)
Epoch: 185 | Batch_idx: 240 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (29885/30848)
Epoch: 185 | Batch_idx: 250 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (31123/32128)
Epoch: 185 | Batch_idx: 260 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (32361/33408)
Epoch: 185 | Batch_idx: 270 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (33598/34688)
Epoch: 185 | Batch_idx: 280 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (34849/35968)
Epoch: 185 | Batch_idx: 290 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (36086/37248)
Epoch: 185 | Batch_idx: 300 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (37321/38528)
Epoch: 185 | Batch_idx: 310 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (38556/39808)
Epoch: 185 | Batch_idx: 320 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (39796/41088)
Epoch: 185 | Batch_idx: 330 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (41028/42368)
Epoch: 185 | Batch_idx: 340 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (42271/43648)
Epoch: 185 | Batch_idx: 350 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (43510/44928)
Epoch: 185 | Batch_idx: 360 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (44753/46208)
Epoch: 185 | Batch_idx: 370 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (45985/47488)
Epoch: 185 | Batch_idx: 380 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (47223/48768)
Epoch: 185 | Batch_idx: 390 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (48409/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_185.pth.tar'
# TEST : Loss: (0.4508) | Acc: (87.00%) (8766/10000)
percent tensor([0.5374, 0.5448, 0.5277, 0.5194, 0.5342, 0.5148, 0.5460, 0.5334, 0.5486,
        0.5447, 0.5469, 0.5412, 0.5433, 0.5479, 0.5286, 0.5340],
       device='cuda:0') torch.Size([16])
percent tensor([0.4811, 0.4830, 0.4694, 0.4707, 0.4732, 0.4811, 0.4801, 0.4777, 0.4785,
        0.4770, 0.4829, 0.4675, 0.4853, 0.4824, 0.4758, 0.4838],
       device='cuda:0') torch.Size([16])
percent tensor([0.5820, 0.5079, 0.5588, 0.6167, 0.5694, 0.6510, 0.5235, 0.5869, 0.5839,
        0.5217, 0.5423, 0.4979, 0.5238, 0.6308, 0.5329, 0.6017],
       device='cuda:0') torch.Size([16])
percent tensor([0.6761, 0.7174, 0.6100, 0.6008, 0.6159, 0.6295, 0.6885, 0.6319, 0.6813,
        0.7117, 0.7173, 0.6465, 0.7158, 0.7053, 0.6676, 0.6871],
       device='cuda:0') torch.Size([16])
percent tensor([0.5731, 0.5331, 0.7350, 0.7277, 0.7581, 0.7293, 0.6129, 0.6166, 0.6692,
        0.5605, 0.6371, 0.6557, 0.5440, 0.6320, 0.5787, 0.5795],
       device='cuda:0') torch.Size([16])
percent tensor([0.6966, 0.6962, 0.7039, 0.6856, 0.7460, 0.7498, 0.7062, 0.6498, 0.6894,
        0.6691, 0.6614, 0.6553, 0.6934, 0.6980, 0.6367, 0.7303],
       device='cuda:0') torch.Size([16])
percent tensor([0.7058, 0.7694, 0.7292, 0.6409, 0.7459, 0.8069, 0.6791, 0.4985, 0.7648,
        0.6938, 0.7479, 0.7360, 0.7445, 0.6974, 0.5658, 0.6476],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9998, 0.9999, 0.9998, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 186 | Batch_idx: 0 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 186 | Batch_idx: 10 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 186 | Batch_idx: 20 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (2599/2688)
Epoch: 186 | Batch_idx: 30 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (3842/3968)
Epoch: 186 | Batch_idx: 40 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (5082/5248)
Epoch: 186 | Batch_idx: 50 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (6334/6528)
Epoch: 186 | Batch_idx: 60 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (7581/7808)
Epoch: 186 | Batch_idx: 70 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (8829/9088)
Epoch: 186 | Batch_idx: 80 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (10071/10368)
Epoch: 186 | Batch_idx: 90 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (11313/11648)
Epoch: 186 | Batch_idx: 100 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (12547/12928)
Epoch: 186 | Batch_idx: 110 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (13797/14208)
Epoch: 186 | Batch_idx: 120 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (15029/15488)
Epoch: 186 | Batch_idx: 130 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (16276/16768)
Epoch: 186 | Batch_idx: 140 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (17517/18048)
Epoch: 186 | Batch_idx: 150 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (18771/19328)
Epoch: 186 | Batch_idx: 160 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (20014/20608)
Epoch: 186 | Batch_idx: 170 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (21259/21888)
Epoch: 186 | Batch_idx: 180 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (22510/23168)
Epoch: 186 | Batch_idx: 190 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (23751/24448)
Epoch: 186 | Batch_idx: 200 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (24985/25728)
Epoch: 186 | Batch_idx: 210 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (26230/27008)
Epoch: 186 | Batch_idx: 220 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (27461/28288)
Epoch: 186 | Batch_idx: 230 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (28708/29568)
Epoch: 186 | Batch_idx: 240 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (29941/30848)
Epoch: 186 | Batch_idx: 250 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (31186/32128)
Epoch: 186 | Batch_idx: 260 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (97.00%) (32426/33408)
Epoch: 186 | Batch_idx: 270 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (33659/34688)
Epoch: 186 | Batch_idx: 280 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (34899/35968)
Epoch: 186 | Batch_idx: 290 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (36141/37248)
Epoch: 186 | Batch_idx: 300 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (37382/38528)
Epoch: 186 | Batch_idx: 310 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (38608/39808)
Epoch: 186 | Batch_idx: 320 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (39847/41088)
Epoch: 186 | Batch_idx: 330 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (41083/42368)
Epoch: 186 | Batch_idx: 340 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (42327/43648)
Epoch: 186 | Batch_idx: 350 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (43574/44928)
Epoch: 186 | Batch_idx: 360 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (44805/46208)
Epoch: 186 | Batch_idx: 370 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (46055/47488)
Epoch: 186 | Batch_idx: 380 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (47297/48768)
Epoch: 186 | Batch_idx: 390 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (48480/50000)
# TEST : Loss: (0.4143) | Acc: (87.00%) (8797/10000)
percent tensor([0.5382, 0.5459, 0.5276, 0.5202, 0.5340, 0.5165, 0.5464, 0.5342, 0.5501,
        0.5452, 0.5482, 0.5408, 0.5447, 0.5494, 0.5298, 0.5356],
       device='cuda:0') torch.Size([16])
percent tensor([0.4804, 0.4826, 0.4710, 0.4690, 0.4733, 0.4795, 0.4801, 0.4772, 0.4787,
        0.4776, 0.4833, 0.4679, 0.4852, 0.4818, 0.4745, 0.4830],
       device='cuda:0') torch.Size([16])
percent tensor([0.5837, 0.5149, 0.5526, 0.6179, 0.5670, 0.6457, 0.5338, 0.5942, 0.5837,
        0.5260, 0.5431, 0.4863, 0.5247, 0.6420, 0.5347, 0.6066],
       device='cuda:0') torch.Size([16])
percent tensor([0.6741, 0.7155, 0.6176, 0.5998, 0.6137, 0.6240, 0.6834, 0.6274, 0.6761,
        0.7096, 0.7172, 0.6467, 0.7141, 0.6934, 0.6626, 0.6859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5862, 0.5577, 0.7319, 0.7376, 0.7654, 0.7481, 0.6444, 0.6363, 0.6923,
        0.5777, 0.6427, 0.6853, 0.5735, 0.6402, 0.6202, 0.5975],
       device='cuda:0') torch.Size([16])
percent tensor([0.7054, 0.7078, 0.7087, 0.6813, 0.7487, 0.7552, 0.7165, 0.6602, 0.6989,
        0.6735, 0.6656, 0.6480, 0.7074, 0.7021, 0.6499, 0.7366],
       device='cuda:0') torch.Size([16])
percent tensor([0.7098, 0.7828, 0.7423, 0.6143, 0.7405, 0.8086, 0.6957, 0.5170, 0.7870,
        0.6944, 0.7596, 0.7172, 0.7628, 0.7126, 0.5624, 0.6451],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9998, 0.9996, 0.9999, 0.9997, 0.9998, 0.9995, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9998, 0.9994, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 187 | Batch_idx: 0 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 187 | Batch_idx: 10 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 187 | Batch_idx: 20 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (2595/2688)
Epoch: 187 | Batch_idx: 30 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (96.00%) (3842/3968)
Epoch: 187 | Batch_idx: 40 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (5096/5248)
Epoch: 187 | Batch_idx: 50 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (6342/6528)
Epoch: 187 | Batch_idx: 60 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (7580/7808)
Epoch: 187 | Batch_idx: 70 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (8836/9088)
Epoch: 187 | Batch_idx: 80 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (10078/10368)
Epoch: 187 | Batch_idx: 90 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (11322/11648)
Epoch: 187 | Batch_idx: 100 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (12566/12928)
Epoch: 187 | Batch_idx: 110 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (13804/14208)
Epoch: 187 | Batch_idx: 120 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (15043/15488)
Epoch: 187 | Batch_idx: 130 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (16284/16768)
Epoch: 187 | Batch_idx: 140 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (17520/18048)
Epoch: 187 | Batch_idx: 150 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (18758/19328)
Epoch: 187 | Batch_idx: 160 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (96.00%) (19986/20608)
Epoch: 187 | Batch_idx: 170 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (96.00%) (21229/21888)
Epoch: 187 | Batch_idx: 180 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (22463/23168)
Epoch: 187 | Batch_idx: 190 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (23701/24448)
Epoch: 187 | Batch_idx: 200 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (24945/25728)
Epoch: 187 | Batch_idx: 210 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (26190/27008)
Epoch: 187 | Batch_idx: 220 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (27438/28288)
Epoch: 187 | Batch_idx: 230 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (28671/29568)
Epoch: 187 | Batch_idx: 240 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (29917/30848)
Epoch: 187 | Batch_idx: 250 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (31145/32128)
Epoch: 187 | Batch_idx: 260 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (32382/33408)
Epoch: 187 | Batch_idx: 270 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (33615/34688)
Epoch: 187 | Batch_idx: 280 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (34855/35968)
Epoch: 187 | Batch_idx: 290 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (36089/37248)
Epoch: 187 | Batch_idx: 300 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (37332/38528)
Epoch: 187 | Batch_idx: 310 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (38570/39808)
Epoch: 187 | Batch_idx: 320 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (39812/41088)
Epoch: 187 | Batch_idx: 330 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (41043/42368)
Epoch: 187 | Batch_idx: 340 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (42286/43648)
Epoch: 187 | Batch_idx: 350 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (43523/44928)
Epoch: 187 | Batch_idx: 360 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (44769/46208)
Epoch: 187 | Batch_idx: 370 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (46004/47488)
Epoch: 187 | Batch_idx: 380 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (47241/48768)
Epoch: 187 | Batch_idx: 390 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (48426/50000)
# TEST : Loss: (0.4446) | Acc: (87.00%) (8787/10000)
percent tensor([0.5373, 0.5452, 0.5248, 0.5180, 0.5319, 0.5150, 0.5455, 0.5323, 0.5488,
        0.5440, 0.5474, 0.5389, 0.5435, 0.5488, 0.5288, 0.5340],
       device='cuda:0') torch.Size([16])
percent tensor([0.4792, 0.4819, 0.4654, 0.4681, 0.4696, 0.4788, 0.4781, 0.4750, 0.4762,
        0.4756, 0.4819, 0.4643, 0.4840, 0.4827, 0.4742, 0.4823],
       device='cuda:0') torch.Size([16])
percent tensor([0.5867, 0.5057, 0.5501, 0.6149, 0.5626, 0.6430, 0.5231, 0.5893, 0.5779,
        0.5229, 0.5424, 0.4920, 0.5317, 0.6329, 0.5278, 0.6019],
       device='cuda:0') torch.Size([16])
percent tensor([0.6717, 0.7147, 0.6093, 0.5962, 0.6135, 0.6267, 0.6862, 0.6306, 0.6784,
        0.7055, 0.7157, 0.6386, 0.7072, 0.6994, 0.6650, 0.6822],
       device='cuda:0') torch.Size([16])
percent tensor([0.5717, 0.5317, 0.7383, 0.7405, 0.7662, 0.7414, 0.6009, 0.6159, 0.6709,
        0.5665, 0.6387, 0.6879, 0.5663, 0.5947, 0.5967, 0.5788],
       device='cuda:0') torch.Size([16])
percent tensor([0.6948, 0.6889, 0.6953, 0.6912, 0.7457, 0.7530, 0.7097, 0.6602, 0.6869,
        0.6576, 0.6547, 0.6558, 0.6968, 0.6879, 0.6402, 0.7279],
       device='cuda:0') torch.Size([16])
percent tensor([0.6911, 0.7719, 0.7071, 0.6747, 0.7150, 0.8097, 0.6835, 0.5143, 0.7426,
        0.6780, 0.7551, 0.7662, 0.7325, 0.7344, 0.5996, 0.6435],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 188 | Batch_idx: 0 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 188 | Batch_idx: 10 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 188 | Batch_idx: 20 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (2538/2688)
Epoch: 188 | Batch_idx: 30 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (3741/3968)
Epoch: 188 | Batch_idx: 40 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (93.00%) (4930/5248)
Epoch: 188 | Batch_idx: 50 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (93.00%) (6126/6528)
Epoch: 188 | Batch_idx: 60 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (93.00%) (7326/7808)
Epoch: 188 | Batch_idx: 70 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (8507/9088)
Epoch: 188 | Batch_idx: 80 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (93.00%) (9710/10368)
Epoch: 188 | Batch_idx: 90 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (93.00%) (10911/11648)
Epoch: 188 | Batch_idx: 100 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (93.00%) (12125/12928)
Epoch: 188 | Batch_idx: 110 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (93.00%) (13330/14208)
Epoch: 188 | Batch_idx: 120 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (93.00%) (14537/15488)
Epoch: 188 | Batch_idx: 130 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (93.00%) (15760/16768)
Epoch: 188 | Batch_idx: 140 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (16978/18048)
Epoch: 188 | Batch_idx: 150 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (18181/19328)
Epoch: 188 | Batch_idx: 160 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (19383/20608)
Epoch: 188 | Batch_idx: 170 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (20600/21888)
Epoch: 188 | Batch_idx: 180 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (21814/23168)
Epoch: 188 | Batch_idx: 190 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (23033/24448)
Epoch: 188 | Batch_idx: 200 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (24250/25728)
Epoch: 188 | Batch_idx: 210 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (25475/27008)
Epoch: 188 | Batch_idx: 220 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (26689/28288)
Epoch: 188 | Batch_idx: 230 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (27901/29568)
Epoch: 188 | Batch_idx: 240 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (29106/30848)
Epoch: 188 | Batch_idx: 250 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (30320/32128)
Epoch: 188 | Batch_idx: 260 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (31529/33408)
Epoch: 188 | Batch_idx: 270 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (32751/34688)
Epoch: 188 | Batch_idx: 280 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (33974/35968)
Epoch: 188 | Batch_idx: 290 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (35198/37248)
Epoch: 188 | Batch_idx: 300 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (36400/38528)
Epoch: 188 | Batch_idx: 310 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (37633/39808)
Epoch: 188 | Batch_idx: 320 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (38860/41088)
Epoch: 188 | Batch_idx: 330 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (40089/42368)
Epoch: 188 | Batch_idx: 340 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (41319/43648)
Epoch: 188 | Batch_idx: 350 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (42530/44928)
Epoch: 188 | Batch_idx: 360 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (43763/46208)
Epoch: 188 | Batch_idx: 370 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (44978/47488)
Epoch: 188 | Batch_idx: 380 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (46205/48768)
Epoch: 188 | Batch_idx: 390 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (94.00%) (47390/50000)
# TEST : Loss: (0.4605) | Acc: (87.00%) (8735/10000)
percent tensor([0.5307, 0.5369, 0.5190, 0.5120, 0.5247, 0.5099, 0.5368, 0.5243, 0.5412,
        0.5368, 0.5398, 0.5324, 0.5365, 0.5407, 0.5217, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.4822, 0.4849, 0.4653, 0.4685, 0.4698, 0.4825, 0.4805, 0.4765, 0.4778,
        0.4776, 0.4849, 0.4647, 0.4863, 0.4851, 0.4776, 0.4860],
       device='cuda:0') torch.Size([16])
percent tensor([0.5848, 0.5074, 0.5382, 0.6031, 0.5642, 0.6321, 0.5296, 0.5890, 0.5699,
        0.5196, 0.5322, 0.4922, 0.5310, 0.6253, 0.5299, 0.5968],
       device='cuda:0') torch.Size([16])
percent tensor([0.6969, 0.7421, 0.6307, 0.6106, 0.6359, 0.6484, 0.7113, 0.6505, 0.7065,
        0.7321, 0.7479, 0.6630, 0.7363, 0.7231, 0.6967, 0.7085],
       device='cuda:0') torch.Size([16])
percent tensor([0.5725, 0.5427, 0.7126, 0.7104, 0.7198, 0.7193, 0.5953, 0.5811, 0.6685,
        0.5665, 0.6323, 0.6656, 0.5828, 0.6158, 0.5764, 0.5654],
       device='cuda:0') torch.Size([16])
percent tensor([0.7186, 0.6986, 0.7118, 0.7093, 0.7596, 0.7685, 0.7304, 0.6755, 0.7011,
        0.6732, 0.6651, 0.6685, 0.7042, 0.7062, 0.6596, 0.7509],
       device='cuda:0') torch.Size([16])
percent tensor([0.7077, 0.7664, 0.6684, 0.6622, 0.6659, 0.8119, 0.6798, 0.4805, 0.7284,
        0.6761, 0.7330, 0.7196, 0.7330, 0.7386, 0.5700, 0.6652],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9995, 0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9997, 0.9999, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 189 | Batch_idx: 0 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 189 | Batch_idx: 10 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (94.00%) (1331/1408)
Epoch: 189 | Batch_idx: 20 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 189 | Batch_idx: 30 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (3789/3968)
Epoch: 189 | Batch_idx: 40 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (5014/5248)
Epoch: 189 | Batch_idx: 50 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (6243/6528)
Epoch: 189 | Batch_idx: 60 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (7463/7808)
Epoch: 189 | Batch_idx: 70 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (8687/9088)
Epoch: 189 | Batch_idx: 80 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (9904/10368)
Epoch: 189 | Batch_idx: 90 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (11128/11648)
Epoch: 189 | Batch_idx: 100 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (12367/12928)
Epoch: 189 | Batch_idx: 110 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (13589/14208)
Epoch: 189 | Batch_idx: 120 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (14823/15488)
Epoch: 189 | Batch_idx: 130 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (16046/16768)
Epoch: 189 | Batch_idx: 140 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (17279/18048)
Epoch: 189 | Batch_idx: 150 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (18496/19328)
Epoch: 189 | Batch_idx: 160 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (19734/20608)
Epoch: 189 | Batch_idx: 170 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (20956/21888)
Epoch: 189 | Batch_idx: 180 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (22192/23168)
Epoch: 189 | Batch_idx: 190 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (23423/24448)
Epoch: 189 | Batch_idx: 200 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (24642/25728)
Epoch: 189 | Batch_idx: 210 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (25865/27008)
Epoch: 189 | Batch_idx: 220 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (27086/28288)
Epoch: 189 | Batch_idx: 230 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (28314/29568)
Epoch: 189 | Batch_idx: 240 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (29536/30848)
Epoch: 189 | Batch_idx: 250 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (30767/32128)
Epoch: 189 | Batch_idx: 260 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (31993/33408)
Epoch: 189 | Batch_idx: 270 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (33237/34688)
Epoch: 189 | Batch_idx: 280 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (34465/35968)
Epoch: 189 | Batch_idx: 290 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (35691/37248)
Epoch: 189 | Batch_idx: 300 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (36923/38528)
Epoch: 189 | Batch_idx: 310 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (38158/39808)
Epoch: 189 | Batch_idx: 320 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (39394/41088)
Epoch: 189 | Batch_idx: 330 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (95.00%) (40635/42368)
Epoch: 189 | Batch_idx: 340 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (41874/43648)
Epoch: 189 | Batch_idx: 350 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (95.00%) (43105/44928)
Epoch: 189 | Batch_idx: 360 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (95.00%) (44334/46208)
Epoch: 189 | Batch_idx: 370 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (95.00%) (45563/47488)
Epoch: 189 | Batch_idx: 380 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (95.00%) (46799/48768)
Epoch: 189 | Batch_idx: 390 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (95.00%) (47977/50000)
# TEST : Loss: (0.4344) | Acc: (87.00%) (8778/10000)
percent tensor([0.5396, 0.5461, 0.5283, 0.5214, 0.5345, 0.5194, 0.5466, 0.5332, 0.5500,
        0.5452, 0.5488, 0.5411, 0.5446, 0.5490, 0.5312, 0.5362],
       device='cuda:0') torch.Size([16])
percent tensor([0.4823, 0.4864, 0.4644, 0.4679, 0.4694, 0.4835, 0.4812, 0.4760, 0.4775,
        0.4779, 0.4853, 0.4642, 0.4867, 0.4858, 0.4786, 0.4867],
       device='cuda:0') torch.Size([16])
percent tensor([0.5900, 0.5149, 0.5391, 0.6028, 0.5685, 0.6344, 0.5373, 0.5924, 0.5755,
        0.5256, 0.5382, 0.4964, 0.5373, 0.6331, 0.5341, 0.6012],
       device='cuda:0') torch.Size([16])
percent tensor([0.6993, 0.7456, 0.6313, 0.6104, 0.6364, 0.6490, 0.7147, 0.6510, 0.7079,
        0.7338, 0.7492, 0.6648, 0.7393, 0.7244, 0.6998, 0.7109],
       device='cuda:0') torch.Size([16])
percent tensor([0.5713, 0.5394, 0.7130, 0.7164, 0.7203, 0.7231, 0.5978, 0.5796, 0.6752,
        0.5627, 0.6374, 0.6691, 0.5815, 0.6253, 0.5789, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.7242, 0.7042, 0.7182, 0.7140, 0.7665, 0.7716, 0.7371, 0.6851, 0.7064,
        0.6795, 0.6719, 0.6730, 0.7065, 0.7108, 0.6663, 0.7579],
       device='cuda:0') torch.Size([16])
percent tensor([0.6983, 0.7561, 0.6462, 0.6377, 0.6368, 0.8045, 0.6563, 0.4643, 0.7125,
        0.6565, 0.7171, 0.6998, 0.7276, 0.7248, 0.5425, 0.6550],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9995, 0.9997, 0.9998, 0.9999, 0.9998, 0.9997, 0.9997,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 190 | Batch_idx: 0 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 190 | Batch_idx: 10 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 190 | Batch_idx: 20 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (2583/2688)
Epoch: 190 | Batch_idx: 30 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (3810/3968)
Epoch: 190 | Batch_idx: 40 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (5043/5248)
Epoch: 190 | Batch_idx: 50 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (6272/6528)
Epoch: 190 | Batch_idx: 60 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (7515/7808)
Epoch: 190 | Batch_idx: 70 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (8754/9088)
Epoch: 190 | Batch_idx: 80 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (9990/10368)
Epoch: 190 | Batch_idx: 90 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (11223/11648)
Epoch: 190 | Batch_idx: 100 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (12449/12928)
Epoch: 190 | Batch_idx: 110 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (13683/14208)
Epoch: 190 | Batch_idx: 120 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (14924/15488)
Epoch: 190 | Batch_idx: 130 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (16163/16768)
Epoch: 190 | Batch_idx: 140 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (17401/18048)
Epoch: 190 | Batch_idx: 150 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (18632/19328)
Epoch: 190 | Batch_idx: 160 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (19859/20608)
Epoch: 190 | Batch_idx: 170 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (21100/21888)
Epoch: 190 | Batch_idx: 180 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (22338/23168)
Epoch: 190 | Batch_idx: 190 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (23559/24448)
Epoch: 190 | Batch_idx: 200 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (24786/25728)
Epoch: 190 | Batch_idx: 210 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (26004/27008)
Epoch: 190 | Batch_idx: 220 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (27245/28288)
Epoch: 190 | Batch_idx: 230 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (28479/29568)
Epoch: 190 | Batch_idx: 240 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (29704/30848)
Epoch: 190 | Batch_idx: 250 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (30945/32128)
Epoch: 190 | Batch_idx: 260 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (32176/33408)
Epoch: 190 | Batch_idx: 270 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (33414/34688)
Epoch: 190 | Batch_idx: 280 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (34639/35968)
Epoch: 190 | Batch_idx: 290 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (35864/37248)
Epoch: 190 | Batch_idx: 300 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (37086/38528)
Epoch: 190 | Batch_idx: 310 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (38328/39808)
Epoch: 190 | Batch_idx: 320 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (39577/41088)
Epoch: 190 | Batch_idx: 330 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (40806/42368)
Epoch: 190 | Batch_idx: 340 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (42035/43648)
Epoch: 190 | Batch_idx: 350 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (43259/44928)
Epoch: 190 | Batch_idx: 360 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (44482/46208)
Epoch: 190 | Batch_idx: 370 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (45716/47488)
Epoch: 190 | Batch_idx: 380 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (46949/48768)
Epoch: 190 | Batch_idx: 390 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (48142/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_190.pth.tar'
# TEST : Loss: (0.4227) | Acc: (88.00%) (8820/10000)
percent tensor([0.5413, 0.5471, 0.5298, 0.5231, 0.5359, 0.5215, 0.5482, 0.5343, 0.5511,
        0.5463, 0.5500, 0.5420, 0.5457, 0.5501, 0.5329, 0.5380],
       device='cuda:0') torch.Size([16])
percent tensor([0.4839, 0.4889, 0.4645, 0.4684, 0.4700, 0.4853, 0.4831, 0.4769, 0.4792,
        0.4797, 0.4877, 0.4649, 0.4887, 0.4884, 0.4805, 0.4888],
       device='cuda:0') torch.Size([16])
percent tensor([0.5845, 0.5062, 0.5330, 0.5970, 0.5607, 0.6296, 0.5290, 0.5854, 0.5704,
        0.5181, 0.5315, 0.4877, 0.5290, 0.6304, 0.5253, 0.5955],
       device='cuda:0') torch.Size([16])
percent tensor([0.6938, 0.7398, 0.6247, 0.6040, 0.6297, 0.6424, 0.7092, 0.6436, 0.7031,
        0.7275, 0.7437, 0.6578, 0.7346, 0.7195, 0.6928, 0.7059],
       device='cuda:0') torch.Size([16])
percent tensor([0.5706, 0.5399, 0.7135, 0.7195, 0.7218, 0.7229, 0.6015, 0.5852, 0.6748,
        0.5593, 0.6356, 0.6706, 0.5815, 0.6228, 0.5847, 0.5578],
       device='cuda:0') torch.Size([16])
percent tensor([0.7138, 0.6958, 0.7119, 0.7063, 0.7614, 0.7652, 0.7282, 0.6765, 0.6971,
        0.6695, 0.6605, 0.6648, 0.6943, 0.7021, 0.6569, 0.7491],
       device='cuda:0') torch.Size([16])
percent tensor([0.7157, 0.7754, 0.6592, 0.6420, 0.6467, 0.8172, 0.6671, 0.4664, 0.7289,
        0.6738, 0.7323, 0.7149, 0.7439, 0.7427, 0.5512, 0.6676],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9996, 0.9998, 0.9998, 0.9999, 0.9998, 0.9997, 0.9997,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(185.5844, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.5617, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(835.2636, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1511.8763, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(481.8973, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2275.4111, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4249.9937, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1354.3120, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6244.4395, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11568.6631, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3808.0984, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16051.0488, device='cuda:0')
Epoch: 191 | Batch_idx: 0 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 191 | Batch_idx: 10 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 191 | Batch_idx: 20 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 191 | Batch_idx: 30 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (3836/3968)
Epoch: 191 | Batch_idx: 40 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (5073/5248)
Epoch: 191 | Batch_idx: 50 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (6306/6528)
Epoch: 191 | Batch_idx: 60 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (7529/7808)
Epoch: 191 | Batch_idx: 70 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (8769/9088)
Epoch: 191 | Batch_idx: 80 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (10013/10368)
Epoch: 191 | Batch_idx: 90 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (11252/11648)
Epoch: 191 | Batch_idx: 100 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (12493/12928)
Epoch: 191 | Batch_idx: 110 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (13725/14208)
Epoch: 191 | Batch_idx: 120 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (14961/15488)
Epoch: 191 | Batch_idx: 130 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (16185/16768)
Epoch: 191 | Batch_idx: 140 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (17418/18048)
Epoch: 191 | Batch_idx: 150 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (18663/19328)
Epoch: 191 | Batch_idx: 160 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (19905/20608)
Epoch: 191 | Batch_idx: 170 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (21151/21888)
Epoch: 191 | Batch_idx: 180 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (22388/23168)
Epoch: 191 | Batch_idx: 190 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (23629/24448)
Epoch: 191 | Batch_idx: 200 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (24856/25728)
Epoch: 191 | Batch_idx: 210 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (26094/27008)
Epoch: 191 | Batch_idx: 220 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (27330/28288)
Epoch: 191 | Batch_idx: 230 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (28568/29568)
Epoch: 191 | Batch_idx: 240 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (29804/30848)
Epoch: 191 | Batch_idx: 250 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (31029/32128)
Epoch: 191 | Batch_idx: 260 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (32275/33408)
Epoch: 191 | Batch_idx: 270 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (33507/34688)
Epoch: 191 | Batch_idx: 280 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (34741/35968)
Epoch: 191 | Batch_idx: 290 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (35970/37248)
Epoch: 191 | Batch_idx: 300 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (37217/38528)
Epoch: 191 | Batch_idx: 310 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (38459/39808)
Epoch: 191 | Batch_idx: 320 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (39694/41088)
Epoch: 191 | Batch_idx: 330 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (40933/42368)
Epoch: 191 | Batch_idx: 340 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (42156/43648)
Epoch: 191 | Batch_idx: 350 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (43393/44928)
Epoch: 191 | Batch_idx: 360 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (44632/46208)
Epoch: 191 | Batch_idx: 370 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (45874/47488)
Epoch: 191 | Batch_idx: 380 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (47110/48768)
Epoch: 191 | Batch_idx: 390 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (48293/50000)
# TEST : Loss: (0.4187) | Acc: (88.00%) (8818/10000)
percent tensor([0.5423, 0.5478, 0.5312, 0.5243, 0.5374, 0.5231, 0.5491, 0.5349, 0.5520,
        0.5471, 0.5510, 0.5429, 0.5466, 0.5507, 0.5342, 0.5394],
       device='cuda:0') torch.Size([16])
percent tensor([0.4809, 0.4864, 0.4611, 0.4650, 0.4669, 0.4826, 0.4803, 0.4736, 0.4761,
        0.4769, 0.4850, 0.4617, 0.4862, 0.4856, 0.4776, 0.4861],
       device='cuda:0') torch.Size([16])
percent tensor([0.5831, 0.5048, 0.5326, 0.5970, 0.5618, 0.6282, 0.5286, 0.5869, 0.5708,
        0.5161, 0.5293, 0.4870, 0.5264, 0.6316, 0.5244, 0.5934],
       device='cuda:0') torch.Size([16])
percent tensor([0.6918, 0.7377, 0.6220, 0.6009, 0.6273, 0.6401, 0.7076, 0.6411, 0.7010,
        0.7245, 0.7412, 0.6553, 0.7331, 0.7170, 0.6908, 0.7036],
       device='cuda:0') torch.Size([16])
percent tensor([0.5864, 0.5545, 0.7270, 0.7361, 0.7350, 0.7381, 0.6184, 0.6002, 0.6908,
        0.5737, 0.6522, 0.6846, 0.5977, 0.6385, 0.6026, 0.5742],
       device='cuda:0') torch.Size([16])
percent tensor([0.7147, 0.6973, 0.7139, 0.7088, 0.7639, 0.7661, 0.7297, 0.6777, 0.6997,
        0.6726, 0.6641, 0.6676, 0.6942, 0.7048, 0.6595, 0.7487],
       device='cuda:0') torch.Size([16])
percent tensor([0.7139, 0.7758, 0.6570, 0.6416, 0.6469, 0.8129, 0.6678, 0.4684, 0.7349,
        0.6785, 0.7323, 0.7140, 0.7425, 0.7468, 0.5552, 0.6626],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9995, 0.9998, 0.9998, 0.9999, 0.9998, 0.9997, 0.9997,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 192 | Batch_idx: 0 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 192 | Batch_idx: 10 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 192 | Batch_idx: 20 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 192 | Batch_idx: 30 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (3844/3968)
Epoch: 192 | Batch_idx: 40 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (5075/5248)
Epoch: 192 | Batch_idx: 50 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (6317/6528)
Epoch: 192 | Batch_idx: 60 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (7546/7808)
Epoch: 192 | Batch_idx: 70 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (8772/9088)
Epoch: 192 | Batch_idx: 80 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (10008/10368)
Epoch: 192 | Batch_idx: 90 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (11246/11648)
Epoch: 192 | Batch_idx: 100 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (12485/12928)
Epoch: 192 | Batch_idx: 110 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (13724/14208)
Epoch: 192 | Batch_idx: 120 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (14960/15488)
Epoch: 192 | Batch_idx: 130 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (16200/16768)
Epoch: 192 | Batch_idx: 140 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (17446/18048)
Epoch: 192 | Batch_idx: 150 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (18689/19328)
Epoch: 192 | Batch_idx: 160 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (19930/20608)
Epoch: 192 | Batch_idx: 170 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (21166/21888)
Epoch: 192 | Batch_idx: 180 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (22408/23168)
Epoch: 192 | Batch_idx: 190 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (23644/24448)
Epoch: 192 | Batch_idx: 200 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (24888/25728)
Epoch: 192 | Batch_idx: 210 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (26124/27008)
Epoch: 192 | Batch_idx: 220 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (27364/28288)
Epoch: 192 | Batch_idx: 230 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (28603/29568)
Epoch: 192 | Batch_idx: 240 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (29845/30848)
Epoch: 192 | Batch_idx: 250 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (31089/32128)
Epoch: 192 | Batch_idx: 260 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (32327/33408)
Epoch: 192 | Batch_idx: 270 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (33570/34688)
Epoch: 192 | Batch_idx: 280 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (34793/35968)
Epoch: 192 | Batch_idx: 290 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (36038/37248)
Epoch: 192 | Batch_idx: 300 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (37284/38528)
Epoch: 192 | Batch_idx: 310 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (38525/39808)
Epoch: 192 | Batch_idx: 320 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (39760/41088)
Epoch: 192 | Batch_idx: 330 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (40991/42368)
Epoch: 192 | Batch_idx: 340 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (42230/43648)
Epoch: 192 | Batch_idx: 350 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (43468/44928)
Epoch: 192 | Batch_idx: 360 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (44705/46208)
Epoch: 192 | Batch_idx: 370 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (45941/47488)
Epoch: 192 | Batch_idx: 380 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (47177/48768)
Epoch: 192 | Batch_idx: 390 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (48363/50000)
# TEST : Loss: (0.4210) | Acc: (88.00%) (8819/10000)
percent tensor([0.5407, 0.5477, 0.5299, 0.5241, 0.5353, 0.5206, 0.5481, 0.5347, 0.5508,
        0.5465, 0.5496, 0.5411, 0.5458, 0.5512, 0.5333, 0.5387],
       device='cuda:0') torch.Size([16])
percent tensor([0.4817, 0.4862, 0.4660, 0.4666, 0.4715, 0.4847, 0.4820, 0.4747, 0.4765,
        0.4774, 0.4844, 0.4653, 0.4861, 0.4841, 0.4772, 0.4858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5801, 0.4992, 0.5548, 0.6095, 0.5793, 0.6421, 0.5320, 0.5865, 0.5705,
        0.5132, 0.5194, 0.4922, 0.5157, 0.6262, 0.5260, 0.5943],
       device='cuda:0') torch.Size([16])
percent tensor([0.6936, 0.7360, 0.6121, 0.6036, 0.6203, 0.6426, 0.7047, 0.6418, 0.6959,
        0.7244, 0.7395, 0.6507, 0.7340, 0.7212, 0.6847, 0.7071],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.5694, 0.7304, 0.7406, 0.7547, 0.7422, 0.6454, 0.6216, 0.6892,
        0.5747, 0.6540, 0.6944, 0.5881, 0.6391, 0.6347, 0.5816],
       device='cuda:0') torch.Size([16])
percent tensor([0.7098, 0.6971, 0.7225, 0.7126, 0.7694, 0.7588, 0.7301, 0.6852, 0.6885,
        0.6843, 0.6564, 0.6663, 0.6986, 0.6930, 0.6570, 0.7380],
       device='cuda:0') torch.Size([16])
percent tensor([0.6950, 0.7545, 0.6679, 0.6268, 0.6833, 0.8014, 0.6635, 0.4929, 0.7525,
        0.7092, 0.7047, 0.6996, 0.7457, 0.6967, 0.5463, 0.6114],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9997, 0.9998, 0.9998, 0.9998, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 193 | Batch_idx: 0 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 193 | Batch_idx: 10 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 193 | Batch_idx: 20 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (2625/2688)
Epoch: 193 | Batch_idx: 30 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (3866/3968)
Epoch: 193 | Batch_idx: 40 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (5100/5248)
Epoch: 193 | Batch_idx: 50 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (6341/6528)
Epoch: 193 | Batch_idx: 60 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (7580/7808)
Epoch: 193 | Batch_idx: 70 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (8809/9088)
Epoch: 193 | Batch_idx: 80 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (96.00%) (10054/10368)
Epoch: 193 | Batch_idx: 90 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (11290/11648)
Epoch: 193 | Batch_idx: 100 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (12530/12928)
Epoch: 193 | Batch_idx: 110 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (13763/14208)
Epoch: 193 | Batch_idx: 120 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (14998/15488)
Epoch: 193 | Batch_idx: 130 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (16231/16768)
Epoch: 193 | Batch_idx: 140 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (17468/18048)
Epoch: 193 | Batch_idx: 150 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (18718/19328)
Epoch: 193 | Batch_idx: 160 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (19959/20608)
Epoch: 193 | Batch_idx: 170 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (21214/21888)
Epoch: 193 | Batch_idx: 180 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (22458/23168)
Epoch: 193 | Batch_idx: 190 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (23698/24448)
Epoch: 193 | Batch_idx: 200 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (24933/25728)
Epoch: 193 | Batch_idx: 210 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (26177/27008)
Epoch: 193 | Batch_idx: 220 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (27418/28288)
Epoch: 193 | Batch_idx: 230 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (28671/29568)
Epoch: 193 | Batch_idx: 240 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (29905/30848)
Epoch: 193 | Batch_idx: 250 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (31142/32128)
Epoch: 193 | Batch_idx: 260 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (32383/33408)
Epoch: 193 | Batch_idx: 270 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (33634/34688)
Epoch: 193 | Batch_idx: 280 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (34881/35968)
Epoch: 193 | Batch_idx: 290 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (36124/37248)
Epoch: 193 | Batch_idx: 300 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (37355/38528)
Epoch: 193 | Batch_idx: 310 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (38600/39808)
Epoch: 193 | Batch_idx: 320 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (39826/41088)
Epoch: 193 | Batch_idx: 330 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (41063/42368)
Epoch: 193 | Batch_idx: 340 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (42307/43648)
Epoch: 193 | Batch_idx: 350 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (43549/44928)
Epoch: 193 | Batch_idx: 360 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (44790/46208)
Epoch: 193 | Batch_idx: 370 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (46022/47488)
Epoch: 193 | Batch_idx: 380 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (47268/48768)
Epoch: 193 | Batch_idx: 390 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (48459/50000)
# TEST : Loss: (0.4856) | Acc: (86.00%) (8678/10000)
percent tensor([0.5410, 0.5466, 0.5302, 0.5231, 0.5364, 0.5218, 0.5477, 0.5339, 0.5506,
        0.5457, 0.5496, 0.5415, 0.5457, 0.5499, 0.5330, 0.5385],
       device='cuda:0') torch.Size([16])
percent tensor([0.4817, 0.4857, 0.4652, 0.4662, 0.4704, 0.4834, 0.4812, 0.4744, 0.4766,
        0.4779, 0.4843, 0.4647, 0.4868, 0.4830, 0.4764, 0.4859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5822, 0.5026, 0.5555, 0.6188, 0.5767, 0.6498, 0.5289, 0.5919, 0.5753,
        0.5142, 0.5223, 0.4975, 0.5182, 0.6262, 0.5317, 0.5996],
       device='cuda:0') torch.Size([16])
percent tensor([0.6958, 0.7415, 0.6115, 0.6003, 0.6192, 0.6400, 0.7061, 0.6406, 0.6944,
        0.7304, 0.7428, 0.6539, 0.7391, 0.7199, 0.6896, 0.7083],
       device='cuda:0') torch.Size([16])
percent tensor([0.5795, 0.5396, 0.7326, 0.7451, 0.7529, 0.7242, 0.6275, 0.6161, 0.6862,
        0.5642, 0.6363, 0.6883, 0.5771, 0.6062, 0.5977, 0.5655],
       device='cuda:0') torch.Size([16])
percent tensor([0.7080, 0.7063, 0.7080, 0.7038, 0.7603, 0.7549, 0.7195, 0.6785, 0.7001,
        0.6769, 0.6569, 0.6602, 0.6916, 0.7090, 0.6580, 0.7380],
       device='cuda:0') torch.Size([16])
percent tensor([0.6996, 0.7843, 0.6632, 0.6131, 0.6791, 0.7793, 0.6475, 0.5059, 0.7545,
        0.7036, 0.7206, 0.7121, 0.7509, 0.7409, 0.5399, 0.6456],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9999, 0.9998, 0.9997, 0.9996, 0.9997,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 194 | Batch_idx: 0 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 194 | Batch_idx: 10 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 194 | Batch_idx: 20 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (2621/2688)
Epoch: 194 | Batch_idx: 30 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (3869/3968)
Epoch: 194 | Batch_idx: 40 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (5108/5248)
Epoch: 194 | Batch_idx: 50 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (6358/6528)
Epoch: 194 | Batch_idx: 60 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (7595/7808)
Epoch: 194 | Batch_idx: 70 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (8828/9088)
Epoch: 194 | Batch_idx: 80 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (10070/10368)
Epoch: 194 | Batch_idx: 90 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (11308/11648)
Epoch: 194 | Batch_idx: 100 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (12559/12928)
Epoch: 194 | Batch_idx: 110 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (13795/14208)
Epoch: 194 | Batch_idx: 120 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (15030/15488)
Epoch: 194 | Batch_idx: 130 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (97.00%) (16271/16768)
Epoch: 194 | Batch_idx: 140 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (17519/18048)
Epoch: 194 | Batch_idx: 150 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (18759/19328)
Epoch: 194 | Batch_idx: 160 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (19998/20608)
Epoch: 194 | Batch_idx: 170 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (21235/21888)
Epoch: 194 | Batch_idx: 180 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (22485/23168)
Epoch: 194 | Batch_idx: 190 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (23724/24448)
Epoch: 194 | Batch_idx: 200 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (24977/25728)
Epoch: 194 | Batch_idx: 210 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (26220/27008)
Epoch: 194 | Batch_idx: 220 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (27466/28288)
Epoch: 194 | Batch_idx: 230 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (28715/29568)
Epoch: 194 | Batch_idx: 240 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (97.00%) (29960/30848)
Epoch: 194 | Batch_idx: 250 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (31216/32128)
Epoch: 194 | Batch_idx: 260 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (32458/33408)
Epoch: 194 | Batch_idx: 270 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (33706/34688)
Epoch: 194 | Batch_idx: 280 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (34951/35968)
Epoch: 194 | Batch_idx: 290 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (36201/37248)
Epoch: 194 | Batch_idx: 300 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (37434/38528)
Epoch: 194 | Batch_idx: 310 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (38678/39808)
Epoch: 194 | Batch_idx: 320 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (39929/41088)
Epoch: 194 | Batch_idx: 330 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (41175/42368)
Epoch: 194 | Batch_idx: 340 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (42411/43648)
Epoch: 194 | Batch_idx: 350 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (43649/44928)
Epoch: 194 | Batch_idx: 360 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (44895/46208)
Epoch: 194 | Batch_idx: 370 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (46134/47488)
Epoch: 194 | Batch_idx: 380 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (47370/48768)
Epoch: 194 | Batch_idx: 390 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (48559/50000)
# TEST : Loss: (0.4717) | Acc: (87.00%) (8732/10000)
percent tensor([0.5412, 0.5467, 0.5312, 0.5250, 0.5374, 0.5219, 0.5479, 0.5349, 0.5507,
        0.5465, 0.5494, 0.5426, 0.5458, 0.5498, 0.5334, 0.5392],
       device='cuda:0') torch.Size([16])
percent tensor([0.4821, 0.4856, 0.4688, 0.4677, 0.4727, 0.4830, 0.4815, 0.4768, 0.4769,
        0.4790, 0.4843, 0.4670, 0.4872, 0.4823, 0.4766, 0.4866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.5019, 0.5479, 0.6126, 0.5731, 0.6339, 0.5239, 0.5963, 0.5769,
        0.5137, 0.5276, 0.4892, 0.5183, 0.6307, 0.5226, 0.5952],
       device='cuda:0') torch.Size([16])
percent tensor([0.6964, 0.7333, 0.6184, 0.5972, 0.6287, 0.6392, 0.7057, 0.6381, 0.6921,
        0.7268, 0.7367, 0.6586, 0.7356, 0.7071, 0.6859, 0.7039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5800, 0.5682, 0.7294, 0.7379, 0.7437, 0.7279, 0.6549, 0.6181, 0.6968,
        0.5742, 0.6802, 0.6906, 0.5964, 0.6529, 0.6153, 0.5805],
       device='cuda:0') torch.Size([16])
percent tensor([0.7104, 0.7130, 0.7194, 0.7011, 0.7708, 0.7606, 0.7251, 0.6878, 0.6917,
        0.6841, 0.6613, 0.6565, 0.6881, 0.6939, 0.6569, 0.7394],
       device='cuda:0') torch.Size([16])
percent tensor([0.6910, 0.7687, 0.6720, 0.5925, 0.6877, 0.8018, 0.6644, 0.4957, 0.7519,
        0.7261, 0.7159, 0.6588, 0.7438, 0.7178, 0.5545, 0.6436],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9998, 0.9999, 0.9999, 0.9997, 0.9995, 0.9997,
        0.9999, 1.0000, 0.9997, 0.9998, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 195 | Batch_idx: 0 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 195 | Batch_idx: 10 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 195 | Batch_idx: 20 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 195 | Batch_idx: 30 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (3866/3968)
Epoch: 195 | Batch_idx: 40 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (5117/5248)
Epoch: 195 | Batch_idx: 50 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (6353/6528)
Epoch: 195 | Batch_idx: 60 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (7600/7808)
Epoch: 195 | Batch_idx: 70 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (8837/9088)
Epoch: 195 | Batch_idx: 80 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (10081/10368)
Epoch: 195 | Batch_idx: 90 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (11325/11648)
Epoch: 195 | Batch_idx: 100 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (12559/12928)
Epoch: 195 | Batch_idx: 110 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (13802/14208)
Epoch: 195 | Batch_idx: 120 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (15042/15488)
Epoch: 195 | Batch_idx: 130 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (16280/16768)
Epoch: 195 | Batch_idx: 140 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (17526/18048)
Epoch: 195 | Batch_idx: 150 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (18769/19328)
Epoch: 195 | Batch_idx: 160 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (20018/20608)
Epoch: 195 | Batch_idx: 170 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (21260/21888)
Epoch: 195 | Batch_idx: 180 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (22500/23168)
Epoch: 195 | Batch_idx: 190 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (23749/24448)
Epoch: 195 | Batch_idx: 200 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (24997/25728)
Epoch: 195 | Batch_idx: 210 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (26235/27008)
Epoch: 195 | Batch_idx: 220 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (27481/28288)
Epoch: 195 | Batch_idx: 230 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (28735/29568)
Epoch: 195 | Batch_idx: 240 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (29982/30848)
Epoch: 195 | Batch_idx: 250 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (31231/32128)
Epoch: 195 | Batch_idx: 260 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (32482/33408)
Epoch: 195 | Batch_idx: 270 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (33720/34688)
Epoch: 195 | Batch_idx: 280 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (34964/35968)
Epoch: 195 | Batch_idx: 290 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (36206/37248)
Epoch: 195 | Batch_idx: 300 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (37454/38528)
Epoch: 195 | Batch_idx: 310 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (38694/39808)
Epoch: 195 | Batch_idx: 320 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (39932/41088)
Epoch: 195 | Batch_idx: 330 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (41169/42368)
Epoch: 195 | Batch_idx: 340 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (42413/43648)
Epoch: 195 | Batch_idx: 350 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (43651/44928)
Epoch: 195 | Batch_idx: 360 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (44888/46208)
Epoch: 195 | Batch_idx: 370 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (46137/47488)
Epoch: 195 | Batch_idx: 380 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (47381/48768)
Epoch: 195 | Batch_idx: 390 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (48576/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_195.pth.tar'
# TEST : Loss: (0.4403) | Acc: (87.00%) (8774/10000)
percent tensor([0.5408, 0.5471, 0.5300, 0.5238, 0.5366, 0.5220, 0.5481, 0.5340, 0.5499,
        0.5462, 0.5491, 0.5419, 0.5455, 0.5498, 0.5335, 0.5384],
       device='cuda:0') torch.Size([16])
percent tensor([0.4817, 0.4858, 0.4681, 0.4670, 0.4723, 0.4821, 0.4820, 0.4759, 0.4776,
        0.4793, 0.4844, 0.4672, 0.4875, 0.4833, 0.4763, 0.4859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5788, 0.4984, 0.5541, 0.6077, 0.5754, 0.6310, 0.5254, 0.5860, 0.5777,
        0.5135, 0.5229, 0.4931, 0.5195, 0.6246, 0.5203, 0.5900],
       device='cuda:0') torch.Size([16])
percent tensor([0.6942, 0.7393, 0.6138, 0.5981, 0.6221, 0.6386, 0.7065, 0.6434, 0.6988,
        0.7304, 0.7401, 0.6536, 0.7387, 0.7177, 0.6856, 0.7077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5805, 0.5499, 0.7263, 0.7407, 0.7534, 0.7318, 0.6330, 0.6120, 0.6810,
        0.5666, 0.6516, 0.6908, 0.5802, 0.6442, 0.6141, 0.5733],
       device='cuda:0') torch.Size([16])
percent tensor([0.7001, 0.7130, 0.7183, 0.6965, 0.7672, 0.7464, 0.7217, 0.6771, 0.6924,
        0.6832, 0.6598, 0.6649, 0.6995, 0.6994, 0.6575, 0.7342],
       device='cuda:0') torch.Size([16])
percent tensor([0.6999, 0.7881, 0.7017, 0.6520, 0.7149, 0.7925, 0.6880, 0.5014, 0.7738,
        0.7410, 0.7318, 0.7264, 0.7713, 0.7238, 0.5886, 0.6482],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9997, 0.9997, 0.9998, 0.9999, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9997, 0.9999, 0.9996, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 196 | Batch_idx: 0 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 196 | Batch_idx: 10 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 196 | Batch_idx: 20 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (2594/2688)
Epoch: 196 | Batch_idx: 30 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (3829/3968)
Epoch: 196 | Batch_idx: 40 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (5057/5248)
Epoch: 196 | Batch_idx: 50 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (6287/6528)
Epoch: 196 | Batch_idx: 60 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (7520/7808)
Epoch: 196 | Batch_idx: 70 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (8761/9088)
Epoch: 196 | Batch_idx: 80 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (9997/10368)
Epoch: 196 | Batch_idx: 90 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (11237/11648)
Epoch: 196 | Batch_idx: 100 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (12476/12928)
Epoch: 196 | Batch_idx: 110 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (13721/14208)
Epoch: 196 | Batch_idx: 120 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (14965/15488)
Epoch: 196 | Batch_idx: 130 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (16205/16768)
Epoch: 196 | Batch_idx: 140 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (17447/18048)
Epoch: 196 | Batch_idx: 150 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (18679/19328)
Epoch: 196 | Batch_idx: 160 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (19908/20608)
Epoch: 196 | Batch_idx: 170 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (21141/21888)
Epoch: 196 | Batch_idx: 180 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (22384/23168)
Epoch: 196 | Batch_idx: 190 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (23621/24448)
Epoch: 196 | Batch_idx: 200 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (24861/25728)
Epoch: 196 | Batch_idx: 210 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (26106/27008)
Epoch: 196 | Batch_idx: 220 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (27340/28288)
Epoch: 196 | Batch_idx: 230 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (28579/29568)
Epoch: 196 | Batch_idx: 240 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (29805/30848)
Epoch: 196 | Batch_idx: 250 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (31050/32128)
Epoch: 196 | Batch_idx: 260 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (32290/33408)
Epoch: 196 | Batch_idx: 270 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (33541/34688)
Epoch: 196 | Batch_idx: 280 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (34777/35968)
Epoch: 196 | Batch_idx: 290 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (36022/37248)
Epoch: 196 | Batch_idx: 300 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (37266/38528)
Epoch: 196 | Batch_idx: 310 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (38504/39808)
Epoch: 196 | Batch_idx: 320 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (39750/41088)
Epoch: 196 | Batch_idx: 330 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (40994/42368)
Epoch: 196 | Batch_idx: 340 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (42231/43648)
Epoch: 196 | Batch_idx: 350 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (43460/44928)
Epoch: 196 | Batch_idx: 360 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (44696/46208)
Epoch: 196 | Batch_idx: 370 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (45936/47488)
Epoch: 196 | Batch_idx: 380 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (47171/48768)
Epoch: 196 | Batch_idx: 390 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (48358/50000)
# TEST : Loss: (0.4264) | Acc: (88.00%) (8835/10000)
percent tensor([0.5477, 0.5571, 0.5357, 0.5304, 0.5435, 0.5290, 0.5574, 0.5417, 0.5576,
        0.5548, 0.5579, 0.5490, 0.5535, 0.5593, 0.5427, 0.5462],
       device='cuda:0') torch.Size([16])
percent tensor([0.4798, 0.4859, 0.4680, 0.4646, 0.4718, 0.4787, 0.4813, 0.4752, 0.4762,
        0.4791, 0.4835, 0.4673, 0.4871, 0.4809, 0.4743, 0.4842],
       device='cuda:0') torch.Size([16])
percent tensor([0.6014, 0.5310, 0.5588, 0.6204, 0.5845, 0.6516, 0.5468, 0.5983, 0.5964,
        0.5405, 0.5547, 0.5072, 0.5515, 0.6480, 0.5449, 0.6156],
       device='cuda:0') torch.Size([16])
percent tensor([0.6824, 0.7306, 0.6035, 0.5836, 0.6105, 0.6236, 0.6943, 0.6286, 0.6820,
        0.7192, 0.7274, 0.6416, 0.7269, 0.7011, 0.6726, 0.6927],
       device='cuda:0') torch.Size([16])
percent tensor([0.5871, 0.5657, 0.7303, 0.7399, 0.7555, 0.7339, 0.6456, 0.6281, 0.6995,
        0.5820, 0.6647, 0.7014, 0.5945, 0.6493, 0.6202, 0.5862],
       device='cuda:0') torch.Size([16])
percent tensor([0.6984, 0.7099, 0.7141, 0.6975, 0.7620, 0.7428, 0.7189, 0.6750, 0.6930,
        0.6827, 0.6611, 0.6616, 0.6995, 0.7015, 0.6523, 0.7307],
       device='cuda:0') torch.Size([16])
percent tensor([0.6846, 0.7638, 0.7184, 0.6621, 0.7278, 0.7793, 0.6756, 0.5009, 0.7779,
        0.7302, 0.7419, 0.7460, 0.7640, 0.7215, 0.5829, 0.6102],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9994, 0.9998,
        0.9999, 0.9999, 0.9997, 0.9999, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 197 | Batch_idx: 0 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 197 | Batch_idx: 10 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 197 | Batch_idx: 20 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 197 | Batch_idx: 30 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (3820/3968)
Epoch: 197 | Batch_idx: 40 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (5054/5248)
Epoch: 197 | Batch_idx: 50 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (6301/6528)
Epoch: 197 | Batch_idx: 60 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (7548/7808)
Epoch: 197 | Batch_idx: 70 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (8788/9088)
Epoch: 197 | Batch_idx: 80 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (10025/10368)
Epoch: 197 | Batch_idx: 90 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (11263/11648)
Epoch: 197 | Batch_idx: 100 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (12507/12928)
Epoch: 197 | Batch_idx: 110 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (13751/14208)
Epoch: 197 | Batch_idx: 120 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (14994/15488)
Epoch: 197 | Batch_idx: 130 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (16241/16768)
Epoch: 197 | Batch_idx: 140 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (17488/18048)
Epoch: 197 | Batch_idx: 150 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (18730/19328)
Epoch: 197 | Batch_idx: 160 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (19988/20608)
Epoch: 197 | Batch_idx: 170 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (21231/21888)
Epoch: 197 | Batch_idx: 180 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (22464/23168)
Epoch: 197 | Batch_idx: 190 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (23708/24448)
Epoch: 197 | Batch_idx: 200 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (24954/25728)
Epoch: 197 | Batch_idx: 210 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (26197/27008)
Epoch: 197 | Batch_idx: 220 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (27448/28288)
Epoch: 197 | Batch_idx: 230 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (28695/29568)
Epoch: 197 | Batch_idx: 240 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (29940/30848)
Epoch: 197 | Batch_idx: 250 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (31183/32128)
Epoch: 197 | Batch_idx: 260 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (32432/33408)
Epoch: 197 | Batch_idx: 270 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (33672/34688)
Epoch: 197 | Batch_idx: 280 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (34913/35968)
Epoch: 197 | Batch_idx: 290 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (36159/37248)
Epoch: 197 | Batch_idx: 300 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (37402/38528)
Epoch: 197 | Batch_idx: 310 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (38647/39808)
Epoch: 197 | Batch_idx: 320 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (39897/41088)
Epoch: 197 | Batch_idx: 330 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (41153/42368)
Epoch: 197 | Batch_idx: 340 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (42397/43648)
Epoch: 197 | Batch_idx: 350 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (43641/44928)
Epoch: 197 | Batch_idx: 360 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (44894/46208)
Epoch: 197 | Batch_idx: 370 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (46145/47488)
Epoch: 197 | Batch_idx: 380 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (47388/48768)
Epoch: 197 | Batch_idx: 390 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (48590/50000)
# TEST : Loss: (0.4101) | Acc: (88.00%) (8865/10000)
percent tensor([0.5429, 0.5518, 0.5309, 0.5253, 0.5386, 0.5239, 0.5523, 0.5369, 0.5525,
        0.5497, 0.5528, 0.5440, 0.5487, 0.5539, 0.5376, 0.5413],
       device='cuda:0') torch.Size([16])
percent tensor([0.4800, 0.4871, 0.4674, 0.4640, 0.4713, 0.4782, 0.4822, 0.4752, 0.4767,
        0.4797, 0.4845, 0.4676, 0.4880, 0.4818, 0.4748, 0.4845],
       device='cuda:0') torch.Size([16])
percent tensor([0.6027, 0.5360, 0.5525, 0.6157, 0.5764, 0.6547, 0.5452, 0.5904, 0.5958,
        0.5434, 0.5617, 0.5037, 0.5559, 0.6513, 0.5459, 0.6190],
       device='cuda:0') torch.Size([16])
percent tensor([0.6845, 0.7322, 0.6035, 0.5860, 0.6120, 0.6254, 0.6962, 0.6306, 0.6829,
        0.7202, 0.7294, 0.6415, 0.7282, 0.7037, 0.6748, 0.6947],
       device='cuda:0') torch.Size([16])
percent tensor([0.5930, 0.5712, 0.7463, 0.7536, 0.7686, 0.7417, 0.6543, 0.6449, 0.7089,
        0.5890, 0.6686, 0.7143, 0.6008, 0.6523, 0.6249, 0.5957],
       device='cuda:0') torch.Size([16])
percent tensor([0.6947, 0.7054, 0.7088, 0.6942, 0.7588, 0.7423, 0.7142, 0.6696, 0.6898,
        0.6752, 0.6570, 0.6557, 0.6978, 0.6979, 0.6489, 0.7278],
       device='cuda:0') torch.Size([16])
percent tensor([0.6774, 0.7583, 0.7243, 0.6683, 0.7318, 0.7820, 0.6695, 0.4983, 0.7781,
        0.7156, 0.7396, 0.7514, 0.7620, 0.7127, 0.5772, 0.5992],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9994, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 198 | Batch_idx: 0 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 198 | Batch_idx: 10 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 198 | Batch_idx: 20 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (2613/2688)
Epoch: 198 | Batch_idx: 30 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (3862/3968)
Epoch: 198 | Batch_idx: 40 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (5107/5248)
Epoch: 198 | Batch_idx: 50 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (6358/6528)
Epoch: 198 | Batch_idx: 60 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (7615/7808)
Epoch: 198 | Batch_idx: 70 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (8858/9088)
Epoch: 198 | Batch_idx: 80 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (10105/10368)
Epoch: 198 | Batch_idx: 90 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (11352/11648)
Epoch: 198 | Batch_idx: 100 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (12601/12928)
Epoch: 198 | Batch_idx: 110 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (13853/14208)
Epoch: 198 | Batch_idx: 120 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (15105/15488)
Epoch: 198 | Batch_idx: 130 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (16347/16768)
Epoch: 198 | Batch_idx: 140 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (17594/18048)
Epoch: 198 | Batch_idx: 150 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (18839/19328)
Epoch: 198 | Batch_idx: 160 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (20085/20608)
Epoch: 198 | Batch_idx: 170 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (21320/21888)
Epoch: 198 | Batch_idx: 180 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (22563/23168)
Epoch: 198 | Batch_idx: 190 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (23807/24448)
Epoch: 198 | Batch_idx: 200 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (25051/25728)
Epoch: 198 | Batch_idx: 210 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (26288/27008)
Epoch: 198 | Batch_idx: 220 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (27536/28288)
Epoch: 198 | Batch_idx: 230 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (28774/29568)
Epoch: 198 | Batch_idx: 240 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (30021/30848)
Epoch: 198 | Batch_idx: 250 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (31263/32128)
Epoch: 198 | Batch_idx: 260 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (32505/33408)
Epoch: 198 | Batch_idx: 270 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (33748/34688)
Epoch: 198 | Batch_idx: 280 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (34997/35968)
Epoch: 198 | Batch_idx: 290 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (36248/37248)
Epoch: 198 | Batch_idx: 300 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (37498/38528)
Epoch: 198 | Batch_idx: 310 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (38750/39808)
Epoch: 198 | Batch_idx: 320 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (39994/41088)
Epoch: 198 | Batch_idx: 330 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (41253/42368)
Epoch: 198 | Batch_idx: 340 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (42499/43648)
Epoch: 198 | Batch_idx: 350 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (43746/44928)
Epoch: 198 | Batch_idx: 360 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (44991/46208)
Epoch: 198 | Batch_idx: 370 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (46230/47488)
Epoch: 198 | Batch_idx: 380 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (47477/48768)
Epoch: 198 | Batch_idx: 390 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (48679/50000)
# TEST : Loss: (0.4040) | Acc: (88.00%) (8885/10000)
percent tensor([0.5417, 0.5504, 0.5304, 0.5245, 0.5379, 0.5229, 0.5510, 0.5360, 0.5511,
        0.5484, 0.5513, 0.5430, 0.5474, 0.5522, 0.5365, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.4803, 0.4881, 0.4676, 0.4643, 0.4714, 0.4780, 0.4829, 0.4757, 0.4772,
        0.4804, 0.4851, 0.4681, 0.4887, 0.4826, 0.4751, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.6019, 0.5367, 0.5517, 0.6159, 0.5775, 0.6559, 0.5457, 0.5901, 0.5948,
        0.5416, 0.5608, 0.5029, 0.5546, 0.6519, 0.5473, 0.6192],
       device='cuda:0') torch.Size([16])
percent tensor([0.6868, 0.7358, 0.6047, 0.5886, 0.6147, 0.6270, 0.7001, 0.6340, 0.6853,
        0.7234, 0.7326, 0.6445, 0.7302, 0.7082, 0.6787, 0.6974],
       device='cuda:0') torch.Size([16])
percent tensor([0.5906, 0.5668, 0.7507, 0.7572, 0.7698, 0.7401, 0.6495, 0.6493, 0.7069,
        0.5871, 0.6644, 0.7137, 0.5966, 0.6462, 0.6190, 0.5953],
       device='cuda:0') torch.Size([16])
percent tensor([0.6953, 0.7068, 0.7076, 0.6945, 0.7586, 0.7436, 0.7160, 0.6679, 0.6906,
        0.6748, 0.6578, 0.6548, 0.7004, 0.6987, 0.6495, 0.7284],
       device='cuda:0') torch.Size([16])
percent tensor([0.6812, 0.7607, 0.7268, 0.6733, 0.7346, 0.7856, 0.6727, 0.4985, 0.7839,
        0.7165, 0.7476, 0.7523, 0.7710, 0.7143, 0.5791, 0.5967],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9994, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 199 | Batch_idx: 0 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 199 | Batch_idx: 10 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 199 | Batch_idx: 20 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 199 | Batch_idx: 30 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (98.00%) (3893/3968)
Epoch: 199 | Batch_idx: 40 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (5139/5248)
Epoch: 199 | Batch_idx: 50 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (6393/6528)
Epoch: 199 | Batch_idx: 60 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (7640/7808)
Epoch: 199 | Batch_idx: 70 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (8892/9088)
Epoch: 199 | Batch_idx: 80 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (10135/10368)
Epoch: 199 | Batch_idx: 90 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (11381/11648)
Epoch: 199 | Batch_idx: 100 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (12634/12928)
Epoch: 199 | Batch_idx: 110 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (13879/14208)
Epoch: 199 | Batch_idx: 120 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (15125/15488)
Epoch: 199 | Batch_idx: 130 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (16377/16768)
Epoch: 199 | Batch_idx: 140 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (17624/18048)
Epoch: 199 | Batch_idx: 150 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (18869/19328)
Epoch: 199 | Batch_idx: 160 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (20115/20608)
Epoch: 199 | Batch_idx: 170 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (21362/21888)
Epoch: 199 | Batch_idx: 180 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (22612/23168)
Epoch: 199 | Batch_idx: 190 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (23863/24448)
Epoch: 199 | Batch_idx: 200 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (25118/25728)
Epoch: 199 | Batch_idx: 210 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (26369/27008)
Epoch: 199 | Batch_idx: 220 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (27613/28288)
Epoch: 199 | Batch_idx: 230 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (28862/29568)
Epoch: 199 | Batch_idx: 240 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (30108/30848)
Epoch: 199 | Batch_idx: 250 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (31343/32128)
Epoch: 199 | Batch_idx: 260 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (32593/33408)
Epoch: 199 | Batch_idx: 270 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (33839/34688)
Epoch: 199 | Batch_idx: 280 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (35086/35968)
Epoch: 199 | Batch_idx: 290 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (36338/37248)
Epoch: 199 | Batch_idx: 300 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (37593/38528)
Epoch: 199 | Batch_idx: 310 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (38835/39808)
Epoch: 199 | Batch_idx: 320 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (40081/41088)
Epoch: 199 | Batch_idx: 330 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (41325/42368)
Epoch: 199 | Batch_idx: 340 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (42577/43648)
Epoch: 199 | Batch_idx: 350 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (43825/44928)
Epoch: 199 | Batch_idx: 360 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (45068/46208)
Epoch: 199 | Batch_idx: 370 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (46313/47488)
Epoch: 199 | Batch_idx: 380 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (47557/48768)
Epoch: 199 | Batch_idx: 390 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (48756/50000)
# TEST : Loss: (0.3977) | Acc: (89.00%) (8901/10000)
percent tensor([0.5420, 0.5509, 0.5311, 0.5249, 0.5387, 0.5232, 0.5516, 0.5364, 0.5514,
        0.5489, 0.5518, 0.5435, 0.5478, 0.5524, 0.5372, 0.5404],
       device='cuda:0') torch.Size([16])
percent tensor([0.4791, 0.4868, 0.4668, 0.4632, 0.4704, 0.4768, 0.4819, 0.4750, 0.4759,
        0.4792, 0.4838, 0.4671, 0.4875, 0.4814, 0.4738, 0.4839],
       device='cuda:0') torch.Size([16])
percent tensor([0.5923, 0.5267, 0.5442, 0.6083, 0.5697, 0.6489, 0.5360, 0.5822, 0.5852,
        0.5318, 0.5512, 0.4938, 0.5437, 0.6417, 0.5386, 0.6099],
       device='cuda:0') torch.Size([16])
percent tensor([0.6862, 0.7336, 0.6058, 0.5904, 0.6150, 0.6268, 0.6989, 0.6336, 0.6852,
        0.7218, 0.7312, 0.6444, 0.7283, 0.7086, 0.6769, 0.6967],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.5643, 0.7463, 0.7538, 0.7641, 0.7305, 0.6437, 0.6449, 0.7000,
        0.5867, 0.6600, 0.7090, 0.5924, 0.6413, 0.6115, 0.5893],
       device='cuda:0') torch.Size([16])
percent tensor([0.6945, 0.7080, 0.7076, 0.6942, 0.7589, 0.7452, 0.7164, 0.6668, 0.6882,
        0.6726, 0.6568, 0.6536, 0.6999, 0.7004, 0.6496, 0.7272],
       device='cuda:0') torch.Size([16])
percent tensor([0.6833, 0.7688, 0.7260, 0.6710, 0.7329, 0.7836, 0.6776, 0.5017, 0.7844,
        0.7201, 0.7497, 0.7551, 0.7729, 0.7179, 0.5837, 0.5983],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9994, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 200 | Batch_idx: 0 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 200 | Batch_idx: 10 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 200 | Batch_idx: 20 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (2623/2688)
Epoch: 200 | Batch_idx: 30 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (3864/3968)
Epoch: 200 | Batch_idx: 40 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (5111/5248)
Epoch: 200 | Batch_idx: 50 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (6353/6528)
Epoch: 200 | Batch_idx: 60 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (7604/7808)
Epoch: 200 | Batch_idx: 70 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (8845/9088)
Epoch: 200 | Batch_idx: 80 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (10089/10368)
Epoch: 200 | Batch_idx: 90 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (11331/11648)
Epoch: 200 | Batch_idx: 100 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (12577/12928)
Epoch: 200 | Batch_idx: 110 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (13815/14208)
Epoch: 200 | Batch_idx: 120 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (15053/15488)
Epoch: 200 | Batch_idx: 130 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (16295/16768)
Epoch: 200 | Batch_idx: 140 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (17538/18048)
Epoch: 200 | Batch_idx: 150 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (18789/19328)
Epoch: 200 | Batch_idx: 160 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (20030/20608)
Epoch: 200 | Batch_idx: 170 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (21265/21888)
Epoch: 200 | Batch_idx: 180 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (22517/23168)
Epoch: 200 | Batch_idx: 190 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (23752/24448)
Epoch: 200 | Batch_idx: 200 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (24997/25728)
Epoch: 200 | Batch_idx: 210 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (26239/27008)
Epoch: 200 | Batch_idx: 220 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (27497/28288)
Epoch: 200 | Batch_idx: 230 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (28736/29568)
Epoch: 200 | Batch_idx: 240 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (29982/30848)
Epoch: 200 | Batch_idx: 250 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (31224/32128)
Epoch: 200 | Batch_idx: 260 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (32462/33408)
Epoch: 200 | Batch_idx: 270 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (33712/34688)
Epoch: 200 | Batch_idx: 280 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (34960/35968)
Epoch: 200 | Batch_idx: 290 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (36206/37248)
Epoch: 200 | Batch_idx: 300 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (37447/38528)
Epoch: 200 | Batch_idx: 310 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (38685/39808)
Epoch: 200 | Batch_idx: 320 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (39927/41088)
Epoch: 200 | Batch_idx: 330 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (41177/42368)
Epoch: 200 | Batch_idx: 340 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (42422/43648)
Epoch: 200 | Batch_idx: 350 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (43660/44928)
Epoch: 200 | Batch_idx: 360 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (44898/46208)
Epoch: 200 | Batch_idx: 370 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (46146/47488)
Epoch: 200 | Batch_idx: 380 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (47388/48768)
Epoch: 200 | Batch_idx: 390 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (48577/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_200.pth.tar'
# TEST : Loss: (0.4569) | Acc: (87.00%) (8773/10000)
percent tensor([0.5469, 0.5530, 0.5388, 0.5281, 0.5458, 0.5264, 0.5557, 0.5408, 0.5570,
        0.5529, 0.5561, 0.5499, 0.5524, 0.5522, 0.5401, 0.5440],
       device='cuda:0') torch.Size([16])
percent tensor([0.4824, 0.4896, 0.4690, 0.4670, 0.4720, 0.4798, 0.4846, 0.4777, 0.4778,
        0.4824, 0.4860, 0.4696, 0.4903, 0.4840, 0.4780, 0.4866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5911, 0.5301, 0.5604, 0.6158, 0.5846, 0.6517, 0.5475, 0.5922, 0.5900,
        0.5407, 0.5540, 0.5189, 0.5415, 0.6461, 0.5501, 0.6100],
       device='cuda:0') torch.Size([16])
percent tensor([0.6860, 0.7324, 0.6110, 0.6003, 0.6160, 0.6309, 0.7010, 0.6399, 0.6914,
        0.7248, 0.7357, 0.6518, 0.7320, 0.7144, 0.6789, 0.7028],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5734, 0.7583, 0.7642, 0.7734, 0.7242, 0.6528, 0.6537, 0.7013,
        0.5868, 0.6739, 0.7007, 0.5898, 0.6673, 0.6025, 0.5799],
       device='cuda:0') torch.Size([16])
percent tensor([0.7074, 0.7124, 0.7171, 0.7094, 0.7693, 0.7581, 0.7338, 0.6862, 0.6902,
        0.6802, 0.6641, 0.6626, 0.7005, 0.7068, 0.6583, 0.7402],
       device='cuda:0') torch.Size([16])
percent tensor([0.6794, 0.7774, 0.6994, 0.6769, 0.7388, 0.7852, 0.6676, 0.5152, 0.7673,
        0.7128, 0.7551, 0.7292, 0.7429, 0.7235, 0.5778, 0.5986],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9996, 0.9996, 0.9998, 0.9999, 0.9998, 0.9995, 0.9998,
        0.9999, 0.9999, 0.9997, 0.9997, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(185.8991, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.0088, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(836.3412, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1510.0177, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(480.1611, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2278.5659, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4245.8022, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1349.3235, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6253.8687, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11534.9072, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3793.4722, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15987.2676, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 201 | Batch_idx: 0 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 201 | Batch_idx: 10 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 201 | Batch_idx: 20 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (2616/2688)
Epoch: 201 | Batch_idx: 30 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (3860/3968)
Epoch: 201 | Batch_idx: 40 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (5104/5248)
Epoch: 201 | Batch_idx: 50 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (6347/6528)
Epoch: 201 | Batch_idx: 60 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (7590/7808)
Epoch: 201 | Batch_idx: 70 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (8839/9088)
Epoch: 201 | Batch_idx: 80 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (10078/10368)
Epoch: 201 | Batch_idx: 90 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (11327/11648)
Epoch: 201 | Batch_idx: 100 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (12563/12928)
Epoch: 201 | Batch_idx: 110 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (13814/14208)
Epoch: 201 | Batch_idx: 120 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (15057/15488)
Epoch: 201 | Batch_idx: 130 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (16306/16768)
Epoch: 201 | Batch_idx: 140 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (17549/18048)
Epoch: 201 | Batch_idx: 150 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (18794/19328)
Epoch: 201 | Batch_idx: 160 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (20043/20608)
Epoch: 201 | Batch_idx: 170 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (21273/21888)
Epoch: 201 | Batch_idx: 180 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (22520/23168)
Epoch: 201 | Batch_idx: 190 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (23762/24448)
Epoch: 201 | Batch_idx: 200 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (24995/25728)
Epoch: 201 | Batch_idx: 210 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (26238/27008)
Epoch: 201 | Batch_idx: 220 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (27483/28288)
Epoch: 201 | Batch_idx: 230 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (28713/29568)
Epoch: 201 | Batch_idx: 240 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (29959/30848)
Epoch: 201 | Batch_idx: 250 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (31195/32128)
Epoch: 201 | Batch_idx: 260 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (32435/33408)
Epoch: 201 | Batch_idx: 270 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (33674/34688)
Epoch: 201 | Batch_idx: 280 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (34905/35968)
Epoch: 201 | Batch_idx: 290 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (36152/37248)
Epoch: 201 | Batch_idx: 300 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (37407/38528)
Epoch: 201 | Batch_idx: 310 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (38642/39808)
Epoch: 201 | Batch_idx: 320 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (39884/41088)
Epoch: 201 | Batch_idx: 330 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (41116/42368)
Epoch: 201 | Batch_idx: 340 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (42368/43648)
Epoch: 201 | Batch_idx: 350 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (43613/44928)
Epoch: 201 | Batch_idx: 360 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (44863/46208)
Epoch: 201 | Batch_idx: 370 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (46101/47488)
Epoch: 201 | Batch_idx: 380 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (47349/48768)
Epoch: 201 | Batch_idx: 390 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (48542/50000)
# TEST : Loss: (0.4282) | Acc: (88.00%) (8835/10000)
percent tensor([0.5460, 0.5536, 0.5363, 0.5278, 0.5436, 0.5251, 0.5552, 0.5402, 0.5562,
        0.5526, 0.5556, 0.5481, 0.5514, 0.5541, 0.5395, 0.5438],
       device='cuda:0') torch.Size([16])
percent tensor([0.4819, 0.4889, 0.4664, 0.4646, 0.4710, 0.4815, 0.4836, 0.4761, 0.4778,
        0.4802, 0.4860, 0.4671, 0.4896, 0.4833, 0.4775, 0.4861],
       device='cuda:0') torch.Size([16])
percent tensor([0.5888, 0.5240, 0.5487, 0.6167, 0.5737, 0.6524, 0.5371, 0.5931, 0.5933,
        0.5325, 0.5519, 0.4999, 0.5364, 0.6455, 0.5394, 0.6108],
       device='cuda:0') torch.Size([16])
percent tensor([0.6886, 0.7355, 0.6148, 0.6031, 0.6204, 0.6357, 0.7059, 0.6429, 0.6929,
        0.7235, 0.7337, 0.6556, 0.7292, 0.7177, 0.6858, 0.7000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5843, 0.5619, 0.7352, 0.7433, 0.7585, 0.7200, 0.6376, 0.6111, 0.6941,
        0.5815, 0.6689, 0.6846, 0.5892, 0.6570, 0.5895, 0.5886],
       device='cuda:0') torch.Size([16])
percent tensor([0.7158, 0.7258, 0.7154, 0.7027, 0.7600, 0.7658, 0.7329, 0.6748, 0.6987,
        0.6902, 0.6725, 0.6728, 0.7056, 0.7101, 0.6633, 0.7593],
       device='cuda:0') torch.Size([16])
percent tensor([0.7241, 0.7887, 0.7128, 0.6544, 0.7085, 0.8261, 0.6694, 0.5011, 0.7711,
        0.7137, 0.7783, 0.7507, 0.7625, 0.7344, 0.5514, 0.6765],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9997, 0.9997,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 202 | Batch_idx: 0 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 202 | Batch_idx: 10 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 202 | Batch_idx: 20 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 202 | Batch_idx: 30 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (3864/3968)
Epoch: 202 | Batch_idx: 40 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (5118/5248)
Epoch: 202 | Batch_idx: 50 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (6368/6528)
Epoch: 202 | Batch_idx: 60 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (7613/7808)
Epoch: 202 | Batch_idx: 70 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (8862/9088)
Epoch: 202 | Batch_idx: 80 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (10110/10368)
Epoch: 202 | Batch_idx: 90 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (11359/11648)
Epoch: 202 | Batch_idx: 100 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (12614/12928)
Epoch: 202 | Batch_idx: 110 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (13867/14208)
Epoch: 202 | Batch_idx: 120 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (15119/15488)
Epoch: 202 | Batch_idx: 130 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (16358/16768)
Epoch: 202 | Batch_idx: 140 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (17602/18048)
Epoch: 202 | Batch_idx: 150 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (18846/19328)
Epoch: 202 | Batch_idx: 160 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (20103/20608)
Epoch: 202 | Batch_idx: 170 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (21349/21888)
Epoch: 202 | Batch_idx: 180 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (22606/23168)
Epoch: 202 | Batch_idx: 190 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (23856/24448)
Epoch: 202 | Batch_idx: 200 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (25098/25728)
Epoch: 202 | Batch_idx: 210 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (26349/27008)
Epoch: 202 | Batch_idx: 220 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (27599/28288)
Epoch: 202 | Batch_idx: 230 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (28840/29568)
Epoch: 202 | Batch_idx: 240 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (30095/30848)
Epoch: 202 | Batch_idx: 250 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (31335/32128)
Epoch: 202 | Batch_idx: 260 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (32580/33408)
Epoch: 202 | Batch_idx: 270 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (33832/34688)
Epoch: 202 | Batch_idx: 280 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (35074/35968)
Epoch: 202 | Batch_idx: 290 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (36316/37248)
Epoch: 202 | Batch_idx: 300 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (37550/38528)
Epoch: 202 | Batch_idx: 310 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (38791/39808)
Epoch: 202 | Batch_idx: 320 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (40033/41088)
Epoch: 202 | Batch_idx: 330 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (41286/42368)
Epoch: 202 | Batch_idx: 340 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (42526/43648)
Epoch: 202 | Batch_idx: 350 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (43778/44928)
Epoch: 202 | Batch_idx: 360 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (45019/46208)
Epoch: 202 | Batch_idx: 370 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (46261/47488)
Epoch: 202 | Batch_idx: 380 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (47503/48768)
Epoch: 202 | Batch_idx: 390 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (48700/50000)
# TEST : Loss: (0.4308) | Acc: (88.00%) (8828/10000)
percent tensor([0.5488, 0.5570, 0.5387, 0.5307, 0.5459, 0.5273, 0.5585, 0.5434, 0.5587,
        0.5559, 0.5582, 0.5523, 0.5544, 0.5565, 0.5424, 0.5462],
       device='cuda:0') torch.Size([16])
percent tensor([0.4831, 0.4909, 0.4673, 0.4693, 0.4708, 0.4819, 0.4845, 0.4792, 0.4780,
        0.4819, 0.4860, 0.4684, 0.4908, 0.4864, 0.4795, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5972, 0.5224, 0.5665, 0.6299, 0.5838, 0.6571, 0.5409, 0.6014, 0.5932,
        0.5354, 0.5478, 0.5188, 0.5417, 0.6474, 0.5458, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.6895, 0.7321, 0.6190, 0.6078, 0.6223, 0.6351, 0.7047, 0.6442, 0.6973,
        0.7292, 0.7360, 0.6578, 0.7322, 0.7232, 0.6821, 0.7026],
       device='cuda:0') torch.Size([16])
percent tensor([0.5858, 0.5790, 0.7562, 0.7582, 0.7773, 0.7427, 0.6488, 0.6480, 0.6926,
        0.5797, 0.6834, 0.7080, 0.5865, 0.6374, 0.6218, 0.5965],
       device='cuda:0') torch.Size([16])
percent tensor([0.7108, 0.7224, 0.7103, 0.7091, 0.7619, 0.7618, 0.7328, 0.6702, 0.6987,
        0.6961, 0.6787, 0.6727, 0.7107, 0.7237, 0.6589, 0.7484],
       device='cuda:0') torch.Size([16])
percent tensor([0.6720, 0.7843, 0.6899, 0.6352, 0.7259, 0.7803, 0.6716, 0.4791, 0.7636,
        0.7228, 0.7718, 0.7521, 0.7368, 0.7449, 0.5667, 0.6048],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9997, 0.9996, 0.9998, 0.9999, 0.9997, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9994, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 203 | Batch_idx: 0 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 203 | Batch_idx: 10 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 203 | Batch_idx: 20 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (2630/2688)
Epoch: 203 | Batch_idx: 30 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (3879/3968)
Epoch: 203 | Batch_idx: 40 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (5127/5248)
Epoch: 203 | Batch_idx: 50 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (6378/6528)
Epoch: 203 | Batch_idx: 60 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (7625/7808)
Epoch: 203 | Batch_idx: 70 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (8881/9088)
Epoch: 203 | Batch_idx: 80 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (10121/10368)
Epoch: 203 | Batch_idx: 90 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (11367/11648)
Epoch: 203 | Batch_idx: 100 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (12616/12928)
Epoch: 203 | Batch_idx: 110 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (13861/14208)
Epoch: 203 | Batch_idx: 120 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (15117/15488)
Epoch: 203 | Batch_idx: 130 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (16365/16768)
Epoch: 203 | Batch_idx: 140 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (17611/18048)
Epoch: 203 | Batch_idx: 150 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (18854/19328)
Epoch: 203 | Batch_idx: 160 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (20088/20608)
Epoch: 203 | Batch_idx: 170 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (21333/21888)
Epoch: 203 | Batch_idx: 180 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (22576/23168)
Epoch: 203 | Batch_idx: 190 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (23816/24448)
Epoch: 203 | Batch_idx: 200 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (25072/25728)
Epoch: 203 | Batch_idx: 210 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (26317/27008)
Epoch: 203 | Batch_idx: 220 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (27559/28288)
Epoch: 203 | Batch_idx: 230 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (28802/29568)
Epoch: 203 | Batch_idx: 240 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (30047/30848)
Epoch: 203 | Batch_idx: 250 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (31297/32128)
Epoch: 203 | Batch_idx: 260 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (32548/33408)
Epoch: 203 | Batch_idx: 270 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (33804/34688)
Epoch: 203 | Batch_idx: 280 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (35040/35968)
Epoch: 203 | Batch_idx: 290 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (36282/37248)
Epoch: 203 | Batch_idx: 300 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (37524/38528)
Epoch: 203 | Batch_idx: 310 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (38767/39808)
Epoch: 203 | Batch_idx: 320 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (40018/41088)
Epoch: 203 | Batch_idx: 330 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (41269/42368)
Epoch: 203 | Batch_idx: 340 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (42509/43648)
Epoch: 203 | Batch_idx: 350 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (43756/44928)
Epoch: 203 | Batch_idx: 360 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (45007/46208)
Epoch: 203 | Batch_idx: 370 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (46243/47488)
Epoch: 203 | Batch_idx: 380 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (47483/48768)
Epoch: 203 | Batch_idx: 390 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (48682/50000)
# TEST : Loss: (0.4474) | Acc: (87.00%) (8792/10000)
percent tensor([0.5479, 0.5558, 0.5379, 0.5297, 0.5459, 0.5262, 0.5575, 0.5420, 0.5579,
        0.5548, 0.5571, 0.5513, 0.5535, 0.5560, 0.5410, 0.5455],
       device='cuda:0') torch.Size([16])
percent tensor([0.4842, 0.4929, 0.4672, 0.4700, 0.4713, 0.4824, 0.4862, 0.4804, 0.4794,
        0.4841, 0.4888, 0.4688, 0.4924, 0.4871, 0.4814, 0.4891],
       device='cuda:0') torch.Size([16])
percent tensor([0.5856, 0.5205, 0.5492, 0.6154, 0.5713, 0.6469, 0.5377, 0.5919, 0.5837,
        0.5274, 0.5437, 0.4985, 0.5291, 0.6452, 0.5385, 0.6080],
       device='cuda:0') torch.Size([16])
percent tensor([0.6965, 0.7375, 0.6222, 0.6111, 0.6265, 0.6420, 0.7085, 0.6457, 0.7005,
        0.7280, 0.7443, 0.6591, 0.7331, 0.7216, 0.6899, 0.7075],
       device='cuda:0') torch.Size([16])
percent tensor([0.5895, 0.5691, 0.7592, 0.7568, 0.7693, 0.7392, 0.6511, 0.6458, 0.6871,
        0.5852, 0.6672, 0.7054, 0.5933, 0.6424, 0.6193, 0.5912],
       device='cuda:0') torch.Size([16])
percent tensor([0.7120, 0.7257, 0.7106, 0.7021, 0.7558, 0.7676, 0.7318, 0.6638, 0.7113,
        0.6905, 0.6754, 0.6566, 0.7087, 0.7251, 0.6616, 0.7443],
       device='cuda:0') torch.Size([16])
percent tensor([0.6918, 0.7964, 0.7291, 0.6357, 0.7340, 0.7812, 0.6912, 0.4943, 0.7993,
        0.7228, 0.7613, 0.7391, 0.7449, 0.7357, 0.5546, 0.6226],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9997, 0.9998, 0.9999, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9995, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 204 | Batch_idx: 0 |  Loss: (0.0218) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 204 | Batch_idx: 10 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 204 | Batch_idx: 20 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (2613/2688)
Epoch: 204 | Batch_idx: 30 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (3861/3968)
Epoch: 204 | Batch_idx: 40 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (5106/5248)
Epoch: 204 | Batch_idx: 50 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (6357/6528)
Epoch: 204 | Batch_idx: 60 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (7611/7808)
Epoch: 204 | Batch_idx: 70 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (8855/9088)
Epoch: 204 | Batch_idx: 80 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (10104/10368)
Epoch: 204 | Batch_idx: 90 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (11346/11648)
Epoch: 204 | Batch_idx: 100 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (12592/12928)
Epoch: 204 | Batch_idx: 110 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (13842/14208)
Epoch: 204 | Batch_idx: 120 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (15091/15488)
Epoch: 204 | Batch_idx: 130 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (16337/16768)
Epoch: 204 | Batch_idx: 140 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (17584/18048)
Epoch: 204 | Batch_idx: 150 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (18834/19328)
Epoch: 204 | Batch_idx: 160 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (20092/20608)
Epoch: 204 | Batch_idx: 170 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (21340/21888)
Epoch: 204 | Batch_idx: 180 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (22581/23168)
Epoch: 204 | Batch_idx: 190 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (23828/24448)
Epoch: 204 | Batch_idx: 200 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (25087/25728)
Epoch: 204 | Batch_idx: 210 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (26349/27008)
Epoch: 204 | Batch_idx: 220 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (27601/28288)
Epoch: 204 | Batch_idx: 230 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (28834/29568)
Epoch: 204 | Batch_idx: 240 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (30078/30848)
Epoch: 204 | Batch_idx: 250 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (31333/32128)
Epoch: 204 | Batch_idx: 260 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (32572/33408)
Epoch: 204 | Batch_idx: 270 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (33813/34688)
Epoch: 204 | Batch_idx: 280 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (35062/35968)
Epoch: 204 | Batch_idx: 290 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (36306/37248)
Epoch: 204 | Batch_idx: 300 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (37552/38528)
Epoch: 204 | Batch_idx: 310 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (38802/39808)
Epoch: 204 | Batch_idx: 320 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (40048/41088)
Epoch: 204 | Batch_idx: 330 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (41297/42368)
Epoch: 204 | Batch_idx: 340 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (42541/43648)
Epoch: 204 | Batch_idx: 350 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (43789/44928)
Epoch: 204 | Batch_idx: 360 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (45034/46208)
Epoch: 204 | Batch_idx: 370 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (46287/47488)
Epoch: 204 | Batch_idx: 380 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (47533/48768)
Epoch: 204 | Batch_idx: 390 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (48738/50000)
# TEST : Loss: (0.4214) | Acc: (88.00%) (8869/10000)
percent tensor([0.5500, 0.5589, 0.5377, 0.5307, 0.5464, 0.5279, 0.5604, 0.5445, 0.5612,
        0.5572, 0.5606, 0.5526, 0.5560, 0.5606, 0.5429, 0.5476],
       device='cuda:0') torch.Size([16])
percent tensor([0.4873, 0.4942, 0.4732, 0.4718, 0.4771, 0.4858, 0.4892, 0.4823, 0.4827,
        0.4863, 0.4903, 0.4747, 0.4946, 0.4876, 0.4832, 0.4906],
       device='cuda:0') torch.Size([16])
percent tensor([0.5988, 0.5226, 0.5546, 0.6303, 0.5741, 0.6563, 0.5366, 0.6042, 0.5875,
        0.5327, 0.5514, 0.5032, 0.5369, 0.6479, 0.5432, 0.6197],
       device='cuda:0') torch.Size([16])
percent tensor([0.6996, 0.7404, 0.6268, 0.6170, 0.6327, 0.6429, 0.7132, 0.6500, 0.6993,
        0.7325, 0.7393, 0.6698, 0.7376, 0.7271, 0.6923, 0.7099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5891, 0.5603, 0.7542, 0.7635, 0.7759, 0.7512, 0.6550, 0.6444, 0.7023,
        0.5812, 0.6839, 0.7077, 0.5824, 0.6518, 0.6259, 0.5944],
       device='cuda:0') torch.Size([16])
percent tensor([0.7184, 0.7171, 0.7222, 0.7109, 0.7689, 0.7713, 0.7330, 0.6750, 0.7001,
        0.6955, 0.6701, 0.6708, 0.7038, 0.7088, 0.6606, 0.7559],
       device='cuda:0') torch.Size([16])
percent tensor([0.7033, 0.7896, 0.7096, 0.6380, 0.7253, 0.8124, 0.6683, 0.4985, 0.7580,
        0.7463, 0.7420, 0.7234, 0.7470, 0.7342, 0.5569, 0.6529],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9998, 0.9997, 0.9999, 0.9998, 0.9998, 0.9995, 0.9997,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 205 | Batch_idx: 0 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 205 | Batch_idx: 10 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 205 | Batch_idx: 20 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (2613/2688)
Epoch: 205 | Batch_idx: 30 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (3869/3968)
Epoch: 205 | Batch_idx: 40 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (5112/5248)
Epoch: 205 | Batch_idx: 50 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (6371/6528)
Epoch: 205 | Batch_idx: 60 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (7621/7808)
Epoch: 205 | Batch_idx: 70 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (8874/9088)
Epoch: 205 | Batch_idx: 80 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (10119/10368)
Epoch: 205 | Batch_idx: 90 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (11362/11648)
Epoch: 205 | Batch_idx: 100 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (12615/12928)
Epoch: 205 | Batch_idx: 110 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (13869/14208)
Epoch: 205 | Batch_idx: 120 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (15118/15488)
Epoch: 205 | Batch_idx: 130 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (16375/16768)
Epoch: 205 | Batch_idx: 140 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (17634/18048)
Epoch: 205 | Batch_idx: 150 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (18876/19328)
Epoch: 205 | Batch_idx: 160 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (20123/20608)
Epoch: 205 | Batch_idx: 170 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (21363/21888)
Epoch: 205 | Batch_idx: 180 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (22613/23168)
Epoch: 205 | Batch_idx: 190 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (23859/24448)
Epoch: 205 | Batch_idx: 200 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (25112/25728)
Epoch: 205 | Batch_idx: 210 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (26354/27008)
Epoch: 205 | Batch_idx: 220 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (27606/28288)
Epoch: 205 | Batch_idx: 230 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (28855/29568)
Epoch: 205 | Batch_idx: 240 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (30104/30848)
Epoch: 205 | Batch_idx: 250 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (31345/32128)
Epoch: 205 | Batch_idx: 260 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (32598/33408)
Epoch: 205 | Batch_idx: 270 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (33847/34688)
Epoch: 205 | Batch_idx: 280 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (35104/35968)
Epoch: 205 | Batch_idx: 290 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (36369/37248)
Epoch: 205 | Batch_idx: 300 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (37611/38528)
Epoch: 205 | Batch_idx: 310 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (38858/39808)
Epoch: 205 | Batch_idx: 320 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (40114/41088)
Epoch: 205 | Batch_idx: 330 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (41360/42368)
Epoch: 205 | Batch_idx: 340 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (42611/43648)
Epoch: 205 | Batch_idx: 350 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (43853/44928)
Epoch: 205 | Batch_idx: 360 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (45092/46208)
Epoch: 205 | Batch_idx: 370 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (46330/47488)
Epoch: 205 | Batch_idx: 380 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (47587/48768)
Epoch: 205 | Batch_idx: 390 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (48788/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_205.pth.tar'
# TEST : Loss: (0.4415) | Acc: (88.00%) (8829/10000)
percent tensor([0.5487, 0.5559, 0.5381, 0.5287, 0.5453, 0.5272, 0.5582, 0.5424, 0.5595,
        0.5548, 0.5585, 0.5511, 0.5542, 0.5570, 0.5407, 0.5453],
       device='cuda:0') torch.Size([16])
percent tensor([0.4870, 0.4945, 0.4730, 0.4714, 0.4768, 0.4847, 0.4897, 0.4836, 0.4838,
        0.4865, 0.4921, 0.4742, 0.4950, 0.4883, 0.4829, 0.4905],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.5298, 0.5544, 0.6197, 0.5739, 0.6543, 0.5444, 0.6025, 0.5957,
        0.5358, 0.5585, 0.5014, 0.5441, 0.6551, 0.5419, 0.6175],
       device='cuda:0') torch.Size([16])
percent tensor([0.6945, 0.7394, 0.6239, 0.6081, 0.6289, 0.6339, 0.7098, 0.6461, 0.6998,
        0.7316, 0.7380, 0.6669, 0.7374, 0.7228, 0.6875, 0.7049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5834, 0.5517, 0.7474, 0.7695, 0.7724, 0.7547, 0.6394, 0.6435, 0.6924,
        0.5698, 0.6657, 0.6824, 0.5833, 0.6411, 0.6226, 0.5937],
       device='cuda:0') torch.Size([16])
percent tensor([0.7204, 0.7208, 0.7175, 0.7082, 0.7685, 0.7685, 0.7338, 0.6729, 0.6996,
        0.6912, 0.6667, 0.6599, 0.7126, 0.7028, 0.6610, 0.7581],
       device='cuda:0') torch.Size([16])
percent tensor([0.7195, 0.7852, 0.6870, 0.6344, 0.7291, 0.8224, 0.6831, 0.4602, 0.7638,
        0.7353, 0.7418, 0.7061, 0.7510, 0.7001, 0.5578, 0.6473],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9996, 0.9997,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9997, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 206 | Batch_idx: 0 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 206 | Batch_idx: 10 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 206 | Batch_idx: 20 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 206 | Batch_idx: 30 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (3876/3968)
Epoch: 206 | Batch_idx: 40 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (5122/5248)
Epoch: 206 | Batch_idx: 50 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (6374/6528)
Epoch: 206 | Batch_idx: 60 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (7624/7808)
Epoch: 206 | Batch_idx: 70 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (8875/9088)
Epoch: 206 | Batch_idx: 80 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (10129/10368)
Epoch: 206 | Batch_idx: 90 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (11383/11648)
Epoch: 206 | Batch_idx: 100 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (12640/12928)
Epoch: 206 | Batch_idx: 110 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (13890/14208)
Epoch: 206 | Batch_idx: 120 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (15142/15488)
Epoch: 206 | Batch_idx: 130 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (16394/16768)
Epoch: 206 | Batch_idx: 140 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (17643/18048)
Epoch: 206 | Batch_idx: 150 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (18887/19328)
Epoch: 206 | Batch_idx: 160 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (20139/20608)
Epoch: 206 | Batch_idx: 170 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (21390/21888)
Epoch: 206 | Batch_idx: 180 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (22631/23168)
Epoch: 206 | Batch_idx: 190 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (23881/24448)
Epoch: 206 | Batch_idx: 200 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (25127/25728)
Epoch: 206 | Batch_idx: 210 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (26370/27008)
Epoch: 206 | Batch_idx: 220 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (27610/28288)
Epoch: 206 | Batch_idx: 230 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (28862/29568)
Epoch: 206 | Batch_idx: 240 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (30112/30848)
Epoch: 206 | Batch_idx: 250 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (31371/32128)
Epoch: 206 | Batch_idx: 260 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (32629/33408)
Epoch: 206 | Batch_idx: 270 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (33883/34688)
Epoch: 206 | Batch_idx: 280 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (35132/35968)
Epoch: 206 | Batch_idx: 290 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (36383/37248)
Epoch: 206 | Batch_idx: 300 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (37634/38528)
Epoch: 206 | Batch_idx: 310 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (38885/39808)
Epoch: 206 | Batch_idx: 320 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (40134/41088)
Epoch: 206 | Batch_idx: 330 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (41379/42368)
Epoch: 206 | Batch_idx: 340 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (42620/43648)
Epoch: 206 | Batch_idx: 350 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (43876/44928)
Epoch: 206 | Batch_idx: 360 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (45127/46208)
Epoch: 206 | Batch_idx: 370 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (46372/47488)
Epoch: 206 | Batch_idx: 380 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (47610/48768)
Epoch: 206 | Batch_idx: 390 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (48814/50000)
# TEST : Loss: (0.4879) | Acc: (87.00%) (8766/10000)
percent tensor([0.5529, 0.5608, 0.5432, 0.5339, 0.5508, 0.5308, 0.5630, 0.5472, 0.5638,
        0.5600, 0.5628, 0.5558, 0.5584, 0.5615, 0.5453, 0.5497],
       device='cuda:0') torch.Size([16])
percent tensor([0.4882, 0.4940, 0.4742, 0.4731, 0.4782, 0.4876, 0.4897, 0.4836, 0.4833,
        0.4863, 0.4918, 0.4749, 0.4948, 0.4884, 0.4831, 0.4924],
       device='cuda:0') torch.Size([16])
percent tensor([0.5922, 0.5188, 0.5614, 0.6232, 0.5774, 0.6559, 0.5384, 0.5887, 0.5847,
        0.5297, 0.5515, 0.5124, 0.5266, 0.6464, 0.5365, 0.6124],
       device='cuda:0') torch.Size([16])
percent tensor([0.6981, 0.7413, 0.6283, 0.6168, 0.6340, 0.6418, 0.7114, 0.6537, 0.6998,
        0.7373, 0.7406, 0.6656, 0.7402, 0.7212, 0.6924, 0.7104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.5564, 0.7586, 0.7734, 0.7804, 0.7374, 0.6512, 0.6495, 0.6883,
        0.5769, 0.6642, 0.7069, 0.5781, 0.6308, 0.6237, 0.5933],
       device='cuda:0') torch.Size([16])
percent tensor([0.7168, 0.7289, 0.7253, 0.7272, 0.7716, 0.7742, 0.7452, 0.6822, 0.7119,
        0.6983, 0.6684, 0.6748, 0.7075, 0.7215, 0.6716, 0.7585],
       device='cuda:0') torch.Size([16])
percent tensor([0.6973, 0.7786, 0.7085, 0.6773, 0.7365, 0.8173, 0.6965, 0.5014, 0.7591,
        0.7174, 0.7343, 0.7117, 0.7146, 0.7282, 0.5824, 0.6424],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9997, 0.9997,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 207 | Batch_idx: 0 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 207 | Batch_idx: 10 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 207 | Batch_idx: 20 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (2633/2688)
Epoch: 207 | Batch_idx: 30 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (3883/3968)
Epoch: 207 | Batch_idx: 40 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (98.00%) (5144/5248)
Epoch: 207 | Batch_idx: 50 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (6392/6528)
Epoch: 207 | Batch_idx: 60 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (7641/7808)
Epoch: 207 | Batch_idx: 70 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (8884/9088)
Epoch: 207 | Batch_idx: 80 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (10133/10368)
Epoch: 207 | Batch_idx: 90 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (11390/11648)
Epoch: 207 | Batch_idx: 100 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (12630/12928)
Epoch: 207 | Batch_idx: 110 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (13880/14208)
Epoch: 207 | Batch_idx: 120 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (15128/15488)
Epoch: 207 | Batch_idx: 130 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (16380/16768)
Epoch: 207 | Batch_idx: 140 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (17636/18048)
Epoch: 207 | Batch_idx: 150 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (18891/19328)
Epoch: 207 | Batch_idx: 160 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (20148/20608)
Epoch: 207 | Batch_idx: 170 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (21399/21888)
Epoch: 207 | Batch_idx: 180 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (22650/23168)
Epoch: 207 | Batch_idx: 190 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (23901/24448)
Epoch: 207 | Batch_idx: 200 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (25150/25728)
Epoch: 207 | Batch_idx: 210 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (26390/27008)
Epoch: 207 | Batch_idx: 220 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (27633/28288)
Epoch: 207 | Batch_idx: 230 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (28870/29568)
Epoch: 207 | Batch_idx: 240 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (30113/30848)
Epoch: 207 | Batch_idx: 250 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (31352/32128)
Epoch: 207 | Batch_idx: 260 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (32587/33408)
Epoch: 207 | Batch_idx: 270 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (33833/34688)
Epoch: 207 | Batch_idx: 280 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (35076/35968)
Epoch: 207 | Batch_idx: 290 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (36318/37248)
Epoch: 207 | Batch_idx: 300 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (37561/38528)
Epoch: 207 | Batch_idx: 310 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (38801/39808)
Epoch: 207 | Batch_idx: 320 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (40040/41088)
Epoch: 207 | Batch_idx: 330 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (41290/42368)
Epoch: 207 | Batch_idx: 340 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (42531/43648)
Epoch: 207 | Batch_idx: 350 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (43778/44928)
Epoch: 207 | Batch_idx: 360 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (45025/46208)
Epoch: 207 | Batch_idx: 370 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (46274/47488)
Epoch: 207 | Batch_idx: 380 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (47524/48768)
Epoch: 207 | Batch_idx: 390 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (48728/50000)
# TEST : Loss: (0.4100) | Acc: (89.00%) (8908/10000)
percent tensor([0.5512, 0.5566, 0.5451, 0.5328, 0.5518, 0.5291, 0.5602, 0.5463, 0.5613,
        0.5578, 0.5595, 0.5573, 0.5562, 0.5546, 0.5425, 0.5468],
       device='cuda:0') torch.Size([16])
percent tensor([0.4899, 0.4967, 0.4747, 0.4747, 0.4785, 0.4875, 0.4922, 0.4857, 0.4858,
        0.4888, 0.4940, 0.4760, 0.4969, 0.4921, 0.4861, 0.4935],
       device='cuda:0') torch.Size([16])
percent tensor([0.5973, 0.5219, 0.5775, 0.6351, 0.5880, 0.6566, 0.5428, 0.6080, 0.5939,
        0.5335, 0.5556, 0.5244, 0.5346, 0.6553, 0.5404, 0.6154],
       device='cuda:0') torch.Size([16])
percent tensor([0.6930, 0.7342, 0.6211, 0.6131, 0.6253, 0.6359, 0.7054, 0.6470, 0.6963,
        0.7301, 0.7348, 0.6597, 0.7319, 0.7170, 0.6882, 0.7030],
       device='cuda:0') torch.Size([16])
percent tensor([0.5778, 0.5681, 0.7607, 0.7572, 0.7846, 0.7254, 0.6531, 0.6574, 0.6815,
        0.5819, 0.6691, 0.7117, 0.5865, 0.6490, 0.6179, 0.5875],
       device='cuda:0') torch.Size([16])
percent tensor([0.7237, 0.7435, 0.7237, 0.7254, 0.7743, 0.7780, 0.7528, 0.6915, 0.7081,
        0.7063, 0.6858, 0.6818, 0.7159, 0.7307, 0.6900, 0.7574],
       device='cuda:0') torch.Size([16])
percent tensor([0.6971, 0.7917, 0.7070, 0.6847, 0.7352, 0.8104, 0.6900, 0.4775, 0.7665,
        0.7319, 0.7649, 0.7434, 0.7411, 0.7330, 0.6099, 0.6308],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9997, 0.9999, 0.9998, 0.9996, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 208 | Batch_idx: 0 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 208 | Batch_idx: 10 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 208 | Batch_idx: 20 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (2630/2688)
Epoch: 208 | Batch_idx: 30 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (3885/3968)
Epoch: 208 | Batch_idx: 40 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (5140/5248)
Epoch: 208 | Batch_idx: 50 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (6387/6528)
Epoch: 208 | Batch_idx: 60 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (7640/7808)
Epoch: 208 | Batch_idx: 70 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (8880/9088)
Epoch: 208 | Batch_idx: 80 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (10127/10368)
Epoch: 208 | Batch_idx: 90 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (11372/11648)
Epoch: 208 | Batch_idx: 100 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (12616/12928)
Epoch: 208 | Batch_idx: 110 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (13865/14208)
Epoch: 208 | Batch_idx: 120 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (15112/15488)
Epoch: 208 | Batch_idx: 130 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (16369/16768)
Epoch: 208 | Batch_idx: 140 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (17613/18048)
Epoch: 208 | Batch_idx: 150 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (18857/19328)
Epoch: 208 | Batch_idx: 160 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (20108/20608)
Epoch: 208 | Batch_idx: 170 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (21356/21888)
Epoch: 208 | Batch_idx: 180 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (22598/23168)
Epoch: 208 | Batch_idx: 190 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (23855/24448)
Epoch: 208 | Batch_idx: 200 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (25108/25728)
Epoch: 208 | Batch_idx: 210 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (26361/27008)
Epoch: 208 | Batch_idx: 220 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (27607/28288)
Epoch: 208 | Batch_idx: 230 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (28857/29568)
Epoch: 208 | Batch_idx: 240 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (30105/30848)
Epoch: 208 | Batch_idx: 250 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (31339/32128)
Epoch: 208 | Batch_idx: 260 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (32591/33408)
Epoch: 208 | Batch_idx: 270 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (33825/34688)
Epoch: 208 | Batch_idx: 280 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (35069/35968)
Epoch: 208 | Batch_idx: 290 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (36322/37248)
Epoch: 208 | Batch_idx: 300 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (37575/38528)
Epoch: 208 | Batch_idx: 310 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (38817/39808)
Epoch: 208 | Batch_idx: 320 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (40062/41088)
Epoch: 208 | Batch_idx: 330 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (41302/42368)
Epoch: 208 | Batch_idx: 340 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (42553/43648)
Epoch: 208 | Batch_idx: 350 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (43797/44928)
Epoch: 208 | Batch_idx: 360 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (45050/46208)
Epoch: 208 | Batch_idx: 370 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (46293/47488)
Epoch: 208 | Batch_idx: 380 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (47532/48768)
Epoch: 208 | Batch_idx: 390 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (48732/50000)
# TEST : Loss: (0.4727) | Acc: (87.00%) (8746/10000)
percent tensor([0.5507, 0.5587, 0.5400, 0.5307, 0.5475, 0.5284, 0.5606, 0.5454, 0.5614,
        0.5577, 0.5606, 0.5546, 0.5569, 0.5588, 0.5429, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.4891, 0.4954, 0.4722, 0.4737, 0.4768, 0.4884, 0.4899, 0.4833, 0.4831,
        0.4865, 0.4923, 0.4735, 0.4953, 0.4893, 0.4850, 0.4923],
       device='cuda:0') torch.Size([16])
percent tensor([0.5991, 0.5304, 0.5528, 0.6303, 0.5711, 0.6596, 0.5437, 0.6057, 0.5984,
        0.5379, 0.5642, 0.5066, 0.5434, 0.6648, 0.5472, 0.6209],
       device='cuda:0') torch.Size([16])
percent tensor([0.6923, 0.7372, 0.6252, 0.6106, 0.6303, 0.6360, 0.7083, 0.6477, 0.6946,
        0.7278, 0.7343, 0.6630, 0.7294, 0.7169, 0.6883, 0.7021],
       device='cuda:0') torch.Size([16])
percent tensor([0.5867, 0.5562, 0.7639, 0.7694, 0.7825, 0.7461, 0.6553, 0.6595, 0.6881,
        0.5933, 0.6675, 0.7177, 0.5922, 0.6418, 0.6143, 0.6003],
       device='cuda:0') torch.Size([16])
percent tensor([0.7199, 0.7281, 0.7294, 0.7134, 0.7700, 0.7719, 0.7361, 0.6818, 0.7135,
        0.7049, 0.6705, 0.6714, 0.7094, 0.7178, 0.6669, 0.7507],
       device='cuda:0') torch.Size([16])
percent tensor([0.7205, 0.8060, 0.7219, 0.6454, 0.7241, 0.8040, 0.6886, 0.5043, 0.7849,
        0.7436, 0.7492, 0.7524, 0.7395, 0.7461, 0.6029, 0.6420],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9996, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9995, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 209 | Batch_idx: 0 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 209 | Batch_idx: 10 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 209 | Batch_idx: 20 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 209 | Batch_idx: 30 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (3901/3968)
Epoch: 209 | Batch_idx: 40 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (98.00%) (5152/5248)
Epoch: 209 | Batch_idx: 50 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (98.00%) (6408/6528)
Epoch: 209 | Batch_idx: 60 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (98.00%) (7663/7808)
Epoch: 209 | Batch_idx: 70 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (98.00%) (8910/9088)
Epoch: 209 | Batch_idx: 80 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (98.00%) (10162/10368)
Epoch: 209 | Batch_idx: 90 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (11414/11648)
Epoch: 209 | Batch_idx: 100 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (12655/12928)
Epoch: 209 | Batch_idx: 110 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (13907/14208)
Epoch: 209 | Batch_idx: 120 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (15147/15488)
Epoch: 209 | Batch_idx: 130 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (16395/16768)
Epoch: 209 | Batch_idx: 140 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (17644/18048)
Epoch: 209 | Batch_idx: 150 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (18891/19328)
Epoch: 209 | Batch_idx: 160 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (20139/20608)
Epoch: 209 | Batch_idx: 170 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (21387/21888)
Epoch: 209 | Batch_idx: 180 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (22641/23168)
Epoch: 209 | Batch_idx: 190 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (23890/24448)
Epoch: 209 | Batch_idx: 200 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (25135/25728)
Epoch: 209 | Batch_idx: 210 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (26369/27008)
Epoch: 209 | Batch_idx: 220 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (27618/28288)
Epoch: 209 | Batch_idx: 230 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (28867/29568)
Epoch: 209 | Batch_idx: 240 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (30121/30848)
Epoch: 209 | Batch_idx: 250 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (31363/32128)
Epoch: 209 | Batch_idx: 260 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (32616/33408)
Epoch: 209 | Batch_idx: 270 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (33866/34688)
Epoch: 209 | Batch_idx: 280 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (35114/35968)
Epoch: 209 | Batch_idx: 290 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (36364/37248)
Epoch: 209 | Batch_idx: 300 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (37623/38528)
Epoch: 209 | Batch_idx: 310 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (38875/39808)
Epoch: 209 | Batch_idx: 320 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (40130/41088)
Epoch: 209 | Batch_idx: 330 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (41367/42368)
Epoch: 209 | Batch_idx: 340 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (42618/43648)
Epoch: 209 | Batch_idx: 350 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (43871/44928)
Epoch: 209 | Batch_idx: 360 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (45114/46208)
Epoch: 209 | Batch_idx: 370 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (46370/47488)
Epoch: 209 | Batch_idx: 380 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (47628/48768)
Epoch: 209 | Batch_idx: 390 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (48833/50000)
# TEST : Loss: (0.4435) | Acc: (88.00%) (8836/10000)
percent tensor([0.5528, 0.5605, 0.5426, 0.5320, 0.5500, 0.5306, 0.5628, 0.5475, 0.5642,
        0.5601, 0.5632, 0.5573, 0.5590, 0.5595, 0.5449, 0.5494],
       device='cuda:0') torch.Size([16])
percent tensor([0.4885, 0.4950, 0.4761, 0.4748, 0.4789, 0.4875, 0.4910, 0.4842, 0.4835,
        0.4869, 0.4910, 0.4759, 0.4946, 0.4900, 0.4848, 0.4921],
       device='cuda:0') torch.Size([16])
percent tensor([0.5954, 0.5268, 0.5667, 0.6312, 0.5820, 0.6506, 0.5494, 0.6058, 0.5968,
        0.5395, 0.5588, 0.5124, 0.5397, 0.6579, 0.5417, 0.6171],
       device='cuda:0') torch.Size([16])
percent tensor([0.6968, 0.7359, 0.6283, 0.6144, 0.6314, 0.6432, 0.7096, 0.6545, 0.6997,
        0.7307, 0.7428, 0.6652, 0.7354, 0.7213, 0.6915, 0.7069],
       device='cuda:0') torch.Size([16])
percent tensor([0.5880, 0.5702, 0.7536, 0.7660, 0.7810, 0.7402, 0.6570, 0.6597, 0.7096,
        0.5875, 0.6792, 0.7087, 0.5851, 0.6657, 0.6264, 0.6011],
       device='cuda:0') torch.Size([16])
percent tensor([0.7278, 0.7410, 0.7327, 0.7239, 0.7799, 0.7770, 0.7474, 0.6850, 0.7220,
        0.7019, 0.6786, 0.6785, 0.7196, 0.7397, 0.6773, 0.7517],
       device='cuda:0') torch.Size([16])
percent tensor([0.7031, 0.8071, 0.7120, 0.6345, 0.7388, 0.8094, 0.6796, 0.5032, 0.7819,
        0.6898, 0.7378, 0.7146, 0.7316, 0.7443, 0.5855, 0.6259],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9999, 0.9998, 0.9998, 0.9999, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9994, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 210 | Batch_idx: 0 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 210 | Batch_idx: 10 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 210 | Batch_idx: 20 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 210 | Batch_idx: 30 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (3888/3968)
Epoch: 210 | Batch_idx: 40 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (98.00%) (5151/5248)
Epoch: 210 | Batch_idx: 50 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (98.00%) (6407/6528)
Epoch: 210 | Batch_idx: 60 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (98.00%) (7659/7808)
Epoch: 210 | Batch_idx: 70 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (98.00%) (8913/9088)
Epoch: 210 | Batch_idx: 80 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (98.00%) (10162/10368)
Epoch: 210 | Batch_idx: 90 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (98.00%) (11419/11648)
Epoch: 210 | Batch_idx: 100 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (98.00%) (12671/12928)
Epoch: 210 | Batch_idx: 110 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (13923/14208)
Epoch: 210 | Batch_idx: 120 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (15178/15488)
Epoch: 210 | Batch_idx: 130 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (16432/16768)
Epoch: 210 | Batch_idx: 140 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (17686/18048)
Epoch: 210 | Batch_idx: 150 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (18936/19328)
Epoch: 210 | Batch_idx: 160 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (20186/20608)
Epoch: 210 | Batch_idx: 170 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (21435/21888)
Epoch: 210 | Batch_idx: 180 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (22688/23168)
Epoch: 210 | Batch_idx: 190 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (23946/24448)
Epoch: 210 | Batch_idx: 200 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (25199/25728)
Epoch: 210 | Batch_idx: 210 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (26462/27008)
Epoch: 210 | Batch_idx: 220 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (27714/28288)
Epoch: 210 | Batch_idx: 230 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (28959/29568)
Epoch: 210 | Batch_idx: 240 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (30210/30848)
Epoch: 210 | Batch_idx: 250 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (31463/32128)
Epoch: 210 | Batch_idx: 260 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (32710/33408)
Epoch: 210 | Batch_idx: 270 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (33960/34688)
Epoch: 210 | Batch_idx: 280 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (35209/35968)
Epoch: 210 | Batch_idx: 290 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (36452/37248)
Epoch: 210 | Batch_idx: 300 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (37698/38528)
Epoch: 210 | Batch_idx: 310 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (38943/39808)
Epoch: 210 | Batch_idx: 320 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (40183/41088)
Epoch: 210 | Batch_idx: 330 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (41428/42368)
Epoch: 210 | Batch_idx: 340 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (42674/43648)
Epoch: 210 | Batch_idx: 350 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (43926/44928)
Epoch: 210 | Batch_idx: 360 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (45174/46208)
Epoch: 210 | Batch_idx: 370 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (46429/47488)
Epoch: 210 | Batch_idx: 380 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (47673/48768)
Epoch: 210 | Batch_idx: 390 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (48872/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_210.pth.tar'
# TEST : Loss: (0.4528) | Acc: (88.00%) (8800/10000)
percent tensor([0.5528, 0.5640, 0.5383, 0.5325, 0.5473, 0.5304, 0.5642, 0.5473, 0.5648,
        0.5614, 0.5650, 0.5550, 0.5602, 0.5650, 0.5465, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.4893, 0.4951, 0.4741, 0.4747, 0.4774, 0.4875, 0.4904, 0.4847, 0.4843,
        0.4859, 0.4918, 0.4732, 0.4956, 0.4905, 0.4847, 0.4924],
       device='cuda:0') torch.Size([16])
percent tensor([0.6101, 0.5358, 0.5723, 0.6414, 0.5855, 0.6639, 0.5541, 0.6127, 0.6059,
        0.5526, 0.5702, 0.5146, 0.5515, 0.6678, 0.5524, 0.6288],
       device='cuda:0') torch.Size([16])
percent tensor([0.6954, 0.7347, 0.6326, 0.6173, 0.6302, 0.6369, 0.7102, 0.6539, 0.6993,
        0.7316, 0.7383, 0.6647, 0.7334, 0.7231, 0.6858, 0.7061],
       device='cuda:0') torch.Size([16])
percent tensor([0.5781, 0.5628, 0.7493, 0.7645, 0.7787, 0.7269, 0.6526, 0.6390, 0.6927,
        0.5858, 0.6704, 0.7155, 0.5849, 0.6637, 0.6185, 0.5934],
       device='cuda:0') torch.Size([16])
percent tensor([0.7180, 0.7252, 0.7353, 0.7222, 0.7759, 0.7707, 0.7364, 0.6819, 0.7187,
        0.6843, 0.6738, 0.6684, 0.7146, 0.7241, 0.6635, 0.7480],
       device='cuda:0') torch.Size([16])
percent tensor([0.6743, 0.7913, 0.7173, 0.6612, 0.7260, 0.7972, 0.6803, 0.4965, 0.7803,
        0.6942, 0.7248, 0.7098, 0.7344, 0.7362, 0.5625, 0.6080],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9996, 0.9996, 0.9997, 0.9998, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9997, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(187.1633, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(835.4913, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(841.3380, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1512.2018, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(478.7861, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2292.5469, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4252.5186, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1344.5978, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6292.2886, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11512.5352, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3778.9092, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15923.0146, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 211 | Batch_idx: 0 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 211 | Batch_idx: 10 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 211 | Batch_idx: 20 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (2630/2688)
Epoch: 211 | Batch_idx: 30 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (3880/3968)
Epoch: 211 | Batch_idx: 40 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (5136/5248)
Epoch: 211 | Batch_idx: 50 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (6391/6528)
Epoch: 211 | Batch_idx: 60 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (7642/7808)
Epoch: 211 | Batch_idx: 70 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (8897/9088)
Epoch: 211 | Batch_idx: 80 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (10157/10368)
Epoch: 211 | Batch_idx: 90 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (11404/11648)
Epoch: 211 | Batch_idx: 100 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (12657/12928)
Epoch: 211 | Batch_idx: 110 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (13915/14208)
Epoch: 211 | Batch_idx: 120 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (15168/15488)
Epoch: 211 | Batch_idx: 130 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (16424/16768)
Epoch: 211 | Batch_idx: 140 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (17686/18048)
Epoch: 211 | Batch_idx: 150 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (18930/19328)
Epoch: 211 | Batch_idx: 160 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (20188/20608)
Epoch: 211 | Batch_idx: 170 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (21440/21888)
Epoch: 211 | Batch_idx: 180 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (22700/23168)
Epoch: 211 | Batch_idx: 190 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (23950/24448)
Epoch: 211 | Batch_idx: 200 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (25209/25728)
Epoch: 211 | Batch_idx: 210 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (26466/27008)
Epoch: 211 | Batch_idx: 220 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (27722/28288)
Epoch: 211 | Batch_idx: 230 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (28965/29568)
Epoch: 211 | Batch_idx: 240 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (30218/30848)
Epoch: 211 | Batch_idx: 250 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (31473/32128)
Epoch: 211 | Batch_idx: 260 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (32732/33408)
Epoch: 211 | Batch_idx: 270 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (33984/34688)
Epoch: 211 | Batch_idx: 280 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (35238/35968)
Epoch: 211 | Batch_idx: 290 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (36496/37248)
Epoch: 211 | Batch_idx: 300 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (37744/38528)
Epoch: 211 | Batch_idx: 310 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (38996/39808)
Epoch: 211 | Batch_idx: 320 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (40255/41088)
Epoch: 211 | Batch_idx: 330 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (41516/42368)
Epoch: 211 | Batch_idx: 340 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (42763/43648)
Epoch: 211 | Batch_idx: 350 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (44001/44928)
Epoch: 211 | Batch_idx: 360 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (45253/46208)
Epoch: 211 | Batch_idx: 370 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (46509/47488)
Epoch: 211 | Batch_idx: 380 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (47757/48768)
Epoch: 211 | Batch_idx: 390 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (48963/50000)
# TEST : Loss: (0.4527) | Acc: (88.00%) (8819/10000)
percent tensor([0.5520, 0.5593, 0.5419, 0.5318, 0.5497, 0.5296, 0.5615, 0.5467, 0.5630,
        0.5590, 0.5622, 0.5556, 0.5582, 0.5587, 0.5437, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.4910, 0.4957, 0.4788, 0.4759, 0.4818, 0.4900, 0.4928, 0.4866, 0.4861,
        0.4888, 0.4931, 0.4785, 0.4968, 0.4896, 0.4868, 0.4938],
       device='cuda:0') torch.Size([16])
percent tensor([0.5999, 0.5353, 0.5692, 0.6324, 0.5867, 0.6519, 0.5556, 0.6014, 0.6046,
        0.5470, 0.5637, 0.5193, 0.5434, 0.6675, 0.5437, 0.6181],
       device='cuda:0') torch.Size([16])
percent tensor([0.7016, 0.7354, 0.6378, 0.6226, 0.6389, 0.6504, 0.7134, 0.6587, 0.7042,
        0.7332, 0.7445, 0.6686, 0.7378, 0.7239, 0.6928, 0.7139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5862, 0.5828, 0.7481, 0.7567, 0.7757, 0.7370, 0.6598, 0.6428, 0.6928,
        0.5930, 0.6755, 0.6919, 0.5996, 0.6695, 0.6247, 0.6068],
       device='cuda:0') torch.Size([16])
percent tensor([0.7391, 0.7450, 0.7452, 0.7288, 0.7840, 0.7861, 0.7554, 0.6942, 0.7273,
        0.7124, 0.6892, 0.6853, 0.7286, 0.7396, 0.6865, 0.7671],
       device='cuda:0') torch.Size([16])
percent tensor([0.7148, 0.7966, 0.7220, 0.6302, 0.7262, 0.8121, 0.7025, 0.4946, 0.7787,
        0.7430, 0.7476, 0.7000, 0.7434, 0.7324, 0.5694, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9998, 0.9998, 0.9999, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 212 | Batch_idx: 0 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 212 | Batch_idx: 10 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 212 | Batch_idx: 20 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 212 | Batch_idx: 30 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (3891/3968)
Epoch: 212 | Batch_idx: 40 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (5155/5248)
Epoch: 212 | Batch_idx: 50 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (6413/6528)
Epoch: 212 | Batch_idx: 60 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (7669/7808)
Epoch: 212 | Batch_idx: 70 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (8919/9088)
Epoch: 212 | Batch_idx: 80 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (10163/10368)
Epoch: 212 | Batch_idx: 90 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (11421/11648)
Epoch: 212 | Batch_idx: 100 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (12676/12928)
Epoch: 212 | Batch_idx: 110 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (13930/14208)
Epoch: 212 | Batch_idx: 120 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (15181/15488)
Epoch: 212 | Batch_idx: 130 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (97.00%) (16425/16768)
Epoch: 212 | Batch_idx: 140 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (97.00%) (17684/18048)
Epoch: 212 | Batch_idx: 150 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (18934/19328)
Epoch: 212 | Batch_idx: 160 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (20179/20608)
Epoch: 212 | Batch_idx: 170 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (21430/21888)
Epoch: 212 | Batch_idx: 180 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (22689/23168)
Epoch: 212 | Batch_idx: 190 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (23948/24448)
Epoch: 212 | Batch_idx: 200 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (25206/25728)
Epoch: 212 | Batch_idx: 210 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (26460/27008)
Epoch: 212 | Batch_idx: 220 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (27713/28288)
Epoch: 212 | Batch_idx: 230 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (28965/29568)
Epoch: 212 | Batch_idx: 240 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (30220/30848)
Epoch: 212 | Batch_idx: 250 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (31473/32128)
Epoch: 212 | Batch_idx: 260 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (32717/33408)
Epoch: 212 | Batch_idx: 270 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (33970/34688)
Epoch: 212 | Batch_idx: 280 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (35204/35968)
Epoch: 212 | Batch_idx: 290 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (36447/37248)
Epoch: 212 | Batch_idx: 300 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (37693/38528)
Epoch: 212 | Batch_idx: 310 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (38944/39808)
Epoch: 212 | Batch_idx: 320 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (40197/41088)
Epoch: 212 | Batch_idx: 330 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (41446/42368)
Epoch: 212 | Batch_idx: 340 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (42697/43648)
Epoch: 212 | Batch_idx: 350 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (43941/44928)
Epoch: 212 | Batch_idx: 360 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (45190/46208)
Epoch: 212 | Batch_idx: 370 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (46443/47488)
Epoch: 212 | Batch_idx: 380 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (47691/48768)
Epoch: 212 | Batch_idx: 390 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (48896/50000)
# TEST : Loss: (0.4313) | Acc: (88.00%) (8837/10000)
percent tensor([0.5552, 0.5626, 0.5460, 0.5346, 0.5536, 0.5326, 0.5654, 0.5496, 0.5665,
        0.5625, 0.5653, 0.5599, 0.5612, 0.5613, 0.5468, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.4921, 0.4968, 0.4782, 0.4760, 0.4807, 0.4904, 0.4934, 0.4867, 0.4888,
        0.4893, 0.4952, 0.4781, 0.4983, 0.4931, 0.4873, 0.4949],
       device='cuda:0') torch.Size([16])
percent tensor([0.6035, 0.5276, 0.5732, 0.6294, 0.5845, 0.6585, 0.5494, 0.5999, 0.6050,
        0.5431, 0.5657, 0.5190, 0.5469, 0.6606, 0.5437, 0.6165],
       device='cuda:0') torch.Size([16])
percent tensor([0.6996, 0.7412, 0.6305, 0.6183, 0.6336, 0.6488, 0.7162, 0.6561, 0.7067,
        0.7369, 0.7455, 0.6683, 0.7408, 0.7239, 0.6946, 0.7105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5792, 0.5568, 0.7534, 0.7610, 0.7746, 0.7194, 0.6493, 0.6543, 0.6688,
        0.5678, 0.6531, 0.6981, 0.5773, 0.6407, 0.6149, 0.5860],
       device='cuda:0') torch.Size([16])
percent tensor([0.7164, 0.7251, 0.7244, 0.7166, 0.7627, 0.7776, 0.7363, 0.6728, 0.7062,
        0.6809, 0.6770, 0.6638, 0.7081, 0.7140, 0.6695, 0.7418],
       device='cuda:0') torch.Size([16])
percent tensor([0.6911, 0.7913, 0.7054, 0.6448, 0.6938, 0.7996, 0.6727, 0.4858, 0.7621,
        0.6931, 0.7337, 0.7060, 0.7153, 0.6974, 0.5643, 0.6114],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9996, 0.9997, 0.9999, 0.9998, 0.9995, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 213 | Batch_idx: 0 |  Loss: (0.0208) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 213 | Batch_idx: 10 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 213 | Batch_idx: 20 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (2646/2688)
Epoch: 213 | Batch_idx: 30 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (3906/3968)
Epoch: 213 | Batch_idx: 40 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (5154/5248)
Epoch: 213 | Batch_idx: 50 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (6414/6528)
Epoch: 213 | Batch_idx: 60 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (7667/7808)
Epoch: 213 | Batch_idx: 70 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (8932/9088)
Epoch: 213 | Batch_idx: 80 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (10183/10368)
Epoch: 213 | Batch_idx: 90 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (11435/11648)
Epoch: 213 | Batch_idx: 100 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (12681/12928)
Epoch: 213 | Batch_idx: 110 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (13928/14208)
Epoch: 213 | Batch_idx: 120 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (15177/15488)
Epoch: 213 | Batch_idx: 130 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (16425/16768)
Epoch: 213 | Batch_idx: 140 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (17683/18048)
Epoch: 213 | Batch_idx: 150 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (18937/19328)
Epoch: 213 | Batch_idx: 160 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (20194/20608)
Epoch: 213 | Batch_idx: 170 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (21449/21888)
Epoch: 213 | Batch_idx: 180 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (22705/23168)
Epoch: 213 | Batch_idx: 190 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (23968/24448)
Epoch: 213 | Batch_idx: 200 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (25226/25728)
Epoch: 213 | Batch_idx: 210 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (26477/27008)
Epoch: 213 | Batch_idx: 220 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (27732/28288)
Epoch: 213 | Batch_idx: 230 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (28981/29568)
Epoch: 213 | Batch_idx: 240 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (30240/30848)
Epoch: 213 | Batch_idx: 250 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (31494/32128)
Epoch: 213 | Batch_idx: 260 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (32753/33408)
Epoch: 213 | Batch_idx: 270 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (34000/34688)
Epoch: 213 | Batch_idx: 280 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (35246/35968)
Epoch: 213 | Batch_idx: 290 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (36509/37248)
Epoch: 213 | Batch_idx: 300 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (37764/38528)
Epoch: 213 | Batch_idx: 310 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (39017/39808)
Epoch: 213 | Batch_idx: 320 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (40274/41088)
Epoch: 213 | Batch_idx: 330 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (41519/42368)
Epoch: 213 | Batch_idx: 340 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (98.00%) (42779/43648)
Epoch: 213 | Batch_idx: 350 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (44038/44928)
Epoch: 213 | Batch_idx: 360 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (45293/46208)
Epoch: 213 | Batch_idx: 370 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (46536/47488)
Epoch: 213 | Batch_idx: 380 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (47787/48768)
Epoch: 213 | Batch_idx: 390 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (48991/50000)
# TEST : Loss: (0.4158) | Acc: (88.00%) (8887/10000)
percent tensor([0.5532, 0.5596, 0.5453, 0.5328, 0.5522, 0.5309, 0.5628, 0.5475, 0.5642,
        0.5601, 0.5628, 0.5585, 0.5588, 0.5582, 0.5446, 0.5491],
       device='cuda:0') torch.Size([16])
percent tensor([0.4940, 0.4993, 0.4775, 0.4769, 0.4816, 0.4921, 0.4951, 0.4876, 0.4894,
        0.4911, 0.4972, 0.4795, 0.5003, 0.4945, 0.4894, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.6013, 0.5306, 0.5661, 0.6320, 0.5846, 0.6614, 0.5499, 0.6019, 0.5953,
        0.5444, 0.5596, 0.5219, 0.5470, 0.6570, 0.5461, 0.6168],
       device='cuda:0') torch.Size([16])
percent tensor([0.6946, 0.7386, 0.6335, 0.6143, 0.6311, 0.6388, 0.7114, 0.6540, 0.7044,
        0.7332, 0.7436, 0.6674, 0.7335, 0.7239, 0.6914, 0.7071],
       device='cuda:0') torch.Size([16])
percent tensor([0.5898, 0.5645, 0.7736, 0.7706, 0.7952, 0.7352, 0.6690, 0.6678, 0.6942,
        0.5700, 0.6700, 0.7071, 0.5933, 0.6486, 0.6180, 0.6047],
       device='cuda:0') torch.Size([16])
percent tensor([0.7260, 0.7403, 0.7442, 0.7277, 0.7842, 0.7806, 0.7542, 0.6856, 0.7218,
        0.7047, 0.6835, 0.6920, 0.7265, 0.7209, 0.6758, 0.7578],
       device='cuda:0') torch.Size([16])
percent tensor([0.6895, 0.7854, 0.7107, 0.6454, 0.7418, 0.8087, 0.7056, 0.5020, 0.7830,
        0.7146, 0.7372, 0.7361, 0.7335, 0.7062, 0.5467, 0.6287],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9998, 0.9999, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 214 | Batch_idx: 0 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 214 | Batch_idx: 10 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 214 | Batch_idx: 20 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 214 | Batch_idx: 30 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (3904/3968)
Epoch: 214 | Batch_idx: 40 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (5168/5248)
Epoch: 214 | Batch_idx: 50 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (6424/6528)
Epoch: 214 | Batch_idx: 60 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (7690/7808)
Epoch: 214 | Batch_idx: 70 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (8949/9088)
Epoch: 214 | Batch_idx: 80 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (10206/10368)
Epoch: 214 | Batch_idx: 90 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (11471/11648)
Epoch: 214 | Batch_idx: 100 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (12732/12928)
Epoch: 214 | Batch_idx: 110 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (13992/14208)
Epoch: 214 | Batch_idx: 120 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (15250/15488)
Epoch: 214 | Batch_idx: 130 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (16505/16768)
Epoch: 214 | Batch_idx: 140 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (17758/18048)
Epoch: 214 | Batch_idx: 150 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (19011/19328)
Epoch: 214 | Batch_idx: 160 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (20257/20608)
Epoch: 214 | Batch_idx: 170 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (21510/21888)
Epoch: 214 | Batch_idx: 180 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (22767/23168)
Epoch: 214 | Batch_idx: 190 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (24037/24448)
Epoch: 214 | Batch_idx: 200 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (25296/25728)
Epoch: 214 | Batch_idx: 210 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (26555/27008)
Epoch: 214 | Batch_idx: 220 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (27810/28288)
Epoch: 214 | Batch_idx: 230 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (29068/29568)
Epoch: 214 | Batch_idx: 240 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (30327/30848)
Epoch: 214 | Batch_idx: 250 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (31583/32128)
Epoch: 214 | Batch_idx: 260 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (32833/33408)
Epoch: 214 | Batch_idx: 270 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (34083/34688)
Epoch: 214 | Batch_idx: 280 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (35337/35968)
Epoch: 214 | Batch_idx: 290 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (36582/37248)
Epoch: 214 | Batch_idx: 300 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (37833/38528)
Epoch: 214 | Batch_idx: 310 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (39085/39808)
Epoch: 214 | Batch_idx: 320 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (40339/41088)
Epoch: 214 | Batch_idx: 330 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (41589/42368)
Epoch: 214 | Batch_idx: 340 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (42841/43648)
Epoch: 214 | Batch_idx: 350 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (44092/44928)
Epoch: 214 | Batch_idx: 360 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (45338/46208)
Epoch: 214 | Batch_idx: 370 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (46589/47488)
Epoch: 214 | Batch_idx: 380 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (47835/48768)
Epoch: 214 | Batch_idx: 390 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (49044/50000)
# TEST : Loss: (0.4559) | Acc: (88.00%) (8828/10000)
percent tensor([0.5551, 0.5642, 0.5419, 0.5343, 0.5511, 0.5327, 0.5653, 0.5482, 0.5658,
        0.5621, 0.5656, 0.5582, 0.5611, 0.5643, 0.5475, 0.5517],
       device='cuda:0') torch.Size([16])
percent tensor([0.4913, 0.4978, 0.4744, 0.4758, 0.4790, 0.4896, 0.4935, 0.4859, 0.4863,
        0.4898, 0.4950, 0.4767, 0.4975, 0.4932, 0.4877, 0.4945],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.5344, 0.5756, 0.6410, 0.5906, 0.6670, 0.5561, 0.6121, 0.6079,
        0.5505, 0.5731, 0.5245, 0.5524, 0.6682, 0.5488, 0.6256],
       device='cuda:0') torch.Size([16])
percent tensor([0.6952, 0.7374, 0.6345, 0.6185, 0.6333, 0.6392, 0.7097, 0.6561, 0.6991,
        0.7319, 0.7343, 0.6672, 0.7301, 0.7202, 0.6914, 0.7072],
       device='cuda:0') torch.Size([16])
percent tensor([0.6003, 0.5773, 0.7563, 0.7684, 0.7849, 0.7487, 0.6672, 0.6462, 0.7097,
        0.5924, 0.7030, 0.7200, 0.6259, 0.6577, 0.6284, 0.6137],
       device='cuda:0') torch.Size([16])
percent tensor([0.7265, 0.7443, 0.7246, 0.7179, 0.7799, 0.7841, 0.7464, 0.6762, 0.7277,
        0.7129, 0.6894, 0.6784, 0.7269, 0.7328, 0.6714, 0.7540],
       device='cuda:0') torch.Size([16])
percent tensor([0.7022, 0.8001, 0.6869, 0.6391, 0.7289, 0.8125, 0.7176, 0.4920, 0.7912,
        0.7438, 0.7487, 0.7530, 0.7494, 0.7661, 0.5586, 0.6223],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9997, 0.9998, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 215 | Batch_idx: 0 |  Loss: (0.0176) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 215 | Batch_idx: 10 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 215 | Batch_idx: 20 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 215 | Batch_idx: 30 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (3894/3968)
Epoch: 215 | Batch_idx: 40 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (5147/5248)
Epoch: 215 | Batch_idx: 50 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (6405/6528)
Epoch: 215 | Batch_idx: 60 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (7652/7808)
Epoch: 215 | Batch_idx: 70 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (8906/9088)
Epoch: 215 | Batch_idx: 80 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (10170/10368)
Epoch: 215 | Batch_idx: 90 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (11422/11648)
Epoch: 215 | Batch_idx: 100 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (12671/12928)
Epoch: 215 | Batch_idx: 110 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (13927/14208)
Epoch: 215 | Batch_idx: 120 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (15186/15488)
Epoch: 215 | Batch_idx: 130 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (16442/16768)
Epoch: 215 | Batch_idx: 140 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (17701/18048)
Epoch: 215 | Batch_idx: 150 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (18959/19328)
Epoch: 215 | Batch_idx: 160 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (20220/20608)
Epoch: 215 | Batch_idx: 170 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (21476/21888)
Epoch: 215 | Batch_idx: 180 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (22731/23168)
Epoch: 215 | Batch_idx: 190 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (23983/24448)
Epoch: 215 | Batch_idx: 200 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (25241/25728)
Epoch: 215 | Batch_idx: 210 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (26494/27008)
Epoch: 215 | Batch_idx: 220 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (27752/28288)
Epoch: 215 | Batch_idx: 230 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (29003/29568)
Epoch: 215 | Batch_idx: 240 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (30257/30848)
Epoch: 215 | Batch_idx: 250 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (31514/32128)
Epoch: 215 | Batch_idx: 260 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (32772/33408)
Epoch: 215 | Batch_idx: 270 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (34034/34688)
Epoch: 215 | Batch_idx: 280 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (35285/35968)
Epoch: 215 | Batch_idx: 290 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (36540/37248)
Epoch: 215 | Batch_idx: 300 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (37790/38528)
Epoch: 215 | Batch_idx: 310 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (39049/39808)
Epoch: 215 | Batch_idx: 320 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (40305/41088)
Epoch: 215 | Batch_idx: 330 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (41561/42368)
Epoch: 215 | Batch_idx: 340 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (42825/43648)
Epoch: 215 | Batch_idx: 350 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (44080/44928)
Epoch: 215 | Batch_idx: 360 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (45338/46208)
Epoch: 215 | Batch_idx: 370 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (46599/47488)
Epoch: 215 | Batch_idx: 380 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (47850/48768)
Epoch: 215 | Batch_idx: 390 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (49059/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_215.pth.tar'
# TEST : Loss: (0.4207) | Acc: (88.00%) (8884/10000)
percent tensor([0.5541, 0.5642, 0.5420, 0.5344, 0.5496, 0.5313, 0.5649, 0.5492, 0.5660,
        0.5624, 0.5657, 0.5575, 0.5614, 0.5651, 0.5467, 0.5511],
       device='cuda:0') torch.Size([16])
percent tensor([0.4933, 0.4995, 0.4795, 0.4779, 0.4817, 0.4916, 0.4947, 0.4892, 0.4885,
        0.4912, 0.4965, 0.4797, 0.4996, 0.4937, 0.4899, 0.4968],
       device='cuda:0') torch.Size([16])
percent tensor([0.6052, 0.5341, 0.5755, 0.6386, 0.5845, 0.6616, 0.5496, 0.6133, 0.6089,
        0.5495, 0.5717, 0.5151, 0.5474, 0.6714, 0.5472, 0.6236],
       device='cuda:0') torch.Size([16])
percent tensor([0.6937, 0.7394, 0.6316, 0.6138, 0.6307, 0.6356, 0.7128, 0.6545, 0.7005,
        0.7305, 0.7363, 0.6664, 0.7322, 0.7229, 0.6894, 0.7037],
       device='cuda:0') torch.Size([16])
percent tensor([0.5776, 0.5481, 0.7419, 0.7583, 0.7689, 0.7320, 0.6497, 0.6473, 0.6823,
        0.5676, 0.6627, 0.6831, 0.5873, 0.6445, 0.6087, 0.6067],
       device='cuda:0') torch.Size([16])
percent tensor([0.7335, 0.7489, 0.7380, 0.7218, 0.7823, 0.7797, 0.7501, 0.6959, 0.7231,
        0.7096, 0.6920, 0.6751, 0.7265, 0.7230, 0.6758, 0.7695],
       device='cuda:0') torch.Size([16])
percent tensor([0.6805, 0.8090, 0.7307, 0.6269, 0.7339, 0.7870, 0.7013, 0.5262, 0.7758,
        0.7261, 0.7458, 0.7258, 0.7384, 0.7215, 0.5456, 0.6580],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9997, 0.9998, 0.9999, 0.9997, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 216 | Batch_idx: 0 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 216 | Batch_idx: 10 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 216 | Batch_idx: 20 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (2636/2688)
Epoch: 216 | Batch_idx: 30 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (3892/3968)
Epoch: 216 | Batch_idx: 40 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (5148/5248)
Epoch: 216 | Batch_idx: 50 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (6405/6528)
Epoch: 216 | Batch_idx: 60 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (7669/7808)
Epoch: 216 | Batch_idx: 70 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (8927/9088)
Epoch: 216 | Batch_idx: 80 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (10176/10368)
Epoch: 216 | Batch_idx: 90 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (11437/11648)
Epoch: 216 | Batch_idx: 100 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (12690/12928)
Epoch: 216 | Batch_idx: 110 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (13939/14208)
Epoch: 216 | Batch_idx: 120 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (15192/15488)
Epoch: 216 | Batch_idx: 130 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (16448/16768)
Epoch: 216 | Batch_idx: 140 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (17697/18048)
Epoch: 216 | Batch_idx: 150 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (18955/19328)
Epoch: 216 | Batch_idx: 160 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (20215/20608)
Epoch: 216 | Batch_idx: 170 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (21462/21888)
Epoch: 216 | Batch_idx: 180 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (22709/23168)
Epoch: 216 | Batch_idx: 190 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (97.00%) (23959/24448)
Epoch: 216 | Batch_idx: 200 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (25218/25728)
Epoch: 216 | Batch_idx: 210 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (26477/27008)
Epoch: 216 | Batch_idx: 220 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (27729/28288)
Epoch: 216 | Batch_idx: 230 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (28983/29568)
Epoch: 216 | Batch_idx: 240 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (30242/30848)
Epoch: 216 | Batch_idx: 250 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (31492/32128)
Epoch: 216 | Batch_idx: 260 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (32745/33408)
Epoch: 216 | Batch_idx: 270 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (34002/34688)
Epoch: 216 | Batch_idx: 280 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (97.00%) (35247/35968)
Epoch: 216 | Batch_idx: 290 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (36495/37248)
Epoch: 216 | Batch_idx: 300 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (97.00%) (37752/38528)
Epoch: 216 | Batch_idx: 310 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (97.00%) (39010/39808)
Epoch: 216 | Batch_idx: 320 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (40255/41088)
Epoch: 216 | Batch_idx: 330 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (41508/42368)
Epoch: 216 | Batch_idx: 340 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (42754/43648)
Epoch: 216 | Batch_idx: 350 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (44007/44928)
Epoch: 216 | Batch_idx: 360 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (45260/46208)
Epoch: 216 | Batch_idx: 370 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (46519/47488)
Epoch: 216 | Batch_idx: 380 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (47765/48768)
Epoch: 216 | Batch_idx: 390 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (48963/50000)
# TEST : Loss: (0.4361) | Acc: (88.00%) (8867/10000)
percent tensor([0.5542, 0.5616, 0.5452, 0.5340, 0.5526, 0.5312, 0.5642, 0.5491, 0.5662,
        0.5619, 0.5650, 0.5596, 0.5610, 0.5599, 0.5460, 0.5503],
       device='cuda:0') torch.Size([16])
percent tensor([0.4935, 0.4994, 0.4796, 0.4782, 0.4824, 0.4909, 0.4955, 0.4890, 0.4896,
        0.4920, 0.4977, 0.4809, 0.5002, 0.4937, 0.4898, 0.4969],
       device='cuda:0') torch.Size([16])
percent tensor([0.5998, 0.5322, 0.5702, 0.6365, 0.5865, 0.6588, 0.5522, 0.6088, 0.6056,
        0.5457, 0.5673, 0.5194, 0.5444, 0.6661, 0.5495, 0.6200],
       device='cuda:0') torch.Size([16])
percent tensor([0.6989, 0.7394, 0.6374, 0.6220, 0.6375, 0.6464, 0.7143, 0.6582, 0.7002,
        0.7351, 0.7411, 0.6687, 0.7339, 0.7261, 0.6934, 0.7107],
       device='cuda:0') torch.Size([16])
percent tensor([0.5864, 0.5617, 0.7517, 0.7666, 0.7768, 0.7424, 0.6407, 0.6408, 0.7018,
        0.5795, 0.6771, 0.7002, 0.5921, 0.6688, 0.6201, 0.6088],
       device='cuda:0') torch.Size([16])
percent tensor([0.7326, 0.7470, 0.7332, 0.7144, 0.7762, 0.7818, 0.7566, 0.6829, 0.7288,
        0.7051, 0.6947, 0.6878, 0.7265, 0.7251, 0.6724, 0.7610],
       device='cuda:0') torch.Size([16])
percent tensor([0.6748, 0.8089, 0.6603, 0.5913, 0.6881, 0.7890, 0.7093, 0.4601, 0.7798,
        0.7083, 0.7428, 0.7252, 0.7386, 0.7022, 0.5445, 0.6189],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 217 | Batch_idx: 0 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 217 | Batch_idx: 10 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 217 | Batch_idx: 20 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (2644/2688)
Epoch: 217 | Batch_idx: 30 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (3906/3968)
Epoch: 217 | Batch_idx: 40 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (5166/5248)
Epoch: 217 | Batch_idx: 50 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (6422/6528)
Epoch: 217 | Batch_idx: 60 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (7685/7808)
Epoch: 217 | Batch_idx: 70 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (8947/9088)
Epoch: 217 | Batch_idx: 80 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (10199/10368)
Epoch: 217 | Batch_idx: 90 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (11455/11648)
Epoch: 217 | Batch_idx: 100 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (12715/12928)
Epoch: 217 | Batch_idx: 110 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (13975/14208)
Epoch: 217 | Batch_idx: 120 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (15233/15488)
Epoch: 217 | Batch_idx: 130 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (16498/16768)
Epoch: 217 | Batch_idx: 140 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (17757/18048)
Epoch: 217 | Batch_idx: 150 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (19014/19328)
Epoch: 217 | Batch_idx: 160 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (20268/20608)
Epoch: 217 | Batch_idx: 170 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (21525/21888)
Epoch: 217 | Batch_idx: 180 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (22779/23168)
Epoch: 217 | Batch_idx: 190 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (24033/24448)
Epoch: 217 | Batch_idx: 200 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (25291/25728)
Epoch: 217 | Batch_idx: 210 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (26550/27008)
Epoch: 217 | Batch_idx: 220 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (27803/28288)
Epoch: 217 | Batch_idx: 230 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (29064/29568)
Epoch: 217 | Batch_idx: 240 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (30324/30848)
Epoch: 217 | Batch_idx: 250 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (31577/32128)
Epoch: 217 | Batch_idx: 260 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (32838/33408)
Epoch: 217 | Batch_idx: 270 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (34095/34688)
Epoch: 217 | Batch_idx: 280 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (35345/35968)
Epoch: 217 | Batch_idx: 290 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (36602/37248)
Epoch: 217 | Batch_idx: 300 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (37854/38528)
Epoch: 217 | Batch_idx: 310 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (39099/39808)
Epoch: 217 | Batch_idx: 320 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (40346/41088)
Epoch: 217 | Batch_idx: 330 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (41600/42368)
Epoch: 217 | Batch_idx: 340 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (42855/43648)
Epoch: 217 | Batch_idx: 350 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (44110/44928)
Epoch: 217 | Batch_idx: 360 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (45365/46208)
Epoch: 217 | Batch_idx: 370 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (46620/47488)
Epoch: 217 | Batch_idx: 380 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (47867/48768)
Epoch: 217 | Batch_idx: 390 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (49077/50000)
# TEST : Loss: (0.4183) | Acc: (88.00%) (8880/10000)
percent tensor([0.5532, 0.5630, 0.5413, 0.5332, 0.5489, 0.5306, 0.5640, 0.5475, 0.5657,
        0.5610, 0.5649, 0.5566, 0.5602, 0.5636, 0.5457, 0.5504],
       device='cuda:0') torch.Size([16])
percent tensor([0.4924, 0.4993, 0.4784, 0.4778, 0.4818, 0.4913, 0.4950, 0.4881, 0.4870,
        0.4903, 0.4953, 0.4791, 0.4985, 0.4944, 0.4891, 0.4961],
       device='cuda:0') torch.Size([16])
percent tensor([0.6133, 0.5366, 0.5778, 0.6433, 0.5930, 0.6733, 0.5558, 0.6054, 0.6109,
        0.5511, 0.5732, 0.5244, 0.5540, 0.6729, 0.5559, 0.6278],
       device='cuda:0') torch.Size([16])
percent tensor([0.6964, 0.7415, 0.6314, 0.6187, 0.6325, 0.6453, 0.7167, 0.6573, 0.7039,
        0.7354, 0.7395, 0.6680, 0.7364, 0.7288, 0.6938, 0.7111],
       device='cuda:0') torch.Size([16])
percent tensor([0.5914, 0.5629, 0.7484, 0.7541, 0.7740, 0.7255, 0.6396, 0.6299, 0.7106,
        0.5883, 0.6937, 0.7000, 0.5959, 0.6567, 0.6181, 0.5977],
       device='cuda:0') torch.Size([16])
percent tensor([0.7354, 0.7400, 0.7351, 0.7216, 0.7789, 0.7789, 0.7518, 0.6850, 0.7309,
        0.7106, 0.6949, 0.6932, 0.7265, 0.7331, 0.6775, 0.7542],
       device='cuda:0') torch.Size([16])
percent tensor([0.6943, 0.7972, 0.7043, 0.6135, 0.7130, 0.7886, 0.7005, 0.4792, 0.7860,
        0.7231, 0.7370, 0.7415, 0.7393, 0.7195, 0.5361, 0.6111],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 218 | Batch_idx: 0 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 218 | Batch_idx: 10 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 218 | Batch_idx: 20 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 218 | Batch_idx: 30 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (3899/3968)
Epoch: 218 | Batch_idx: 40 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (5155/5248)
Epoch: 218 | Batch_idx: 50 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (6412/6528)
Epoch: 218 | Batch_idx: 60 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (7673/7808)
Epoch: 218 | Batch_idx: 70 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (8941/9088)
Epoch: 218 | Batch_idx: 80 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (10197/10368)
Epoch: 218 | Batch_idx: 90 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (11454/11648)
Epoch: 218 | Batch_idx: 100 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (12714/12928)
Epoch: 218 | Batch_idx: 110 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (13972/14208)
Epoch: 218 | Batch_idx: 120 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (15238/15488)
Epoch: 218 | Batch_idx: 130 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (16491/16768)
Epoch: 218 | Batch_idx: 140 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (17754/18048)
Epoch: 218 | Batch_idx: 150 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (19014/19328)
Epoch: 218 | Batch_idx: 160 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (20277/20608)
Epoch: 218 | Batch_idx: 170 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (21532/21888)
Epoch: 218 | Batch_idx: 180 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (22784/23168)
Epoch: 218 | Batch_idx: 190 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (24041/24448)
Epoch: 218 | Batch_idx: 200 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (25294/25728)
Epoch: 218 | Batch_idx: 210 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (26552/27008)
Epoch: 218 | Batch_idx: 220 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (27809/28288)
Epoch: 218 | Batch_idx: 230 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (29059/29568)
Epoch: 218 | Batch_idx: 240 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (30310/30848)
Epoch: 218 | Batch_idx: 250 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (31565/32128)
Epoch: 218 | Batch_idx: 260 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (32826/33408)
Epoch: 218 | Batch_idx: 270 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (34082/34688)
Epoch: 218 | Batch_idx: 280 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (35340/35968)
Epoch: 218 | Batch_idx: 290 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (36606/37248)
Epoch: 218 | Batch_idx: 300 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (37853/38528)
Epoch: 218 | Batch_idx: 310 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (39105/39808)
Epoch: 218 | Batch_idx: 320 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (40358/41088)
Epoch: 218 | Batch_idx: 330 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (41623/42368)
Epoch: 218 | Batch_idx: 340 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (42878/43648)
Epoch: 218 | Batch_idx: 350 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (44134/44928)
Epoch: 218 | Batch_idx: 360 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (45391/46208)
Epoch: 218 | Batch_idx: 370 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (46654/47488)
Epoch: 218 | Batch_idx: 380 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (47914/48768)
Epoch: 218 | Batch_idx: 390 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (49116/50000)
# TEST : Loss: (0.4519) | Acc: (88.00%) (8826/10000)
percent tensor([0.5541, 0.5627, 0.5397, 0.5331, 0.5493, 0.5306, 0.5640, 0.5469, 0.5657,
        0.5612, 0.5653, 0.5570, 0.5609, 0.5636, 0.5458, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.4931, 0.4999, 0.4770, 0.4778, 0.4807, 0.4914, 0.4946, 0.4892, 0.4878,
        0.4912, 0.4963, 0.4781, 0.4998, 0.4942, 0.4903, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.6037, 0.5315, 0.5607, 0.6303, 0.5800, 0.6668, 0.5472, 0.6074, 0.6090,
        0.5467, 0.5715, 0.5091, 0.5493, 0.6682, 0.5515, 0.6222],
       device='cuda:0') torch.Size([16])
percent tensor([0.7049, 0.7424, 0.6449, 0.6286, 0.6466, 0.6502, 0.7216, 0.6656, 0.7064,
        0.7397, 0.7488, 0.6773, 0.7423, 0.7263, 0.6994, 0.7168],
       device='cuda:0') torch.Size([16])
percent tensor([0.5905, 0.5711, 0.7374, 0.7468, 0.7647, 0.7394, 0.6494, 0.6388, 0.7031,
        0.5883, 0.6853, 0.6892, 0.5945, 0.6661, 0.6256, 0.6047],
       device='cuda:0') torch.Size([16])
percent tensor([0.7275, 0.7315, 0.7397, 0.7181, 0.7823, 0.7874, 0.7438, 0.6885, 0.7219,
        0.7002, 0.6778, 0.6716, 0.7174, 0.7236, 0.6725, 0.7644],
       device='cuda:0') torch.Size([16])
percent tensor([0.6848, 0.7933, 0.7242, 0.6001, 0.7319, 0.8130, 0.6896, 0.5212, 0.7725,
        0.7329, 0.7221, 0.7134, 0.7246, 0.7047, 0.5559, 0.6641],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9997, 0.9999, 0.9998, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 219 | Batch_idx: 0 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 219 | Batch_idx: 10 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 219 | Batch_idx: 20 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 219 | Batch_idx: 30 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (3908/3968)
Epoch: 219 | Batch_idx: 40 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (5159/5248)
Epoch: 219 | Batch_idx: 50 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (6414/6528)
Epoch: 219 | Batch_idx: 60 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (7671/7808)
Epoch: 219 | Batch_idx: 70 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (8930/9088)
Epoch: 219 | Batch_idx: 80 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (10189/10368)
Epoch: 219 | Batch_idx: 90 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (11451/11648)
Epoch: 219 | Batch_idx: 100 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (12712/12928)
Epoch: 219 | Batch_idx: 110 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (13970/14208)
Epoch: 219 | Batch_idx: 120 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (15235/15488)
Epoch: 219 | Batch_idx: 130 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (16491/16768)
Epoch: 219 | Batch_idx: 140 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (17751/18048)
Epoch: 219 | Batch_idx: 150 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (19005/19328)
Epoch: 219 | Batch_idx: 160 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (20269/20608)
Epoch: 219 | Batch_idx: 170 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (21529/21888)
Epoch: 219 | Batch_idx: 180 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (22787/23168)
Epoch: 219 | Batch_idx: 190 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (24031/24448)
Epoch: 219 | Batch_idx: 200 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (25290/25728)
Epoch: 219 | Batch_idx: 210 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (26546/27008)
Epoch: 219 | Batch_idx: 220 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (27800/28288)
Epoch: 219 | Batch_idx: 230 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (29056/29568)
Epoch: 219 | Batch_idx: 240 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (30306/30848)
Epoch: 219 | Batch_idx: 250 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (31565/32128)
Epoch: 219 | Batch_idx: 260 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (32820/33408)
Epoch: 219 | Batch_idx: 270 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (34074/34688)
Epoch: 219 | Batch_idx: 280 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (35329/35968)
Epoch: 219 | Batch_idx: 290 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (36589/37248)
Epoch: 219 | Batch_idx: 300 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (37843/38528)
Epoch: 219 | Batch_idx: 310 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (39099/39808)
Epoch: 219 | Batch_idx: 320 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (40361/41088)
Epoch: 219 | Batch_idx: 330 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (41613/42368)
Epoch: 219 | Batch_idx: 340 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (42872/43648)
Epoch: 219 | Batch_idx: 350 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (44131/44928)
Epoch: 219 | Batch_idx: 360 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (45393/46208)
Epoch: 219 | Batch_idx: 370 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (46656/47488)
Epoch: 219 | Batch_idx: 380 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (47900/48768)
Epoch: 219 | Batch_idx: 390 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (49113/50000)
# TEST : Loss: (0.4597) | Acc: (88.00%) (8817/10000)
percent tensor([0.5529, 0.5642, 0.5386, 0.5338, 0.5478, 0.5299, 0.5640, 0.5480, 0.5650,
        0.5616, 0.5649, 0.5552, 0.5604, 0.5661, 0.5464, 0.5511],
       device='cuda:0') torch.Size([16])
percent tensor([0.4938, 0.4990, 0.4805, 0.4798, 0.4835, 0.4933, 0.4950, 0.4895, 0.4892,
        0.4913, 0.4962, 0.4805, 0.4997, 0.4948, 0.4902, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.6090, 0.5311, 0.5916, 0.6459, 0.6043, 0.6738, 0.5571, 0.6150, 0.6112,
        0.5497, 0.5697, 0.5352, 0.5498, 0.6670, 0.5533, 0.6272],
       device='cuda:0') torch.Size([16])
percent tensor([0.6997, 0.7395, 0.6267, 0.6155, 0.6322, 0.6426, 0.7170, 0.6581, 0.7030,
        0.7360, 0.7471, 0.6636, 0.7380, 0.7221, 0.6925, 0.7129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5851, 0.5748, 0.7561, 0.7734, 0.7899, 0.7345, 0.6641, 0.6521, 0.7080,
        0.5787, 0.6802, 0.7134, 0.5946, 0.6679, 0.6288, 0.6014],
       device='cuda:0') torch.Size([16])
percent tensor([0.7328, 0.7397, 0.7439, 0.7225, 0.7842, 0.7830, 0.7527, 0.6906, 0.7226,
        0.7091, 0.6912, 0.6961, 0.7316, 0.7230, 0.6798, 0.7633],
       device='cuda:0') torch.Size([16])
percent tensor([0.6941, 0.7947, 0.7248, 0.6363, 0.7270, 0.7966, 0.6933, 0.5054, 0.7802,
        0.7454, 0.7177, 0.7383, 0.7461, 0.7101, 0.5665, 0.6394],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9997, 0.9997, 0.9998, 0.9999, 0.9997, 0.9999,
        1.0000, 1.0000, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 220 | Batch_idx: 0 |  Loss: (0.0249) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 220 | Batch_idx: 10 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 220 | Batch_idx: 20 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (2654/2688)
Epoch: 220 | Batch_idx: 30 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 220 | Batch_idx: 40 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (5178/5248)
Epoch: 220 | Batch_idx: 50 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (6438/6528)
Epoch: 220 | Batch_idx: 60 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (7699/7808)
Epoch: 220 | Batch_idx: 70 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (8958/9088)
Epoch: 220 | Batch_idx: 80 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (10214/10368)
Epoch: 220 | Batch_idx: 90 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (11463/11648)
Epoch: 220 | Batch_idx: 100 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (12729/12928)
Epoch: 220 | Batch_idx: 110 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (13982/14208)
Epoch: 220 | Batch_idx: 120 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (15246/15488)
Epoch: 220 | Batch_idx: 130 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (16501/16768)
Epoch: 220 | Batch_idx: 140 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (17760/18048)
Epoch: 220 | Batch_idx: 150 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (19019/19328)
Epoch: 220 | Batch_idx: 160 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (20280/20608)
Epoch: 220 | Batch_idx: 170 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (21533/21888)
Epoch: 220 | Batch_idx: 180 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (22795/23168)
Epoch: 220 | Batch_idx: 190 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (24058/24448)
Epoch: 220 | Batch_idx: 200 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (25313/25728)
Epoch: 220 | Batch_idx: 210 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (26561/27008)
Epoch: 220 | Batch_idx: 220 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (27822/28288)
Epoch: 220 | Batch_idx: 230 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (29086/29568)
Epoch: 220 | Batch_idx: 240 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (30338/30848)
Epoch: 220 | Batch_idx: 250 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (31595/32128)
Epoch: 220 | Batch_idx: 260 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (32860/33408)
Epoch: 220 | Batch_idx: 270 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (34110/34688)
Epoch: 220 | Batch_idx: 280 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (35356/35968)
Epoch: 220 | Batch_idx: 290 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (36611/37248)
Epoch: 220 | Batch_idx: 300 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (37859/38528)
Epoch: 220 | Batch_idx: 310 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (39124/39808)
Epoch: 220 | Batch_idx: 320 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (40385/41088)
Epoch: 220 | Batch_idx: 330 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (41645/42368)
Epoch: 220 | Batch_idx: 340 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (42905/43648)
Epoch: 220 | Batch_idx: 350 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (44160/44928)
Epoch: 220 | Batch_idx: 360 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (45421/46208)
Epoch: 220 | Batch_idx: 370 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (46688/47488)
Epoch: 220 | Batch_idx: 380 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (47947/48768)
Epoch: 220 | Batch_idx: 390 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (49160/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_220.pth.tar'
# TEST : Loss: (0.4375) | Acc: (88.00%) (8842/10000)
percent tensor([0.5568, 0.5651, 0.5446, 0.5359, 0.5532, 0.5330, 0.5670, 0.5504, 0.5677,
        0.5644, 0.5673, 0.5606, 0.5630, 0.5650, 0.5486, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.4950, 0.5001, 0.4784, 0.4811, 0.4816, 0.4935, 0.4953, 0.4900, 0.4885,
        0.4923, 0.4972, 0.4800, 0.5013, 0.4944, 0.4913, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.5273, 0.5697, 0.6414, 0.5831, 0.6667, 0.5459, 0.6143, 0.6092,
        0.5467, 0.5731, 0.5183, 0.5501, 0.6686, 0.5505, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.7060, 0.7424, 0.6364, 0.6243, 0.6376, 0.6462, 0.7215, 0.6624, 0.7107,
        0.7404, 0.7503, 0.6743, 0.7430, 0.7325, 0.6964, 0.7174],
       device='cuda:0') torch.Size([16])
percent tensor([0.5812, 0.5590, 0.7582, 0.7642, 0.7835, 0.7425, 0.6531, 0.6465, 0.6832,
        0.5618, 0.6626, 0.7021, 0.5775, 0.6450, 0.6251, 0.5914],
       device='cuda:0') torch.Size([16])
percent tensor([0.7346, 0.7397, 0.7452, 0.7290, 0.7845, 0.7934, 0.7551, 0.6850, 0.7227,
        0.7130, 0.6900, 0.6887, 0.7275, 0.7259, 0.6834, 0.7664],
       device='cuda:0') torch.Size([16])
percent tensor([0.7000, 0.7825, 0.7070, 0.6259, 0.7303, 0.8181, 0.7168, 0.5017, 0.7564,
        0.7334, 0.7356, 0.7373, 0.7442, 0.6915, 0.5495, 0.6734],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9997, 0.9998, 0.9998, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(188.1187, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(839.0073, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(845.3685, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1513.1305, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(477.1815, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2302.7698, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4256.8730, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1339.8138, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6323.5015, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11488.7305, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3764.3152, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15858.6279, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 221 | Batch_idx: 0 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 221 | Batch_idx: 10 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 221 | Batch_idx: 20 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (2635/2688)
Epoch: 221 | Batch_idx: 30 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (3899/3968)
Epoch: 221 | Batch_idx: 40 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (5153/5248)
Epoch: 221 | Batch_idx: 50 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (6407/6528)
Epoch: 221 | Batch_idx: 60 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (7663/7808)
Epoch: 221 | Batch_idx: 70 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (8923/9088)
Epoch: 221 | Batch_idx: 80 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (10178/10368)
Epoch: 221 | Batch_idx: 90 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (11428/11648)
Epoch: 221 | Batch_idx: 100 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (12689/12928)
Epoch: 221 | Batch_idx: 110 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (13944/14208)
Epoch: 221 | Batch_idx: 120 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (15204/15488)
Epoch: 221 | Batch_idx: 130 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (16465/16768)
Epoch: 221 | Batch_idx: 140 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (17730/18048)
Epoch: 221 | Batch_idx: 150 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (18988/19328)
Epoch: 221 | Batch_idx: 160 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (20251/20608)
Epoch: 221 | Batch_idx: 170 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (21508/21888)
Epoch: 221 | Batch_idx: 180 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (22758/23168)
Epoch: 221 | Batch_idx: 190 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (24018/24448)
Epoch: 221 | Batch_idx: 200 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (25276/25728)
Epoch: 221 | Batch_idx: 210 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (26535/27008)
Epoch: 221 | Batch_idx: 220 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (27788/28288)
Epoch: 221 | Batch_idx: 230 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (29045/29568)
Epoch: 221 | Batch_idx: 240 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (30302/30848)
Epoch: 221 | Batch_idx: 250 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (31562/32128)
Epoch: 221 | Batch_idx: 260 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (32815/33408)
Epoch: 221 | Batch_idx: 270 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (34068/34688)
Epoch: 221 | Batch_idx: 280 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (35328/35968)
Epoch: 221 | Batch_idx: 290 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (36582/37248)
Epoch: 221 | Batch_idx: 300 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (37840/38528)
Epoch: 221 | Batch_idx: 310 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (39092/39808)
Epoch: 221 | Batch_idx: 320 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (40345/41088)
Epoch: 221 | Batch_idx: 330 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (41605/42368)
Epoch: 221 | Batch_idx: 340 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (42854/43648)
Epoch: 221 | Batch_idx: 350 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (44110/44928)
Epoch: 221 | Batch_idx: 360 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (45368/46208)
Epoch: 221 | Batch_idx: 370 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (46630/47488)
Epoch: 221 | Batch_idx: 380 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (47894/48768)
Epoch: 221 | Batch_idx: 390 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (49101/50000)
# TEST : Loss: (0.4496) | Acc: (88.00%) (8870/10000)
percent tensor([0.5569, 0.5661, 0.5449, 0.5360, 0.5533, 0.5328, 0.5676, 0.5511, 0.5691,
        0.5654, 0.5685, 0.5618, 0.5640, 0.5664, 0.5489, 0.5540],
       device='cuda:0') torch.Size([16])
percent tensor([0.4961, 0.5020, 0.4817, 0.4803, 0.4843, 0.4947, 0.4981, 0.4910, 0.4907,
        0.4932, 0.4990, 0.4824, 0.5018, 0.4975, 0.4918, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.6103, 0.5343, 0.5572, 0.6393, 0.5777, 0.6692, 0.5528, 0.6135, 0.6068,
        0.5502, 0.5737, 0.5155, 0.5508, 0.6711, 0.5571, 0.6309],
       device='cuda:0') torch.Size([16])
percent tensor([0.7018, 0.7428, 0.6357, 0.6191, 0.6373, 0.6354, 0.7197, 0.6573, 0.7053,
        0.7395, 0.7461, 0.6725, 0.7398, 0.7237, 0.6939, 0.7097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5785, 0.5742, 0.7479, 0.7489, 0.7659, 0.7382, 0.6534, 0.6459, 0.6852,
        0.5870, 0.6645, 0.6983, 0.5873, 0.6496, 0.6178, 0.6117],
       device='cuda:0') torch.Size([16])
percent tensor([0.7303, 0.7467, 0.7456, 0.7151, 0.7763, 0.7829, 0.7529, 0.6946, 0.7221,
        0.7089, 0.6938, 0.6809, 0.7300, 0.7393, 0.6726, 0.7605],
       device='cuda:0') torch.Size([16])
percent tensor([0.7059, 0.7900, 0.7106, 0.6106, 0.6881, 0.7965, 0.6861, 0.4987, 0.7616,
        0.7239, 0.7444, 0.7161, 0.7490, 0.7190, 0.5586, 0.6462],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9999, 0.9998, 0.9998, 0.9997, 0.9998, 0.9997, 0.9997,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 222 | Batch_idx: 0 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 222 | Batch_idx: 10 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 222 | Batch_idx: 20 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 222 | Batch_idx: 30 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (3914/3968)
Epoch: 222 | Batch_idx: 40 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 222 | Batch_idx: 50 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (6439/6528)
Epoch: 222 | Batch_idx: 60 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (7702/7808)
Epoch: 222 | Batch_idx: 70 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (8964/9088)
Epoch: 222 | Batch_idx: 80 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (10223/10368)
Epoch: 222 | Batch_idx: 90 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (11483/11648)
Epoch: 222 | Batch_idx: 100 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (12746/12928)
Epoch: 222 | Batch_idx: 110 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (14005/14208)
Epoch: 222 | Batch_idx: 120 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (15265/15488)
Epoch: 222 | Batch_idx: 130 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (16528/16768)
Epoch: 222 | Batch_idx: 140 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (17790/18048)
Epoch: 222 | Batch_idx: 150 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (19057/19328)
Epoch: 222 | Batch_idx: 160 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (20318/20608)
Epoch: 222 | Batch_idx: 170 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (21585/21888)
Epoch: 222 | Batch_idx: 180 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (22846/23168)
Epoch: 222 | Batch_idx: 190 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (24112/24448)
Epoch: 222 | Batch_idx: 200 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (25379/25728)
Epoch: 222 | Batch_idx: 210 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (26642/27008)
Epoch: 222 | Batch_idx: 220 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (27907/28288)
Epoch: 222 | Batch_idx: 230 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (29176/29568)
Epoch: 222 | Batch_idx: 240 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (30441/30848)
Epoch: 222 | Batch_idx: 250 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (31702/32128)
Epoch: 222 | Batch_idx: 260 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (32963/33408)
Epoch: 222 | Batch_idx: 270 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (34226/34688)
Epoch: 222 | Batch_idx: 280 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (35485/35968)
Epoch: 222 | Batch_idx: 290 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (36744/37248)
Epoch: 222 | Batch_idx: 300 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (38006/38528)
Epoch: 222 | Batch_idx: 310 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (39270/39808)
Epoch: 222 | Batch_idx: 320 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (40535/41088)
Epoch: 222 | Batch_idx: 330 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (41794/42368)
Epoch: 222 | Batch_idx: 340 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (43054/43648)
Epoch: 222 | Batch_idx: 350 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (44311/44928)
Epoch: 222 | Batch_idx: 360 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (45569/46208)
Epoch: 222 | Batch_idx: 370 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (46831/47488)
Epoch: 222 | Batch_idx: 380 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (48091/48768)
Epoch: 222 | Batch_idx: 390 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (49304/50000)
# TEST : Loss: (0.4273) | Acc: (89.00%) (8919/10000)
percent tensor([0.5567, 0.5654, 0.5455, 0.5359, 0.5531, 0.5333, 0.5670, 0.5511, 0.5691,
        0.5646, 0.5679, 0.5614, 0.5634, 0.5655, 0.5488, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.4965, 0.5028, 0.4803, 0.4812, 0.4832, 0.4939, 0.4984, 0.4912, 0.4908,
        0.4945, 0.4992, 0.4815, 0.5030, 0.4977, 0.4928, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.5341, 0.5798, 0.6388, 0.5862, 0.6614, 0.5548, 0.6118, 0.6032,
        0.5474, 0.5674, 0.5276, 0.5433, 0.6742, 0.5519, 0.6205],
       device='cuda:0') torch.Size([16])
percent tensor([0.7083, 0.7504, 0.6335, 0.6252, 0.6395, 0.6542, 0.7242, 0.6645, 0.7112,
        0.7427, 0.7496, 0.6746, 0.7457, 0.7340, 0.7005, 0.7194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5741, 0.5479, 0.7523, 0.7540, 0.7750, 0.7230, 0.6400, 0.6413, 0.6728,
        0.5773, 0.6593, 0.6961, 0.5793, 0.6185, 0.6136, 0.5868],
       device='cuda:0') torch.Size([16])
percent tensor([0.7351, 0.7360, 0.7394, 0.7217, 0.7822, 0.7837, 0.7560, 0.6929, 0.7303,
        0.7127, 0.6962, 0.6932, 0.7314, 0.7381, 0.6828, 0.7545],
       device='cuda:0') torch.Size([16])
percent tensor([0.7128, 0.7783, 0.7028, 0.6352, 0.7364, 0.7902, 0.6974, 0.5067, 0.7541,
        0.7169, 0.7458, 0.7457, 0.7266, 0.7364, 0.5878, 0.6328],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9999, 0.9997, 0.9997,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 223 | Batch_idx: 0 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 223 | Batch_idx: 10 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 223 | Batch_idx: 20 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (2659/2688)
Epoch: 223 | Batch_idx: 30 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (99.00%) (3929/3968)
Epoch: 223 | Batch_idx: 40 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (5194/5248)
Epoch: 223 | Batch_idx: 50 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (6459/6528)
Epoch: 223 | Batch_idx: 60 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (7717/7808)
Epoch: 223 | Batch_idx: 70 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (8981/9088)
Epoch: 223 | Batch_idx: 80 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (10231/10368)
Epoch: 223 | Batch_idx: 90 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (11483/11648)
Epoch: 223 | Batch_idx: 100 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (12746/12928)
Epoch: 223 | Batch_idx: 110 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (14005/14208)
Epoch: 223 | Batch_idx: 120 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (15261/15488)
Epoch: 223 | Batch_idx: 130 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (16512/16768)
Epoch: 223 | Batch_idx: 140 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (17778/18048)
Epoch: 223 | Batch_idx: 150 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (19040/19328)
Epoch: 223 | Batch_idx: 160 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (20301/20608)
Epoch: 223 | Batch_idx: 170 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (21562/21888)
Epoch: 223 | Batch_idx: 180 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (22817/23168)
Epoch: 223 | Batch_idx: 190 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (24078/24448)
Epoch: 223 | Batch_idx: 200 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (25344/25728)
Epoch: 223 | Batch_idx: 210 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (26602/27008)
Epoch: 223 | Batch_idx: 220 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (27858/28288)
Epoch: 223 | Batch_idx: 230 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (29113/29568)
Epoch: 223 | Batch_idx: 240 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (30366/30848)
Epoch: 223 | Batch_idx: 250 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (31630/32128)
Epoch: 223 | Batch_idx: 260 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (32889/33408)
Epoch: 223 | Batch_idx: 270 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (34146/34688)
Epoch: 223 | Batch_idx: 280 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (35399/35968)
Epoch: 223 | Batch_idx: 290 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (36658/37248)
Epoch: 223 | Batch_idx: 300 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (37918/38528)
Epoch: 223 | Batch_idx: 310 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (39179/39808)
Epoch: 223 | Batch_idx: 320 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (40436/41088)
Epoch: 223 | Batch_idx: 330 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (41693/42368)
Epoch: 223 | Batch_idx: 340 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (42954/43648)
Epoch: 223 | Batch_idx: 350 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (44214/44928)
Epoch: 223 | Batch_idx: 360 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (45471/46208)
Epoch: 223 | Batch_idx: 370 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (46739/47488)
Epoch: 223 | Batch_idx: 380 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (47989/48768)
Epoch: 223 | Batch_idx: 390 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (49196/50000)
# TEST : Loss: (0.4479) | Acc: (88.00%) (8870/10000)
percent tensor([0.5577, 0.5631, 0.5490, 0.5364, 0.5566, 0.5353, 0.5673, 0.5512, 0.5699,
        0.5642, 0.5678, 0.5633, 0.5637, 0.5624, 0.5484, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.4940, 0.4999, 0.4785, 0.4801, 0.4816, 0.4935, 0.4955, 0.4889, 0.4884,
        0.4920, 0.4977, 0.4796, 0.5005, 0.4963, 0.4907, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.6110, 0.5378, 0.5871, 0.6476, 0.5917, 0.6730, 0.5542, 0.6150, 0.6062,
        0.5470, 0.5718, 0.5331, 0.5516, 0.6665, 0.5612, 0.6291],
       device='cuda:0') torch.Size([16])
percent tensor([0.7006, 0.7455, 0.6347, 0.6192, 0.6379, 0.6429, 0.7203, 0.6584, 0.7079,
        0.7405, 0.7491, 0.6728, 0.7411, 0.7329, 0.6965, 0.7131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5954, 0.5680, 0.7469, 0.7592, 0.7744, 0.7332, 0.6537, 0.6379, 0.6895,
        0.5870, 0.6735, 0.6929, 0.5966, 0.6516, 0.6186, 0.6044],
       device='cuda:0') torch.Size([16])
percent tensor([0.7433, 0.7378, 0.7471, 0.7332, 0.7838, 0.7927, 0.7564, 0.6992, 0.7322,
        0.7204, 0.6995, 0.6991, 0.7311, 0.7452, 0.6886, 0.7637],
       device='cuda:0') torch.Size([16])
percent tensor([0.7015, 0.7595, 0.7040, 0.5958, 0.7058, 0.7873, 0.6839, 0.5024, 0.7697,
        0.6731, 0.7346, 0.7284, 0.7169, 0.7024, 0.5219, 0.6099],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 224 | Batch_idx: 0 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 224 | Batch_idx: 10 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 224 | Batch_idx: 20 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (2653/2688)
Epoch: 224 | Batch_idx: 30 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (3914/3968)
Epoch: 224 | Batch_idx: 40 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (5171/5248)
Epoch: 224 | Batch_idx: 50 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (6435/6528)
Epoch: 224 | Batch_idx: 60 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (7693/7808)
Epoch: 224 | Batch_idx: 70 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (8951/9088)
Epoch: 224 | Batch_idx: 80 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (10214/10368)
Epoch: 224 | Batch_idx: 90 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (11481/11648)
Epoch: 224 | Batch_idx: 100 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (12741/12928)
Epoch: 224 | Batch_idx: 110 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (14004/14208)
Epoch: 224 | Batch_idx: 120 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (15267/15488)
Epoch: 224 | Batch_idx: 130 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (16533/16768)
Epoch: 224 | Batch_idx: 140 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (17794/18048)
Epoch: 224 | Batch_idx: 150 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (19055/19328)
Epoch: 224 | Batch_idx: 160 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (20315/20608)
Epoch: 224 | Batch_idx: 170 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (21582/21888)
Epoch: 224 | Batch_idx: 180 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (22843/23168)
Epoch: 224 | Batch_idx: 190 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (24107/24448)
Epoch: 224 | Batch_idx: 200 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (25361/25728)
Epoch: 224 | Batch_idx: 210 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (26624/27008)
Epoch: 224 | Batch_idx: 220 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (27885/28288)
Epoch: 224 | Batch_idx: 230 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (29140/29568)
Epoch: 224 | Batch_idx: 240 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (30391/30848)
Epoch: 224 | Batch_idx: 250 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (31651/32128)
Epoch: 224 | Batch_idx: 260 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (32904/33408)
Epoch: 224 | Batch_idx: 270 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (34158/34688)
Epoch: 224 | Batch_idx: 280 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (35425/35968)
Epoch: 224 | Batch_idx: 290 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (36686/37248)
Epoch: 224 | Batch_idx: 300 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (37946/38528)
Epoch: 224 | Batch_idx: 310 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (39199/39808)
Epoch: 224 | Batch_idx: 320 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (40458/41088)
Epoch: 224 | Batch_idx: 330 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (41711/42368)
Epoch: 224 | Batch_idx: 340 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (42975/43648)
Epoch: 224 | Batch_idx: 350 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (44241/44928)
Epoch: 224 | Batch_idx: 360 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (45505/46208)
Epoch: 224 | Batch_idx: 370 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (46760/47488)
Epoch: 224 | Batch_idx: 380 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (48025/48768)
Epoch: 224 | Batch_idx: 390 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (49233/50000)
# TEST : Loss: (0.4655) | Acc: (88.00%) (8841/10000)
percent tensor([0.5580, 0.5660, 0.5455, 0.5369, 0.5542, 0.5345, 0.5676, 0.5513, 0.5698,
        0.5655, 0.5688, 0.5620, 0.5647, 0.5659, 0.5497, 0.5548],
       device='cuda:0') torch.Size([16])
percent tensor([0.4957, 0.5016, 0.4837, 0.4827, 0.4857, 0.4947, 0.4978, 0.4916, 0.4906,
        0.4951, 0.4981, 0.4843, 0.5016, 0.4965, 0.4924, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.6023, 0.5309, 0.5777, 0.6403, 0.5844, 0.6600, 0.5481, 0.6129, 0.6008,
        0.5491, 0.5690, 0.5242, 0.5453, 0.6674, 0.5515, 0.6216],
       device='cuda:0') torch.Size([16])
percent tensor([0.6961, 0.7407, 0.6349, 0.6165, 0.6399, 0.6391, 0.7181, 0.6554, 0.7020,
        0.7365, 0.7449, 0.6738, 0.7356, 0.7257, 0.6918, 0.7093],
       device='cuda:0') torch.Size([16])
percent tensor([0.5892, 0.5769, 0.7604, 0.7611, 0.7853, 0.7412, 0.6597, 0.6565, 0.7024,
        0.6006, 0.6833, 0.6972, 0.6139, 0.6586, 0.6250, 0.6140],
       device='cuda:0') torch.Size([16])
percent tensor([0.7323, 0.7375, 0.7436, 0.7204, 0.7828, 0.7882, 0.7448, 0.6812, 0.7347,
        0.7123, 0.6945, 0.6961, 0.7316, 0.7326, 0.6760, 0.7510],
       device='cuda:0') torch.Size([16])
percent tensor([0.7052, 0.7845, 0.7047, 0.6112, 0.7127, 0.7927, 0.6789, 0.4964, 0.7858,
        0.7143, 0.7209, 0.7362, 0.7448, 0.7252, 0.5499, 0.6078],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9998, 0.9999, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 225 | Batch_idx: 0 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 225 | Batch_idx: 10 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 225 | Batch_idx: 20 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (2652/2688)
Epoch: 225 | Batch_idx: 30 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (3918/3968)
Epoch: 225 | Batch_idx: 40 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (5175/5248)
Epoch: 225 | Batch_idx: 50 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (6441/6528)
Epoch: 225 | Batch_idx: 60 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (7702/7808)
Epoch: 225 | Batch_idx: 70 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (8963/9088)
Epoch: 225 | Batch_idx: 80 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (10226/10368)
Epoch: 225 | Batch_idx: 90 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (11488/11648)
Epoch: 225 | Batch_idx: 100 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (12752/12928)
Epoch: 225 | Batch_idx: 110 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (14014/14208)
Epoch: 225 | Batch_idx: 120 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (15270/15488)
Epoch: 225 | Batch_idx: 130 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (16537/16768)
Epoch: 225 | Batch_idx: 140 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (17797/18048)
Epoch: 225 | Batch_idx: 150 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (19063/19328)
Epoch: 225 | Batch_idx: 160 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (20323/20608)
Epoch: 225 | Batch_idx: 170 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (21578/21888)
Epoch: 225 | Batch_idx: 180 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (22835/23168)
Epoch: 225 | Batch_idx: 190 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (24099/24448)
Epoch: 225 | Batch_idx: 200 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (25359/25728)
Epoch: 225 | Batch_idx: 210 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (26619/27008)
Epoch: 225 | Batch_idx: 220 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (27877/28288)
Epoch: 225 | Batch_idx: 230 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (29138/29568)
Epoch: 225 | Batch_idx: 240 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (30399/30848)
Epoch: 225 | Batch_idx: 250 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (31654/32128)
Epoch: 225 | Batch_idx: 260 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (32912/33408)
Epoch: 225 | Batch_idx: 270 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (34170/34688)
Epoch: 225 | Batch_idx: 280 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (35430/35968)
Epoch: 225 | Batch_idx: 290 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (36686/37248)
Epoch: 225 | Batch_idx: 300 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (37949/38528)
Epoch: 225 | Batch_idx: 310 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (39211/39808)
Epoch: 225 | Batch_idx: 320 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (40475/41088)
Epoch: 225 | Batch_idx: 330 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (41735/42368)
Epoch: 225 | Batch_idx: 340 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (42981/43648)
Epoch: 225 | Batch_idx: 350 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (44240/44928)
Epoch: 225 | Batch_idx: 360 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (45496/46208)
Epoch: 225 | Batch_idx: 370 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (46760/47488)
Epoch: 225 | Batch_idx: 380 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (48013/48768)
Epoch: 225 | Batch_idx: 390 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (49219/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_225.pth.tar'
# TEST : Loss: (0.4590) | Acc: (88.00%) (8854/10000)
percent tensor([0.5590, 0.5660, 0.5490, 0.5382, 0.5561, 0.5356, 0.5686, 0.5533, 0.5711,
        0.5663, 0.5695, 0.5638, 0.5655, 0.5657, 0.5502, 0.5553],
       device='cuda:0') torch.Size([16])
percent tensor([0.4971, 0.5032, 0.4834, 0.4825, 0.4851, 0.4954, 0.4985, 0.4923, 0.4926,
        0.4951, 0.4998, 0.4830, 0.5035, 0.4989, 0.4926, 0.5008],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.5284, 0.5890, 0.6432, 0.5958, 0.6625, 0.5528, 0.6209, 0.6050,
        0.5481, 0.5636, 0.5288, 0.5388, 0.6693, 0.5477, 0.6235],
       device='cuda:0') torch.Size([16])
percent tensor([0.7020, 0.7488, 0.6408, 0.6204, 0.6409, 0.6450, 0.7259, 0.6638, 0.7072,
        0.7436, 0.7490, 0.6766, 0.7415, 0.7339, 0.6992, 0.7146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5982, 0.5630, 0.7564, 0.7677, 0.7793, 0.7528, 0.6542, 0.6421, 0.6880,
        0.5803, 0.6762, 0.6981, 0.6097, 0.6359, 0.6223, 0.6250],
       device='cuda:0') torch.Size([16])
percent tensor([0.7357, 0.7511, 0.7461, 0.7314, 0.7885, 0.7987, 0.7518, 0.6912, 0.7359,
        0.7167, 0.7010, 0.6972, 0.7320, 0.7377, 0.6780, 0.7691],
       device='cuda:0') torch.Size([16])
percent tensor([0.6758, 0.7767, 0.6899, 0.6116, 0.7197, 0.8000, 0.6706, 0.4819, 0.7492,
        0.6998, 0.7062, 0.7199, 0.7088, 0.7283, 0.5263, 0.6123],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9997, 0.9998, 0.9996, 0.9997, 0.9997, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9998, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 226 | Batch_idx: 0 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 226 | Batch_idx: 10 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 226 | Batch_idx: 20 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 226 | Batch_idx: 30 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 226 | Batch_idx: 40 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (5163/5248)
Epoch: 226 | Batch_idx: 50 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (6426/6528)
Epoch: 226 | Batch_idx: 60 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (7692/7808)
Epoch: 226 | Batch_idx: 70 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (8951/9088)
Epoch: 226 | Batch_idx: 80 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (10217/10368)
Epoch: 226 | Batch_idx: 90 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (11477/11648)
Epoch: 226 | Batch_idx: 100 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (12738/12928)
Epoch: 226 | Batch_idx: 110 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (13997/14208)
Epoch: 226 | Batch_idx: 120 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (15260/15488)
Epoch: 226 | Batch_idx: 130 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (16527/16768)
Epoch: 226 | Batch_idx: 140 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (17786/18048)
Epoch: 226 | Batch_idx: 150 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (19045/19328)
Epoch: 226 | Batch_idx: 160 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (20306/20608)
Epoch: 226 | Batch_idx: 170 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (21568/21888)
Epoch: 226 | Batch_idx: 180 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (22823/23168)
Epoch: 226 | Batch_idx: 190 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (24077/24448)
Epoch: 226 | Batch_idx: 200 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (25343/25728)
Epoch: 226 | Batch_idx: 210 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (26603/27008)
Epoch: 226 | Batch_idx: 220 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (27855/28288)
Epoch: 226 | Batch_idx: 230 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (29122/29568)
Epoch: 226 | Batch_idx: 240 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (30385/30848)
Epoch: 226 | Batch_idx: 250 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (31653/32128)
Epoch: 226 | Batch_idx: 260 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (32911/33408)
Epoch: 226 | Batch_idx: 270 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (34180/34688)
Epoch: 226 | Batch_idx: 280 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (35444/35968)
Epoch: 226 | Batch_idx: 290 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (36705/37248)
Epoch: 226 | Batch_idx: 300 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (37960/38528)
Epoch: 226 | Batch_idx: 310 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (39224/39808)
Epoch: 226 | Batch_idx: 320 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (40489/41088)
Epoch: 226 | Batch_idx: 330 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (41752/42368)
Epoch: 226 | Batch_idx: 340 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (43013/43648)
Epoch: 226 | Batch_idx: 350 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (44273/44928)
Epoch: 226 | Batch_idx: 360 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (45530/46208)
Epoch: 226 | Batch_idx: 370 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (46777/47488)
Epoch: 226 | Batch_idx: 380 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (48037/48768)
Epoch: 226 | Batch_idx: 390 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (49255/50000)
# TEST : Loss: (0.4395) | Acc: (89.00%) (8931/10000)
percent tensor([0.5608, 0.5670, 0.5529, 0.5401, 0.5596, 0.5368, 0.5707, 0.5556, 0.5730,
        0.5686, 0.5709, 0.5676, 0.5673, 0.5659, 0.5515, 0.5566],
       device='cuda:0') torch.Size([16])
percent tensor([0.4965, 0.5027, 0.4852, 0.4834, 0.4866, 0.4948, 0.4991, 0.4930, 0.4920,
        0.4953, 0.4994, 0.4842, 0.5030, 0.4964, 0.4929, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.5315, 0.5746, 0.6432, 0.5859, 0.6610, 0.5502, 0.6172, 0.6046,
        0.5455, 0.5643, 0.5177, 0.5393, 0.6679, 0.5509, 0.6206],
       device='cuda:0') torch.Size([16])
percent tensor([0.7042, 0.7538, 0.6393, 0.6231, 0.6439, 0.6497, 0.7251, 0.6621, 0.7142,
        0.7471, 0.7556, 0.6801, 0.7483, 0.7366, 0.7030, 0.7196],
       device='cuda:0') torch.Size([16])
percent tensor([0.5778, 0.5341, 0.7597, 0.7667, 0.7788, 0.7336, 0.6439, 0.6473, 0.6724,
        0.5646, 0.6547, 0.6836, 0.5737, 0.6250, 0.6016, 0.5967],
       device='cuda:0') torch.Size([16])
percent tensor([0.7314, 0.7426, 0.7458, 0.7302, 0.7845, 0.7874, 0.7538, 0.6941, 0.7303,
        0.7060, 0.6961, 0.6941, 0.7282, 0.7249, 0.6651, 0.7574],
       device='cuda:0') torch.Size([16])
percent tensor([0.6836, 0.7847, 0.6683, 0.5721, 0.6786, 0.7928, 0.6935, 0.4961, 0.7632,
        0.6852, 0.7073, 0.7165, 0.7309, 0.6783, 0.5089, 0.5780],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9997, 0.9998, 0.9998, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 227 | Batch_idx: 0 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 227 | Batch_idx: 10 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 227 | Batch_idx: 20 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 227 | Batch_idx: 30 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (3908/3968)
Epoch: 227 | Batch_idx: 40 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (5168/5248)
Epoch: 227 | Batch_idx: 50 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (6428/6528)
Epoch: 227 | Batch_idx: 60 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (7685/7808)
Epoch: 227 | Batch_idx: 70 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (8945/9088)
Epoch: 227 | Batch_idx: 80 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (10202/10368)
Epoch: 227 | Batch_idx: 90 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (11460/11648)
Epoch: 227 | Batch_idx: 100 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (12711/12928)
Epoch: 227 | Batch_idx: 110 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (13968/14208)
Epoch: 227 | Batch_idx: 120 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (15230/15488)
Epoch: 227 | Batch_idx: 130 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (16495/16768)
Epoch: 227 | Batch_idx: 140 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (17756/18048)
Epoch: 227 | Batch_idx: 150 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (19020/19328)
Epoch: 227 | Batch_idx: 160 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (20277/20608)
Epoch: 227 | Batch_idx: 170 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (21538/21888)
Epoch: 227 | Batch_idx: 180 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (22791/23168)
Epoch: 227 | Batch_idx: 190 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (24054/24448)
Epoch: 227 | Batch_idx: 200 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (25315/25728)
Epoch: 227 | Batch_idx: 210 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (26578/27008)
Epoch: 227 | Batch_idx: 220 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (27845/28288)
Epoch: 227 | Batch_idx: 230 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (29107/29568)
Epoch: 227 | Batch_idx: 240 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (30361/30848)
Epoch: 227 | Batch_idx: 250 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (31613/32128)
Epoch: 227 | Batch_idx: 260 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (32872/33408)
Epoch: 227 | Batch_idx: 270 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (34130/34688)
Epoch: 227 | Batch_idx: 280 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (35391/35968)
Epoch: 227 | Batch_idx: 290 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (36657/37248)
Epoch: 227 | Batch_idx: 300 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (37914/38528)
Epoch: 227 | Batch_idx: 310 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (39168/39808)
Epoch: 227 | Batch_idx: 320 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (40427/41088)
Epoch: 227 | Batch_idx: 330 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (41690/42368)
Epoch: 227 | Batch_idx: 340 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (42941/43648)
Epoch: 227 | Batch_idx: 350 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (44197/44928)
Epoch: 227 | Batch_idx: 360 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (45457/46208)
Epoch: 227 | Batch_idx: 370 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (46716/47488)
Epoch: 227 | Batch_idx: 380 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (47976/48768)
Epoch: 227 | Batch_idx: 390 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (49182/50000)
# TEST : Loss: (0.4747) | Acc: (88.00%) (8827/10000)
percent tensor([0.5611, 0.5684, 0.5471, 0.5391, 0.5558, 0.5382, 0.5698, 0.5536, 0.5724,
        0.5682, 0.5720, 0.5639, 0.5679, 0.5681, 0.5526, 0.5576],
       device='cuda:0') torch.Size([16])
percent tensor([0.4956, 0.5023, 0.4833, 0.4812, 0.4852, 0.4935, 0.4983, 0.4923, 0.4920,
        0.4943, 0.4996, 0.4826, 0.5023, 0.4974, 0.4918, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.6048, 0.5286, 0.5888, 0.6458, 0.5964, 0.6625, 0.5517, 0.6222, 0.6112,
        0.5465, 0.5679, 0.5328, 0.5448, 0.6678, 0.5506, 0.6217],
       device='cuda:0') torch.Size([16])
percent tensor([0.7021, 0.7463, 0.6434, 0.6272, 0.6442, 0.6486, 0.7210, 0.6625, 0.7105,
        0.7432, 0.7487, 0.6799, 0.7440, 0.7296, 0.7002, 0.7145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.5419, 0.7497, 0.7612, 0.7759, 0.7380, 0.6449, 0.6466, 0.6738,
        0.5532, 0.6523, 0.6926, 0.5766, 0.6290, 0.6160, 0.6022],
       device='cuda:0') torch.Size([16])
percent tensor([0.7437, 0.7480, 0.7452, 0.7346, 0.7809, 0.7903, 0.7649, 0.6952, 0.7399,
        0.7244, 0.7141, 0.7119, 0.7358, 0.7420, 0.6875, 0.7618],
       device='cuda:0') torch.Size([16])
percent tensor([0.7151, 0.8009, 0.7102, 0.6284, 0.6757, 0.8023, 0.7267, 0.5104, 0.7894,
        0.7203, 0.7606, 0.7653, 0.7300, 0.7356, 0.5797, 0.6223],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9998, 0.9999, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 228 | Batch_idx: 0 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 228 | Batch_idx: 10 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 228 | Batch_idx: 20 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (2630/2688)
Epoch: 228 | Batch_idx: 30 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (97.00%) (3886/3968)
Epoch: 228 | Batch_idx: 40 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (5152/5248)
Epoch: 228 | Batch_idx: 50 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (6415/6528)
Epoch: 228 | Batch_idx: 60 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (7677/7808)
Epoch: 228 | Batch_idx: 70 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (8942/9088)
Epoch: 228 | Batch_idx: 80 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (10209/10368)
Epoch: 228 | Batch_idx: 90 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (11477/11648)
Epoch: 228 | Batch_idx: 100 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (12743/12928)
Epoch: 228 | Batch_idx: 110 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (14001/14208)
Epoch: 228 | Batch_idx: 120 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (15259/15488)
Epoch: 228 | Batch_idx: 130 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (16527/16768)
Epoch: 228 | Batch_idx: 140 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (17789/18048)
Epoch: 228 | Batch_idx: 150 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (19049/19328)
Epoch: 228 | Batch_idx: 160 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (20311/20608)
Epoch: 228 | Batch_idx: 170 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (21566/21888)
Epoch: 228 | Batch_idx: 180 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (22821/23168)
Epoch: 228 | Batch_idx: 190 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (24088/24448)
Epoch: 228 | Batch_idx: 200 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (25353/25728)
Epoch: 228 | Batch_idx: 210 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (26615/27008)
Epoch: 228 | Batch_idx: 220 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (27883/28288)
Epoch: 228 | Batch_idx: 230 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (29150/29568)
Epoch: 228 | Batch_idx: 240 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (30419/30848)
Epoch: 228 | Batch_idx: 250 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (31680/32128)
Epoch: 228 | Batch_idx: 260 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (32939/33408)
Epoch: 228 | Batch_idx: 270 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (34197/34688)
Epoch: 228 | Batch_idx: 280 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (35450/35968)
Epoch: 228 | Batch_idx: 290 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (36710/37248)
Epoch: 228 | Batch_idx: 300 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (37972/38528)
Epoch: 228 | Batch_idx: 310 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (39229/39808)
Epoch: 228 | Batch_idx: 320 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (40493/41088)
Epoch: 228 | Batch_idx: 330 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (41750/42368)
Epoch: 228 | Batch_idx: 340 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (43009/43648)
Epoch: 228 | Batch_idx: 350 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (44269/44928)
Epoch: 228 | Batch_idx: 360 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (45527/46208)
Epoch: 228 | Batch_idx: 370 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (46786/47488)
Epoch: 228 | Batch_idx: 380 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (48050/48768)
Epoch: 228 | Batch_idx: 390 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (49272/50000)
# TEST : Loss: (0.4301) | Acc: (89.00%) (8912/10000)
percent tensor([0.5605, 0.5684, 0.5489, 0.5396, 0.5564, 0.5370, 0.5704, 0.5545, 0.5726,
        0.5684, 0.5714, 0.5652, 0.5674, 0.5687, 0.5519, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.4976, 0.5034, 0.4829, 0.4833, 0.4850, 0.4960, 0.4987, 0.4932, 0.4931,
        0.4952, 0.5003, 0.4824, 0.5037, 0.4994, 0.4934, 0.5009],
       device='cuda:0') torch.Size([16])
percent tensor([0.6053, 0.5351, 0.5802, 0.6458, 0.5971, 0.6702, 0.5553, 0.6212, 0.6116,
        0.5462, 0.5693, 0.5277, 0.5483, 0.6699, 0.5577, 0.6231],
       device='cuda:0') torch.Size([16])
percent tensor([0.6980, 0.7436, 0.6309, 0.6220, 0.6372, 0.6436, 0.7188, 0.6586, 0.7082,
        0.7379, 0.7468, 0.6710, 0.7392, 0.7312, 0.6953, 0.7120],
       device='cuda:0') torch.Size([16])
percent tensor([0.5930, 0.5692, 0.7635, 0.7683, 0.7831, 0.7398, 0.6568, 0.6497, 0.6797,
        0.6004, 0.6786, 0.7051, 0.5990, 0.6454, 0.6228, 0.6144],
       device='cuda:0') torch.Size([16])
percent tensor([0.7335, 0.7401, 0.7402, 0.7323, 0.7827, 0.7898, 0.7520, 0.6963, 0.7219,
        0.7112, 0.6952, 0.6805, 0.7234, 0.7302, 0.6690, 0.7600],
       device='cuda:0') torch.Size([16])
percent tensor([0.6759, 0.8074, 0.7195, 0.6222, 0.7185, 0.8083, 0.7059, 0.5033, 0.7649,
        0.7324, 0.7309, 0.7110, 0.7402, 0.7319, 0.5216, 0.6180],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9997, 0.9997, 0.9999, 0.9998, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 229 | Batch_idx: 0 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 229 | Batch_idx: 10 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 229 | Batch_idx: 20 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 229 | Batch_idx: 30 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (3905/3968)
Epoch: 229 | Batch_idx: 40 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (5168/5248)
Epoch: 229 | Batch_idx: 50 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (6434/6528)
Epoch: 229 | Batch_idx: 60 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (7693/7808)
Epoch: 229 | Batch_idx: 70 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (8960/9088)
Epoch: 229 | Batch_idx: 80 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (10223/10368)
Epoch: 229 | Batch_idx: 90 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (11487/11648)
Epoch: 229 | Batch_idx: 100 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (12750/12928)
Epoch: 229 | Batch_idx: 110 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (14012/14208)
Epoch: 229 | Batch_idx: 120 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (15282/15488)
Epoch: 229 | Batch_idx: 130 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (16543/16768)
Epoch: 229 | Batch_idx: 140 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (17809/18048)
Epoch: 229 | Batch_idx: 150 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (19065/19328)
Epoch: 229 | Batch_idx: 160 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (20328/20608)
Epoch: 229 | Batch_idx: 170 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (21590/21888)
Epoch: 229 | Batch_idx: 180 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (22850/23168)
Epoch: 229 | Batch_idx: 190 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (24108/24448)
Epoch: 229 | Batch_idx: 200 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (25367/25728)
Epoch: 229 | Batch_idx: 210 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (26628/27008)
Epoch: 229 | Batch_idx: 220 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (27889/28288)
Epoch: 229 | Batch_idx: 230 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (29149/29568)
Epoch: 229 | Batch_idx: 240 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (30408/30848)
Epoch: 229 | Batch_idx: 250 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (31666/32128)
Epoch: 229 | Batch_idx: 260 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (32912/33408)
Epoch: 229 | Batch_idx: 270 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (34164/34688)
Epoch: 229 | Batch_idx: 280 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (35421/35968)
Epoch: 229 | Batch_idx: 290 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (36685/37248)
Epoch: 229 | Batch_idx: 300 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (37938/38528)
Epoch: 229 | Batch_idx: 310 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (39196/39808)
Epoch: 229 | Batch_idx: 320 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (40457/41088)
Epoch: 229 | Batch_idx: 330 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (41722/42368)
Epoch: 229 | Batch_idx: 340 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (42976/43648)
Epoch: 229 | Batch_idx: 350 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (44240/44928)
Epoch: 229 | Batch_idx: 360 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (45494/46208)
Epoch: 229 | Batch_idx: 370 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (46761/47488)
Epoch: 229 | Batch_idx: 380 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (48020/48768)
Epoch: 229 | Batch_idx: 390 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (49226/50000)
# TEST : Loss: (0.4627) | Acc: (88.00%) (8884/10000)
percent tensor([0.5605, 0.5671, 0.5490, 0.5390, 0.5576, 0.5367, 0.5699, 0.5534, 0.5718,
        0.5680, 0.5708, 0.5662, 0.5670, 0.5661, 0.5514, 0.5563],
       device='cuda:0') torch.Size([16])
percent tensor([0.4957, 0.5031, 0.4807, 0.4818, 0.4839, 0.4937, 0.4980, 0.4928, 0.4909,
        0.4939, 0.4994, 0.4814, 0.5024, 0.4986, 0.4926, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.6034, 0.5280, 0.5725, 0.6394, 0.5904, 0.6669, 0.5451, 0.6114, 0.6050,
        0.5401, 0.5667, 0.5200, 0.5440, 0.6576, 0.5566, 0.6162],
       device='cuda:0') torch.Size([16])
percent tensor([0.6991, 0.7442, 0.6335, 0.6232, 0.6380, 0.6470, 0.7190, 0.6569, 0.7064,
        0.7367, 0.7474, 0.6709, 0.7378, 0.7334, 0.6966, 0.7142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5888, 0.5394, 0.7589, 0.7648, 0.7809, 0.7403, 0.6374, 0.6371, 0.6928,
        0.5697, 0.6670, 0.6925, 0.5814, 0.6279, 0.6077, 0.6059],
       device='cuda:0') torch.Size([16])
percent tensor([0.7376, 0.7460, 0.7459, 0.7346, 0.7821, 0.7949, 0.7546, 0.6987, 0.7375,
        0.7248, 0.7072, 0.6904, 0.7361, 0.7397, 0.6797, 0.7587],
       device='cuda:0') torch.Size([16])
percent tensor([0.6980, 0.7819, 0.7288, 0.5881, 0.6944, 0.7980, 0.6717, 0.4958, 0.7935,
        0.7300, 0.7433, 0.7150, 0.7694, 0.7040, 0.5430, 0.5905],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9997, 0.9999, 0.9998, 0.9999, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 230 | Batch_idx: 0 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 230 | Batch_idx: 10 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 230 | Batch_idx: 20 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 230 | Batch_idx: 30 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 230 | Batch_idx: 40 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (5183/5248)
Epoch: 230 | Batch_idx: 50 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (6446/6528)
Epoch: 230 | Batch_idx: 60 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (7713/7808)
Epoch: 230 | Batch_idx: 70 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (8980/9088)
Epoch: 230 | Batch_idx: 80 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (10241/10368)
Epoch: 230 | Batch_idx: 90 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (11503/11648)
Epoch: 230 | Batch_idx: 100 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (12766/12928)
Epoch: 230 | Batch_idx: 110 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (14030/14208)
Epoch: 230 | Batch_idx: 120 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (15290/15488)
Epoch: 230 | Batch_idx: 130 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (16553/16768)
Epoch: 230 | Batch_idx: 140 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (17818/18048)
Epoch: 230 | Batch_idx: 150 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (19077/19328)
Epoch: 230 | Batch_idx: 160 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (20343/20608)
Epoch: 230 | Batch_idx: 170 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (21605/21888)
Epoch: 230 | Batch_idx: 180 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (22866/23168)
Epoch: 230 | Batch_idx: 190 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (24120/24448)
Epoch: 230 | Batch_idx: 200 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (25386/25728)
Epoch: 230 | Batch_idx: 210 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (26641/27008)
Epoch: 230 | Batch_idx: 220 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (27896/28288)
Epoch: 230 | Batch_idx: 230 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (29160/29568)
Epoch: 230 | Batch_idx: 240 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (30417/30848)
Epoch: 230 | Batch_idx: 250 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (31674/32128)
Epoch: 230 | Batch_idx: 260 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (32927/33408)
Epoch: 230 | Batch_idx: 270 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (34187/34688)
Epoch: 230 | Batch_idx: 280 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (35451/35968)
Epoch: 230 | Batch_idx: 290 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (36712/37248)
Epoch: 230 | Batch_idx: 300 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (37975/38528)
Epoch: 230 | Batch_idx: 310 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (39241/39808)
Epoch: 230 | Batch_idx: 320 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (40505/41088)
Epoch: 230 | Batch_idx: 330 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (41759/42368)
Epoch: 230 | Batch_idx: 340 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (43022/43648)
Epoch: 230 | Batch_idx: 350 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (44286/44928)
Epoch: 230 | Batch_idx: 360 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (45550/46208)
Epoch: 230 | Batch_idx: 370 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (46811/47488)
Epoch: 230 | Batch_idx: 380 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (48074/48768)
Epoch: 230 | Batch_idx: 390 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (49289/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_230.pth.tar'
# TEST : Loss: (0.4795) | Acc: (88.00%) (8804/10000)
percent tensor([0.5599, 0.5652, 0.5485, 0.5379, 0.5567, 0.5366, 0.5684, 0.5522, 0.5700,
        0.5668, 0.5689, 0.5650, 0.5660, 0.5629, 0.5502, 0.5551],
       device='cuda:0') torch.Size([16])
percent tensor([0.4974, 0.5009, 0.4844, 0.4834, 0.4868, 0.4950, 0.4981, 0.4940, 0.4930,
        0.4941, 0.4999, 0.4845, 0.5033, 0.4953, 0.4927, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.6060, 0.5285, 0.5722, 0.6412, 0.5834, 0.6743, 0.5409, 0.6103, 0.6069,
        0.5397, 0.5675, 0.5146, 0.5437, 0.6621, 0.5557, 0.6212],
       device='cuda:0') torch.Size([16])
percent tensor([0.6993, 0.7459, 0.6348, 0.6209, 0.6413, 0.6440, 0.7214, 0.6622, 0.7072,
        0.7373, 0.7497, 0.6717, 0.7418, 0.7283, 0.6994, 0.7112],
       device='cuda:0') torch.Size([16])
percent tensor([0.5898, 0.5518, 0.7590, 0.7708, 0.7828, 0.7392, 0.6529, 0.6396, 0.6905,
        0.5886, 0.6685, 0.7021, 0.5907, 0.6473, 0.6140, 0.6076],
       device='cuda:0') torch.Size([16])
percent tensor([0.7280, 0.7405, 0.7433, 0.7240, 0.7792, 0.7895, 0.7503, 0.6967, 0.7281,
        0.7155, 0.6973, 0.6862, 0.7302, 0.7212, 0.6750, 0.7498],
       device='cuda:0') torch.Size([16])
percent tensor([0.6828, 0.8011, 0.6755, 0.5896, 0.6692, 0.7921, 0.6753, 0.4824, 0.7482,
        0.7343, 0.7376, 0.7057, 0.7325, 0.6770, 0.5626, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9997, 0.9998, 0.9998, 0.9999, 0.9997, 0.9997,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(188.8448, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(841.4377, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(848.2583, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1513.4832, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(475.5079, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2311.8235, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4259.4546, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1335.0715, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6349.4570, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11461.2051, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3749.7590, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15794.9111, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 231 | Batch_idx: 0 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 231 | Batch_idx: 10 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 231 | Batch_idx: 20 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (2659/2688)
Epoch: 231 | Batch_idx: 30 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (3926/3968)
Epoch: 231 | Batch_idx: 40 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (99.00%) (5196/5248)
Epoch: 231 | Batch_idx: 50 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (6458/6528)
Epoch: 231 | Batch_idx: 60 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (7726/7808)
Epoch: 231 | Batch_idx: 70 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (8994/9088)
Epoch: 231 | Batch_idx: 80 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (10257/10368)
Epoch: 231 | Batch_idx: 90 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (11526/11648)
Epoch: 231 | Batch_idx: 100 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (12781/12928)
Epoch: 231 | Batch_idx: 110 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (14038/14208)
Epoch: 231 | Batch_idx: 120 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (15304/15488)
Epoch: 231 | Batch_idx: 130 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (16558/16768)
Epoch: 231 | Batch_idx: 140 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (17824/18048)
Epoch: 231 | Batch_idx: 150 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (19082/19328)
Epoch: 231 | Batch_idx: 160 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (20342/20608)
Epoch: 231 | Batch_idx: 170 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (21608/21888)
Epoch: 231 | Batch_idx: 180 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (22864/23168)
Epoch: 231 | Batch_idx: 190 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (24135/24448)
Epoch: 231 | Batch_idx: 200 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (25400/25728)
Epoch: 231 | Batch_idx: 210 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (26660/27008)
Epoch: 231 | Batch_idx: 220 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (27920/28288)
Epoch: 231 | Batch_idx: 230 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (29179/29568)
Epoch: 231 | Batch_idx: 240 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (30440/30848)
Epoch: 231 | Batch_idx: 250 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (31703/32128)
Epoch: 231 | Batch_idx: 260 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (32972/33408)
Epoch: 231 | Batch_idx: 270 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (34231/34688)
Epoch: 231 | Batch_idx: 280 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (35489/35968)
Epoch: 231 | Batch_idx: 290 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (36761/37248)
Epoch: 231 | Batch_idx: 300 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (38017/38528)
Epoch: 231 | Batch_idx: 310 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (39280/39808)
Epoch: 231 | Batch_idx: 320 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (40537/41088)
Epoch: 231 | Batch_idx: 330 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (41797/42368)
Epoch: 231 | Batch_idx: 340 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (43060/43648)
Epoch: 231 | Batch_idx: 350 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (44317/44928)
Epoch: 231 | Batch_idx: 360 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (45572/46208)
Epoch: 231 | Batch_idx: 370 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (46844/47488)
Epoch: 231 | Batch_idx: 380 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (48105/48768)
Epoch: 231 | Batch_idx: 390 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (49322/50000)
# TEST : Loss: (0.4551) | Acc: (88.00%) (8894/10000)
percent tensor([0.5605, 0.5692, 0.5485, 0.5392, 0.5565, 0.5375, 0.5707, 0.5537, 0.5724,
        0.5685, 0.5715, 0.5648, 0.5670, 0.5684, 0.5527, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.5036, 0.4831, 0.4845, 0.4861, 0.4974, 0.4994, 0.4936, 0.4930,
        0.4955, 0.5011, 0.4833, 0.5040, 0.4996, 0.4947, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.6094, 0.5382, 0.5756, 0.6475, 0.5900, 0.6788, 0.5557, 0.6193, 0.6105,
        0.5480, 0.5771, 0.5249, 0.5494, 0.6748, 0.5617, 0.6303],
       device='cuda:0') torch.Size([16])
percent tensor([0.6994, 0.7419, 0.6391, 0.6183, 0.6400, 0.6430, 0.7204, 0.6565, 0.7082,
        0.7391, 0.7470, 0.6712, 0.7381, 0.7275, 0.6939, 0.7111],
       device='cuda:0') torch.Size([16])
percent tensor([0.5930, 0.5531, 0.7665, 0.7785, 0.7932, 0.7420, 0.6531, 0.6508, 0.6842,
        0.5720, 0.6769, 0.7081, 0.5888, 0.6456, 0.6216, 0.6078],
       device='cuda:0') torch.Size([16])
percent tensor([0.7265, 0.7275, 0.7455, 0.7276, 0.7844, 0.7871, 0.7437, 0.6879, 0.7235,
        0.6940, 0.6998, 0.6851, 0.7217, 0.7312, 0.6694, 0.7441],
       device='cuda:0') torch.Size([16])
percent tensor([0.6547, 0.7846, 0.6780, 0.6047, 0.7011, 0.7799, 0.6461, 0.4693, 0.7575,
        0.6853, 0.7263, 0.7237, 0.7240, 0.7092, 0.5287, 0.5623],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9999, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 232 | Batch_idx: 0 |  Loss: (0.0127) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 232 | Batch_idx: 10 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 232 | Batch_idx: 20 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (2655/2688)
Epoch: 232 | Batch_idx: 30 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (3920/3968)
Epoch: 232 | Batch_idx: 40 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (5179/5248)
Epoch: 232 | Batch_idx: 50 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (6444/6528)
Epoch: 232 | Batch_idx: 60 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (7708/7808)
Epoch: 232 | Batch_idx: 70 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (8974/9088)
Epoch: 232 | Batch_idx: 80 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (10237/10368)
Epoch: 232 | Batch_idx: 90 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (11506/11648)
Epoch: 232 | Batch_idx: 100 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (12776/12928)
Epoch: 232 | Batch_idx: 110 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (14042/14208)
Epoch: 232 | Batch_idx: 120 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (15306/15488)
Epoch: 232 | Batch_idx: 130 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (16568/16768)
Epoch: 232 | Batch_idx: 140 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (17834/18048)
Epoch: 232 | Batch_idx: 150 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (19101/19328)
Epoch: 232 | Batch_idx: 160 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (20370/20608)
Epoch: 232 | Batch_idx: 170 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (21636/21888)
Epoch: 232 | Batch_idx: 180 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (22896/23168)
Epoch: 232 | Batch_idx: 190 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (24157/24448)
Epoch: 232 | Batch_idx: 200 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (25418/25728)
Epoch: 232 | Batch_idx: 210 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (26680/27008)
Epoch: 232 | Batch_idx: 220 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (27946/28288)
Epoch: 232 | Batch_idx: 230 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (29210/29568)
Epoch: 232 | Batch_idx: 240 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (30464/30848)
Epoch: 232 | Batch_idx: 250 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (31730/32128)
Epoch: 232 | Batch_idx: 260 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (32991/33408)
Epoch: 232 | Batch_idx: 270 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (34249/34688)
Epoch: 232 | Batch_idx: 280 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (35515/35968)
Epoch: 232 | Batch_idx: 290 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (36777/37248)
Epoch: 232 | Batch_idx: 300 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (38043/38528)
Epoch: 232 | Batch_idx: 310 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (39308/39808)
Epoch: 232 | Batch_idx: 320 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (40573/41088)
Epoch: 232 | Batch_idx: 330 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (41833/42368)
Epoch: 232 | Batch_idx: 340 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (43096/43648)
Epoch: 232 | Batch_idx: 350 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (44361/44928)
Epoch: 232 | Batch_idx: 360 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (45620/46208)
Epoch: 232 | Batch_idx: 370 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (46884/47488)
Epoch: 232 | Batch_idx: 380 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (48146/48768)
Epoch: 232 | Batch_idx: 390 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (49356/50000)
# TEST : Loss: (0.4552) | Acc: (88.00%) (8841/10000)
percent tensor([0.5592, 0.5669, 0.5486, 0.5387, 0.5569, 0.5361, 0.5696, 0.5530, 0.5710,
        0.5679, 0.5695, 0.5655, 0.5661, 0.5663, 0.5507, 0.5559],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.5039, 0.4849, 0.4859, 0.4870, 0.4972, 0.4998, 0.4944, 0.4928,
        0.4961, 0.5004, 0.4846, 0.5036, 0.5002, 0.4950, 0.5009],
       device='cuda:0') torch.Size([16])
percent tensor([0.6023, 0.5318, 0.5717, 0.6454, 0.5805, 0.6688, 0.5462, 0.6159, 0.6063,
        0.5449, 0.5701, 0.5198, 0.5416, 0.6745, 0.5541, 0.6240],
       device='cuda:0') torch.Size([16])
percent tensor([0.7009, 0.7446, 0.6377, 0.6228, 0.6409, 0.6420, 0.7229, 0.6585, 0.7078,
        0.7409, 0.7474, 0.6771, 0.7417, 0.7308, 0.6959, 0.7135],
       device='cuda:0') torch.Size([16])
percent tensor([0.5964, 0.5669, 0.7637, 0.7719, 0.7866, 0.7364, 0.6671, 0.6531, 0.7162,
        0.5898, 0.6967, 0.7081, 0.6016, 0.6782, 0.6245, 0.6068],
       device='cuda:0') torch.Size([16])
percent tensor([0.7363, 0.7437, 0.7597, 0.7340, 0.7842, 0.7935, 0.7524, 0.6981, 0.7281,
        0.7229, 0.7033, 0.6974, 0.7254, 0.7296, 0.6738, 0.7569],
       device='cuda:0') torch.Size([16])
percent tensor([0.6733, 0.7965, 0.7071, 0.5964, 0.6750, 0.7946, 0.6877, 0.4814, 0.7691,
        0.7310, 0.7383, 0.7049, 0.7363, 0.6888, 0.5224, 0.5883],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 233 | Batch_idx: 0 |  Loss: (0.0182) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 233 | Batch_idx: 10 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 233 | Batch_idx: 20 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 233 | Batch_idx: 30 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (3916/3968)
Epoch: 233 | Batch_idx: 40 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (5179/5248)
Epoch: 233 | Batch_idx: 50 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (6450/6528)
Epoch: 233 | Batch_idx: 60 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (7719/7808)
Epoch: 233 | Batch_idx: 70 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (8986/9088)
Epoch: 233 | Batch_idx: 80 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (10252/10368)
Epoch: 233 | Batch_idx: 90 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (11516/11648)
Epoch: 233 | Batch_idx: 100 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (12780/12928)
Epoch: 233 | Batch_idx: 110 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (14042/14208)
Epoch: 233 | Batch_idx: 120 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (15302/15488)
Epoch: 233 | Batch_idx: 130 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (16570/16768)
Epoch: 233 | Batch_idx: 140 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (17836/18048)
Epoch: 233 | Batch_idx: 150 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (19094/19328)
Epoch: 233 | Batch_idx: 160 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (20358/20608)
Epoch: 233 | Batch_idx: 170 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (21608/21888)
Epoch: 233 | Batch_idx: 180 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (22871/23168)
Epoch: 233 | Batch_idx: 190 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (24130/24448)
Epoch: 233 | Batch_idx: 200 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (25392/25728)
Epoch: 233 | Batch_idx: 210 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (26660/27008)
Epoch: 233 | Batch_idx: 220 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (27921/28288)
Epoch: 233 | Batch_idx: 230 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (29182/29568)
Epoch: 233 | Batch_idx: 240 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (30443/30848)
Epoch: 233 | Batch_idx: 250 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (31703/32128)
Epoch: 233 | Batch_idx: 260 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (32961/33408)
Epoch: 233 | Batch_idx: 270 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (34225/34688)
Epoch: 233 | Batch_idx: 280 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (35478/35968)
Epoch: 233 | Batch_idx: 290 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (36740/37248)
Epoch: 233 | Batch_idx: 300 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (38001/38528)
Epoch: 233 | Batch_idx: 310 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (39269/39808)
Epoch: 233 | Batch_idx: 320 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (40532/41088)
Epoch: 233 | Batch_idx: 330 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (41792/42368)
Epoch: 233 | Batch_idx: 340 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (43050/43648)
Epoch: 233 | Batch_idx: 350 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (44311/44928)
Epoch: 233 | Batch_idx: 360 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (45568/46208)
Epoch: 233 | Batch_idx: 370 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (46835/47488)
Epoch: 233 | Batch_idx: 380 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (48094/48768)
Epoch: 233 | Batch_idx: 390 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (49306/50000)
# TEST : Loss: (0.4645) | Acc: (88.00%) (8824/10000)
percent tensor([0.5591, 0.5651, 0.5493, 0.5383, 0.5566, 0.5355, 0.5681, 0.5530, 0.5708,
        0.5669, 0.5692, 0.5650, 0.5660, 0.5638, 0.5498, 0.5551],
       device='cuda:0') torch.Size([16])
percent tensor([0.4997, 0.5059, 0.4858, 0.4858, 0.4881, 0.4980, 0.5016, 0.4961, 0.4956,
        0.4977, 0.5032, 0.4855, 0.5057, 0.5014, 0.4962, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.6156, 0.5407, 0.5798, 0.6499, 0.5921, 0.6743, 0.5577, 0.6219, 0.6160,
        0.5521, 0.5807, 0.5268, 0.5531, 0.6784, 0.5604, 0.6341],
       device='cuda:0') torch.Size([16])
percent tensor([0.7039, 0.7460, 0.6434, 0.6281, 0.6415, 0.6471, 0.7210, 0.6614, 0.7119,
        0.7432, 0.7514, 0.6785, 0.7440, 0.7325, 0.6988, 0.7158],
       device='cuda:0') torch.Size([16])
percent tensor([0.5924, 0.5569, 0.7672, 0.7790, 0.7882, 0.7419, 0.6605, 0.6505, 0.6918,
        0.5828, 0.6722, 0.7111, 0.5971, 0.6617, 0.6177, 0.6075],
       device='cuda:0') torch.Size([16])
percent tensor([0.7414, 0.7528, 0.7499, 0.7367, 0.7858, 0.7955, 0.7576, 0.6996, 0.7424,
        0.7342, 0.7154, 0.7028, 0.7374, 0.7483, 0.6835, 0.7652],
       device='cuda:0') torch.Size([16])
percent tensor([0.6798, 0.7864, 0.6791, 0.5825, 0.6720, 0.7873, 0.6951, 0.4751, 0.7666,
        0.7197, 0.7515, 0.7035, 0.7230, 0.7079, 0.5326, 0.5994],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9999, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 234 | Batch_idx: 0 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 234 | Batch_idx: 10 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 234 | Batch_idx: 20 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (2659/2688)
Epoch: 234 | Batch_idx: 30 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (3926/3968)
Epoch: 234 | Batch_idx: 40 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (5188/5248)
Epoch: 234 | Batch_idx: 50 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (6455/6528)
Epoch: 234 | Batch_idx: 60 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (7724/7808)
Epoch: 234 | Batch_idx: 70 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (8988/9088)
Epoch: 234 | Batch_idx: 80 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (10254/10368)
Epoch: 234 | Batch_idx: 90 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (11511/11648)
Epoch: 234 | Batch_idx: 100 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (12773/12928)
Epoch: 234 | Batch_idx: 110 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (14033/14208)
Epoch: 234 | Batch_idx: 120 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (15293/15488)
Epoch: 234 | Batch_idx: 130 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (16555/16768)
Epoch: 234 | Batch_idx: 140 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (17822/18048)
Epoch: 234 | Batch_idx: 150 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (19085/19328)
Epoch: 234 | Batch_idx: 160 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (20351/20608)
Epoch: 234 | Batch_idx: 170 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (21612/21888)
Epoch: 234 | Batch_idx: 180 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (22871/23168)
Epoch: 234 | Batch_idx: 190 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (24136/24448)
Epoch: 234 | Batch_idx: 200 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (25397/25728)
Epoch: 234 | Batch_idx: 210 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (26665/27008)
Epoch: 234 | Batch_idx: 220 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (27934/28288)
Epoch: 234 | Batch_idx: 230 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (29204/29568)
Epoch: 234 | Batch_idx: 240 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (30472/30848)
Epoch: 234 | Batch_idx: 250 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (31731/32128)
Epoch: 234 | Batch_idx: 260 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (32997/33408)
Epoch: 234 | Batch_idx: 270 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (34254/34688)
Epoch: 234 | Batch_idx: 280 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (35518/35968)
Epoch: 234 | Batch_idx: 290 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (36781/37248)
Epoch: 234 | Batch_idx: 300 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (38051/38528)
Epoch: 234 | Batch_idx: 310 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (39313/39808)
Epoch: 234 | Batch_idx: 320 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (40581/41088)
Epoch: 234 | Batch_idx: 330 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (41848/42368)
Epoch: 234 | Batch_idx: 340 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (43110/43648)
Epoch: 234 | Batch_idx: 350 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (44376/44928)
Epoch: 234 | Batch_idx: 360 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (45635/46208)
Epoch: 234 | Batch_idx: 370 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (46896/47488)
Epoch: 234 | Batch_idx: 380 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (48160/48768)
Epoch: 234 | Batch_idx: 390 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (49370/50000)
# TEST : Loss: (0.4329) | Acc: (89.00%) (8933/10000)
percent tensor([0.5601, 0.5655, 0.5537, 0.5413, 0.5606, 0.5363, 0.5697, 0.5552, 0.5712,
        0.5690, 0.5689, 0.5689, 0.5666, 0.5633, 0.5508, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.5017, 0.5065, 0.4877, 0.4871, 0.4898, 0.5007, 0.5030, 0.4973, 0.4972,
        0.4985, 0.5042, 0.4880, 0.5069, 0.5025, 0.4979, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.6108, 0.5327, 0.5734, 0.6456, 0.5856, 0.6769, 0.5525, 0.6153, 0.6123,
        0.5451, 0.5734, 0.5228, 0.5441, 0.6715, 0.5594, 0.6269],
       device='cuda:0') torch.Size([16])
percent tensor([0.7010, 0.7490, 0.6440, 0.6255, 0.6421, 0.6457, 0.7220, 0.6636, 0.7058,
        0.7424, 0.7482, 0.6764, 0.7433, 0.7330, 0.6995, 0.7170],
       device='cuda:0') torch.Size([16])
percent tensor([0.6007, 0.5504, 0.7699, 0.7668, 0.7880, 0.7346, 0.6657, 0.6502, 0.7086,
        0.5752, 0.6791, 0.7059, 0.5979, 0.6404, 0.6148, 0.6032],
       device='cuda:0') torch.Size([16])
percent tensor([0.7510, 0.7550, 0.7637, 0.7207, 0.7974, 0.7968, 0.7578, 0.7057, 0.7462,
        0.7246, 0.7139, 0.7058, 0.7454, 0.7464, 0.6859, 0.7671],
       device='cuda:0') torch.Size([16])
percent tensor([0.7012, 0.7919, 0.7213, 0.5292, 0.7110, 0.7945, 0.6822, 0.4942, 0.7756,
        0.7117, 0.7495, 0.7051, 0.7465, 0.6825, 0.5473, 0.5925],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9997, 0.9998, 0.9999, 0.9998, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9996, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 235 | Batch_idx: 0 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 235 | Batch_idx: 10 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 235 | Batch_idx: 20 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 235 | Batch_idx: 30 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (3913/3968)
Epoch: 235 | Batch_idx: 40 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 235 | Batch_idx: 50 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (6439/6528)
Epoch: 235 | Batch_idx: 60 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (7707/7808)
Epoch: 235 | Batch_idx: 70 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (8974/9088)
Epoch: 235 | Batch_idx: 80 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (10234/10368)
Epoch: 235 | Batch_idx: 90 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (11498/11648)
Epoch: 235 | Batch_idx: 100 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (12763/12928)
Epoch: 235 | Batch_idx: 110 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (14029/14208)
Epoch: 235 | Batch_idx: 120 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (15288/15488)
Epoch: 235 | Batch_idx: 130 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (16552/16768)
Epoch: 235 | Batch_idx: 140 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (17818/18048)
Epoch: 235 | Batch_idx: 150 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (19082/19328)
Epoch: 235 | Batch_idx: 160 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (20339/20608)
Epoch: 235 | Batch_idx: 170 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (21602/21888)
Epoch: 235 | Batch_idx: 180 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (22861/23168)
Epoch: 235 | Batch_idx: 190 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (24127/24448)
Epoch: 235 | Batch_idx: 200 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (25383/25728)
Epoch: 235 | Batch_idx: 210 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (26648/27008)
Epoch: 235 | Batch_idx: 220 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (27903/28288)
Epoch: 235 | Batch_idx: 230 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (29166/29568)
Epoch: 235 | Batch_idx: 240 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (30435/30848)
Epoch: 235 | Batch_idx: 250 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (31699/32128)
Epoch: 235 | Batch_idx: 260 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (32953/33408)
Epoch: 235 | Batch_idx: 270 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (34216/34688)
Epoch: 235 | Batch_idx: 280 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (35474/35968)
Epoch: 235 | Batch_idx: 290 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (36733/37248)
Epoch: 235 | Batch_idx: 300 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (37994/38528)
Epoch: 235 | Batch_idx: 310 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (39257/39808)
Epoch: 235 | Batch_idx: 320 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (40519/41088)
Epoch: 235 | Batch_idx: 330 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (41771/42368)
Epoch: 235 | Batch_idx: 340 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (43036/43648)
Epoch: 235 | Batch_idx: 350 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (44290/44928)
Epoch: 235 | Batch_idx: 360 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (45558/46208)
Epoch: 235 | Batch_idx: 370 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (46817/47488)
Epoch: 235 | Batch_idx: 380 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (48081/48768)
Epoch: 235 | Batch_idx: 390 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (49294/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_235.pth.tar'
# TEST : Loss: (0.4569) | Acc: (88.00%) (8896/10000)
percent tensor([0.5605, 0.5683, 0.5471, 0.5384, 0.5558, 0.5382, 0.5700, 0.5526, 0.5722,
        0.5680, 0.5714, 0.5646, 0.5671, 0.5680, 0.5522, 0.5568],
       device='cuda:0') torch.Size([16])
percent tensor([0.5013, 0.5076, 0.4863, 0.4868, 0.4894, 0.5006, 0.5038, 0.4977, 0.4965,
        0.4990, 0.5047, 0.4866, 0.5072, 0.5039, 0.4980, 0.5051],
       device='cuda:0') torch.Size([16])
percent tensor([0.5999, 0.5309, 0.5601, 0.6321, 0.5754, 0.6612, 0.5461, 0.6082, 0.6056,
        0.5404, 0.5730, 0.5083, 0.5400, 0.6736, 0.5474, 0.6213],
       device='cuda:0') torch.Size([16])
percent tensor([0.7025, 0.7487, 0.6443, 0.6244, 0.6429, 0.6472, 0.7247, 0.6611, 0.7130,
        0.7452, 0.7531, 0.6848, 0.7456, 0.7328, 0.7015, 0.7171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5911, 0.5519, 0.7556, 0.7745, 0.7771, 0.7402, 0.6512, 0.6386, 0.6874,
        0.5776, 0.6754, 0.6824, 0.5950, 0.6517, 0.6117, 0.6090],
       device='cuda:0') torch.Size([16])
percent tensor([0.7389, 0.7493, 0.7533, 0.7246, 0.7889, 0.7951, 0.7533, 0.7014, 0.7408,
        0.7232, 0.7118, 0.6986, 0.7408, 0.7338, 0.6787, 0.7600],
       device='cuda:0') torch.Size([16])
percent tensor([0.6915, 0.7831, 0.6925, 0.5850, 0.6980, 0.8061, 0.7013, 0.4944, 0.7642,
        0.7228, 0.7503, 0.7261, 0.7378, 0.6725, 0.5579, 0.5984],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9997, 0.9998, 0.9999, 0.9999, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 236 | Batch_idx: 0 |  Loss: (0.0143) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 236 | Batch_idx: 10 |  Loss: (0.0276) |  Loss2: (0.0000) | Acc: (99.00%) (1401/1408)
Epoch: 236 | Batch_idx: 20 |  Loss: (0.0297) |  Loss2: (0.0000) | Acc: (99.00%) (2666/2688)
Epoch: 236 | Batch_idx: 30 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (3927/3968)
Epoch: 236 | Batch_idx: 40 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (5191/5248)
Epoch: 236 | Batch_idx: 50 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (6453/6528)
Epoch: 236 | Batch_idx: 60 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (7718/7808)
Epoch: 236 | Batch_idx: 70 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (8978/9088)
Epoch: 236 | Batch_idx: 80 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (10240/10368)
Epoch: 236 | Batch_idx: 90 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (11506/11648)
Epoch: 236 | Batch_idx: 100 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (12769/12928)
Epoch: 236 | Batch_idx: 110 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (14038/14208)
Epoch: 236 | Batch_idx: 120 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (15299/15488)
Epoch: 236 | Batch_idx: 130 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (16567/16768)
Epoch: 236 | Batch_idx: 140 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (17827/18048)
Epoch: 236 | Batch_idx: 150 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (19091/19328)
Epoch: 236 | Batch_idx: 160 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (20352/20608)
Epoch: 236 | Batch_idx: 170 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (21614/21888)
Epoch: 236 | Batch_idx: 180 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (22878/23168)
Epoch: 236 | Batch_idx: 190 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (24142/24448)
Epoch: 236 | Batch_idx: 200 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (25405/25728)
Epoch: 236 | Batch_idx: 210 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (26678/27008)
Epoch: 236 | Batch_idx: 220 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (27947/28288)
Epoch: 236 | Batch_idx: 230 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (29206/29568)
Epoch: 236 | Batch_idx: 240 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (30469/30848)
Epoch: 236 | Batch_idx: 250 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (31734/32128)
Epoch: 236 | Batch_idx: 260 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (32994/33408)
Epoch: 236 | Batch_idx: 270 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (34259/34688)
Epoch: 236 | Batch_idx: 280 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (35524/35968)
Epoch: 236 | Batch_idx: 290 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (36787/37248)
Epoch: 236 | Batch_idx: 300 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (38054/38528)
Epoch: 236 | Batch_idx: 310 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (39308/39808)
Epoch: 236 | Batch_idx: 320 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (40573/41088)
Epoch: 236 | Batch_idx: 330 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (41835/42368)
Epoch: 236 | Batch_idx: 340 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (43097/43648)
Epoch: 236 | Batch_idx: 350 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (44360/44928)
Epoch: 236 | Batch_idx: 360 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (45623/46208)
Epoch: 236 | Batch_idx: 370 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (46889/47488)
Epoch: 236 | Batch_idx: 380 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (48152/48768)
Epoch: 236 | Batch_idx: 390 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (49370/50000)
# TEST : Loss: (0.4463) | Acc: (88.00%) (8889/10000)
percent tensor([0.5589, 0.5687, 0.5455, 0.5392, 0.5543, 0.5360, 0.5691, 0.5529, 0.5699,
        0.5678, 0.5697, 0.5628, 0.5660, 0.5682, 0.5521, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.5007, 0.5058, 0.4857, 0.4854, 0.4885, 0.4994, 0.5023, 0.4957, 0.4968,
        0.4977, 0.5036, 0.4862, 0.5063, 0.5018, 0.4962, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.6103, 0.5369, 0.5733, 0.6421, 0.5891, 0.6687, 0.5543, 0.6179, 0.6114,
        0.5459, 0.5784, 0.5219, 0.5501, 0.6706, 0.5588, 0.6286],
       device='cuda:0') torch.Size([16])
percent tensor([0.7073, 0.7492, 0.6452, 0.6263, 0.6427, 0.6466, 0.7251, 0.6592, 0.7120,
        0.7472, 0.7555, 0.6806, 0.7499, 0.7342, 0.6983, 0.7184],
       device='cuda:0') torch.Size([16])
percent tensor([0.5809, 0.5507, 0.7604, 0.7772, 0.7837, 0.7237, 0.6590, 0.6574, 0.6899,
        0.5648, 0.6669, 0.7029, 0.5772, 0.6550, 0.6227, 0.5982],
       device='cuda:0') torch.Size([16])
percent tensor([0.7393, 0.7549, 0.7537, 0.7190, 0.7904, 0.7934, 0.7599, 0.6972, 0.7469,
        0.7257, 0.7090, 0.6982, 0.7431, 0.7397, 0.6821, 0.7609],
       device='cuda:0') torch.Size([16])
percent tensor([0.6834, 0.7943, 0.6694, 0.5375, 0.6946, 0.7811, 0.6922, 0.4834, 0.7765,
        0.7068, 0.7421, 0.6744, 0.7475, 0.6858, 0.5566, 0.5927],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9997, 0.9998, 0.9999, 0.9999, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 237 | Batch_idx: 0 |  Loss: (0.0118) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 237 | Batch_idx: 10 |  Loss: (0.0336) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 237 | Batch_idx: 20 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (2653/2688)
Epoch: 237 | Batch_idx: 30 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 237 | Batch_idx: 40 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (5185/5248)
Epoch: 237 | Batch_idx: 50 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (6448/6528)
Epoch: 237 | Batch_idx: 60 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (7711/7808)
Epoch: 237 | Batch_idx: 70 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (8964/9088)
Epoch: 237 | Batch_idx: 80 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (10234/10368)
Epoch: 237 | Batch_idx: 90 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (11490/11648)
Epoch: 237 | Batch_idx: 100 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (12751/12928)
Epoch: 237 | Batch_idx: 110 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (14014/14208)
Epoch: 237 | Batch_idx: 120 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (15276/15488)
Epoch: 237 | Batch_idx: 130 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (16536/16768)
Epoch: 237 | Batch_idx: 140 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (17803/18048)
Epoch: 237 | Batch_idx: 150 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (19068/19328)
Epoch: 237 | Batch_idx: 160 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (20328/20608)
Epoch: 237 | Batch_idx: 170 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (21590/21888)
Epoch: 237 | Batch_idx: 180 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (22852/23168)
Epoch: 237 | Batch_idx: 190 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (24116/24448)
Epoch: 237 | Batch_idx: 200 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (25384/25728)
Epoch: 237 | Batch_idx: 210 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (26644/27008)
Epoch: 237 | Batch_idx: 220 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (27909/28288)
Epoch: 237 | Batch_idx: 230 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (29171/29568)
Epoch: 237 | Batch_idx: 240 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (30436/30848)
Epoch: 237 | Batch_idx: 250 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (31701/32128)
Epoch: 237 | Batch_idx: 260 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (32971/33408)
Epoch: 237 | Batch_idx: 270 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (34240/34688)
Epoch: 237 | Batch_idx: 280 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (35499/35968)
Epoch: 237 | Batch_idx: 290 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (36757/37248)
Epoch: 237 | Batch_idx: 300 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (38024/38528)
Epoch: 237 | Batch_idx: 310 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (39288/39808)
Epoch: 237 | Batch_idx: 320 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (40553/41088)
Epoch: 237 | Batch_idx: 330 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (41818/42368)
Epoch: 237 | Batch_idx: 340 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (43086/43648)
Epoch: 237 | Batch_idx: 350 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (44350/44928)
Epoch: 237 | Batch_idx: 360 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (45606/46208)
Epoch: 237 | Batch_idx: 370 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (46873/47488)
Epoch: 237 | Batch_idx: 380 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (48140/48768)
Epoch: 237 | Batch_idx: 390 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (49358/50000)
# TEST : Loss: (0.4461) | Acc: (89.00%) (8909/10000)
percent tensor([0.5597, 0.5705, 0.5452, 0.5401, 0.5545, 0.5379, 0.5706, 0.5534, 0.5709,
        0.5691, 0.5710, 0.5631, 0.5672, 0.5706, 0.5535, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.5008, 0.5070, 0.4855, 0.4864, 0.4883, 0.4994, 0.5030, 0.4961, 0.4958,
        0.4977, 0.5037, 0.4857, 0.5065, 0.5044, 0.4968, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.6145, 0.5335, 0.5777, 0.6499, 0.5918, 0.6735, 0.5520, 0.6203, 0.6068,
        0.5458, 0.5729, 0.5217, 0.5521, 0.6729, 0.5595, 0.6307],
       device='cuda:0') torch.Size([16])
percent tensor([0.7002, 0.7467, 0.6400, 0.6251, 0.6355, 0.6398, 0.7218, 0.6625, 0.7084,
        0.7426, 0.7504, 0.6738, 0.7416, 0.7351, 0.6971, 0.7117],
       device='cuda:0') torch.Size([16])
percent tensor([0.6040, 0.5660, 0.7639, 0.7766, 0.7853, 0.7364, 0.6630, 0.6489, 0.7073,
        0.5856, 0.6858, 0.7166, 0.5957, 0.6699, 0.6257, 0.6190],
       device='cuda:0') torch.Size([16])
percent tensor([0.7440, 0.7538, 0.7556, 0.7326, 0.7896, 0.7897, 0.7679, 0.7019, 0.7467,
        0.7184, 0.7109, 0.7002, 0.7430, 0.7532, 0.6835, 0.7605],
       device='cuda:0') torch.Size([16])
percent tensor([0.7023, 0.8129, 0.7145, 0.6095, 0.7211, 0.8000, 0.7138, 0.5010, 0.7856,
        0.7319, 0.7394, 0.7237, 0.7453, 0.7114, 0.5729, 0.6029],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9999, 0.9996, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 238 | Batch_idx: 0 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 238 | Batch_idx: 10 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 238 | Batch_idx: 20 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 238 | Batch_idx: 30 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (3919/3968)
Epoch: 238 | Batch_idx: 40 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (5188/5248)
Epoch: 238 | Batch_idx: 50 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (6451/6528)
Epoch: 238 | Batch_idx: 60 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (7721/7808)
Epoch: 238 | Batch_idx: 70 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (8989/9088)
Epoch: 238 | Batch_idx: 80 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (10248/10368)
Epoch: 238 | Batch_idx: 90 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (11515/11648)
Epoch: 238 | Batch_idx: 100 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (12775/12928)
Epoch: 238 | Batch_idx: 110 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (14036/14208)
Epoch: 238 | Batch_idx: 120 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (15301/15488)
Epoch: 238 | Batch_idx: 130 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (16565/16768)
Epoch: 238 | Batch_idx: 140 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (17836/18048)
Epoch: 238 | Batch_idx: 150 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (19101/19328)
Epoch: 238 | Batch_idx: 160 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (20359/20608)
Epoch: 238 | Batch_idx: 170 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (21625/21888)
Epoch: 238 | Batch_idx: 180 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (22890/23168)
Epoch: 238 | Batch_idx: 190 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (24146/24448)
Epoch: 238 | Batch_idx: 200 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (25410/25728)
Epoch: 238 | Batch_idx: 210 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (26674/27008)
Epoch: 238 | Batch_idx: 220 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (27942/28288)
Epoch: 238 | Batch_idx: 230 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (29205/29568)
Epoch: 238 | Batch_idx: 240 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (30475/30848)
Epoch: 238 | Batch_idx: 250 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (31748/32128)
Epoch: 238 | Batch_idx: 260 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (33014/33408)
Epoch: 238 | Batch_idx: 270 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (34284/34688)
Epoch: 238 | Batch_idx: 280 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (35552/35968)
Epoch: 238 | Batch_idx: 290 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (36814/37248)
Epoch: 238 | Batch_idx: 300 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (38080/38528)
Epoch: 238 | Batch_idx: 310 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (39341/39808)
Epoch: 238 | Batch_idx: 320 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (40604/41088)
Epoch: 238 | Batch_idx: 330 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (41872/42368)
Epoch: 238 | Batch_idx: 340 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (43140/43648)
Epoch: 238 | Batch_idx: 350 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (44403/44928)
Epoch: 238 | Batch_idx: 360 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (45667/46208)
Epoch: 238 | Batch_idx: 370 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (46929/47488)
Epoch: 238 | Batch_idx: 380 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (48194/48768)
Epoch: 238 | Batch_idx: 390 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (49414/50000)
# TEST : Loss: (0.4438) | Acc: (88.00%) (8879/10000)
percent tensor([0.5607, 0.5683, 0.5485, 0.5408, 0.5567, 0.5382, 0.5699, 0.5540, 0.5709,
        0.5688, 0.5705, 0.5649, 0.5672, 0.5670, 0.5526, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.5019, 0.5066, 0.4868, 0.4874, 0.4894, 0.5019, 0.5031, 0.4970, 0.4967,
        0.4987, 0.5045, 0.4870, 0.5071, 0.5023, 0.4980, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.6121, 0.5360, 0.5739, 0.6426, 0.5900, 0.6731, 0.5555, 0.6194, 0.6120,
        0.5501, 0.5797, 0.5228, 0.5485, 0.6752, 0.5586, 0.6285],
       device='cuda:0') torch.Size([16])
percent tensor([0.7061, 0.7496, 0.6434, 0.6259, 0.6395, 0.6454, 0.7238, 0.6656, 0.7134,
        0.7436, 0.7538, 0.6785, 0.7464, 0.7352, 0.7001, 0.7165],
       device='cuda:0') torch.Size([16])
percent tensor([0.5952, 0.5445, 0.7769, 0.7794, 0.7970, 0.7399, 0.6560, 0.6493, 0.6862,
        0.5776, 0.6677, 0.7246, 0.5915, 0.6368, 0.6216, 0.6139],
       device='cuda:0') torch.Size([16])
percent tensor([0.7381, 0.7530, 0.7529, 0.7312, 0.7883, 0.7963, 0.7611, 0.7026, 0.7378,
        0.7255, 0.7074, 0.7200, 0.7418, 0.7499, 0.6870, 0.7603],
       device='cuda:0') torch.Size([16])
percent tensor([0.6947, 0.7997, 0.7189, 0.5808, 0.7135, 0.8140, 0.6966, 0.5142, 0.7600,
        0.7191, 0.7374, 0.7547, 0.7295, 0.7323, 0.5807, 0.5878],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9999, 0.9998, 0.9999, 0.9997, 0.9998,
        1.0000, 1.0000, 0.9998, 0.9998, 0.9997, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 239 | Batch_idx: 0 |  Loss: (0.0142) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 239 | Batch_idx: 10 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 239 | Batch_idx: 20 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 239 | Batch_idx: 30 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (3912/3968)
Epoch: 239 | Batch_idx: 40 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (5182/5248)
Epoch: 239 | Batch_idx: 50 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (6449/6528)
Epoch: 239 | Batch_idx: 60 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (7708/7808)
Epoch: 239 | Batch_idx: 70 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (8969/9088)
Epoch: 239 | Batch_idx: 80 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (10236/10368)
Epoch: 239 | Batch_idx: 90 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (11504/11648)
Epoch: 239 | Batch_idx: 100 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (12768/12928)
Epoch: 239 | Batch_idx: 110 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (14033/14208)
Epoch: 239 | Batch_idx: 120 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (15292/15488)
Epoch: 239 | Batch_idx: 130 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (16560/16768)
Epoch: 239 | Batch_idx: 140 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (17823/18048)
Epoch: 239 | Batch_idx: 150 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (19088/19328)
Epoch: 239 | Batch_idx: 160 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (20355/20608)
Epoch: 239 | Batch_idx: 170 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (21623/21888)
Epoch: 239 | Batch_idx: 180 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (22885/23168)
Epoch: 239 | Batch_idx: 190 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (24146/24448)
Epoch: 239 | Batch_idx: 200 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (25416/25728)
Epoch: 239 | Batch_idx: 210 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (26682/27008)
Epoch: 239 | Batch_idx: 220 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (27948/28288)
Epoch: 239 | Batch_idx: 230 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (29208/29568)
Epoch: 239 | Batch_idx: 240 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (30467/30848)
Epoch: 239 | Batch_idx: 250 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (31725/32128)
Epoch: 239 | Batch_idx: 260 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (32987/33408)
Epoch: 239 | Batch_idx: 270 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (34246/34688)
Epoch: 239 | Batch_idx: 280 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (35505/35968)
Epoch: 239 | Batch_idx: 290 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (36774/37248)
Epoch: 239 | Batch_idx: 300 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (38028/38528)
Epoch: 239 | Batch_idx: 310 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (39293/39808)
Epoch: 239 | Batch_idx: 320 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (40564/41088)
Epoch: 239 | Batch_idx: 330 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (41831/42368)
Epoch: 239 | Batch_idx: 340 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (43095/43648)
Epoch: 239 | Batch_idx: 350 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (44361/44928)
Epoch: 239 | Batch_idx: 360 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (45628/46208)
Epoch: 239 | Batch_idx: 370 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (46891/47488)
Epoch: 239 | Batch_idx: 380 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (48158/48768)
Epoch: 239 | Batch_idx: 390 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (49381/50000)
# TEST : Loss: (0.4384) | Acc: (88.00%) (8869/10000)
percent tensor([0.5626, 0.5685, 0.5508, 0.5415, 0.5595, 0.5409, 0.5712, 0.5545, 0.5720,
        0.5696, 0.5720, 0.5675, 0.5687, 0.5669, 0.5540, 0.5587],
       device='cuda:0') torch.Size([16])
percent tensor([0.5049, 0.5097, 0.4895, 0.4891, 0.4916, 0.5032, 0.5055, 0.5008, 0.5009,
        0.5017, 0.5083, 0.4899, 0.5107, 0.5057, 0.5002, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.6198, 0.5381, 0.5717, 0.6511, 0.5863, 0.6765, 0.5546, 0.6366, 0.6173,
        0.5523, 0.5780, 0.5159, 0.5516, 0.6776, 0.5633, 0.6373],
       device='cuda:0') torch.Size([16])
percent tensor([0.7040, 0.7470, 0.6501, 0.6278, 0.6445, 0.6443, 0.7215, 0.6611, 0.7082,
        0.7431, 0.7520, 0.6830, 0.7445, 0.7277, 0.6999, 0.7133],
       device='cuda:0') torch.Size([16])
percent tensor([0.6034, 0.5607, 0.7649, 0.7811, 0.7910, 0.7405, 0.6792, 0.6579, 0.7042,
        0.5816, 0.6720, 0.7149, 0.5959, 0.6675, 0.6353, 0.6275],
       device='cuda:0') torch.Size([16])
percent tensor([0.7432, 0.7577, 0.7634, 0.7291, 0.7977, 0.8027, 0.7537, 0.7104, 0.7559,
        0.7213, 0.7195, 0.7048, 0.7520, 0.7530, 0.6914, 0.7654],
       device='cuda:0') torch.Size([16])
percent tensor([0.6925, 0.8049, 0.6798, 0.5715, 0.7041, 0.7964, 0.6690, 0.5117, 0.7822,
        0.7259, 0.7558, 0.6769, 0.7411, 0.7315, 0.5727, 0.5973],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9998, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(189.3140, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(843.4600, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(850.3837, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1513.9065, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(474.1245, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2317.7383, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4259.9917, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1330.7478, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6368.6284, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11435.9141, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3736.6350, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15737.8398, device='cuda:0', grad_fn=<NormBackward0>)
6 hours 12 mins 16 secs for training